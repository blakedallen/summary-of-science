{"id": "http://arxiv.org/abs/1007.0906v1", "guidislink": true, "updated": "2010-07-06T14:35:59Z", "updated_parsed": [2010, 7, 6, 14, 35, 59, 1, 187, 0], "published": "2010-07-06T14:35:59Z", "published_parsed": [2010, 7, 6, 14, 35, 59, 1, 187, 0], "title": "Matrix Algebras and Semidefinite Programming Techniques for Codes", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1007.0123%2C1007.3558%2C1007.0406%2C1007.4969%2C1007.3853%2C1007.1919%2C1007.4674%2C1007.0921%2C1007.3603%2C1007.5504%2C1007.5268%2C1007.0082%2C1007.1749%2C1007.4021%2C1007.1327%2C1007.1047%2C1007.5261%2C1007.5185%2C1007.0906%2C1007.0682%2C1007.0499%2C1007.0222%2C1007.2205%2C1007.5054%2C1007.0274%2C1007.1930%2C1007.2027%2C1007.4839%2C1007.0882%2C1007.2624%2C1007.4917%2C1007.4895%2C1007.2447%2C1007.1276%2C1007.4280%2C1007.1241%2C1007.1367%2C1007.1617%2C1007.1588%2C1007.4962%2C1007.1211%2C1007.0536%2C1007.3172%2C1007.0350%2C1007.5256%2C1007.4392%2C1007.2464%2C1007.1612%2C1007.1788%2C1007.2180%2C1007.0062%2C1007.3002%2C1007.1257%2C1007.2421%2C1007.0055%2C1007.3370%2C1007.0078%2C1007.1846%2C1007.0369%2C1007.5127%2C1007.2492%2C1007.3571%2C1007.3476%2C1007.1870%2C1007.3004%2C1007.3832%2C1007.1333%2C1007.1723%2C1007.4146%2C1007.1874%2C1007.1188%2C1007.2741%2C1007.1114%2C1007.4221%2C1007.2130%2C1007.4473%2C1007.4102%2C1007.3869%2C1007.4893%2C1007.4705%2C1007.3159%2C1007.3062%2C1007.3509%2C1007.1100%2C1007.3757%2C1007.4749%2C1007.0071%2C1007.1420%2C1007.2202%2C1007.1514%2C1007.4193%2C1007.0839%2C1007.2088%2C1007.0259%2C1007.4170%2C1007.3592%2C1007.3244%2C1007.1373%2C1007.1170%2C1007.3860%2C1007.5362&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Matrix Algebras and Semidefinite Programming Techniques for Codes"}, "summary": "This PhD thesis is concerned with SDP bounds for codes: upper bounds for\n(non)-binary error correcting codes and lower bounds for (non)-binary covering\ncodes. The methods are based on the method of Schrijver that uses triple\ndistances in stead of pairs as in the classical Delsarte bound.\n  The main topics discussed are:\n  1) Block-diagonalisation of matrix *-algebras,\n  2) Terwilliger-algebra of the nonbinary Hamming scheme (including an explicit\nblock-diagonalisation),\n  3) SDP-bounds for (nonbinary) error-correcting codes and covering codes\n(including computational results),\n  4) Discussion on the relation with matrix-cuts,\n  5) Computational results for Affine caps.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1007.0123%2C1007.3558%2C1007.0406%2C1007.4969%2C1007.3853%2C1007.1919%2C1007.4674%2C1007.0921%2C1007.3603%2C1007.5504%2C1007.5268%2C1007.0082%2C1007.1749%2C1007.4021%2C1007.1327%2C1007.1047%2C1007.5261%2C1007.5185%2C1007.0906%2C1007.0682%2C1007.0499%2C1007.0222%2C1007.2205%2C1007.5054%2C1007.0274%2C1007.1930%2C1007.2027%2C1007.4839%2C1007.0882%2C1007.2624%2C1007.4917%2C1007.4895%2C1007.2447%2C1007.1276%2C1007.4280%2C1007.1241%2C1007.1367%2C1007.1617%2C1007.1588%2C1007.4962%2C1007.1211%2C1007.0536%2C1007.3172%2C1007.0350%2C1007.5256%2C1007.4392%2C1007.2464%2C1007.1612%2C1007.1788%2C1007.2180%2C1007.0062%2C1007.3002%2C1007.1257%2C1007.2421%2C1007.0055%2C1007.3370%2C1007.0078%2C1007.1846%2C1007.0369%2C1007.5127%2C1007.2492%2C1007.3571%2C1007.3476%2C1007.1870%2C1007.3004%2C1007.3832%2C1007.1333%2C1007.1723%2C1007.4146%2C1007.1874%2C1007.1188%2C1007.2741%2C1007.1114%2C1007.4221%2C1007.2130%2C1007.4473%2C1007.4102%2C1007.3869%2C1007.4893%2C1007.4705%2C1007.3159%2C1007.3062%2C1007.3509%2C1007.1100%2C1007.3757%2C1007.4749%2C1007.0071%2C1007.1420%2C1007.2202%2C1007.1514%2C1007.4193%2C1007.0839%2C1007.2088%2C1007.0259%2C1007.4170%2C1007.3592%2C1007.3244%2C1007.1373%2C1007.1170%2C1007.3860%2C1007.5362&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This PhD thesis is concerned with SDP bounds for codes: upper bounds for\n(non)-binary error correcting codes and lower bounds for (non)-binary covering\ncodes. The methods are based on the method of Schrijver that uses triple\ndistances in stead of pairs as in the classical Delsarte bound.\n  The main topics discussed are:\n  1) Block-diagonalisation of matrix *-algebras,\n  2) Terwilliger-algebra of the nonbinary Hamming scheme (including an explicit\nblock-diagonalisation),\n  3) SDP-bounds for (nonbinary) error-correcting codes and covering codes\n(including computational results),\n  4) Discussion on the relation with matrix-cuts,\n  5) Computational results for Affine caps."}, "authors": ["Dion Gijswijt"], "author_detail": {"name": "Dion Gijswijt"}, "author": "Dion Gijswijt", "arxiv_comment": "PhD Thesis (2005), about 100 pages", "links": [{"href": "http://arxiv.org/abs/1007.0906v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1007.0906v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.CO", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.CO", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1007.0906v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1007.0906v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:1007.0906v1 [math.CO] 6 Jul 2010\n\nMatrix Algebras and Semidefinite Programming Techniques for\nCodes\n\nDion Gijswijt\n\n\f\fMatrix Algebras and Semidefinite Programming\nTechniques for Codes\n\nAcademisch Proefschrift\n\nter verkrijging van de graad van doctor\naan de Universiteit van Amsterdam\nop gezag van de Rector Magnificus prof. mr. P.F. van der Heijden\nten overstaan van een door het college voor promoties ingestelde\ncommissie, in het openbaar te verdedigen in de Aula der Universiteit\nop donderdag 22 september 2005, te 12.00 uur\n\ndoor\n\nDion Camilo Gijswijt\ngeboren te Bunschoten.\n\n\fPromotiecommissie\nPromotor:\n\nProf. dr. A. Schrijver\n\nOverige leden:\n\nProf.\nProf.\nProf.\nProf.\n\ndr. A.E. Brouwer\ndr. G. van der Geer\ndr. T.H. Koornwinder\ndr.ir. H.C.A. van Tilborg\n\nFaculteit der Natuurwetenschappen, Wiskunde en Informatica\n\nThis research was supported by the Netherlands Organisation for Scientific Research\n(NWO) under project number 613.000.101.\n\n\fvoor Violeta\n\n\f\fContents\n1 Introduction\n1.1 Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2 The Delsarte bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3 Overview of the thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2 Preliminaries\n2.1 Notation . . . . . . . . . .\n2.2 Matrix \u2217-algebras . . . . .\n2.3 Semidefinite programming\n2.4 Association schemes . . .\n3 The\n3.1\n3.2\n3.3\n3.4\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\nTerwilliger algebra of H(n, q)\nThe Hamming scheme . . . . . . . . . . . . .\nBlock diagonalisation of An . . . . . . . . . .\nBlock-diagonalisation of Aq,n . . . . . . . . . .\nThe Terwilliger algebra of the Johnson scheme\n\n4 Error correcting codes\n4.1 Delsarte's linear programming bound\n4.2 Semidefinite programming bound . .\n4.2.1 Variations . . . . . . . . . . .\n4.2.2 A strengthening . . . . . . . .\n4.3 Computational results . . . . . . . .\n5 Covering codes\n5.1 Definitions and notation . . . . .\n5.2 Method of linear inequalities . . .\n5.3 Semidefinite programming bounds\n5.3.1 The first SDP bound . . .\n5.3.2 The second SDP bound .\n5.4 Nonbinary case . . . . . . . . . .\n5.5 Computational results . . . . . .\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n1\n1\n2\n3\n\n.\n.\n.\n.\n\n5\n5\n6\n13\n17\n\n.\n.\n.\n.\n\n21\n21\n25\n30\n37\n\n.\n.\n.\n.\n.\n\n39\n39\n41\n44\n45\n45\n\n.\n.\n.\n.\n.\n.\n.\n\n49\n49\n50\n52\n53\n55\n59\n64\n\n6 Matrix cuts\n67\n6.1 The theta body TH(G) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n6.2 Matrix cuts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\ni\n\n\fii\n\nCONTENTS\n6.3\n6.4\n\nBounds for codes using matrix cuts . . . . . . . . . . . . . . . . . . . . . . 72\nComputational results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n\n7 Further discussion\n77\n7.1 Bounds for affine caps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n7.2 Notes on computational results . . . . . . . . . . . . . . . . . . . . . . . . 78\nBibliography\n\n81\n\nIndex\n\n85\n\nSamenvatting\n\n85\n\nDankwoord\n\n89\n\nCurriculum Vitae\n\n91\n\n\fChapter 1\nIntroduction\nIn this thesis, we consider codes of length n over an alphabet of q symbols. We give new\nupper bounds on the maximum size Aq (n, d) of codes with minimum distance d, and new\nlower bounds on the minimum size Kq (n, r) of codes of covering radius r. The bounds\nare based on semidefinite programming and on an explicit block diagonalisation of the\n(non-commutative) Terwilliger algebra of the Hamming scheme. Our methods can be seen\nas a refinement of Delsarte's linear programming approach and are related to the theory\nof matrix cuts. They build upon the recent work of Schrijver [38] for binary codes.\n\n1.1\n\nCodes\n\nA code is a collection of words of some fixed length, for example the collection of all\nsix letter words in a dictionary. However, the words need not have any meaning. They\nare merely concatenations of symbols chosen from a fixed set called the alphabet. Other\nexamples of codes are: all possible strings of eight binary digits, a set of bets in a football\npool, or a collection of DNA sequences. Here the alphabets are {0, 1}, {Win, Lose, Tie}\nand {A, C, T, G} respectively.\nIt is often important to know how similar two words are. This can be measured by\ntheir Hamming distance. By definition, this is the number of positions in which the two\nwords differ. Suppose for example that we want to transmit information over a noisy\ncommunication channel. The letters in a transmitted word each have some small chance\nof being changed into a different letter. At the receiving end, we would like to be able to\nrecover the original message (if not too many letters are erroneous). This can be achieved\nby using a code in which any two words have distance at least d = 2e + 1 for some integer\ne. If we only transmit words belonging to this code, it is always possible to recover the\nsent code word if at most e errors are introduced during transmission. The received\nword is interpreted as the code word that is the closest match. If we aim for a highest\npossible information rate, we should maximize the number of words in the code, under\nthe condition that any two code words have distance at least d. Geometrically, this means\nthat we want to pack a maximum number of spheres ('balls' would be more accurate) of\nradius r inside the Hamming space consisting of all q n words of length n. Here the chosen\ncode words correspond to the centers of the spheres. This leads to the following central\nquestion in coding theory.\n1\n\n\f2\n\nCHAPTER 1. INTRODUCTION\nWhat is the maximum cardinality of a code of word length n, in which\nany two words have distance at least d?\n\nWhen the alphabet consists of q symbols, this maximum is denoted by Aq (n, d). The\nnumber Aq (n, d) can also be seen as the stability number of a graph. Let G be the graph\nwith the set of all q n words as vertices, and two words are joined by an edge if their\ndistance is less than d. Then the maximum size of a set of vertices, no two of which are\njoined by an edge, equals Aq (n, d).\nThe problem of determining Aq (n, d) is hard in general and we will have to be satisfied\nwith lower and upper bounds. One major field of research is to find explicit examples\nof (families of) good codes. In this thesis we will address the converse problem and\ngive upper bounds on the numbers Aq (n, d). In the case d = 2e + 1 the geometric idea\nof packing spheres already gives an upper bound. Since the spheres are disjoint, their\n'volumes' should add up to a number that is at most q n . This gives an upper bound on\nAq (n, d) called the sphere packing bound.\n\n1.2\n\nThe Delsarte bound\n\nCurrently, many of the best bounds known, are based on Delsarte's linear programming\napproach [15]. When viewed from the right perspective, the work in this thesis can be\nseen as a refinement of this method. Let us give a very rough sketch of Delsarte's method.\nAs is often the case in mathematics, we first seem to make the problem harder. Instead\nof optimizing the cardinality of a code directly, we associate to each code C a symmetric\nmatrix of which the rows and columns correspond to all q n possible code words. The\nmatrix is constructed by putting a 1 in those positions where both the row and the\ncolumn of the matrix belong to C, and a 0 in all other positions. The size of the code\ncan be recovered from the matrix by dividing the total number of ones by the number of\nones on the diagonal. Although we have no good grasp of the set of matrices that arise\nthis way, they share some important and elegant abstract properties:\n\u2022 the matrix has zeros in positions indexed by a row and column that are at distance\n1, 2, . . . , d \u2212 1,\n\u2022 the matrix is positive semidefinite: it has no negative eigenvalues.\nWe enlarge our set of matrices from those associated to codes, to include all symmetric\nmatrices sharing the two given properties. The resulting relaxation is much 'smoother'\nand has a very clear description which allows more efficient optimization. Of course\nthe magical part is, that optimizing over this larger set gives a good approximation of\nthe original problem! This bound was given in the more general setting of bounding\nthe stability number of a graph by Lov\u00e1sz [31]. It can be calculated using semidefinite\nprogramming in time bounded by a polynomial in the number of vertices of the graph.\nIn the coding setting, this will not suffice since the size of the matrices is prohibitively\nlarge. Even for codes of length n = 20, we have to deal with matrices of more then a\nmillion rows and columns. However, the problem admits a very large symmetry group.\nIt turns out that we can use these symmetries to our advantage to -dramatically-\n\n\f1.3. OVERVIEW OF THE THESIS\n\n3\n\nreduce the complexity of the problem. We may restrict ourselves to only those matrices,\nthat are invariant under the full group of symmetries. These matrices live in a lowdimensional commutative subalgebra called the Bose-Mesner algebra of the Hamming\nscheme. Diagonalising this algebra reduces the huge optimization problem to a simple\nlinear program of only n variables! The resulting linear programming bound (adding the\nconstraint that the matrix is nonnegative) is due to Delsarte.\n\n1.3\n\nOverview of the thesis\n\nIn this thesis, we give tighter bounds for codes by essentially isolating more properties\nsatisfied by the zero-one matrices associated to a code. More accurately, we associate to\neach code C two matrices. Both matrices are obtained by summing zero-one matrices\ncorresponding to certain permutations of the code C. This allows to include constraints\nthat come from triples of code words, instead of pairs. This method was initiated recently\nby Schrijver [38] to obtain bounds for binary error correcting codes, resulting in a large\nnumber of improved upper bounds.\nThe main result in this thesis is to generalize the methods to include non-binary\ncodes. The primary issue that we need to deal with, is how to exploit the remaining\nsymmetries to obtain a semidefinite program of a size that is polynomially bounded by\nthe word length n. This is the most technical part of the thesis and requires an explicit\nblock diagonalisation of the Terwilliger algebra of the nonbinary Hamming scheme. Such\na block diagonalisation is described in Chapter 3. It uses the block diagonalisation of\nthe Terwilliger algebra of the binary Hamming scheme found by Schrijver, which we will\ndescribe as well.\nIn Chapter 4 we apply our methods to obtain a semidefinite programming bound for\nnonbinary codes. Computationally, we have found a large number of improved upper\nbounds for q = 3, 4, 5, which we have tabulated in the final section.\nIn Chapter 5 we discuss covering codes. The problem here is to cover the Hamming\nspace with as few spheres as possible. When the spheres have radius r, this minimum\nnumber of required spheres is denoted by Kq (n, r). We give new linear and semidefinite\nprogramming bounds on Kq (n, r). For q = 4, 5 we obtain several improved lower bounds\non Kq (n, r).\nIn Chapter 6 we relate our coding bounds to the general theory of matrix cuts for\nobtaining improved relaxations of 0\u20131 polytopes. It is shown that the bound for error\ncorrecting codes is stronger than the bound obtained from a single iteration of the N+\noperator applied to the modified theta body of the graph on all words in which two words\nare joined by an edge if they are at distance smaller then d.\n\n\f4\n\nCHAPTER 1. INTRODUCTION\n\n\fChapter 2\nPreliminaries\nThis thesis is largely self-contained and most results are derived from explicit constructions. However, some theory is desirable for putting them into the right perspective and\nrelating them to the body of mathematics to which they connect. In this chapter we\ngive some definitions and basic facts. After giving some general notation in the first\nsection, we introduce matrix \u2217-algebras in the second section, which are an important\ntool throughout the thesis. The main (classical) theorem says (roughly) that any matrix\n\u2217-algebra is isomorphic to a direct sum of full matrix \u2217-algebras. In the third section we\ndescribe semidefinite programming. The bounds we derive for codes, are defined as the\noptimum of certain semidefinite programs and can be computed efficiently. Finally, we\nrecall the basics of association schemes. In particular we describe the Delsarte bound on\nthe maximum size of cliques in association schemes.\n\n2.1\n\nNotation\n\nFor positive integers n, m and a set R (usually R = C, R), we denote by Rn\u00d7m the set of n\nby m matrices with entries in R and by Rn the set of (column) vectors of length n. When\nR is a ring, we define matrix addition and multiplication of matrices (with compatible\ndimensions) as usual. Frequently, the rows and columns correspond to the elements of\nsome given finite sets X and Y . When we want to explicitly index the rows and columns of\nthe matrix using these sets, we will write RX\u00d7Y for the set of matrices with rows indexed\nby X and columns indexed by Y . The i-th row of a matrix A is denoted by Ai and the\nentry in row i and column j by Ai,j . The transpose of an X \u00d7 Y matrix is the Y \u00d7 X\nmatrix AT , where ATi,j = Aj,i for i \u2208 Y , j \u2208 X. When |Y | = 1, we often identify the\nmatrices in RX\u00d7Y and the vectors in RX .\nFor finite sets X, Y , the all-one vector in RX is denoted by 1. The X \u00d7 Y all-one\nmatrix is denoted by J, the all-zero matrix by 0 and the X \u00d7 X identity matrix by I.\nThe sets X and Y will be clear from the context.\nGiven a matrix A \u2208 RX\u00d7X , we define diag(A) to be the vector a \u2208 RX of diagonal\nelements of A, that is ai := Ai,i for i \u2208 X. The trace of A is the sum of the diagonal\nelements of A and is denoted trA. So trA = 1T diag(A). We mention the useful fact that\n5\n\n\f6\n\nCHAPTER 2. PRELIMINARIES\n\nfor matrices A \u2208 Rk\u00d7l and B \u2208 Rl\u00d7k the following identity holds:\ntr(AB) = tr(BA).\n\n(2.1)\n\nGiven a vector a \u2208 RX , we denote by Diag(a) the diagonal matrix A \u2208 RX\u00d7X with\ndiag(A) = a.\nFor a subset S \u2286 X we denote by \u03c7S the vector in RX definied by\n(\n1 if i \u2208 S\nS\n(\u03c7 )i :=\n(2.2)\n0 otherwise.\nFor a vector x and a set S, we define\nx(S) :=\n\nX\n\nxi .\n\n(2.3)\n\ni\u2208S\n\nFor a matrix A \u2208 CX\u00d7Y , the conjugate transpose of A is denoted by A\u2217 . That is\nA\u2217i,j = Aj,i for i \u2208 X and j \u2208 Y , where z is the complex conjugate of a complex number\nz. A square matrix A is called normal if A\u2217 A = AA\u2217 , hermitian if A\u2217 = A and unitary if\nA\u2217 A = AA\u2217 = I.\nFor A, B \u2208 CX\u00d7Y , we define\nX\n(2.4)\nhA, Bi := tr(AB \u2217 ) =\nAi,j Bi,j .\ni\u2208X,j\u2208Y\n\nThis is the standard complex inner product on CX\u00d7Y . Observe that\nhA, Ji = 1T A1.\n\n(2.5)\n\nFor matrices A \u2208 CX1 \u00d7Y1 and B \u2208 CX2 \u00d7Y2 , we denote by A \u2297 B the tensor product of\nA and B defined as the (X1 \u00d7 X2 ) \u00d7 (Y1 \u00d7 Y2 ) matrix given by\n(A \u2297 B)(i,i0 ),(j,j 0 ) := Ai,j Bi0 ,j 0 .\n\n2.2\n\n(2.6)\n\nMatrix \u2217-algebras\n\nIn this section we consider algebras of matrices. For general background on linear algebra\nwe refer the reader to [22, 27].\nA matrix \u2217-algebra is a nonempty set of matrices A \u2286 Cn\u00d7n that is closed under\naddition, scalar multiplication, matrix multiplication and under taking the conjugate\ntranspose. A matrix \u2217-algebra is a special case of a finite dimensional C \u2217 -algebra. Trivial\nexamples are the full matrix algebra Cn\u00d7n and the zero algebra {0}.\nMost of the matrix \u2217-algebras that we will encounter in this thesis are of a special type.\nThey are the set of matrices that commute with a given set of permutation matrices. More\nprecisely, we have the following.\n\n\f2.2. MATRIX \u2217-ALGEBRAS\n\n7\n\nLet G \u2286 Sn be a subgroup of the symmetric group on n elements. To every element\n\u03c3 \u2208 G we associate the permutation matrix M\u03c3 \u2208 Cn\u00d7n given by\n(\n1 if \u03c3(j) = i,\n(M\u03c3 )i,j :=\n(2.7)\n0 otherwise.\nObserve that\nM\u03c3\u2217 = M\u03c3T = M\u03c3\u22121 .\n\n(2.8)\n\nThe map \u03c3 7\u2192 M\u03c3 defines a representation of G. This means that for all \u03c3, \u03c4 \u2208 G we have\nM\u03c4 \u03c3 = M\u03c4 M\u03c3\n\nand M\u03c3\u22121 = M\u03c3\u22121 .\n\n(2.9)\n\nHere \u03c4 \u03c3 denotes the permutation (\u03c4 \u03c3)(i) := \u03c4 (\u03c3(i)). We define the centralizer algebra\n(see [2]) of G to be the set A of matrices that are invariant under permuting the rows and\ncolumns by elements of G. That is,\nA := {A \u2208 Cn\u00d7n | M\u03c3\u22121 AM\u03c3 = A for all \u03c3 \u2208 G}.\n\n(2.10)\n\nIf we denote by B the matrix \u2217-algebra spanned by the set of permutation matrices\n{M\u03c3 , \u03c3 \u2208 G}, then A is also called the commutant algebra of B: the algebra of matrices\nthat commute with all the elements of B. To see that the set A is indeed a matrix \u2217algebra, we first observe that it is closed under addition and scalar multiplication. That\nA is closed under matrix multiplication and taking the conjugate transpose follows from\nM\u03c3\u22121 ABM\u03c3 = M\u03c3\u22121 AM\u03c3 M\u03c3\u22121 BM\u03c3 = AB,\nM\u03c3\u22121 A\u2217 M\u03c3 = (M\u03c3\u22121 AM\u03c3 )\u2217 = A\u2217\n\n(2.11)\n\nfor any A, B \u2208 A.\nOne of the special features of A is that it contains the identity and is spanned by\na set of zero-one matrices whose supports partition {1, . . . , n} \u00d7 {1, . . . , n} (that is, it\nis the algebra belonging to a coherent configuration, see [12]). These matrices have a\ncombinatorial interpretation. Indeed, from (2.10) it follows that\nA \u2208 A if and only if Ai,j = A\u03c3(i),\u03c3(j) for all i, j \u2208 X.\n\n(2.12)\n\nHence A is spanned by zero-one matrices A1 , . . . , At , where the supports of the Ai are the\norbits of {1, . . . , n} \u00d7 {1, . . . , n} under the action of G, called the orbitals of G.\nThe following structure theorem is one of the main motivations for this thesis. It allows\nto give a matrix \u2217-algebra a simple appearance by performing a unitary transformation\n(a block diagonalisation). We will not use this theorem, but rather give explicit block\ndiagonalisations for the matrix \u2217-algebras under consideration.\nTheorem 1. Let A \u2286 Cn\u00d7n be a matrix \u2217-algebra containing the identity matrix I. Then\nthere exists a unitary n \u00d7 n matrix U and positive integers p1 , . . . , pm and q1 , . . . , qm such\nthat U \u2217 AU consists of all block diagonal matrices\n\uf8eb\n\uf8f6\nC1 0 * * * 0\n\uf8ec 0 C2 * * * 0 \uf8f7\n\uf8ec\n\uf8f7\n(2.13)\n\uf8ec ..\n\uf8f7\n.. . .\n\uf8ed.\n. 0 \uf8f8\n.\n0 0 * * * Cm\n\n\f8\n\nCHAPTER 2. PRELIMINARIES\n\nwhere each Ck is a block diagonal matrix\n\uf8eb\nBk 0\n\uf8ec 0 Bk\n\uf8ec\n\uf8ec ..\n..\n\uf8ed .\n.\n0\n0\n\n***\n***\n..\n.\n***\n\n\uf8f6\n0\n0\uf8f7\n\uf8f7\n\uf8f7\n0\uf8f8\nBk\n\n(2.14)\n\nwith qk identical blocks Bk \u2208 Cpk \u00d7pk on the diagonal.\nObserve that the numbers p1 , . . . , pm and q1 , . . . , qm satisfy\nq1 p1 + q2 p2 + * * * + qm pm = n,\np21 + p22 + * * * + p2m = dim A.\n\n(2.15)\n\nWe call the algebra U \u2217 AU a block diagonalisation of A. This theorem was proved in [3]\nby using (a special case of) the Wedderburn-Artin theorem (see also [45], [35]). However,\nwe will present a self-contained proof here.\nA well-known instance is when A \u2286 Cn\u00d7n is commutative. This occurs for example\nwhen A is the Bose\u2013Mesner algebra of an association scheme. In the commutative case we\nmust have p1 = . . . = pm = 1, since for any p \u2265 2 the algebra Cp\u00d7p is non-commutative.\nThe theorem then says that the matrices in A can be simultaneously diagonalised:\nU \u2217 AU = {x1 I1 + x2 I2 + * * * + xm Im | x \u2208 Cm },\n\n(2.16)\n\nwhere for each k the matrix Ik \u2208 Cn is a zero-one diagonal matrix with qk ones, and\nI1 + * * * + Im = I. The rest of this section is devoted to proving Theorem 1.\nWe first introduce some more notation. For two square matrices A \u2208 Cn\u00d7n and\nB \u2208 Cm\u00d7m , we define their direct sum A \u2295 B \u2208 C(n+m)\u00d7(n+m) by\n\u0012\n\u0013\nA 0\nA \u2295 B :=\n.\n(2.17)\n0 B\nFor two matrix \u2217-algebras A and B, we define their direct sum by\nA \u2295 B := {A \u2295 B | A \u2208 A, B \u2208 B}.\n\n(2.18)\n\nThis is again a matrix \u2217-algebra. For a positive integer t, we define\nt\n\nA := {t\n\nA | A \u2208 A},\n\n(2.19)\n\nwhere t A denotes the iterated direct sum \u2295ti=1 A.\nWe call two square matrices A, B \u2208 Cn\u00d7n equivalent if there exists a unitary matrix U\nsuch that B = U \u2217 AU . We extend this to matrix \u2217-algebras and call two matrix \u2217-algebras\nA and B equivalent if B = U \u2217 AU for some unitary matrix U .\nTheorem 1 can thus be expressed by saying that every matrix \u2217-algebra A containing\nthe identity matrix is equivalent to a matrix \u2217-algebra of the form\nm\nM\ni=1\n\n(qi\n\nCpi \u00d7pi ).\n\n(2.20)\n\n\f2.2. MATRIX \u2217-ALGEBRAS\n\n9\n\nWe start by considering the commutative case. We first introduce some more notions.\nLet A \u2286 Cn\u00d7n and let V \u2286 Cn be a linear subspace. We say that V is A-invariant when\nAv \u2208 V for every A \u2208 A and every v \u2208 V . Observe that if A is closed under taking the\nconjugate transpose, also the orthoplement\nV \u22a5 := {v \u2208 Cn | hv, ui = 0 for all u \u2208 V }\n\n(2.21)\n\nis A-invariant. Indeed, for every u \u2208 V , v \u2208 V \u22a5 and A \u2208 A we have\nhAv, ui = hv, A\u2217 ui = 0,\n\n(2.22)\n\nsince A\u2217 u \u2208 V .\nA nonzero vector v \u2208 Cn is called a common eigenvector for A when Cv is A-invariant.\nWe recall the following basic fact from linear algebra.\nFact. Let V be a complex linear space of finite, nonzero dimension, and let A : V \u2212\u2192 V\nbe a linear map. Then there exist \u03bb \u2208 C and v \u2208 V \\ {0} such that Av = \u03bbv.\nIn particular, this implies that when A \u2208 Cn\u00d7n and V \u2286 Cn is {A}-invariant, there\nexists an eigenvector of A that belongs to V . We are now ready to prove the following\ntheorem.\nTheorem 2. Let A \u2286 Cn\u00d7n be a commutative matrix \u2217-algebra and let V \u2286 Cn be an\nA-invariant subspace. Then V has an orthonormal basis of common eigenvectors for A.\nProof. The proof is by induction on dim V . If all vectors in V are common eigenvectors\nfor A, then we are done since we can take any orthonormal basis of V . Therefore we may\nassume that there exists an A \u2208 A such that not every v \u2208 V is an eigenvector for A.\nSince V is {A}-invariant, A has some eigenvector v \u2208 V of eigenvalue \u03bb \u2208 C. Denote by\nE\u03bb := {x \u2208 Cn | Ax = \u03bbx}\n\n(2.23)\n\nthe eigenspace of A for eigenvalue \u03bb. As A is commutative, the space E\u03bb is A-invariant.\nThis follows since for any B \u2208 A and any v \u2208 E\u03bb we have\nA(Bv) = B(Av) = \u03bbBv,\n\n(2.24)\n\nand hence Bv \u2208 E\u03bb . It follows that also V 0 := V \u2229 E\u03bb and V 00 := V \u2229 E\u03bb\u22a5 are A-invariant.\nBy assumption on A, V 00 has positive dimension, yielding a nontrivial orthogonal decomposition V = V 0 \u2295 V 00 . By induction both V 0 and V 00 have an orthonormal basis of\ncommon eigenvectors of A. The union of these two bases gives an orthonormal basis of\nV consisting of common eigenvectors of A.\nLet us consider the special case V := Cn . Let {U1 , . . . , Un } be an orthonormal basis\nof common eigenvectors for A and denote by U the square matrix with these vectors as\ncolumns (in some order). Then U is a unitary matrix that diagonalises A. That is, all\nmatrices in U \u2217 AU are diagonal matrices.\n\n\f10\n\nCHAPTER 2. PRELIMINARIES\n\nProposition 1. Let A \u2286 Cn\u00d7n be an algebra consisting of diagonal matrices. Then there\nexist zero-one diagonal matrices I1 , . . . Im with disjoint support such that\nA = CI1 + * * * + CIm .\n\n(2.25)\n\nProof. Let S := {i \u2208 {1, . . . , n} | Ai,i 6= 0 for some A \u2208 A} be the union of the supports\non the diagonal, of the matrices in A. Define an equivalence relation on S by calling i\nand j equivalent when Ai,i = Aj,j for every A \u2208 A, and let S1 , . . . , Sm be the equivalence\nclasses. Denote for k = 1, . . . , m by Ik := Diag(\u03c7Sk ) the zero-one diagonal matrix with\nsupport Sk . The inclusion\nA \u2286 CI1 + * * * + CIm\n(2.26)\nis clear.\nTo finish the proof, we show that I1 , . . . , Im \u2208 A. It is not hard to see that there is a\nmatrix A \u2208 A with\nA = c1 I1 + c2 I2 + * * * + cm Im ,\n(2.27)\nfor pairwise different nonzero numbers c1 , . . . , cm . It then follows that for k = 1, . . . , m\nwe have\nQ\nA i6=k (A \u2212 ci I)\nQ\nIk =\n.\n(2.28)\nck i6=k (ck \u2212 ci )\nSince the right-hand side is a polynomial in A with constant term equal to zero, we obtain\nIk \u2208 A.\nWhen A is a commutative matrix \u2217-algebra containing the identity, and U is a unitary\nmatrix diagonalising the algebra, say U \u2217 AU = CI1 + * * * + CIm , then the matrices\nEk := U Ik U \u2217 \u2208 A\n\n(2.29)\n\nform a basis of orthogonal idempotents of A. They satisfy\nE1 + * * * + Em = I,\nEi Ej = \u03b4i,j ,\nEi = Ei\u2217 ,\n\n(2.30)\n\nfor i, j \u2208 {1, . . . , m}. Geometrically, we have an orthogonal decomposition\nCn = V1 \u2295 * * * \u2295 Vm\n\n(2.31)\n\nand Ek is the orthogonal projection of Cn onto Vk .\nWe will now consider the case that the matrix \u2217-algebra A is not necessarily commutative. We first introduce some terminology. Let A \u2286 Cn\u00d7n be a matrix \u2217-algebra. An\nelement E \u2208 A is called a unit of A when EA = AE = A for every A \u2208 A. Every matrix\n\u2217-algebra has a unit, see Proposition 3 below. A sub \u2217-algebra of A is a subset of A that\nis a matrix \u2217-algebra. An important example is\nCA := {A \u2208 A | AB = BA for all B \u2208 A}.\n\n(2.32)\n\n\f2.2. MATRIX \u2217-ALGEBRAS\n\n11\n\nAn ideal of A is a sub \u2217-algebra that is closed under both left and right multiplication\nby elements of A. We observe that if I is an ideal of A and E is the unit of I, then\nE \u2208 CA . This follows since for any A \u2208 A both EA and AE belong to I and hence\nEA = EAE = AE.\nWe say that a commutative sub \u2217-algebra of A is maximal if it is not strictly contained\nin a commutative sub \u2217-algebra of A. We have the following useful property.\nProposition 2. Let B be a maximal commutative sub \u2217-algebra of the matrix \u2217-algebra\nA and let\nB 0 := {A \u2208 A | AB = BA for all B \u2208 B}.\n(2.33)\nThen B 0 = B.\nProof. Clearly B \u2286 B 0 . We show the converse inclusion. First observe that for any A \u2208 B 0\nalso A\u2217 \u2208 B 0 . This follows since for any B \u2208 B we have\nA\u2217 B = (B \u2217 A)\u2217 = (AB \u2217 )\u2217 = BA\u2217 .\n\n(2.34)\n\nNext, we show that B contains every A \u2208 B 0 that is normal (that is AA\u2217 = AA\u2217 ). This\nfollows since for any normal A \u2208 B 0 \\ B the commutative matrix \u2217-algebra generated by\nA, A\u2217 and B, strictly contains B.\nFinally, let A \u2208 B 0 be arbitrary. The matrix A + A\u2217 is normal, and hence belongs to\nB. It follows that A(A + A\u2217 ) = (A + A\u2217 )A, or AA\u2217 = A\u2217 A, and hence A itself is normal\nand therefore belongs to B.\nWhen a matrix \u2217-algebra does not contain the identity, the following proposition is\nuseful.\nProposition 3. Every nonzero matrix \u2217-algebra A is equivalent to a direct sum of a\nmatrix \u2217-algebra containing the identity and (possibly) a zero algebra. In particular, A\nhas a unit.\nProof. Let B be a maximal commutative sub \u2217-algebra of A. By diagonalising B we may\nassume that\nB = CI1 + * * * + CIm\n(2.35)\nfor diagonal zero-one matrices I0 , I1 , . . . , Im with I = I0 + I1 + * * * + Im . If I0 = 0, we are\ndone. So we may assume that I0 =\n6 0. To prove the proposition, it suffices to show that\nI0 A = AI0 = {0},\n\n(2.36)\n\nsince this implies that A is the direct sum of the algebra obtained by restricting A to the\nsupport of I1 + * * * + Im and the zero algebra on the support of I0 .\nFirst observe that\nI0 A = A \u2212 (I1 + * * * + Im )A \u2208 A for every A \u2208 A.\n\n(2.37)\n\nLet A \u2208 A be arbitrary and let\nA0 := (I0 A)(I0 A)\u2217 \u2208 A.\n\n(2.38)\n\n\f12\n\nCHAPTER 2. PRELIMINARIES\n\nThen for k = 1, . . . , m we have\nIk A0 = Ik I0 AA\u2217 I0 = 0 = I0 AA\u2217 I0 Ik = A0 Ik .\n\n(2.39)\n\nIt follows that A0 commutes with I1 , . . . , Im and hence is a linear combination of I1 , . . . , Im\nby the maximality of B. On the other hand A0 Ik = 0 for k = 1, . . . , m, and hence A0 = 0.\nIt follows that also I0 A = 0.\nSimilarly, by considering A\u2217 we obtain I0 A\u2217 = 0 and hence AI0 = 0.\nWe call a nonzero matrix \u2217-algebra A simple if CA = CE, where E is the unit of A.\nSince the unit of any ideal of A belongs to CA , it follows that if A is simple, it has only\nthe two trivial ideals {0} and A. The reverse implication also holds (see Proposition 4).\nProposition 4. Every matrix \u2217-algebra A containing the identity is equivalent to a direct\nsum of simple matrix \u2217-algebras.\nProof. Since CA is commutative, we may assume it is diagonalised by replacing A by\nU \u2217 AU for a unitary matrix U diagonalising CA . Then\nCA = CI1 + * * * + CIm\n\n(2.40)\n\nwhere I1 , . . . , Im are zero-one diagonal matrices with I1 + * * * + Im = I. For every i, j \u2208\n{1, . . . , m} with i 6= j we have\nIi AIj = Ii Ij A = {0}.\n\n(2.41)\n\nIt follows that A is the direct sum\nA = A1 \u2295 * * * \u2295 Am ,\n\n(2.42)\n\nwhere for i = 1, . . . , m the matrix \u2217-algebra Ai is obtained from Ii AIi by restricting to\nthe rows and columns in which Ii has a 1.\nFinally, we show that every simple matrix \u2217-algebra can be brought into block diagonal\nform.\nProposition 5. Every simple matrix \u2217-algebra A containing the identity is equivalent to\na matrix \u2217-algebra of the form t Cm\u00d7m for some t, m.\nProof. Let A \u2286 Cn\u00d7n be a simple matrix \u2217-algebra containing the identity, and let B be\na maximal commutative sub \u2217-algebra of A. We may assume that B consists of diagonal\nmatrices, say\nB = CI1 + * * * + CIm\n(2.43)\nwhere Ii = \u03c7Si for i = 1, . . . , m and S1 \u222a * * * \u222a Sm is a partition of {1, . . . , n}. For every i\nand every A \u2208 A the matrix Ii AIi commutes with I1 , . . . , Im and hence, by the maximality\nof B, the matrix Ii AIi is a linear combination of I1 , . . . , Im . It follows that\nIi AIi = CIi for i = 1, . . . , m.\n\n(2.44)\n\n\f2.3. SEMIDEFINITE PROGRAMMING\n\n13\n\nFor any i, the set I := AIi A is a nonzero ideal of A. Hence the unit of I belongs to\nCA = CI. It follows that I \u2208 I and hence\nIi AIj 6= {0} for every i, j = 1, . . . , m.\n\n(2.45)\n\nFor any A \u2208 Cn\u00d7n , and i, j \u2208 {1, . . . , m}, we denote by Ai,j \u2208 C|Si |\u00d7|Sj | the matrix\nobtained from A by restricting the rows to Si and the columns to Sj (and renumbering\nthe rows and columns). By (2.45) we can fix an A \u2208 A with Ai,j 6= 0 for every i, j \u2208\n{1, . . . , m}. In fact we can arrange that\ntr((Ai,j )\u2217 Ai,j ) = |Si |.\n\n(2.46)\n\nLet i be arbitrary and let A0 := I1 AIi . Then\nA0 (A0 )\u2217 is a nonzero matrix in CI1 ,\n(A0 )\u2217 A0 is a nonzero matrix in CIi .\n\n(2.47)\n\nThis shows that I1 and Ii have the same rank t, namely the rank of A0 . In other words:\n|S1 | = |Si | = t. Moreover by (2.46), the matrices A1,i are unitary since\n(A1,i )\u2217 A1,i = A1,i (A1,i )\u2217 = I.\n\n(2.48)\n\nLet U := A\u22171,1 \u2295 * * * \u2295 A\u22171,m \u2208 Cn\u00d7n be the unitary matrix with blocks A\u22171,i on the diagonal.\nBy replacing A by U \u2217 AU we may assume that A1,i = I for i = 1, . . . , m.\nThis implies that for any i, j \u2208 {1, . . . , m}\nBi,1 = A1,i Bi,1 = (I1 AIi BI1 )1,1 \u2208 CI for any B \u2208 A,\n\n(2.49)\n\nBi,j = Bi,j (A\u2217 )j,1 = (Ii BIj A\u2217 I1 )i,1 \u2208 CI for any B \u2208 A.\n\n(2.50)\n\nand hence\nSummarizing, we have\nA = {A \u2208 Cn\u00d7n | Ai,j \u2208 CI for all i, j \u2208 {1, . . . , m}}.\n\n(2.51)\n\nBy reordering the rows and columns, we obtain the proposition.\nProposition 4 and 5 together imply Theorem 1.\n\n2.3\n\nSemidefinite programming\n\nIn this section we introduce semidefinite programming. For an overview of semidefinite\nprogramming and further references, we refer the reader to [41].\nRecall that a complex matrix A is called hermitian if A\u2217 = A. It follows that all\neigenvalues of A are real. An hermitian matrix A \u2208 Cn\u00d7n is called positive semidefinite,\nin notation A \u0017 0, when it has only nonnegative eigenvalues.\n\n\f14\n\nCHAPTER 2. PRELIMINARIES\n\nProposition 6. For an hermitian matrix A \u2208 Cn\u00d7n the following are equivalent:\n(i)\n(ii)\n(iii)\n\nA \u0017 0,\nx\u2217 Ax \u2265 0 for all x \u2208 Cn ,\nA = B \u2217 B for some B \u2208 Cn\u00d7n .\n\n(2.52)\n\nIn the case that A is real, we may restrict to real vectors x in (ii) and take B real in (iii).\nIt follows that for positive semidefinite matrices A, B \u2208 Cn\u00d7n the inner product is\nnonnegative:\nhA, Bi = tr(C \u2217 CDD\u2217 ) = tr(CDD\u2217 C \u2217 ) = hCD, CDi \u2265 0,\n\n(2.53)\n\nwhen A = C \u2217 C and B = D\u2217 D. Another useful observation is that when A is positive\nsemidefinite, every principal submatrix is positive semidefinite as well. In particular, the\ndiagonal of A consists of nonnegative real numbers. Also\nif U is nonsingular, then A \u0017 0 if and only if U \u2217 AU \u0017 0.\n\n(2.54)\n\nIn the remainder of this section, all matrices will be real. A semidefinite program is a\nan optimization problem of the following form, where A1 , . . . , An , B are given symmetric\nmatrices in Rn\u00d7n and c \u2208 Rn is a given vector:\nminimize\nsubject to\n\ncT x\nx1 A1 + * * * + xn An \u2212 B \u0017 0.\n\n(2.55)\n\nWhen A1 , . . . , An , B are diagonal matrices, the program reduces to a linear program. In\nparticular, linear constraints Ax \u2264 b can be incorporated into the program (2.55) by\nsetting\n\u0012\n\u0013\nA\n0\ni\nei :=\nA\n(2.56)\n0 \u2212Diag(ai )\nand\ne :=\nB\n\n\u0012\n\u0013\nB\n0\n,\n0 \u2212Diag(b)\n\n(2.57)\n\nwhere ai is the i-th column of A. Semidefinite programs can be approximated in polynomial time within any specified accuracy by the ellipsoid algorithm ([17]) or by practically\nefficient interior point methods ([34]).\nFor any symmetric matrix A \u2208 Rn\u00d7n , the matrix R(A) is defined by:\n\u0012\n\u0013\n1 aT\nR(A) :=\n,\n(2.58)\na A\nwhere a := diag(A) is the vector of diagonal elements of A. We will index the extra row\nand column of R(A) by 0.\nThe following propositions are helpful when dealing with semidefinite programs that\ninvolve matrices of the form R(A).\n\n\f2.3. SEMIDEFINITE PROGRAMMING\n\n15\n\nProposition 7. Let A \u2208 Rn\u00d7n be a symmetric matrix such that diag(A) = c * A1 for some\nc \u2208 R. Then the following are equivalent:\n(i)\n(ii)\n\nR(A) is positive semidefinite,\nA is positive semidefinite and 1T A1 \u2265 (trA)2 .\n\n(2.59)\n\nProof. First assume that (i) holds. Let R(A) = U T U , where U \u2208 R(n+1)\u00d7(n+1) . Using\nU0T U0 = 1, we obtain\nT\n\n1 A1 =\n\nn\nX\ni,j=1\n\nUiT Uj\n\n= (\n\nn\nX\n\nn\nX\nUi ) (\nUi ) * U0T U0\n\ni=1\nn\nX\n\n\u2265 ((\n\nT\n\n(2.60)\n\ni=1\n\nUi )T U0 )2 = (trA)2 .\n\ni=1\n\nHere the inequality follows using Cauchy-Schwarz, and in the last equality we use UiT U0 =\nAi,i . Next assume that (ii) holds. We may assume that trA > 0, since otherwise A = 0 and\nhence R(A) is positive semidefinite. Let A = U T U where U \u2208 Rn\u00d7n . Let a := diag(A).\nFor any x \u2208 Rn the following holds:\nxT Ax \u2265 (1T A1)\u22121 (xT A1)2\n\u00132\n\u0012\ntrA T\nx A1\n\u2265\n1T A1\n1T a\n= c T c\u22121 xT a\n1 a\n= (xT a)2 .\n\n(2.61)\n\nHere the first inequality follows by applying Cauchy-Schwartz on the inner product of U x\nand U 1, and the second\ninequality follows from the assumption 1T A1 \u2265 (trA)2 . It follows\n\u0001\nthat for any vector \u03b1x with x \u2208 Rn and \u03b1 \u2208 R, we have\n\u0012 \u0013\n\u03b1\nT\n(\u03b1, x )R(A)\n= \u03b12 + 2\u03b1aT x + xT Ax\nx\n\u2265 \u03b12 + 2\u03b1aT x + (aT x)2\n= (\u03b1 + aT x)2 \u2265 0.\n\nThis implies the folowing useful equivalence of semidefinite programs.\nProposition 8. Let C \u2286 Rn\u00d7n be a cone, and assume that the following two maxima\nexist:\nO1 := max{1T A1 | trA = 1, A \u0017 0, A \u2208 C},\nO2 := max{trA | R(A) \u0017 0, A \u2208 C}.\n\n(2.62)\n\nFurther assume that the maximum in the first program is attained by a matrix A with\ndiag(A) = c * A1 for some c \u2208 R. Then O1 = O2 .\n\n\f16\n\nCHAPTER 2. PRELIMINARIES\n\nProof. Let A be an optimal solution to the first program with diag(A) = c * A1 for some\nc \u2208 R, and define A0 := (1T A1)A. Then\n1T A0 1 = (1T A1)2 = (trA0 )2 .\n\n(2.63)\n\nHence A0 is feasible for the second program by Proposition 7. Since trA0 = 1T A1 we\nobtain O2 \u2265 O1 .\nLet A be an optimal solution to the second program. If trA = 0 we have O1 \u2265 O2 and\nwe are done. Hence we may assume that trA > 0. Observe that (trA)2 = 1T A1, since\notherwise we would have 1T A1 = \u03bb(trA)2 for some \u03bb > 1 by Proposition 7. This would\n1\nA. Then\nimply that \u03bbA is also feasible, contradicting the optimality of A. Define A0 := trA\n0\nA is feasible for the first program and\n1T A 0 1 =\n\n1 T\n1 A1 = trA\ntrA\n\n(2.64)\n\nThis implies that O1 \u2265 O2 .\nAn important special case is when all feasible matrices have constant diagonal and\nconstant row sum. this occurs for example in semidefinite programs where the feasible\nmatrices belong to the Bose-Mesner algebra of an association scheme. Another case is\nwhen the cone C is closed under scaling rows and columns by nonnegative numbers.\nProposition 9. Let C \u2286 Rn\u00d7n be a cone of symmetric matrices, such that for any\nnonnegative x \u2208 Rn and any A \u2208 C also Diag(x)ADiag(x) belongs to C. Then any\noptimal solution A to the program\nmax{1T A1 | trA = 1, A \u0017 0, A \u2208 C}\n\n(2.65)\n\nsatisfies diag(A) = c * A1 for some c \u2208 R.\nProof. Let A be an optimal solution. If Ai,i =0 for some i, we have\np Ai = 0 and the claim\nfollows by induction on n. Therefore we may assume that ai := Ai,i > 0 for i = 1, . . . , n.\nThe matrix A0 := (Diag(a))\u22121 A(Diag(a))\u22121 is scaled to have only ones on the diagonal.\nNow for every nonnegative x \u2208 Rn with kxk = 1, the matrix A(x) := Diag(x)A0 Diag(x)\nis a feasible solution to (2.65) and has value xT A0 x. By the optimality of A, the vector\na maximizes xT A0 x over all nonnegative vectors x with kxk = 1. In fact, since a > 0, it\nmaximizes xT A0 x over all x with kxk = 1. As Rn has an orthonormal basis of eigenvectors\nfor A0 , it follows that a is an eigenvector of A0 belonging to the maximal eigenvalue \u03bb.\nThis implies that\nA1 = Diag(a)A0 Diag(a)1 = Diag(a)A0 a\n= \u03bbDiag(a)a\n= \u03bb(a21 , . . . , a2n )T .\n\n(2.66)\n\nThis finishes the proof since\ndiag(A) = (a21 , . . . , a2n )T .\n\n(2.67)\n\n\f2.4. ASSOCIATION SCHEMES\n\n2.4\n\n17\n\nAssociation schemes\n\nIn this section, we give some basic facts and notions related to association schemes,\nincluding Delsarte's linear programming approach for bounding the size of cliques in\nan association scheme. This is by no means a complete introduction to the theory of\nassociation schemes. For further reading, we recommend [8, 1, 15] on association schemes\nand [10] on the related topic of distance regular graphs.\nRoughly speaking, an association scheme is a very regular colouring of the edges of\na complete graph. The colouring is such, that the number of walks from a vertex a to\na vertex b traversing colours in a prescribed order, does not depend on the two vertices\na and b, but merely on the colour of the edge ab. The following formal definition is due\nto Bose and Shimamoto [8]. A t-class association scheme S = (X, {R0 , R1 , . . . , Rt }) is a\nfinite set X together with t + 1 relations R0 , . . . , Rt on X that satisfy the following axioms\n(i)\n(ii)\n(iii)\n(iv)\n\n{R0 , R1 , . . . , Rt } is a partition of X \u00d7 X,\nR0 = {(x, x) | x \u2208 X},\n(x, y) \u2208 Ri if and only if (y, x) \u2208 Ri for all x, y \u2208 X, i \u2208 {0, . . . , t},\nfor any i, j, k \u2208 {0, . . . , t} there is an integer pki,j such that\n|{z \u2208 X | (x, z) \u2208 Ri , (z, y) \u2208 Rj }| = pki,j whenever (x, y) \u2208 Rk .\n\nThe set X is called the set of points of the association scheme and two points x, y \u2208 X\nare said to be i-related when (x, y) \u2208 Ri . An association scheme defined as above, is\nsometimes called a symmetric association scheme since all relations are symmetric by\n(iii). Some authors prefer to allow for 'non-symmetric association schemes' by replacing\ncondition (iii) by\n(iii0 )\n(iii00 )\n\nfor each i \u2208 {0, . . . , t} there is an i\u2217 \u2208 {0, . . . , t} such that\n(x, y) \u2208 Ri implies (y, x) \u2208 Ri\u2217 for all x, y \u2208 X,\npki,j = pkj,i for all i, j, k \u2208 {0, . . . , t}.\n(2.68)\n\nIn this thesis we will only use symmetric association schemes.\nThe numbers pki,j are called the intersection numbers of the association scheme. The\nintersection numbers are not free of relations. We mention some obvious relations:\npki,j = pkj,i ,\np0i,j\n\n(2.69)\n\n= 0 when i 6= j.\n\nThe numbers ni := p0i,i are called the degrees of the scheme and give the number of points\nthat are i-related to a given point (each relation Ri induces an ni -regular graph on X).\nTo each relation Ri , we associate the X \u00d7 X matrix Ai in the obvious way:\n(\n1 if (x, y) \u2208 Ri\n(Ai )x,y :=\n(2.70)\n0 otherwise.\n\n\f18\n\nCHAPTER 2. PRELIMINARIES\n\nThe matrices A0 , . . . , At are called the adjacency matrices of the association scheme and\nallow to study the association scheme using algebraic (spectral) tools. In terms of the\nadjacency matrices, the axioms in (2.68) become\n(i)\n(ii)\n(iii)\n(iv)\n\nA0 + A1 + * * * + At = J,\nA0 = I,\nAi = ATi for all i \u2208 {0, . . . , t},\nt\nX\nAi Aj =\npki,j Ak for any i, j \u2208 {0, . . . , t}.\nk=0\n\nLet\nA := {x0 A0 + x1 A1 + * * * + xt At | x0 , . . . , xt \u2208 C }\n\n(2.71)\n\nbe the linear space spanned by the adjacency matrices. Axiom (iv) says that A is closed\nunder matrix multiplication. Since all matrices in A are symmetric, it follows that A is a\ncommutative matrix \u2217-algebra, which is called the Bose\u2013Mesner algebra of the association\nscheme. Since the adjacency matrices are nonzero and have disjoint support, they are\nlinearly independent. This implies that the dimension of A equals t + 1.\nSince the algebra A is commutative, it has a basis E0 , E1 , . . . , Et of matrices satisfying\n(i)\n(ii)\n(iii)\n\nEi Ej = \u03b4i,j Ei ,\nE0 + . . . + Et = I,\nEi\u2217 = Ei ,\n\n(2.72)\n\nfor every i, j \u2208 {0, . . . , t}. The matrices Ei are called the minimal idempotents of the\nalgebra and are uniquely determined by A. Geometrically, this means that there is an\northogonal decomposition\nCX = V0 \u2295 V1 \u2295 * * * \u2295 Vt ,\n(2.73)\nwhere Ei is the orthogonal projection onto Vi for i = 0, . . . , t. For each i the dimension\nmi := dim Vi\n\n(2.74)\n\nequals the rank of Ei . The numbers m0 , . . . , mt are called the multiplicities of the association scheme.\nIn general, there is no natural way to order the Ei . However, there is one exception.\nThe matrix |X|\u22121 J is always a minimal idempotent, hence it is customary to take E0 :=\n|X|\u22121 J (and V0 = C1, m0 = 1). Since all matrices in A are symmetric, the idempotents\nEi are real by (2.72)(iii).\nSince both {E0 , . . . , Ek } and {A0 , . . . , Ak } are bases for A, we can express every matrix\nin one base as a linear combination of matrices in the other base. The (t + 1) \u00d7 (t + 1)\nreal matrices P, Q are defined as follows:\nAj =\n|X| * Ej =\n\nt\nX\ni=0\nt\nX\ni=0\n\nPi,j Ei ,\nQi,j Ai ,\n\n(2.75)\n\n\f2.4. ASSOCIATION SCHEMES\n\n19\n\nfor j = 0, . . . , t. The matrices P and Q are called the first and second eigenmatrix of the\nscheme respectively. Indeed, since\nt\nX\nci Ei\n(2.76)\ni=0\n\nhas eigenvalue ci with multiplicity mi (if the ci are different), the i-th column of P gives\nthe eigenvalues of Ai . Clearly\nP Q = QP = |X| * I,\n(2.77)\nbut additionally, the matrices P and Q satisfy the following relation\nfor all i, j \u2208 {0, . . . , t}.\n\n(2.78)\n\nP T Diag(m0 , . . . , mt ) = Diag(n0 , . . . , nt )Q.\n\n(2.79)\n\nmj Pj,i = ni Qi,j ,\nIn matrix form:\n\nThis is a consequence of the fact that both bases {A0 , . . . , At } and {E0 , . . . , Et } are\northogonal. Indeed, this implies by (2.75) that both the left-hand side and the right-hand\nside in equation (2.78) are equal to hAi , Ej i.\nGiven a subset Y \u2286 X of the point set, the distribution vector of Y is the (t + 1)-tuple\n(a0 , a1 , . . . , at ) of nonnegative numbers defined by\nai := |Y |\u22121 * |(Y \u00d7 Y ) \u2229 Ri |,\n\ni = 0, . . . , t.\n\n(2.80)\n\nThe numbers ai give the average number of elements in Y that are i-related to a given\nelement in Y . In particular a0 = 1 and a0 + * * * + at = |Y |. Delsarte [15] showed that the\ndistribution vector satisfies the following system of inequalities:\nt\nX\n\nQi,j ai \u2265 0 for j = 0, . . . , t.\n\n(2.81)\n\ni=0\n\nLet K \u2286 {1, . . . , t}. A subset S \u2286 X of the point set is called a K-clique if any two\ndifferent elements x, y \u2208 K are i-related for some i \u2208 K. The inequalities (2.81) yield an\nupper bound on the maximum size of a K-clique called the Delsarte bound.\nTheorem 3. Let (X, {R0 , . . . , Rt }) be an association scheme and let K \u2286 {1, . . . , t}.\nThen the maximum size of a K-clique is upper bounded by\nmax {a1 + * * * + at |\n\na0 = 1, ai = 0 for i \u2208 {1, 2, . . . , t} \\ K\nai \u2265 0 for all i \u2208 {1, 2, . . . , t}\na0 , . . . , at satisfy the inequalities (2.81)}.\n\n(2.82)\n\nThe Delsarte bound can be efficiently calculated using linear programming and often\ngives a remarkably good upper bound.\nOne source of association schemes are (permutation) groups. Let G be a group acting\non a finite set X. Then G has a natural action on X \u00d7 X given by g(x, y) := (gx, gy).\nThe orbits\n{(gx, gy) | g \u2208 G}\n(2.83)\n\n\f20\n\nCHAPTER 2. PRELIMINARIES\n\nof X \u00d7 X are called orbitals. The group G is said to act generously transitive when for\nevery pair (x, y) \u2208 X \u00d7 X there is a group element g \u2208 G that exchanges x and y, that is\ngx = gy and gy = gx. When G acts generously transitive, the orbitals form the relations\nof an association scheme.\nIndeed, the orbitals partition X \u00d7 X, for any x \u2208 X the orbital {(gx, gx) | g \u2208 G} is\nthe identity relation (as G acts transitively on X) and the orbitals are symmetric (since\nG acts generously transitive). Finally, let Ri , Rj , Rk be orbitals and let for (x, y) \u2208 Rk\nZx,y := {z \u2208 X | (x, z) \u2208 Ri , (z, y) \u2208 Rj }.\n\n(2.84)\n\nWe have to show that the cardinality pki,j of Zx,y only depends on the relations i, j, k and\nnot on the particular choice of x and y. This follows since\nZgx,gy \u2287 {gz | z \u2208 Zx,y }\n\n(2.85)\n\nfor any g \u2208 G. In this case, the Bose\u2013Mesner algebra is the centralizer algebra of G.\nGiven an association scheme S = (X, R) with adjacency matrices A0 , A1 , . . . , At \u2208\nCX\u00d7X , and a point x \u2208 X, the Terwilliger algebra of S with respect to x is the complex\nalgebra generated by A0 , . . . , At and the diagonal matrices E00 , . . . , Et0 defined by\n(\n1 if (x, y) \u2208 Ri\n(2.86)\n(Ei0 )y,y :=\n0 otherwise.\nObserve that E00 + * * * + Et0 = I. These algebras were introduced by Terwilliger in [39]\nunder the name subconstituent algebra as a tool for studying association schemes. In this\nthesis we will use the Terwilliger algebra of the Hamming scheme to obtain bounds for\ncodes, improving the Delsarte bound.\n\n\fChapter 3\nThe Terwilliger algebra of the\nHamming scheme\nA particular association scheme that plays an important role in the theory of error correcting codes is the Hamming scheme. In this chapter we will consider this scheme together\nwith matrix algebras associated to it. In particular we construct a block diagonalisation\nof the Terwilliger algebra of the binary and the nonbinary Hamming scheme.\n\n3.1\n\nThe Hamming scheme and its Terwilliger algebra\n\nFix integers n \u2265 1 and q \u2265 2, and fix an alphabet q = {0, 1, . . . , q \u2212 1}. We will consider\nthe Hamming space E = qn consisting of words of length n equipped with the Hamming\ndistance given by\nd(u, v) := |{i | ui 6= vi }|.\n\n(3.1)\n\nFor a word u \u2208 E, we denote the support of u by S(u) := {i | ui 6= 0}. Note that\n|S(u)| = d(u, 0), where 0 is the all-zero word. This number is called the weight of u.\nDenote by Aut(q, n) the set of permutations of E that preserve the Hamming distance.\nIt is not hard to see that Aut(q, n) consists of the permutations of E obtained by permuting\nthe n coordinates followed by independently permuting the alphabet q at each of the n\ncoordinates. If we consider the action of Aut(q, n) on the set E \u00d7 E, the orbits form\nan association scheme known as the Hamming scheme H(n, q), with adjacency matrices\nA0 , A1 , . . . , An defined by\n(Ai )u,v\n\n(\n1 if d(u, v) = i,\n:=\n'\n0 otherwise,\n\n(3.2)\n\nfor i = 0, 1, . . . , n. The adjacency matrices span a commutative algebra over the complex\nnumbers called the Bose\u2013Mesner algebra of the scheme.\nWe will now consider the action of Aut(q, n) on ordered triples of words, leading to\na noncommutative algebra Aq,n containing the Bose\u2013Mesner algebra. To each ordered\n21\n\n\f22\n\nCHAPTER 3. THE TERWILLIGER ALGEBRA OF H(N, Q)\n\ntriple (u, v, w) \u2208 E \u00d7 E \u00d7 E we associate the four-tuple\nd(u, v, w) := (i, j, t, p), where\ni := d(u, v),\nj := d(u, w),\nt := |{i | ui 6= vi and ui 6= wi }|,\np := |{i | ui 6= vi = wi }|.\n\n(3.3)\n\nWe remark that the case q = 2 is special since in that case we always have p = t. Note\nthat d(v, w) = i + j \u2212 t \u2212 p and |{i | ui 6= vi 6= wi 6= ui }| = t \u2212 p. The set of four-tuples\n(i, j, t, p) that occur as d(u, v, w) for some u, v, w \u2208 E is given by\nI(2, n) := {(i, j, t, p) | 0 \u2264 p = t \u2264 i, j and i + j \u2264 n + t},\n\n(3.4)\n\nI(q, n) := {(i, j, t, p) | 0 \u2264 p \u2264 t \u2264 i, j and i + j \u2264 n + t},\n\n(3.5)\n\nand\nfor q \u2265 3. The sets I(q, n) will be used to index various objects defined below.\nProposition 10. Let n \u2265 1. We have\n\n|I(q, n)|\n\n\uf8f1\n\uf8f4\n\uf8f2\n\nn+3\n3\n\n\uf8f4\n\uf8f3\n\nn+4\n4\n\n\u0001\n\nfor q = 2,\n(3.6)\n\n\u0001\n\nfor q \u2265 3.\n\nProof. Substitute p0 := p, t0 := t \u2212 p, i0 := i \u2212 t and j 0 := j \u2212 t. Then the integer solutions\nof\n0 \u2264 p \u2264 t \u2264 i, j, i + j \u2264 n + t\n(3.7)\nare in bijection with the integer solutions of\n0 \u2264 p0 , t0 , i0 , j 0 ,\n\np0 + t0 + i0 + j 0 \u2264 n.\n\n(3.8)\n\nThe proposition now follows since\n|{(n1 , n2 , . . . , nk ) \u2208 Z\u22650\n\n\u0012\n\u0013\nn+k\n| n1 + * * * + nk = n}| =\n.\nk\n\n(3.9)\n\nThe integers i, j, t, p parametrize the ordered triples of words up to symmetry. We\ndefine\nXi,j,t,p := {(u, v, w) \u2208 E \u00d7 E \u00d7 E | d(u, v, w) = (i, j, t, p)},\n(3.10)\nfor (i, j, t, p) \u2208 I(q, n). The meaning of the sets Xi,j,t,p is given by the following proposition.\nProposition 11. The sets Xi,j,t,p , (i, j, t, p) \u2208 I(q, n) are the orbits of E \u00d7 E \u00d7 E under\nthe action of Aut(q, n).\n\n\f3.1. THE HAMMING SCHEME\n\n23\n\nProof. Let u, v, w \u2208 E and let (i, j, t, p) = d(u, v, w). Since the Hamming distances\ni, j, i + j \u2212 t \u2212 p and the number t \u2212 p = |{i | ui 6= vi 6= wi 6= ui }| are unchanged when\npermuting the coordinates or permuting the elements of q at any coordinate, we have\nd(u, v, w) = d(\u03c0u, \u03c0v, \u03c0w) for any \u03c0 \u2208 Aut(q, n).\nHence it suffices to show that there is an automorphism \u03c0 such that (\u03c0u, \u03c0v, \u03c0w) only\ndepends upon i, j, t and p. By permuting q at the coordinates in the support of u, we\nmay assume that u = 0. Let A := {i | vi 6= 0, wi = 0}, B := {i | vi = 0, wi 6= 0},\nC := {i | vi 6= 0, wi 6= 0, vi 6= wi } and D := {i | vi = wi 6= 0}. Note that |A| = i \u2212 t,\n|B| = j \u2212 t, |C| = t \u2212 p and |D| = p. By permuting coordinates, we may assume that\nA = {1, 2, . . . , i \u2212 t}, B = {i \u2212 t + 1, . . . , i + j \u2212 2t}, C = {i + j \u2212 2t + 1, . . . , i + j \u2212 t \u2212 p}\nand D = {i + j \u2212 t \u2212 p + 1, . . . , i + j \u2212 t}. Now by permuting q at each of the points in\nA \u222a B \u222a C \u222a D, we can accomplish that vi = 1 for i \u2208 A \u222a C \u222a D and wi = 2 for i \u2208 B \u222a C\nand wi = 1 for i \u2208 D.\nt,p\nDenote the stabilizer of 0 in Aut(q, n) by Aut0 (q, n). For (i, j, t, p) \u2208 I(q, n), let Mi,j\nbe the E \u00d7 E matrix defined by:\n\uf8f1\n\uf8f4\n\uf8f21 if |S(u)| = i, |S(v)| = j, |S(u) \u2229 S(v)| = t,\nt,p\n(3.11)\n(Mi,j )u,v :=\n|{i | vi = ui 6= 0}| = p,\n\uf8f4\n\uf8f3\n0 otherwise.\n\nLet Aq,n be the set of matrices\nX\n\nt,p\nxt,p\ni,j Mi,j ,\n\n(3.12)\n\n(i,j,t,p)\u2208I(q,n)\n\nwhere xt,p\ni,j \u2208 C. In the binary case, we will usually drop the superfluous p from the\nt\nnotation and write xti,j and Mi,j\n.\nFrom Proposition 11 it follows that Aq,n is the set of matrices that are stable under\npermutations \u03c0 \u2208 Aut0 (q, n) of the rows and columns. Hence Aq,n is the centralizer\nt,p\nalgebra of Aut0 (q, n). The Mi,j\nconstitute a basis for Aq,n and hence\n\uf8f1 n+3\u0001\n\uf8f4\nif q = 2,\n\uf8f2 3\ndim Aq,n =\n(3.13)\n\uf8f4\n\uf8f3 n+4\u0001\nif q \u2265 3,\n4\nby Proposition 10. Note that the algebra Aq,n contains the Bose\u2013Mesner algebra since\nX\nt,p\nAk =\nMi,j\n.\n(3.14)\n(i,j,t,p)\u2208I(q,n)\ni+j\u2212t\u2212p=k\n\nWe would like to point out here, that Aq,n coincides with the Terwilliger algebra (see\n[39]) of the Hamming scheme H(n, q) (with respect to 0). Recall that the Terwilliger algebra Tq,n is the complex matrix algebra generated by the adjacency matrices A0 , A1 , . . . , An\nof the Hamming scheme and the diagonal matrices E00 , E10 , . . . , En0 defined by\n(\n1 if |S(u)| = i,\n(Ei0 )u,u :=\n(3.15)\n0 otherwise,\n\n\f24\n\nCHAPTER 3. THE TERWILLIGER ALGEBRA OF H(N, Q)\n\nfor i = 0, 1, . . . , n.\nProposition 12. The algebras Aq,n and Tq,n coincide.\nk,k\nProof. Since Aq,n contains the matrices Ak and the matrices Ek0 = Mk,k\nfor k = 0, 1, . . . , n,\nit follows that Tq,n is a subalgebra of Aq,n . We show the converse inclusion. In the case\nq = 2 this follows since\nt,t\nMi,j\n= Ei0 Ai+j\u22122t Ej0 ,\n(3.16)\n\nas is readily verified. We concentrate on the case q \u2265 3. Define the zero-one matrices\nBi , Ci , Di \u2208 Tq,n by\nBi := Ei0 A1 Ei0 ,\n0\n,\nCi := Ei0 A1 Ei+1\n0\n0\nDi := Ei A1 Ei\u22121 .\n\n(3.17)\n\n(Bi )u,v = 1 if and only if\n|S(u)| = i, d(u, v) = 1, |S(v)| = i, S(u) = S(v),\n(Ci )u,v = 1 if and only if\n|S(u)| = i, d(u, v) = 1, |S(v)| = i + 1, |S(u)\u2206S(v)| = 1,\n(Di )u,v = 1 if and only if\n|S(u)| = i, d(u, v) = 1, |S(v)| = i \u2212 1, |S(u)\u2206S(v)| = 1.\n\n(3.18)\n\nObserve that:\n\nFor given (i, j, t, p) \u2208 I(q, n), let At,p\ni,j \u2208 Tq,n be given by\nt\u2212p\nAt,p\n.\ni,j := (Di Di\u22121 * * * Dt+1 )(Ct Ct+1 * * * Cj\u22121 )(Bj )\n\n(3.19)\n\nThen for words u, v \u2208 E, the entry (At,p\ni,j )u,v counts the number of (i + j \u2212 t \u2212 p + 3)-tuples\nu = di , di\u22121 , . . . , dt = ct , ct+1 , . . . , cj = b0 , . . . , bt\u2212p = v\n\n(3.20)\n\nwhere any two consecutive words have Hamming distance 1, the bk have equal support\nof cardinality j, and |S(dk )| = k, |S(ck )| = k for all k. Hence for u, v \u2208 E the following\nholds.\n(At,p\ni,j )u,v = 0 if d(u, v) > i + j \u2212 t \u2212 p or\n|S(u)\u2206S(v)| > i + j \u2212 2t\n\n(3.21)\n\nand\n(At,p\ni,j )u,v > 0 if |S(u)| = i, |S(v)| = j,\nd(u, v) = i + j \u2212 t \u2212 p and\n|S(u)\u2206S(v)| = i + j \u2212 2t.\n\n(3.22)\n\n\f3.2. BLOCK DIAGONALISATION OF AN\n\n25\n\nEquation (3.21) follows from the triangle inequality for d and d0 (x, y) := |S(x) \u2229 S(y)|.\nTo see (3.22) one may take for dk the zero-one word with support {i + 1 \u2212 k, . . . , i}, for ck\nthe zero-one word with support {i + 1 \u2212 t, . . . , i + k \u2212 t} and for bk the word with support\n{i + 1 \u2212 t, . . . , i + j \u2212 t} where the first k nonzero entries are 2 and the other nonzero\nentries are 1.\nt,p\nNow suppose that Aq,n is not contained in Tq,n , and let Mi,j\nbe a matrix not in Tq,n\nwith t maximal and (secondly) p maximal. If we write\nX t0 ,p0 t0 ,p0\nAt,p\n=\nxi,j Mi,j ,\n(3.23)\ni,j\nt0 ,p0\n0\n\n0\n\nt,p\nt,p\nthen by (3.21) xti,j,p = 0 if t0 + p0 < t + p or t0 < t implying that At,p\ni,j \u2212 xi,j Mi,j \u2208 Tq,n by\nt,p\nthe maximality assumption. Therefore since xt,p\ni,j > 0 by (3.22), also Mi,j belongs to Tq,n ,\na contradiction.\n\n3.2\n\nBlock diagonalisation of An\n\nA block diagonalisation of An := A2,n was first given by Schrijver in [38]. In this section\nwe will describe this block diagonalisation. In the next section we will use it to describe\na block diagonalisation of Aq,n for general q.\nLet n be a fixed positive integer and let P = Pn denote the collection of subsets of\n{1, . . . , n}. It will be convenient to identify binary words with their supports (as elements\nof P). We will use capital letters to denote sets. For convenience, we use the notation\ni\u22121\nCi := Mi\u22121,i\n,\n\nthat is\n(Ci )X,Y\n\n(\n1 if |X| = i \u2212 1, |Y | = i, X \u2286 Y ,\n=\n,\n0 otherwise\n\n(3.24)\n\n(3.25)\n\nfor i = 0, . . . n. In particular observe that C0 is the zero matrix. The matrices C1 , . . . , Cn\nand their transposes C1T , . . . , CnT play a prominent role in the block diagonalisation of An .\nThey generate the algebra An as can be easily seen from the identities\nT\nCi+1 Ci+1\n\u2212 CiT Ci = (n \u2212 2i)Ei0\n\nand\n\nn\nX\n\n(Ci + CiT ) = M1 .\n\n(3.26)\n\n(3.27)\n\ni=0\n\nIndeed, the adjacency matrix M1 of the P\nHamming cube generates the Bose\u2013Mesner algebra\nn\n0\nof the Hamming scheme. Since I =\ni=1 Ei is in the Bose\u2013Mesner algebra it follows\n0\nby (3.26) that also the diagonal matrices E1 , . . . , En0 are in the algebra generated by\nC1 , . . . , Cn , C1T , . . . ,\u0004Cn\u0005T .\nFor k = 0, . . . , n2 , define the linear space Lk to be the intersection of the space of\nvectors with support contained in the collection of sets of cardinality k, and the kernel of\nCk :\nLk := {b \u2208 RP | Ck b = 0, bX = 0 if |X| =\n6 k}.\n(3.28)\n\n\f26\n\nCHAPTER 3. THE TERWILLIGER ALGEBRA OF H(N, Q)\n\nProposition 13. For each k \u2264\n\n\u0004n\u0005\n\nthe dimension of Lk is given by\n\u0012 \u0013 \u0012\n\u0013\nn\nn\ndim Lk =\n\u2212\n.\n(3.29)\nk\nk\u22121\n\u0001\nn\nProof. It suffices to prove that Ck has rank k\u22121\n. This follows since for any nonzero\nP\nx \u2208 R with xI = 0 when |I| =\n6 k \u2212 1, we have Ck x 6= 0. Indeed\n2\n\nT\nxT Ck CkT x = xT Ck\u22121\nCk\u22121 x + (n \u2212 2k + 2)xT x > 0\n\n(3.30)\n\nby (3.26).\nBefore giving an explicit block diagonalisation, we will first sketch the basic idea. Let\nb \u2208 Lk be nonzero and consider the vectors bk , bk+1 , bk+2 , . . ., where bk := b and\nT\nT\nT\nb\nCk+1\n* * * Ck+2\nbi+1 := Ci+1\n\n(3.31)\n\nfor i \u2265 k. It can be shown (see Proposition 15 below) that\n\u0012\n\nn \u2212 2k\nkbi k = kbk *\ni\u2212k\n\n\u0013 12\n(i \u2212 k)!.\n\n(3.32)\n\nIt follows that bi is zero for i > n \u2212 k and nonzero for i = k, . . . , n \u2212 k. Since the bi have\ndisjoint support, bk , . . . , bn\u2212k are an orthogonal basis for the linear space Vb they span.\nFrom (3.26) it follows that\nT\nCi+1 bi+1 = Ci+1 Ci+1\nbi = (n \u2212 2i)bi + CiT (Ci bi )\n\n(3.33)\n\nand hence, since Ck bk = 0, that\nCi+i bi+1 = bi *\n\ni\nX\n\n(n \u2212 2s).\n\n(3.34)\n\ns=k\n\nThe space Vb is thus mapped to itself by each of the Ci and CiT and hence by every\nM \u2208 An . The action of An restricted to Vb is determined by\nCi+1 (\n\nn\u2212k\nX\nj=k\n\nT\nCi+1\n(\n\nn\u2212k\nX\n\ni\nX\nxj bj ) = xi+1 ( (n \u2212 2s))bi\n\n(3.35)\n\ns=k\n\nxj bj ) = xi bi+1\n\nj=k\n\nand does not depend on the particular choice of b \u2208 Lk , but only on k. If we take for\neach k an orthonormal basis of Lk and let b range over the union of these bases, we will\nobtain a decomposition of RP as a direct sum of orthogonal subspaces Vb . This yields a\nblock diagonalisation of An , where for each k there is a block of multiplicity dim Lk . In\nt\norder to obtain a formula for the image of Mi,j\nin each of the blocks, we need to express\nt\nMi,j (as a polynomial) in the matrices Cl and ClT .\n\n\f3.2. BLOCK DIAGONALISATION OF AN\n\n27\n\nWe will now give a detailed proof, see also [38]. We begin by giving a convenient way\nt\nto express the matrices Mi,j\nin terms of C1 , . . . , Cn , C1T , . . . , CnT . A first observation is that\ni\ni\n(k \u2212 i)Mi,k\n= Mi,k\u22121\nCk\n\nfor all i < k.\n\n(3.36)\n\nAn important consequence is that\ni\nMi,k\nb = 0 for all i < k and b \u2208 Lk .\n\n(3.37)\n\nSecondly, we have the following identity.\nProposition 14. For all l, k, p \u2208 {0, . . . , n}:\np\nMl,k\n\n\u0012 \u0013\nn\nX\ns\ns\ns\u2212p s\n.\nMs,k\nMl,s\n=\n(\u22121)\np\ns=0\n\n(3.38)\n\nProof. The entry of\nn\nX\n\n(\u22121)\n\ns\u2212p\n\ns=0\n\n\u0012 \u0013\ns\ns\ns\nMl,s\nMs,k\np\n\n(3.39)\n\nin position (X, Y ), with |X| = k, |Y | = l and |X \u2229 Y | = t, equals\nn\nX\n\n(\u22121)\n\ns=0\n\ns\u2212p\n\n\u0012 \u0013\u0012 \u0013\n\u0012 \u0013\u0012\n\u0013\nt\nX\ns\nt\nt\u2212p\ns\u2212p t\n(\u22121)\n=\np s\np s\u2212p\ns=p\n\u0012 \u0013X\n\u0012\n\u0013\nt\u2212p\nt\ns0 t \u2212 p\n(\u22121)\n=\n.\np s0 =0\ns0\n\n(3.40)\n\nThis last sum equals zero if t 6= p and equals 1 if t = p.\nk\nThe following proposition gives the inner products between vectors of the form Mj,k\nb,\nwhere b \u2208 Lk . These will be used to construct an orthonormal basis with respect to which\nthe algebra is in block diagonal form.\n\nProposition 15. For i, j, k, l \u2208 {0, . . . , n} with k, l \u2264\n(\nc\n\nT\n\nl\nk\nMl,i\nMj,k\nb\n\n=\n\nn\u22122k\ni\u2212k\n\n0\n\n\u0001\n\n\u0004n\u0005\n, and for c \u2208 Ll , b \u2208 Lk :\n2\n\ncT b if l = k, i = j\notherwise.\n\n(3.41)\n\nl\nk\nProof. Clearly Ml,i\nMj,k\n= 0 if i 6= j, hence we may assume i = j in the remainder of the\nproof. By (3.38) we have for 0 \u2264 p \u2264 k, l:\n\n(\n\u0001\nk\u2212p k T\n(\u22121)\nc b if k = l\np\np\ncT Ml,k\nb=\n0\notherwise,\n\n(3.42)\n\n\f28\n\nCHAPTER 3. THE TERWILLIGER ALGEBRA OF H(N, Q)\n\ns\ns\nsince cT Ml,s\n= 0 for s 6= l and Ms,k\nb = 0 for s 6= k. Hence we obtain\n\nc\n\nT\n\nl\nk\nMl,i\nMi,k\nb\n\n\u0013\nn \u0012\nX\nn+p\u2212l\u2212k\n\np\ncT Ml,k\nb\nn\n\u2212\ni\np=0\n\u0012 \u0013\n\u0013\nk \u0012\nX\nn + p \u2212 2k\nk\u2212p k\ncT b\n= \u03b4k,l *\n(\u22121)\np\nn\u2212i\np=0\n\u0012\n\u0013\nn \u2212 2k T\n= \u03b4k,l *\nc b.\ni\u2212k\n\n=\n\n(3.43)\n\nDefine for i, j, k, t \u2208 {0, . . . , n} the number\nt\n\u03b2i,j,k\n\n\u0012 \u0013\u0012\n\u0013\u0012\n\u0013\n\u0012\n\u0013 n\ni\u2212p n+p\u2212i\u2212k\nn \u2212 2k X\nk\u2212p k\n.\n:=\n(\u22121)\np t\u2212p\nn+t\u2212i\u2212j\ni \u2212 k p=0\n\n(3.44)\n\nThese numbers will be used to describe the block diagonalisation.\nProposition 16. For i, j, k, t \u2208 {0, . . . , n} with k \u2264\n\n\u0004n\u0005\n, and for b \u2208 Lk :\n2\n\n\u0012\n\u0013\nn \u2212 2k\nt\nk\nt\nk\nMi,j\nMj,k\nb = \u03b2i,j,k\nMi,k\nb.\ni\u2212k\n\n(3.45)\n\nProof. By (3.38), it follows that for 0 \u2264 p \u2264 n:\np\nMi,k\nb\n\n= (\u22121)\n\nk\u2212p\n\n\u0012 \u0013\nk\nk\nMi,k\nb.\np\n\n(3.46)\n\nThis implies that\nt\nk\nMi,j\nMj,k\nb\n\n=\n=\n\n\u0013\u0012\n\u0013\nn \u0012\nX\ni\u2212p n+p\u2212i\u2212k\nt\u2212p\n\np=0\nn \u0012\nX\np=0\n\ni\u2212p\nt\u2212p\n\nn+t\u2212i\u2212j\n\u0013\u0012\n\np\nMi,k\nb\n\n(3.47)\n\n\u0013\n\u0012 \u0013\nn+p\u2212i\u2212k\nk\u2212p k\nk\n(\u22121)\nMi,k\nb.\nn+t\u2212i\u2212j\np\n\nThis proves the proposition.\n\u0004 \u0005\nWe will now describe the block diagonalisation. For each k = 0, . . . , n2 , choose an\northonormal\n\u0001\n\u0001 basis Bk of the linear space Lk . By Proposition 13 we know that |Bk | =\nn\nn\n\u2212\n. Let\nk\nk\u22121\nV := {(k, b, i) | k \u2208 {0, . . . ,\n\njnk\n2\n\n}, b \u2208 Bk , i \u2208 {k, k + 1, . . . , n \u2212 k}}.\n\n(3.48)\n\n\f3.2. BLOCK DIAGONALISATION OF AN\n\n29\n\nThen\nn min{i,n\u2212i}\nX\nX \u0012\u0012n\u0013\n\n\u0012\n\n\u0013\u0013\nn\n|V| =\n\u2212\nk\nk\u22121\ni=0\nk=0\n\u0012\n\u0013\nn\nn \u0012 \u0013\nX\nX\nn\nn\n=\n=\n= 2n .\nmin{i, n \u2212 i}\ni\ni=0\ni=0\n\n(3.49)\n\nDefine for each (k, b, i) \u2208 V the vector uk,b,i \u2208 RP by\nuk,b,i\n\n\u0012\n\u0013\u2212 1\nn \u2212 2k 2 k\n:=\nMi,k b.\ni\u2212k\n\n(3.50)\n\nIf follows from Proposition 15 and |V| = 2n that the vectors uk,b,i form an orthonormal\nbase of RP . Let U be the P \u00d7 V matrix with uk,b,i as the (k, b, i)-th column. We will show\nthat for each triple i, j, t the matrix\nft := U T M t U\nM\ni,j\ni,j\n\n(3.51)\n\nis in block diagonal form. Indeed we have\nProposition 17. For (l, c, i0 ), (k, b, j 0 ) \u2208 V and i, j, t \u2208 {0, . . . , n}:\n\uf8f1\n\u0001 1\n\u0001 1\nn\u22122k \u2212 2 n\u22122k \u2212 2 t\n\uf8f4\n\u03b2i,j,k if l = k, i = i0 , j = j 0 , b = c,\n\uf8f2 i\u2212k\nj\u2212k\nft )(l,c,i0 ),(k,b,j 0 ) =\n(M\ni,j\n\uf8f4\n\uf8f3\n0\notherwise.\n\n(3.52)\n\nProof. We have\nt\nMi,j\nuk,b,j 0\n\n\u0013\u2212 1\nn \u2212 2k 2 t k\n=\nMi,j Mj 0 ,k b\nj0 \u2212 k\n\u0012\n\u0013\u2212 1 \u0012\n\u0013\u22121\nn \u2212 2k 2 n \u2212 2k\nt\nk\n= \u03b4j,j 0\n\u03b2i,j,k\nMi,k\nb\nj\u2212k\ni\u2212k\n\u0013\u2212 1\n\u0012\n\u0013\u2212 1 \u0012\nn \u2212 2k 2 n \u2212 2k 2 t\n\u03b2i,j,k uk,b,i .\n= \u03b4j,j 0\ni\u2212k\nj\u2212k\n\u0012\n\n(3.53)\n\nSince\nt\nt\nfi,j\n(M\n)(l,c,i0 ),(k,b,j 0 ) = uTl,c,i0 Mi,j\nuk,b,j 0\n\n(3.54)\n\nthe proposition follows.\nProposition 18. The matrix U gives a block diagonalisation of An .\nft has a block diagonal form, where for\nProof. Proposition 17 implies that each matrix M\ni,j\n\u0001\n\u0001\n\u0004n\u0005\nn\ncopies of an (n + 1 \u2212 2k) \u00d7 (n + 1 \u2212 2k) block on\neach k = 0, . . . 2 there are nk \u2212 k\u22121\nthe diagonal. For each k the copies are indexed by the elements of Bk , and in each copy\nthe rows and columns are indexed by the integers i \u2208 {k, k + 1, . . . , n \u2212 k}. Hence we\n\n\f30\n\nCHAPTER 3. THE TERWILLIGER ALGEBRA OF H(N, Q)\n\nneed to show that all matrices of this block diagonal form belong to U T An U . It suffices\nPb n2 c\nto show that the dimension k=0\n(n + 1 \u2212 2k)2 of the algebra consisting of\n\u0001 the matrices\nn+3\nin the given block diagonal form equals the dimension of An , which is 3 . This follows\nby induction on n from\n\u0012\n\u0013 \u0012\n\u0013 \u0012\n\u0013\n\u0012\n\u0013\nn+1\nn+3\n(n \u2212 2) + 3\nn+1\n\u2212\n=\n+2\n= (n + 1)2 .\n(3.55)\n3\n3\n1\n2\n\nRemark 1. Since\nt T\nt T\nfi,j\n) = U T (Mi,j\n) U\n(M\n\n(3.56)\n\nt\n= U T Mj,i\nU\nft ,\n= M\nj,i\n\nt\nt\nif follows from Proposition 17 that \u03b2i,j,k\n= \u03b2j,i,k\n, which is not obvious from the definition\nt\nof \u03b2i,j,k . In [38], Proposition 17 is derived in a slightly different manner, resulting in a\nt\ndifferent expression for \u03b2i,j,k\nwhich displays the symmetry between i and j:\n\u0012 \u0013\u0012\n\u0013\u0012\n\u0013\u0012\n\u0013\nn\nX\nn \u2212 2k\nn\u2212k\u2212u n\u2212k\u2212u\nt\nu\u2212t u\n\u03b2i,j,k =\n(\u22121)\n.\n(3.57)\nt\nu\n\u2212\nk\ni\n\u2212\nu\nj\n\u2212\nu\nu=0\n\n3.3\n\nBlock-diagonalisation of Aq,n\n\nIn this section we give an explicit block diagonalisation of the algebra Aq,n . The block\ndiagonalisation can be seen as an extension of the block diagonalisation in the binary\ncase as given in the previous section. There the binary Hamming space was taken to\nbe the collection of subsets P of {1, . . . , n}. Now it will be convenient to replace this\nby the collection of subsets of a given finite set V . Let V be a finite set of cardinality\n|V | = m. By P(V ) we denote the collection of subsets of V . For integers i, j, define the\nV\nP(V ) \u00d7 P(V ) matrix Ci,j\nby\n(\n1 if |I| = i, |J| = j, I \u2286 J or J \u2286 I,\nV\n(Ci,j\n)I,J :=\n(3.58)\n0 otherwise.\nV\nk\nThe matrices Ci,k\ncorrespond to the matrices Mi,k\nfrom the binary Terwilliger algebra.\nt,p\nWe have renamed them in order to avoid confusion with the matrices Mi,j\n\u2208 Aq,n . For\nk = 0, . . . , b m2 c define the linear space LVk by\nV\nLVk := {x \u2208 CP(V) | Ck\u22121,k\nx = 0, xI = 0 if |I| =\n6 k},\n\n(3.59)\n\nand let BkV be an orthonormal base of LVk . For i, j, k, t \u2208 {0, . . . , m}, define the number\n\u0012\n\u0013 m\n\u0012 \u0013\u0012\n\u0013\u0012\n\u0013\nm \u2212 2k X\ni\u2212p m+p\u2212i\u2212k\nm,t\nk\u2212p k\n\u03b2i,j,k :=\n(\u22121)\n.\n(3.60)\ni\u2212k\np t\u2212p\nm+t\u2212i\u2212j\np=0\nWe recall the following facts.\n\n\f3.3. BLOCK-DIAGONALISATION OF AQ,N\n\n31\n\nProposition 19. Let V be a finite set of cardinality m. Then\n\u0004 \u0005\n(i) For k \u2208 {0, . . . , m2 } we have\n\u0012 \u0013 \u0012\n\u0013\nm\nm\nV\ndim Lk =\n\u2212\n.\nk\nk\u22121\n\u0004m\u0005\n, and for b \u2208 LVk , c \u2208 LVl\n2\n(\n\u0001\nm\u22122k T\nc b if k = l,\nV\nT V\ni\u2212k\n(Ci,l c) Ci,k b =\n0\notherwise.\n\n(3.61)\n\n(ii) For i, k, l \u2208 {0, . . . , n} with k, l \u2264\n\n(iii) For i, j, k, t \u2208 {0, . . . , n} with k \u2264\nX\n\nV\n(Ci,k\nb)U\n\n(3.62)\n\n\u0004m\u0005\n, b \u2208 LVk and Y \u2286 V with |Y | = j\n2\n=\n\nm,t\n\u03b2i,j,k\n\n\u0012\n\nU \u2286V\n|U |=i\n|U \u2229Y |=t\n\nm \u2212 2k\nj\u2212k\n\n\u0013\u22121\n\nV\n(Cj,k\nb)Y .\n\n(3.63)\n\nProof. Items (i),(ii) and (iii) follow directly from Propositions 13, 15 and 16.\nWe will now describe a block diagonalisation of Aq,n . Let \u03c6 \u2208 C be a primitive\n(q \u2212 1)-th root of unity. Let\nV := {(a, k, i, a, b) |\na, k, i are integers satisfying 0 \u2264 a \u2264 k \u2264 i \u2264 n + a \u2212 k,\na \u2208 qn satisfies |S(a)| = a, ah 6= q \u2212 1 for h = 1, . . . , n,\n\n(3.64)\n\nS(a)\n\nb \u2208 Bk\u2212a },\nwhere U := {1, 2, . . . , n} \\ U for any set U \u2286 {1, 2, . . . , n}. For each tuple (a, k, i, a, b) in\nqn\nV, define the vector \u03a8a,k,i\nby\na,b \u2208 C\n(\u03a8a,k,i\na,b )x :=\n(\n1\n(q \u2212 1)\u2212 2 i\n0\n\n\u0001 1\nS(a)\nn+a\u22122k \u2212 2 ha,xi\n\u03c6\n(Ci\u2212a,k\u2212a b)S(x)\\S(a)\ni\u2212k\n\nif S(a) \u2286 S(x),\notherwise,\n\n(3.65)\n\nfor any x \u2208 qn . Here the nonnegative integer hx, yi is given by\nhx, yi :=\n\nn\nX\n\nx h yh\n\n(3.66)\n\nh=0\n\nfor any x, y \u2208 qn . We stress that hx, yi is not taken modulo q. Observe that (\u03a8a,k,i\na,b )x = 0\nif |S(x)| =\n6 i. We have:\nn\n\nq\nProposition 20. The vectors \u03a8a,k,i\na,b , (a, k, i, a, b) \u2208 V form an orthonormal base of C .\n\n\f32\n\nCHAPTER 3. THE TERWILLIGER ALGEBRA OF H(N, Q)\n\nn\nProof. First, the number |V| of vectors \u03a8a,k,i\na,b equals q since:\n\u0014\u0012\n\u0013 \u0012\n\u0013\u0015\n\u0012 \u0013\nX\nn\u2212a\nn\u2212a\nn\na\n\u2212\n(q \u2212 2)\nk\n\u2212\na\nk\u2212a\u22121\na\na,k,i\n0\u2264a\u2264k\u2264i\u2264n+a\u2212k\n\n\u0013 \u0012\n\u0013\u0015\nmin(i,n+a\u2212i) \u0014\u0012\nn X\ni \u0012 \u0013\nX\nX\nn\nn\u2212a\nn\u2212a\na\n=\n(q \u2212 2)\n\u2212\na\nk\n\u2212\na\nk\u2212a\u22121\ni=0 a=0\nk=a\n\u0012\n\u0013\n\u0012\n\u0013\nn X\ni\nX\nn\u2212a\nn\n=\n(q \u2212 2)a\nmin{i \u2212 a, n \u2212 i}\na\ni=0 a=0\n\u0012 \u0013\nn \u0012 \u0013X\ni\nX\nn\na i\n=\n(q \u2212 2)\na\ni a=0\ni=0\n\u0012\n\u0013\nn\nX\nn\n=\n(q \u2212 1)i = q n .\ni\ni=0\n0\n\n(3.67)\n\n0 0\n\na ,k ,i\n0\nSecondly, we calculate the inner product of \u03a8a,k,i\na,b and \u03a8a0 ,b0 . If i 6= i then the inner\nproduct is zero since the two vectors have disjoint support. So we may assume that i0 = i.\nWe obtain:\n\u0012\n\u0013\u2212 12 \u0012\n\u0013\u2212 1\nE\nD\nn + a0 \u2212 2k 0 2\na,k,i\na0 ,k0 ,i\n\u2212i n + a \u2212 2k\n\u03a8a,b , \u03a8a0 ,b0 = (q \u2212 1)\ni\u2212k\ni \u2212 k0\n(3.68)\nX\n0\nS(a)\nS(a0 )\n*\n\u03c6ha,xi\u2212ha ,xi (Ci\u2212a,k\u2212a b)S(x)\\S(a) * (Ci\u2212a0 ,k0 \u2212a0 b0 )S(x)\\S(a0 ) ,\nx\n\nwhere the sum ranges over all x \u2208 qn with |S(x)| = i and S(x) \u2287 S(a) \u222a S(a0 ). If aj 6= a0j\nP\nxj (aj \u2212a0j )\n=\nfor some j, then the inner product equals zero, since we can factor out q\u22121\nxj =1 \u03c6\n0\n0\n0. So we may assume that a = a (and hence a = a ), which simplifies the right-hand side\nof (3.68) to\n\u0012\n\u0013\u2212 1 \u0012\n\u0013\u2212 1\nn + a \u2212 2k 2 n + a \u2212 2k 0 2 S(a)\nS(a)\n(Ci\u2212a,k\u2212a b)T Ci\u2212a,k0 \u2212a b0 .\n(3.69)\ni \u2212 k0\ni\u2212k\nIndeed, since a0 = a, we observe that\n\u03c6ha,xi\u2212ha,xi = 1,\n\n(3.70)\n\nand hence the summand only depends on the support of x. We obtain\nX\nS(a)\nS(a)\n(Ci\u2212a,k\u2212a b)S(x)\\S(a) * (Ci\u2212a,k0 \u2212a b0 )S(x)\\S(a)\nx\n|S(x)|=i,S(x)\u2287S(a)\n\n=\n\nX\n\nS(a)\n\nS(a)\n\n(q \u2212 1)i (Ci\u2212a,k\u2212a b)X\\S(a) * (Ci\u2212a,k0 \u2212a b0 )X\\S(a)\n\nX\n|X|=i,X\u2287S(a)\n\n= (q \u2212 1)i\n\nX\n\n(3.71)\nS(a)\n(Ci\u2212a,k\u2212a b)Y\n\n*\n\nS(a)\n(Ci\u2212a,k0 \u2212a b0 )Y\n\nY \u2286S(a)\n|Y |=i\u2212a\nS(a)\n\nS(a)\n\n= (q \u2212 1)i (Ci\u2212a,k\u2212a b)T Ci\u2212a,k0 \u2212a b0 .\n\n\f3.3. BLOCK-DIAGONALISATION OF AQ,N\n\n33\n\nD\nE\na,k,i\na,k0 ,i\nFrom equation (3.69) and Proposition 19 we conclude that \u03a8a,b , \u03a8a,b0 is nonzero only\nif k = k 0 and b = b0 , in which case the inner product equals 1.\nt,p\nThe block diagonalisation will follow by writing the matrices Mi,j\nwith respect to the\na,k,i\nqn\nnew orthonormal basis of C formed by the vectors \u03a8a,b . To this end we define for\ni, j, t, p, a, k \u2208 {0, . . . , n} with a \u2264 k \u2264 i, j the number\n1\n\nn\u2212a,t\u2212a\n(q \u2212 1) 2 (i+j)\u2212t\n\u03b1(i, j, t, p, a, k) :=\u03b2i\u2212a,j\u2212a,k\u2212a\n\u0012 \u0013\u0012\n\u0013\np\nX\nt\u2212a\na\u2212g a\n(q \u2212 2)t\u2212a\u2212p+g .\n(\u22121)\n*\ng\np\n\u2212\ng\ng=0\n\n(3.72)\n\nWe obtain the following.\nProposition 21. For (i, j, t, p) \u2208 I(q, n) and (a, k, i0 , a, b) \u2208 V we have:\n0\n\nt,p a,k,i\nMj,i\n\u03a8a,b =\n\u0012\n\u0013\u2212 1 \u0012\n\u0013\u2212 1\nn + a \u2212 2k 2 n + a \u2212 2k 2\n\u03b4i,i0\n\u03b1(i, j, t, p, a, k)\u03a8a,k,j\na,b .\ni\u2212k\nj\u2212k\n\n(3.73)\n\nProof. Clearly, both sides of (3.73) are zero if i 6= i0 , hence we may assume that i = i0 .\nt,p a,k,i\nWe calculate (Mj,i\n\u03a8a,b )y . We may assume that |S(y)| = j, since otherwise both sides\nof (3.73) have a zero in position y. We have:\nt,p a,k,i\n(Mj,i\n\u03a8a,b )y =\n\nX\n\nt,p\n(Mj,i\n)y,x (\u03a8a,k,i\na,b )x\n\n(3.74)\n\nx\u2208qn\n\u2212 21 i\n\n= (q \u2212 1)\n\n\u0012\n\u0013\u2212 1\nn + a \u2212 2k 2 X hx,ai S(a)\n\u03c6\n(Ci\u2212a,k\u2212a b)S(x)\\S(a) ,\ni\u2212k\nx\n\nwhere the last sum ranges over all x \u2208 qn with |S(x)| = i, S(x) \u2287 S(a), |S(x) \u2229 S(y)| = t\nand |{h | xh = yh 6= 0}| = p.\nWe will work out the sum:\nX\nS(a)\n\u03c6hx,ai (Ci\u2212a,k\u2212a b)S(x)\\S(a) .\n(3.75)\nx\n|S(x)|=i,S(x)\u2287S(a)\n|S(x)\u2229S(y)|=t\n|{h|xh =yh 6=0}|\n\nP\nl*ah\nIf there exists an h \u2208 S(a) \\ S(y), we can factor out q\u22121\n= 0, implying that\nl=1 \u03c6\nboth sides of (3.73) have a zero at position y. Hence we may assume that S(y) \u2287 S(a).\nNow the support of each word x in this sum can be split into five parts U, U 0 , V, V 0 , W ,\nwhere\nU\nU0\nV\nV0\nW\n\n=\n=\n=\n=\n=\n\n{h \u2208 S(a) | xh = yh }\nS(a) \\ U,\n{h \u2208 S(y) \\ S(a) | xh = yh },\n((S(y) \\ S(a)) \u2229 S(x)) \\ V,\nS(x) \\ S(y).\n\n(3.76)\n\n\f34\n\nCHAPTER 3. THE TERWILLIGER ALGEBRA OF H(N, Q)\n\nSetting g := |U |, gives |U 0 | = a \u2212 g, |V | = p \u2212 g, |V 0 | = t \u2212 a \u2212 p + g and |W | = i \u2212 t.\nHence splitting the sum over g, we obtain:\np\nX\n\nX\n\ng=0\n\nU,U 0 ,V,V 0 ,W\n\nS(a)\n\n(Ci\u2212a,k\u2212a b)V \u222aV 0 \u222aW\nY\nh\u2208U\n\n\u03c6ah yh\n\nY\n\n(\u2212\u03c6ah yh )\n\nh\u2208U 0\n\nY\nh\u2208V\n\n1\n\nY\nh\u2208V\n\n(q \u2212 2)\n\n0\n\nY\n\n(q \u2212 1), (3.77)\n\nh\u2208W\n\nwhere U, U 0 , V, V 0 , W are as indicated. Substituting T = V \u222a V 0 \u222a W , we can rewrite this\nas\n\u0013\np \u0012 \u0013\u0012\nX\na\nt\u2212a\n(\u22121)a\u2212g (q \u2212 2)t\u2212a\u2212p+g *\ng\np\u2212g\ng=0\nX S(a)\n(Ci\u2212a,k\u2212a b)T , (3.78)\n(q \u2212 1)i\u2212t \u03c6ha,yi\nT\n\nwhere the sum ranges over all T \u2286 S(a) with |T | = i \u2212 a and |T \u2229 S(y)| = t \u2212 a. Now by\nProposition 19(iii), this is equal to\ni\u2212t\n\n(q \u2212 1)\n\n\u0013\np \u0012 \u0013\u0012\nX\na\nt\u2212a\ng=0\n\ng\n\np\u2212g\n\n(\u22121)a\u2212g (q \u2212 2)t\u2212a\u2212p+g *\nha,yi\n\n\u03c6\n\n\u0012\n\u0013\u22121\nn + a \u2212 2k\nS(a)\nn\u2212a,t\u2212a\n\u03b2i\u2212a,j\u2212a,k\u2212a\n(Cj\u2212a,k\u2212a b)S(y)\\S(a) , (3.79)\nj\u2212k\n\nwhich equals\n(\u03a8a,k,j\na,b )y\n\n*\n\nn\u2212a,t\u2212a\n\u03b2i\u2212a,j\u2212a,k\u2212a\n\n\u0012\n\u0013\u2212 1\n1\nn + a \u2212 2k 2\n(q \u2212 1)i\u2212t+ 2 j *\nj\u2212k\n\u0012 \u0013\u0012\n\u0013\np\nX\nt\u2212a\na\u2212g a\n(\u22121)\n(q \u2212 2)t\u2212a\u2212p+g . (3.80)\ng\np\u2212g\ng=0\n\nThis completes the proof.\nIf we define U to be the qn \u00d7 V matrix with \u03a8a,k,i\na,b as the (a, k, i, a, b)-th column, then\nft,p := U \u2217 M t,p U has\nProposition 21 shows that for each (i, j, t, p) \u2208 I(q, n) the matrix M\ni,j\ni,j\nentries\nft,p )(a,k,l,a,b),(a0 ,k0 ,l0 ,a0 ,b0 ) =\n(M\ni,j\n\uf8f1\n\u0001 1\n\u0001 1\nn+a\u22122k \u2212 2 n+a\u22122k \u2212 2\n\uf8f4\n\u03b1(i, j, t, p, a, k) if a = a0 , k = k 0 , a = a0 , b = b0 and\n\uf8f2 i\u2212k\nj\u2212k\n(3.81)\nl = i, l0 = j,\n\uf8f4\n\uf8f3\n0\notherwise.\nThis implies\n\n\f3.3. BLOCK-DIAGONALISATION OF AQ,N\n\n35\n\nProposition 22. The matrix U gives a block diagonalisation of Aq,n .\nft,p has a block diagonal form, where for\nProof. Equation (3.81) implies that each matrix M\ni,j\n\u0002\n\u0001\n\u0001\u0003\n\u0001\nn\u2212a\n\u2212\ncopies of an (n+a+1\u22122k)\u00d7(n+a+\neach pair (a, k) there are na (q\u22122)a n\u2212a\nk\u2212a\nn\u2212a\u22121\n1 \u2212 2k) block on the diagonal. For fixed a, k the copies are indexed by the pairs (a, b) such\nS(a)\nthat a \u2208 qn satisfies |S(a)| = a, ah 6= q \u2212 1 for h = 1, . . . , n, and b \u2208 Bk\u2212a . In each copy\nthe rows and columns in the block are indexed by the integers i with k \u2264 i \u2264 n + a \u2212 k.\nHence we need to show that all matricesP\nof this block diagonal form belong to U \u2217 Aq,n U .\n2\nIt suffices to show that the dimension\n0\u2264a\u2264k\u2264n+a\u2212k (n + a + 1 \u2212 2k) of the algebra\nconsisting of \u0001the matrices in the given block diagonal form equals the dimension of Aq,n ,\nwhich is n+4\n. This follows from\n4\nX\n\n(n + a + 1 \u2212 2k)2\n\n0\u2264a\u2264k\u2264n+a\u2212k\nn\u2212a\n\nc\nn bX\n2\nX\n\n=\n\n(n \u2212 a + 1 \u2212 2k)2\n\na=0 k=0\n\n\u0013\nn \u0012\nX\nn\u2212a+3\n\n=\n\na=0\n\u0012\n\u0013\nn+4\n=\n.\n4\n\n(3.82)\n\n3\n\nThis implies the following result.\nTheorem 4. The matrix\nM=\n\nX\n\nt,p\nxt,p\ni,j Mi,j\n\n(3.83)\n\n(i,j,t,p)\n\nis positive semidefinite if and only if for all a, k with 0 \u2264 a \u2264 k \u2264 n + a \u2212 k the matrices\n!n+a\u2212k\nX\n\n\u03b1(i, j, t, p, a, k)xt,p\ni,j\n\nt,p\n\n(3.84)\ni,j=k\n\nare positive semidefinite.\nProof. The matrix M is positive semidefinite if and only if U \u2217 M U is positive semidefinite.\nSince U \u2217 M U is in block diagonal form, where the blocks are exactly the matrices in (3.84),\neach with multiplicity at least one, the theorem follows.\nTheorem 5. The matrix\n\n\uf8eb\nR\uf8ed\n\n\uf8f6\nX\n\n(i,j,t,p)\n\nt,p \uf8f8\nxt,p\ni,j Mi,j\n\n(3.85)\n\n\f36\n\nCHAPTER 3. THE TERWILLIGER ALGEBRA OF H(N, Q)\n\nis positive semidefinite if and only if for all a, k with 0 \u2264 a \u2264 k \u2264 n + a \u2212 k and k 6= 0\nthe matrix\n!n+a\u2212k\nX\nt,p\n\u03b1(i, j, t, p, a, k)xi,j\n(3.86)\nt,p\n\ni,j=k\n\nis positive semidefinite, and also the matrix\n\u0012\n\n1 xT\nx L\n\n\u0013\n(3.87)\n\nis positive semidefinite, where\n!n\nL :=\n\nX\n\n\u03b1(i, j, t, p, 0, 0)xt,p\ni,j\n\nt,p\n\n(3.88)\ni,j=0\n\nand\n\u0012 \u0013\nn\nxi =\n(q \u2212 1)i * xi,i\ni,i\ni\n\nfor i = 0, . . . , n.\n\n(3.89)\n\nProof. Let\nX\n\nM :=\n\nt,p\nxt,p\ni,j Mi,j .\n\n(3.90)\n\n(i,j,t,p)\n\nObserve that\n\u0012\n\n1 0\n0 U\n\n\u0013\u2217\n\n\u0012\n\u0013 \u0012\n\u0013\n1 0\n1\n(diag(M ))T U\nR(M )\n=\n.\n0 U\nU \u2217 diag(M )\nU \u2217M U\n\n(3.91)\n\n\u0012 \u0013\n\u0012 \u0013\nn\nn\ni 0,0,i\n=\n(q \u2212 1) \u03a80,1 =\n(q \u2212 1)i U(0,0,i,0,1)\ni\ni\n\n(3.92)\n\nSince\nSi (0)\n\n\u03c7\n\nand U \u2217 U = I, we see that\nU \u2217 diag(M ) = U \u2217\n\nn\nX\n\nSi (0)\nxi,i\ni,i \u03c7\n\n(3.93)\n\ni=0\nn\nX\n\n\u0012 \u0013\nn\n=\n(q \u2212 1)i U \u2217 U(0,0,i,0,1)\ni\ni=0\n\u0012 \u0013\nn\nX\ni,i n\n=\nxi,i\n(q \u2212 1)i \u03c7(0,0,i,0,1)\ni\ni=0\nxi,i\ni,i\n\nhas nonzero entries only in the block corresponding to a = k = 0. The theorem follows.\n\n\f3.4. THE TERWILLIGER ALGEBRA OF THE JOHNSON SCHEME\n\n3.4\n\n37\n\nThe Terwilliger algebra of the Johnson scheme\n\nThe Hamming scheme is a natural and powerful tool in studying subsets of the binary\nHamming space with prescribed distance relations. In particular, the Delsarte bound\ngives good upper bounds on the size of a code. In the case of constant weight codes, one\nconsiders subsets of the Johnson space, consisting of the subsets of some fixed size w.\nNow the appropiate tool to use is the Johnson scheme.\nLet w \u2264 n be positive integers and let Pnw be the collection of subsets of {1, . . . , n}\nof cardinality\nw. So Pn is the disjoint union of Pn0 , Pn1 , . . . , Pnn . We will assume that\n\u0004n\u0005\nw \u2264 2 . This is not a severe restriction since Pnw and Pnn\u2212w , with the Hamming distance, are isomorphic. This is because the Hamming distance is preserved under taking\ncomplements: d(U, V ) = d(U , V ) for sets U, V \u2208 {1, . . . , n}. It is convenient to define the\nJohnson distance dJ by\n1\ndJ (U, V ) := w \u2212 |U \u2229 V | = d(U, V ).\n2\n\n(3.94)\n\nWe denote by Aut(n, w) the set of automorphisms of the Johnson space. It is easy to\nsee that the automorphisms are just the permutations of Pnw induced by permuting the\nground set {1, . . . , n}. The distance relations R0 , . . . , Rw given by\nRd := {(U, V ) \u2208 Pnw \u00d7 Pnw | dJ (U, V ) = d}\n\n(3.95)\n\nare precisely the orbits under the action of Aut(n, w) on Pnw \u00d7 Pnw :\nRd = {(\u03c3U, \u03c3V ) | \u03c3 \u2208 Aut(n, w)},\n\nwhen dJ (U, V ) = d.\n\n(3.96)\n\nHence R0 , . . . , Rw form an association scheme called the Johnson scheme J(n, w). The\nw\nw\nBose\u2013Mesner algebra of the Johnson scheme is spanned by the matrices Ad \u2208 CPn \u00d7Pn ,\nd = 0, . . . , w given by\n(\n1 if dJ (U, V ) = d\n.\n(3.97)\n(Ad )U,V :=\n0 otherwise\nLike in the case of the Hamming scheme, it useful to consider the refinement of the\nJohnson scheme obtained by replacing the full symmetry group Aut(n, w) by the stabilizer\nsubgroup AutW (n, w) of some arbitrary element W \u2208 Pnw . Therefore we fix some W \u2208 Pnw .\ns,t\nConsider the complex algebra T spanned by the 0\u20131 matrices Mi,j\nwhere 0 \u2264 s \u2264 i, j \u2264 w\nand t \u2264 w \u2212 i, w \u2212 j, given by\n\uf8f1\n\uf8f4\n\uf8f21 if |U \u2229 W | = i, |V \u2229 W | = j,\ns,t\n(Mi,j )U,V :=\n(3.98)\n|U \u2229 V \u2229 W | = s, |U \u2229 V \\ W | = t .\n\uf8f4\n\uf8f3\n0 otherwise\ns,t\nIt is not hard to verify that supports of the matrices Mi,j\ncorrespond to the orbits of\nPnw \u00d7 Pnw under the action of AutW (n, w). The algebra T is in fact the Terwilliger algebra\nof the Johnson scheme J(n, w) with respect to W .\nWe will give a block diagonalisation of the Terwilliger algebra of the Johnson scheme.\nThis was implicit in the work of Schrijver ([38]).\n\n\f38\n\nCHAPTER 3. THE TERWILLIGER ALGEBRA OF H(N, Q)\n\nLet Aw,n\u2212w := Aw \u2297 An\u2212w be the tensor product of the algebras Aw and An\u2212w . The\nalgebra Aw,n\u2212w consists of the matrices\nX\n0\nt\nt0\nxt,t\n(3.99)\ni,j,i0 ,j 0 Mw;i,j \u2297 Mn\u2212w;i0 ,j 0 ,\ni,j,t,i0 ,j 0 ,t0\n0\n\nT\nwhere xt,t\ni,j,i0 ,j 0 \u2208 C. From Section 3.2 we obtain matrices Uw and Un\u2212w such that Uw Aw Uw\nT\nAn\u2212w Un\u2212w are in block diagonal form. It follows that U := Uw \u2297 Un\u2212w block\nand Un\u2212w\ndiagonalises Aw,n\u2212w since\nT\nU T Aw,n\u2212w U = UwT Aw Uw \u2297 Un\u2212w\nAn\u2212w Un\u2212w .\n\n(3.100)\n\nIt follows from Proposition 17 that the blocks are indexed by the pairs\n\u0016\n\u0017\njwk\nn\u2212w\n0\n(k, k ) \u2208 {0, 1, . . . ,\n} \u00d7 {0, 1, . . . ,\n}.\n2\n2\n\n(3.101)\n\nFor each such pair (k, k 0 ) we have a block Bk,k0 , consisting of all (Vk \u00d7 Vk00 ) \u00d7 (Vk \u00d7 Vk00 )\nmatrices, where Vk := {k, . . . , w \u2212 k} and Vk00 := {k 0 , . . . , n \u2212 w \u2212 k 0 }. The image of (3.99)\nin block (k, k 0 ) is given by\n!\nh\nX t,t0\n\u0001\n\u0001\n\u0001\n\u0001i\u2212 21\nw,t\nn\u2212w,t0\nw\u22122k w\u22122k n\u2212w\u22122k0 n\u2212w\u22122k0\nxi,j,i0 ,j 0 \u03b2i,j,k * \u03b2i0 ,j 0 ,k0\n(3.102)\ni\u2212k\nj\u2212k\ni0 \u2212k0\nj 0 \u2212k0\ni,j\u2208Vk\ni0 ,j 0 \u2208Vk00\n\nt,t0\n\nBy extending each matrix in T by zeros to a Pn \u00d7 Pn matrix, and identifying Pn with\nPw \u00d7 Pn\u2212w (by identifying U and (U \u2229 W, U \\ W ) for any U \u2208 Pn ), the Terwilliger algebra\ns,t\ns\nt\nis identified with Mi,j\n\u2297 Mw\u2212i,w\u2212j\n.\nT can be seen as a subalgebra of Aw,n\u2212w , where Mi,j\nIt follows that in the block diagonalisation given above, T is mapped in block (k, k 0 ) to\nthose matrices that have nonzeros only in positions with rows and columns indexed by\n{(i, w \u2212 i) | i \u2208 Vk , w \u2212 i \u2208 Vk00 }. Hence restricting each block to those indices, we obtain\na block diagonalisation of T with blocks of size\n|{k, . . . , n \u2212 k} \u2229 {2w \u2212 n + k 0 , . . . , w \u2212 k 0 }|\n\n(3.103)\n\nfor each pair (k, k 0 ) with k + k 0 \u2264 w. This was used in [38] to obtain bounds on constant\nweight codes.\nIn the nonbinary case, let E be the set of q-ary word of length n and weight w, equipped\nwith the Hamming distance. The q-ary Johnson scheme Jq (n, w) has adjacency matrices\nMt,p for 0 \u2264 p \u2264 t \u2264 w given by the orbits of E \u00d7 E under the action of the automorphism\ngroup of E:\n(\n1 if |S(x) \u2229 S(y)| = t, |{i | xi = yi 6= 0}| = p,\n(Mt,p )x,y :=\n(3.104)\n0 otherwise.\nReplacing the full automorphism group by the stabilizer of some word w \u2208 E we obtain\nan algebra containing the Bose\u2013Mesner algebra of the nonbinary Johnson scheme which\nmay serve to improve bounds for constant weight codes in the nonbinary case. We do not\nknow if this is the Terwilliger algebra (with respect to w) of the nonbinary Johnson scheme\nJq (n, w). The \u0001algebra is\u0001a subalgebra of a tensor product of Aq,n\u2212w and an algebra of\ndimension w+9\n(or w+8\nif q = 3). It would be interesting to find a block diagonalisation\n9\n8\nof this algebra.\n\n\fChapter 4\nError correcting codes\nGiven a code C \u2286 E := q n , the minimum distance of C is defined to be the minimum\nof {d(u, v) | u 6= v, u, v \u2208 C}. The maximum cardinality of a code with minimum\ndistance at least d is denoted by Aq (n, d). In this chapter we give new upper bounds on\nAq (n, d) based on a semidefinite programming approach, strengthening Delsarte's linear\nprogramming bound. For more information on coding theory, the reader is referred to\n[30, 33].\n\n4.1\n\nDelsarte's linear programming bound\n\nGiven a code C \u2286 E, the (n + 1)-tuple (x0 , x1 , . . . , xn ) defined by\nxi := |C|\u22121 * |{(u, v) \u2208 C \u00d7 C | d(u, v) = i}|\n\n(4.1)\n\nis called the distance distribution of the code C. For each i the number xi equals the\naverage number of code words at distance i from a given code word. Observe that x0 = 1\nand x0 + x1 + * * * + xn = |C|. The key observation that leads to the linear programming\nbound is that the following inequalities hold:\nn\nX\n\nxi Kj (i) \u2265 0 for all j = 0, . . . , n,\n\n(4.2)\n\ni=0\n\nwhere\n\u0012 \u0013\u0012\n\u0013\nj\nX\nn\u2212x\nk x\nKj (x) :=\n(\u22121)\n(q \u2212 1)j\u2212k ,\nk\nj\u2212k\nk=0\n\nj = 0, . . . , n\n\n(4.3)\n\nare the Krawtchouk polynomials. These inequalities give rise to the following linear programming bound on the size of a code with minimum distance at least d:\nn\nX\nAq (n, d) \u2264 max{\nxi |\n\nx0 = 1, x1 , . . . , xn \u2265 0,\n\ni=0\n\nx1 = * * * = xd\u22121 = 0,\nthe xi satisfy (4.2)}.\n39\n\n(4.4)\n\n\f40\n\nCHAPTER 4. ERROR CORRECTING CODES\n\nThis approach turned out to be very powerful. Many of the best known upper bounds on\nAq (n, d) are obtained using this method.\nA proof of the validity of (4.2) can be found for example in [15, 30]. To illustrate the\nsemidefinite programming approach in this chapter, we sketch a proof here. For any code\nC \u2286 E, we denote by MC the 0\u20131 matrix defined by\n(\n1 if u, v \u2208 C\n(MC )u,v :=\n.\n(4.5)\n0 otherwise\nWe prove (4.2).\nProof. Consider the matrix\nM :=\n\n1\n|Aut(q, n)| * |C|\n\nX\n\nM\u03c3C .\n\n(4.6)\n\n\u03c3\u2208Aut(q,n)\n\nThe matrix M is an element of the Bose\u2013Mesner algebra of the Hamming scheme and the\ncoefficients with respect to the adjacency matrices Ai of the Hamming scheme reflect the\ndistance distribution:\nn\nX\nM=\nxi \u03b3i\u22121 Ai ,\n(4.7)\ni=0\n\nwhere\n\n\u0012 \u0013\nn\n\u03b3i := q (q \u2212 1)\ni\nn\n\ni\n\n(4.8)\n\nis the number of nonzero entries of Ai . Indeed, we have hAi , M\u03c3C i = |C|xi , and hence\nhAi , M i = xi for every i = 0, . . . , n and every \u03c3 \u2208 Aut(q, n).\nThe matrix M is a nonnegative combination of the positive semidefinite matrices\nM\u03c3C and is therefore positive semidefinite itself. The inequalities (4.2) will follow from\nthis semidefiniteness by diagonalising the Bose\u2013Mesner algebra. Let the unitary matrix\nU \u2208 CE\u00d7E be given by\n(U )u,v := q \u2212n/2 \u03c6hu,vi\n(4.9)\nfor u, v \u2208 E, where \u03c6 is a primitive q-th root of unity. It is a straightforward calculation\nei := U \u2217 Ai U is a diagonal matrix with\nto show that for each i = 0, . . . , n the matrix A\nei )u,u = Ki (j) = \u03b3i \u03b3 \u22121 Kj (i) when d(0, u) = j.\n(A\nj\n\n(4.10)\n\nSince M is positive semidefinite, also the diagonal\nmatrix U \u2217 M U is positive semidefinite,\nPn\nwhich means that all diagonal elements i=0 xi Kj (i)\u03b3j\u22121 , j = 0, . . . n are nonnegative.\nThis implies (4.2).\nIn fact, the equivalence of U \u2217 M U \u0017 0 and M \u0017 0 shows the following, which we\nmention for future reference.\nProposition 23. For x0 , x1 , . . . , xn \u2208 R, we have\nx0 A0 + xc1 A1 + * * * + xn An \u0017 0 if and only if\nx0 Kj (0) + x1 Kj (1) + * * * + xn Kj (n) \u2265 0 for j = 0, . . . , n.\n\n(4.11)\n\n\f4.2. SEMIDEFINITE PROGRAMMING BOUND\n\n4.2\n\n41\n\nSemidefinite programming bound\n\nIn this section we describe a way to obtain upper bounds on Aq (n, d) by semidefinite\nprogramming. The method strengthens Delsarte's linear programming bound and was\nintroduced by Schrijver in [38] in the case of binary codes. There it was used to find a\nlarge number of improved bounds for binary codes. While this thesis was being written,\nthe same method was used by de Klerk and Pasechnik in [26] to bound the stability\nnumber of orthogonality graphs, (or equivalently) the maximum size of a binary code of\nlength n in which no two words have Hamming distance 12 n, where n is divisible by four.\nIn this section we will describe this method, but restrict ourselves to the nonbinary\ncase. In Section 4.3 we give a list of improved upper bounds that we found with this\nmethod for q = 3, 4, 5.\nLet C be any code. We define the matrices M 0 and M 00 by:\nX\nM 0 := |Aut(q, n)|\u22121\nM\u03c3C\n(4.12)\n\u03c3\u2208Aut(q,n)\n0\u2208\u03c3C\n\nM 00 := |Aut(q, n)|\u22121\n\nX\n\nM\u03c3C .\n\n\u03c3\u2208Aut(q,n)\n06\u2208\u03c3C\n\nBy construction, the matrices M 0 and M 00 are invariant under permutations \u03c3 \u2208\nAut0 (q, n) of the rows and columns. Hence M 0 and M 00 are elements of the algebra Aq,n .\nWe write\nX t,p t,p\n(4.13)\nM0 =\nxi,j Mi,j .\n(i,j,t,p)\nt,p\nare the standard basis matrices of the algebra Aq,n .\nHere the matrices Mi,j\n00\nThe matrix M can be expressed in terms of the coefficients xt,p\ni,j as follows.\n\nProposition 24. The matrix M 00 satisfies\nX 0,0\nt,p\nM 00 =\n(xi+j\u2212t\u2212p,0 \u2212 xt,p\ni,j )Mi,j .\n\n(4.14)\n\n(i,j,t,p)\n\nProof. The matrix\nX\n\nM := M 0 + M 00 = |Aut(q, n)|\u22121\n\nM\u03c3C\n\n(4.15)\n\n\u03c3\u2208Aut(q,n)\n\nis invariant under permutation of the rows and columns by any permutation \u03c3 \u2208 Aut(q, n),\nand hence is an element of the Bose\u2013Mesner algebra, say\nX\nM=\nyk A k .\n(4.16)\nk\n\nObserve that for any u \u2208 E with d(u, 0) = k, we have\nyk = (M )u,0 = (M 0 )u,0 = x0,0\nk,0 ,\n\n(4.17)\n\n\f42\n\nCHAPTER 4. ERROR CORRECTING CODES\n\nsince (M 00 )u,0 = 0. Hence we have\nM 00 = M \u2212 M 0\nX 0,0\nX t,p t,p\n=\nxi,j Mi,j\nxk,0 Ak \u2212\nk\n\n=\n\n(i,j,t,p)\n\nX\n\nX\n\nk\n\ni+j\u2212t\u2212p=k\n\nX\n\n=\n\n(4.18)\n\nX\n\n0,0\nt,p\nxk,0\nMi,j\n\u2212\n\n(x0,0\ni+j\u2212t\u2212p,0\n\nt,p\nxt,p\ni,j Mi,j\n\n(i,j,t,p)\n\n\u2212\n\nt,p\nxt,p\ni,j )Mi,j ,\n\n(i,j,t,p)\n\nwhich proves the proposition.\nThe coefficients xt,p\ni,j carry important information about the code C, comparable to\nthe distance distribution in Delsarte's linear programming approach. Where the distance\ndistribution records for each distance d the number of pairs in C at distance d, the\n3\ncoefficients xt,p\ni,j count the number of triples (u, v, w) \u2208 C for each equivalence class of\n3\nE under the action of Aut(q, n). We express this formally as follows. Recall that\nXi,j,t,p := {(u, v, w) \u2208 E \u00d7 E \u00d7 E | d(u, v, w) = (i, j, t, p)},\n\n(4.19)\n\nfor (i, j, t, p) \u2208 I(q, n). Now denote for each (i, j, t, p) \u2208 I(q, n) the numbers\n\u03bbt,p\ni,j := |(C \u00d7 C \u00d7 C) \u2229 Xi,j,t,p |,\n\n(4.20)\n\nt,p\n\u03b3i,j\n:= |({0} \u00d7 E \u00d7 E) \u2229 Xi,j,t,p |\n\n(4.21)\n\nand let\nt,p\nbe the number of nonzero entries of Mi,j\n. A simple calculation yields:\n\u0012\n\u0013\nn\nt,p\ni+j\u2212t\nt\u2212p\n\u03b3i,j = (q \u2212 1)\n(q \u2212 2)\n.\np, t \u2212 p, i \u2212 t, j \u2212 t\n\n(4.22)\n\nt,p\nThe numbers xt,p\ni,j are related to the numbers \u03bbi,j by\n\u2212n t,p \u22121 t,p\nProposition 25. xt,p\n(\u03b3i,j ) \u03bbi,j .\ni,j = q\nt,p\nt,p\nt,p\nProof. Observe that the matrices Mi,j\nare pairwise orthogonal and that Mi,j\n, Mi,j\n=\nt,p\n\u03b3i,j for (i, j, t, p) \u2208 I(q, n). Hence\nX X\nt,p\nt,p\nM 0 , Mi,j\n= |Aut(q, n)|\u22121\nM\u03c3C , Mi,j\n(4.23)\nu\u2208C \u03c3\u2208Aut(q,n)\n\u03c3u=0\n\n= |Aut(q, n)|\u22121 * |Aut0 (q, n)|\n\nX\n\n*|({u} \u00d7 C \u00d7 C) \u2229 Xi,j,t,p |\n\nu\u2208C\n\n= q \u2212n |(C \u00d7 C \u00d7 C) \u2229 Xi,j,t,p | = q \u2212n \u03bbt,p\ni,j\nimplies that\nM 0 = q \u2212n\n\nX\n\nt,p \u22121\nt,p\n\u03bbt,p\ni,j (\u03b3i,j ) Mi,j .\n\n(i,j,t,p)\u2208I(q,n)\nt,p\nComparing the coefficients of the Mi,j\nwith those in (4.13) proves the proposition.\n\n(4.24)\n\n\f4.2. SEMIDEFINITE PROGRAMMING BOUND\n\n43\n\nProposition 26. The xt,p\ni,j satisfy the following linear constraints, where (iii) holds if C\nhas minimum distance at least d:\n(i)\n(ii)\n(iii)\n\n0,0\n0 \u2264 xt,p\ni,j \u2264 xi,0\n\n(4.25)\n\nt0 ,p0\n\n0\n0\nxt,p\ni,j = xi0 ,j 0 if t \u2212 p = t \u2212 p and\n(i, j, i + j \u2212 t \u2212 p) is a permutation of (i0 , j 0 , i0 + j 0 \u2212 t0 \u2212 p0 )\nxt,p\n6 \u2205.\ni,j = 0 if {i, j, i + j \u2212 t \u2212 p} \u2229 {1, 2, . . . , d \u2212 1} =\n\nProof. Conditions (ii) and (iii) follow directly from Proposition 25. Condition (i) follows\nfrom the fact that if M = M\u03c3C for some \u03c3 \u2208 Aut(q, n) with 0 \u2208 \u03c3C, then 0 \u2264 Mu,v \u2264 M0,u\nfor any u, v \u2208 E.\nAn important feature of the matrices M 0 and M 00 is, that they are positive semidefinite.\nThis follows since M 0 and M 00 are nonnegative combinations of the matrices M\u03c3C =\n\u03c7\u03c3C (\u03c7\u03c3C )T which are clearly positive semidefinite. Using the block diagonalisation of\nAq,n , the positive semidefiniteness of M 0 and M 00 is equivalent to:\nfor all a, k with 0 \u2264 a \u2264 k \u2264 n + a \u2212 k, the matrices\n!n+a\u2212k\nX\n\u03b1(i, j, t, p, a, k)xt,p\ni,j\nt,p\n\n(4.26)\n\ni,j=k\n\nand\n!n+a\u2212k\nX\n\n0,0\n\u03b1(i, j, t, p, a, k)(xi+j\u2212t\u2212p,0\n\n\u2212\n\nxt,p\ni,j )\n\nt,p\n\ni,j=k\n\nare positive semidefinite.\nIf we view the xt,p\ni,j as variables, we obtain an upper bound on the size of a code of\nminimum distance d as follows.\nTheorem 6. The semidefinite programming problem\nn \u0012 \u0013\nX\nn\n0,0\nmaximize\n(q \u2212 1)i xi,0\ni\ni=0\n\nsubject to\n\n(4.27)\n\nx0,0\n0,0 = 1, and conditions (4.25) and (4.26)\nis an upper bound on Aq (n, d).\nProof. We first remark that conditions (4.25) and (4.26) are invariant under scaling the\n0,0\nnumbers xt,p\ni,j with a common positive factor. The constraint x0,0 = 1 serves as a normalisation. If C \u2286 E is a code of minimum distance d. Setting\nt,p t,p\nn\nxt,p\ni,j := q * \u03bbi,j \u03b3i,j\n\ngives a feasible solution with objective value |C|.\n\n(4.28)\n\n\f44\n\nCHAPTER 4. ERROR CORRECTING CODES\n\nThis is a semidefinite programming problem with O(n4 ) variables, and can be solved\nin time polynomial in n. This semidefinite programming bound is at leastP\nas strong as\n\u0001 the\nn\nDelsarte bound. Indeed, the Delsarte bound is equal to the maximum of ni=0 x0,0\ni,0 i (q \u2212\n0,0\n0,0\n0,0\n0,0\ni\n1) subject to the conditions x0,0 = 1, x1,0 = * * * = xd\u22121,0 = 0, xi,0 \u2265 0 for all i = d, . . . , n\nand\nn\nX\nx0,0\nis positive semidefinite,\n(4.29)\ni,0 Ai\ni=0\n\nas was shown in the previous section. This last constraint is equivalent to\nX 0,0\nt,p\nxi+j\u2212t\u2212p,0 Mi,j\nis positive semidefinite,\n\n(4.30)\n\ni,j,t,p\n\nP\nt,p\nsince Ak = i+j\u2212t\u2212p=k Mi,j\n. It follows that (4.29) is implied by the condition that M 0\nand M 00 be positive semidefinite, that is condition (4.26).\n\n4.2.1\n\nVariations\n\nThere are a number of obvious variations to the semidefinite program (4.27), altering the\n0,0\nobjective function and the constraint x0,0\n= 1. For convenience we will optimize over\nmatrices\nX t,p t,p\nM :=\nxi,j Mi,j\n(4.31)\ni,j,t,p\n\nin the Terwilliger algebra. Observe that the numbers xt,p\ni,j are uniquely determined by M\nand vice versa. The semidefinite program (4.27) can be rewritten as\n0,0\nsubject to (4.25), (4.26) and x0,0\n= 1.\n\nmaximize trM\n\n(4.32)\n\nConsider the following two variations\nmaximize\n\nx0,0\n0,0\n\n(4.33)\n\u0012\n\nsubject to\n\n(4.25), (4.26) and\n\n0,0 \u0013\nx0,0\n\n1\nx0,0\n0,0 trM\n\n\u0017 0,\n\nand\nmaximize\nsubject to\n\n1T M 1\n(4.25), (4.26) and trM = 1.\n\n(4.34)\n\nThe idea behind variation (4.33) is that for a code C, setting\nt,p\nn t,p \u22121\nxt,p\ni,j := \u03bbi,j * q (\u03b3i,j ) ,\n\n(4.35)\n\nP\nt,p\nt,p\n2\n0\nwe obtain a feasible solution with x0,0\n0,0 = |C| and trM = |C| . If M =\ni,j,t,p yi,j Mi,j\n0,0 \u22121\nis a feasible solution to (4.33), then M := (y0,0\n) M 0 is a feasible solution to (4.32) with\nP\n0,0 \u22121\n0,0\nt,p\nt,p\ntrM = trM 0 * (y0,0\n) \u2265 y0,0\n. Conversely, if M 0 = i,j,t,p yi,j\nMi,j\nis a feasible solution to\n\n\f4.3. COMPUTATIONAL RESULTS\n\n45\n\nt,p\n0,0\n0\n0\n(4.32), then setting xt,p\ni,j := yi,j * trM gives a feasible solution to (4.33) with x0,0 = 1 * trM .\nHence both semidefinite programs yield the same value.\nt,p\nn t,p \u22121\n\u22122\nThe validity of variation (4.34) can be seen by setting xt,p\nfor\ni,j := \u03bbi,j * q (\u03b3i,j ) |C|\nT\n0\na given code C. Then trM = 1 and 1 M 1 = |C|. For any feasible solution M to (4.32),\nwe have 1T M 0 1 \u2265 (trM 0 )2 , hence M := (trM 0 )\u22121 M 0 is a feasible solution to (4.34) with\n1T M 1 \u2265 trM 0 . It follows that the optimum value in (4.34) is at least the optimum value\nin (4.32). We do not know if the reverse inequality holds.\n\n4.2.2\n\nA strengthening\n\nIt was observed by Laurent (see [28]) that not only is the matrix M 00 defined in (4.14)\npositive semidefinite, also the following stronger property holds:\n\u0012\n\u0013\n(diag(M 00 ))T\n1 \u2212 x0,0\n0,0\nis positive semidefinite.\n(4.36)\ndiag(M 00 )\nM 00\nThis follows from the fact that for a code C and \u03c3 \u2208 Aut(q, n) the matrix\n\u0013 \u0012\n\u0013\u0012\n\u0013T\n\u0012\n1\n1\n1\n(\u03c7\u03c3C )T\n=\nis positive semidefinite\n\u03c7\u03c3C \u03c7\u03c3C (\u03c7\u03c3C )T\n\u03c7\u03c3C\n\u03c7\u03c3C\n\n(4.37)\n\nand the fact that semidefiniteness is preserved under taking nonnegative linear combinations. This yields the stronger semidefinite programming bound\nmaximize q n * x0,0\n0,0\n\nsubject to (4.25), (4.26) and (4.36),\n\n(4.38)\n\nwhere\nM 00 :=\n\nX\n\nt,p\nt,p\n(x0,0\ni+j\u2212t\u2212p,0 \u2212 xi,j )Mi,j .\n\n(4.39)\n\ni,j,t,p\n\nObserve that condition (4.36) can be checked in time polynomial in n by Theorem 5. The\nbound obtained is as least as good as the one obtained from (4.32). Indeed, given a feasible\nsolution to (4.38), the matrix M := M 0 + M 00 satisfies: R(M ) is positive semidefinite.\nHence\n0,0 2\nq n trM 0 = 1T M 1 \u2265 trM 2 = (q n * x0,0\n).\n(4.40)\nThis implies that N 0 :=\n\n1\nM0\nx0,0\n0,0\n\nis a feasible solution to (4.32) with trN 0 \u2265 q n * x0,0\n0,0 . Hence\n\nthe optimum in(4.38) is at most the optimum in (4.32). In the binary case, this yields an\nimproved bound when n = 25 and d = 6. We did not find new improvements using this\nstrengthening in the range q = 3, n \u2264 16, q = 4, n \u2264 12 or q = 5, n \u2264 11.\n\n4.3\n\nComputational results\n\nThe semidefinite programming method was successfully applied to binary codes in [38]\nwhere a large number of upper bounds were improved. In this section we describe the\ncomputational results obtained in the nonbinary case. Apart from the binary case, tables\nof bounds on Aq (n, d) are maintained for q = 3, 4, 5. We have limited the computations to\n\n\f46\n\nCHAPTER 4. ERROR CORRECTING CODES\n\nthese three cases and computed the semidefinite programming bound for the range n \u2264 16,\nn \u2264 12 and n \u2264 11, respectively. The instances in which we found an improvement over\nthe best upper bound that was known, are summarized in Tables 4.1, 4.2 and 4.3 below.\nAs a reference we have used the tables given by Brouwer, H\u00e4m\u00e4l\u00e4inen, \u00d6sterg\u00e5rd and\nSloane [11] and by Bogdanova, Brouwer, Kapralov and \u00d6sterg\u00e5rd [5] for the cases q = 3\nand q = 4, along with subsequent improvements recorded on the website of Brouwer [9]\nand the table by Bogdanova and \u00d6sterg\u00e5rd [6] for the case q = 5.\nTable 4.1: New upper bounds on A3 (n, d)\n\nn d\n12 4\n13 4\n14 4\n15 4\n16 4\n12 5\n13 5\n14 5\n15 5\n13 6\n14 6\n15 6\n16 6\n14 7\n15 7\n16 7\n13 8\n15 8\n16 8\n14 9\n15 9\n16 10\n\nbest\nbest upper\nlower\nnew\nbound\nbound upper previously Delsarte\nknown bound\nknown\nbound\n4374\n6839\n7029\n7029\n8019 19270\n19682\n19683\n24057 54774\n59046\n59049\n72171 149585\n153527\n153527\n216513 424001\n434815\n434815\n729\n1557\n1562\n1562\n2187\n4078\n4163\n4163\n6561 10624\n10736\n10736\n6561 29213\n29524\n29524\n729\n1449\n1562\n1562\n2187\n3660\n3885\n4163\n2187\n9904\n10736\n10736\n6561 27356\n29524\n29524\n243\n805\n836\n836\n729\n2204\n2268\n2268\n729\n6235\n6643\n6643\n42\n95\n103\n103\n243\n685\n711\n712\n297\n1923\n2079\n2079\n31\n62\n66\n81\n81\n165\n166\n166\n54\n114\n117\n127\n\n\f4.3. COMPUTATIONAL RESULTS\n\nTable 4.2: New upper bounds on A4 (n, d)\n\nn d\n7 4\n8 4\n9 4\n10 4\n10 5\n10 6\n11 6\n12 6\n12 7\n\nbest\nbest upper\nlower\nnew\nbound\nbound upper previously Delsarte\nknown bound\nknown\nbound\n128\n169\n179\n179\n320\n611\n614\n614\n1024\n2314\n2340\n2340\n4096\n8951\n9360\n9362\n1024\n2045\n2048\n2145\n256\n496\n512\n512\n1024\n1780\n2048\n2048\n4096\n5864\n6241\n6241\n256\n1167\n1280\n1280\n\nTable 4.3: New upper bounds on A5 (n, d)\n\nn d\n7 4\n7 5\n8 5\n9 5\n10 5\n11 5\n10 6\n11 6\n\nbest\nbest upper\nlower\nnew\nbound\nbound upper previously Delsarte\nknown bound\nknown\nbound\n250\n545\n554\n625\n53\n108\n125\n125\n160\n485\n554\n625\n625\n2152\n2291\n2291\n3125\n9559\n9672\n9672\n15625 44379\n44642\n44642\n625\n1855\n1875\n1875\n3125\n8840\n9375\n9375\n\n47\n\n\f48\n\nCHAPTER 4. ERROR CORRECTING CODES\n\n\fChapter 5\nCovering codes\nConsider the following combinatorial problem. Given integers q, n and r, what is the\nsmallest number of Hamming spheres of radius r that cover the Hamming space consisting\nof all q-ary words of length n? This covering problem is the dual of the packing problem\nfrom the previous chapter. Apart from being an aesthetically appealing combinatorial\nproblem, it has several technical applications, for example to write-once memories and\ndata compression. Another, down to earth, application is to betting systems. In many\ncountries a popular game is played that involves forecasting the outcomes of a set of n\n(football)matches. Each match can end in three ways: a loss, a tie or a win for the hosting\nclub. The goal is to find an efficient set of bets that is guaranteed to have a forecast with\nat most one wrong outcome. For this reason the covering problem in the case q = 3 and\nr = 1 is widely known as the football pool problem, see [20].\nIn this chapter we show how the method of matrix cuts from Chapter 6 can be applied\nto obtain new lower bounds on the minimum size of covering codes. For a survey of results\non covering codes as well as many applications, the reader is referred to [14].\n\n5.1\n\nDefinitions and notation\n\nLet q \u2265 2 and n \u2265 1 be integers. Let E := qn be the Hamming space consisting of all words\nof length n over the alphabet q := {0, 1, . . . , q \u2212 1}. Recall that the Hamming distance\nd(u, v) of two words u, v \u2208 E is defined as the number of positions in which u and v\ndiffer. We define d(u, v) := (i, j, t) where i = d(u, 0), j = d(v, 0) and 2t = i + j \u2212 d(u, v).\nFor a word u \u2208 E, we denote the support of u by S(u) := {i | ui 6= 0}. Note that\n|S(u)| = d(u, 0), where 0 is the all-zero word. Denote by\nBr (u) := {v \u2208 E | d(u, v) \u2264 r} and\nSr (u) := {v \u2208 E | d(u, v) = r}\n\n(5.1)\n\nthe ball and the sphere respectively, with center u \u2208 E and radius r. They are generally\nreferred to as the Hamming sphere and the Hamming ring with center u and radius r in\nthe literature. The covering radius of a code C \u2286 E is the smallest integer r for which\n[\nBr (u) = E.\n(5.2)\nu\u2208C\n\n49\n\n\f50\n\nCHAPTER 5. COVERING CODES\n\nA code C \u2286 E is called an (n, K, q)r code if |C| = K and the covering radius of C is r.\nWe denote\nKq (n, r) := min{K | there exists an (n, K, q)r code}.\n(5.3)\nIn this chapter we will be interested in lower bounds on Kq (n, r).\n\n5.2\n\nMethod of linear inequalities\n\nAn important tool used in deriving lower bounds on Kq (n, r) is the method of linear\ninequalities. Let C \u2286 E be a code and denote\nAi (u) := |C \u2229 Si (u)|\n\n(5.4)\n\nfor u \u2208 E and i = 0, . . . , n. We consider linear inequalities of a code. That is, valid\ninequalities of the form\nn\nX\n\u03bbi Ai (u) \u2265 \u03b2 for all u \u2208 E,\n(5.5)\ni=0\n\nwhere \u03bb0 , . . . , \u03bbn \u2265 0 and \u03b2 > 0. Such a set of inequalities is denoted by (\u03bb0 , . . . , \u03bbn )\u03b2\nand leads to a lower bound on Kq (n, r) by the following proposition.\nProposition 27. If any (n, K, q)r code satisfies (\u03bb0 , . . . , \u03bbn )\u03b2 then\n\u03b2q n\n\u0001\n.\nn\ni\ni=0 \u03bbi i (q \u2212 1)\n\nK \u2265 Pn\n\n(5.6)\n\nProof. Summing 5.5 over all u \u2208 E we obtain\n\u03b2q n \u2264\n\nn\nXX\n\n\u03bbi Ai (u) =\n\nu\u2208E i=0\n\n=\n\nn\nX\n\n\u03bbi\n\nX\n\ni=0\n\nu\u2208E\n\nn\nX\n\n\u03bbi\n\nX\n\ni=0\n\n= |C|\n\nAi (u)\n\n(5.7)\n\n|Si (v)|\n\nv\u2208C\nn\nX\ni=0\n\n\u0012 \u0013\nn\n\u03bbi\n(q \u2212 1)i .\ni\n\nThe basic sphere covering inequalities\nr\nX\n\nAi (u) \u2265 1 for all u \u2208 E\n\n(5.8)\n\nqn\n\u0001\n.\nn\ni\n(q\n\u2212\n1)\ni\n\n(5.9)\n\ni=0\n\ngive the sphere covering bound\nKq (n, r) \u2265 Pr\n\ni=0\n\n\f5.2. METHOD OF LINEAR INEQUALITIES\n\n51\n\nMany other valid inequalities have been obtained, in particular in the binary case\n(q = 2), by studying the way the elements in Bs (u) can be covered for s = 1, 2, 3. In the\ncase s = 1 this gives the van Wee inequalities [43, 44]:\n\u0019\nr\u22121 \u0018\nX\nn+1\ni=0\n\n\u0018\n\nn+1\nAi (u) + Ar (u) + Ar+1 (u) \u2265\nr+1\nr+1\n\n\u0019\n(5.10)\n\nwhich improve upon the sphere covering bound whenever r + 1 does not divide n + 1.\nThe case s = 2 leads to the pair covering inequalities found by Johnson [23] and Zhang\n[46]:\nr\u22122\nX\nm0 Ai (u) + m1 (Ar\u22121 (u) + Ar (u)) + Ar+1 (u) + Ar+2 (u) \u2265 m0 ,\n(5.11)\ni=0\n\nwhere\n(n\u2212iR+1,R+2)\nm1 = maxi\u22652 F (n\u2212r+1,r+2)\u2212F\n,\ni\u22121\nm0\n= m1 + F (n \u2212 r + 1, r + 2),\n\n(5.12)\n\nand F (m, k) is the minimum number of k-sets needed to cover all pairs of an m-set. Other\ninequalities can be found in [47].\nStarting from a set of inequalities for a code, new inequalities can be obtained by\ntaking nonnegative linear combinations. Also by summing the inequality (\u03bb0 , . . . , \u03bbn )\u03b2\nover Si (u), we obtain the induced inequality (\u03bb00 , . . . , \u03bb0n )\u03b2 0 , where\nn\nX\n\n\u03bb0k\n\n:=\n\n\u03b20\n\n\u0012 \u0013\nn\n:=\n(q \u2212 1)i \u03b2,\ni\n\nk\n\u03bbj \u03b1i,j\n\n(5.13)\n\nj=0\n\nand\nk\n\u03b1i,j\n:= |{v | d(0, v) = i, d(v, u) = j}|\nk\nwhen d(0, u) = k. The numbers \u03b1i,j\ncan be expressed as\n\uf8f1P\n\u0001 n\u2212k\u0001\nk\n(q \u2212 1)i\u2212t (q \u2212 2)t\u2212p\n\uf8f4\np,t\n\uf8f4\n\uf8f2 t+p=k+i\u2212j t\u2212p,p i\u2212t\nk\n=\n\u03b1i,j\n\uf8f4\n\u0001\n\u0001\n\uf8f4\nk n\u2212k\n\uf8f3P t\n2t=k+i\u2212j\n\nt\n\ni\u2212t\n\n(5.14)\n\nif q \u2265 3\n(5.15)\nif q = 2.\n\nNote that the bound obtained from an induced inequality is equal to the bound obtained from the original one. Using the fact that the Ai (u) are integers, the inequality\n(\u03bb0 , . . . , \u03bbn )\u03b2 implies the inequality (d\u03bb0 e , . . . , d\u03bbn e) d\u03b2e. This way the van Wee inequalities, for example, can be derived from the sphere covering inequalities as follows. Starting\nfrom the sphere covering inequalities, we obtain\nr\u22121\nX\n(n + 1)Ai (u) + (r + 1)(Ar (u) + Ar+1 (u)) \u2265 n + 1 for every u \u2208 E\ni=0\n\n(5.16)\n\n\f52\n\nCHAPTER 5. COVERING CODES\n\nby summing the sphere covering inequalities over B1 (u). Then dividing by r + 1 and\nrounding up the coefficients, the van Wee inequalities are obtained.\nUsing this method, Habsieger and Plagne obtained many new lower bounds in the\nbinary and ternary case, by computer search see [19].\n\n5.3\n\nSemidefinite programming bounds\n\nThe bound from Proposition 27 may be viewed as a linear programming bound as follows.\nGiven \u03bb \u2208 Rn+1 and \u03b2 \u2208 R, define the polyhedron\nP\u03bb,\u03b2 := {x \u2208 RE |\n\nn\nX\n\n\u03bbi x(Si (u)) \u2265 \u03b2\n\nfor all u \u2208 E }.\n\n(5.17)\n\ni=0\n\nWe have the following proposition.\nProposition 28.\n\u03b2q n\n\u0001\n.\nn\ni\ni=0 \u03bbi i (q \u2212 1)\n\n(5.18)\n\n\u03c3(x) \u2208 P\u03bb,\u03b2\n\n(5.19)\n\nmin{1T x | x \u2208 P\u03bb,\u03b2 } = Pn\nProof. Observe that for any x \u2208 P\u03bb,\u03b2 also\nx :=\n\n1\n|Aut(q, n)|\n\nX\n\u03c3\u2208Aut(q,n)\n\nand x = c1 where 1T c1 = 1T x. Hence\nmin{1T x | x \u2208 P\u03bb,\u03b2 } = min{1T c1 | c1 \u2208 P\u03bb,\u03b2 }\nn\nX\nn\n= min{q c |\n\u03bbi c|Si (0)| \u2265 \u03b2}\n\n(5.20)\n\ni=0\n\n\u03b2\n\u0001\n}\nn\ni\ni=0 \u03bbi i (q \u2212 1)\n\n= min{q n c | c \u2265 Pn\n\n\u03b2q n\n\u0001\n.\nn\ni\ni=0 \u03bbi i (q \u2212 1)\n\n= Pn\n\nClearly, replacing P\u03bb,\u03b2 by P\u03bb,\u03b2 \u2229 {0, 1}E and considering the 0\u20131 optimization problem,\ncan be expected to give a better lower bound. In fact, when (\u03bb0 , . . . , \u03bbn )\u03b2 corresponds to\nthe sphere covering inequalities, this 0\u20131 program gives the exact value Kq (n, r)1 . This\nmotivates to replace the linear relaxation P\u03bb,\u03b2 by a tighter (semidefinite) relaxation using\nthe method of matrix cuts from Chapter 6. We will pursue this idea in the following.\n1\n\nIn general there may be solutions that do not have covering radius \u2264 r, for example when n = 3, r = 1,\nthe code {100, 010, 001} has covering radius 2 but satisfies the van Wee inequalities.\n\n\f5.3. SEMIDEFINITE PROGRAMMING BOUNDS\n\n5.3.1\n\n53\n\nThe first SDP bound\n\nIn this section we derive a semidefinite programming lower bound on Kq (n, r) with O(n)\nvariables and O(n) constraints. This bound is equal to the value obtained by minimizing\n1T x over N+ (P\u03bb,\u03b2 ), see Chapter 6.\nTo any code C \u2286 E, we associate the symmetric 0\u20131 matrix MC defined by:\n(\n1 if u, v \u2208 C,\n(MC )u,v :=\n(5.21)\n0 otherwise.\nLet C \u2286 E be a code. Define the matrix\nM := |Aut(q, n)|\u22121\n\nX\n\nM\u03c3C .\n\n(5.22)\n\n\u03c3\u2208Aut(q,n)\n\nBy construction, the matrix M is invariant under permutations of the rows and columns\nby any \u03c3 \u2208 Aut(q, n). Hence M is an element of the Bose\u2013Mesner algebra of the Hamming\nscheme and we write\nn\nX\nM=\nxi Ai ,\n(5.23)\ni=0\n\nwhere Ai is the i-th basis matrix of the Bose\u2013Mesner algebra and x0 , . . . , xn \u2208 R.\nProposition 29. The matrix M satisfies the following.\n(i)\n(ii)\n(iii)\n\ntrM = |C|,\nM \u2265 0 and R(M ) \u0017 0,\nIf C satisfies (\u03bb0 , . . . , \u03bbn )\u03b2, then\nMu \u2208 Mu,u P\u03bb,\u03b2 and diag(M ) \u2212 Mu \u2208 (1 \u2212 Mu,u )P\u03bb,\u03b2\nfor every u \u2208 E.\n\n(5.24)\n\nProof. Since M is a convex combination of the M\u03c3C , \u03c3 \u2208 Aut(q, n), it suffices to observe\nthat the contraints hold for each M\u03c3C . Clearly, trM\u03c3C = |C| and M\u03c3C \u2265 0. As R(M\u03c3C ) =\n\u0001 1 \u0001T\n1\n, R(M\u03c3C ) is positive semidefinite. Finally, for any u \u2208 E\n\u03c7\u03c3C \u03c7\u03c3C\n(M\u03c3C )u = (M\u03c3C )u,u \u03c7\u03c3C\n\n(5.25)\n\ndiag(M\u03c3C ) \u2212 (M\u03c3C )u = (1 \u2212 (M\u03c3C )u,u )\u03c7\u03c3C\n\n(5.26)\n\nand\nand hence (iii) follows from the fact that \u03c3C satisfies (\u03bb0 , . . . , \u03bbn )\u03b2 for every \u03c3 \u2208 Aut(q, n).\n\nBelow, we will make these constraints more explicit by expressing them in terms of\nthe variables xi .\n\n\f54\n\nCHAPTER 5. COVERING CODES\n\nProposition 30. R(M ) \u0017 0 is equivalent to\nn\nX\n\nxi Pj (i) \u2265 0 for every j = 0, . . . , n\n\n(5.27)\n\ni=0\n\nand\n\u0012\n\n\u0013\nqn P\nq n x\u00010\n\u0017 0.\nn\nn\ni\nq n x0\ni=0 xi i (q \u2212 1)\n\u0001\nP\nProof. Since trM = q n x0 and 1T M 1 = q n ni=0 xi ni (q \u2212 1)i , it follows from Proposition\n7 that R(M ) \u0017 0 if and only if M \u0017 0 and\n\u0013\n\u0012 n\nn\nq\nq\nx\n0\n\u0001\nPn\nn\ni\nq n x0\ni=0 xi i (q \u2212 1)\nPn\nis positive semidefinite. By\nProposition\n23\nit\nfollows\nthat\nM\n=\ni=0 xi Ai is positive\nPn\nsemidefinite if and only if i=0 xi Pj (i) \u2265 0 for every j = 0, . . . , n.\nP\nProposition 31. Let x = ni=0 xi \u03c7Si (0) \u2208 RE . Then the following are equivalent:\n(i)\n\nn\nX\n\n\u03bbi x(Si (u)) \u2265 \u03b2\n\nfor every u \u2208 E,\n\n(5.28)\n\ni=0\n\n(ii)\n\nn\nX\nj=0\n\nxj *\n\nn\nX\n\nk\n\u03bbi \u03b1i,j\n\u2265\u03b2\n\nfor every k = 0, . . . , n.\n\ni=0\n\nProof. If d(u, 0) = k then\nn\nX\n\n\u03bbi x(Si (u)) =\n\ni=0\n\nn\nX\n\n\u03bbi\n\ni=0\n\n=\n=\n\nn\nX\ni=0\nn\nX\nj=0\n\nn\nX\nX\nj=0\n\n\u03bbi\nxj\n\nn\nX\nj=0\nn\nX\n\nxj\n\n(5.29)\n\nv\u2208E\nd(0,v)=j\nd(u,v)=i\nk\n\u03b1i,j\nxj\n\nk\n\u03bbi \u03b1i,j\n.\n\ni=0\n\nProposition 32. The following are equivalent\n(i)\n\n(ii)\n\nMu \u2208 Mu,u P\u03bb,\u03b2 and\ndiag(M ) \u2212 Mu \u2208 (1 \u2212 Mu,u )P\u03bb,\u03b2\nfor every u \u2208 E,\nn\nn\nX\nX\nk\nxj *\n\u03bbi \u03b1i,j\n\u2265 x0 \u03b2\nj=0\nn\nX\n\ni=0\n\n(x0 \u2212 xj ) *\n\nj=0\n\nn\nX\n\nk\n\u03bbi \u03b1i,j\n\u2265 (1 \u2212 x0 )\u03b2\n\ni=0\n\nfor every k = 0, . . . , n.\n\n(5.30)\n\n(5.31)\n\n\f5.3. SEMIDEFINITE PROGRAMMING BOUNDS\n\n55\n\nProof. Directly from Proposition 31\nCollecting all the propositions, we obtain the following theorem.\nTheorem 7. If every code C \u2286 E with covering radius r satisfies (\u03bb0 , . . . , \u03bbn )\u03b2, we have\nKq (n, r) \u2265 min q n x0 ,\n\n(5.32)\n\nx\n\nwhere the minimum ranges over all x = (x0 , x1 , . . . , xn )T \u2208 Rn+1 satisfying\n(i)\n(ii)\n\nxk \u2265 0,\nn\nX\nxi Pk (i) \u2265 0,\n\n(5.33)\n\ni=0\n\n(iii)\n(iv)\n\nn\nX\n\nxi *\n\ni=0\nn\nX\n\nn\nX\n\nk\n\u03bbj \u03b1i,j\n\u2265 \u03b2x0 ,\n\nj=0\n\n(x0 \u2212 xi ) *\n\ni=0\n\nn\nX\n\nk\n\u03bbj \u03b1i,j\n\u2265 \u03b2(1 \u2212 x0 ),\n\nj=0\n\n\u0012\n(v)\n\nqn P\nq n x\u00010\nn\nn\nn\ni\nq x0\ni=0 xi i (q \u2212 1)\n\n\u0013\n\u00170\n\nfor all k = 0, . . . , n.\nProof.\nObserve that if we relax the semidefinite program by only requiring M to be positive\nsemidefinite instead of R(M ) (that is: delete condition (v)), we obtain for a linear program\nin O(n) variables and inequalities that is a lower bound on Kq (n, r).\n\n5.3.2\n\nThe second SDP bound\n\nIn this section we describe a stronger semidefinite programming relaxation that uses more\nof the symmetry of the Hamming space, but requires O(n3 ) variables in the binary case\nand O(n4 ) variables in the nonbinary case. In this section we will focus on the binary case.\nThe nonbinary case is very similar, although more complicated and it will be adressed in\nthe next section.\nRestricting ourselves to the binary case, we have E = {0, 1}n , the n-dimensional\nHamming cube. Let C \u2286 E be any code and define the matrices M 0 and M 00 by:\nX\nM 0 := |Aut(2, n)|\u22121\nM\u03c3C\n(5.34)\n\u03c3\u2208Aut(2,n)\n0\u2208\u03c3C\n\nM 00 := |Aut(2, n)|\u22121\n\nX\n\u03c3\u2208Aut(2,n)\n06\u2208\u03c3C\n\nM\u03c3C .\n\n\f56\n\nCHAPTER 5. COVERING CODES\n\nBy construction, the matrices M 0 and M 00 are invariant under permutations \u03c3 \u2208 Aut0 (2, n)\nof the rows and columns, that fix the element 0. Hence M 0 and M 00 are elements of the\nalgebra A2,n . Write\nX\nt\n,\n(5.35)\nM0 =\nxti,j Mi,j\n(i,j,t)\nt\nare the zero\u2013one basis matrices of A2,n . The matrix M 00 can be\nwhere the matrices Mi,j\nexpressed in terms of the coefficients xti,j as follows.\n\nProposition 33. The matrix M 00 satisfies\nX 0,0\nt\nM 00 =\n(xi+j\u22122t,0 \u2212 xti,j )Mi,j\n.\n\n(5.36)\n\n(i,j,t)\n\nProof. The matrix\nX\n\nM := M 0 + M 00 = |Aut(2, n)|\u22121\n\nM\u03c3C\n\n(5.37)\n\n\u03c3\u2208Aut(2,n)\n\nis invariant under permutation of the rows and columns by any permutation \u03c3 \u2208 Aut(2, n),\nand hence is an element of the Bose\u2013Mesner algebra, say\nX\nM=\nyk Ak .\n(5.38)\nk\n\nObserve that for any u \u2208 E with d(u, 0) = k, we have\nyk = (M )u,0 = (M 0 )u,0 = x0k,0 ,\n\n(5.39)\n\nsince (M 00 )u,0 = 0. Hence we have\nM 00 = M \u2212 M 0\nX\nX\nt\n=\nx0k,0 Ak \u2212\nxti,j Mi,j\nk\n\n(5.40)\n\n(i,j,t)\n\n=\n\nX\n\nX\n\nk\n\ni+j\u22122t=k\n\n=\n\nX\n\nt\nx0k,0 Mi,j\n\u2212\n\nX\n\nt\nxti,j Mi,j\n\n(i,j,t)\n\nt\n,\n(x0i+j\u22122t,0 \u2212 xti,j )Mi,j\n\n(i,j,t)\n\nwhich proves the proposition.\nProposition 34. The matrices\nM\nare positive semidefinite.\n\n0\n\n1 \u2212 x00,0 (diag(M 00 ))T\ndiag(M 00 )\nM 00\n\n\u0012\nand\n\n\u0013\n(5.41)\n\n\f5.3. SEMIDEFINITE PROGRAMMING BOUNDS\n\n57\n\n\u0001 1 \u0001T\n1\nProof. Clearly, R(M\u03c3C ) = \u03c7\u03c3C\nis positive semidefinite for each \u03c3 \u2208 Aut(2, n).\n\u03c7\u03c3C\n0 \u22121\n0\n0 \u22121\nHence R((x0,0 ) M ) and R((1 \u2212 x0,0 ) M 00 ) are positive semidefinite as they are convex\ncombinations of the R(M\u03c3C ). This implies the statement in the proposition.\nUsing the block diagonalisation of A2,n , Proposition 34 is equivalent to the following\nmatrices being positive semidefinite\n!n\u2212k\n!n\u2212k\nn\nn\nX\nX\nt\nt\nt\n0\nt\n\u03b2i,j,k xi,j\n,\n\u03b2i,j,k (xi+j\u22122t,0 \u2212 xi,j )\nt=0\n\nfor each k = 1, . . . ,\n\n2\n\nt=0\n\ni,j=k\n\n\u0004n\u0005\n\ni,j=k\n\n,\nn\nX\n\n!n\nt\n\u03b2i,j,0\nxti,j\n\n\u0012\n,\n\nt=0\n\n1 \u2212 x00,0 xT\nx\nL\n\n\u0013\n\u00170\n\ni,j=0\n\nwhere\nL :=\n\nn\nX\n\n!n\nt\n\u03b2i,j,0\n(x0i+j\u22122t,0 \u2212 xti,j )\n\nt=0\n\n,\ni,j=0\n\n\u0012 \u0013\nn\n0\n0\nxi := (x0,0 \u2212 xi,0 )\n, for i = 0, . . . , n.\ni\nProposition 35. The coefficients xti,j satisfy the following:\n2n x00,0 = |C|,\n\n(5.42)\n\nand for any i, j, t\n(i)\n\n0 \u2264 xti,j \u2264 xii,i ,\n\n(ii)\n\nx0i,0\nxti,j\n\n(iii)\n\n+ x0i+j\u22122t,0 \u2212 x00,0\n0\n= xti0 ,j 0 if (i, j, i\n0 0 0\n0\n0\n\n(5.43)\n\u2264\n\nxti,j\n\n\u2264\n\nx0i+j\u22122t,0 ,\n\n+ j \u2212 2t) is a permutation\nof (i , j , i + j \u2212 2t ).\n\nProof. Since for any u \u2208 E\n|{\u03c3 \u2208 Aut(2, n) | \u03c3u = 0}| = |Aut0 (2, n)|,\n\n(5.44)\n\nwe obtain\nx00,0 =\n\n|Aut0 (2, n)|\n|{\u03c3 \u2208 Aut(2, n) | 0 \u2208 \u03c3C}|\n= |C|\n= 2\u2212n |C|.\n|Aut(2, n)|\n|Aut(2, n)|\n\n(5.45)\n\nInequalities (i) and (ii) follow from the fact that (M 0 )u,u \u2265 (M 0 )u,v and (M 00 )u,u \u2265 (M 00 )u,v\nfor any u, v \u2208 E respectively. The truth of (iii) can be seen as follows. Let u, v \u2208 E be\nsuch that d(u, v) = (i, j, t) and let (i0 , j 0 , t0 ) be such that (i, j, i + j \u2212 2t) is a permutation\nof (i0 , j 0 , i0 + j 0 \u2212 2t0 ). It can be seen that in that case there is a \u03c3 \u2208 Aut(2, n) such that\n\u03c3{0, u, v} = {0, u0 , v0 } with d(u0 , v0 ) = (i0 , j 0 , t0 ). Hence\n0\n\nxti,j = (M 0 )u,v = (M 0 )u0 ,v0 = xti0 ,j 0 .\n\n(5.46)\n\n\f58\n\nCHAPTER 5. COVERING CODES\n(i,j,t)\n\nGiven two words u, v \u2208 E with d(u, v) = (i, j, t), we denote by \u03b1(i,j 0 ,t0 ),d the number\nof words w \u2208 E with d(u, w) = (i, j 0 , t0 ) and d(v, w) = d. This number is well-defined,\nand indeed we have the following proposition.\n(i,j,t)\n\nProposition 36. The numbers \u03b1(i,j 0 ,t0 ),d are given by\n\u0012\n\u0013\u0012\n\u0013\u0012 \u0013\u0012\n\u0013\nX\ni\u2212t j\u2212t\nt\nn+t\u2212i\u2212j\n(i,j,t)\n,\n\u03b1(i,j 0 ,t0 ),d =\na10\na01\na11\na00\na ,a ,a ,a\n00\n\n01\n\n10\n\n(5.47)\n\n11\n\nwhere the indices a00 , a01 , a10 and a11 range over the nonnegative integers that satisfy\nj 0 = a00 + a01 + a10 + a11\nt0 = a10 + a11\nd \u2212 j = a00 + a10 \u2212 a01 \u2212 a11 .\n\n(5.48)\n\nProof. Partition the support of the words w into four sets A00 , A01 , A10 and A11 as follows:\nA00\nA01\nA10\nA11\n\n:=\n:=\n:=\n:=\n\n{k\n{k\n{k\n{k\n\n\u2208 S(w) | uk\n\u2208 S(w) | uk\n\u2208 S(w) | uk\n\u2208 S(w) | uk\n\n= 0, vk\n= 0, vk\n6= 0, vk\n6= 0, vk\n\n= 0}\n6= 0}\n= 0}\n6= 0}.\n\n(5.49)\n\nIf we denote the sizes of these four sets by a00 , a01 , a10 and a11 respectively, we obtain the\nclaimed result by summing over all possible sets A00 , A01 , A10 and A11 .\nProposition 37. Let u \u2208 E be a word with d(u, 0) = i and let x \u2208 RE be such that xv\nonly depends on d(u, v), say xv = xti,j , when d(u, v) = (i, j, t). Then\nn\nX\n\n\u03bbd x(Sd (v)) \u2265 \u03b2\n\nfor all v \u2208 E\n\n(5.50)\n\nd=0\n\nis equivalent to\nX\nj 0 ,t0\n\n0\nxti,j 0\n\n*\n\nn\nX\n\n(i,j,t)\n\n\u03bbd \u03b1(i,j 0 ,t0 ),d \u2265 \u03b2\n\nfor all j, t.\n\n(5.51)\n\nd=0\n\nProof. Let v \u2208 E and let d(u, v) = (i, j, t). Then we have the following equalities.\nn\nX\n\n\u03bbd x(Sd (v)) =\n\nd=0\n\nn\nX\n\n=\n\n\u03bbd\n\nd=0\n\n=\n\nn\nX\nd=0\n\n=\n\nX\nj 0 ,t0\n\nxw\n\n(5.52)\n\nw\u2208E\nd(v,w)=d\n\nd=0\nn\nX\n\nX\n\n\u03bbd\n\n\u03bbd\n\nX\n\nX\n\nj 0 ,t0\n\nw\u2208E\nd(v,w)=d)\nd(u,w)=(i,j 0 ,t0 )\n\nX\n\n\u03b1(i,j 0 ,t0 ),d xti,j 0\n\n(i,j,t)\n\nxw\n\n0\n\nj 0 ,t0\n0\nxti,j 0\n\n*\n\nn\nX\nd=0\n\n(i,j,t)\n\n\u03bbd \u03b1(i,j 0 ,t0 ),d .\n\n\f5.4. NONBINARY CASE\n\n59\n\nProposition 38. If the code C satisfies the set of inequalities (\u03bb0 , . . . , \u03bbn )\u03b2, then the\nvariables xti,j satisfy the following set of inequalities. For every tuple (i, j, t)\nX\n\n0\n\n0\nxti,j 0 * \u03bbi,j,t\nj 0 ,t0 \u2265 xi,0 \u03b2\n\n(5.53)\n\nj 0 ,t0\n\nX\n\n0\n\n0\n0\n(x0j 0 ,0 \u2212 xti,j 0 ) * \u03bbi,j,t\nj 0 ,t0 \u2265 (x0,0 \u2212 xi,0 )\u03b2\n\nj 0 ,t0\n\nX\n\n0\n0\n(x0i+j\u22122t,0 \u2212 xti,j ) * \u03bbi,j,t\nj 0 ,t0 \u2265 (x0,0 \u2212 xi,0 )\u03b2\n\nj 0 ,t0\n\nX\n\n0\n\n0\n0\n(x00,0 \u2212 x0j 0 ,0 \u2212 x0i+j 0 \u22122t0 ,0 + xti,j 0 ) * \u03bbi,j,t\nj 0 ,t0 \u2265 (1 \u2212 2x0,0 + xi,0 )\u03b2,\n\nj 0 ,t0\n\nwhere we use the shorthand notation\n\u03bbi,j,t\nj 0 ,t0 :=\n\nn\nX\n\n(i,j,t)\n\n\u03bbd \u03b1(i,j 0 ,t0 ),d .\n\n(5.54)\n\nd=0\n\nProof. For any \u03c3 \u2208 Aut(2, n), the matrix M := M\u03c3C satisfies\nMu \u2208 Mu,u P\u03bb,\u03b2 ,\ndiag(M ) \u2212 Mu \u2208 (1 \u2212 Mu,u )P\u03bb,\u03b2\nfor every u \u2208 E.\n\n(5.55)\n\nThis implies that also the matrices x01 M 0 and 1\u2212x1 0 M 00 satisfy (5.55) as they are convex\n0,0\n0,0\ncombinations of the matrices M\u03c3C . Now using Proposition 37 gives a proof of the claim.\nThis leads to the following semidefinite programming bound on K2 (n, r).\nTheorem 8. If any code C \u2286 E with covering radius r satisfies (\u03bb0 , . . . , \u03bbn )\u03b2, we have\nK2 (n, r) \u2265 min 2n x00,0 ,\nx\n\n(5.56)\n\nwhere the minimum ranges over all x = (xti,j ) satisfying (5.42), (5.43) and (5.53).\nProof.\n\n5.4\n\nNonbinary case\n\nIn this section we consider the nonbinary case, that is q \u2265 3. The nonbinary case is very\nsimilar to the binary case described in the previous section and we will skip some of the\ndetails in the proofs.\n\n\f60\n\nCHAPTER 5. COVERING CODES\nAgain define the matrices M 0 and M 00 by\nX\n\nM 0 := |Aut(2, n)|\u22121\n\nM\u03c3C\n\n(5.57)\n\n\u03c3\u2208Aut(2,n)\n0\u2208\u03c3C\n\nX\n\nM 00 := |Aut(2, n)|\u22121\n\nM\u03c3C .\n\n\u03c3\u2208Aut(2,n)\n06\u2208\u03c3C\n\nThe matrices M 0 and M 00 are invariant under permutations of the rows and columns by\npermutations \u03c3 \u2208 Aut0 (q, n). Hence M 0 and M 00 are elements of the algebra Aq,n . We\nwrite\nX t,p t,p\nM0 =\nxi,j Mi,j\n(5.58)\n(i,j,t,p)\nt,p\nwhere the Mi,j\nare the 0\u20131 basis matrices of the algebra Aq,n . The matrix M 00 can be\nexpressed in terms of the coefficients xt,p\ni,j as follows.\n\nProposition 39. The matrix M 00 is given by\nX 0,0\nt,p\nM 00 =\n(xi+j\u2212t\u2212p,0 \u2212 xt,p\ni,j )Mi,j .\n\n(5.59)\n\n(i,j,t,p)\n\nProof. The matrix\nM := M 0 + M 00 = |Aut(q, n)|\u22121\n\nX\n\nM\u03c3C\n\n(5.60)\n\n\u03c3\u2208Aut(q,n)\n\nis invariant under permutation of the rows and columns by permutations \u03c3 \u2208 Aut(q, n),\nand hence is an element of the Bose\u2013Mesner algebra, say\nX\nyk Ak .\n(5.61)\nM=\nk\n\nNote that for any u \u2208 E with |S(u)| = k, we have\nyk = (M )u,0 = (M 0 )u,0 = x0,0\nk,0 ,\n\n(5.62)\n\nsince (M 00 )u,0 = 0. Hence we have\nM 00 = M \u2212 M 0\nX 0,0\nX t,p t,p\n=\nxk,0 Ak \u2212\nxi,j Mi,j\nk\n\n=\n=\n\n(i,j,t,p)\n\nX\n\nX\n\nk\n\ni+j\u2212t\u2212p=k\n\nX\n(i,j,t,p)\n\nwhich proves the proposition.\n\n0,0\nt,p\n(xk,0\n\u2212 xt,p\ni,j )Mi,j\n\nt,p\nt,p\n(x0,0\ni+j\u2212t\u2212p,0 \u2212 xi,j )Mi,j ,\n\n(5.63)\n\n\f5.4. NONBINARY CASE\n\n61\n\nProposition 40. The matrices\nM\n\n1 \u2212 x0,0\n(diag(M 00 ))T\n0,0\n00\ndiag(M )\nM 00\n\n\u0012\n\n0\n\nand\n\n\u0013\n(5.64)\n\nare positive semidefinite.\nUsing the block diagonalisation of Aq,n , the positive semidefiniteness of R and R0 is\nequivalent to:\nfor all a, k with 0 \u2264 a \u2264 k \u2264 n + a \u2212 k, k 6= 0 the matrices\n\n(5.65)\n\n!n+a\u2212k\nX\n\n\u03b1(i, j, t, p, a, k)xt,p\ni,j\n\nt,p\n\ni,j=k\n\nand\n!n+a\u2212k\nX\n\n\u03b1(i, j, t, p, a, k)(x0,0\ni+j\u2212t\u2212p,0\n\n\u2212\n\nxt,p\ni,j )\n\nt,p\n\ni,j=k\n\nare positive semidefinite, and\n!n\nX\n\u03b1(i, j, t, p, 0, 0)xt,p\ni,j\nt,p\n\ni,j=0\n\nand\n\u0012\n\u0013\nT\n1 \u2212 x0,0\n0,0 x\nx\nL\nare positive semidefinite, where\n!n\nL :=\n\nX\n\n0,0\n\u03b1(i, j, t, p, 0, 0)(xi+j\u2212t\u2212p,0\n\u2212 xt,p\ni,j )\n\nt,p\n\n,\ni,j=0\n\n\u0012 \u0013\nn\n0,0\ni,i\nxi := (x0,0 \u2212 xi,i )\n(q \u2212 1)i for i = 0, . . . , n.\ni\n\n(5.66)\n\nProposition 41. The coefficients xt,p\ni,j satisfy the following.\nq n x00,0 = |C|,\n\n(5.67)\n\nand for any i, j, t, p\n(i)\n(ii)\n(iii)\n\ni,i\n0 \u2264 xt,p\ni,j \u2264 xi,i ,\n0,0\n0,0\nt,p\n0,0\nx0,0\ni,0 + xi+j\u2212t\u2212p,0 \u2212 x0,0 \u2264 xi,j \u2264 xi+j\u2212t\u2212p,0 ,\n0\n\n0\n\nt ,p\nif (i, j, i + j \u2212 t \u2212 p) is a permutation of\nxt,p\ni,j = xi0 ,j 0\n0 0 0\n0\n(i , j , i + j \u2212 t0 \u2212 p0 ) and t \u2212 p=t0 \u2212 p0 .\n\n(5.68)\n\n\f62\n\nCHAPTER 5. COVERING CODES\n\nProposition 42. Let u, v \u2208 E be words with d(u, v) = (i, j, t, p) and let (i, j 0 , t0 , p0 ) and\n(i,j,t,p)\nd be given. Then the number \u03b1(i,j 0 ,t0 ,p0 ),d of words w \u2208 E with d(u, w) = (i, j 0 , t,0 p0 ) and\nd(v, w) = d is given by\n(i,j,t,p)\n\u03b1(i,j 0 ,t0 ,p0 ),d\n\nX \u0012 i \u2212 t \u0013\u0012j \u2212 t\u0013\u0012 p \u0013\u0012 t \u2212 p \u0013\n=\na1 , a2\nb1 , b2\nc1 , c2\nd1 , d2 , d3\na1 ,a2\nb1 ,b2\nc1 ,c2\nd1 ,d2 ,d3\ne\n\n\u0012\n\n\u0013\nn+t\u2212i\u2212j\n*\n(q \u2212 1)e (q \u2212 2)a2 +b2 +c2 (q \u2212 3)d3 , (5.69)\ne\nwhere the indices a1 , a2 , b1 , b2 , c1 , c2 , d1 , d2 , d3 and e range over the nonnegative integers\nthat satisfy\nj0\nt0\np0\nd\n\n=\n=\n=\n=\n\na1 + a2 + b 1 + b 2 + c 1 + c 2 + d 1 + d 2 + d 3 + e\na1 + a2 + c1 + c2 + d1 + d2 + d3\na1 + c1 + d1\na1 + a2 + e + j \u2212 b1 \u2212 c1 \u2212 d2 .\n\n(5.70)\n\nNote that in the case q = 3 we adopt the convention that 00 = 1.\nProof. Partition the support of the word w into sets A1 , A2 , B1 , B2 , C1 , C2 , D1 , D2 , D3\nand E as follows\nA1\nA2\nB1\nB2\nC1\nC2\nD1\nD2\nD3\nE\n\n:=\n:=\n:=\n:=\n:=\n:=\n:=\n:=\n:=\n:=\n\n{k\n{k\n{k\n{k\n{k\n{k\n{k\n{k\n{k\n{k\n\n\u2208 S(w) | uk\n\u2208 S(w) | uk\n\u2208 S(w) | uk\n\u2208 S(w) | uk\n\u2208 S(w) | uk\n\u2208 S(w) | uk\n\u2208 S(w) | uk\n\u2208 S(w) | uk\n\u2208 S(w) | uk\n\u2208 S(w) | uk\n\n6 0, vk\n=\n6= 0, vk\n= 0, vk\n= 0, vk\n6= 0, vk\n6= 0, vk\n6= 0, vk\n6= 0, vk\n6= 0, vk\n= 0, vk\n\n= 0, wk = uk }\n= 0, wk 6= uk }\n6= 0, wk = vk }\n6= 0, wk 6= vk }\n= uk , wk = uk }\n= uk , wk 6= uk }\n6= 0, uk , wk = uk }\n6= 0, uk , wk = vk }\n6= 0, uk , wk 6= uk , vk }\n= 0}.\n\n(5.71)\n\nIf we denote the sizes by a1 , a2 , b1 , b2 , c1 , c2 , d1 , d2 , d3 and e respectively, we obtain the\nproposition by summing over all possible sets A1 , A2 , B1 , B2 , C1 , C2 , D1 , D2 , D3 and\nE.\nProposition 43. Let u \u2208 E be a word with |S(u)| = i and let x \u2208 RE be such that xv\nonly depends on d(u, v), say xv = xt,p\ni,j , when d(u, v) = (i, j, t, p). Then\nn\nX\nd=0\n\n\u03bbd x(Sd (v)) \u2265 \u03b2\n\nfor all v \u2208 E\n\n(5.72)\n\n\f5.4. NONBINARY CASE\n\n63\n\nis equivalent to\n0 0\nxti,j,p0\n\nX\nj 0 ,t0 ,p0\n\n*\n\nn\nX\n\n(i,j,t,p)\n\n\u03bbd \u03b1(i,j 0 ,t0 ,p0 ),d \u2265 \u03b2\n\nfor every j, t, p.\n\n(5.73)\n\nd=0\n\nProof. Let v \u2208 E and let d(u, v) = (i, j, t, p). Then we have the following equality.\nn\nX\n\n\u03bbd x(Sd (v)) =\n\nn\nX\nX\n\nd=0\n\nd=0\n\n=\n\nn\nX\n\n(5.74)\n\nw\u2208E\nd(v,w)=d\n\nX\n\n\u03bbd\n\n0\n\n0\n\n(i,j,t,p)\n\nxti,j,p0 \u03b1(i,j 0 ,t0 ,p0 ),d\n\n(5.75)\n\nj 0 ,t0 ,p0\n\nd=0\n\nX\n\n=\n\nxw\n\n0 0\nxti,j,p0\n\nj 0 ,t0 ,p0\n\n*\n\nn\nX\n\n(i,j,t,p)\n\n\u03bbd \u03b1(i,j 0 ,t0 ,p0 ),d .\n\n(5.76)\n\nd=0\n\nProposition 44. If the code C satisfies the set of inequalities (\u03bb, \u03b2), then the variables\nxt,p\ni,j satisfy the following set of inequalities. For every tuple (i, j, t, p)\nX t0 ,p0 (i,j,t,p)\n(5.77)\nxi,j 0 * \u03bb(i,j 0 ,t0 ,p0 ) \u2265 x0,0\ni,0 \u03b2\nj 0 ,t0 ,p0\n\nX\n\n0\n\n0\n\n(i,j,t,p)\n\nt ,p\n0,0\n(xj0,0\n\u2265 (x0,0\n0 ,0 \u2212 xi,j 0 ) * \u03bb(i,j 0 ,t0 ,p0 )\n0,0 \u2212 xi,0 )\u03b2\n\nj 0 ,t0 ,p0\n\nX\n\n(i,j,t,p)\n\nt,p\n0,0\n0,0\n(x0,0\ni+j\u2212t\u2212p,0 \u2212 xi,j ) * \u03bb(i,j 0 ,t0 ,p0 ) \u2265 (x0,0 \u2212 xi,0 )\u03b2\n\nj 0 ,t0 ,p0\n\nX\n\n0\n\n0\n\n(i,j,t,p)\n\n0,0\n0,0\nt ,p\n0,0\n0,0\n(x0,0\n0,0 \u2212 xj 0 ,0 \u2212 xi+j 0 \u2212t0 \u2212p0 ,0 + xi,j 0 ) * \u03bb(i,j 0 ,t0 ,p0 ) \u2265 (1 \u2212 2x0,0 + xi,0 )\u03b2,\n\nj 0 ,t0 ,p0\n\nwhere we have used the shorthand notation\nn\nX\n(i,j,t,p)\n(i,j,t,p)\n\u03bb(i,j 0 ,t0 ,p0 ) :=\n\u03bbd \u03b1(i,j 0 ,t0 ,p0 ),d .\n\n(5.78)\n\nd=0\n\nProof. For any \u03c3 \u2208 Aut(q, n), the matrix M := M\u03c3C satisfies\nMu \u2208 Mu,u P\u03bb,\u03b2\n\nand diag(M ) \u2212 Mu \u2208 (1 \u2212 Mu,u )P\u03bb,\u03b2\n\nThis implies that also the matrices\n\n1\n0\nx0,0\n0,0 M\n\nand\n\n1\n1\u2212x0,0\n0,0\n\nfor every u \u2208 E.\n\n(5.79)\n\nsatisfy (5.79) as they are convex\n\ncombinations of the matrices M\u03c3C . Now using Proposition 43 gives a proof of the claim.\nTheorem 9. If any code C \u2286 E with covering radius r satisfies (\u03bb0 , . . . , \u03bbn )\u03b2, we have\nKq (n, r) \u2265 min q n x0,0\n0,0 ,\nx\n\nwhere the minimum ranges over all x = (xt,p\ni,j ) satisfying (5.65), (5.68) and (5.77).\nProof.\n\n(5.80)\n\n\f64\n\nCHAPTER 5. COVERING CODES\n\n5.5\n\nComputational results\n\nUsing the sphere covering inequalities, we obtained a number of explicit new upper bounds\nin the case q = 4 and q = 5. The results2 are shown in table 5.1 and 5.2 below. The\nupper bounds and previous lower bounds are taken from the website of G. K\u00e9ri ([24]),\nwho maintains an updated table of upper and lower bounds on covering codes. In the\nbinary and ternary case, no new lower bounds were found.\nTable 5.1: New lower bounds on K4 (n, R)\n\nn R\n7 1\n11 1\n9 2\n10 2\n11 2\n11 3\n9 4\n11 4\n11 5\n11 6\n\n2\n\nbest\nbest lower\nupper\nnew\nbound\nSphere\nbound\nlower previously covering\nknown bound\nknown\nbound\n1008\n762\n752\n745\n131072 123846\n123362\n123362\n1024\n748\n747\n745\n4096\n2412\n2408\n2405\n16128\n7942\n7929\n7929\n2048\n843\n842\n842\n64\n22\n21\n21\n512\n134\n133\n133\n128\n31\n30\n30\n32\n10\n9\n9\n\nIn the instance R = 1, n = 11 we were unable to solve the second SDP. The given number is the\nbound obtained from the first SDP.\n\n\f5.5. COMPUTATIONAL RESULTS\n\nTable 5.2: New lower bounds on K5 (n, R)\n\nn R\n7 1\n8 1\n9 1\n10 1\n11 2\n11 3\n11 4\n11 5\n11 6\n\nbest\nbest lower\nupper\nnew\nbound\nSphere\nbound\nlower previously covering\nknown bound\nknown\nbound\n3125\n2722\n2702\n2694\n15625 11945\n11887\n11838\n78125 53138\n52800\n52788\n390625 238993\n238200\n238186\n115000 52842\n52788\n52788\n21875\n4253\n4252\n4252\n3125\n510\n509\n509\n625\n87\n86\n86\n125\n21\n20\n20\n\n65\n\n\f66\n\nCHAPTER 5. COVERING CODES\n\n\fChapter 6\nMatrix cuts\nIn Chapter 4 we discussed the problem of finding good upper bounds on the maximum\nsize of a code with certain distance constraints. This is a special case of the general\nproblem to find bounds for the stability number of a graph. There exist general methods\nfor bounding the stability number. In this chapter we explore the relationship between\nthese general methods, when applied to codes, and the method from Chapter 4.\nRecall that for any symmetric matrix A \u2208 Rn\u00d7n , the matrix R(A) is defined by:\n\u0012\n\u0013\n1 aT\nR(A) :=\n,\n(6.1)\na A\nwhere a := diag(A) is the vector of diagonal elements of A. We will index the extra row\nand column of R(A) by 0. Denote the convex set of symmetric matrices\nRn := {A \u2208 Rn\u00d7n | R(A) \u0017 0}.\n\n(6.2)\n\nObserve that for A \u2208 Rn , the entries of A belong to [\u22121, 1]. Indeed, let i, j \u2208 {0, . . . , n}.\nThe principal submatrix\n\u0012\n\u0013\n1 Ai,i\n(6.3)\nAi,i Ai,i\nof R(A) indexed by 0 and i is positive semidefinite. This is equivalent to A2i,i \u2264 1 * Ai,i ,\nwhich implies that Ai,i \u2208 [0, 1]. For i \u2264 j the semidefiniteness of the principal submatrix\nof R(A) indexed by i and j\n\u0012\n\u0013\nAi,i Ai,j\n(6.4)\nAi,j Aj,j\nimplies that A2i,j \u2264 Ai,i Aj,j \u2264 1 and hence Ai,j \u2208 [\u22121, 1]. We define the projection p(M)\nof a set M \u2286 Rn and the lift l(K) of a set K \u2286 [0, 1]n by\np(M) := {diag(A) | A \u2208 M}\nl(K) := {A \u2208 Rn | diag(A) \u2208 K}.\n\n(6.5)\n\nBy the previous remarks we see that p(M) \u2286 [0, 1]n for M \u2286 Rn . Observe that for any\nK \u2286 [0, 1]n we have p(l(K)) = K. Indeed, if x \u2208 [0, 1]n , the matrix\n\u0012 \u0013\u0012 \u0013T\n1\n1\n(6.6)\n+ Diag(0, x1 \u2212 x21 , . . . , xn \u2212 x2n )\nx x\n67\n\n\f68\n\nCHAPTER 6. MATRIX CUTS\n\nis a positive semidefinite matrix of the form R(A) with diagonal x. Conversely, we only\nhave l(p(M)) \u2287 M for M \u2286 Rn .\nIn the following, the idea will be for a given convex set K, to find approximations of the\nconvex hull of the 0\u20131 points in K. The method will be to describe these approximations\nas the projection of set in the larger space Rn . The most prominent example is the\nso-called theta body of a graph, and the associated Lov\u00e1sz theta number.\n\n6.1\n\nThe theta body TH(G)\n\nLet G = (V, E) be a graph. We will assume that the vertex set is given by V = {1, . . . , n}.\nDefine the set M(G) by\nM(G) := {A \u2208 Rn | Ai,j = 0 if {i, j} \u2208 E}.\n\n(6.7)\n\nTH(G) := p(M(G)) = {diag(A) | A \u2208 M(G)}\n\n(6.8)\n\nThe projection\nwas defined in [17] and is referred to as the theta body of G. The number\n\u03b8(G) := max{1T x | x \u2208 TH(G)}\n\n(6.9)\n\nwas introduced by Lov\u00e1sz in [31] as an upper bound on the Shannon capacity of the\ngraph G. Although we will not be concerned with Shannon capacities, the following two\nproperties of \u03b8(G) are relevant to our discussion: the number \u03b8(G) can be approximated\nin polynomial time, and gives an (often close) upper bound on the stability number \u03b1(G).\nThis last fact follows since for every stable set S \u2286 V in the graph G, the matrix \u03c7S (\u03c7S )T\nbelongs to M(G). The theta body gives a good approximation of the stable set polytope.\nIn particular, for perfect graphs G, equality holds, implying that the stability number can\nbe calculated in polynomial time for perfect graphs.\nThe following strengthening of the theta body was given by Schrijver in [36]. Define\nM0 (G) := {A \u2208 Rn | A \u2265 0, Ai,j = 0 if {i, j} \u2208 E},\n\n(6.10)\n\nTH0 (G) := p(M0 (G)).\n\n(6.11)\n\n\u03b80 (G) := max{1T x | x \u2208 TH0 (G)}\n\n(6.12)\n\nand\nAgain the number\ngives an upper bound on \u03b1(G) and clearly \u03b80 (G) \u2264 \u03b8(G). We note that \u03b80 (G) can be\nalternatively defined by\nn\u00d7n\n\u03b80 (G) = max{ 1T A1 | A \u2208 R\u22650\n, trA = 1,\nAi,j = 0 when {i, j} \u2208 E},\n\n(6.13)\n\nand similarly for \u03b8(G). The equivalence of the two definitions follows from Propositions\n9 and 8 in Chapter 2 (see also [37]).\n\n\f6.1. THE THETA BODY TH(G)\n\n69\n\nIt was shown in [36] that for association schemes, the number \u03b80 (G) corresponds to the\nDelsarte bound. Given a scheme (X, R) with adjacency matrices I = A0 , A1 , . . . , An and\nM \u2286 {1, . . . , n} we are interested in the maximum size of an M -clique, that is a subset\nS \u2286 X with the property that (Ai )x,y = 0 for all x, y \u2208 X and i 6\u2208 M . Consider the graph\nG = (X, E), where E = {{x, y} | (Ai )x,y = 1 for some i 6\u2208 M }. Then the stable sets of G\nare precisely the M -cliques of the scheme (X, R). By (6.13), the upper bound \u03b80 (G) on\nthe maximum size of a stable set in G is given by\nX\u00d7X\nmax{1T A1 | A \u2208 R\u22650\n, trA = 1, Ai,j = 0 when {i, j} \u2208 E}.\n\n(6.14)\n\nWe will sketch a proof that this maximum equals the Delsarte bound. The proof consists\nof two ideas.\nProof. First, we may restrict the range of A in the program to the matrices in the Bose\u2013\nMesner algebra, without decreasing the maximum. Indeed, let \u03c0 denote the orthogonal\nprojection onto the Bose\u2013Mesner algebra (as a subspace of RX\u00d7X ) given by\nn\nX\nhA, Ei i\n* Ei ,\n\u03c0(A) :=\nhE\n,\nE\ni\ni\ni\ni=0\n\n(6.15)\n\nwhere the matrices E0 , . . . , En are the orthogonal idempotents of the scheme. Since the Ei\nhave eigenvalues 0 and 1, they are positive semidefinite. Hence for positive semidefinite\nA the projection \u03c0(A) is a nonnegative combination of positive semidefinite matrices,\nand hence again positive semidefinite. Furthermore, \u03c0 preserves the inner product with\nmatrices in the Bose-Mesner algebra. In particular\ntr\u03c0(A) = hI, \u03c0(A)i\n1 \u03c0(A)1 = hJ, \u03c0(A)i\nhAi , \u03c0(A)i\nhAi , \u03c0(A)i\nT\n\n=\n=\n=\n=\n\nhI, Ai = trA\nhJ, Ai = 1T A1\nhAi , Ai = 0 for i 6\u2208 M\nhAi , Ai \u2265 0 for i = 0, . . . , n.\n\nIt follows that \u03c0(A) is a feasible point with the same objective value as A.\nSecondly, writing\nn\nX\nei ,\nA=\nxi A\n\n(6.16)\n\n(6.17)\n\ni=0\n\nei := hAi , Ai i\u22121 Ai , the program becomes\nwhere A\nX\nX\nei \u0017 0}.\nmax{\nxi | x0 = 1, xi \u2265 0 for i \u2208 M ,\nxi A\ni\u2208M\n\n(6.18)\n\ni\u2208M\n\nei = Pn Qj,i hEj , Ej i\u22121 Ej , where Q is the second eigenmatrix of the scheme, the\nSince A\nj=0\npositive semidefinite constraint reduces to linear constraints\nX\nxi Qj,i \u2265 0 for j = 0, . . . , n.\n(6.19)\ni\u2208M\n\n\f70\n\nCHAPTER 6. MATRIX CUTS\n\nWe remark that when the Bose\u2013Mesner algebra is the centralizer algebra of its automorphism group, for example in the case of the Hamming schemes and the Johnson\nschemes, the orthogonal projection \u03c0 satisfies\nX\n\u03c3A,\n(6.20)\n\u03c0(A) = |\u0393|\u22121\n\u03c3\u2208\u0393\n\nwhere \u0393 denotes the automorphism group of the scheme.\n\n6.2\n\nMatrix cuts\n\nIn [32], Lov\u00e1sz and Schrijver introduced a general lift and project method for strengthening\napproximations of 0\u20131 polytopes. Given a convex body K contained in the unit cube\n[0, 1]n , a convex body N+ (K) is constructed such that\n(n)\n\nK \u2287 N+ (K) \u2287 N+ (N+ (K)) \u2287 * * * \u2287 N+ (K) = K \u2229 {0, 1}n .\n\n(6.21)\n\nAn important property of the operator N+ is that for a family K of convex bodies, if\none can optimize in polynomial time over K for each K \u2208 K, then also the optimization\nproblem over N+ (K) is polynomial time solvable for K \u2208 K. An important instance\nis when G = (V, E) is a perfect graph and K = FRAC(G) is the fractional stable set\npolytope of G. In that case one iteration of the N+ operator suffices to obtain the stable\nset polytope STAB(G) := FRAC(G) \u2229 {0, 1}V .\nWe start by describing the lift-and-project-method of Lov\u00e1sz and Schrijver and prove\nsome of the basic properties of the operator N+ . The idea is to lift a convex set K \u2286 [0, 1]n\nto a convex set in the space of symmetric positive semidefinite n \u00d7 n matrices and then\nto project it back into [0, 1]n .\nFor M \u2286 Rn , define the set N (M) by\nN (M) := {A \u2208 Rm | for i = 1, . . . , n there are U, V \u2208 M\nsuch that Ai = Ai,i * diag(U ),\ndiag(A) \u2212 Ai = (1 \u2212 Ai,i )diag(V )}.\n\n(6.22)\n\nThe operator N+ is now defined as\nN+ (K) := p(N (l(K))).\n\n(6.23)\n\nN+ (K) \u2286 [0, 1]n ,\n\n(6.24)\n\nClearly\nsince if R(A) is positive semidefinite diag(A) \u2208 [0, 1]n as we have seen before. Furthermore,\nwe have:\nN+ (K) \u2286 K.\n(6.25)\nIndeed, if A \u2208 N (l(K)), then for any i = 1, . . . , n we have:\ndiag(A) = Ai + (diag(A) \u2212 Ai ) \u2208 Ai,i * K + (1 \u2212 Ai,i ) * K\n\n(6.26)\n\n\f6.2. MATRIX CUTS\n\n71\n\nand hence diag(A) \u2208 K, since Ai,i \u2208 [0, 1]. Note that this argument shows that in fact\nN+ (K) \u2286 conv.hull{x \u2208 K | xi \u2208 {0, 1}}\n\n(6.27)\n\nfor i = 1, . . . n since for each i we have\nAi \u2208 Ai,i * {x \u2208 K | xi = 1},\n\ndiag(A) \u2212 Ai \u2208 (1 \u2212 Ai,i ) * {x \u2208 K | xi = 0}.\n\n(6.28)\n\nBy induction it then follows that\nN+n (K) \u2286 {0, 1}n \u2229 K.\n\n(6.29)\n\nOn the other hand, N+ does not cut off any integer points:\n{0, 1}n \u2229 K \u2286 N+ (K),\n\n(6.30)\n\nsince for any x \u2208 {0, 1}n \u2229 K the matrix xxT belongs to N (l(K)). The operator N+ was\nintroduced in [32], see also [37].\nLet G = (V, E) be a graph and let FRAC(G) denote the fractional stable set polytope\nof G, that is:\nFRAC(G) := {x \u2208 RV | x \u2265 0, xi + xj \u2264 1 for any edge {i, j} \u2208 E}.\n\n(6.31)\n\nWe observe that N+ (FRAC(G)) is contained in the modified theta body TH0 (G). Indeed,\nif A \u2208 N (l(FRAC(G))), then Ai,j = 0 for any edge {i, j} since Ai \u2208 Ai,i *FRAC(G) implies\nthat\nAi,i + Ai,j \u2264 Ai,i * 1.\n(6.32)\ne given by\nWe will also consider the operator N\ne (M) := {A \u2208 Rn | for i = 1, . . . , n there are\nN\nU \u2208 Ai,i M, V \u2208 (1 \u2212 Ai,i )M\nsuch that Ui,i = Ai,i and A = U + V }.\n\n(6.33)\n\ne (M) \u2286 N (M) for any M \u2286 Rn . We show that any x \u2208 p(M) \u2229 {0, 1}n belongs\nClearly N\nto p(N (M)). Let A \u2208 M have diagonal x \u2208 {0, 1}n . Then for i = 1, . . . , n we have\nA = Ai,i U + (1 \u2212 Ai,i )V , where we take U = A, V = 0 if Ai,i = 1 and U = 0, V = A if\ne (M) can alternatively be described by:\nAi,i = 0. The set N\ne (M) = {A | A \u2208 conv.hull{M \u2208 M | Mi,i \u2208 {0, 1}} for each i = 1, . . . , n}.\nN\n\n(6.34)\n\ne (M). Let i \u2208 {1, . . . , n} and let U, V be as in the definition. Observe\nProof. Let A \u2208 N\nthat R(A) is positive semidefinite, since A = U + V \u2208 Ai,i M + (1 \u2212 Ai,i )M = M. We\nprove that\nAi = diag(U ) and diag(A) \u2212 Ai = diag(V ).\n(6.35)\nIf Ai,i = 0 we have Ai = 0 since A is positive semidefinite, and (6.35) follows. Hence we\nmay assume that Ai,i > 0. Notice that Vi,i = 0 and hence Vi = 0. Since A\u22121\ni,i Ui,i = 1 it\n\u22121\nfollows from the positive semidefiniteness of R(Ai,i U ) that Ui = diag(U ). Hence Ai =\nUi + Vi = diag(U ) and diag(A) \u2212 Ai = diag(U ) Ui + diag(V ) + Vi = diag(V ).\n\n\f72\n\n6.3\n\nCHAPTER 6. MATRIX CUTS\n\nBounds for codes using matrix cuts\n\nFix integers 1 \u2264 d \u2264 n and q \u2265 2, and fix an alphabet q = {0, 1, . . . , q \u22121}. The Hamming\ndistance d(x, y) of two words x and y is defined as the number of positions in which x and\ny differ. Let G = (V, E) be the graph with V = qn , where two different words x, y \u2208 V\nare joined by an edge if x and y differ in at most d \u2212 1 position. The stable sets in G\nare precisely the q-ary codes of length n and minimum distance at most d. The stability\nnumber of G equals Aq (n, d). Define\nM0 := {A \u2208 RV | A \u2265 0, Ax,y = 0 if {x, y} \u2208 E},\n\n(6.36)\n\nTH0 (G) := p(M0 ) = {diag(A) | A \u2208 M0 }\n\n(6.37)\n\nand let\ndenote the modified theta body of G. Maximizing the all-one vector over TH0 (G) gives\nan upper bound on Aq (n, d), which we have seen, equals the Delsarte bound. A tighter\nupper bound can be found by maximizing the all-one vector over the smaller convex set\nN+ (TH0 (G)):\nmax{trA | A \u2208 N (M)}.\n(6.38)\nUsing the symmetries of the graph G, this can be made more explicit as follows.\nDenote by Aut(q, n) the set of permutations of qn that preserve the Hamming distance. It is not hard to see that Aut(q, n) consists of the permutations of qn obtained\nby permuting the n coordinates followed by independently permuting the alphabet q at\neach of the n coordinates. The group Aut(q, n) acts on the set of V \u00d7 V matrices in the\nfollowing way. For \u03c3 \u2208 Aut(q, n) and A \u2208 RV \u00d7V define \u03c3(A) by\n(\u03c3(A))\u03c3x,\u03c3y = Ax,y .\n\n(6.39)\n\nThe matrices in RV \u00d7V that are invariant under this action of Aut(q, n) are precisely the\nadjacency matrices A0 , A1 , . . . , An of the Hamming scheme H(n, q) defined by\n(\n1 if d(x, y) = i,\n(Ai )x,y :\n(6.40)\n0 otherwise,\nfor i = 0, 1, . . . , n and the Bose\u2013Mesner algebra of the Hamming scheme.\nIn the following calculations, it will be convenient do define for a square matrix A and\na positive real number c the matrix R(c; A) by\n\u0012\n\u0013\nc\n(diag(A))T\nR(c; A) :=\n.\n(6.41)\ndiag(A)\nA\nObserve that R(1; A) = R(A) and R(c; A) is positive semidefinite if and only if R(c\u22121 A) is\npositive semidefinite. Since G is invariant under the permutations \u03c3 \u2208 Aut(q, n), also M0 ,\nN (M0 ) and N+ (TH0 (G)) are invariant under the action of Aut(q, n). Hence if A \u2208 N (M0 )\nmaximizes trM over all M \u2208 N (M0 ), also\n1\n|Aut(q, n)|\n\nX\n\u03c3\u2208Aut(q,n)\n\n\u03c3(A) \u2208 N (M0 )\n\n(6.42)\n\n\f6.3. BOUNDS FOR CODES USING MATRIX CUTS\n\n73\n\nis a maximizer. Hence the maximum in (6.38) is equal to\nmax{trA | A \u2208 N (M0 ) is in the Bose\u2013Mesner algebra}.\n\n(6.43)\n\nIf A is a matrix in the Bose-Mesner algebra, all rows of A are equal up to permuting\nby elements of Aut(q, n). Hence since M0 is invariant under these permutations, the\nmaximum is equal to\nn\nX\nn\nmax{q * x0 |R(\nxi Ai ) is positive semidefinite\ni=0\n\nand there exist U \u2208 x0 * M0 and V \u2208 (1 \u2212 x0 ) * M0 such that\nUu,u = xi if d(u, 0) = i and\nVu,u = x0 \u2212 xi if d(u, 0) = i}.\n\n(6.44)\n\nNote that if U and V are as in (6.44), and \u03c3 \u2208 Aut(q, n) fixes the zero word, then \u03c3(U )\nand \u03c3(V ) satisfy the same constraints. Hence U may be replaced by\nX\n1\n\u03c3(U )\n(6.45)\n|Aut0 (q, n)|\n\u03c3\u2208Aut0 (q,n)\n\nand similarly for V . Here Aut0 (q, n) denotes the set {\u03c3 \u2208 Aut(q, n) | \u03c3(0) = 0}. Hence\nwe may impose that U and V are elements of the Terwilliger algebra without changing\nthe maximum. We obtain\nn\nX\nn\nmax{q * x0 |R(\nxi Ai ) is positive semidefinite,\ni=0\n\nR(\n\nX\n\nt,p\nt,p\nMi,j\n), R(\nyi,j\n\nX\n\nt,p\nt,p\nzi,j\nMi,j\n) are positive semidefinite,\n\n(6.46)\n\ni,j,t,p\n\ni,j,t,p\n\ni,i\ni,i\nxi = x0 yi,i\n, x0 \u2212 xi = (1 \u2212 x0 )zi,i\n(i = 0, . . . , n),\nt,p t,p\nyi,j\n, zi,j \u2265 0,\nt,p\nt,p\nyi,j = zi,j\n= 0 if i + j \u2212 t \u2212 p \u2208 {1, . . . , d \u2212 1}}.\ni,i\nSince xi = x0 * yi,i\nwe can eliminate the variables xi from this program by substituting\nt,p\nt,p\nyei,j\n:= x0 * yi,j\nt,p\nzei,j\n\n:= (1 \u2212\n\n(6.47)\n\nt,p\nx0 )zi,j\n.\n\nWe obtain the following semidefinite program (where we have dropped all the tilde's from\nthe variables):\nn\nX\n0,0\ni,i\nn\nmax{q * y0,0 |R(\nyi,i\nAi ) is positive semidefinite,\ni=0\n0,0\nR(y0,0\n;\n\nX\n\nt,p\nt,p\nyi,j\nMi,j\n), R(1\n\n\u2212\n\n0,0\ny0,0\n;\n\ni,j,t,p\n\nt,p\nt,p\nzi,j\nMi,j\n)\u00170\n\ni,j\n\n0,0\ni,i\ni,i\ny0,0\n\u2212 yi,i\n= zi,i\nt,p t,p\nyi,j\n, zi,j \u2265 0,\nt,p\nt,p\nyi,j = zi,j\n=0\n\nt,p\nX\n\n(i = 0, . . . , n),\n\nif i + j \u2212 t \u2212 p \u2208 {1, . . . , d \u2212 1}}.\n\n(6.48)\n\n\f74\n\nCHAPTER 6. MATRIX CUTS\n\ne in stead of N we arrive in a similar fashion at the\nIf we use the stronger operator N\nprogram\nX t,p t,p\nX t,p t,p\nmax{q n * x0 |R(x0 ;\nyi,j Mi,j ), R(1 \u2212 x0 ;\nzi,j Mi,j ) \u0017 0,\ni,j,t,p\ni,j,t,p\n0,0\nt,p\nt,p\ny0,0 = x0 , yi,j + zi,j = xi+j\u2212t\u2212p\nt,p t,p\nt,p\nt,p\nyi,j\n, zi,j \u2265 0, yi,j\n= zi,j\n= 0 if i + j\n\n(6.49)\n\u2212 t \u2212 p \u2208 {1, . . . , d \u2212 1}}\n\n0,0\n0,0\n0,0\n0,0\n= 0. Since for each feasible solution\n= x0 that z0,0\n= x0 and y0,0\n+ z0,0\nit follows from y0,0\nthe matrix\nt,p\nX\nt,p\nt,p\nzi,j\nMi,j\n(6.50)\nM :=\ni,j\n0,0\n0,0\nis positive semidefinite, it follows from M0,0 = z0,0\n= 0 that 0 = Mu,0 = zi,0\nwhen u\nhas weight i. Hence\n0,0\n0,0\n0,0\nxi = yi,0\n+ zi,0\n= yi,0\n.\n(6.51)\nt,p\nThis implies that we can eliminate the variables xi and zi,j\nby using\n0,0\nxi = yi,0\n,\n\nt,p\n0,0\nt,p\nzi,j\n= yi+j\u2212t\u2212p,0\n\u2212 yi,j\n\n(6.52)\n\nfor all i, j, t, p. We obtain the following semidefinite program:\n0,0\n0,0\nmax{q n * y0,0\n|R(y0,0\n;\n\nX\n\nX\n\nt,p\nt,p\n0,0\nyi,j\nMi,j\n), R(1 \u2212 y0,0\n;\n\ni,j,t,p\nt,p 0,0\nt,p\nyi,j , yi+j\u2212t\u2212p,0 \u2212 yi,j\n\u2265\nt,p\n0,0\nyi,j = yi+j\u2212t\u2212p,0 = 0 if\n\n0,0\nt,p\nt,p\n(yi+j\u2212t\u2212p,0\n\u2212 yi,j\n)Mi,j\n) \u0017 0,\n\ni,j,t,p\n\n(6.53)\n\n0,\ni + j \u2212 t \u2212 p \u2208 {1, . . . , d \u2212 1}}\n\nThis program may be further simplified by observing that for a matrix A with A1,1 = 1\nR(A) \u0017 0 if and only if A \u0017 0, A1 = diag(A).\n\n(6.54)\n\nWe finally obtain\n0,0\nmax{q n * y0,0\n|\n\nX\n\nt,p\nt,p\n0,0\nyi,j\nMi,j\n, R(1 \u2212 y0,0\n;\n\ni,j,t,p\nt,p 0,0\nt,p\nyi,j\n, yi+j\u2212t\u2212p,0 \u2212 yi,j\n\u2265\n0,0\ni,i\nyi,0 = yi,i ,\nt,p\n0,0\nyi,j\n= yi+j\u2212t\u2212p,0\n= 0 if\n\nX\n\n0,0\nt,p\nt,p\n(yi+j\u2212t\u2212p,0\n\u2212 yi,j\n)Mi,j\n) \u0017 0,\n\ni,j,t,p\n\n0,\n\n(6.55)\n\ni + j \u2212 t \u2212 p \u2208 {1, . . . , d \u2212 1}}\n\nThis bound is very similar to the bound (4.38) derived in Chapter 4, that is to say the\nimpoved version of Schrijver's bound given by Laurent. The main difference is that in\n(6.55) the symmetry conditions\n0\n\n0\n\nt,p\nyi,j\n= yit0 ,j,p0\n\nwhen t \u2212 p = t0 \u2212 p0 and (i, j, i + j \u2212 t \u2212 p) is a\npermutation of (i0 , j 0 , i0 + j 0 \u2212 t0 \u2212 p0 )\n\n(6.56)\n\nare lacking. It can be seen from the computational results in given in the next section,\nthat these conditions make a huge difference in the resulting bound.\n\n\f6.4. COMPUTATIONAL RESULTS\n\n6.4\n\n75\n\nComputational results\n\nIn this section we give some computational results on the different bounds we obtain and\ncompare them to the bound proposed by Schrijver (see [38], [16]) with the improvement of\nLaurent. That is, the bound obtained from (4.38). Each of the bounds can be computed\nin polynomial time in n by block diagonalising the Terwilliger algebra of the Hamming\nscheme for each q and n.\nFrom the tables below it follows that we can have the strict inequality\ne (M) \u2282 N (M).\nN\n\n(6.57)\n\nTable 6.1: Bounds on A3 (n, d)\n\nn d\n6 3\n7 3\n8 3\n9 3\n7 4\n8 4\n9 4\n10 4\n11 4\n12 4\n6 5\n7 5\n8 5\n9 5\n10 5\n11 5\n12 5\n7 6\n9 7\n10 7\n11 7\n12 7\n\nbest best upper\nlower\nbound\nbound previously\nknown\nknown\n38\n38\n99\n111\n243\n333\n729\n937\n33\n33\n99\n99\n243\n297\n729\n891\n1458\n2561\n4374\n7029\n4\n4\n10\n10\n27\n27\n81\n81\n243\n243\n729\n729\n729\n1562\n3\n3\n6\n6\n14\n14\n36\n36\n54\n108\n\nDelsarte\nbound\n48\n145\n340\n937\n48\n139\n340\n937\n2811\n7029\n5\n15\n41\n90\n243\n729\n1562\n4\n7\n21\n63\n138\n\nbound bound bound\nfrom\nfrom\nfrom\n(6.48) (6.55) (4.38)\n48\n48\n46\n145\n144\n136\n340\n340\n340\n937\n937\n937\n48\n48\n44\n139\n139\n121\n340\n339\n324\n937\n937\n914\n2811\n2805\n2583\n7029\n7029\n6839\n5\n4\n4\n15\n14\n13\n41\n41\n33\n90\n90\n86\n243\n243\n243\n729\n729\n729\n1562\n1562\n1557\n4\n4\n4\n7\n7\n7\n21\n21\n21\n63\n62\n49\n138\n138\n131\n\nP\nn\nRemark: We calculate the Delsarte bound by maximizing\nx\n*q\n(the\ntrace\nof\n0\ni xi Mi )\nP\nunder the condition that the xi are nonnegative and R( i xi Mi ) is positive semidefinite.\nThis turns out\na more stable semidefinite program than setting x0 = 1 and\n\u0001\nP to give\nmaximizing i xi ni (q \u2212 1)i .\n\n\f76\n\nCHAPTER 6. MATRIX CUTS\nTable 6.2: Bounds on A4 (n, d)\n\nn d\n7 4\n8 4\n9 4\n10 4\n7 5\n8 5\n9 5\n10 5\n10 6\n11 6\n12 6\n10 7\n12 7\n\nbest best upper\nlower\nbound\nbound previously\nknown\nknown\n128\n179\n320\n614\n1024\n2340\n4096\n9360\n32\n32\n70\n128\n256\n512\n1024\n2048\n256\n512\n1024\n2048\n4096\n6241\n40\n80\n256\n1280\n\nDelsarte\nbound\n179\n614\n2340\n9362\n40\n160\n614\n2145\n512\n2048\n6241\n112\n1280\n\nbound bound bound\nfrom\nfrom\nfrom\n(6.48) (6.55) (4.38)\n179\n179\n169\n614\n614\n611\n2340\n2340\n2314\n9362\n9360\n8951\n40\n40\n39\n160\n160\n147\n614\n614\n579\n2145\n2145\n2045\n512\n511\n496\n2048\n2047\n1780\n6241\n6241\n5864\n112\n111\n106\n1280\n1280\n1167\n\nTable 6.3: Bounds on A5 (n, d)\n\nn d\n6 4\n7 4\n8 4\n9 4\n10 4\n11 4\n7 5\n8 5\n9 5\n10 5\n11 5\n8 6\n9 6\n10 6\n11 6\n11 9\n\nbest best upper\nlower\nbound\nbound previously\nknown\nknown\n125\n125\n250\n554\n1125\n2291\n3750\n9672\n15625\n44642\n78125\n217013\n53\n125\n160\n554\n625\n2291\n3125\n9672\n15625\n44642\n45\n75\n135\n375\n625\n1875\n3125\n9375\n25\n35\n\nDelsarte\nbound\n125\n625\n2291\n9672\n44642\n217013\n125\n625\n2291\n9672\n44642\n75\n375\n1875\n9375\n45\n\nbound bound bound\nfrom\nfrom\nfrom\n(6.48) (6.55) (4.38)\n125\n125\n125\n625\n623\n545\n2291\n2291\n2291\n9672\n9672\n9672\n44642 44642 44642\n217013 217013 217013\n125\n124\n108\n625\n623\n485\n2291\n2291\n2152\n9672\n9672\n9559\n44642 44642 44379\n75\n75\n75\n375\n375\n375\n1875\n1875\n1855\n9375\n9375\n8840\n45\n45\n43\n\n\fChapter 7\nFurther discussion\nIn this chapter, we present some further observations, and notes related to the methods\nfrom previous chapters.\n\n7.1\n\nBounds for affine caps\n\nLet AG(k, q) be the k-dimensional affine space over the field GFq . A subset A \u2286 AG(k, q)\nis called an affine cap if\u0001 no three elements of A are on an affine line, that is, any three\ndifferent vectors in { a1 | a \u2208 A} are linearly independent. We denote by Ck (q) the\nmaximum cardinality of an affine cap in AG(k, q).\nThe effectiveness of the semidefinite programming approach for error correcting codes,\nsuggested that we could, more generally, find good bounds for the size of a code where we\nforbid the occurence of triples of code words in some prescribed configuration. Indeed the\nvariables xt,p\ni,j in the semidefinite program correspond exactly to the number of tripes in a\ncode, for each equivalence class under automorphisms of the Hamming space. One may\nbe led to wonder if setting those variables that correspond to forbidden configurations to\nzero, would yield good upper bounds in general. This is an appealing idea. Unfortunately,\nit turned out to be false in general.\nA prominent structure that might be approached this way are affine caps over the field\nof three elements. The only known values are C1 (3) = 2, C2 (3) = 4, C3 (3) = 9, C4 (3) = 20\nwas shown. A code A \u2286 AG(k, 3)\nand C5 (3) = 45. In [4] the general bound Ck (3) \u2264 3k k+1\nk2\nis an affine cap if and only if for any three elements u, v, w \u2208 A we have d(u, v, w) 6=\n(i, i, i, 0) for every i = 1, . . . , k. Recall that\nd(u, v, w) := (i, j, t, p), where\ni := d(u, v),\nj := d(u, w),\nt := |{i | ui 6= vi and ui 6= wi }|,\np := |{i | ui 6= vi = wi }|.\nConsider the following semidefinite program.\n77\n\n(7.1)\n\n\f78\n\nCHAPTER 7. FURTHER DISCUSSION\n\nn \u0012 \u0013\nX\nn\n\nmaximize\n\ni=0\n\n(i)\n(ii)\n(iii)\n(iv)\n(v)\n\nx0,0\n0,0\n\ni\n\n2i x0,0\ni,0\n\nsubject to\n\n(7.2)\n\n=1\n\n0,0\n0 \u2264 xt,p\ni,j \u2264 xi,0\n0\n\n0\n\nt ,p\n0\n0\nxt,p\ni,j = xi0 ,j 0 if t \u2212 p = t \u2212 p and\n(i, j, i + j \u2212 t \u2212 p) is a permutation of (i0 , j 0 , i0 + j 0 \u2212 t0 \u2212 p0 )\nxi,0\ni,i = 0 for i = 1, . . . , n.\nX t,p t,p X 0,0\nt,p\nxi,j Mi,j ,\n(xi+j\u2212t\u2212p,0 \u2212 xt,p\ni,j )Mi,j are positive semidefinite.\ni,j,t,p\n\ni,j,t,p\n\nClearly, this gives an upper bound on Cn (3). We have the following result.\nProposition 45. The maximum in (7.2) equals 1 +\n\n3n \u22121\n.\n2\n\nProof. Setting the variables xt,p\ni,j as follows:\n\nxt,p\ni,j :=\n\n\uf8f1\n1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f21\n2\n\n\uf8f4\n0\n\uf8f4\n\uf8f4\n\uf8f31\n4\n\nif i = j = t = p = 0,\nif i = j = t = p 6= 0 or exactly one of i, j is zero,\nif i = j = t 6= 0 and p = 0,\notherwise\n\n(7.3)\n\nn\n\ngives a feasible solution with objective value equal to 1 + 3 2\u22121 .\nother hand, let any feasible solution be given. Then the matrix M 0 :=\nP On the\nt,p\nt,p\ni,j,t,p xi,j Mi,j is positive semidefinite. Hence for any nonzero word u the 3 \u00d7 3 principal submatrix indexed by the words 0, u, \u2212u is positive semidefinite and equals\n\uf8eb\n\uf8f6\n1\nMu,u M\u2212u,\u2212u\n\uf8ed Mu,u Mu,u\n0 \uf8f8\n(7.4)\nM\u2212u,\u2212u\n0\nM\u2212u,\u2212u .\n2\n2\nThis implies that (Mu,u \u2212 Mu,u\n)(M\u2212u,\u2212u \u2212 M\u2212u,\u2212u\n) \u2265 (Mu,u M\u2212u,\u2212u )2 . Hence Mu,u +\nM\u2212u,\u2212u \u2264 1. Since the objective function equals the trace of M , the value is at most\nn\n1 + 3 2\u22121 .\n\nThis bound is very poor. The same bound already follows from the fact that if 0 \u2208 A,\nfor every nonzero word u not both u and \u2212u can belong to A.\n\n7.2\n\nNotes on computational results\n\nThe computational results from Chapters 4 and 5 have been obtained by using CSDP\nversion 4.7 (see [7]) and SDPT3 (see [42]). Both are SDP-solvers and can be accessed\nalso through the NEOS server, see\n\n\f7.2. NOTES ON COMPUTATIONAL RESULTS\n\n79\n\nwww-neos.mcs.anl.gov/\n. The semidefinite programs were generated by perl scripts in the sparse SDPA format,\nwhich allows for explicit block structure in the constraint matrices to be exploited by the\nsolver.\nIn the case of error correcting codes (tables 1,2,3 from Chapter 4), all solutions produced by the solvers have been examined by a perl script to ensure that the produced\nnumbers really do give valid upper bounds on error correcting codes. In none of the instances this has made a diference for the final\nThis was done as follows.\n\u0001 obtained.\nPbound\n0,0\n, given certain constraints\nThe original problem was to maximize i ni (q \u2212 1)i xi,0\non the variables xt,p\ni,j (4.27). By changing the sign of the objective vector, we obtain a\nsemidefinite program of the following form:\nminimize\nsubject to\n\nx 1 c1 + * * * + x m cm\nx1 F1 + * * * + xm Fm \u2212 F0 =: X \u0017 0,\n\n(7.5)\n\nwhere we minimize over xT = (x1 , . . . , xm ), cT = (c1 , . . . , cm ) is the objective vector and\nF0 , . . . , Fm are given symmetric matrices. The SDP solver not only returns a solution to\nthis (primal) problem, but also to its dual:\nmaximize\nsubject to\n\nhF0 , Y i\nhFi , Y i = ci ,\nY \u0017 0.\n\n(7.6)\ni = 1, . . . , m,\n\nAny genuine feasible matrix Y for the dual problem gives a lower bound on the minimum\nin the primal problem, and hence an upper bound for our coding problem. However, the\nproduced dual solutions Y usually do not exactly satisfy the linear constraint, but satisfy\nhFi , Y i = ci + \u000fi ,\n\n(7.7)\n\nfor small numbers \u000f1 , . . . , \u000fm . In all cases we did find that Y \u0017 0 was satisfied. This\nyields a lower bound on the optimum of the primal program as follows. Let (x, X) be an\noptimal solution for the primal program with value O. Then we obtain:\nhF0 , Y i =\n\u2264\n=\n=\n=\n\nhx1 F1 + * * * + xm Fm \u2212 X, Y i\nhx1 F1 + * * * + xm Fm , Y i\nx1 hF1 , Y i + * * * + xm hFm , Y i\nx1 (c1 + \u000f1 ) + * * * + xm (cm + \u000fm )\nO + (x1 \u000f1 + * * * + xm \u000fm ).\n\n(7.8)\n\nThe numbers \u000f1 , . . . , \u000fm are easily calculated from the solution Y . Although the numbers\nx1 , . . . , xm are not known, we can say that xi \u2208 [0, 1] in this case, which allows us to\nbound the error term by\n(x1 \u000f1 + * * * + xm \u000fm ) \u2264 max{0, \u000f1 } + * * * + max{0, \u000fm }.\n\n(7.9)\n\nThis gives lower bound on O, and hence an upper bound on the maximum size of a code.\n\n\f80\n\nCHAPTER 7. FURTHER DISCUSSION\n\n\fBibliography\n[1] R. A. Bailey. Association schemes, volume 84 of Cambridge Studies in Advanced\nMathematics. Cambridge University Press, Cambridge, 2004. Designed experiments,\nalgebra and combinatorics.\n[2] E. Bannai and T. Ito. Algebraic combinatorics. I. The Benjamin/Cummings Publishing Co. Inc., Menlo Park, CA, 1984. Association schemes.\n[3] G. P. Barker, L. Q. Eifler, and T. P. Kezlan. A non-commutative spectral theorem.\nLinear Algebra and Appl., 20(2):95\u2013100, 1978.\n[4] J. Bierbrauer and Y. Edel. Bounds on affine caps. J. Combin. Des., 10(2):111\u2013115,\n2002.\n[5] G. T. Bogdanova, A. E. Brouwer, S. N. Kapralov, and P. R. J. \u00d6sterg\u00e5rd. Errorcorrecting codes over an alphabet of four elements. Des. Codes Cryptogr., 23(3):333\u2013\n342, 2001.\n[6] G. T. Bogdanova and P. R. J. \u00d6sterg\u00e5rd. Bounds on codes over an alphabet of five\nelements. Discrete Math., 240(1-3):13\u201319, 2001.\n[7] B. Borchers. CSDP, a C library for semidefinite programming. Optim. Methods\nSoftw., 11/12(1-4):613\u2013623, 1999. Interior point methods.\n[8] R. C. Bose and T. Shimamoto. Classification and analysis of partially balanced\nincomplete block designs with two associate classes. J. Amer. Statist. Assoc., 47:151\u2013\n184, 1952.\n[9] A. E. Brouwer. Website: http://www.win.tue.nl/\u223caeb.\n[10] A. E. Brouwer, A. M. Cohen, and A. Neumaier. Distance-regular graphs, volume 18\nof Ergebnisse der Mathematik und ihrer Grenzgebiete (3) [Results in Mathematics\nand Related Areas (3)]. Springer-Verlag, Berlin, 1989.\n[11] A. E. Brouwer, H. O. H\u00e4m\u00e4l\u00e4inen, P. R. J. \u00d6sterg\u00e5rd, and N. J. A. Sloane. Bounds\non mixed binary/ternary codes. IEEE Trans. Inform. Theory, 44(1):140\u2013161, 1998.\n[12] P. J. Cameron. Coherent configurations, association schemes and permutation\ngroups. In Groups, combinatorics & geometry (Durham, 2001), pages 55\u201371. World\nSci. Publishing, River Edge, NJ, 2003.\n81\n\n\f82\n\nBIBLIOGRAPHY\n\n[13] W. D. Chen and I. S. Honkala. Lower bounds for q-ary covering codes. IEEE Trans.\nInform. Theory, 36(3):664\u2013671, 1990.\n[14] G. Cohen, I. Honkala, S. Litsyn, and A. Lobstein. Covering codes, volume 54 of\nNorth-Holland Mathematical Library. North-Holland Publishing Co., Amsterdam,\n1997.\n[15] P. Delsarte. An algebraic approach to the association schemes of coding theory.\nPhilips Res. Rep. Suppl., (10):vi+97, 1973.\n[16] D. Gijswijt, A. Schrijver, and H. Tanaka. New upper bounds for nonbinary codes\nbased on the terwilliger algebra and semidefinite programming. Submitted, November\n2004.\n[17] M. Gr\u00f6tschel, L. Lov\u00e1sz, and A. Schrijver. Geometric algorithms and combinatorial\noptimization, volume 2 of Algorithms and Combinatorics. Springer-Verlag, Berlin,\nsecond edition, 1993.\n[18] L. Habsieger. Some new lower bounds for ternary covering codes. Electron. J. Combin., 3(2):Research Paper 23, approx. 14 pp. (electronic), 1996. The Foata Festschrift.\n[19] L. Habsieger and A. Plagne. New lower bounds for covering codes. Discrete Math.,\n222(1-3):125\u2013149, 2000.\n[20] H. H\u00e4m\u00e4l\u00e4inen, I. Honkala, S. Litsyn, and P. \u00d6sterg\u00e5rd. Football pools-a game for\nmathematicians. Amer. Math. Monthly, 102(7):579\u2013588, 1995.\n[21] I. S. Honkala. Lower bounds for binary covering codes. IEEE Trans. Inform. Theory,\n34(2):326\u2013329, 1988.\n[22] R. A. Horn and C. R. Johnson. Matrix analysis. Cambridge University Press, Cambridge, 1990. Corrected reprint of the 1985 original.\n[23] S. M. Johnson. A new lower bound for coverings by rook domains. Utilitas Math.,\n1:121\u2013140, 1972.\n[24] G. K\u00e9ri. Website: http://www.sztaki.hu/\u223ckeri/codes.\n[25] G. K\u00e9ri and P. R. J. \u00d6sterg\u00e5rd. Bounds for covering codes over large alphabets. Des.\nCodes Cryptogr., 37(1):45\u201360, 2005.\n[26] E. de Klerk and D.V. Pasechnik. A note on the stability number of an orthogonality\ngraph. ArXiv:math.CO/0505038, May 2005.\n[27] S. Lang. Linear algebra. Undergraduate Texts in Mathematics. Springer-Verlag, New\nYork, third edition, 1989.\n[28] M. Laurent. Strengthened semidefinite bounds for codes. Januari 2005.\n[29] D. F. Li and W. D. Chen. New lower bounds for binary covering codes. IEEE Trans.\nInform. Theory, 40(4):1122\u20131129, 1994.\n\n\fBIBLIOGRAPHY\n\n83\n\n[30] J. H. van Lint. Introduction to coding theory, volume 86 of Graduate Texts in Mathematics. Springer-Verlag, Berlin, third edition, 1999.\n[31] L. Lov\u00e1sz. On the Shannon capacity of a graph. IEEE Trans. Inform. Theory,\n25(1):1\u20137, 1979.\n[32] L. Lov\u00e1sz and A. Schrijver. Cones of matrices and set-functions and 0-1 optimization.\nSIAM J. Optim., 1(2):166\u2013190, 1991.\n[33] F. J. MacWilliams and N. J. A. Sloane. The theory of error-correcting codes. I,\nII. North-Holland Publishing Co., Amsterdam, 1977. North-Holland Mathematical\nLibrary, Vol. 16.\n[34] Y. Nesterov and A. Nemirovskii. Interior-point polynomial algorithms in convex programming, volume 13 of SIAM Studies in Applied Mathematics. Society for Industrial\nand Applied Mathematics (SIAM), Philadelphia, PA, 1994.\n[35] M. R\u00f8rdam, F. Larsen, and N. Laustsen. An introduction to K-theory for C \u2217 -algebras,\nvolume 49 of London Mathematical Society Student Texts. Cambridge University\nPress, Cambridge, 2000.\n[36] A. Schrijver. A comparison of the Delsarte and Lov\u00e1sz bounds. IEEE Trans. Inform.\nTheory, 25(4):425\u2013429, 1979.\n[37] A. Schrijver. Combinatorial optimization. Polyhedra and efficiency. Vol. B, volume 24\nof Algorithms and Combinatorics. Springer-Verlag, Berlin, 2003. Matroids, trees,\nstable sets, Chapters 39\u201369.\n[38] A. Schrijver. New code upper bounds from the terwilliger algebra. IEEE Trans.\nInform. Theory, To appear.\n[39] P. Terwilliger. The subconstituent algebra of an association scheme. I. J. Algebraic\nCombin., 1(4):363\u2013388, 1992.\n[40] P. Terwilliger. The subconstituent algebra of an association scheme. III. J. Algebraic\nCombin., 2(2):177\u2013210, 1993.\n[41] M. J. Todd. Semidefinite optimization. Acta Numer., 10:515\u2013560, 2001.\n[42] K. C. Toh, M. J. Todd, and R. H. T\u00fct\u00fcnc\u00fc. SDPT3-a MATLAB software package\nfor semidefinite programming, version 1.3. Optim. Methods Softw., 11/12(1-4):545\u2013\n581, 1999. Interior point methods.\n[43] G. J. M. van Wee. Improved sphere bounds on the covering radius of codes. IEEE\nTrans. Inform. Theory, 34(2):237\u2013245, 1988.\n[44] G. J. M. van Wee. Covering codes, perfect codes, and codes from algebraic curves.\nTechnische Universiteit Eindhoven, Eindhoven, 1991. Dissertation, Technische Universiteit Eindhoven, Eindhoven, 1991, With a Dutch summary.\n\n\f84\n\nBIBLIOGRAPHY\n\n[45] J. H. M. Wedderburn. Lectures on matrices. Dover Publications Inc., New York,\n1964.\n[46] Z. Zhang. Linear inequalities for covering codes. I. Pair covering inequalities. IEEE\nTrans. Inform. Theory, 37(3, part 1):573\u2013582, 1991.\n[47] Z. Zhang and C. Lo. Linear inequalities for covering codes. II. Triple covering inequalities. IEEE Trans. Inform. Theory, 38(6):1648\u20131662, 1992.\n\n\fSamenvatting\nDit proefschrift gaat over foutcorrigerende codes en overdekkingscodes. Een code is een\ncollectie woorden van dezelfde lengte n met letters uit een alfabet q = {0, 1, . . . , q \u2212 1}\nbestaande uit een q-tal symbolen. In het geval dat q = 2 bestaat elk woord uit een rijtje\nvan n nullen en enen. We spreken in dat geval van een binaire code. Voor q \u2265 3 spreken\nwe van niet-binaire codes. De Hamming afstand d(x, y) tussen twee woorden x en y is\ngedefinieerd als het aantal posities waarin zij verschillen. Zo krijgt de verzameling qn van\nalle woorden de structuur van een metrische ruimte, de Hamming ruimte.\nEen centrale vraag in de theorie van foutcorrigerende codes is:\nGegeven een 'minimum afstand' d, wat is het maximale aantal woorden in\neen code als we eisen dat van elk tweetal woorden de onderlinge afstand ten\nminste d moet zijn?\nDit maximum, aangegeven met Aq (n, d) heeft een mooie 'meetkundige' interpretatie in\nhet geval dat d = 2e + 1 oneven is. Het getal Aq (n, d) is dan precies het aantal bollen\nvan straal e dat binnen de Hammingruimte kan worden gestapeld. De foutcorrigerende\neigenschappen van zo'n code volgen uit het feit dat wanneer een codewoord in hoogstens e posities wordt gewijzigd, het originele woord weer terug wordt gevonden door het\ndichtsbijzijnde codewoord te nemen.\nEen twee vraag, die duaal is aan de vorige, speelt een rol in onder andere datacompressie:\nGegeven een 'overdekkings straal' r, wat is het minimale aantal woorden in\neen code als we eisen dat ieder woord afstand ten hoogste r tot een woord in\nde code heeft?\nDit minimum, aangegeven met Kq (n, r) is het aantal bollen van straal r dat nodig is om\nde hele Hamming ruimte te bedekken.\nIn het algemeen zijn de getallen Aq (n, d) en Kq (n, r) erg moeilijk te bepalen en slechts\nweinig waarden zijn bekend. Daarom is het interessant om goede onder- en bovengrenzen\nte vinden voor deze getallen. Het meetkundige beeld van het stapelen van en overdekken\nmet bollen geeft al een bovengrens voor Aq (n, 2r + 1) en een ondergrens voor Kq (n, r)\ndoor het volume van de gehele Hamming ruimte te delen door het volume van een bol\nvan straal r.\nIn dit proefschrift geven we nieuwe bovengrenzen voor Aq (n, d) en nieuwe ondergrenzen voor Kq (n, r) met behulp van semidefiniete programmering. Een belangrijke rol wordt\ngespeeld door een expliciete blokdiagonalisatie van de Terwilliger algebra van het Hamming schema. Deze maakt het mogelijk om de grote symmetriegroep van de Hamming\n85\n\n\f86\n\nSAMENVATTING\n\nruimte te benutten, zowel voor het verkrijgen van scherpere grenzen, als voor het efficient kunnen bepalen van deze grenzen. De beschreven methode voor het begrenzen\nvan Aq (n, d) werd door Schrijver geintroduceerd voor het binaire geval in [38]. In hetzelfde artikel werd ook een blokdiagonalisatie gegeven voor de Terwilliger algebra van\nhet binaire Hamming schema. Een centraal resultaat uit dit proefschrift is een expliciete\nblokdiagonalisatie van de Terwilliger algebra van het niet-binaire Hamming schema.\nIn hoofdstuk 2 brengen we de benodigde theorie in herinnering. In het bijzonder\nstippen we de krachtige methode van Delsarte [15] aan, waarmee met behulp van associatieschemas bovengrenzen voor Aq (n, d) te verkrijgen zijn door middel van lineaire\nprogrammering. Het idee is om te kijken naar de afstandsverdeling 1 = x0 , x1 , . . . , xn van\neen code, waar xi het gemiddeld aantal codewoorden op afstand i van een codewoord is.\nDe getallen xi voldoen aan bepaalde lineaire ongelijkheden. De eerste soort ongelijkheden\nheeft een directe combinatorische betekenis: de getallen xi zijn niet-negatief en xi = 0 als\ner geen twee woorden zijn op afstand i. De andere ongelijkheden, met coefficienten gegeven\ndoor de Krawtchouk polynomen, hebben een diepere betekenis. Zij weerspiegelen het feit\ndat de corresponderende lineaire combinatie A := x0 A0 +* * *+xn An van associatiematrices\nvan het Hamming schema positief semidefiniet is. Dat het positief semidefiniet zijn van A\nkan worden teruggebracht tot een n + 1 tal lineaire ongelijkheden, is het plezierige gevolg\nvan het feit dat de Bose\u2013Mesner algebra behorende bij het Hamming schema commutatief\nis, en daardoor in diagonaalvorm kan worden gebracht.\nEen van de ideeen achter het onderhavige werk, is om naar de verdeling van drietallen\ncodewoorden te kijken in plaats van naar paren. Dit leidt tot de bestudering van een\nverfijning van de Bose\u2013Mesner algebra in Hoofdstuk 3. De algebra bestaat uit alle matrices die invariant zijn onder die automorfismen van het Hamming schema H(n, q), die\neen gekozen woord vasthouden. Er is een basis van 0\u20131 matrices die geparametriseerd\nwordt door de mogelijke configuraties van drietallen woorden modulo automorfismen. We\nlaten zien dat de algebra overeenkomt met de Terwilliger algebra [39] van het Hamming\nschema. Deze Terwilliger algebra is niet langer commutatief en kan daarom niet worden\ngediagonaliseerd. Het analogon voor niet-commutatieve algebras is een blokdiagonalisatie,\nwaarbij de algebra bestaat uit alle matrices met gegeven blok-diagonaal structuur. Een\ncentraal resultaat van dit proefschrift is een expliciete blokdiagonalisatie van de Terwilliger\nalgebra behorende bij het niet-binaire Hamming schema. Hoewel het positief semidefiniet\nzijn van een matrix in de Terwilliger algebra niet langer kan worden geformuleerd door\neen klein aantal lineaire ongelijkheden, geeft de blokdiagonalisatie toch een handzame formulering in termen van het positief semidefinitiet zijn van een klein aantal kleine matrices\n(het aantal is O(n2 ) en de grootte O(n)).\nIn hoofdstuk 4 geven we een verscherping van de Delsarte grens voor codes. Met behulp\nvan de expliciete blokdiagonalisatie van de Terwilliger algebra uit hoofdstuk 3, kan deze\ngrens efficient worden bepaald middels semidefinite programmering. Voor q = 3, 4, 5 levert\ndit computationeel een reeks verscherpingen op voor bekende bovengrenzen voor Aq (n, d).\nIn hoofdstuk 5 beschouwen we overdekkingscodes en geven we nieuwe ondergrenzen\nvoor Kq (n, r). Veel bestaande grenzen voor Kq (n, r) zijn gebaseerd op de afstandsverdeling A0 (x), . . . , An (x) van de code C gezien vanuit een woord x. Hier is Ai (x) het aantal\nwoorden in C op afstand i van x. Iedere lineaire ongelijkheid in A0 , . . . , An die voor de\nafstandsverdeling vanuit ieder woord x geldt, geeft een ondergrens voor Kq (n, r). De voor\n\n\f87\nde hand liggende ongelijkheid\nA0 + A1 + * * * + Ar \u2265 1\n\n(7.10)\n\nleidt op deze manier tot dezelfde grens ('sphere covering bound') als het volume argument\nals boven. Vanuit polyhedraal oogpunt optimaliseren we een lineare functie over een\nn\neen polytoop P \u2286 [0, 1]q binnen de eenheidskubus, met een groot aantal symmetrieen,\nnamelijk de symmetrieen van de Hamming ruimte qn . Met behulp van de theorie van\nmatrix snedes [32] kunnen we P vervangen door een kleinere convexe verzameling, en\ndaarmee scherpere grenzen voor Kq (n, r) vinden. Om deze grenzen efficient te kunnen\nbepalen met lineaire en semidefiniete programmering, is wederom de blokdiagonalisatie\nvan de Terwilliger algebra van het Hamming schema van groot belang. Computationeel\nlevert deze methode voor q = 3 en q = 4 een aantal verscherpingen op ten opzichte van\nde ondergrenzen voor Kq (n, r) uit de literatuur.\nIn hoofdstuk 6 brengen we deze theorie van matrix-snedes in herinnering en bestuderen\nwe de relatie tussen de nieuwe grenzen voor Aq (n, d) en deze theorie van matrix snedes.\nIn het bijzonder blijkt dat de grenzen voor Aq (n, d) uit hoofdstuk 4 scherper zijn dan die\nafkomstig van het toepassen van matrix-snedes op het 'theta-body'. Dit is (vooral) te\ndanken aan extra relaties die voortvloeien uit de aanwezige symmetrieen.\n\n\f88\n\nSAMENVATTING\n\n\fDankwoord\nMet groot genoegen maak ik hier van de mogelijkheid gebruik om een ieder te bedanken\ndie mij gedurende mijn promotietijd heeft gesteund, met dit proefschrift als resultaat.\nZonder mijn promotor, Lex Schrijver, was dit proefschrift er niet geweest, en zou ik\ngeen promotieonderzoek hebben gedaan in de combinatorische optimalisatie. Graag wil ik\nhem bedanken voor zijn continue steun en vertrouwen, ook wanneer ik dat laatste schier\nverloren had. Ik ben blij dat ik zo veel van hem heb kunnen leren.\nDit boekje heb ik opgedragen aan Violeta, mijn partner en moeder van onze twee\nkinderen Amber en Mark. Hoewel ik soms te weinig tijd voor hen vrij maakte, heeft\nVioleta mij altijd gesteund. Mark en Amber hebben mij altijd weer weten te verleiden\nom mijn werk even opzij te schuiven.\nVeel heb ik ook te danken aan mijn ouders, en ook mijn schoonouders. Zij hebben mij\nop zoveel verschillende manieren beinvloed en ondersteund.\nVoor de prettige werksfeer dank ik mijn collegas aan de UvA, in het bijzonder mijn\nkamergenoot Pia Pfluger. Ook aan het CWI heb ik het enorm getroffen met fijne collegas.\nIk bedank Monique Laurent voor de gesprekken over het onderwerp van dit proefschrift.\nOok wil ik mijn kamergenoot Gabor Maroti bedanken. Zonder hem was het vast niet\ngelukt om Theory of Integer and Linear Programming zo grondig te bestuderen. Ook\nging er geen keer voorbij dat hij geen nice puzzle had. Ik vermoed dat zijn Hongaarse\nachtergrond hier deels verantwoordelijk voor was.\nGraag wil ik ook Chris Zaal noemen. Ik herinner mij goed de SET-workshop die we\naan het APS gegeven hebben, de opnamen van de Nationale Wetenschaps Quiz en diverse\nandere creativiteiten op het gebied van wiskunde-promotie. In het bijzonder heeft hij mij\ngeintroduceerd bij Pythagoras, waar ik nog steeds de problemenrubriek mag vullen.\nIk dank ook Marco Zwaan. Via hem heb ik mogen proeven hoe het is om wiskundeleraren te onderwijzen aan de eerstegraads opleiding, een bijzondere ervaring.\nTenslotte dank ik de iedereen die ik niet met name heb genoemd, maar aan wie ik\nniettemin fijne herinneringen dank. Bedankt!\n\n89\n\n\f90\n\n\fCurriculum Vitae\nDion Camilo Gijswijt is geboren op 20 maart 1978 te Bunschoten. Al vroeg had hij\ngrote interesse in natuurkunde en andere exacte wetenschappen. Tijdens de eerste jaren\nvan zijn middelbareschool-tijd groeide zijn interesse voor kunstmatige intelligentie en\nwiskunde. Het boek G\u00f6del, Escher, Bach van D.R. Hofstadter had daarin een groot\naandeel. Uiteindelijk gaf zijn deelname aan de International Wiskunde Olympiade in de\nlaatste jaren van de middelbare school de doorslag om wiskunde te gaan studeren.\nIn 1996 slaagde hij voor het eindexamen VWO aan het Goois Lyceum in Bussum en\nbegon aan een dubbele studie wiskunde en natuurkunde aan de Universiteit van Amsterdam. Na in 1997 zijn propedeuses wiskunde en natuurkunde cum laude te hebben behaald,\nbesloot hij zich te concentreren op de studie wiskunde. Tijdens zijn studie besteede hij\neen groot deel van zijn tijd aan het tijdschrift Pythagoras, dat juist onder de bezielende\nleiding van Chris Zaal nieuw leven was ingeblazen. Nadat hij in 1996 begon met het\nvullen van de problemenrubriek, werd hij in 1998 tevens redacteur.\nIn augustus 2001 behaalde hij zijn doctoraaldiploma (cum laude) na het schrijven van\neen scriptie getiteld The Colin de Verdi\u00e8re Graph Parameter \u03bc onder begeleiding van Lex\nSchrijver. In september 2001 begon hij, eveneens onder supervisie van Lex Schrijver, aan\nzijn promotie-onderzoek aan het KdVI aan de Universiteit van Amsterdam. Dit onderzoek, met als thema Spectral Methods for Graph Optimization and Embedding, mondde\nin juli 2005 uit in het onderhavige proefschrift.\nGedurende deze vier jaar als promovendus was hij ook in de gelegenheid andere\nactiviteiten te ontplooien. Naast het met plezier begeleiden van diverse werkcolleges,\nheeft hij vooral veel geleerd van het doceren van een college grafentheorie aan eerstejaars\nwiskunde studenten, en later aan leraren aan de eerstegraads lerarenopleiding. Ook het\nbegeleiden van twee studenten bij het schrijven van hun kandidaatsscriptie was een grote\nervaring.\nDaarnaast heeft hij zich beziggehouden met activiteiten ter promotie van de wiskunde.\nNaast zijn werk voor Pythagoras, was hij actief als lid van de vraagstukkencommissie\nvoor de Nederlandse Wiskunde Olympiade, en was betrokken bij diverse promotionele\nactiviteiten waaronder: de Leve de Wiskunde dag, Nationale Wetenschapsdag, voorlichtingsdagen van de UvA, mastercourse voor wiskundeleraren en workshops voor scholieren\nen leraren.\n\n91\n\n\f"}