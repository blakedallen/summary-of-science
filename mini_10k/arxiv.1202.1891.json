{"id": "http://arxiv.org/abs/1202.1891v1", "guidislink": true, "updated": "2012-02-09T05:51:18Z", "updated_parsed": [2012, 2, 9, 5, 51, 18, 3, 40, 0], "published": "2012-02-09T05:51:18Z", "published_parsed": [2012, 2, 9, 5, 51, 18, 3, 40, 0], "title": "Hyper heuristic based on great deluge and its variants for exam\n  timetabling problem", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1202.2839%2C1202.6076%2C1202.1104%2C1202.4681%2C1202.6658%2C1202.4204%2C1202.0480%2C1202.0081%2C1202.2316%2C1202.3176%2C1202.5035%2C1202.0972%2C1202.1199%2C1202.2846%2C1202.4328%2C1202.1607%2C1202.0584%2C1202.0806%2C1202.1319%2C1202.2511%2C1202.2432%2C1202.6145%2C1202.4782%2C1202.1891%2C1202.0021%2C1202.4791%2C1202.0142%2C1202.0969%2C1202.6535%2C1202.0580%2C1202.4224%2C1202.5133%2C1202.2224%2C1202.1137%2C1202.2022%2C1202.3331%2C1202.4293%2C1202.0351%2C1202.3049%2C1202.0750%2C1202.1884%2C1202.2832%2C1202.1404%2C1202.3676%2C1202.2048%2C1202.6180%2C1202.0249%2C1202.1037%2C1202.5008%2C1202.1689%2C1202.3066%2C1202.1870%2C1202.3270%2C1202.0943%2C1202.5599%2C1202.3980%2C1202.5696%2C1202.4922%2C1202.1270%2C1202.6272%2C1202.1619%2C1202.0292%2C1202.0631%2C1202.5192%2C1202.0212%2C1202.0387%2C1202.4345%2C1202.5207%2C1202.6496%2C1202.1170%2C1202.6108%2C1202.4900%2C1202.2759%2C1202.2892%2C1202.3416%2C1202.6203%2C1202.4956%2C1202.0975%2C1202.2815%2C1202.3828%2C1202.2431%2C1202.2178%2C1202.1698%2C1202.1580%2C1202.1552%2C1202.4605%2C1202.5183%2C1202.3352%2C1202.5773%2C1202.0339%2C1202.6263%2C1202.4251%2C1202.0458%2C1202.1802%2C1202.4310%2C1202.3284%2C1202.4221%2C1202.2985%2C1202.2243%2C1202.6399%2C1202.4729&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Hyper heuristic based on great deluge and its variants for exam\n  timetabling problem"}, "summary": "Today, University Timetabling problems are occurred annually and they are\noften hard and time consuming to solve. This paper describes Hyper Heuristics\n(HH) method based on Great Deluge (GD) and its variants for solving large,\nhighly constrained timetabling problems from different domains. Generally, in\nhyper heuristic framework, there are two main stages: heuristic selection and\nmove acceptance. This paper emphasizes on the latter stage to develop Hyper\nHeuristic (HH) framework. The main contribution of this paper is that Great\nDeluge (GD) and its variants: Flex Deluge(FD), Non-linear(NLGD), Extended Great\nDeluge(EGD) are used as move acceptance method in HH by combining Reinforcement\nlearning (RL).These HH methods are tested on exam benchmark timetabling problem\nand best results and comparison analysis are reported.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1202.2839%2C1202.6076%2C1202.1104%2C1202.4681%2C1202.6658%2C1202.4204%2C1202.0480%2C1202.0081%2C1202.2316%2C1202.3176%2C1202.5035%2C1202.0972%2C1202.1199%2C1202.2846%2C1202.4328%2C1202.1607%2C1202.0584%2C1202.0806%2C1202.1319%2C1202.2511%2C1202.2432%2C1202.6145%2C1202.4782%2C1202.1891%2C1202.0021%2C1202.4791%2C1202.0142%2C1202.0969%2C1202.6535%2C1202.0580%2C1202.4224%2C1202.5133%2C1202.2224%2C1202.1137%2C1202.2022%2C1202.3331%2C1202.4293%2C1202.0351%2C1202.3049%2C1202.0750%2C1202.1884%2C1202.2832%2C1202.1404%2C1202.3676%2C1202.2048%2C1202.6180%2C1202.0249%2C1202.1037%2C1202.5008%2C1202.1689%2C1202.3066%2C1202.1870%2C1202.3270%2C1202.0943%2C1202.5599%2C1202.3980%2C1202.5696%2C1202.4922%2C1202.1270%2C1202.6272%2C1202.1619%2C1202.0292%2C1202.0631%2C1202.5192%2C1202.0212%2C1202.0387%2C1202.4345%2C1202.5207%2C1202.6496%2C1202.1170%2C1202.6108%2C1202.4900%2C1202.2759%2C1202.2892%2C1202.3416%2C1202.6203%2C1202.4956%2C1202.0975%2C1202.2815%2C1202.3828%2C1202.2431%2C1202.2178%2C1202.1698%2C1202.1580%2C1202.1552%2C1202.4605%2C1202.5183%2C1202.3352%2C1202.5773%2C1202.0339%2C1202.6263%2C1202.4251%2C1202.0458%2C1202.1802%2C1202.4310%2C1202.3284%2C1202.4221%2C1202.2985%2C1202.2243%2C1202.6399%2C1202.4729&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Today, University Timetabling problems are occurred annually and they are\noften hard and time consuming to solve. This paper describes Hyper Heuristics\n(HH) method based on Great Deluge (GD) and its variants for solving large,\nhighly constrained timetabling problems from different domains. Generally, in\nhyper heuristic framework, there are two main stages: heuristic selection and\nmove acceptance. This paper emphasizes on the latter stage to develop Hyper\nHeuristic (HH) framework. The main contribution of this paper is that Great\nDeluge (GD) and its variants: Flex Deluge(FD), Non-linear(NLGD), Extended Great\nDeluge(EGD) are used as move acceptance method in HH by combining Reinforcement\nlearning (RL).These HH methods are tested on exam benchmark timetabling problem\nand best results and comparison analysis are reported."}, "authors": ["Ei Shwe Sin", "Nang Saing Moon Kham"], "author_detail": {"name": "Nang Saing Moon Kham"}, "author": "Nang Saing Moon Kham", "links": [{"href": "http://arxiv.org/abs/1202.1891v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1202.1891v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1202.1891v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1202.1891v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "HYPER HEURISTIC BASED ON GREAT DELUGE\nAND ITS VARIANTS FOR EXAM TIMETABLING\nPROBLEM\nEi Shwe Sin1, Nang Saing Moon Kham2\n1\n\nUniversity of Computer Studies, Yangon\neishwe.ucsy@gmail.com\n2\nHead of Information Science Dept, University of Computer Studies, Yangon\nmoonkhamucsy@gmail.com\n\nABSTRACT\nToday, University Timetabling problems are occurred annually and they are often hard and\ntime consuming to solve. This paper describes Hyper Heuristics (HH) method based on Great Deluge\n(GD) and its variants for solving large, highly constrained timetabling problems from different domains.\nGenerally, in hyper heuristic framework, there are two main stages: heuristic selection and move\nacceptance. This paper emphasizes on the latter stage to develop Hyper Heuristic (HH) framework. The\nmain contribution of this paper is that Great Deluge (GD) and its variants: Flex Deluge(FD), Nonlinear(NLGD), Extended Great Deluge(EGD) are used as move acceptance method in HH by combining\nReinforcement learning (RL).These HH methods are tested on exam benchmark timetabling problem and\nbest results and comparison analysis are reported.\n\nKEYWORDS\nHyper Heuristic, Great Deluge, Exam Timetabling Problem\n\n1. INTRODUCTION\nToday, because of being critical in education sectors, most of the university administrators are\ntrying to get more enrolment of the student and they have to be very careful to increase in\nstudent's stratifications. As a result, they are very careful to solve university problem. In fact, it\nrepresents the difficult optimization problem. As the difficulty of the problem, their importance\nin practice and inherent scientific challenge increases, they have been widely investigated across\nboth the operational research and the artificial intelligence community. . It can be classified into\nexam timetabling problem and course timetabling problem. In this paper, exam timetabling\nproblem (ETP) is used as the test bed for the proposed three HH methods.\nThe exam timetabling problem is to assign a number of exams to a number of potential time\nperiods or slots by taking into account to satisfy the several constraints. Several approaches\nhave been conducted with various methodologies being applied to attempt to produce better\nquality exam timetables. There are a lot of researchers and their publications in the literature.\nFor more detailed information about examination timetabling, it can be found in [2, 16, and 18].\nThere are also varieties of timetabling problem classes on which variety of approaches such as\nsequential method, cluster methods, constraint-based methods and meta-heuristics are used.\nMoreover, there are a large number of Meta heuristics for solving an examination timetabling\nproblem. However, these methods have some issues such as parameter tuning and they are not\ncapable of dealing with other different problems. As a result, the current methods being applied\n\n\fto exam timetabling are hyper heuristic (HH). Hyper Heuristic is an emerged search technique\nfor the purpose to raise the generality [7]. Early research works on hyper heuristic focused on\nthe development of advanced strategies for choosing the heuristics to be applied at different\npoints of the search [3]. Likewise, researchers have proposed different acceptance criteria to\ndrive selection of low level heuristics within a hyper heuristic framework. For instance, a Monte\nCarlo acceptance criterion is used by Ayob and Kendall in [6] while the great deluge acceptance\ncriterion is used by Kendall and Mohamad in [7]. Due to the success of the great deluge and its\nvariants, in this paper, we use them as move acceptance method to find out whether they can\nsupport the good quality solutions for the Toronto benchmark exam timetabling problem or not.\nThe rest of the paper is organized as follows: the Section 2 reviews the previous methods that\nare related our proposed system while Section 3 describes the exam timetabling problem\nincluding constraints. In Section 4, the proposed move acceptance methods are presented. The\nexperiment results and analysis are shown in the Section 5. Finally, the conclusion is shown at\nthe Section 6.\n\n2. RELATED WORKS\nNormally, a hyper heuristic can conduct with a single point or multi-point search. There are two\nmain stages in a single iteration of a hyper heuristic method .They are heuristic selection and\nmovement acceptance. In this paper, the second stage is emphasized. In general, the movement\nacceptance can be deterministic or nondeterministic. There are many methods such as Great\nDeluge (GD), ACO algorithm and simulated annealing methods are used as move acceptance\ncriteria in hyper heuristic because of their very popularities. Therefore, a brief review of GD and\nits variants is made in this paper.\nBykov Y. proposed the time-predefined great deluge algorithm and Trajectory base search to\nexam timetabling in 2003 [19] and Edmund K. Burke and Yuri Bykov made an extension of the\ngreat deluge algorithm (which they called \"Flex-Deluge\") where the acceptance of uphill moves\ndepends on a \"flexibility\" coefficient, for solving exam timetabling problem in 2006 . Good\nresults were presented and they suggested that the flex deluge method is relatively higher\neffective in the large-scale problems [8].\nIn 2007, C. Pramodh and V. Ravi also proposed four variants of Modified Great Deluge\nAlgorithm based Auto Associative Neural Network (MGDAAANN) and worked on three\ndifferent banks data sets [4]. Likewise, Bilgin et al. also reported that a simple random-great\ndeluge based hyper heuristic was the second best after choice function-simulated annealing,\nconsidering the average performance of all hyper heuristic over a set of examination timetabling\nproblem[1]. For course timetabling problem, non linear great deluge algorithm (NLGD) was\nproposed by Landa Silva and Obit. That method produced new best in 4 out of 11 course\ntimetabling problem instances of datasets [14]. In addition , McMullan proposed an extended\ngreat deluge algorithm(EGD) for university course timetabling , which allows re-heating similar\nto simulated annealing, and found new best results for the 5 medium instances. Moreover, in\n2009, the EGD algorithm is also investigated and made a comparison with the first winner,\nTomas Muller in the 2nd International Timetabling Competition (ITC2007). And it seems that\nEGD is comparable to existing state of the art techniques, and form previous application to\nother data sets and a different problem domain (course timetabling)[3].\nIn 2010, Nabil Nahas , Mustapha Nourelfath and Daoud Ait-Kadi have proposed the Iterated\ngreat Deluge heuristic to implement for the dynamic facility layout problem(DFLP) . It consists\nof two main steps. The objective of the first step is to find a local optimum solution by EGD and\nthe second step is a loop that allows the search process to alternate between diversification and\nintensification [18]. Likewise, in 2010, Ender Ozcan et al. proposed a hyper heuristic system by\n\n\fusing reinforcement learning in heuristic selection and great deluge in move acceptance method\nand also achieved the comparative results with other HH methods in the literature [9]. By\nfollowing this idea, we have already proposed to employ the Extended Great Deluge (EGD) as\nmove acceptance method to make a decision whether to accept or reject a resultant solution in\nRL based HH framework. Therefore, from these well-known literature reviews and experiences,\nnow, we would like to do another contribution by making comparison and more analysis about\nthe GD and its other variants in HH framework.\n\n3. DESCRIPTION OF THE EXAM TIMETABLING PROBLEM\nThe university exam timetabling problem can be defined and described in many ways. The basic\nway to represent to it is graph model .Mathematical model can also be used. In a more formal\nway, the timetabling literature defines two types of constraints. Hard Constraints are the\nconstraints that must be satisfied at all times. Soft Constraints are not critical but their\nsatisfaction is beneficial to students and/or the institution. Typically one cannot satisfy all soft\nconstraints thus there is a need for a performance function measuring the degree of satisfaction\nof these constraints [3]. The primary hard and soft constraints in exam timetabling problem can\nbe found in [2]. Among them, the following table shows the hard and soft constraints are used in\nthis paper.\nTable 1. Hard and Soft Constraints\nConstraints\n\nDescription\n\nHC1\n\nNo exams with common resources (e.g. students)\nassigned simultaneously.\n\nHC2\n\nResources of exams need to be sufficient (i.e. size of\nexams need to be below the room capacity, enough\nrooms for all of the exams.)\n\nHC3\n\nEach examination must be assigned to a timeslot only\nfor once.\n\nHC4\n\nAll the examinations must be scheduled.\n\nSC1\n\nA student should have at least a single timeslot in\nbetween his/her examinations in the same day.\n\nIn addition, the problem can be defined with the terms shown in the table 2.\nTable 2. Problem Description\nE\n\nthe number of n exams: E1, E2,E3,... ,En\n\nS\nT\n\nthe number of m students:S1, S2, S3,...Sm;\nthe number of k timeslots: T1, T2, T3,....Tk;\n\nB n*k\n\nA binary matrix such that bik=1 when exam ei is assigned\nto the timeslot t \u20ac T and bik =0 otherwise.\n\n\fC=(cij)n*n\n\nThe conflict matrix; where each element (denoted by cij\nwhere i, j) is the number of students that have to take\nboth exams i and j. This is a symmetrical matrix of size\nN, where diagonal element cii equal the number of\nstudents who have taken exam i.\n\nIn our system, we use not only the conflict matrix but also the binary matrix to ensure HC1 and\nHC3. The objective is to schedule all of the exams into time slots, while minimizing the average\ntotal cost per student. The following function is used to calculate the average cost per student.\nn\n\n\uf0e5 w (| e\ni \uf03d1\n\ni\n\ni\n\n\uf02d e j |) cij\n(1)\n\ns\n\nIn equation, wi is the weight that represents the importance of scheduling exams with common\nstudents i timeslots apart , where, w(1)=16, w(2)=8 w(3)=4,w(4)=2 and w(5)=1, i.e. the smaller\nthe distance between periods the higher the weight allocated. Note for n>5, w (n) =0. For\nexample, if a student has two consecutive examinations (i.e. no free time between them) then\nthe weight value of 16 is assigned. If a student has two consecutive exams with a free timeslot\nin between then a value 8 is assigned and so on. The value of cij is the number of students\ncommon to both examinations. The example of conflict matrix is presented in the following\nfigure 1. In the figure , the value 3 of c11 means that there are 3 students who takes the exam E1\nand the value 1 of c12 means that there is 1 conflict student who will take not only the exam E1\nbut also exam E2. This conflict matrix is also symmetric.\n\nE1\n\nE2\n\nE3\n\nE4\n\nE5\n\nE6\n\nE7\n\nE1\n\n3\n\n1\n\n2\n\n1\n\n2\n\n1\n\n1\n\nE2\n\n1\n\n3\n\n0\n\n1\n\n2\n\n2\n\n1\n\nE3\n\n2\n\n0\n\n2\n\n1\n\n1\n\n0\n\n1\n\nE4\n\n1\n\n1\n\n1\n\n2\n\n1\n\n0\n\n1\n\nE5\n\n2\n\n2\n\n1\n\n1\n\n3\n\n1\n\n0\n\nE6\n\n1\n\n2\n\n0\n\n0\n\n1\n\n2\n\n1\n\nE7\n\n1\n\n1\n\n1\n\n1\n\n0\n\n1\n\n2\n\nFigure 1. Example of Conflict Matrix\n\n4. PROPOSED GD\nMETHODS\n\nAND ITS VARIANTS FOR\n\nMOVE ACCEPTANCE\n\nIN\n\nHH\n\nBy using reinforcement learning in the first stage of HH and the variants of GD are used as\nmove acceptance method, the three hyper heuristic systems such as: RL_EGD, RL_NLGD and\nRL_FD are discussed in this section. Firstly, we present how to produce an initial solution and\nits representation and the low level heuristic which are used in these proposed systems. And\nthen, the analysis and comparison of these three HH systems are described.\n\n\f4.1. Low Level Heuristic and Initial Solution\nTo get the final optimized solutions, it also totally depends on the set of heuristics it can be\nchosen from. Also, due to the performance changes of a number of heuristics over a search\nspace, it is not easy to find a heuristic that always produces the best decisions. They are\nheuristics that allow movement through a solution space and that require domain knowledge and\nare problem dependent. Each heuristic creates its own heuristic search space that is part of the\nsolution search space. There are many low level heuristics (LLH) in the literature, for example:\nmutational heuristic, ruin or recreate heuristic and so on. For low level heuristic module, the\nfollowing table is presented the low level heuristics used in this paper.\nTable 3. Low level Heuristics\nLow level Heuristic\n\nDescription\n\nLargest Enrolment-(LE)\n\nThis heuristic takes exams with the largest\nnumber of registered students and\nschedules them first.\n\nSwap Timeslot with Kempe Chain (ST-KC)\n\nSwapping a subset of exams in two distinct\ntimeslots making sure that a hard constraint\nviolation does not occur.\n\nReassign Timeslot (RT)\n\nRandomly reassign a sequence of timeslots.\n\nInverting Timeslot (IT)\n\nInverting timeslots making sure that a hard\nconstraint violation does not occur.\n\nShifting Timeslot (ST)\n\nLeft or right shifting a sequence of\ntimeslots.\n\nThe first heuristic is one of the graph colourings heuristic and which is used to create a feasible\ninitial solution in this paper. Generally, it is important to have an easy and quick way of\ngenerating an initial solution. Note that it is not necessary though that initial solution should be\ncompletely feasible. However, it is preferred to be as feasible as possible because the quality of\ninitial solution would affect the final solution. Therefore, in this paper, completely feasible\nsolution is produced by using (LE) heuristic. The examination with the largest student\nenrolment is selected and kept in the vector. And then another exams which are not conflict with\nthe exam in the vector, are added to that vector. This process is repeated until the required\ncapacity for exams in the vector is less than the total capacity and unscheduled exam list is\nempty. Finally, this exam vector which satisfied all hard constraints is assigned to the timeslot\nsequentially. For the solution representation; there are two forms of assignment such as:\n\uf0a7 Exam-Timeslot assignment\n\uf0a7 Exam- Classroom assignment.\nIn this paper, the first one is used to represent of the solution. By taking the advantages of HH\nmethod, to produce the feasible solution of all data instances is the aim of this paper. Moreover,\none of the contributions of this paper is that the average timeslot per exam is also used to be\nbalance in exam-timeslot assignment. Otherwise, many exams are assigned to a timeslot\nwhereas few exams are assigned in another timeslot.\nThe rest four low level heuristics from the table 3 are used in the reinforcement learning process\nto improve the solution to get the optimal solution which meets the objective. These heuristics\nare also called the slot move in [2]. The following figure shows the swapping a set of assigned\nexams in two distinct timeslot as an example. In figure, the exams e2, e3, e5 are assigned\n\n\ftimeslot 5 whereas the exams e4 and e1 are assigned in timeslot 2. After the heuristic, ST-KC\nhas been applied; the set of exams assigned in each timeslot will be changed.\n\n1\n\n5\n\n8\n\n7\n\ne2, e3, e5\n1\n\n5\n\n8\n\ne4, e1\n\n2\n\n3\n\n6\n\n4\n\nBefore\n\n3\n\n6\n\n4\n\nAfter\n\ne4, e1\n7\n\n2\n\ne2, e3, e5\n\nFigure 2. Example of Swap Timeslot with Kempe Chain (ST-KC)\n\n4.2. Reinforcement Learning\nFor the heuristic selection process in hyper heuristics, machine learning techniques are vital to\nmake the right choices. Learning can be achieved in an offline or online manner. An online\nlearning hyper heuristic learns through the feedback obtained during the search process while\nsolving a given problem. In addition, it is better than offline method. Most of the existing online\nlearning hyper heuristic incorporates reinforcement learning (RL). It is a sub-field of machine\nlearning, represents an important direction for research in Artificial Intelligence [9]. RL is a\nframework for learning an optimal policy of a task from trials. It requires less a priori\nknowledge. Furthermore, it is successfully applied to scheduling, control, game theory and so\non. However, the quality of solution obtained by using RL is not satisfactory in many times.\nHowever, EGD can control to make a decision whether it is accepts or rejects, after the chosen\nheuristic has been applied to initial solution. In this paper, not only a simple P: 1-N: 1(Additive\nadaption-Negative adaption) strategy to increase and decrease the utility value and but also\nmaximum utility method are used for RL. For the parameter setting for lower bound and upper\nbound of utility values in RL, we follow the reference [9] and the values can be seen at the\nSection 5.\n\n4.3. Great Deluge (GD) and its variant\nThe Great Deluge algorithm (GD) is a genetic algorithm applied to optimization problems. It is\nsimilar in many ways to the hill-climbing and simulated annealing algorithms. In GD, the water\nlevel is set to a value higher than the expected penalty of the best solution at the start of the\nsearch. Then the water level is decreased in a linear fashion during the search until it reaches a\nvalue of zero [19]. It is a well known acceptance method proposed by (Dueck; 1993, Burke et\nal., 2003). There are many variants form of GD in the literature such as NLGD, EGD and FD.\nThey are discussed in the next section in detail.\n4.3.1. Extended Great Deluge\nIn fact, the concept of EGD algorithm is quite similar with the hyper heuristic method. As far as\nthe author knows, it has been considered first time as move acceptance for hyper heuristic. It has\nadvantages to require the tuning of a few input parameters that can represent the search time. It\ncan provide a wider test with the hidden data sets for consistency in the approaches. Moreover,\nit can be interested to run all techniques at some future point with further hidden data sets. It is\nalso proved to be both robust and general. Because of these advantages, it has been successfully\n\n\fapplied to many optimization problems such as buffer allocation problem, redundancy\nallocation problem and so on.\nTherefore, in this paper, it is investigated to make further improvement in hyper heuristic or not.\nThe standard GDA has been extended by adding reheat mechanism, step 13 in figure 1, similar\nto that employed with simulated annealing in timetabling. The aim of this approach is to both\nimprove the speed at which an optimal solution can be found and at the same time utilize the\nbenefits of this technique in avoiding the trap of local optima. In addition, the Great Deluge\ngenerally can cause the continuous lack of improvement, which means the final solution is same\nwith the initial after the complete execution, which can lead to RL to select only one heuristic\nrepeatedly. Rather than terminating, the extended approach employs reheating in order to relax\nthe boundary condition to allow worse moves to be applied to the current solution. Cooling\ncontinues and the boundary is reduced at a rate according to the remaining length of the run.\nThe initial decay rate of the EGD is used to show how fast the boundary is reduced and\nultimately the condition for accepting worse moves is narrowed. In this paper, we use the halflife decay rate, is the amount of time it takes for half of the amount of substance to decay to\nattempt to reach the optimal solution. The wait parameter is used to invoke the reheat\nmechanism. It can be specified in terms of percentage or number of total moves in the process\n[3].\n4.3.2. Flex-Deluge\nAn extension of the Great Deluge algorithm is \"Flex-Deluge\", where the acceptance of uphill\nmoves depends on a \"flexibility\" coefficient kf (0<= kf<=1). The acceptance rules are outlined\nin Expression (2):\nP\u2032=P + kf (B - P)\n\nwhen P < B\n\nP\u2032=P\n\nwhen P \u2265 B.\n\n(2)\n\nby varying kf, it is possible to obtain an algorithm with characteristics of both the original Great\nDeluge (kf = 1) and greedy Hill-Climbing (kf = 0). This method enables the search procedure to\ndevelop with an adaptive level of strictness of acceptance for each particular move [8]. Thus, in\nthis paper, the flexibility coefficient value for the all data instances can be seen in the Section 5.\n4.3.3. Non-Linear Great Deluge\nAnother extension of GD is non-linear great deluge algorithm (NLGD) in which the acceptance\ncriterion refers to accepting improving and non-improving low-level heuristics depending of the\nperformance of the heuristic and the current water level B. Improving heuristics are always\naccepted while non-improving ones are accepted only if the detriment in quality is less than or\nequal B. The initial water level is usually set to the quality of the initial solution and then\ndecreased by a non-linear function proposed in [17] as follows:\nB = B \u00d7 (exp\u2212\u03b4 (rnd [min, max])) + \u03b2\n\n(3)\n\nThe various parameters in Eq. (3) control the speed and the shape of the water level decay rate.\nParameter \u03b2 influences the shape of the decay rate and it represents the minimum expected\npenalty corresponding to the best solution. The role of parameters min and max is to control the\nspeed of the decay rate. Therefore, for higher values of min and max, the water level decreases\nmore rapidly and hence, improvements to the solution quality are also achieved faster [14]. As\nfar as the author knows, it has been employed only for the university course timetabling\nproblem [5, 13, 14 and 16]. So, this paper is first used and tested for exam timetabling problem.\nThe parameter values are being set not to be specified for all data instances and these are shown\nin table 4.\n\n\f4.4. Three HH Methods for Exam Timetabling Problem\nThe first HH method, RL-EGD has already been proposed and published as our previous job\n[10]. It is capable of producing feasible solutions for all problem instances and comparable\nresults in the literature. Now other two HH methods such as RL-FD and RL-NLGD for exam\ntimetabling problem are implemented and compared with it. The main differences of these three\nHH methods can be seen at the step 10 of the figures 3, 4 and 5.\nRL-EGD\n1. Input: UtilityValue[ 4], noOfHeuristic=4, maxIteration=1000, iterationCount=1,\nLLHs;\n2. Construct Initial Solution\n3. Calculate initial cost function f(S)\n4. Set Initial Boundary Level B= f(S)\n5. Set initial decay Rate \u2022B based on Cooling Parameter\n6. While ( iterationCount<maxIteration)\n7. Choose LLH by using RL ( )\n8. Apply the chosen Heuristic S* on S\n9. Calculate f(S*) // Calculate cost;\n10. ComparedByEGD( );\n{ If f(S*) <= f(S) or (f(S*) <= B Then\nAccept S = S*\nLowerBoundary B = B \u2013 \u2022B\n// Reheat- Mechanism\nIf no improvement in given time T\nReset Boundary Level B0 = f(S)\nSet new decay rate \u2022B based on Secondary\nCooling Parameter\nElse Reject S*;\nOldCost=CurrentCost;\n}\n\nFigure 3. RL-EGD HH framework\nRL-FD\n1. Input: UtilityValue[ 4], noOfHeuristic=4, maxIteration=1000, iterationCount=1,\nLLHs; CurrentCost=0.0,OldCost=0.0;\n2. Coefficient _Kf =0.5 // (0 kf\n1)\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n\nConstruct Initial Solution\nCalculate initial cost function f(S)\nSet Initial Boundary Level: boundaryLevelFD = f(S)\nWhile ( iterationCount<maxIteration)\nChoose LLH by using RL( )\nApply the chosen Heuristic S* on S\nCalculate f(S*) // Calculate cost();\nComparedByFlexD()\n{ IF (CurrentCost<=OldCost||CurrentCost<= boundaryLevelFD)\nthen\nAccept S = S*\nOldCost=CurrentCost+ Coefficient_Kf*(boundaryLevelFDCurrentCost )\nElse\nReject S*;\nOldCost=CurrentCost;\n}\n\nFigure 4. RL-FD HH framework\n\n\fRL-NLGD\n1.\n2.\n3.\n4.\n5.\n6.\n\nInput: utilityValue[4],noOfHeuristic=4,maxIteration=1000, iterationCount=1,\nLLHs; CurrentCost, OldCost, \u03b2 =0.0,Bmin =100000, Bmax =300000, \u03b4 =5*10-10\nConstruct Initial Solution\nCalculate initial cost function f(S)\nSet Initial Boundary Level boundaryLevelNLGD=OldCost;\nSet initial decay Rate\nWhile ( iterationCount<maxIteration)\n7. { Choose LLH by using RL ( )\n8.\nApply the chosen Heuristic S* on S\n9.\nCalculate f(S*)\n10. ComparedByNLGD()\n{ If(CurrentCost<=OldCost||CurrentCost<= boundaryLevelNLGD) then\nAccept S = S*\nB = B*(exp\u2212\u03b4 (rnd[min,max]))+\u03b2\nElse Reject S*;\nOldCost=CurrentCost;\n}\n\nFigure 5. RL-NLGD Framework\n\n5. RESULTS AND DISCUSSION\nOur experimental analysis is making on the computer Pentium IV, Dell with the RAM 2GB .We\ntested the three HH methods on 31 instances. These are 13 instances proposed by Carter et al.\nand 18 instances created by instance generator. All of these data instances and random instance\ngenerator can be available from the link: \"http://www.asap.cs.nott.ac.uk/resources/data.shtml.\nEach data instance is executed 10 times as shown in the following table. Each run is performed\nstarting from the same initial configuration. The HH methods are implemented in Java and the\nparameters and environmental settings are as shown in the following table. In the parameter\nsetting, Coefficient_Kf is used in the RL-FD while \u03b2, Bmin , Bmax, \u03b4 are being used in RL-NLGD.\nFor the values of these parameters, we follow the reference [16] because that paper provided the\nbetter results.\nTable 4. Parameter Setting Values\n\nParameters\n\nValue\n\nNumber of runs\n\n10 per each data instances\n\nNumber of Iterations\n\nMaximum Iteration=1000\n\nCoefficient _Kf\n\u03b2\n\n0.5\n0.0\n100000\n\nBmin\n\n\fBmax\n\u03b4\n\n300000\n5*10-10\n\nWait Value for reheat mechanism\n\n25%\n\nLower bound\n\n0.0\n\nUpper Bound\n\n40.0\n\nUtility Value for each low level heuristic\n\n0.75*Upper Bound\n\nTo make a comparison, the Lowest Best Cost is used as the performance criterion for all\nexperiments. According to the objective function, the lowest the cost, the better the timetable is.\nThe results of lowest best cost for each HH methods are presented in the following graphs.\nThe figure 6 shows the comparison of the Lowest Best Cost on small 9 data instances. At the\nsame time, the figure 7 shows the comparison on large 9 data instances. Although there is no\nsignificant difference in the cost values of three HH methods in each dataset, it is observed that\nRL-EGD can provide the lowest best cost in small five data sets whereas the other two HH\nmethods, RL-FD and RL-NLGD can produce the lowest cost in two datasets. Likewise, it is\nobserved that RL-EGD can also provide the lowest best cost in large five data sets. The figure 8\nshows the comparison for 5 data instances from the Carter's Datasets. We choose these data\ninstances by randomly. Here, because of the reheat mechanism of the RL-EGD, it can also\nproduce much lower costs in three instances than those by other two HH methods. In these\nfigure, the symbol star shows the data instance got the lowest best cost by RL-EGD HH\napproach.\n\nFigure 6. Comparison of Three HH methods on Small 9 Data Instances generated by Random\nGenerator\n\n\fFigure 7. Comparison of Three HH methods on 9 large data instances generated by Random\nGenerator\n\nFigure 8. Comparison of three HH methods on 5 data instances from Carter's Dataset\n\n\fFigure 9. Comparison of Average Lowest Best Cost\nFor another comparison, the figure 9 represents the comparison of average lowest cost of all\nsmall data instances. Among three HH methods, it can be seen that RL-EGD methods has\nachieved the lowest average best cost in most of the data instances except the SP25.exm and\nSP15.exm. In figures, X axis shows the data instances names while Y axis is being representing\nthe lowest cost of the best solution.\n\n6. CONCLUSION\nHyper heuristics have been starting to prove themselves as fast and effective methods for\nsolving complex real world optimization problems. Therefore, the RL-EGD HH method is also\nproposed as our first job and also achieves the better solutions for the problem domain. Now, as\nthe next step, we have made a comparison it with two other HH methods. From the\nexperiments, it can be concluded that the method RL-EGD can provide the lowest best cost for\nmost of the data instances and compare with the other methods in the literature. To be able to\nschedule invigilators such as professors, doctors and teaching assistant to proctor the scheduled\nexams, as the future work, another enhancement would be to integrate this system with the\ninvigilation timetabling system.\n\nAcknowledgements\nI would like to express my gratitude to my rector, Dr. Ni Lar Thein, and all of my honourable\nteachers who check my grammar errors and provide valuable suggestions and guidance.\n\n\fREFERENCES\n[1]\n\nB. Bilgin, E. Ozcan, & Korkmaz E. E.(2007), \"An experimental study on hyper\nheuristic and exam timetabling\", In(PATAT'06)(LNCS 67,pp.394-412).\n\n[2]\n\nB. Bullnheimer, \"An Examination Scheduling Model to Maximize Students' Study\nTime\", Practice And Theory of Automated Timetabling (PATAT's 97), August 1997,\nToronto\n\n[3]\n\nB. McCollum, P.J. McMullan, A. J. Parkes, E.K. Burke, S. Abdullah, \"An Extended\nGreat Deluge Approach to the Examination Timetabling Problem \" , MISTA,2009.\n\n[4]\n\nC. Pramodh and V. Ravi, \" Modified Great Deluge Algorithm based Auto Associated\nNeural Network for Bankruptcy Prediction in Banks\", International Journal of\nComputer Intelligence Reserach, ISSN 097-1873 Vol.3, No.4(2007), pp. 363-370\n\n[5]\n\nDario Landa-Silva and Joe Henry Obit, \"Evolutionary Non-linear Great Deluge for\nUniversity Course Timetabling\"\n\n[6]\n\nE. Burke, G. Kendall, E. Soubeiga. \"A tabu-search hyper heuristic for timetabling and\nroistering\", Journal of Heuristic, 9:451-470, 2003.\n\n[7]\n\nE. K. Burke, Kendall Graham and R. Ozcan,\" Hyper Heuristics: A Survey of the State\nof the Art\". Journal of the Operational Research Society, Palgrave Macmillan.\n\n[8]\n\nE. K. Burke, Y. Bykov, \"Solving Exam Timetabling Problems with Flex-Deluge\nAlgorithm\", PATAT 2006, pp. 370-372. ISBN 80-210-3726-1.\n\n[9]\n\nE. Ozcan, M. Misir, G. Ochoa, E. K. Burke , \"A reinforcement learning- great deluge\nhyper heuristic for Examination Timetabling\" , In: Journal of Applied Met heuristic\nComputing, 1(1), 39-59, January-March 2010.\n\n[10]\n\nES Sin, \"Reinforcement Learning with EGD based Hyper Heuristic System for Exam\nTimetabling Problem\", In: Proceedings of the IEEE-CCIS 2011.\n\n[11]\n\nE. Soubeiga. \"Development and application of hyper heuristic to personnel scheduling.\"\nPhD thesis, School of Computer Science, University on Nottingham, UK, 2003.\n\n[12]\n\nGabriela Serban , \" A new reinforcement learning algorithm\", STUDIA UNIV.\nBABES-BOLYAI, INFOMATICA, Volume XLVIII, Nubmer 1,2003.\n\n[13]\n\nH. J. Obit, D. Landa-Silva,D. Quelhadj , M. Sevaux, \"Non-Linear Great Deluge with\nlearning Mechanism for Solving the Course Timetabling Problem\", MIC-2009: The\nVIII Meta-heuristic International Conference.\n\n[14]\n\nJoe Henry Obit et al.,\"Non Linear Great Deluge with Reinforcement Learning for\nUniversity Course Timetabling\".\n\n[15]\n\nK. Leslie and Michael L. Littman, \"Reinforcement learning: A Survey\", Journal of\nArtificial Intelligence Research 4 (1996) 237-285.\n\n[16]\n\nLanda-Silva, Obit, H.H: \"Great Deluge with Nonlinear Decay Rate for Solving Course\nTimetabling Problem\", In: Proceedings of the 2008 IEEE Conference on Intelligent\nSystem (IS 2008), pp. 8.11-8.18. IEEE Press, Los Almitos (2008)\n\n\f[17]\n\nM. Carter and G. Laporte:\" Recent Developments in Practical Exam Timetabling\". In:\nBurke E.K and Ross P. (eds.): (PATAT95) Lectures Notes in Computer Science 1153,\n3-21, 1996.\n\n[18]\n\nNabil Nahas, Mustapha Nourelfath and Daoud Ait-Kadi,\" Iterated Great Deluge for the\nDynamic Facility Layout Problem\", in May, 2010.\n\n[19]\n\nY. Bykov,\"Time-Predefined and Trajectory-Based Search: Single and Multiobjective\nApproaches to Exam Timetabling\", 2003.\n\nAuthors\nEi Shwe, Sin\nPh.D(IT) Research Student\nUniversity of Computer Studies, Yangon\n\n\f"}