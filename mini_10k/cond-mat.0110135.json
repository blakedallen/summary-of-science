{"id": "http://arxiv.org/abs/cond-mat/0110135v2", "guidislink": true, "updated": "2003-05-08T15:19:58Z", "updated_parsed": [2003, 5, 8, 15, 19, 58, 3, 128, 0], "published": "2001-10-07T23:41:47Z", "published_parsed": [2001, 10, 7, 23, 41, 47, 6, 280, 0], "title": "How fundamental is the character of thermal uncertainty relations?", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0110447%2Ccond-mat%2F0110346%2Ccond-mat%2F0110446%2Ccond-mat%2F0110165%2Ccond-mat%2F0110035%2Ccond-mat%2F0110362%2Ccond-mat%2F0110197%2Ccond-mat%2F0110004%2Ccond-mat%2F0110657%2Ccond-mat%2F0110450%2Ccond-mat%2F0110655%2Ccond-mat%2F0110252%2Ccond-mat%2F0110267%2Ccond-mat%2F0110211%2Ccond-mat%2F0110303%2Ccond-mat%2F0110040%2Ccond-mat%2F0110585%2Ccond-mat%2F0110380%2Ccond-mat%2F0110488%2Ccond-mat%2F0110413%2Ccond-mat%2F0110085%2Ccond-mat%2F0110540%2Ccond-mat%2F0110580%2Ccond-mat%2F0110105%2Ccond-mat%2F0110223%2Ccond-mat%2F0110396%2Ccond-mat%2F0110643%2Ccond-mat%2F0110361%2Ccond-mat%2F0110140%2Ccond-mat%2F0110606%2Ccond-mat%2F0110496%2Ccond-mat%2F0110072%2Ccond-mat%2F0110406%2Ccond-mat%2F0110201%2Ccond-mat%2F0110224%2Ccond-mat%2F0110294%2Ccond-mat%2F0110646%2Ccond-mat%2F0110426%2Ccond-mat%2F0110240%2Ccond-mat%2F0110262%2Ccond-mat%2F0110605%2Ccond-mat%2F0110544%2Ccond-mat%2F0110344%2Ccond-mat%2F0110474%2Ccond-mat%2F0110341%2Ccond-mat%2F0110198%2Ccond-mat%2F0110221%2Ccond-mat%2F0110073%2Ccond-mat%2F0110254%2Ccond-mat%2F0110504%2Ccond-mat%2F0110394%2Ccond-mat%2F0110428%2Ccond-mat%2F0110121%2Ccond-mat%2F0110382%2Ccond-mat%2F0110108%2Ccond-mat%2F0110018%2Ccond-mat%2F0110373%2Ccond-mat%2F0110027%2Ccond-mat%2F0110063%2Ccond-mat%2F0110439%2Ccond-mat%2F0110307%2Ccond-mat%2F0110342%2Ccond-mat%2F0110263%2Ccond-mat%2F0110236%2Ccond-mat%2F0110531%2Ccond-mat%2F0110216%2Ccond-mat%2F0110117%2Ccond-mat%2F0110386%2Ccond-mat%2F0110515%2Ccond-mat%2F0110584%2Ccond-mat%2F0110164%2Ccond-mat%2F0110102%2Ccond-mat%2F0110098%2Ccond-mat%2F0110393%2Ccond-mat%2F0110490%2Ccond-mat%2F0110559%2Ccond-mat%2F0110150%2Ccond-mat%2F0110114%2Ccond-mat%2F0110369%2Ccond-mat%2F0110366%2Ccond-mat%2F0110056%2Ccond-mat%2F0110096%2Ccond-mat%2F0110257%2Ccond-mat%2F0110551%2Ccond-mat%2F0110011%2Ccond-mat%2F0110626%2Ccond-mat%2F0110213%2Ccond-mat%2F0110334%2Ccond-mat%2F0110166%2Ccond-mat%2F0110560%2Ccond-mat%2F0110588%2Ccond-mat%2F0110529%2Ccond-mat%2F0110101%2Ccond-mat%2F0110352%2Ccond-mat%2F0110338%2Ccond-mat%2F0110210%2Ccond-mat%2F0110030%2Ccond-mat%2F0110135%2Ccond-mat%2F0110521%2Ccond-mat%2F0110563%2Ccond-mat%2F0110399&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "How fundamental is the character of thermal uncertainty relations?"}, "summary": "We show that thermodynamic uncertainties do not preserve their form if the\nunderlying probability distribution is transformed into an escort one.\nHeisenberg's relations, on the other hand, are not affected by such\ntransformation. We conclude therefore that the former uncertainty cannot be as\nfundamental as the quantum one.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0110447%2Ccond-mat%2F0110346%2Ccond-mat%2F0110446%2Ccond-mat%2F0110165%2Ccond-mat%2F0110035%2Ccond-mat%2F0110362%2Ccond-mat%2F0110197%2Ccond-mat%2F0110004%2Ccond-mat%2F0110657%2Ccond-mat%2F0110450%2Ccond-mat%2F0110655%2Ccond-mat%2F0110252%2Ccond-mat%2F0110267%2Ccond-mat%2F0110211%2Ccond-mat%2F0110303%2Ccond-mat%2F0110040%2Ccond-mat%2F0110585%2Ccond-mat%2F0110380%2Ccond-mat%2F0110488%2Ccond-mat%2F0110413%2Ccond-mat%2F0110085%2Ccond-mat%2F0110540%2Ccond-mat%2F0110580%2Ccond-mat%2F0110105%2Ccond-mat%2F0110223%2Ccond-mat%2F0110396%2Ccond-mat%2F0110643%2Ccond-mat%2F0110361%2Ccond-mat%2F0110140%2Ccond-mat%2F0110606%2Ccond-mat%2F0110496%2Ccond-mat%2F0110072%2Ccond-mat%2F0110406%2Ccond-mat%2F0110201%2Ccond-mat%2F0110224%2Ccond-mat%2F0110294%2Ccond-mat%2F0110646%2Ccond-mat%2F0110426%2Ccond-mat%2F0110240%2Ccond-mat%2F0110262%2Ccond-mat%2F0110605%2Ccond-mat%2F0110544%2Ccond-mat%2F0110344%2Ccond-mat%2F0110474%2Ccond-mat%2F0110341%2Ccond-mat%2F0110198%2Ccond-mat%2F0110221%2Ccond-mat%2F0110073%2Ccond-mat%2F0110254%2Ccond-mat%2F0110504%2Ccond-mat%2F0110394%2Ccond-mat%2F0110428%2Ccond-mat%2F0110121%2Ccond-mat%2F0110382%2Ccond-mat%2F0110108%2Ccond-mat%2F0110018%2Ccond-mat%2F0110373%2Ccond-mat%2F0110027%2Ccond-mat%2F0110063%2Ccond-mat%2F0110439%2Ccond-mat%2F0110307%2Ccond-mat%2F0110342%2Ccond-mat%2F0110263%2Ccond-mat%2F0110236%2Ccond-mat%2F0110531%2Ccond-mat%2F0110216%2Ccond-mat%2F0110117%2Ccond-mat%2F0110386%2Ccond-mat%2F0110515%2Ccond-mat%2F0110584%2Ccond-mat%2F0110164%2Ccond-mat%2F0110102%2Ccond-mat%2F0110098%2Ccond-mat%2F0110393%2Ccond-mat%2F0110490%2Ccond-mat%2F0110559%2Ccond-mat%2F0110150%2Ccond-mat%2F0110114%2Ccond-mat%2F0110369%2Ccond-mat%2F0110366%2Ccond-mat%2F0110056%2Ccond-mat%2F0110096%2Ccond-mat%2F0110257%2Ccond-mat%2F0110551%2Ccond-mat%2F0110011%2Ccond-mat%2F0110626%2Ccond-mat%2F0110213%2Ccond-mat%2F0110334%2Ccond-mat%2F0110166%2Ccond-mat%2F0110560%2Ccond-mat%2F0110588%2Ccond-mat%2F0110529%2Ccond-mat%2F0110101%2Ccond-mat%2F0110352%2Ccond-mat%2F0110338%2Ccond-mat%2F0110210%2Ccond-mat%2F0110030%2Ccond-mat%2F0110135%2Ccond-mat%2F0110521%2Ccond-mat%2F0110563%2Ccond-mat%2F0110399&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We show that thermodynamic uncertainties do not preserve their form if the\nunderlying probability distribution is transformed into an escort one.\nHeisenberg's relations, on the other hand, are not affected by such\ntransformation. We conclude therefore that the former uncertainty cannot be as\nfundamental as the quantum one."}, "authors": ["F. Pennini", "A. Plastino", "A. R. Plastino", "M. Casas"], "author_detail": {"name": "M. Casas"}, "author": "M. Casas", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/S0375-9601(02)01163-5", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/cond-mat/0110135v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cond-mat/0110135v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "4 pages, no figures", "arxiv_primary_category": {"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cond-mat/0110135v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cond-mat/0110135v2", "journal_reference": "Physics Letters A 302, 156 (2002)", "doi": "10.1016/S0375-9601(02)01163-5", "fulltext": "arXiv:cond-mat/0110135v2 [cond-mat.stat-mech] 8 May 2003\n\nHow fundamental is the character of thermal uncertainty\nrelations?\nF. Pennini\u2217 , A. Plastino\u2020 , and A. R. Plastino\u2021\nNational University La Plata (UNLP) & Argentine National Research Council (CONICET)\nC.C. 727, 1900 La Plata, Argentina\n\nAbstract\nWe show that thermodynamic uncertainties do not preserve their form if the\nunderlying probability distribution is transformed into an escort one. Heisenberg's relations, on the other hand, are not affected by such transformation.\nWe conclude therefore that the former uncertainty cannot be as fundamental\nas the quantum one.\nKEYWORDS: Fisher information, power-law distributions, escort probabilities, thermal uncertainty.\n02.50.-r, 89.70.+c, 02.50.Wp, 05.30.Ch\n\nTypeset using REVTEX\n\n\u2217 e-mail:\n\npennini@venus.fisica.unlp.edu.ar\n\n\u2020 Corresponding\n\u2021 e-mail:\n\nAuthor, e-mail: plastino@venus.fisica.unlp.edu.ar\n\nplastino@sinectis.com.ar\n\n1\n\n\fI. INTRODUCTION\n\nThermodynamics \"uncertainty\" relations have been the subject of much interesting work\nover the years (see, for instance, [1\u20133]). An excellent, recent review is that of Uffink & van\nLith [4]. We will be interested here in these uncertainty relations insofar as they are derived\nby recourse to statistical inference [5], with emphasis upon Mandelbrot's results [2].\nHeisenberg's uncertainty relations and Bohr's complementarity principle constitute two\npillars of 20-th century science. These two prominent authors have suggested that there is\na classical analogue of the complementarity principle, specifically between temperature and\nenergy [6]. Although such ideas have not received general acceptation, several renowned\nauthors have defended them, as exemplified by, among others, Refs. [1\u20133]. These claims\nremain still controversial (see [4,7,8]).\nWe wish in this Communication to add a footnote to the controversy by focusing attention upon particular aspects of the thermal uncertainty derivation of Mandelbrot's [2]. This\nderivation contains as an essential ingredient the information measure introduced by Fisher\nin the twenties [5,9].\nMandelbrot [2] is one of the first authors that linked statistical physics with the theory\nof statistical inference, adopting the viewpoint that one can work in statistical mechanics directly with probability distributions over macroscopic variables, the microscopic substructure\n(e.g., phase space) being largely superfluous. Let U denote the internal energy. Mandelbrot\n[2] established which is the form of the probability distribution p\u03b3 (U) that allows for an\nadequate description of the energy fluctuations of a system in contact with a heat bath at\nthe (inverse) temperature \u03b3 = 1/T . The ensuing distribution turns out to be the celebrated,\ntext-book (Gibbs') canonical one [10], an exponential probability density. A quite interesting uncertainty relation between mean energy and inverse temperature is then obtained (see\nbelow). A main protagonist in his treatment is Fisher's information measure [5,9,11,12].\nNow, power-law distributions are ubiquitous in physics, critical phenomena being a conspicuous example [13]. In a statistical mechanics' context they arise quite naturally if the\n2\n\n\finformation measure one maximizes (subject to appropriate constraints) in order to arrive\nat the equilibrium distribution is not Shannon's one but a generalized one. A lot of work in\nthis respect has been devoted to Tsallis' measure (see [14\u201319] and references therein).\nIn view of the importance of these results it should seem appropriate to revisit the FisherMandelbrot link by taking a closer look at non-exponential distributions of the power-law\nkind. The ensuing results will offer novel insights into the meaning of non-extensivity:\nFisher's measure involves all energy moments. Some new features of the thermal uncertainty\nsubject will also be revealed. We proceed first to a brief reminder of Fisher-related concepts.\n\nII. A BRIEF FISHER PRIMER\n\nEstimation theory [20] provides one with a powerful result that needs to be quoted\nbefore embarking into the present discussion. Consider a system that is specified by a\nphysical parameter \u03b8. Let x be a stochastic variable and p\u03b8 (x) the probability density for\nthis variable, which depends on the parameter \u03b8. An observer makes a measurement of x\nand has to best infer \u03b8 from this measurement, calling the resulting estimate \u03b8\u0303 = \u03b8\u0303(x). One\nwonders how well \u03b8 can be determined. Estimation theory asserts [20] that the best possible\nestimator \u03b8\u0303(x), after a very large number of x-samples is examined, suffers a mean-square\nerror e2 from \u03b8 that obeys a relationship involving Fisher's I, namely, Ie2 = 1, where the\nFisher information measure I is of the form\nI=\n\nZ\n\ndx p\u03b8 (x)\n\n(\n\n\u2202p\u03b8\n\u2202\u03b8\n\np\u03b8 (x)\n\n)2\n\n=\n\n*\"\n\n1 \u2202p\u03b8\np\u03b8 (x) \u2202\u03b8\n\n#2 +\n\n.\n\n(1)\n\nThis \"best\" estimator is called the efficient estimator. Any other estimator must have\na larger mean-square error. The only proviso to the above result is that all estimators be\nunbiased, i.e., satisfy h\u03b8\u0303(x)i = \u03b8.\nThus, Fisher's information measure has a lower bound, in the sense that, no matter what\nparameter of the system we choose to measure, I has to be larger or equal than the inverse\nof the mean-square error associated with the concomitant experiment. This result, i.e.,\n3\n\n\fI e2 \u2265 1,\n\n(2)\n\nis referred to as the Cramer-Rao (CR) bound, and constitutes a very powerful statistical\nresult [5]. Applications of Fisher's information measure to different physical problems have\nproliferated in the last 12 years (see details and references in Frieden's book [5]).\n\nIII. THE THERMAL UNCERTAINTY RELATION\n\nMandelbrot [2] has established which is the form of the probability distribution p\u03b3 (U)\nthat allows for an adequate description of the energy fluctuations of a system in contact\nwith a heat bath at the (inverse) temperature \u03b3 = 1/T . It is required that estimators for \u03b3\nshould be functions of the energy U only [4] (one demands sufficiency of the estimator [4]).\nWe are led to the canonical distribution\np\u03b3 (U) = g(U)\nwith Z(\u03b3) =\n\nR\n\ne\u2212\u03b3U\n,\nZ(\u03b3)\n\n(3)\n\ndUg(U)e\u2212\u03b3U the partition function and g(U) the structure function, which\n\nwould be interpreted as a measure of the number of microscopic states compatible with\nenergy U [4].\nLet us address the question of estimating the unknown parameter \u03b3 of the system by\nmeasurements of the energy. In this case the Fisher information reads [4]\nI(\u03b3) = (\u2206\u03b3 U)2 = hU 2 i\u03b3 \u2212 hUi2\u03b3 .\n\n(4)\n\nThe CR inequality for unbiased estimators \u03b3\u0303 then yields\n\u2206\u03b3 U\u2206\u03b3\u0303 \u2265 1,\n\n(5)\n\nwhich is Mandelbrot's uncertainty relation between energy and temperature, expressing that\nthe efficiency with which temperature can be estimated is bounded by the spread in energy.\nThis does not entail that the temperature does really fluctuate. It is assumed throughout that\nthe distribution function (3) with fixed \u03b3 provides one with an adequate description. Instead,\n4\n\n\fthe estimators are fluctuating, random quantities. Their standard deviation is employed as\na criterion to indicate the quality with which the inverse temperature is estimated [4].\nWe can translate the preceding considerations into a microscopic, statistical mechanics' language as follows: i) you start with a system in contact with a heath bath at the\ntemperature T , described by Gibbs' canonical distribution (3), ii) role switch: regard the\nassociated inverse temperature (originally a variational Lagrange multiplier in the entropy\nmaximization process [21,22]) as an estimator, iii) consider the Fisher information for (3)\ntogether with its associated CR bound and then, iv) you get a thermal uncertainty relation\nfrom this CR bound.\n\nIV. MOTIVATION FOR REVISITING THE THERMAL UNCERTAINTY\nDERIVATION\n\nThe point we wish to make here is that the above referred to heath bath, employed in\nMandelbrot's derivation, cannot be a finite one. It is shown in [17] that if one attempts to\nrepeat Gibbs' celebrated derivation [10] for the probability distribution (PD) that maximizes\nentropy for a system in contact with a finite heath bath at the inverse temperature \u03b2, the\nensuing PD is not Gibbs canonical distribution for the internal energy U. Instead, one is\nforced to deal with the power-law distribution [17]\np(U) =\n\n1\n1\n[1 \u2212 \u03b2(1 \u2212 q)U] 1\u2212q ; q \u2208 R,\nZq\n\n(6)\n\nwhere Zq is a normalization constant (the partition function). For q = 1 the above qprobability distribution becomes Gibbs' canonical one. The distribution (6) maximizes the\nso-called Tsallis information measure Sq , whose main feature is that of being non-extensive\nif q 6= 1: for two independent systems A, B the entropy composition rule is [14,15]\nSq (A + B) = Sq (A) + Sq (B) + (1 \u2212 q)Sq (A)Sq (B).\n\n(7)\n\nRemember that one of the fundamental tenets of information theory is that of assigning an information content (Shannon's measure) to any normalized probability distribution.\n5\n\n\fThe whole of statistical mechanics can be elegantly re-formulated by extremization of this\nmeasure, subject to the constraints imposed by the a priori information one may possess concerning the system of interest [21,22]. It has been shown in the last decade (see, for instance\n[14\u201316,18,19] and references therein) that a parallel process can be undertaken with reference\nto Tsallis' measure, giving rise to what is called non-extensive Tsallis' thermostatistics, responsible for the successful description of an ample variety of phenomena that cannot be\nexplained by appeal to the conventional, extensive one (that of Boltzmann-Gibbs) [14,15].\nIt is shown in [17] that a system in contact with a finite bath is properly described\nby a distribution of the type (6). The canonical distribution obtains only in the limit\nin which the heath bath becomes infinite [17]. In order to repeat the steps described in\nclosing the preceding Section when the protagonist is a power-law PD, one needs to evaluate\nthe associated Fisher measure. What happens then with the associated, putative thermal\nuncertainty? Will it remain operative? We show below that it will NOT. This entails that\nthe thermal uncertainty cannot be a fundamental physical property. Our task is not a trivial\none, as the content of the following section will show.\n\nV. FISHER MEASURE FOR A POWER-LAW DISTRIBUTION\n\nWe discuss here two different information measures of the Tsallis type, and their associated probability distributions, in order to repeat the steps outlined previously (last paragraph of Section III) that led to a thermal uncertainty relation for exponential distributions.\nWe deal first with the original Tsallis measure and discuss afterwards the concept of escort\ndistribution.\n\nA. Original Tsallis measure\n\nWe start with\n1\n\np\u03b2 (U(x)) \u2261 p\u03b2 (x) = Zq\u22121 [1 \u2212 (1 \u2212 q)\u03b2U(x)] 1\u2212q ,\n6\n\n(8)\n\n\fwhere \u03b2 is a variational Lagrange multiplier and Zq is the accompanying partition function\n(as we sum over microstates no structure constant is needed [23])\nZq =\n\nZ\n\n1\n\ndx [1 \u2212 (1 \u2212 q)\u03b2U(x)] 1\u2212q .\n\n(9)\n\nWe effect now the just mentioned role-switch with regards to the meaning of the parameter\n\u03b2 by introduction of the probability distribution (8) into I: \u03b2 plays the same role as \u03b3 above.\nIt becomes an estimator:\nI=\n\nZ\n\ndx p\u03b2 (x)\n\n\u22121\n\n\"\n\n\u2202p\u03b2 (x)\n\u2202\u03b2\n\n#2\n\n,\n\n(10)\n\nAccording to Tsallis' tenets [14] i) (Tsallis' cut-off)\n(1 \u2212 q)\u03b2U(x) \u2264 1,\nguaranteeing non-negative probabilities and ii) one computes mean-values according to\nhUiq =\n\nZ\n\ndxpq\u03b2 U(x).\n\n(11)\n\nFor the sake of an easier notation we shall omit, herefrom, writing down explicitly the\nvariable x. We need to evaluate the integrand of Eq. (10). By using (8) one finds that\n\u2202Zq\n\u2202p\u03b2\n= \u2212pq\u03b2 UZqq\u22121 \u2212 p\u03b2 Zq\u22121\n\u2202\u03b2\n\u2202\u03b2\n\n(12)\n\n\u2202Zq\n= \u2212Zqq hUiq .\n\u2202\u03b2\n\n(13)\n\nand by (9)\n\nAs a consequence, one has, for the integrand in (10)\np\u22121\n\u03b2\n\n\u2202p\u03b2\n\u2202\u03b2\n\n!2\n\nh\n\ni\n\n= Zq2(q\u22121) p\u03b22q\u22121 U 2 + p\u03b2 hUi2q \u2212 2pq\u03b2 UhUiq ,\n\n(14)\n\nso that, when the above relation is replaced into (10), we arrive at\nh\n\ni\n\nI = Zq2(q\u22121) hp\u03b2q\u22121U 2 iq \u2212 hUi2q .\nBy suitably manipulating Eq. (8), it is now easy to see that\n7\n\n(15)\n\n\fp\u03b2q\u22121 Zqq\u22121 = [1 \u2212 (1 \u2212 q)\u03b2U]\u22121 ,\n\n(16)\n\nwhich allows one to write, for the product of the first two factors in the first term on the\nright hand side above,\nZq2(q\u22121) p\u03b22q\u22121 = p\u03b2 [1 \u2212 (1 \u2212 q)\u03b2U]\u22122 .\n\n(17)\n\nLimiting ourselves to q\u2212values such that |q| < 1, one can expand the last expression\ninto a power series in (1 \u2212 q)\u03b2 (the convergence of the series is assured because of Tsallis'\ncut-off):\np\u03b22q\u22121\n\nZq2(q\u22121)\n\n= p\u03b2\n\n\u221e\nX\n\n(n + 1)(1 \u2212 q)n \u03b2 n U n .\n\n(18)\n\nn=0\n\nInserting this into the first term of the r.h.s of Eq. (15) one finally gets\nI=\n\n\u221e\nX\n\n(n + 1)(1 \u2212 q)n \u03b2 n \u03bdn+2 \u2212 Zq2(q\u22121) hUi2q ,\n\n(19)\n\nn=0\n\nwhere \u03bdn+2 = hU n+2 iq=1 , is the n + 2 \u2212 th order momentum of the probability distribution\n[20].\nIt is time to give now to the last term of Eq. (19) the form of a momentum expansion.\nWe note first that\nhUi2q Zq2(q\u22121) = [hZqq\u22121 Uiq ]2\n\n(20)\n\nwhich, because of (16) can be cast as\nD\n\nhZqq\u22121 Uiq = U[1 \u2212 (1 \u2212 q)\u03b2U]\u22121\n\nE\n\nq=1\n\n.\n\n(21)\n\nThus, a power-series expansion in (1 \u2212 q)\u03b2 plus Cauchy's series' multiplication rule yield\n\nhUi2q Zq2(q\u22121) =\n\n\u221e\nX\n\n(1 \u2212 q)n \u03b2 n\n\nn=0\n\nn\nX\n\n\u03bdk+1 \u03bdn\u2212k+1 ,\n\nk=0\n\nand, finally\nI=\n\n\u221e\nX\n\nn n\n\n(1 \u2212 q) \u03b2\n\nn=0\n\n\"\n\n\u03bdn+2 \u2212\n\nn\nX\n\nk=0\n\n8\n\n#\n\n\u03bdk+1 \u03bdn\u2212k+1 ,\n\n(22)\n\n\fthat involves cross-correlation terms. We would like to establish now an \u00e0 la Mandelbrot\nuncertainty (5). This turns out to be impossible! We cannot define a generalized uncertainty\nthat assimilates the second order U-momentum to I, because the quantity I contains a sum\nof terms in powers of the estimator \u03b2. This negative result implies that thermal uncertainties\nare not operative for finite baths, only for (unphysical) infinite ones.\n\nB. A Tsallis-like measure: the \"escort\" one\n\nOne may wonder whether the peculiar aspect of the mean values hUiq =\n\nR\n\ndxpq\u03b2 U(x)\n\nmay not be responsible for the failure we have just detected. We will repeat now the above\nsteps using ordinary, linear mean values. At this point we introduce the useful concept of\nescort probabilities (see [24] and references therein). One introduces the transformation\npq\u03b2 (x) \u2192 P\u03b2 (x),\n\n(23)\n\nwith\nP\u03b2 (x) =\n\nR\n\npq\u03b2 (x)\n,\ndxpq\u03b2 (x)\n\n(24)\n\nq being any real parameter. Here, of course, p\u03b2 (x) is given by (8). For q = 1 we have P\u03b2 \u2261 p\u03b2\nand, obviously, P\u03b2 is normalized to unity. Our main theme here is that any fundamental\nphysical law must be invariant under the above transformation.\nGeneral global quantities formed with escort distributions of different order q, such as\nthe different types of information or mean values, will give more revealing information than\nthose formed with the original distribution only. Changing q is indeed a tool for scanning the\nstructure of the original distribution [24]. However, basic relationships among expectation\nvalues, like, say, Ehrenfest theorem, are invariant under the escort transformation.\n\n1. Heisenberg's uncertainty relations are invariant under (23)\n\nWe start with usual coordinate-momentum relation\n9\n\n\f\u2206xb\u2206pb \u2265\n\nwhere\n\nh\u0304\n2\n\n(25)\n\n(\u2206xb)2 = hxb2 i \u2212 hxbi2\n\n(26)\n\nb\nwhile a similar expression for the momentum fluctuation \u2206p.\n\nExpectation values of operators general Ab are defined as customary\nb = T r(\u03c1bA)\nb\nhAi\n\n(27)\n\nwhere \u03c1b is, of course, the density (or statistical) operator.\nUnder the transformation (23) we have\n\u03c1b \u2192\n\nso that\n\nwhich entails\n\nb\nT r(\u03c1bA)\n\n\u03c1bq\nb\n\u2261\u03a9\nT r(\u03c1bq )\n\n\u03c1bq Ab\n\u2192 Tr\nT r(\u03c1bq )\n\n!\n\nb A),\nb\n\u2261 T r(\u03a9\n\nb \u2192 hAi\nb\nb b\nhAi\nesc \u2261 T r(\u03a9A),\n\n(28)\n\n(29)\n\n(30)\n\ni.e.,\n\u2206xb(esc) \u2206pb(esc) \u2265\n\nwith\n\u0010\n\nand analogously for \u2206pb(esc) .\n\n\u2206xb(esc)\n\n\u00112\n\nh\u0304\n2\n\n= hxbi2esc \u2212 hxb2 iesc ,\n\nThe form of Heisenberg's principle remains invariant under (23).\n\n10\n\n(31)\n\n(32)\n\n\f2. Thermal uncertainty is not invariant under (23)\n\nDi Sisto et al. have shown [25] that one can develop an alternative non-extensive thermostatistics that employs an information measure SP P = SP P [P\u03b2 ] which is a functional of\nthe escort distribution of order q. SP P depends upon the escort PD in the same manner as\nTsallis' measure depends on the original distribution. The associated mean values are linear\nin the probabilities. In our case\nhUiesc =\n\nZ\n\ndx P\u03b2 (x) U(x).\n\n(33)\n\nWe face now an \"escort\" Fisher's measure\nI=\n\nZ\n\ndx P\u03b2 (x)\n\n\u22121\n\n\"\n\n\u2202P\u03b2 (x)\n\u2202\u03b2\n\n#2\n\n.\n\n(34)\n\nFor our purposes we need to evaluate the integrand in (34). Taking derivatives in (24)\nwe find\n(\n\n*\n\n\u2202p\u03b2\n\u2202p\u03b2\n\u2202P\u03b2\n= q P\u03b2 p\u22121\n\u2212 p\u22121\n\u03b2\n\u03b2\n\u2202\u03b2\n\u2202\u03b2\n\u2202\u03b2\n\n+\n\nesc\n\n)\n\n,\n\n(35)\n\nso that, taking derivatives in (8) one is led to\n\u2202p\u03b2\n\u2202Zq\n= \u2212Zqq\u22121 Upq\u03b2 \u2212 p\u03b2 Zq\u22121\n,\n\u2202\u03b2\n\u2202\u03b2\n\n(36)\n\nand, using the result\n\u2202Zq\n= \u2212Zqq Q hUiesc ,\n\u2202\u03b2\nwhere we have defined Q =\n\nR\n\ndxpq\u03b2 , we get\n\nh\ni\n\u2202p\u03b2\n= \u2212Zqq\u22121 Upq\u03b2 \u2212 p\u03b2 QhUiesc .\n\u2202\u03b2\n\n(37)\n\nReplacement of this relation into (35) leads to\nn\no\n\u2202P\u03b2\n= \u2212qZqq\u22121 P\u03b2 p\u03b2q\u22121 U \u2212 hp\u03b2q\u22121 Uiesc ,\n\u2202\u03b2\n\nand then to\n11\n\n(38)\n\n\fP\u03b2\u22121\n\n\u2202P\u03b2\n\u2202\u03b2\n\n!2\n\nn\n\n2(q\u22121)\n\n= q 2 Zq2(q\u22121) P\u03b2 p\u03b2\n\no\n\nU 2 + hpq\u22121 Ui2esc \u2212 2p\u03b2q\u22121 Uhp\u03b2q\u22121 Uiesc .\n\n(39)\n\nFinally, replacing this into (34), Fisher's information measure acquires the appearance\nI =q\n\n2\n\nZq2(q\u22121)\n\n\u001aD\n\nE\n\n2(q\u22121) 2\np\u03b2\nU\nesc\n\n\u2212\n\nD\n\nE2\np\u03b2q\u22121 U\nesc\n\n\u001b\n\n.\n\n(40)\n\nRecourse to (17) seems to yield now a 2nd order moment. However, it is not a U-moment\nbut one of the \"effective\" energy\nE = U/[1 \u2212 (1 \u2212 q)\u03b2U],\ni.e.,\nq \u22122 I = \u03bcE \u2261 hE 2 iesc \u2212 hEi2esc ,\n\n(41)\n\nso that the Cramer-Rao bound gives\n\u03bcE \u2206\u03b2 \u2265 q \u22122 .\n\n(42)\n\nAppearances are deceptive, though. The above is not an uncertainty relation, because\n\u03b2 enters the two factors in the l.h.s. Indeed, expansion into a (1 \u2212 q)\u03b2-powers series and\nCauchy's rule, where \u03bdk = hU \u03bd iesc is now a generalized momentum of order \u03bd, with \u03bdk,k\u2212n =\n\u03bdk \u03bdn\u2212k , gives\nI=q\n\n2\n\n\u221e\nX\n\n(1 \u2212 q)\n\nn=0\n\nn\u22121 n\u22121\n\n\u03b2\n\n\"\n\n(n + 1)\u03bdn \u2212\n\nn\nX\n\nk=0\n\n#\n\n\u03bdk,k\u2212n ,\n\n(43)\n\nwhich shows again that it is not possible to get a thermal uncertainty relation between U\nand \u03b2.\n\nVI. CONCLUSIONS\n\nAs the main result of this Communication we find that it is impossible to find a thermal\nuncertainty of the type (5) if the underlying probability distribution is not of the exponential\nform. While for such exponential PDs I can be assimilated to the second moment of the\n12\n\n\fenergy, for non-exponential PDs (for instance, of the Tsallis form) the Fisher information\nmeasure becomes a sum over all energy moments that involves all powers of the estimator \u03b2\nas well. This prevents us from re-obtaining the thermal uncertainty relation of Mandelbrot's\nfor non-exponential PDs.\nA physical interpretation of the above circumstance is connected with the type of heath\nbath that helps our system to attain thermal equilibrium. The thermal uncertainty relation only holds for systems in contact with an infinite bath, since only in such a case the\nGibbs canonical distribution strictly applies. For finite baths one needs a Tsallis-canonical\ndistribution, as shown in detailed fashion in [17].\nClearly, the status of the thermal uncertainty relation is thereby affected. It can not be\nregarded as a fundamental property. These facts could constitute a hopefully interesting\nfootnote to the ongoing controversy concerning uncertainty relations in thermodynamics.\n\nVII. ACKNOWLEDGEMENT\n\nF. Pennini thanks financial support from UNLP.\n\n13\n\n\fREFERENCES\n[1] L. Rosenfeld, in Ergodic theories, edited by P. Caldirola (Academic Press, NY, 1961).\n[2] B. Mandelbrot, Ann. Math. Stat. 33, 1021 (1962); IRE Trans. Inform. Theory IT-2,\n190 (1956); J. Math. Phys. 5, 164 (1964).\n[3] B. Lavenda, Int. J. Theor. Phys. 26, 1069 (1987); 27, 451 (1988); J. Phys. Chem. Sol.\n49, 685 (1988); Statistical physics: a probabilistic approach (J. Wiley, NY, 1991).\n[4] J. Uffink and J. van Lith, Foundations of Physics 29, 655 (1999).\n[5] B. R. Frieden, Physics from Fisher information (Cambridge University Press, Cambridge, England, 1998).\n[6] N. Bohr, Collected works, edited by J. Kalckar (North-Holland, Amsterdam, 1985),\nVol. 6, pp. 316-330 and 376-377; A. Pais, Niels Bohr's times in physics, philosophy,\nand polity (Clarendon Press, Oxford, 1991).\n[7] C. Kittel, Phys. Today (May 1988) 93.\n[8] B. B. Mandelbrot, Phys. Today (January 1989) 71.\n[9] B. R. Frieden and B. H. Soffer, Phys. Rev. E 52, 2274 (1995).\n[10] J. W. Gibbs, Elementary principles in statistical mechanics (Yale University Press,\n1903).\n[11] A. R. Plastino and A. Plastino, Phys. Rev. E 54, 4423 (1996).\n[12] A. Plastino, A. R. Plastino, and H. G. Miller, Phys. Lett. A 235, 129 (1997).\n[13] N. Goldenfeld, Lectures on phase transitions and the renormalization group (AddisonWesley, NY, 1992).\n[14] C. Tsallis, Braz. J. of Phys. 29, 1 (1999), and references therein.\n[15] A. Plastino and A. R. Plastino, Braz. J. Phys. 29, 50 (1999).\n14\n\n\f[16] C. Tsallis, J. Stat. Phys. 52, 479 (1988).\n[17] A. R. Plastino, A. Plastino, Phys. Lett. A 193, 251 (1994).\n[18] E. M. F. Curado and C. Tsallis, J. Phys. A 24, L69 (1991); Corrigenda: 24, 3187\n(1991) and 25, 1019 (1992).\n[19] A. R. Plastino and A. Plastino, Phys. Lett. A 177, 177 (1993).\n[20] H. Cramer, Mathematical methods of statistics, (Princeton University Press, Princeton,\nNJ, 1946).\n[21] E. T. Jaynes, Phys. Rev. 106, 620 (1957); 108, 171 (1957).\n[22] E. T. Jaynes in Statistical Physics, ed. W. K. Ford (Benjamin, New York, 1963);\nA. Katz, Statistical Mechanics, (Freeman, San Francisco, 1967).\n[23] F. Reif, Statistical and thermal physics (McGraw-Hill, NY, 1965).\n[24] C. Beck and F. Schl\u00f6gl, Thermodynamics of chaotic systems (Cambridge University\nPress, Cambridge, England, 1993).\n[25] R. P. Di Sisto, S. Martinez, R. B. Orellana, A. R. Plastino, and A. Plastino,\nPhysica A 265, 590 (1999).\n\n15\n\n\f"}