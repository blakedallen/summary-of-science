{"id": "http://arxiv.org/abs/quant-ph/0011049v1", "guidislink": true, "updated": "2000-11-13T09:54:00Z", "updated_parsed": [2000, 11, 13, 9, 54, 0, 0, 318, 0], "published": "2000-11-13T09:54:00Z", "published_parsed": [2000, 11, 13, 9, 54, 0, 0, 318, 0], "title": "String Matching in ${\\tilde O}(\\sqrt{n}+\\sqrt{m})$ Quantum Time", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=quant-ph%2F0003082%2Cquant-ph%2F0003131%2Cquant-ph%2F0003117%2Cquant-ph%2F0003017%2Cquant-ph%2F0003070%2Cquant-ph%2F0003064%2Cquant-ph%2F0003098%2Cquant-ph%2F0003015%2Cquant-ph%2F0003090%2Cquant-ph%2F0003102%2Cquant-ph%2F0003091%2Cquant-ph%2F0003081%2Cquant-ph%2F0003093%2Cquant-ph%2F0003146%2Cquant-ph%2F0003114%2Cquant-ph%2F0003076%2Cquant-ph%2F0003027%2Cquant-ph%2F0003058%2Cquant-ph%2F0011125%2Cquant-ph%2F0011037%2Cquant-ph%2F0011050%2Cquant-ph%2F0011018%2Cquant-ph%2F0011085%2Cquant-ph%2F0011011%2Cquant-ph%2F0011119%2Cquant-ph%2F0011059%2Cquant-ph%2F0011120%2Cquant-ph%2F0011033%2Cquant-ph%2F0011117%2Cquant-ph%2F0011055%2Cquant-ph%2F0011049%2Cquant-ph%2F0011100%2Cquant-ph%2F0011074%2Cquant-ph%2F0011051%2Cquant-ph%2F0011102%2Cquant-ph%2F0011028%2Cquant-ph%2F0011030%2Cquant-ph%2F0011019%2Cquant-ph%2F0011075%2Cquant-ph%2F0011023%2Cquant-ph%2F0011056%2Cquant-ph%2F0011042%2Cquant-ph%2F0011008%2Cquant-ph%2F0011092%2Cquant-ph%2F0011076%2Cquant-ph%2F0011062%2Cquant-ph%2F0011089%2Cquant-ph%2F0011124%2Cquant-ph%2F0011081%2Cquant-ph%2F0011103%2Cquant-ph%2F0011058%2Cquant-ph%2F0011009%2Cquant-ph%2F0011027%2Cquant-ph%2F0011036%2Cquant-ph%2F0011084%2Cquant-ph%2F0011014%2Cquant-ph%2F0011082%2Cquant-ph%2F0011021%2Cquant-ph%2F0011079%2Cquant-ph%2F0011024%2Cquant-ph%2F0011072%2Cquant-ph%2F0011064%2Cquant-ph%2F0011122%2Cquant-ph%2F0011046%2Cquant-ph%2F0011054%2Cquant-ph%2F0011045%2Cquant-ph%2F0011098%2Cquant-ph%2F0011097%2Cquant-ph%2F0011066%2Cquant-ph%2F0011016%2Cquant-ph%2F0011105%2Cquant-ph%2F0011069%2Cquant-ph%2F0011032%2Cquant-ph%2F0011110%2Cquant-ph%2F0011115%2Cquant-ph%2F0011044%2Cquant-ph%2F0011061%2Cquant-ph%2F0011071%2Cquant-ph%2F0011099%2Cquant-ph%2F0011093%2Cquant-ph%2F0011091%2Cquant-ph%2F0011002%2Cquant-ph%2F0011106%2Cquant-ph%2F0011080%2Cquant-ph%2F0011039%2Cquant-ph%2F0011112%2Cquant-ph%2F0011025%2Cquant-ph%2F0011121%2Cquant-ph%2F0011077%2Cquant-ph%2F0011078%2Cquant-ph%2F0011012%2Cquant-ph%2F0011116%2Cquant-ph%2F0011041%2Cquant-ph%2F0011065%2Cquant-ph%2F0011070%2Cquant-ph%2F0011007%2Cquant-ph%2F0011101%2Cquant-ph%2F0011005%2Cquant-ph%2F0011104%2Cquant-ph%2F0011095%2Cquant-ph%2F0011123&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "String Matching in ${\\tilde O}(\\sqrt{n}+\\sqrt{m})$ Quantum Time"}, "summary": "We show how to determine whether a given pattern p of length m occurs in a\ngiven text t of length n in ${\\tilde O}(\\sqrt{n}+\\sqrt{m})$\\footnote{${\\tilde\nO}$ allows for logarithmic factors in m and $n/m$} time, with inverse\npolynomial failure probability. This algorithm combines quantum searching\nalgorithms with a technique from parallel string matching, called {\\em\nDeterministic Sampling}.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=quant-ph%2F0003082%2Cquant-ph%2F0003131%2Cquant-ph%2F0003117%2Cquant-ph%2F0003017%2Cquant-ph%2F0003070%2Cquant-ph%2F0003064%2Cquant-ph%2F0003098%2Cquant-ph%2F0003015%2Cquant-ph%2F0003090%2Cquant-ph%2F0003102%2Cquant-ph%2F0003091%2Cquant-ph%2F0003081%2Cquant-ph%2F0003093%2Cquant-ph%2F0003146%2Cquant-ph%2F0003114%2Cquant-ph%2F0003076%2Cquant-ph%2F0003027%2Cquant-ph%2F0003058%2Cquant-ph%2F0011125%2Cquant-ph%2F0011037%2Cquant-ph%2F0011050%2Cquant-ph%2F0011018%2Cquant-ph%2F0011085%2Cquant-ph%2F0011011%2Cquant-ph%2F0011119%2Cquant-ph%2F0011059%2Cquant-ph%2F0011120%2Cquant-ph%2F0011033%2Cquant-ph%2F0011117%2Cquant-ph%2F0011055%2Cquant-ph%2F0011049%2Cquant-ph%2F0011100%2Cquant-ph%2F0011074%2Cquant-ph%2F0011051%2Cquant-ph%2F0011102%2Cquant-ph%2F0011028%2Cquant-ph%2F0011030%2Cquant-ph%2F0011019%2Cquant-ph%2F0011075%2Cquant-ph%2F0011023%2Cquant-ph%2F0011056%2Cquant-ph%2F0011042%2Cquant-ph%2F0011008%2Cquant-ph%2F0011092%2Cquant-ph%2F0011076%2Cquant-ph%2F0011062%2Cquant-ph%2F0011089%2Cquant-ph%2F0011124%2Cquant-ph%2F0011081%2Cquant-ph%2F0011103%2Cquant-ph%2F0011058%2Cquant-ph%2F0011009%2Cquant-ph%2F0011027%2Cquant-ph%2F0011036%2Cquant-ph%2F0011084%2Cquant-ph%2F0011014%2Cquant-ph%2F0011082%2Cquant-ph%2F0011021%2Cquant-ph%2F0011079%2Cquant-ph%2F0011024%2Cquant-ph%2F0011072%2Cquant-ph%2F0011064%2Cquant-ph%2F0011122%2Cquant-ph%2F0011046%2Cquant-ph%2F0011054%2Cquant-ph%2F0011045%2Cquant-ph%2F0011098%2Cquant-ph%2F0011097%2Cquant-ph%2F0011066%2Cquant-ph%2F0011016%2Cquant-ph%2F0011105%2Cquant-ph%2F0011069%2Cquant-ph%2F0011032%2Cquant-ph%2F0011110%2Cquant-ph%2F0011115%2Cquant-ph%2F0011044%2Cquant-ph%2F0011061%2Cquant-ph%2F0011071%2Cquant-ph%2F0011099%2Cquant-ph%2F0011093%2Cquant-ph%2F0011091%2Cquant-ph%2F0011002%2Cquant-ph%2F0011106%2Cquant-ph%2F0011080%2Cquant-ph%2F0011039%2Cquant-ph%2F0011112%2Cquant-ph%2F0011025%2Cquant-ph%2F0011121%2Cquant-ph%2F0011077%2Cquant-ph%2F0011078%2Cquant-ph%2F0011012%2Cquant-ph%2F0011116%2Cquant-ph%2F0011041%2Cquant-ph%2F0011065%2Cquant-ph%2F0011070%2Cquant-ph%2F0011007%2Cquant-ph%2F0011101%2Cquant-ph%2F0011005%2Cquant-ph%2F0011104%2Cquant-ph%2F0011095%2Cquant-ph%2F0011123&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We show how to determine whether a given pattern p of length m occurs in a\ngiven text t of length n in ${\\tilde O}(\\sqrt{n}+\\sqrt{m})$\\footnote{${\\tilde\nO}$ allows for logarithmic factors in m and $n/m$} time, with inverse\npolynomial failure probability. This algorithm combines quantum searching\nalgorithms with a technique from parallel string matching, called {\\em\nDeterministic Sampling}."}, "authors": ["H. Ramesh", "V. Vinay"], "author_detail": {"name": "V. Vinay"}, "author": "V. Vinay", "arxiv_comment": "7 pages Latex2e file", "links": [{"href": "http://arxiv.org/abs/quant-ph/0011049v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/quant-ph/0011049v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "quant-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "quant-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/quant-ph/0011049v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/quant-ph/0011049v1", "journal_reference": null, "doi": null, "fulltext": "\u221a\n\u221a\nString Matching in \u00d5( n + m) Quantum Time\nH. Ramesh\u2217\n\nV. Vinay\u2020\n\narXiv:quant-ph/0011049v1 13 Nov 2000\n\nAbstract\nWe show how to determine\n\u221a\n\u221a whether a given pattern p of length m occurs in a given\ntext t of length n in \u00d5( n + m)1 time, with inverse polynomial failure probability. This\nalgorithm combines quantum searching algorithms with a technique from parallel string\nmatching, called Deterministic Sampling.\nKeywords: Algorithms, Quantum Computing, String Matching\n\n1\n\nIntroduction\n\nWe consider the following problem: given a text t of length n and a pattern p of length m,\ndoes p occur in t? This question requires \u0398(n + m) time classically, using one of several known\nalgorithms, e.g., the Knuth-Morris-Pratt algorithm or the Boyer-Moore algorithm. Note that\nthe above problem is slightly different from the usual string matching problem which requires\nfinding all occurrences of the pattern in the text.\nWe explore the above question on a quantum machine. Our starting point is the algorithm\n\u221a\ndue to Grover[Gr] which searches for an element in an unordered database in O( n) time.\nBoyer, Brassard, Hoyer and Tapp[BBHT96] gave a tighter analysis of Grover's algorithm and\nalso showed how to handle the case when the number of items searched for is unknown. D\u00fcrr\n\u221a\nand Hoyer[DH] used Grover's algorithm to find the minimum in O( n) time.\nFinding whether the pattern matches somewhere in the text is akin to searching in an\nunordered database; the only issue is that checking one element of this database, i.e., a text\nposition, for an occurrence of the pattern takes O(m) time. In fact, this can be speeded up\n\u221a\nto O( m) by viewing the act of checking whether the pattern matches at a particular text\nposition as the act of finding a mismatch amongst m elements; this search can be performed\n\u221a\nin O( m) time with constant failure probability. This gives an overall time complexity of\n\u221a\nO( nm) (actually, there are additional logarithmic factors, as will be described later).\nq\n\u221a\nn\nIn this paper, we show how this complexity can be improved to O( n log m\nlog m +\n\u221a\n2\nm log m), by combining the above quantum search paradigm with a standard technique from\nparallel string matching, called Deterministic Sampling, due to Vishkin[Vi]. Our algorithm\nwill work with constant failure probability. Thus, if the pattern occurs in the text, it will\nreturn some\nq occurrence\u221aof the pattern in the text (or the leftmost occurrence, if needed) in\n\u221a\nn\nO( n log m\nlog m + m log2 m) time, with probability which is a constant strictly more\n\u2217\n\nIndian Institute of Science, Bangalore, ramesh@csa.iisc.ernet.in.\nIndian Institute of Science, Bangalore, vinay@csa.iisc.ernet.in.\n1\n\u00d5 allows for logarithmic factors in m and n/m\n\u2020\n\n1\n\n\fthan 1/2. And if the pattern does not occur in the text then the algorithm will say so with\nprobability which is also a constant strictly more than 1/2. The failure probability can be\ndecreased to inverse polynomial at the expense of further logarithmic factors. Finally, note\nthat the second component of the running time above will be due to pattern preprocessing.\n\n2\n\nPreliminaries\n\nWe use the following theorem based on Grover's[Gr] database searching algorithm. The theorem itself is due to Boyer et al.[BBHT96].\nTheorem 1 Given an oracle evaluating to 1 on at least t \u2265 1 of the elements in an unordered\ndatabase of size n, there is a quantum algorithm which returns the indexq\nof a random element\non which the oracle evaluates to 1, with probability at least 3/4, in O( nt ) time and oracle\ncalls.\nWe will also need the following theorem for finding the minimum element in a database,\ndue to D\u00fcrr and Hoyer[DH].\nTheorem 2 Given a comparison oracle, there is a quantum algorithm which finds the index\nof the minimum element in an unordered database of size n, with probability at least 3/4, in\n\u221a\nO( n) time.\nWe will assume a basic oracle which will compare a text and a pattern character or two\npattern characters in O(1) time. Our aim then is to use this oracle to develop suitable oracles\n\u221a\n\u221a\nwhich will enable solving the string finding problem in \u00d5( n + m) time. These new oracles\ncould be probabilistic, i.e., they will give the correct answer with constant probability. We\nderive the following corollary to Theorems 1 and 2, in order to use probabilistic oracles. First,\nwe define a probabilistic oracle formally.\nProbabilistic Oracles. These are oracles which evaluate to 1 on good elements (i.e., those\nwhich are being searched for) with probability at least 3/4 and to 0 on bad elements, with probability at least 3/4. A probabilistic comparison oracle gives the correct answer with probability\nat least 3/4.\nCorollary 1 Given a probabilistic oracle and a database with t \u2265 1 good elements, there is a\nquantum algorithm\nq which returns the index of a random good element with probability at least\nq\nn\n3/4 in O( t log nt ) time and oracle calls. Similarly, given a probabilistic comparison oracle,\nthere is a quantum algorithm which finds the index of the minimum element with probability\n\u221a\n\u221a\nat least 3/4, in O( n log n) time.\nProof.q For the searching problem, each original oracle call in Theorem 1 gets replaced by\nO(log nt ) calls and the majority result is taken. This is to ensure that, with constant probq\n\nability, none of the original nt oracle calls returns a 1 on a bad element or a 0 on a good\nelement. Similarly, for the minimum finding problem, each original oracle call in Theorem 2\n\u221a\ngets replaced by O(log n) calls.\n\n2\n\n\fOur algorithm will use oracles whose running time will not be a constant. Therefore, the\nsearch time will be obtained by multiplying the time given by the above corollary with the\ntime taken per oracle call.\nWe will require the following facts about strings.\nPeriodicity. A string p, |p| = m, is said to be aperiodic if any two instances of the string, one\nshifted to the right of the other by at most m/2, differ in some column. A string which is not\naperiodic is called periodic. A periodic string p has the form v k u, where v cannot be expressed\nas a concatenation of several instances of a smaller string, u is a prefix of v, and k \u2265 2. |v| is\nsaid to be the period of p.\n\n3\n\n\u221a \u221a\nThe \u00d5( n m) Time Algorithm\n\nConsider using Grover's algorithm in conjunction with the following natural probabilistic oracle\nf () to solve the string matching problem: f (i) = 1 if the pattern matches with left endpoint\naligned with text position i, and f (i) = 0 with probability at least 3/4, otherwise. This\n\u221a\nprobabilistic oracle can be implemented so that it runs in \u00d5( m) time as follows.\nThe idea is to implement the oracle f (i) using Grover's algorithm itself, using a deterministic oracle g(i, j) which looks for a mismatch at location j. g(i, j) = 1 if and only if the\npattern with left endpoint aligned with t[i] mismatches at location p[j]. By Theorem 1, such\n\u221a\na location, if one exists, can be found in O( m) time with probability at least 3/4. We set\nf (i) = 0 if Grover's algorithm with oracle g(i, j) succeeds in finding a mismatch, and f (i) = 1\n\u221a\n\u221a \u221a\notherwise. Using Corollary 1, the time taken to search using oracle f (i) is O( n m log n)\nand the success probability is at least 3/4.\nNext, we give the faster algorithm, first for aperiodic strings and then for periodic strings.\n\n4\n\n\u221a\n\u221a\nThe \u00d5( n + m) Time Algorithm: Aperiodic Patterns\n\n\u221a\n\u221a\nThe above oracle f (i) was too expensive to get an \u00d5( n + m) bound. A faster oracle will\nclearly improve the time. We do not know how to get a faster oracle directly. However, we\nreorganize the computation as described below and then use a faster oracle followed by a slower\none, speeding up the algorithm on the whole.\nWe partition the text into blocks of length m/2 and use Grover's algorithm to search\nfor a block which contains an occurrence of the pattern. This is done using a probabilistic\noracle h(i) (to be described later), which evaluates to 1 with probability at least 3/4 if block\ni has a match of the pattern (with left endpoint starting in block i), and evaluates to 0\nwith probability at least 3/4, otherwise. Note that by aperiodicity, the pattern can match\n\u221a\nwith left endpoint at at most one text position in block i. h(i) will take O( m log m) time.\nIt q\nfollows fromqCorollary 1 that the\nq time taken for searching with the oracle h(i) will be\n\u221a\nn\u221a\nn\nn\nlog m) and the success probability is a constant.\nO( m m log m log m = n log m\nThe oracle h(i) itself will run in two steps. The first step will use deterministic sampling\n\u221a\nand will takes O( m log m) time with constant success probability. This step will eliminate\nall but at most one of the pattern instances with left endpoint in block i. The second step will\ncheck whether this surviving instance matches the text using the g() oracle defined in Section\n\n3\n\n\f\u221a\n3; this will take O( m) time with constant success probability. We describe the two steps\nnext.\n\n4.1\n\nStep 1: Deterministic Sampling\n\nThe oracle is based on the following theorem due to Vishkin [Vi].\nTheorem 3 [The Deterministic Sampling Theorem] Let p be aperiodic. Consider m\n2\ninstances of p, with successive instances shifted one step to the right. Let these instances be\nlabelled from 1 to m\n2 , from left to right. Then there exists an instance f , and a set of at\nmost O(log m) positions in p, called the deterministic sample with the following property: if\nall positions corresponding to the deterministic sample in instance f of p match the text, then\nnone of the other instances of p above can possibly match the text.\nProof. By aperiodicity, there is a column which contains two distinct characters and stabs all\nthe pattern instances; pick any character in that column which is not in majority. Remove all\npattern instances which do not have this character in the column being considered. Repeat\nO(log m) times until only one pattern instance remains. Then f is the label of the instance\nwhich remains and the columns chosen give the deterministic sample.\nAssume that a deterministic sample for the pattern has been precomputed. We will describe\nthis precomputation later.\nWe now describe the first step in h(i), where i is a block number. We use Grover's algorithm\nin conjunction with the deterministic oracle k(i, j) which evaluates to 1 if and only if the jth\ninstance of the pattern (amongst those instances with left endpoint in block i) matches the text\non its deterministic sample. Clearly, k(i, j) takes O(log m) time. The search using k(i, j) takes\n\u221a\nO( m log m) time by Theorem 1. This search returns an instance j of the pattern with left\nendpoint in block i which has its deterministic sample matching the text (if such an instance\nexists), with probability at least 3/4.\n\n4.2\n\nStep 2: Direct Verification\n\nNext, we use another application of Grover's search to determine whether or not instance j\ndetermined above in block i matches the text; this is done as in Section 3 using the deterministic\n\u221a\noracle g(). It succeeds with probability 3/4, and takes time O( m).\nThus, h(i) returns a 1 with probability at least 3/4 if block i contains a match of the\npattern, and\nq 0 with probability at least 3/4, otherwise. The time taken to search using h(i) is\n\u221a\nn\nlog m), as claimed above, and the success probability is at least 3/4.\nO( n log m\nOnce a block i is found in which h(i) evaluates to 1, a search using oracle k(i, j) on block i\ngives the unique pattern instance j with left endpoint in i whose deterministic sample matches;\nthe success probability is at least 3/4. Another search using the oracle g() determines if this\npattern instance mismatches the text; the success probability q\n(in finding a mismatch, if any)\n\u221a\nn\nlog m), and the probability\nis again at least 3/4. Thus, the total time taken is O( n log m\nof success is as follows.\nIf the pattern occurs in the text, then with probability 3/4, the search with h() will return\na block containing a match of the pattern; subsequently, with probability 3/4, the search with\n4\n\n\fk(i, j) will return a matching pattern instance, and the last search with g() will not discover a\nmismatch with probability 1. Thus an occurrence of the pattern in the text will be found with\n(3/4)2 > 1/2 probability, as claimed. And if the pattern does not occur in the text, then the\nlast search with g() will determine a mismatch with probability at least 3/4 > 1/2, as required.\nFinally, note that the leftmost occurrence of the pattern can be determined using the\nminimum finding algorithm in Corollary 1 to first find the leftmost block with h(i) evaluating\nto 1, and subsequently, searching within that block as above. The time taken and the success\nprobability are as in the previous paragraphs.\n\n5\n\nPattern Preprocessing for Aperiodic Patterns\n\n\u221a\nWe show how to determine the deterministic sample in O( m log2 m) time.\nDetermining the Deterministic Sample. Imagine m/2 copies of the pattern placed as\nin Theorem 3. Determining the sample will proceed in O(log m) stages. In each stage, some\ncolumn and a character in that column will be identified; all surviving pattern copies which do\nnot have this character in this column will be eliminated from future stages. This will continue\n\u221a\nuntil only one pattern copy remains uneliminated. Each stage will take O( m log m) time\nand will have a constant success probability (where we count a success if the surviving pattern\ncopies halve in cardinality).\nA stage proceeds as follows. First, a column containing two distinct characters amongst\nthe surviving pattern copies is found, with constant probability. This column will also have\nthe property that all surviving pattern copies are stabbed by it. Two distinct characters in the\nabove column are also identified. One of these two characters is chosen at random as the next\ncharacter in the sample. Clearly, the number of stages is O(log m) with inverse polynomial\n(in m) failure probability because the probability of the number of surviving pattern instances\nhalving in a stage is at least a constant.\nIt remains to describe how a column containing two distinct characters amongst the surviving pattern copies is found, with constant probability. Before describing this we need to\nmention how to find the leftmost and rightmost surviving patterns in a stage. This is done\nusing the minimum finding algorithm of D\u00fcrr and Hoyer in conjunction with an oracle which\nindicates which pattern copies are consistent with the already chosen deterministic sample\n\u221a\npoints; this oracle takes O(log m) time per call, giving an O( m log m) time algorithm for\nfinding the leftmost/rightmost surviving pattern copy, by Theorem 2. The success probability\nis at least 3/4. Now, we can describe the algorithm for finding a column with two distinct\ncharacters.\nFirst, the leftmost and rightmost surviving pattern copies are found as above. Then a\ncolumn in which these two copies differ is found using Grover's algorithm in conjunction with\n\u221a\na suitable oracle in O( m) time; this step succeeds with probability at least 3/4. Given\na column, this oracle determines whether or not the two pattern copies above differ in this\ncolumn. By Theorem 1, searching for a column with two distinct characters using this oracle\n\u221a\ntakes O( m) time and succeeds with probability 3/4.\n\u221a\nThus, in time O( m log m), a column containing two distinct characters and stabbing all\nsurviving pattern copies is found, with constant probability; it is easily seen that two distinct\ncharacters in this column are also found in this process.\n\u221a\nThe total time taken in determining the deterministic sample is thus O( m log2 m).\n5\n\n\f6\n\nHandling Periodic Patterns\n\nWe sketch briefly the changes required to the above algorithm in order to handle periodic\npattern.\nFor periodic patterns, the above preprocessing algorithm will not terminate with a single\npattern copy but rather with several copies shifted |v| steps to the right successively. When\na stage is reached when the only surviving copies are the periodically shifted copies above,\nthen the search for a heterogeneous column in the next \u0398(log m) stages will fail. Note that for\naperiodic patterns this behaviour happens with low, i.e., inverse polynomial probability.\nAt this point, we determine the period |v| using two instances of the minimum finding\nalgorithm. The first instance finds the leftmost surviving copy and the second the second\n\u221a\nleftmost; the difference of their offsets is the period. This takes O( m log m) time, using the\noracle which checks for consistency with the deterministic sample and also compares offsets.\nGiven the period |v|, the following changes now need to be made to the text processing part.\nRecall the oracle h(i) from Section 4; this oracle determines whether there is a pattern\ninstance with left endpoint in block i which matches, first on its deterministic sample, and\nthen on the whole. This oracle is modified as follows.\nh(i) will first determine the leftmost and the rightmost pattern instances with left endpoints in i which match on their respective deterministic sample points; this is done using the\n\u221a\nminimum finding algorithm and takes O( m log m) time with success probability at least 3/4\n(see Theorem 2, this success probability can be made arbitrarily close to 1 by repeating). Let\nthese two instance have left endpoints at text positions k and l respectively.\nNext, h(i) finds the longest substring (with length at most m) starting at the right boundary\nof text block i which is consistent with the pattern instance starting at text position l (and\ntherefore consistent with the pattern instant starting at text position k as well); this is done\n\u221a\nusing the minimum finding algorithm and takes O( m) time with constant failure probability.\nSimilarly, h(i) finds the longest substring (with length at most m/2) ending at the right\nboundary of text block i which is consistent with the pattern instance starting at text position\nk.\nFinally, using these two substrings, h(i) can determine in O(1) time, whether there exists a\npattern instance with left endpoint in block i which matches the text. If the length of the two\nsubstrings is less than m then there is no such pattern instance; otherwise, all instances of the\npattern which occur completely within these two substrings and starting at shifts of integer\nmultiples of |v| from k are complete matches (here |v| is the pattern period).\n\u221a\nThus, h(i) determines whether or not the pattern occurs in block i in O( m log m) time,\nwith failure probability a constant. This failure probability can be made arbitrarily close to 0\nby repetition. Note that h(i) can determine the leftmost pattern occurrence in block i as well,\nif required, within the same time bounds.\nThe rest of the algorithm stays the same: h(i) is used to find a block containing an occurrence of the pattern and subsequently, an occurrence of the pattern in this block is found\nusing the above method.\n\n7\n\nConclusions And Open Problems\n\n\u221a\nWe have shown how one occurrence or the leftmost occurrence of p in t can be found in \u00d5( n+\n\u221a\nm) time, with constant two-sided failure probability. We also note that an approximate count\n6\n\n\fof the number of occurrences (within a multiplicative constant factor) can also be determined in\n\u221a\n\u221a\n\u00d5( n + m) using the approximate counting algorithm of Brassard, Hoyer and Tapp [BHT],\nadapted appropriately (the oracle h(i) must now return a count of the number of matches\nrather than just the indication of a match). Finally,\nthe same algorithm, the total\n\u221a using\n\u221a\nnumber of occurrences of p can be determined in \u00d5( nt + m) time, where t is the number\nof occurrences.\nOne open problem would be whether string matching with don't cares can be performed\nin the same time bounds as above. The main challenge here to implement convolution using\n\u221a\nFast Fourier Transforms in \u00d5( n) time. It is not obvious how this can be accomplished.\n\nReferences\n[BBHT96] M. Boyer, G. Brassard, P. Hoyer, A. Tapp. Tight bounds on quantum searching.\nProceedings of 4th Workshop on Physics and Computation-PhysComp, 1996, pp. 36\u2013\n43.\n[BHT] G. Brassard, P. Hoyer, A. Tapp. Quantum Counting. Proceedings of 25th International\nColloquium on Automata, Languages and Programming, 1998, pp. 820\u2013831.\n[Gr]\n\nL. Grover. A fast quantum mechanical algorithm for database search. Proceedings of\n28th ACM Symposium on Theory of Computing, 1996, pp. 212\u2013219.\n\n[DH]\n\nC. D\u00fcrr, P. Hoyer, A quantum algorithm for finding the minimum. Quantum Physics\nE-Print Archive, http://xxx.lanl.gov/quant-ph/9607014, 1996.\n\n[Vi]\n\nU. Vishkin. Deterministic Sampling: A new technique for fast pattern matching. SIAM\nJournal of Computing, 20, 1991, pp. 22\u201340.\n\n7\n\n\f"}