{"id": "http://arxiv.org/abs/1011.1703v3", "guidislink": true, "updated": "2012-11-20T20:35:36Z", "updated_parsed": [2012, 11, 20, 20, 35, 36, 1, 325, 0], "published": "2010-11-08T03:20:54Z", "published_parsed": [2010, 11, 8, 3, 20, 54, 0, 312, 0], "title": "Point process modeling for directed interaction networks", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1011.4414%2C1011.1146%2C1011.0668%2C1011.6126%2C1011.2328%2C1011.5825%2C1011.1024%2C1011.3429%2C1011.5106%2C1011.1037%2C1011.3457%2C1011.6377%2C1011.5051%2C1011.0732%2C1011.4191%2C1011.6129%2C1011.4400%2C1011.4987%2C1011.4980%2C1011.2003%2C1011.5074%2C1011.0544%2C1011.5925%2C1011.3650%2C1011.0756%2C1011.4219%2C1011.3740%2C1011.3904%2C1011.5115%2C1011.6467%2C1011.5880%2C1011.1326%2C1011.0873%2C1011.2514%2C1011.1109%2C1011.2531%2C1011.3198%2C1011.0636%2C1011.6206%2C1011.2351%2C1011.2845%2C1011.3480%2C1011.2869%2C1011.1380%2C1011.5520%2C1011.2340%2C1011.6019%2C1011.6365%2C1011.6412%2C1011.1069%2C1011.1708%2C1011.3895%2C1011.3931%2C1011.2454%2C1011.6178%2C1011.3990%2C1011.2219%2C1011.3106%2C1011.3614%2C1011.1218%2C1011.4133%2C1011.1583%2C1011.5841%2C1011.1421%2C1011.1388%2C1011.2302%2C1011.4228%2C1011.4847%2C1011.2856%2C1011.1044%2C1011.5166%2C1011.1962%2C1011.5721%2C1011.1224%2C1011.1703%2C1011.4068%2C1011.2467%2C1011.1615%2C1011.2155%2C1011.0644%2C1011.3596%2C1011.2333%2C1011.5095%2C1011.0595%2C1011.6431%2C1011.5035%2C1011.4762%2C1011.6433%2C1011.2173%2C1011.0851%2C1011.1514%2C1011.0951%2C1011.0745%2C1011.3581%2C1011.4835%2C1011.1473%2C1011.1710%2C1011.5511%2C1011.3425%2C1011.2187%2C1011.5415&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Point process modeling for directed interaction networks"}, "summary": "Network data often take the form of repeated interactions between senders and\nreceivers tabulated over time. A primary question to ask of such data is which\ntraits and behaviors are predictive of interaction. To answer this question, a\nmodel is introduced for treating directed interactions as a multivariate point\nprocess: a Cox multiplicative intensity model using covariates that depend on\nthe history of the process. Consistency and asymptotic normality are proved for\nthe resulting partial-likelihood-based estimators under suitable regularity\nconditions, and an efficient fitting procedure is described. Multicast\ninteractions--those involving a single sender but multiple receivers--are\ntreated explicitly. The resulting inferential framework is then employed to\nmodel message sending behavior in a corporate e-mail network. The analysis\ngives a precise quantification of which static shared traits and dynamic\nnetwork effects are predictive of message recipient selection.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1011.4414%2C1011.1146%2C1011.0668%2C1011.6126%2C1011.2328%2C1011.5825%2C1011.1024%2C1011.3429%2C1011.5106%2C1011.1037%2C1011.3457%2C1011.6377%2C1011.5051%2C1011.0732%2C1011.4191%2C1011.6129%2C1011.4400%2C1011.4987%2C1011.4980%2C1011.2003%2C1011.5074%2C1011.0544%2C1011.5925%2C1011.3650%2C1011.0756%2C1011.4219%2C1011.3740%2C1011.3904%2C1011.5115%2C1011.6467%2C1011.5880%2C1011.1326%2C1011.0873%2C1011.2514%2C1011.1109%2C1011.2531%2C1011.3198%2C1011.0636%2C1011.6206%2C1011.2351%2C1011.2845%2C1011.3480%2C1011.2869%2C1011.1380%2C1011.5520%2C1011.2340%2C1011.6019%2C1011.6365%2C1011.6412%2C1011.1069%2C1011.1708%2C1011.3895%2C1011.3931%2C1011.2454%2C1011.6178%2C1011.3990%2C1011.2219%2C1011.3106%2C1011.3614%2C1011.1218%2C1011.4133%2C1011.1583%2C1011.5841%2C1011.1421%2C1011.1388%2C1011.2302%2C1011.4228%2C1011.4847%2C1011.2856%2C1011.1044%2C1011.5166%2C1011.1962%2C1011.5721%2C1011.1224%2C1011.1703%2C1011.4068%2C1011.2467%2C1011.1615%2C1011.2155%2C1011.0644%2C1011.3596%2C1011.2333%2C1011.5095%2C1011.0595%2C1011.6431%2C1011.5035%2C1011.4762%2C1011.6433%2C1011.2173%2C1011.0851%2C1011.1514%2C1011.0951%2C1011.0745%2C1011.3581%2C1011.4835%2C1011.1473%2C1011.1710%2C1011.5511%2C1011.3425%2C1011.2187%2C1011.5415&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Network data often take the form of repeated interactions between senders and\nreceivers tabulated over time. A primary question to ask of such data is which\ntraits and behaviors are predictive of interaction. To answer this question, a\nmodel is introduced for treating directed interactions as a multivariate point\nprocess: a Cox multiplicative intensity model using covariates that depend on\nthe history of the process. Consistency and asymptotic normality are proved for\nthe resulting partial-likelihood-based estimators under suitable regularity\nconditions, and an efficient fitting procedure is described. Multicast\ninteractions--those involving a single sender but multiple receivers--are\ntreated explicitly. The resulting inferential framework is then employed to\nmodel message sending behavior in a corporate e-mail network. The analysis\ngives a precise quantification of which static shared traits and dynamic\nnetwork effects are predictive of message recipient selection."}, "authors": ["Patrick O. Perry", "Patrick J. Wolfe"], "author_detail": {"name": "Patrick J. Wolfe"}, "author": "Patrick J. Wolfe", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1111/rssb.12013", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1011.1703v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1011.1703v3", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "36 pages, 13 figures; includes supplementary material", "arxiv_primary_category": {"term": "stat.ME", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "stat.ME", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.SI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.TH", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1011.1703v3", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1011.1703v3", "journal_reference": "Journal of the Royal Statistical Society, Series B, 2013", "doi": "10.1111/rssb.12013", "fulltext": "Point process modeling for directed interaction networks\nPatrick O. Perry\nStern School of Business, New York University, USA\n\nPatrick J. Wolfe\nDepartment of Statistical Science, University College London, UK\n\narXiv:1011.1703v3 [stat.ME] 20 Nov 2012\n\n[Received November 2010. Revised November 2012]\nSummary. Network data often take the form of repeated interactions between senders and receivers tabulated over time. A primary question to ask of such data is which traits and behaviors\nare predictive of interaction. To answer this question, a model is introduced for treating directed\ninteractions as a multivariate point process: a Cox multiplicative intensity model using covariates\nthat depend on the history of the process. Consistency and asymptotic normality are proved for\nthe resulting partial-likelihood-based estimators under suitable regularity conditions, and an efficient\nfitting procedure is described. Multicast interactions-those involving a single sender but multiple\nreceivers-are treated explicitly. The resulting inferential framework is then employed to model message sending behavior in a corporate e-mail network. The analysis gives a precise quantification of\nwhich static shared traits and dynamic network effects are predictive of message recipient selection.\nKeywords: Cox proportional hazards model; Network data analysis; Partial likelihood inference; Point processes\n\n1.\n\nIntroduction\n\nMuch effort has been devoted to the statistical analysis of network data; see Jackson (2008),\nGoldenberg et al. (2009), and Kolaczyk (2009) for recent overviews. Often network observables\ncomprise counts of interactions between individuals or groups tabulated over time. Communications networks give rise to directed interactions: phone calls, text messages, or e-mails exchanged\namongst a given set of individuals over a specific time period (Tyler et al., 2005; Eagle and Pentland, 2006). Specific examples of repeated interactions from other types of networks include the\nfollowing: Fowler's (2006) study of legislators authoring and cosponsoring bills (a collaboration\nnetwork); Mckenzie and Rapoport's (2007) study of families migrating between communities in\nMexico (a migration network); Sundaresan, Fischoff, Dushoff, and Rubenstein's (2007) study of\nzebras congregating at locations in their habitat (an animal association network); and Papachristos's (2009) study of gangs in Chicago murdering members of rival factions (an organized crime\nnetwork).\nIn this article, we consider partial-likelihood-based inference for general directed interaction\ndata in the presence of covariates. We first develop asymptotic theory for the case in which interactions are strictly pairwise, and then generalize our results to the multiple-receiver (multicast)\ncase; we also provide efficient algorithms for partial likelihood maximization in these settings.\nOur main assumption on the covariates is that they be predictable, which allows them to vary\nwith time and potentially depend on the past.\nAddress for correspondence: Patrick O. Perry, Information, Operations, and Management Sciences\nDepartment, Stern School of Business, New York University, 44 West 4th St, New York, NY 10012, USA\nE-mail: pperry@stern.nyu.edu\n\n\f2\n\nP. O. Perry and P. J. Wolfe\n\nThe interaction data we consider comprise a set of triples, with triple (t, i, j) indicating that\nat time t, directed interaction i \u2192 j took place-for instance, individual i sent a message to\nindividual j. Given such a set of triples, a primary modeling goal lies in determining which\ncharacteristics and behaviors of the senders and receivers are predictive of interaction. In this\nvein, three important questions stand out:\nHomophily Is there evidence of homophily (an increased rate of interaction among similar\nindividuals)? To what degree is a shared attribute predictive of heightened interaction?\nNetwork Effects To what extent are past interaction behaviors predictive of future ones? If\nwe observe interactions i \u2192 h and h \u2192 j, are we more likely to see the interaction i \u2192 j?\nMultiplicity How should multiple-receiver interactions of the type i \u2192 {j1 , j2 , . . . , jL } be modeled? What are the implications of treating these as L separate pairwise interactions?\nThe issues of homophily, network effects, and their interactions arise frequently in the networks literature; see, e.g., McPherson et al. (2001); Butts (2008); Aral et al. (2009); Snijders et al.\n(2010), and references contained therein. Multiplicity has largely been ignored in this context,\nhowever, with notable exceptions including Lunag\u00f3mez et al. (2009) for graphical models, and\nShafiei and Chipman (2010) for network modeling.\nIn the remainder of this article, we provide a modeling framework and computationally efficient partial likelihood inference procedures to facilitate analysis of these questions. We employ\na Cox proportional intensity model incorporating both static and history-dependent covariates\nto address the first of these two questions, and a parametric bootstrap to address the third.\nSection 2 presents our point process model for directed pairwise interactions, along with the\nresultant inference procedures. Section 3 establishes consistency and asymptotic normality of\nthe corresponding maximum partial likelihood estimator, and Section 4 extends our framework\nto the case of multiple-receiver interactions. Section 5 employs this framework to model message\nsending behavior in a corporate e-mail network. Section 6 evaluates the strength of homophily\nand network effects in explaining these data, and Section 7 concludes the main body of the\narticle. Appendices A\u2013C contain respectively implementation details and technical results from\nSections 3 and 4. The supplementary material provides comparative analyses based on related\nnetwork models in the literature.\n2.\n\nA point process model and partial likelihood inference\n\nEvery interaction process can be encoded by a multivariate counting measure. For sender i,\nreceiver j, and positive time t, define\nNt (i, j) = #{directed interactions i \u2192 j in time interval [0, t]}.\nFor technical reasons, assume that N0 (i, j) = 0 and that Nt (i, j) is adapted to a stochastic basis of\n\u03c3-algebras {Ft }t\u22650 satisfying the usual conditions. Then, Nt (i, j) is a local submartingale, so by\nthe Doob-Meyer decomposition, there exists a predictable increasing process \u039bt (i, j), null at zero,\nsuch that Nt (i, j)\u2212\u039bt (i, j) is an Ft -local martingale. Under mild conditions-the most important\nof which is that no two interactions happen\nsimultaneously-there exists a predictable continuous\nRt\nprocess \u03bbt (i, j) such that \u039bt (i, j) = 0 \u03bbs (i, j) ds. (In practical applications, simultaneous events\nexist and are an annoyance; Efron (1977) handles simultaneity through an ad-hoc adjustment,\nwhile Brostr\u00f6m (2002) adds a discrete component to \u039b.) The process \u03bb is known as the stochastic\nintensity of N . Heuristically,\n\u03bbt (i, j) dt = P{interaction i \u2192 j occurs in time interval [t, t + dt)}.\n\n\fPoint Process Modeling for Directed Interaction Networks\n\n3\n\nWe will model N through \u03bb using a version of the Cox (1972) proportional intensity model.\nLet I be a set of senders and J be a (not necessarily disjoint) set of receivers. For each\nsender i, let \u03bb\u0304t (i) be a non-negative predictable process called the baseline intensity of sender i;\nlet Jt (i) be a predictable finite subset of J called the receiver set of sender i. For each senderreceiver pair (i, j), let xt (i, j) be a predictable locally bounded vector of covariates in Rp . Let \u03b20\nbe an unknown vector of coefficients in Rp . For the remainder of this section, assume that each\ninteraction has a single receiver.\nGiven a multivariate counting process N on R+ \u00d7 I \u00d7 J , we model its stochastic intensity as\n\u03bbt (i, j) = \u03bb\u0304t (i) * exp{\u03b20T xt (i, j)} * 1{j \u2208 Jt (i)}.\n\n(1)\n\nThis model posits that sender i in I interacts with receiver j in Jt (i) at a baseline rate \u03bb\u0304t (i)\nmodulated up or down according to the pair's covariate vector, xt (i, j). As Efron (1977) notes,\nthe specific parametric form for the multiplier exp{\u03b20T xt (i, j)} is not central to the theoretical\nanalysis, but this choice is amenable to computation and gives the parameter vector \u03b20 a straightforward interpretation. Butts (2008), Vu et al. (2011a), and Vu et al. (2011b) used variants of\nthis model to analyze repeated directed actions within social settings.\nThe form of (1) is deceptively simple but remains flexible enough to be useful in practice.\nThe model allows for homophily and group level effects via inclusion of covariates of the form\n\"1{i and j belong to the same group},\" where \"group\" is some observable trait like ethnicity,\ngender, or age group. Its real strength, though, is that xt (i, j) is allowed to be any predictable\nprocess, in particular xt (i, j) can depend on the history of interactions. To model reciprocation\nand transitivity in the interactions (with I = J ), for example, choose appropriate values for \u2206k\nand include relevant covariates in xt (i, j):\n1{interaction j \u2192 i occurred in [t \u2212 \u2206k , t)}\nand\n1{for some h, interactions i \u2192 h and h \u2192 j occurred in [t \u2212 \u2206k , t)}.\nAny process measurable with respect to the predictable \u03c3-algebra is a valid covariate; this excludes only covariates depending on the future or the immediate present. In Section 5.2 we detail\nspecific covariates suitable for measuring homophily and network effects.\nAlso note that despite presuming I and J to be fixed, our analysis allows senders and\nreceivers to enter and leave the study during the observation period. The effective number of\nsenders at time t is the set of i such that \u03bb\u0304t (i) 6= 0, which potentially varies with time. Likewise,\nthe effective number of receivers is controlled through Jt (i).\nFollowing Cox (1975), we treat the baseline rate \u03bb\u0304t (i) as a nuisance parameter and estimate\nthe coefficient vector \u03b20 using a partial likelihood. Specifically, let (t1 , i1 , j1 ), . . . , (tn , in , jn ) be\nthe sequence of observed interactions. The inference procedure is motivated by decomposing the\nfull likelihood, L, as\nL(t1 , i1 , j1 , t2 , i2 , j2 , . . . , tn , in , jn )\n= L(t1 , i1 ) L(j1 |t1 , i1 ) L(t2 , i2 |t1 , i1 , j1 ) L(j2 |t2 , i2 , t1 , i1 , j1 )\n\n* * * L(tn , in |tn\u22121 , in\u22121 , jn\u22121 , . . . t1 , i1 , j1 ) L(jn |tn , in , tn\u22121 , in\u22121 . . . t1 , i1 , j1 )\nh\ni\n= L(t1 , i1 ) L(t2 , i2 |t1 , i1 , j1 ) * * * L(tn , in |tn\u22121 , in\u22121 , jn\u22121 , . . . t1 , i1 , j1 )\nh\ni\n* L(j1 |t1 , i1 ) L(j2 |t2 , i2 , t1 , i1 , j1 ) * * * L(jn |tn , in , tn\u22121 , in\u22121 . . . t1 , i1 , j1 ) ;\n\n\f4\n\nP. O. Perry and P. J. Wolfe\n\nthe term comprised of the product of conditional likelihoods of j1 , . . . , jn is dubbed a partial\nlikelihood. In continuous time, the log partial likelihood at time t, evaluated at \u03b2, is\n\u001b\nX\u001a\n\u0002 X\n\u0003\nlog PLt (\u03b2) =\n\u03b2 T xtm(im , jm ) \u2212 log\nexp{\u03b2 T xtm(im , j)} .\n(2)\ntm \u2264t\n\nj\u2208Jtm(im )\n\nIn Section 3, we prove under suitable regularity conditions that the maximizer of log PLt (*) is a\nconsistent estimator of \u03b20 as t increases.\nThe function log PLt (*) is concave, and so can be maximized via Newton's method or a\ngradient-based optimization approach (Nocedal and Wright, 2006). These methods require one\nor both of the first two derivatives of log PLt (*), which can be expressed in terms of weighted\nmeans and covariances of the covariates. The weights are\nwt (\u03b2, i, j) = exp{\u03b2 T xt (i, j)} * 1{j \u2208 Jt (i)},\nX\nWt (\u03b2, i) =\nwt (\u03b2, i, j).\n\n(3a)\n(3b)\n\nj\u2208Jt (i)\n\nThe inner sum in log PLt (\u03b2) is Wtm(\u03b2, im ). The function log Wt (*, i) has gradient Et (*, i) and\nHessian Vt (*, i), given by\nX\n1\nwt (\u03b2, i, j) xt (i, j),\nWt (\u03b2, i)\nj\u2208Jt (i)\nh\ni\u22972\nX\n1\nVt (\u03b2, i) =\nwt (\u03b2, i, j) xt (i, j) \u2212 Et (\u03b2, i)\n,\nWt (\u03b2, i)\nEt (\u03b2, i) =\n\n(4a)\n(4b)\n\nj\u2208Jt (i)\n\nwhere a\u22972 = a \u2297 a = aaT . Consequently, the gradient and negative Hessian of log PLt (*) are\nX\n\u0002\n\u0003\nUt (\u03b2) = \u2207 log PLt (\u03b2) =\nxtm (im , jm ) \u2212 Etm (\u03b2, im ),\n(5a)\nIt (\u03b2) = \u2212\u2207\n\n2\n\n\u0002\n\ntm \u2264t\n\nX\n\u0003\nlog PLt (\u03b2) =\nVtm (\u03b2, im ).\n\n(5b)\n\ntm \u2264t\n\nWe call Ut (\u03b20 ) the unnormalized score and It (\u03b20 ) the observed information matrix.\nNote the dependence of these terms on time-varying covariates, which precludes using sufficient statistics and introduces additional complexity in maximizing log PLt (*). For most large\ninteraction datasets, existing computational routines for handling Cox models (e.g., the function\ncoxph from the survival package for R (Therneau and Lumley, 2009)) will not suffice. In Appendix A, we describe a customized method for maximizing log PLt (*) that exploits sparsity in\nxt (i, j).\n3.\n\nConsistency of maximum partial likelihood inference\n\nUnder the model of Section 2, the maximum partial likelihood estimator (MPLE) is a natural\nestimate of \u03b20 ; the inverse Hessian of log PLt (*) evaluated at the MPLE is a natural estimate of\nits covariance matrix. We now give conditions under which these estimators are consistent.\nIn the sampling regime where observation time t is fixed and the number of senders |I|\nincreases, Andersen and Gill's (1982) consistency proof for the Cox proportional hazards model in\nsurvival analysis extends to cover model (1). This setting is natural in the context of clinical trial\n\n\fPoint Process Modeling for Directed Interaction Networks\n\n5\n\ndata, where I corresponds to the set of patients under study, but does not meet the requirements\ntypical of interaction data. For most interaction data we cannot control I and J , and the\nonly way to collect more data is to increase the observation time. Cox (1972, 1975) outlines\na proof for general MPLE consistency that applies to our sampling regime, but his argument\nis heuristic; Wong's (1986) treatment is more rigorous but does not cover continuous or timevarying covariates. The general interaction data sampling regime warrants a new consistency\nproof.\nOur proof of consistency relies on rescaling\ntimes uniform. To\nP time to make the interaction\nP\nthis end, define marginal processes Nt (i) = j\u2208J Nt (i, j) and Nt = i\u2208I Nt (i); also note that\ntn = sup{t : Nt < n} is a stopping time and let Ftn be the \u03c3-algebra of events prior to tn . The\nmain idea of the proof is to change time from the original scale to a scale on which tn \u2212 tn0 is\nproportional to n \u2212 n0 .\n3.1. Assumptions\nLet B be a neighborhood of \u03b20 . For a vector, a, let kak denote its Euclidean norm; for a matrix,\nA, let kAk denote its spectral norm, equal to the largest eigenvalue of (AT A)1/2 . We require the\nfollowing assumptions:\nA1. The covariates are uniformly square-integrable. That is,\n\u0014\n\u0015\nE sup kxt (i, j)k2 is bounded.\nt,i,j\n\nA2. The integrated covariance function is well behaved. When \u03b2 \u2208 B and \u03b1 \u2208 [0, 1], as\nn \u2192 \u221e, then with respect to the covariance function \u03a3\u03b1 (\u03b2) we have that\nZ\n1 X tb\u03b1nc\nP\nVs (\u03b2, i) Ws (\u03b2, i) \u03bb\u0304s (i) ds \u2192 \u03a3\u03b1 (\u03b2).\nn\n0\ni\u2208I\n\nA3. The interaction arrival times are finite. For each n,\nP{tn < \u221e} = 1.\nA4. The variance function is equicontinuous. More precisely,\nn\no\nVtn (*, i) : n \u2265 1, i \u2208 I is an equicontinuous family of functions.\nThese technical assumptions are similar to those of Andersen and Gill (1982), who investigate\nspecific settings in which their assumptions hold. Note that when kxt (i, j)k is bounded and\nAssumption A3 is in force, the remaining assumptions follow.\n3.2. Main results\nAssumptions A1\u2013A4 imply that the MPLE is consistent and asymptotically Gaussian, as shown\nby the following two theorems.\nTheorem 3.1. Let N be a multivariate counting process with stochastic intensity as given\nin (1), with true parameter vector \u03b20 . Let tn be the sequence of interaction times, and set Ut (\u03b2)\nand It (\u03b2) to be the gradient and negative Hessian of the log partial likelihood function as given\nrespectively in (5a) and (5b). If assumptions A1\u2013A2 hold, then as n \u2192 \u221e:\n\n\f6\n\nP. O. Perry and P. J. Wolfe\n\n(a) n\u22121/2 Utb\u03b1nc (\u03b20 ) converges weakly to a Gaussian process on [0, 1] with covariance function\n\u03a3\u03b1 (\u03b20 );\n(b) if assumptions A3\u2013A4 also hold, then for any consistent estimator \u03b2\u0302n of \u03b20 , we have that\nsup\n\u03b1\u2208[0,1]\n\n1\nn Itb\u03b1nc (\u03b2\u0302n )\n\nP\n\n\u2212 \u03a3\u03b1 (\u03b20 ) \u2192 0.\n\nWe don't actually require convergence of the whole sample path, but it turns out to be just\nas much effort to prove as convergence of the endpoint. Consistency is a direct consequence of\nTheorem 3.1.\nTheorem 3.2. Let N be a multivariate counting process with stochastic intensity as given\nin (1), with true parameter vector \u03b20 . Let the log partial likelihood, log PLt (*), be as defined\nin (2). Let tn be the sequence of interaction times.\nP\nAssume that for \u03b2 in a neighborhood of \u03b20 that \u2212 n1 \u22072 [log PLtn (\u03b2)] \u2192 \u03a31 (\u03b2), where \u03a31 (*) is locally Lipschitz and with smallest eigenvalue bounded away from zero. If \u03b2\u0302n maximizes log PLtn (*)\nand conclusion (a) of Theorem 3.1 holds, then the following are true as n \u2192 \u221e:\n(a) \u03b2\u0302n is a consistent estimator of \u03b20 ;\n\u221a\n(b) n (\u03b2\u0302n \u2212 \u03b20 ) converges weakly to a mean-zero Gaussian random variable with covariance\n[\u03a31 (\u03b20 )]\u22121 .\nWe prove Theorems 3.1 and 3.2 in Appendix B.\n4.\n\nMulticast interactions\n\nIn Sections 2 and 3, we have assumed that each interaction involves a single sender and a single\nreceiver. The model and corresponding asymptotic theory are sufficient to cover strictly pairwise\ndirected interactions (e.g., phone calls), but they do not describe interactions that can involve\nmultiple receivers (e.g., e-mail messages). We call an interaction involving a single sender and\npossibly multiple receivers a multicast interaction.\nIn practice, multicast interactions are typically treated in an ad-hoc manner via duplication-\nfor example, interaction i \u2192 {j1 , j2 , j3 } gets recorded as three separate pairwise interactions\ni \u2192 j1 , i \u2192 j2 , and i \u2192 j3 -giving rise to approximate likelihood and inference. In this section\nwe explore the implications of using this approximate likelihood in the multicast setting. In\nparticular we show it to be closely related to an extension of our model for directed pairwise\ninteractions, and that the bias introduced by such an approximation can be quantified and in\ncertain cases corrected.\nTo this end, we introduce an extension of the model to the multicast setting. Let I, J ,\nJt (i), xt (i, j), and \u03b20 be as in Section 2. For each sender i and positive integer L, let \u03bb\u0304t (i; L)\nbe a non-negative predictable process called the baseline L-receiver intensity of sender i. Let\n(t1 , i1 , J1 ), . . . , (tn , in , Jn ) be the sequence of observed multicast interactions, with tuple (t, i, J)\nindicating that at time t, sender i interacted with receiver set J. For a set J, let |J| denote its\ncardinality.\nConsider a model for multicast interactions where the rate of interaction between sender i\nand receiver set J is\nnX\no Y\n\u03bbt (i, J) = \u03bb\u0304t (i; |J|) * exp\n\u03b20T xt (i, j) *\n1{j \u2208 Jt (i)}.\n(6)\nj\u2208J\n\nj\u2208J\n\n\fPoint Process Modeling for Directed Interaction Networks\n\nThe log partial likelihood at time t, evaluated at \u03b2, is\n\u001b\nX\u001aX\n\bX T\n\u0003\n\u0002 X\nexp\n\u03b2 xtm(im , j)\n.\nlog PLt (\u03b2) =\n\u03b2 T xtm(im , j) \u2212 log\ntm \u2264t\n\nj\u2208Jm\n\nJ\u2286Jtm (im )\n|J|=|Jm |\n\n7\n\n(7)\n\nj\u2208J\n\nSuppose instead of using the multicast model, we use duplication to get pairwise interactions\nfrom the original multicast data. If we use the model of (1) for the pairwise data and ignore ties\nin the interaction times, we obtain an approximate partial likelihood:\n\u001b\nX\u001aX\n\u0002 X\n\u0003\nT\nT\nf\nlog PLt (\u03b2) =\n\u03b2 xtm(im , j) \u2212 |Jm | log\nexp{\u03b2 xtm(im , j)} .\n(8)\ntm \u2264t\n\nj\u2208Jm\n\nj\u2208Jtm(im )\n\nf t (\u03b2) approximates log PLt (\u03b2). Heuristically, replacing the sum over all sets\nWe claim log PL\nof size |Jm | in (7) with a sum over all multisets of size |Jm | (i.e., allowing duplicate elements\nfrom Jtm (im )), observe\n\u0002 X\n\bX T\n\u0003\n\u0002 X\n\b\n\u0001|Jm | \u0003\nlog\nexp\n\u03b2 xtm(im , j) \u2248 log\nexp \u03b2 T xtm(im , j)\nJ\u2286Jtm (im )\n|J|=|Jm |\n\nj\u2208J\n\nj\u2208Jtm (im )\n\n= |Jm | log\n\n\u0002 X\n\n\b\n\u0003\nexp \u03b2 T xtm(im , j) .\n\nj\u2208Jtm (im )\n\nf t (\u03b2). Section 4.1 makes this statement more precise, and\nIn this sense, log PLt (\u03b2) \u2248 log PL\nf t (\u03b2) in lieu of log PLt (\u03b2).\nSection 4.2 analyzes the bias introduced by maximizing log PL\n4.1. Approximation error\nDefine the receiver set growth sequence\n\nGn =\n\nX 1{|Jm | > 1}\n.\n|Jtm (im )|\n\n(9)\n\ntm \u2264tn\n\nThis sequence plays a critical role in bounding the error introduced by replacing log PL with\nf Note that when |Jt (im )| is constant Gn has linear growth, but when |Jt (im )| increases,\nlog PL.\nm\nm\nGn often has sublinear growth. For example, the Cauchy-Schwartz inequality gives\n\u0014 X\n\u00151/2\n\u221a\n1{|Jm | > 1}\n,\nGn \u2264 n *\n|Jtm (im )|2\ntm \u2264tn\n\n\u221a\n\u221a\nso if |Jtm (im )|/ m \u2192 \u221e, then Gn = O( n). Theorem 4.1 (proved in Appendix C) bounds the\napproximation error in terms of Gn .\nTheorem 4.1. Let (tm , im , Jm ) be a sequence of observations from a multivariate point processes with intensity as given in (6). Assume that supt kxt (i, j)k and supm |Jm | are bounded in\nf are as defined in (7\u20138), and Gn is as defined in (9), then for \u03b2\nprobability. If log PL and log PL\nin a neighborhood of \u03b20 ,\nand\n\nf t (\u03b2)] = OP (Gn ),\n\u2207[log PLtn (\u03b2)] \u2212 \u2207[log PL\nn\n\nf t (\u03b2)] = OP (Gn ).\n\u22072 [log PLtn (\u03b2)] \u2212 \u22072 [log PL\nn\n\n\f8\n\nP. O. Perry and P. J. Wolfe\n\n4.2. Bias correction from the approximate partial likelihood\nWhen we use ad-hoc duplication, we are performing approximate inference under the multicast\nmodel of (6). In practice, even if we explicitly want to use the multicast model, computing the\npartial likelihood of (7) involves an intractable combinatorial sum, so we may resort to using\nf t (*) instead of log PLt (*) introduces bias in the\nthe approximation instead. Maximizing log PL\nestimate of \u03b20 . Theorem 4.2 (proved in Appendix C) bounds the bias.\nTheorem 4.2. Under the setup of Theorem 4.1, let \u03b2\u0302n maximize log PLtn (*) and let \u03b2\u0303n\nf t (*)] is uniformly locally\nf t (*). Suppose for all n that the Hessian 1 \u22072 [log PL\nmaximize log PL\nn\nn\nn\nLipschitz and with smallest eigenvalue bounded away from zero in a neighborhood of \u03b2\u0302n . If\nP\nGn /n \u2192 0, then\nk\u03b2\u0303n \u2212 \u03b2\u0302n k = OP (Gn /n).\n\nThat \u03b2\u0302n is a consistent estimator of \u03b20 follows directly from the theory in Section 3, since\nthe multicast case can be considered as a special case of the single receiver case: Consider the\nproduct I \u00d7 N+ as the sender set, and the power set P(J ) as the receiver set. For sender (i, L),\nthe process \u03bb\u0304(i; L) is then the baseline\nand {J \u2286 Jt (i) : |J| = L} is the receiver\n\u0001 send intensity,\nP\nset; for sender-receiver pair (i, L), J , vector j\u2208J xt (i, j) is the covariate vector. Consistency\nof the MPLE now follows from Theorem\n\u221a 3.2.\nSuppose the true MPLE, \u03b2\u0302n , is a n-consistent estimate of \u03b20 . (Theorem 3.2 gives sufficient\nconditions.) Theorem 4.2 says that if |Jtm (im )| grows fast enough to make Gn smaller than\n\u221a\n\u221a\n\u221a\nOP ( n), then the approximate\u221aMPLE, \u03b2\u0303n , is also n-consistent. Moreover, if n(\u03b2\u0302n \u2212 \u03b20 ) is\nasymptotically Gaussian, then n(\u03b2\u0303n \u2212 \u03b20 ) is asymptotically Gaussian with the same covariance\nf t (\u03b2\u0303n )] consistently\nmatrix but possibly a different mean. Under enough regularity, \u2212 n1 [\u22072 log PL\nn\n\u221a\nestimates the limiting covariance of n(\u03b2\u0303n \u2212\u03b20 ). To get the mean, we use a parametric bootstrap\nas follows.\nAssume that the conditions of Theorem 4.2 hold. The residual \u03b2\u0303n \u2212 \u03b20 depends continuously on \u03b20 and the covariate process xt (i, j). Since \u03b2\u0303n is a consistent estimator of \u03b20 , we can\nestimate the bias in \u03b2\u0303n via a parametric bootstrap. We generate a bootstrap replicate dataset\n(r)\n(r)\n{(tm , im , Jm )} by drawing Jm , a random subset of Jtm (im ) with size |Jm | whose elements are\n(r)\ndrawn proportional to wtm (\u03b2\u0303n , im , *). We then get a bootstrap approximate MPLE, \u03b2\u0303n , by\n(r)\nf t , where\nmaximizing PL\nn\n\n(r)\n\nf t (\u03b2) =\nlog PL\n\nX \u001aX\n\ntm \u2264t\n\n(r)\n\nj\u2208Jm\n\nT\n\n\u03b2 xtm(im , j) \u2212\n\n(r)\n|Jm\n| log\n\n\u0002 X\n\nT\n\nexp{\u03b2 xtm(im , j)}\n\nj\u2208Jtm(im )\n\n\u001b\n\u0003\n\n.\n\nNote that xt (i, j) is determined from the original dataset, not the bootstrap dataset. For each\n(r)\nbootstrap replicate, we get a residual \u03b2\u0303n \u2212 \u03b2\u0303n . With R bootstrap replicates, we estimate the\nbias by\nR\nX\nd = 1\nbias\n\u03b2\u0303 (r) \u2212 \u03b2\u0303n .\nR r=1 n\nd\nWe adjust for estimator bias by replacing \u03b2\u0303n with \u03b2\u0303n \u2212 bias.\n\n4.3. Simulation\nWe show a simulation study to empirically verify the result of Theorem 4.2. In the study, we\nhave one sender, and a receiver count |J | ranging from 32 to 1000. Each receiver was assigned a\n\n\f\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u22121.5\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u22122.0\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\nLog10 Receiver Count\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n1.50\n1.75\n2.00\n2.25\n2.50\n2.75\n3.00\n\n\u22123.0\n\n\u22122.5\n\n9\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u22124.0\n\n\u22123.5\n\nLog10 Mean Squared Error\n\n\u22121.0\n\n\u22120.5\n\nPoint Process Modeling for Directed Interaction Networks\n\n\u25cf\n\u25cf\n\n2\n\n3\n\n4\n\n5\n\nLog10 Sample Size\n\nFig. 1. Multicast coefficient estimation error with approximate MPLE. Receiver count |J | is equal to the\nsquare root of sample size n along the dashed line.\n\nconstant covariate vector x(j) whose elements were independent Bernouli random variables with\nsuccess probability 12 . The components of the true coefficient vector \u03b2 were drawn independently\nfrom the standard Normal distribution.\nWe chose sample sizes n ranging from 32 to 100,000. For each receiver count |J |, we drew n\nmulticast messages, with the receiver set Jm for message m determined as follows: we determined\nthe size, |Jm |, by drawing from a geometric distribution with success probability p = 0.4, so that\nP{|Jm | = L} = (1\u2212p)L\u22121 p for L \u2265 1; once |Jm | P\nwas determined, we chose among all receiver sets\nwith cardinality |Jm |, with P{Jm = J} \u221d exp{ j\u2208J \u03b2 T x(j)}. Once we generated the message\ndata, we computed \u03b2\u0303 by maximizing the approximate log partial likelihood analogous to (8).\nFinally, we computed k\u03b2 \u2212 \u03b2\u0303k.\nWe repeated this procedure for 100 random replicates at each receiver count and sample size,\nand computed the mean squared error of \u03b2\u0303 by averaging the value of k\u03b2 \u2212 \u03b2\u0303k2 over all replicates.\nFigure 1 displays the results. From the spacings of the asymptotes of the solid lines in the figure,\nwe can see that if |J | does not grow with n, then the error k\u03b2 \u2212 \u03b2\u0303k2 is roughly O(|J |\u22122 ) for\nlarge n; strictly speaking, the assumptions of Theorem 4.2 do not hold in this scenario since\nGn = OP (n/|J |), but nevertheless the theorem predicts an error rate of O(|J |\u22122 ). For the\nTheorem 4.2 to apply, we require\u221athat |J | grow with n. From the slope of the dashed line in\n2\n\u22121\nFig. 1, we can see that\n\u221a if |J | = n, then k\u03b2 \u2212 \u03b2\u0303k is roughly OP (n ); this agrees with the\ntheorem, since Gn = n in this situation.\n5.\n\nFitting the model to a corporate e-mail network\n\nRecall from Section 1 that, given a set of interaction data triples (t, i, j), a primary modeling\ngoal lies in determining which characteristics and behaviors of the senders and receivers are\n\n\f10\n\nP. O. Perry and P. J. Wolfe\n\npredictive of interaction. The modeling and inference framework introduced above enables us to\ndirectly address these concerns, as we now demonstrate through the analysis of a corporate e-mail\nnetwork consisting of a large subset of the e-mail messages sent within the Enron corporation\nbetween 1998 and 2002. These e-mail interaction data give rise to the following questions:\nHomophily To what extent are traits shared between individuals (gender, department, or seniority) predictive of interaction behaviors?\nNetwork Effects To what extent are dyadic or even triadic network effects, as characterized\nby past interaction behaviors, relevant to predicting future interaction behaviors?\nWe undertake our analysis using the multicast proportional intensity modeling framework\ndeveloped in Sections 2 and 3 above, employing both static covariates reflecting actor traits,\nas well as dynamic covariates capturing network effects. The bootstrap technique introduced\nin Section 4 for multicast interactions is then used to reduce bias in the estimated effects, as\nwell as to demonstrate that our asymptotic approximations are reasonable in this data modeling\nregime. We conclude this section with a discussion of the goodness of fit of our model in this\nsetting, before turning our attention in Section 6 to an evaluation of the strength of homophily\nand network effects in explaining these data.\n5.1. Data and methods\nOur example analysis uses publicly available data from the Enron e-mail corpus (Cohen, 2009),\na large subset of the e-mail messages sent within the Enron corporation between 1998 and 2002,\nand made public as the result of a subpoena by the U.S. Federal Energy Regulatory Commission\nduring an investigation into fraudulent accounting practices. We analyze the dataset compiled by\nZhou et al. (2007), comprising 21,635 messages sent among 156 employees between November 13,\n1998 and June 21, 2002, along with the genders, seniorities, and departments of these employees.\nApproximately 30% of these messages have more than one recipient across their To, CC, and\nBCC fields, with a few messages having more than fifty recipients. In the subsequent analysis, we\nexclude messages with more than 5 recipients-a subjectively-chosen cutoff that avoids e-mails\nsent en masse to large groups.\nWe model these data using the multicast proportional intensity model of Section 4, with\nI = J = {1, 2, . . . , 156} and Jt (i) = I \\ {i}, and with static and dynamic covariates described\nin the next section. We fit the model by first maximizing the approximate log partial likef t (\u03b2) of (8), and then employing a parametric bootstrap to estimate and correct\nlihood log PL\nthe resultant bias in parameter estimates. We calculate standard errors using the corresponding\nasymptotic theory. In the setting of this example, the interaction count is high, so the asymptotic\nframework developed in Sections 3 and 4 is natural. The main violation of assumptions A1\u2013A4\nis that our covariates (described in Section 5.2) may in principle be unbounded; nevertheless,\nbootstrap calculations (described in Section 5.3) show that the asymptotic approximations we\nemploy remain reasonable in this regime.\nWe wrote custom software in the C programming language to fit the model using Newton's\nmethod. Our implementation exploits structure in the covariates to make the computational\ncomplexity of the fitting procedure roughly linear in the number of messages and the number of\nactors. Appendix A describes the fitting procedure in detail. It took approximately 20 minutes\nto fit the full model using a standard desktop computer with a 2.4 GHz processor and 4GB of\nRAM. Each bootstrap replicate took approximately 10 minutes to generate and fit, using the\noriginal estimate as a starting point for the fitting algorithm. Most of the complexity in the\nfitting procedure is due to the inclusion of triadic covariates as described below; including only\ndyadic covariates reduces the fitting time to approximately 1 minute.\n\n\fPoint Process Modeling for Directed Interaction Networks\n\nVariate\nL(i)\nT (i)\nJ(i)\nF (i)\n\nCharacteristic of actor i\nmember of the Legal department\nmember of the Trading department\nseniority is Junior\ngender is Female\n\n11\n\nCount\n25\n60\n82\n43\n\nFig. 2. Actor-specific traits, with counts of how many of the 156 actors share each trait\n\n5.2. Covariates\nThe goal of our investigation is to assess the predictive ability of actor traits and network effects.\nTo this end, we choose covariates that encode these traits and effects. Each covariate is encoded\nas a component of the time-varying dyad-dependent vector xt (i, j), which is linked to the rate of\ninteraction between sender i and receiver j via the multicast proportional intensity model of (1).\n\n5.2.1. Static covariates to measure homophily and group-level effects\nConsider first those actor traits that do not vary with time: the actors' genders, departments,\nand seniorities. We encode the traits of actor i and their second-order interactions using 9\nactor-dependent binary (0/1) variables, as described in Fig. 2.\nWe encode all 20 identifiable first-order interactions between the traits of sender i and receiver\nj as components of xt (i, j). We do this by using variates of the form Y (j) and X(i) * Y (j), where\nX and Y are chosen from the list of 4 actor-dependent variates (L, T , J, F ). We also include 4\nreceiver-specific covariates of the form 1 * Y (j). We cannot identify the coefficients for covariates\nof the form X(i)*1; if a component of xt (i, j) is the same for all values of j, then the corresponding\ncomponent of \u03b2 will not be identifiable since the product of the two can be absorbed into \u03bb\u0304t (i)\nwithout changing the likelihood.\nWe measure homophily by way of the estimated coefficients for covariates of the form X(i) *\nX(j). For example, if the sum of the coefficients of 1 * J(j) and J(i) * J(j) is large and positive,\nthis tells us that Junior employees exhibit homophily in their choice of message recipients.\n\n5.2.2. Dynamic covariates to measure network effects\nStatic effects are useful for determining which traits are predictive of the relative rate of interaction between sender i and receiver j, but they do not shed light on network effects. Therefore,\nwe are also interested in the predictive relevance of the dynamic network behaviors described in\nFig. 3. The first two behaviors (send and receive) are \"dyadic,\" involving exactly two actors,\nwhile the last four (2-send, 2-receive, sibling, and cosibling) are \"triadic,\" involving exactly\nthree actors.\nTo measure first-order dependence of message exchange behavior on these network effects, we\nintroduce binary indicators for all 6 effects as components of xt (i, j). These indicators depend\non the sender i, the receiver, j, and the history of the process at the current time t. By the\nshorthand notation 1{send}, we denote the indicator variable depending on sender i, receiver\nj, and the current time, t, which indicates if i has sent j a message before time t, with the\nremaining notations (1{receive}, 1{2-receive}, etc.) defined similarly.\nTo measure higher-order time dependence, we introduce additional covariates of the following\nform. We partition the interval [\u2212\u221e, t) into K = 7 sub-intervals:\n[\u2212\u221e, t) = [t \u2212 \u2206K , t \u2212 \u2206K\u22121 ) \u222a [t \u2212 \u2206K\u22121 , t \u2212 \u2206K\u22122 ) \u222a * * * \u222a [t \u2212 \u22061 , t \u2212 \u22060 )\n\n\f12\n\nP. O. Perry and P. J. Wolfe\n\nsend\n\ni\n\nreceive\n\ni \u001b\ni\n\n2-receive\n\ni \u001b\n\ni has sent j a message in the past\n\nj\n\n- h\n\n2-send\n\nsibling\n\n- j\n\ni has received a message from j in the past\n\n- j\n\nthere exists an actor h such that i has sent h a message and h has sent j a message in the past\n\nj\n\nthere exists an actor h such that i has received a\nmessage from h, and h has received a message from j\n\nh \u001b\n\nthere exists an actor h such that h has sent i and j\nmessages in the past\n\nh\n\u0001A\n\u0001 A\n\u0001\nU\nA\ni\nj\n\ncosibling\n\nh\n\nthere exists an actor h such that h has received messages from i and j\n\n\u0015A\nKA\n\u0001\u0001\n\u0001\nA\ni\nj\n\nFig. 3. Dynamic covariates to measure network effects\n\nwhere \u221e = \u2206K > \u2206K\u22121 > * * * > \u22061 > \u22060 = 0 and \"t \u2212 \u221e\" is defined to be \u2212\u221e. Specifically,\nwe set \u2206k = (7.5 minutes) \u00d7 4k for k = 1, . . . , K \u2212 1 so that for k in this range \u2206k takes the\nvalues 30 minutes, 2 hours, 8 hours, 32 hours, 5.33 days, and 21.33 days.\n(k)\n\nDefine the half-open interval It\ndyadic effects\n\n= [t \u2212 \u2206k , t \u2212 \u2206k\u22121 ). For k = 1, . . . , K we define the\n(k)\n\n(k)\n\n(k)\n\n(k)\n\nsendt (i, j) = #{i \u2192 j in It },\nreceivet (i, j) = #{j \u2192 i in It };\nfor sender i, such that these covariates measure the number of messages sent to, and respectively\n(k)\nreceived by, receiver j in time interval It .\nThe dyadic effects have been defined in the manner above to enable easy interpretation of the\ncorresponding coefficients. To illustrate this, for k = 1, . . . , K, suppose that \u03b2k is the coefficient\n(k)\ncorresponding to sendt (i, j). If we observe the message i \u2192 j at time t, then for future time\n0\nt in the interval (t, t + \u22061 ], the rate \u03bbt0 (i, j) will be multiplied be the factor e\u03b21 ; for t0 in the\ninterval (t + \u22061 , t + \u22062 ], the rate will be multiplied by e\u03b22 ; this continues similarly, with the rate\nbeing multiplied by e\u03b2k whenever t0 \u2208 (t + \u2206k\u22121 , t + \u2206k ]; equivalently, when \u2206k\u22121 < t0 \u2212 t \u2264 \u2206k .\nThus, the coefficients \u03b21 , . . . , \u03b2K measure the effect of a \"send event\" and how this effect decays\nover time. We expect that \u03b2k will decrease as k increases, but we do not enforce this constraint\non the estimation procedure.\nThe triadic effects involve pairs of messages. For k = 1, . . . , K and l = 1, . . . , K we define the\n\n\fPoint Process Modeling for Directed Interaction Networks\n\n13\n\ntriadic effects\n(k,l)\n\n2-sendt\n\n(i, j) =\n\nX\n\nh6=i,j\n(k,l)\n2-receivet (i, j)\n\n=\n\nX\n\nh6=i,j\n(k,l)\nsiblingt (i, j)\n\n=\n\nX\n\nh6=i,j\n(k,l)\ncosiblingt (i, j)\n\n=\n\nX\n\nh6=i,j\n\n(k)\n\n(l)\n\n(k)\n\n(l)\n\n(k)\n\n(l)\n\n(k)\n\n(l)\n\n#{i \u2192 h in It } * #{h \u2192 j in It },\n#{h \u2192 i in It } * #{j \u2192 h in It },\n#{h \u2192 i in It } * #{h \u2192 j in It },\n#{i \u2192 h in It } * #{j \u2192 h in It }.\n(k,l)\n\nFor sender i and receiver j, the covariate 2-sendt (i, j) counts the pairs of messages such that\n(k)\nfor some h distinct from i and j, message i \u2192 h occurred in interval It and message h \u2192 j\n(l)\noccurred in interval It ; the other covariates behave similarly.\nAs with the dyadic effects, the triadic effects are designed so that their coefficients have\na straightforward interpretation. However, since triadic effects involve pairs of messages, the\n(k,l)\ninterpretation is a bit more involved. We illustrate with the 2-sendt (i, j) covariate having\ncoefficient \u03b2k,l for k = 1, . . . , K and l = 1, . . . , K. Take i and j to be two actors. Suppose at\ntime t we observe the message h \u2192 j. At this point, we look through the history of the process\nfor all messages of the form i \u2192 h; when paired with the original h \u2192 j message, each of these\ndefines a \"2-send event.\" The other 2-send events are defined as follows: if at time s we observe\nthe message i \u2192 h, then we enumerate all observed messages h \u2192 j in the history of the process;\nwhen each of these is paired with the original i \u2192 h event it constitutes a 2-send event. A pair\n(s, t) can be associated with each 2-send event, where s is the time of the i \u2192 h message and t is\nthe time of the h \u2192 j message. At time t0 after s and t, the existence of the 2-send event causes\nthe sending rate \u03bbt0 (i, j) to be multiplied by the factor e\u03b2k,l , where t0 \u2208 (s + \u2206k\u22121 , s + \u2206k ] and\nt0 \u2208 (t + \u2206l\u22121 , t + \u2206l ]. We expect \u03b2k,l to decrease as k and l increase, though again we do not\nenforce this constraint in the fitting procedure.\nAs previously noted, Butts (2008) used a variant of the proportional intensity model to\ncapture interaction behavior in social settings. As such, a correspondence can be drawn between\ncertain of the covariates in Butts (2008) and those outlined above. If we set K = 1, then the sendt\ncovariate is equivalent to an unnormalized version of Butts' persistence covariate, and the sum\n(sendt +receivet ) becomes an unnormalized version of Butts' preferential attachment covariate.\nFor the triadic effects, Butts' OTP, ITP, ISP, and OSP covariates are analogous to the 2-send,\n2-receive, sibling, and cosibling P\ncovariates, although the exact definitions differ slightly. (For\nexample, OTPt (i, j) is defined as h min[#{i \u2192 h in (\u2212\u221e, t)}, #{h \u2192 j in (\u2212\u221e, t)}].) The\nversions of these covariates that we have introduced above, however, are designed to enable a more\nprecise quantification of the time-dependence of network effects, as well as a more straightforward\ninterpretation of the corresponding coefficients. In related models, Vu et al. (2011a,b) use similar\ncovariates, except that they do not partition [\u2212\u221e, t) into sub-intervals.\n5.3. Bootstrap bias correction\nGiven the model specification, data, and covariates outlined above, we can estimate the parameter\nvector \u03b20 under the approximate log partial likelihood of (8). Recall that the results of Section 4\nbound the bias resulting from this approximate MPLE procedure as a function of the growth rate\nof the recipient set J over time. Here, treating the set J of 156 Enron employees as constant,\nthe resultant bias is of order 1/|J |-and, since |J | = 156 is on the order of the square root\n\n\f14\n\nP. O. Perry and P. J. Wolfe\n\n\u25cf\n\nNormalized Residual\n\n2\n\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n0\n\n\u25cf\u25cf\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf\n\u25cf\n\n\u25cf\n\n\u22122\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf \u25cf \u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf \u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf \u25cf \u25cf \u25cf \u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf \u25cf\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf \u25cf \u25cf\u25cf \u25cf\u25cf\u25cf \u25cf \u25cf \u25cf\n\u25cf\n\u25cf \u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf \u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf \u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\n\u25cf\n\u25cf \u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u22124\n\n\u25cf\n\u25cf\n\n\u25cf\u25cf\n\u25cf\n\n\u22126\n\u25cf\n\n\u22128\n\nCosibling\n\nSibling\n\n2\u2212Receive\n\n2\u2212Send\n\nSend\n\nReceive\n\nStatic\n\n\u25cf\n\nTerm\n\nFig. 4. Enron bootstrap residuals. Summary of bootstrap residuals for estimated coefficients using the\nEnron dataset, normalized by estimated standard errors. The points (orange) show the means, and the\nerror bars (purple) show one standard deviation. Coefficients are grouped by model term.\n\nof the number 21,365 of messages in the dataset, we can correct this bias using the parametric\nbootstrap outlined at the end of Section 4.\nFig. 4 summarizes the corresponding bootstrap residuals (from 500 replicates) for each component of the estimated parameter vector \u03b20 ; we can see from this figure that treating messages\nwith multiple recipients as multiple single-recipient messages introduces bias on the order of the\nstandard error for most of the coefficients. There is a pronounced negative bias in coefficient\nestimates for the dyadic effects, which is representative of a more general phenomenon. Sparsity\nin the components of xt (i, j) (when considered as a function of j), when combined with high\nvalues of the corresponding entries \u03b2, leads to negative bias in the coefficient estimates when\nthere are messages with multiple recipients. The approximation in (7) is worst when for some\nj \u2217 , weight wtm (im , j \u2217 ) far exceeds all other values of wtm (im , j), so that wtm (im , j \u2217 ) \u2248 Wtm (im );\nf will avoid this situation by shrinking \u03b2 where xt (im , j)\nwhen |Jm | is large, the maximum of PL\nm\nis sparse. The dyadic covariates are particularly sparse, so the estimates for their coefficients are\nparticularly vulnerable to this bias.\nBesides correcting for bias, the bootstrap simulations give us confidence that the asymptotic\napproximations are reasonable. The simulated standard errors are very close to those predicted by\nthe theory, despite the norm kxt (i, j)k2 being potentially unbounded, contrary to the assumptions\nof Theorem 3.1.\n5.4. Goodness of fit\nFigure 5 details an ad-hoc analysis of deviance for the fitted model, showing how the approximate\ndeviance (twice the approximate log partial likelihood) behaves as we add consecutive terms to\nthe model. Group-level (static) effects account for 15% of the null deviance and network effects\naccount for 37%. The most dramatic decrease in the residual deviance comes from introducing\nthe \"Send\" terms into the model; with only 8 degrees of freedom, they are able to account for\n33% of the null deviance. The full model accounts for 52% of the null deviance.\nThe residual deviance for the full model is approximately 4.8 times the residual degrees\nof freedom, and so an ad-hoc adjustment for this over-dispersion is to multiply the calculated\n\n\fPoint Process Modeling for Directed Interaction Networks\n\nTerm\nNull\nStatic\nSend\nReceive\nSibling\n2-Send\nCosibling\n2-Receive\n\nDf\n\nDeviance\n\nResid. Df\n\nResid. Dev\n\n20\n8\n8\n50\n50\n50\n50\n\n50365\n107942\n5919\n3601\n516\n1641\n158\n\n32261\n32241\n32233\n32225\n32175\n32125\n32075\n32025\n\n325412\n275047\n167105\n161186\n157585\n157069\n155428\n155270\n\n15\n\nFig. 5. Ad-hoc analysis of deviance for the Enron model. Residual deviance is defined as twice the\napproximate negative log partial likelihood from (8). The \"Static\" term contains the group level effects, and\nthe other terms contain the network effects.\n\n\u221a\nstandard errors by 4.8 \u2248 2.2.\nNote, however, that the residual deviance by itself is not adequate as a goodness-of-fit measure, as it depends only on the estimated coefficients (see Section 4.4.5 of McCullagh and Nelder\n(1989) for discussion of a related problem for logistic regression with sparse data). To shed more\nlight on how well the model fits these data, we use a normalized version of the martingale residual\nfrom Therneau et al. (1990), which we call a Pearson residual. Specifically, given \u03b2\u0302, we define\nN\u0302t (i, j) =\n\nX wt (\u03b2\u0302, i, j)\nm\n\ntm \u2264t\n\nWtm (\u03b2\u0302, i)\n\n1{im = i},\n\nR\nwhich is the expected number of i \u2192 j events given the estimated model, with \u03bb\u0304t (i) dt\nR\nP\nestimated by the Breslow (1974) estimate Wt (\u03b2\u0302, i)\u22121 j dNi,j (t). The martingale residual\nanalogous to that of Therneau et al. (1990) is then defined as Nt (i, j) \u2212 N\u0302t (i, j); we normalize this quantity by an estimate of its standard deviation to get a \"Pearson\" residual:\n(Nt (i, j) \u2212 N\u0302t (i, j))/{N\u0302t (i, j)}1/2 .\nFig. 6a shows a plot of N\u221e (i, j) versus N\u0302\u221e (i, j) for two different models. In the \"static\"\nmodel, we only include the static covariates, while in the full (\"static and dynamic\") model, we\nalso include all six types of network covariates. The fit for the static model is poor. For instance,\nit repeatedly predicts up to 200 i \u2192 j events where we only observed 1 or 2; likewise, the model\npredicts 1 or fewer events where we observed up to 20. For the full model, which includes the\ndynamic covariates to account for network effects, the fit is much better, with the relationship\nbetween observed and expected interaction counts being roughly linear.\nFig. 6b shows the Pearson residuals. For the full model, more than 95% are less than 1.21\nin absolute value, and the maximum absolute residual is 18.7. In contrast, the 95% quantile for\nthe absolute residuals in the static model is at 3.5, and the maximum absolute residual is 182.7.\nThe sum of squares if the residuals (X 2 ) is 17281 in the full model, over 34 times lower than that\nfor the static model (596253). We don't know what a \"reasonable\" value for X 2 is; an ad-hoc\ndegrees of freedom calculation suggests that for the full number this should be roughly equal to\n23944 = 156 * 155 \u2212 (20 + 2 * 8 + 4 * 50), which suggests that the full model is too aggressive. The\nbootstrap simulations confirm this, with 17055 being 5.6 standard deviances below the mean\nvalue X 2 for the bootstrap replicates.\nFor a more parsimonious model, we might drop most of the triadic effects. Indeed, the model\nwhich only uses dyadic effects has a X 2 value of 21094. However, at this stage we desire a model\nwith the lowest possible bias, and also wish to acquire estimates for all of the network effects.\n\n\f16\n\nP. O. Perry and P. J. Wolfe\n\n(a) Observed count N\u221e (i, j) plotted against expected count N\u0302\u221e (i, j)\n\n(b) Pearson residual (N\u221e (i, j) \u2212 N\u0302\u221e (i, j))/{N\u0302\u221e (i, j)}1/2 vs. expected count\nFig. 6. Goodness of fit plots for two models\n\n6.\n\nEvaluating the strength of homophily and network effects\n\nGiven the model fitting procedure and results described above, we may now evaluate the strength\nof homophily and network effects in predicting the interaction behavior observed in our data.\n6.1. Assessing evidence for homophily in the Enron data\nThe analyses of Section 5 above have established that our multicast proportional intensity model\nwith chosen covariates is reasonably accurate in describing message recipient selection, conditional on the sender and the history of the process. Thus, we are justified in using the estimated\ncoefficients from the model to assess the predictive ability of the corresponding covariates.\n\n\fPoint Process Modeling for Directed Interaction Networks\n\n17\n\nReceiver\nSender\n1\nL\nT\nJ\nF\n\nL\n\nT\n\nJ\n\nF\n\n-0.91\n\n-0.36\n\n-0.34\n\n0.04\n\n(0.04)\n\n(0.04)\n\n(0.04)\n\n(0.03)\n\n0.63\n\n0.28\n\n0.22\n\n0.15\n\n(0.05)\n\n(0.05)\n\n(0.04)\n\n(0.04)\n\n0.32\n\n0.43\n\n0.27\n\n-0.07\n\n(0.07)\n\n(0.05)\n\n(0.05)\n\n(0.05)\n\n0.06\n\n0.28\n\n0.37\n\n-0.13\n\n(0.05)\n\n(0.04)\n\n(0.03)\n\n(0.03)\n\n0.59\n\n-0.21\n\n-0.09\n\n0.15\n\n(0.05)\n\n(0.05)\n\n(0.04)\n\n(0.03)\n\nFig. 7. Estimated coefficients and standard errors for group-level covariates of the form X(i) * Y (j),\nwhere i is the sender, j is the receiver, and X(i) and Y (j) are given in the row and column headings; dark\ncoefficients are significant (via Wald test) at level 10\u22123 .\n\nOur first task is to gauge the predictive strength of homophily. To this end, Fig. 7 shows the\nestimated group-level coefficients for our model. Notably, homophily is evident for all almost all\nmain effects (Department, Seniority, and Gender): the estimated coefficients of L(j), T (j), and\nJ(j) are all negative, while the sum of the estimated coefficients of F (j) and F (i)*F (j) is positive.\nNegative homophily is evidenced in that the sum of the coefficients for L(j) and L(i) * L(j) is\nnegative. The coefficient of F (j) and the sum of the coefficients for T (j) and T (i) * T (j); and\nJ(j) and J(i) * J(j) are not significant.\nTaking Gender as an example, the way the homophily effect manifests is as follows: if i\nis a Female sending a message at time t, and person j is identical to person j 0 except for\nGender, then i is more likely to send to the similarly-gendered individual. The relative rate is\nexp(0.04 + 0.15) \u2248 1.2. The characterization for other types of homophily is similar.\nConspicuously, the only example of negative homophily is when the sender i is in the Legal\ndepartment. In this case, if person j is identical to person j 0 except for Department, then i is\nmore likely to send to an individual in a different department. The relative rates for the three\ndepartments are exp(0.63 \u2212 0.91) \u2248 0.76 for the Legal department, exp(0.28 \u2212 0.36) \u2248 0.92 for\nthe Trading department, and exp(0) = 1 for any Other department.\nWere we interested only in homophily, we might be tempted to forgo the proportional intensity\nmodel of (1), and instead perform a contingency table analysis. The supplementary material\nexplores this approach in detail. The major shortcoming of the contingency table approach is that\nit assumes that the messages are independent, which leads to bias in the parameter estimates.\n6.2. Evaluating the importance of network effects\nIn Section 6.1 we established that homophily was predictive of sending behavior, even after\naccounting for network effects. We now investigate the characteristics of these network effects\nand establish which of these effects are of greatest importance.\nTo begin our analysis, Fig. 8 shows the estimated coefficients for the network indicator effects, giving a crude picture of the predictive importance of each network effect. The estimated\ncoefficients are all positive, indicating that network effects strengthen the ties between individu-\n\n\f18\n\nP. O. Perry and P. J. Wolfe\nVariate\n\n1{send}\n\nCoefficient\n(SE)\n\n1{receive}\n\n1{2-send}\n\n1{2-receive}\n\n1{sibling}\n\n1{cosibling}\n\n3.26\n\n0.97\n\n0.67\n\n0.01\n\n1.06\n\n0.09\n\n(0.03)\n\n(0.02)\n\n(0.05)\n\n(0.04)\n\n(0.05)\n\n(0.04)\n\nFig. 8. Estimated coefficients for network indicator effects\nSend\n\nReceive\n\nCoefficient\n\n1.5\n\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n\n0\n0\n\n30m 2h\n\n8h 1.3d 5.3d 21.3d \u221e\n\n0\n\n30m 2h\n\n8h 1.3d 5.3d 21.3d \u221e\n\nTime Elapsed\n\nFig. 9. Estimated coefficients for dyadic effects, with standard errors\n\nals. The estimated coefficient for 1{send} is over three times larger than the other coefficients,\nagreeing with the general notion that one is most likely to do today the things one did yesterday.\nThe next tier of indicator effects comprises 1{receive}, 1{sibling}, and 1{2-send}, whose estimated coefficients range from 0.67 to 1.06. Two triadic effects, 1{2-receive} and 1{cosibling},\nare not significantly predictive of sending behavior.\nThe estimated coefficients for the recency-dependent covariates, shown in Figs. 9 and 10,\ngive a more complete picture of network effects. Firstly, we can see that dyadic effects persist\nfor over three weeks from the time a message is sent. The decay of the estimated coefficients\nis roughly exponential in the time elapsed, corresponding to a super-exponential decay in the\nrelative sending rate. For 30 minutes after i sends a message to j, our estimated model predicts\nthat the rate at which i sends to j will be multiplied by exp(1.11) \u2248 3.05, and the rate at which\nj sends to i will be multiplied by exp(1.85) \u2248 6.39; then, between 30 minutes and 2 hours, the\nrates will be multiplied by exp(0.51) \u2248 1.67 and exp(0.70) \u2248 2.02, respectively; this proceeds\nsimilarly until after 21.3 days, when the rates will be multiplied by exp(0.003) \u2248 1.002 and\nexp(0.002) \u2248 1.002.\n(k)\n(k)\nComparing the coefficients for sendt with those of receivet we see that the latter are\nhigher for k \u2264 2, while the former are higher for k > 2. The corresponding intuition is that if\nA is sending a message up to two hours after receiving a message from B, then A is likely to\nrespond to B, but after that, A is more likely to send to an individual whom A e-mailed at the\ntime of receiving B's original message (provided B and this other individual are identical in all\nother respects). The time window during which reciprocation is more important than past habit\nis less than 8 hours.\n\n\fPoint Process Modeling for Directed Interaction Networks\n\n19\n\nSecond Time Elapsed\n30m 2h\n\n8h 1.3d 5.3d 21.3d \u221e\n\nFirst Time Elapsed\n\n30m\n2h\n8h\n1.3d\n5.3d\n21.3d\n\u221e\n\n30m\n2h\n8h\n1.3d\n5.3d\n21.3d\n\u221e\n\n\u22120.45\n\n\u22120.30\n\n30m 2h\n\n8h 1.3d 5.3d 21.3d \u221e\n\n2\u2212Send\n\n2\u2212Receive\n\nSibling\n\nCosibling\n\n\u22120.15\n\n0.00\n\n0.15\n\n0.30\n\n0.45\n\nCoefficient\n\nFig. 10. Estimated coefficients for triadic effects, with standard errors\n\nFrom Fig. 10, we can see that the triadic effects are in general less pronounced and are much\nmore short-lived than the dyadic effects. About 86% of the estimated coefficients are within\n3 standard errors of 0; even those that are significantly nonzero mostly lie between \u22120.05 and\n(1,1)\n(2,2)\n(3,2)\n+0.05. The exceptions are the coefficients for siblingt\n(0.51), siblingt\n(\u22120.14), siblingt\n(1,2)\n(4,1)\n(4,2)\n(0.15), cosiblingt\n(0.32), 2-receivet\n(\u22120.21), and 2-receivet\n(0.09). We may interpret\nthese coefficients as follows:\nsibling If B sent A and C messages in the last 30 minutes or between two and eight hours ago,\nthen A and C are more likely to send messages to each other; however, if B sent A and\nC messages between 30 minutes and two hours ago, then A and C are less likely to send\nmessages to each other.\ncosibling If A sent a message to B in the last 30 minutes, and C sent a message to B between\n30 minutes and two hours ago, then A will send to B at a higher rate.\n2-receive If A sent a message to B in the last 30 minutes, and B sent a message to C between\n8 hours and 32 hours ago, then C will send to A at a lower rate; if, however, the message\nfrom A to B was sent between 30 minutes and two hours ago, then C will send to A at a\nhigher rate.\nGiven the emphasis on transitivity in the networks literature, it may at first seem disconcerting that most of the estimated coefficients for the time-dependent triadic effects are found\nto be insignificant in this analysis. However, one must bear in mind that, except for messages\nsent to them directly, individuals likely have no knowledge of their colleagues' e-mail activities,\n\n\f20\n\nP. O. Perry and P. J. Wolfe\n\nand therefore there is no reason why this activity should directly affect sending behaviors. Any\npredictive power the triadic effects have, then, must be due to correlation with exogenous factors.\nIn this light, it is not surprising that the triadic effects are small and have small time horizons.\nThe results above provide a detailed view of the ways in which network effects can manifest\nthemselves in data. The supplementary material contains comparative analyses based on an\nactor-oriented model and an exponential random graph model. (See Snijders et al. (2010) and\nAnderson et al. (1999), respectively, for detailed surveys.) These analyses further bolster our\nconfidence in the results of this section.\n7.\n\nConclusion\n\nOur analysis of the Enron corpus in Sections 5 and 6 above has demonstrated the ways in\nwhich static and dynamic effects manifest themselves in e-mail communication networks, and we\nexpect similar conclusions to hold broadly for other types of directed interaction data. Relative to\nalternatives such as contingency table analyses, actor-oriented network models, and exponential\nrandom graph models, an advantage of our approach lies in its ability to model the given data\ndirectly, rather than in an aggregated form. We are able to adjust for network effects to get\nmore reliable estimates of homophily, and by using continuous-time information we get precise\nquantification on the time-dependent behavior of the network effects.\nIn this work, our focus has been on the coefficient vector \u03b2. We have used partial likelihood\nfor its estimation, enabling us to treat each sender-specific baseline intensity \u03bb\u0304t (i) as a nuisance parameter. Were we to use the model for prediction, we would need to estimate baseline\nintensities; this could be done using a Nelson-Aalen estimator as in Andersen et al. (1993).\nThe foundation of our work is Cox's (1972) proportional intensity model and partial likelihood\ntheory, tools which he first introduced almost forty years ago and which have been significantly\ndeveloped since then (Cox, 1975; Fleming and Harrington, 1991; Andersen et al., 1993; Martinussen and Scheike, 2006; Cook and Lawless, 2007). These tools are used extensively in the\ncontext of survival analysis, but require further development for use in modeling interaction data.\nIn this vein, we have extended the associated theory in two directions: first, we have provided\nresults that are asymptotic in time rather than in the size of the population under study; and\nsecond, we have shown that treating multicast interactions via duplication leads to bias in the\nparameter estimates (which can in turn be corrected in certain regimes).\nWe find the proportional intensity model with time-varying covariates to be particularly useful\nfor modeling repeated directed interactions. The model is simple, flexible, and well established,\nand it facilitates investigation into which traits and behaviors are predictive of interaction.\nAcknowledgement\nWe thank Joe Blitzstein, Susan Holmes, Art Owen, and Andrew Thomas for helpful remarks\nand encouragement. We benefited from many helpful comments by the reviewers at JRSS, who\nbrought the paper by Butts (2008) to our attention and pushed us to expand the data analysis\nsection. Work supported in part by the Army Research Office under PECASE Award W911NF09-1-0555, the Office of Naval Research under MURI Award 58153-MA-MUR, and the Royal\nSociety under a Wolfson Research Merit Award.\nA.\n\nImplementation\n\nTo compute the maximum partial likelihood estimator, we use Newton's method as described in\nBoyd and Vandenberghe (2004). This requires an efficient algorithm for computing the gradient\n\n\fPoint Process Modeling for Directed Interaction Networks\n\n21\n\nand Hessian of the log partial likelihood. For simplicity, we describe the case of strictly pairwise\ninteractions with no ties in the interaction times. We use the notation from Section 2, with the\nmodel from (1) and the partial likelihood from (2). Recall that xt (i, j) is in Rp . Assume that\n|I| = I and |J | = J.\nSuppose (t1 , i1 , j1 ), . . . , (tn , in , jn ) is the sequence of observed interactions. Set n(i) = #{im :\nim = i}. The partial likelihood factors into a product of terms, one for each sender:\nPLt (\u03b2) =\n\nY\n\nPLt (\u03b2, i),\n\nPLt (\u03b2, i) =\n\nY wt (\u03b2, i, jm )\nm\n.\nWtm (\u03b2, i)\n\ntm \u2264t,\nim =i\n\ni\u2208I\n\nThis factorization allows us to compute log PLt (\u03b2) and its derivatives by computing the senderspecific terms in parallel and then adding them together.\nThe gradient and Hessian of the sender-specific log partial likelihood are respectively\nX\nX\nEtm (\u03b2, i)\n(10a)\nxtm(i, jm ) \u2212\n\u2207[log PLt (\u03b2, i)] =\ntm \u2264t,\nim =i\n\ntm \u2264t,\nim =i\n\n\u2212\u22072 [log PLt (\u03b2, i)] =\n\nX\n\nVtm (\u03b2, i),\n\n(10b)\n\ntm \u2264t,\nim =i\n\nwhere Et (\u03b2, i) and Vt (\u03b2, i) are as defined in (5a) and (5b). When xt (i, j) is constant over\ntime, sufficient statistics for \u03b2 imply that these formulae simplify. Otherwise, computing the\nfirst two derivatives of log PLtn (\u03b2) necessitates iterating over all messages, potentially requiring\ntime O(n J p2 ). For small- to medium-sized datasets, this is manageable, but for large network\ndatasets it can become prohibitive. In the sequel we show how to exploit sparsity to drastically\nreduce the computation time.\nA.1. Initial values\nWe will need to compute W0 (\u03b2, i), w0 (\u03b2, i, j), E0 (\u03b2, i), and V0 (\u03b2, i) for all values of i and j.\nIn the worst case, doing so will take O(I J p2 ). However, often the senders belong to a small\nnumber, I \u0304 \u001c I of groups such that if i and i0 are in the same group, then the corresponding\nvalues of W0 , \u03c00 , E0 , and V0 are the same, reducing the total complexity to O(I \u0304 J p2 ). The\nremaining complexity estimates assume that the initial values have all been pre-computed.\nA.2. Exploiting sparsity\nWe first decompose x into its static (non-time-varying) and dynamic parts as follows:\nxt (i, j) = x0 (i, j) + \u2206xt (i, j).\n\n(11)\n\nTypically, we can quickly compute the dynamic part \u2206xt (i, j) at each observed message time by\nincrementally updating it. Further, \u2206xt (i, j), is zero for most (i, j) pairs-often \u2206xt (i, j) is zero\nunless i and j have a common acquaintance or they have interacted in the past. For convenience,\nset J0 (i) = J . Let\nJ \u0304(i) = {j \u2208 J : j \u2208 Jt (i) and \u2206xt (i, j) 6= 0 for some t } \u222a {j \u2208 J : j \u2208\n/ Jt (i) for some t }.\n \u0304\nFor fixed t and i, assume that computing \u2206xt (i, j) for all values of j takes amortized time O(dJ).\n\n\f22\n\nP. O. Perry and P. J. Wolfe\n\nSince J0 (i) = J , we have that\n\nwt (\u03b2, i, j) = w0 (\u03b2, i, j) * exp{\u03b2 T \u2206xt (i, j)} * 1{j \u2208 Jt (i)}\n= w0 (\u03b2, i, j) + \u2206wt (i, j);\nX\n\u2206wt (i, j);\nWt (\u03b2, i) = W0 (\u03b2, i) +\nj\u2208J \u0304(i)\n\nwhere\n\u2206wt (i, j) = w0 (\u03b2, i, j)[exp{\u03b2 T \u2206xt (i, j)}1{j \u2208 Jt (i)} \u2212 1];\n\nhere we have used that \u2206wt (i, j) is zero unless j \u2208 J \u0304(i). Write\n\u03c0t (\u03b2, i, j) =\n\nwt (\u03b2, i, j)\n;\nWt (\u03b2, i)\n\nthen, defining\nW0 (\u03b2, i)\n,\nWt (\u03b2, i)\nwe can express \u03c0t (\u03b2, i, j) as follows:\n\u03b3t (i) =\n\n\u2206\u03c0t (\u03b2, i, j) =\n\n\u2206wt (\u03b2, i, j)\n,\nWt (\u03b2, i)\n\n\u03c0t (\u03b2, i, j) = \u03b3t (i)\u03c00 (\u03b2, i, j) + \u2206\u03c0t (\u03b2, i, j).\nMoreover, given the initial values W0 (\u03b2, i) and w0 (\u03b2, i, j), we can efficiently keep track of \u03b3t (i)\n \u0304\nand \u2206\u03c0t (\u03b2, i, j): for any i and t, it takes amortized time O(Jdp)\nto evaluate \u03b3t (i) and all values\nof \u2206\u03c0t (i, j) as j varies.\nA.3. Computing the gradient\nP\nIn evaluating the gradient of the log partial likelihood as given by (10a), the sum\nm xtm (i, jm )\nP\ncan be computed in time O(n p), while the computationally expensive term is m Etm (\u03b2, im ). In\nthe sequel we show how to exploit sparsity in x to reduce the associated computational overhead.\nTo simplify the notation, we suppress the dependence of all quantities on \u03b2 and i. Consider\n\u03c0t and \u2206\u03c0t to be vectors of length J, and write\n\u03c0t = \u03b3t \u03c00 + \u2206\u03c0t .\nAlso, let Xt = Xt (i) and \u2206Xt = \u2206Xt (i) be the J \u00d7 p matrices whose jth rows are xt (i, j) and\n\u2206xt (i, j), respectively, so that\nXt = X0 + \u2206Xt .\nUsing these expressions, we obtain\nEt = XtT \u03c0t = \u03b3t E0 + X0T \u2206\u03c0t + \u2206XtT \u03c0t ,\nand thus,\n\nX\n\nm\nim =i\n\nEtm =\n\n\u0010X\n\nm\nim =i\n\n\u0011\n\u0010X\n\u0011 X\n\u03b3tm E0 + X0T\n\u2206\u03c0tm +\n\u2206XtTm \u03c0tm .\nm\nim =i\n\nm\nim =i\n\nTaking advantage of the sparsity in \u2206Xt and \u2206\u03c0t , computing the three sums on\n\u0010 Pthe right\n\u0011\n\u0001\n \u0304\nhand side takes time O n(i) J d p . Once the sums are known, the multiplication\n\u03b3tm E0\n\u0001\nP\ntakes time O(p), and the multiplication\nX0T\n\u2206\u03c0tm takes time O(J \u0304 p). Thus, we can compute\n\u0001\nP\nm Etm in time O n(i) J \u0304 d p . Computing these terms separately for each i and then summing\nim =i\nover all i to get the total gradient requires time O(n J \u0304 d p + I p).\n\n\fPoint Process Modeling for Directed Interaction Networks\n\n23\n\nA.4. Computing the Hessian\nComputing the Hessian according to P\n(10b) proceeds similarly to the case of the gradient. We\nneed to efficiently compute the sum m Vtm (\u03b2, im ); while a naive computation requires time\nO(n J p2 ), this can be significantly improved by exploiting sparsity in xt (i, j).\nTo this end, define \u03a0t (\u03b2, i) to be the J \u00d7 J diagonal matrix with [\u03a0t (\u03b2, i)]jj = \u03c0t (\u03b2, i, j), and\nset \u2206\u03a0t (\u03b2, i) = \u03a0t (\u03b2, i) \u2212 \u03a00 (\u03b2, i). Suppressing the dependence on \u03b2 and i, we have\nVt = XtT [\u03a0t \u2212 \u03c0t \u03c0tT ]Xt\n\n= X0T [\u03a0t \u2212 \u03c0t \u03c0tT ]X0 + \u2206XtT [\u03a0t \u2212 \u03c0t \u03c0tT ]X0\n\n+ X0T [\u03a0t \u2212 \u03c0t \u03c0tT ]\u2206Xt + \u2206XtT [\u03a0t \u2212 \u03c0t \u03c0tT ]\u2206Xt .\n\nThe first of these terms reduces to\nX0T [\u03a0t \u2212 \u03c0t \u03c0tT ]X0 = \u03b3t V0 + \u03b3t (1 \u2212 \u03b3t )E0 E0T \u2212 E0 (\u03b3t \u2206\u03c0t )T X0T\n\n\u2212 X0 (\u03b3t \u2206\u03c0t )E0T + X0T [\u2206\u03a0t \u2212 \u2206\u03c0t \u2206\u03c0tT ]X0 ,\n\nand the second can be expressed as\n\u2206XtT [\u03a0t \u2212 \u03c0t \u03c0tT ]X0 = (\u03b3t \u2206Xt \u03c0t )E0T + \u2206XtT [\u03a0t + \u03c0t \u2206\u03c0tT ]X0 .\nThe third term is the transpose\nof the second; the fourth does not simplify.\nP\nm Vtm , we only accumulate sums of terms that change with time:\nTo compute the sum\nim =i\n\n\u03b3t , \u2206\u03c0t , \u03b3t (1 \u2212 \u03b3t ), \u03b3t \u2206\u03c0t , \u2206\u03c0t \u2206\u03c0tT , \u03b3t \u2206Xt \u03c0t , \u2206XtT [\u03a0t + \u03c0t \u2206\u03c0tT ], and \u2206XtT [\u03a0t \u2212 \u03c0t \u03c0tT ]\u2206Xt .\nDoing so takes time O(J \u0304 d p2 ) for each time increment. As with the gradient computation, we\ncompute the sums separately for each i and then sum over all i, so that the total computation\ntime is O(n J \u0304 d p2 + I p2 ).\nA.5. Total computation time\nTo perform one Newton step in maximization of the log partial likelihood of (2), we must first\ncompute the gradient and Hessian of the log partial likelihood at the current value of \u03b2, and then\ncompute the inverse of the Hessian and its product with the gradient. Once we have the Hessian,\ncomputing its inverse takes time O(p3 ). Typically, it takes O(1) Newton steps to compute the\nmaximum of a convex function (the constant is often below 30). The key factors in determining\n \u0304 J,\n \u0304 and d:\nthe computation time using the factors laid out above are I,\n\u2022 The value of I \u0304 depends on the structure of x0 (i, j). Specifically, I \u0304 is equal to the number\nof distinct values of the matrix X0 (i) as i varies. For the Enron data, we have that I \u0304 = 12:\neach sender belongs to one of 12 groups determined by group (L/T/O), seniority (J/S),\nand gender (F/M), and so the matrix X0 (i) depends only on the group of i.\n\u2022 The value of J \u0304 depends on the sparsity of xt (i, j). If xt (i, j) includes only dyadic network\neffects, then J \u0304 will typically be of size O(1) or O(J \u03b1 ) for a fractional value \u03b1; when we\nadd triadic effects, this size will typically grow to at most O(J 2\u03b1 ).\n\u2022 The value of d depends on further structure in xt (i, j). In our implementation, d = O(1)\n \u0304 for triadic effects.\nfor dyadic effects and d = O(J)\nThe total computational cost per Newton step is thus O(I \u0304 J p2 + n J \u0304 d p2 + I p2 + p3 ), with the\nsignificance of this expression being that it is nearly linear in I, J, and n. Thus, the algorithm\nscales naturally to large datasets.\n\n\f24\n\nB.\n\nP. O. Perry and P. J. Wolfe\n\nResults from Section 3\n\nB.1. Proof of Theorem 3.1\nRt\nObserve that the process Nt (i, j) has compensator\n\u039bt (i, j) = 0 \u03bbP\ns (i, j) ds; similarly, processes\nP\nNt (i) and Nt have compensators \u039bt (i) = j\u2208J \u039bt (i, j) and \u039bt = i\u2208I \u039bt (i). Correspondingly,\ndefine local martingales Mt (i, j) = Nt (i, j) \u2212 \u039bt (i, j), Mt (i) = Nt (i) \u2212 \u039bt (i), and Mt = Nt \u2212 \u039bt ;\nalso define\nHt (i, j) = xt (i, j) \u2212 Et (\u03b20 , i),\n\nwhere Et (\u03b2, i) is as defined in (4a).\nAs observed by Andersen and Gill (1982), the score function Ut (*) evaluated at \u03b20 has a\nsimple representation in terms of these processes:\nXXZ t\nXXZ t\nHs (i, j) dMs (i, j),\nHs (i, j) dNs (i, j) =\nUt (\u03b20 ) =\ni\u2208I j\u2208J\n\n0\n\n0\n\ni\u2208I j\u2208J\n\nRt\nP\nsince j\u2208J 0 Hs (i, j) d\u039bs (i, j) = 0. Since by Assumption A1, x is uniformly bounded, H is as\nwell. Each term in the sum above is thus locally square integrable, with predictable covariation\n\u001cZ\n\u001d\nZ\nHs (i, j) dMs (i, j),\nHs (i0 , j 0 ) dMs (i0 , j 0 )\n=\n\nZ\n\nt\n\nt\n\n0\n\n=\n\nZ\n\n0\n\nt\n\nHs (i, j) \u2297 Hs (i0 , j 0 ) d M (i, j), M (i0 , j 0 )\n\ns\n\n\u0002\n\u0003\u22972\nHs (i, j)\nd\u039bs (i, j) * 1{i = i0 , j = j 0 }\n\n(Fleming and Harrington, 1991, Thm. 2.4.3). There exists a sequence of stopping times localizing\nall M (i, j) simultaneously, so U (\u03b20 ) is locally square integrable with predictable variation\nXXZ t\u0002\nXZ t\n\u0003\u22972\nU (\u03b20 ) t =\nHs (i, j)\nd\u039bs (i, j) =\nVs (\u03b20 , i) d\u039bs (i).\n(12)\ni\u2208I j\u2208J\n\n0\n\ni\u2208I\n\n0\n\nNow we rescale time. For each positive n define a discretized time-scaled version of the score\nthat is right-continuous with limits from the left. The process is defined for times \u03b1 in [0, 1];\nbetween times in [ nk , k+1\nn ), it takes the value Utk ; i.e.,\n\u0168\u03b1(n) (\u03b2) = Utb\u03b1nc (\u03b2).\n\n(13)\n\n(n)\n\nPart (a): Lemma B.1 shows that \u0168\u03b1 (\u03b20 ) is a square-integrable martingale adapted to\n= Ftb\u03b1nc , the \u03c3-algebra of events prior to tb\u03b1nc . Since it only depends on values at jump\ntimes, the quadratic variation of \u0168 (n) (\u03b20 ) at time \u03b1 is equal to the quadratic variation of U (\u03b20 )\nat time tb\u03b1nc . Therefore, since quadratic and predictable variation have the same limit when\n\n(n)\nF\u0303\u03b1\n\nP\n\nit exists (Rebolledo, 1980, Prop. 1), assumption A2 implies that h \u221a1n \u0168 (n) (\u03b20 )i\u03b1 \u2192 \u03a3\u03b1 (\u03b20 ).\n\nLemma B.2 in turn verifies that \u221a1n \u0168 (n) (\u03b20 ) satisfies a Lindeberg condition necessary for the\napplication of Rebolledo's (1980) Martingale Central Limit Theorem. Thus the process converges\nin distribution to a Gaussian process with covariance function \u03a3\u03b1 (\u03b20 ) as claimed.\nPart (b): Recalling Mt (i) = Nt (i) \u2212 \u039bt (i), combine (5b) and (12) to obtain the relation\nX Z tb\u03b1nc\nVs (\u03b20 , i) dMs (i) = Itb\u03b1nc (\u03b20 ) \u2212 \u0168 (n) (\u03b20 ) \u03b1 .\n(14)\ni\n\n0\n\n\fPoint Process Modeling for Directed Interaction Networks\n\n25\n\nWhen \u03b1 \u2208 [0, 1], a repeated application of the triangle inequality to\n1\nn Itb\u03b1nc (\u03b2\u0302n )\n\nusing the relation of (14) yields\n1\nn Itb\u03b1nc (\u03b2\u0302n )\n\n\u2212\n\n1\nn\n\n\u0001\nItb\u03b1nc (\u03b20 ) \u2212 Itb\u03b1nc (\u03b20 ) \u2212 \u03a3\u03b1 (\u03b20 )\n\nZ\n1 X tb\u03b1nc\n{Vs (\u03b2\u0302n , i) \u2212 Vs (\u03b20 , i)} dNs (i)\n\u2212 \u03a3\u03b1 (\u03b20 ) \u2264\nn i 0\nZ\nZ\n1 X tb\u03b1nc\n1 X tb\u03b1nc\n+\nVs (\u03b20 , i) dMs (i) +\nVs (\u03b20 , i) d\u039bs (i) \u2212 \u03a3\u03b1 (\u03b20 ) .\nn i 0\nn i 0\n\nWe show that all three terms converge to zero in probability. The first term above is uniformly\nP\nbounded by supn0 ,i kVtn0 (\u03b2\u0302n , i)\u2212Vtn0 (\u03b20 , i)k, which converges to zero since \u03b2\u0302n \u2192 \u03b20 by hypothesis\nof the theorem and {Vtn0 (*, i)} is an equicontinuous family by assumption A4. Lemma B.3\nproves, as a consequence of assumption A3 and Lenglart's (1977) Inequality, that the second\nterm converges to zero uniformly in \u03b1. The third term converges to zero by assumption A2,\nthereby concluding the proof.\nB.2. Supporting lemmas for Theorem 3.1\n(n)\nLemma B.1. Using the notation of Theorem 3.1, under assumption A1 the process \u0168\u03b1 (\u03b20 )\n(n)\nfrom (13) is a square-integrable martingale adapted to F\u0303\u03b1 = Ftb\u03b1nc .\nProof. The conditional expectation property holds provided E[Utn (\u03b20 ) | Ftn\u22121 ] = Utn\u22121 (\u03b20 ).\nDefine K = supt,i,j kxt (i, j)k. Note that kHt (i, j)k \u2264 2K. Thus,\n\u0001\nkUt\u2227tn (\u03b20 )k \u2264 2K Nt\u2227tn + \u039bt\u2227tn ,\n\u0014\n\u0015\n\u00011/2\n\u00011/2\n2\nE sup kUt\u2227tn (\u03b20 )k \u2264 8 * EK 2\n* ENt2n + E\u039b2tn\n.\nt\n\nBy assumption A1, EK is finite, and by construction, Ntn is bounded. Since Nt\u2227tn is a counting\nprocess, E\u039b2tn is finite, too (this follows from results in Section 2.3 of Fleming and Harrington\n(1991)). Thus, Ut\u2227tn (\u03b20 ) is uniformly integrable. The Optional Sampling Theorem now applies to give the conditional\nexpectation property\nof \u0168 (n) (\u03b20 ). For square integrability, note\n\u0002\n\u0003\n2\n2\nsup1\u2264m\u2264n EkUtm k \u2264 E supt kUt\u2227tn (\u03b20 )k .\n2\n\nLemma B.2. Using the notation of Theorem 3.1, under assumption A1, the Lindeberg condition for Rebolledo's (1980) Central Limit Theorem is satisfied: for any positive \u03b5,\nZ\n\u221a\n1 X tn\nP\nkHs (i, j)k2 1{kHs (i, j)k > n\u03b5} d\u039bs (i, j) \u2192 0.\nn i,j 0\n\nProof. With K = supt,i,j kxt (i, j)k as above, the integral is bounded by 4 K 2 1{n\u22121/2 K >\n\u039b\n\u03b5/2} * ntn . Since EK 2 < \u221e by assumption A1, the first term converges to zero in probability.\nSince E\u039btn = ENtn = n, the product of the two also converges to zero in probability. Thus, the\nLindeberg condition is satisfied.\n1\nn\n\nLemma B.3. Using the notation of Theorem 3.1, under assumptions A1 and A3 we have that\nP R tb\u03b1nc\nP\nVs (\u03b20 , i) dMs (i) \u2192 0 uniformly in \u03b1.\ni 0\n\n\f26\n\nP. O. Perry and P. J. Wolfe\n\nProof. Lenglart's (1977) Inequality and assumption A3 imply that for any positive \u03c1 and \u03b4,\nZ\nn 1 X Z tn\no\nn\no\n\u03b4\n1X t\nVs (\u03b20 , i) dMs (i) \u2265 \u03c1 \u2264 2 + P 2\nkVs (\u03b20 , i)k2 d\u039bs (i) \u2265 \u03b4 .\nP sup\n\u03c1\nn i 0\nt\u2208[0,tn ] n i\n0\n\n(see Fleming and Harrington (1991, Cor. 3.4.1) for a related proof). As in the proof of Lemma B.1,\n4\n\u039btn\n\u22121/2 2 P\nset K = supt,i,j kxt (i, j)k. The sum is bounded by 16K\nK \u2192 0 by assumption\nn * n . Since n\nA1 and E\u039btn = n, the right-hand side of the inequality converges to \u03c1\u03b42 . Since \u03b4 is arbitrary, the\nright-hand side must converge to zero.\nB.3. Proof of Theorem 3.2\nWe follow Haberman's (1977) approach to proving consistency, which relies on Kantorovich's\n(1948) analysis of Newton's method. Tapia (1971) gives an elementary proof of the Kantorovich\nTheorem. We state a weak form of the result as a lemma.\nLemma B.4 (Kantorovich Theorem). Let P (x) = 0 be a general system of nonlinear\nequations, where P is a map between two Banach spaces. Let P 0 (x) denote the Jacobian (Fr\u00e9chet\ndifferential) of P at x, assumed to exist in D0 , a convex open neighborhood of x0 . Assume that\n(a) k[P 0 (x0 )]\u22121 k \u2264 B,\n\n(b) k[P 0 (x0 )]\u22121 P (x0 )k \u2264 \u03b7,\n\n(c) kP 0 (x) \u2212 P 0 (y)k \u2264 Kkx \u2212 yk,\n\nfor all x and y in D0 ,\n\n1\n2.\n\nwith h = BK\u03b7 \u2264\nLet \u03a9\u2217 = {x : kx \u2212 x0 k \u2264 2\u03b7}. If \u03a9\u2217 \u2282 D0 , then the Newton iterates, xk+1 = xk \u2212\n[P 0 (xk )]\u22121 P (xk ), are well defined, remain in \u03a9\u2217 , and converge to x\u2217 in \u03a9\u2217 such that P (x\u2217 ) = 0.\nIn addition,\nk\n\u03b7 (2h)2\nkx\u2217 \u2212 xk k \u2264\n,\nk = 0, 1, 2, . . . .\nh 2k\nProof (Theorem 3.2). Set Ut (*) and It (*) to be the gradient and negative Hessian of the log\npartial likelihood, as defined in (5a\u20135b). Since It (\u03b2) is a sum of rank-one matrices with positive\nweights, it is positive semi-definite, and log PLt (*) is a concave function. By the assumption\nthat the smallest eigenvalue of \u03a31 (*) is bounded away from zero in a neighborhood of \u03b20 , for n\nsufficiently large, if log PLt (*) has a local maximum in that neighborhood then it must be the\nunique global maximum.\nWe find the local maximum by applying Newton's method to the gradient of n1 log PLtn (*),\ntaking \u03b20 as the initial iterate. Define Zn = \u2212[ n1 Itn (\u03b20 )]\u22121 [ n1 Utn (\u03b20 )]. The first Newton iterate, \u03b2n,1 , is equal to \u03b20 \u2212 Zn . Part (b) of Theorem 3.1 and the assumptions of the theorem\nimply [ n1 Itn (\u03b20 )]\u22121 exists for n large enough, so that Zn is well-defined. Moreover, Part (a) of\n\u221a\nP\nd\nTheorem 3.1 and Slutsky's Theorem imply Zn \u2192 0 and n Zn \u2192 N (0, [\u03a31 (\u03b20 )]\u22121 ).\nNow we may apply Kantorovich's Theorem to bound k\u03b2\u0302n \u2212 \u03b20 k and k\u03b2\u0302n \u2212 \u03b2n,1 k as follows.\nBy assumption, there exists a neighborhood of \u03b20 , say D0 , and finite K and B, such that\nk n1 Itn (\u03b2) \u2212 n1 Itn (\u03b2 0 )k \u2264 Kk\u03b2 \u2212 \u03b2 0 k and k n1 [Itn (\u03b20 )]\u22121 k \u2264 B for \u03b2, \u03b2 0 \u2208 D0 . Define \u03b7n = kZn k\nand hn = BK\u03b7n , noting that hn and \u03b7n are size OP (n\u22121/2 ). Thus, for n large enough,\nP\n\n(a) k\u03b2\u0302n \u2212 \u03b20 k \u2264 2 \u03b7n \u2192 0,\n\u221a\n\u221a\nP\n(b) n k\u03b2\u0302n \u2212 (\u03b20 \u2212 Zn )k \u2264 2 n \u03b7n hn \u2192 0.\n\u221a\n\u221a\nP\nThus, \u03b2\u0302n \u2192 \u03b20 , and n(\u03b2\u0302n \u2212 \u03b20 ) and n Zn converge weakly to the same limit.\n\n\fPoint Process Modeling for Directed Interaction Networks\n\nC.\n\n27\n\nResults from Section 4\n\nC.1. Proof of Theorem 4.1\nP\nProof (Theorem 4.1). When J \u2286 Jt (i), set Xt (i, J) =\nj\u2208J xt (i, j) and wt (\u03b2, i, J) =\nT\nexp{\u03b2 Xt (i, J)}. As a slight abuse of notation, when j is an element of Jt (i), take \"wt (\u03b2, i, j)\"\nto mean wt (\u03b2, i, {j}). Define weights\nX\n\nWt (\u03b2, i; L) =\n\nft (\u03b2, i; L) =\nW\n\nwt (\u03b2, i, J),\n\nJ\u2286Jt (i),\n|J|=L\n\nh X\n\nwt (\u03b2, i, j)\n\nj\u2208Jt (i)\n\niL\n\n,\n\nf t (\u03b2) comes from replacing W with W\nf.\nand note that the approximation error in log PL\nThe gradients of the weights are\n\u0002\n\u0003\nEt (\u03b2, i; L) = \u2207 log Wt (\u03b2, i; L) =\n\n1\nWt (\u03b2, i; L)\n\n\u0002\n\u0003\net (\u03b2, i; L) = \u2207 log W\nft (\u03b2, i; L) = L *\nE\n\nP\n\nX\n\nwt (i, J) Xt (i, J),\n\nJ\u2286Jt (i),\n|J|=L\n\nj\u2208Jt (i)\n\nP\n\nwt (\u03b2, i, j) xt (i, j)\n\nj\u2208Jt (i)\n\nwt (\u03b2, i, j)\n\n.\n\nPL\nThe second is the expectation of\nl=1 xt (i, jl ) when j1 , . . . , jL are drawn independently and\nidentically from Jt (i) with weights wt (\u03b2, i, *); the first is the same expectation, conditional on\nthe event that j1 , . . . , jL are all unique. Let P\u0303t,\u03b2,i;L and Pt,\u03b2,i;L denote the two probability laws\nfor j1 , . . . , jL , and let \u1ebct,\u03b2,i;L and Et,\u03b2,i;L denote expectations with respect to them, so that\n\u0002 PL\n\u0003\n\u0002 PL\n\u0003\ne\nEt (\u03b2, i; L) = Et,\u03b2,i;L\nl=1 xt (i, jl ) and Et (\u03b2, i; L) = \u1ebct,\u03b2,i;L\nl=1 xt (i, jl ) .\nf t (\u03b2)] derives from a bound on Et (\u03b2, i; L)\u2212E\net (\u03b2, i; L).\nThe bound on \u2207[log PLtn (\u03b2)]\u2212\u2207[log PL\nn\nWrite\nL\nL\nhX\ni\nhX\ni\ne t,\u03b2,i;L\net (\u03b2, i; L) = Et,\u03b2,i;L\nEt (\u03b2, i; L) \u2212 E\nxt (i, jl ) \u2212 E\nxt (i, jl ) .\nl=1\n\nl=1\n\nP\u2217t,\u03b2,i;L\n\nWe define probability law\nand associated random variables j1 , . . . , jL and \uf6be\u03031 , . . . , \uf6be\u0303L , such\nthat marginally j1 , . . . , jL are distributed according to Pt,\u03b2,i;L and \uf6be\u03031 , . . . , \uf6be\u0303L are distributed\naccording to P\u0303t,\u03b2,i;L , but the variables are coupled to have nontrivial chance of agreeing. Then,\net (\u03b2, i; L) = E\u2217\nEt (\u03b2, i; L) \u2212 E\nt,\u03b2,i;L\n\u2264 2L *\n\nh\n\nL\nhX\nl=1\n\nxt (i, jl ) \u2212\n\nL\nX\nl=1\n\nxt (i, \uf6be\u0303l )\n\ni\n\ni\nn\no\nsup kxt (i, j)k * P\u2217t,\u03b2,i;L (j1 , . . . , jL ) 6= (\uf6be\u03031 , . . . , \uf6be\u0303L )\n\nj\u2208Jt (i)\n\nThe coupling is as follows:\n(a) Draw (\uf6be\u03031 , . . . , \uf6be\u0303L ) according to P\u0303t,\u03b2,i;L .\n(b) If (\uf6be\u03031 , . . . , \uf6be\u0303L ) are all unique, set (j1 , . . . , jL ) = (\uf6be\u03031 , . . . , \uf6be\u0303L ), otherwise draw (j1 , . . . , jL )\nindependently according to Pt,\u03b2,i;L .\nWith K = supj\u2208Jt (i) kxt (i, j)k, Lemma C.1 shows\nP\u2217t,\u03b2,i;L\n\nn\no \u0012L\u0013 exp{4K k\u03b2k}\n(j1 , . . . , jL ) 6= (\uf6be\u03031 , . . . , \uf6be\u0303L ) \u2264\n*\n.\n|Jt (i)|\n2\n\n\f28\n\nP. O. Perry and P. J. Wolfe\n\nf t (\u03b2)]k now follows by expressing\nThe resulting bound on k\u2207[log PLt (\u03b2)] \u2212 \u2207[log PL\nX\n\u0002\n\u0003\n\u0002\n\u0003\nf t (\u03b2) \u2212 \u2207 log PLt (\u03b2) =\net (\u03b2, im ; |Jm |).\n\u2207 log PL\nEt (\u03b2, im ; |Jm |) \u2212 E\nm\n\nm\n\ntm \u2264t\n\net (\u03b2, i; L) \u2264 K L2 (L \u2212 1) exp{4K k\u03b2k} , we get\nUsing Et (\u03b2, i; L) \u2212 E\n|Jt (i)|\n\nX |Jm |2 (|Jm | \u2212 1)\n\u0002\n\u0003\n\u0002\n\u0003\nf t (\u03b2) \u2212 \u2207 log PLt (\u03b2) \u2264 K exp{4Kk\u03b2k} *\n\u2207 log PL\n.\n|Jtm (im )|\ntm \u2264t\n\nWe get the final bound for the gradients by replacing the numerators of the summands with\nsupm |Jm |.\nUsing the same methods, Lemma C.2 derives the bound on the difference in Hessians.\nC.2. Supporting lemmas for Theorem 4.1\nLemma C.1. Using the notation and assumptions of Theorem 4.1,\nn\no \u0012L\u0013 exp{4K k\u03b2k}\n\u2217\n,\nPt,\u03b2,i;L (j1 , . . . , jL ) 6= (\uf6be\u03031 , . . . , \uf6be\u0303L ) \u2264\n*\n|Jt (i)|\n2\n\nwhere K = supt kxt (i, j)k.\n\nProof. The left hand side is bounded by the probability that the samples \uf6be\u03031 , . . . , \uf6be\u0303L are all\nunique, which can be bounded by\n\u0012 \u0013 X h\ni2\nX\nL\nwt (\u03b2, i, j)\nP\nP\u2217t,\u03b2,i;L {\uf6be\u0303k = \uf6be\u0303l } =\n.\n0\n2\nj 0 \u2208Jt (i) wt (\u03b2, i, j )\nk<l\n\nj\u2208Jt (i)\n\nNote exp{\u2212K k\u03b2k} \u2264 wt (\u03b2, i, j) \u2264 exp{Kk \u03b2k}, so that\ni2\nX h\nexp{4K k\u03b2k}\nwt (\u03b2, i, j)\nP\n.\n\u2264\n0\n|Jt (i)|\nw\n(\u03b2,\ni,\nj\n)\n0\nj \u2208Jt (i) t\nj\u2208Jt (i)\n\nLemma C.2. Using the notation and assumptions of Theorem 4.1,\nX |Jm |3 (|Jm | \u2212 1)\n\u0002\n\u0003\n\u0002\n\u0003\nf t (\u03b2) \u2212 \u22072 log PLt (\u03b2) \u2264 2K 2 exp{4Kk\u03b2k} *\n.\n\u22072 log PL\n|Jtm (im )|\ntm \u2264t\n\nProof. The argument is similar to the bound on the difference in gradients in the proof of\nTheorem 4.1. The Hessians of the weights are\nh\ni\u22972\nX\n\u0002\n\u0003\n1\nVt (\u03b2, i; L) = \u22072 log Wt (\u03b2, i; L) =\nwt (\u03b2, i, J) Xt (i, J) \u2212 Et (\u03b2, i; L)\n,\nWt (\u03b2, i; L)\nVet (\u03b2, i; L) = \u2207\n\n\u0002\n2\n\n\u0003\nft (\u03b2, i; L) = L *\nlog W\n\nP\n\nJ\u2286Jt (i),\n|J|=L\n\nj\u2208Jt (i)\n\ni\u22972\nh\net (\u03b2, i; L)\nwt (\u03b2, i, j) xt (i, j) \u2212 L1 E\nP\n.\nj\u2208Jt (i) wt (\u03b2, i, j)\n\nPL\nThe first is the covariance matrix of l=1 xt (i, jl ) under Pt,\u03b2,i;L ; the second is the covariance\nmatrix of the same quantity under P\u0303t,\u03b2,i;L . The result follows in the same manner as in the proof\nof Theorem 4.1. The relevant intermediate bound is\nexp{4K k\u03b2k}\nVt (\u03b2, i; L) \u2212 Vet (\u03b2, i; L) \u2264 2 K 2 L3 (L \u2212 1)\n.\n|Jt (i)|\n\n\fPoint Process Modeling for Directed Interaction Networks\n\n29\n\nC.3. Proof of Theorem 4.2\nf t (*) converges\nProof (Theorem 4.2). We know that Newton's method applied to n1 log PL\nn\nto \u03b2\u0303n after sufficiently many iterations. We employ \u03b2\u0302n as the initial iterate and use the Kantorovich Theorem (Lemma B.4) to bound k\u03b2\u0303n \u2212 \u03b2\u0302n k.\nf t (*) and P 0 (*) is its Hessian.\nIn the notation of the lemma, P (*) is the gradient of n1 log PL\nn\nThe conditions of Theorem 4.2 imply assumptions (a) and (c) hold uniformly in n for some finite\nB and K. Set\nh \u0002\n\u0003i\u22121 h \u0002 1\n\u0003i\nf t (\u03b2\u0302n )\nf t (\u03b2\u0302n )\n\u2207 n log PL\n\u03b7n = \u22072 n1 log PL\nn\nn\n\u0002\n\u0003\nand set hn = BK\u03b7n . Since \u2207 log PLtn (\u03b2\u0302n ) = 0, Theorem 4.1 and the boundedness of the\ninverse Hessian imply \u03b7n = OP (Gn /n). Therefore, for n large enough,\n0\n\n\u03b7n (2h)2\nk\u03b2\u0303n \u2212 \u03b2\u0302n k \u2264\n= 2\u03b7n = OP (Gn /n).\nh 20\nReferences\nAndersen, P. K., O. Borgan, R. D. Gill, and N. Keiding (1993). Statistical Models Based on\nCounting Processes. New York: Springer-Verlag.\nAndersen, P. K. and R. D. Gill (1982). Cox's regression model for counting processes: A large\nsample study. Ann. Statist. 10, 1100\u20131120.\nAnderson, C. J., W. S., and B. Crouch (1999). A p\u2217 primer: Logit models for social networks.\nSoc. Networks 21, 37\u201366.\nAral, S., L. Muchnik, and A. Sundararajan (2009). Distinguishing influence-based contagion from\nhomophily-driven diffusion in dynamic networks. P. Nat. Acad. Sci. USA 106, 21544\u201321549.\nBoyd, S. and L. Vandenberghe (2004). Convex Optimization. Cambridge University Press.\nBreslow, N. E. (1974). Covariance analysis of censored survival data. Biometrics 30, 89\u201399.\nBrostr\u00f6m, G. (2002). Cox regression; ties without tears. Commun. Stat. Theory Meth. 31,\n285\u2013297.\nButts, C. T. (2008). A relational event framework for social action. Sociol. Methodol. 38, 155\u2013200.\nCohen, W. W. (2009). Enron email dataset. http://www.cs.cmu.edu/ \u0303enron/. Version of 21\nAugust 2009.\nCook, R. J. and J. F. Lawless (2007). The Statistical Analysis of Recurrent Events. Berlin:\nSpringer.\nCox, D. R. (1972). Regression models and life-tables (with discussion). J. R. Statist. Soc. B 34,\n187\u2013220.\nCox, D. R. (1975). Partial likelihood. Biometrika 62, 269\u2013276.\nEagle, N. and A. S. Pentland (2006). Reality mining: Sensing complex social systems. Pers.\nUbiquit. Comput. 10, 255\u2013268.\nEfron, B. (1977). The efficiency of Cox's likelihood function for censored data. J. Am. Statist.\nAss. 72, 557\u2013565.\nFleming, T. R. and D. P. Harrington (1991). Counting Processes and Survival Analysis. New\nYork: Wiley.\nFowler, J. H. (2006). Connecting the Congress: A study of cosponsorship networks. Polit.\nAnal. 14, 456\u2013487.\nGoldenberg, A., A. X. Zheng, S. E. Fienberg, and E. M. Airoldi (2009). A survey of statistical\nnetwork models. Found. Trends Mach. Learn. 2, 129\u2013233.\nHaberman, S. J. (1977). Maximum likelihood estimates in exponential response models. Ann.\nStatist. 5, 815\u2013841.\n\n\f30\n\nP. O. Perry and P. J. Wolfe\n\nJackson, M. O. (2008). Social and Economic Networks. Princeton, NJ: Princeton University\nPress.\nKantorovich, L. V. (1948). Functional analysis and applied mathematics. Uspekhi Matematicheskikh Nauk 3, 89\u2013185. Translated by C. D. Benster, National Bureau of Standards Report\nNo. 1509, 1952.\nKolaczyk, E. D. (2009). Statistical Analysis of Network Data: Methods and Models. New York:\nSpringer.\nLenglart, E. (1977). Relation de domination entre deux processus. Ann. Inst. Henri Poincar\u00e9 13,\n171\u2013179.\nLunag\u00f3mez, S., S. Mukherjee, and R. L. Wolpert (2009). Geometric representations of hypergraphs for prior specification and posterior sampling. Technical Report 2009-01, Duke\nUniversity, Durham, NC. arXiv:0912.3648v1 [math.ST].\nMartinussen, T. and T. H. Scheike (2006). Dynamic Regression Models for Survival Data. New\nYork: Springer.\nMcCullagh, P. and J. A. Nelder (1989). Generalized Linear Models. Chapman & Hall.\nMckenzie, D. and H. Rapoport (2007). Network effects and the dynamics of migration and\ninequality: Theory and evidence from Mexico. J. Dev. Econ. 84, 1\u201324.\nMcPherson, M., L. Smith-Lovin, and J. M. Cook (2001). Birds of a feather: Homophily in social\nnetworks. Annu. Rev. Sociol. 27, 415\u2013444.\nNocedal, J. and S. J. Wright (2006). Numerical Optimization (Second ed.). New York: Springer.\nPapachristos, A. V. (2009). Murder by structure: Dominance relations and the social structure\nof gang homicide. Am. J. Sociol. 115, 74\u2013128.\nRebolledo, R. (1980). Central limit theorems for local martingales. Probab. Theory Rel. Fields 51,\n269\u2013286.\nShafiei, M. and H. Chipman (2010). Mixed-membership stochastic block-models for transactional\nnetworks. arXiv:1010.1437v1 [stat.ML].\nSnijders, T. A. B., G. V. Van de Bunt, and C. E. G. Steglich (2010). Introduction to stochastic\nactor-based models for network dynamics. Soc. Netw. 32, 44\u201360.\nSundaresan, S. R., I. R. Fischoff, J. Dushoff, and D. I. Rubenstein (2007). Network metrics\nreveal differences in social organization between two fission-fusion species, Grevy's zebra and\nonager. Oecologia 151, 140\u2013149.\nTapia, R. A. (1971). The Kantorovich theorem for Newton's method. Am. Math. Mon. 78,\n389\u2013392.\nTherneau, T. and T. Lumley (2009). survival: Survival analysis, including penalised likelihood.\nR package version 2.35-8, http://CRAN.R-project.org/package=survival.\nTherneau, T. M., P. M. Grambsch, and T. R. Fleming (1990). Martingale-based residuals for\nsurvival models. Biometrika 77, 147\u2013160.\nTyler, J. R., D. M. Wilkinson, and B. A. Huberman (2005). E-mail as spectroscopy: Automated\ndiscovery of community structure within organizations. Inform. Soc. 21, 143\u2013153.\nVu, D. Q., A. Asuncion, D. Hunter, and P. Smyth (2011a). Continuous-time regression models for\nlongitudinal networks. In J. Shawe-Taylor, R. Zemel, P. Bartlett, F. Pereira, and K. Weinberger\n(Eds.), Advances in Neural Information Processing Systems 24, pp. 2492\u20132500.\nVu, D. Q., A. U. Asuncion, D. R. Hunter, and P. Smyth (2011b). Dynamic egocentric models\nfor citation networks. In Proc. 28th Intl. Conf. Machine Learning, pp. 857\u2013864.\nWong, W. H. (1986). Theory of partial likelihood. Ann. Statist. 14, 88\u2013123.\nZhou, Y., M. Goldberg, M. Magdon-Ismail, and W. A. Wallace (2007). Strategies for cleaning\norganizational emails with an application to Enron email dataset. In 5th Annu. Conf. North\nAm. Ass. Computat. Social Organizat. Sci. Pittsburgh, PA: North American Association for\nComputational Social and Organizational Science.\n\n\fPoint process modeling for directed interaction networks:\nSupplementary material\nPatrick O. Perry\nStern School of Business, New York University, USA\n\nPatrick J. Wolfe\nDepartment of Statistical Science, University College London, UK\n[Received November 2010. Revised November 2012]\n\n1. A comparative analysis based on contingency tables\nWere we interested only in homophily, we might be tempted to forgo the proportional intensity\nmodel of (1) from the main text, and instead perform a contingency table analysis. However,\nas we now describe, such an analysis leads to very different conclusions about the predictive\nstrength of homophily in our data.\nFor example, suppose that we are interested in testing for seniority-based homophily. Ignoring\nnetwork effects and other dependency, we might model P{i \u2192 j | i}, the probability of employee\nj being the recipient of a message given that employee i is the sender, by way of a multinomial\nlogit model:\nP{i \u2192 j | i} \u221d exp{\u03b2J J(j) + \u03b2JJ J(i)J(j)}.\nIn this setting, Junior-Junior homophily would manifest in a positive value of \u03b2J + \u03b2JJ and\nSenior-Senior homophily would manifest in a negative value of \u03b2J .\nSince there are nJ = 82 Junior executives and nS = 74 Senior executives, and since the\nsender and receiver of a message are distinct, we have that\nP{i \u2192 j | i, J(i) = 1} =\nP{i \u2192 j | i, J(i) = 0}, =\n\ne(\u03b2J +\u03b2JJ )J(j)\n(nJ \u2212 1)e\u03b2J +\u03b2JJ + nS\nnJ\n\ne\u03b2J J(j)\n.\n+ (nS \u2212 1)\n\ne\u03b2J\n\nIn turn, we compute the corresponding maximum likelihood coefficient estimates using the entries\nof a 2 \u00d7 2 table that counts the number of messages exchanged between each group:\nReceiver\nSender\n\nJunior\n\nSenior\n\nJunior\nSenior\n\n7972\n3977\n\n5833\n14479\n\nThe resultant estimates are \u03b2\u0302J = \u22121.4 and \u03b2\u0302JJ = 1.6, with (Wald) standard errors of about 0.02\nfor each. Indeed, these are exactly the estimated coefficients we would obtain if we were to use\nAddress for correspondence: Patrick O. Perry, Information, Operations, and Management Sciences\nDepartment, Stern School of Business, New York University, 44 West 4th St, New York, NY 10012, USA\nE-mail: pperry@stern.nyu.edu\n\n\f2\n\nP. O. Perry and P. J. Wolfe\n\nReceiver\nSender\n1\nL\nT\nJ\nF\n\nL\n\nT\n\nJ\n\nF\n\n-1.48\n\n-1.74\n\n-1.83\n\n-0.25\n\n(0.04)\n\n(0.03)\n\n(0.03)\n\n(0.03)\n\n3.70\n\n0.48\n\n0.23\n\n-0.22\n\n(0.04)\n\n(0.05)\n\n(0.03)\n\n(0.03)\n\n1.06\n\n1.92\n\n1.11\n\n-0.21\n\n(0.06)\n\n(0.04)\n\n(0.04)\n\n(0.04)\n\n-0.12\n\n1.36\n\n1.70\n\n0.25\n\n(0.04)\n\n(0.04)\n\n(0.03)\n\n(0.03)\n\n0.87\n\n-0.58\n\n0.07\n\n0.83\n\n(0.04)\n\n(0.04)\n\n(0.03)\n\n(0.03)\n\nFig. 1. Estimated coefficients and standard errors for the contingency table-based analysis of Section 1;\ndark coefficients are significant (via Wald test) at level 10\u22123 .\n\nthe proportional intensity model \u03bbt (i, j) = \u03bb\u0304t (i) exp{\u03b2J J(j) + \u03b2JJ J(i)J(j)}, a result that holds\nmore generally for non-time-varying covariates.\nOne problem with this analysis is that we have marginalized over the other covariates (Gender\nand Department), potentially introducing a Simpson's paradox. This issue is easily rectified,\nhowever, by introducing covariates for senders and receivers; Fig. 1 above shows the resulting\ncoefficient estimates.\nThe far more important problem is that this analysis implicitly assumes each message to\nbe independent and identically distributed, conditional on the sender of the message. This\nassumption is blatantly false: common sense tells us that if Junior A sends a message to Junior\nB, then the next time B sends a message, B is more likely to choose A as a recipient. Any\nhomophily effect present in these interaction data is thus likely to be exaggerated by reciprocation\nand other network effects. Indeed, comparing the contingency table-based estimates in Fig. 1\nabove with the estimates from the proportional intensity model with network effects in Fig. 7\nfrom the main text, we can see that the coefficient estimates are much higher when we don't\nadjust for network effects. Thus even in cases where network effects themselves are not the\nobject of primary interest, it is important to account for them when making inferences about\nthe predictive strength of other covariates.\n2.\n\nComparative analyses using actor-oriented and exponential random graph models\n\nA number of dynamic network models exist in the literature, including Hanneke, Fu, and\nXing's (2010) exponential random graph model with time-varying coefficients, and Kolar, Song,\nAhmed, and Xing's (2010) time-varying stochastic block model. Alternative approaches explicitly based on point processes, but excluding network effects and other covariate information,\ninclude that of Malmgren et al. (2009), who model activity at the level of the individual using\na hidden Markov model, and of Heard et al. (2010), who work at the level of the dyad, assuming a piecewise-constant interaction rate. The closest match to our approach is given by the\nactor-oriented model of Snijders (2001, 2005), which we now detail in Section 2.1 below. Then,\nin Section 2.2, we provide a comparison to a static network analysis based on an exponential\nrandom graph model.\n\n\fPoint Process Modeling for Directed Interaction Networks: Supplementary Material\n\n3\n\n2.1. Actor-oriented model analysis\nThe actor-oriented model is designed for a sequence of snapshots G1 , G2 , . . . , of network activity,\nwhere each Gt is an I \u00d7 J binary matrix representing pairwise connectivity between actors at\ntime t. The model is best suited for ties that persist in time, not instantaneous events; it treats\nthe sequence of networks as a first-order Markov chain, with the distribution of Gt determined by\nGt\u22121 . Actors are assumed to change their ties between times t \u2212 1 and t to maximize a stochastic\nutility function that depends on characteristics of the overall network. Essentially, given that\nthe network is in state G, and that actor i is allowed to make a change, he will change his link\nto actor j according to\np(j|i, G) \u221d exp\n\nS\nnX\ns=1\n\n0\n\nS\no\n\u0001 X\n\u03b2s Ts G(i ; j) +\n\u03b2s0 Ts0 (G \\ {i \u2192 j}) ,\ns=1\n\nwhere Ts and Ts0 are network statistics; \u03b2s and \u03b2s0 are unknown coefficients; G(i ; j) denotes the\nnetwork obtained either by adding link i \u2192 j if it is absent or removing link i \u2192 j if it is present;\nG \\ {i \u2192 j} denotes the network obtained by removing i \u2192 j if it is present. Additionally, the\nrate at which actor i changes ties between observation times t \u2212 1 and t is given by \u03bb(i), specified\nvia another parametric model. (See Snijders et al. (2010) for a more thorough introduction.)\nThe change probability function p(j|i, G) plays a similar role to the multiplier exp{xt (i, j)T \u03b2}\nin the proportional intensity model from the main text, and the change rate function \u03bb(i) plays\na similar role to the baseline intensity \u03bb\u0304t (i).\nFor purposes of comparison, we specified a change probability model p(j|i, G) with network\nstatistics analogous to those used in Section 5.2 from the main text, and then we estimated\ncoefficient sets \u03b2 and \u03b2 0 analogous to the coefficients in the proportional intensity model. We\nused the RSiena package (Ripley and Snijders, 2011) to specify and fit the actor-oriented model\nafter binning the Enron e-mail interaction data at regular intervals to obtain network snapshots\nG1 , G2 , and G3 . Here, Gt (i, j) = 1 if message i \u2192 j was observed in period t, and Gt (i, j) = 0\notherwise; periods 1\u20133 correspond to consecutive four-month periods in the year 2001. The\nsubset we looked at contains 60% of the messages in the Enron corpus. We chose this particular\nsubset and temporal resolution partially for computational reasons, but also to make the network\nchange statistics (Jaccard coefficients) within the range recommended by RSiena (near 0.3).\nApproximately 2 hours' time was required to fit the model.\nWe included the following terms, chosen to mimic the covariates detailed in Section 5.2 from\nthe main text:\n(a) Outdegree/density (out). This statistic counts the number of outgoing ties; it is analogous\nto our \u03bb\u0304t (i), except that the rate is the same for each sender.\n(b) Group-level edge effects (traits). One covariate is included for each identifiable first-order\ninteraction of the form X(i)Y (j), where i is the sender and j is the receiver; the covariate\ncounts the number of edges i \u2192 j with X(i)Y (j) = 1. These effects correspond to the\ngroup-level effects in our model.\n(c) Outdegree/density endowment (outendow). This statistic counts the number of deleted\noutgoing ties; it corresponds to the negative of the send term in our model.\n(d) Reciprocity (recip). This statistic counts the number of reciprocal ties; i.e., edge sets of\nthe form {i \u2192 j, j \u2192 i}. It corresponds to the receive term in our model.\n(e) 3-cycles (3cycle). This statistic counts the number of cyclic triples; i.e., edge sets of the\nform {h \u2192 i, i \u2192 j, j \u2192 h}. It corresponds to the 2-receive term in our model.\n\n\f4\n\nP. O. Perry and P. J. Wolfe\n\nReceiver\nSender\n1\nL\nT\nJ\nF\n\nL\n\nT\n\nJ\n\nF\n\n-0.65\n\n-0.10\n\n0.13\n\n0.21\n\n(0.12)\n\n(0.07)\n\n(0.07)\n\n(0.09)\n\n-0.16\n\n0.62\n\n-0.28\n\n-0.11\n\n(0.13)\n\n(0.10)\n\n(0.09)\n\n(0.11)\n\n0.46\n\n0.45\n\n-0.15\n\n-0.46\n\n(0.16)\n\n(0.06)\n\n(0.07)\n\n(0.10)\n\n0.00\n\n0.15\n\n0.10\n\n-0.21\n\n(0.11)\n\n(0.06)\n\n(0.06)\n\n(0.09)\n\n0.19\n\n0.33\n\n0.08\n\n0.13\n\n(0.12)\n\n(0.06)\n\n(0.07)\n\n(0.08)\n\n(a) Trait effects (traits)\n\nVariate\nCoefficient\n(SE)\n\nout\n\noutendow\n\nrecip\n\n3cycle\n\n-1.94\n(0.02)\n\nttriple\n\n-0.94\n\n2.02\n\n-0.26\n\n0.30\n\n(0.01)\n\n(0.06)\n\n(0.03)\n\n(0.01)\n\n(b) Network effects\nFig. 2. Estimated effects for the actor-oriented model of Section 2.1\n\n(f) Transitive triplets (ttriple). This statistic counts the number of transitive triples; i.e.,\nedge sets of the form {h \u2192 i, i \u2192 h, h \u2192 j}. It corresponds to the 2-send, sibling, and\ncosibling terms in our model.\nNote that after binning the interaction counts to form network snapshots as required by the\nactor-oriented model, it is impossible to separate the 2-send, sibling, and cosibling effects.\nFurther, the first-order Markov nature of the model restricts our ability to quantify the time\ndecay of the dynamic network effects.\nFigure 2 above shows the fitted coefficients for the actor-oriented model. We can see that\nthe estimated network effects agree qualitatively with those in Fig. 8 from the main text, as\noutdegree/density endowment has a negative coefficient while reciprocity and transitive triplets\nhave positive coefficients. Further, the dyadic coefficients are larger than the triadic coefficients.\nA discrepancy between the two models is that 2-receive had a negligible effect in the proportional\nintensity model, while its analogue (3cycle) had a small negative effect in the actor-oriented\nmodel. One possible explanation for this discrepancy is that treating all ties as binary forces a\nnegative bias in otherwise-unimportant network effects. With the limitation that ties are binary,\nwhen actor i tries to maximize his stochastic utility, he is forbidden from reinforcing an existing\ni \u2192 j link; he is more likely to link to an actor j 0 for which link i \u2192 j 0 is absent. To counteract\nthis tendency, the coefficient of 3cycle is forced to be negative.\n2.2. Exponential random graph model analysis\nAs a final comparison, we fit an exponential random graph model to our data. This class of\nmodels-one of the more popular for estimating the importance of network effects-specifies a\nprobability distribution for a single directed graph represented by a binary matrix G. It supposes\n\n\fPoint Process Modeling for Directed Interaction Networks: Supplementary Material\n\n5\n\nPS\nthat P{G = g} \u221d exp{ s=1 Ts (g)}, where Ts (g) is a network statistic, for example the number\nof transitive triples in the graph. (See Anderson et al. (1999) for a detailed survey.)\nTo apply this form of model, we employed a reduction of our data to obtain a single directed\ngraph G as follows. Based on an \"elbow\" in the empirical cumulative distribution function of\nmessage counts N\u221e (i, j) in our data, we chose a threshold of 10 sent messages and defined G by\nG(i, j) = 1{N\u221e (i, j) \u2265 10}.\nNext, as in our comparison to the actor-oriented model, we chose terms in the model to mimic\nthe covariates from Section 5.2 of the main text. We used the ergm software package to fit the\nmodel (Handcock et al., 2011), based on a Markov chain Monte Carlo sample size of 105 following\na burn-in period of 106 iterates. The covariates were as follows:\n(a) Sender effects (sender). One covariate is included for each sender, measuring the outdegree\nof the sender. The corresponding coefficient plays the role of \u03bb\u0304t (i) in our model.\n(b) Group-level edge effects (edgecov). One covariate is included for each identifiable firstorder interaction of the form X(i)Y (j), where i is the sender and j is the receiver; the\ncovariate counts the number of edges i \u2192 j with X(i)Y (j) = 1. These effects correspond\nto the group-level effects in our model. We attempted to include second-order interactions\nas well, but were unable (for computational reasons) to fit the model with these terms.\n(c) Mutuality (mutual). This statistic counts the number of mutual ties; i.e., edge sets of the\nform {i \u2192 j, j \u2192 i}, and corresponds to the receive term in our model.\n(d) Cyclic triples (ctriple). This statistic counts the number of cyclic triples; i.e., edge sets\nof the form {h \u2192 i, i \u2192 j, j \u2192 h}, and corresponds to the 2-receive term in our model.\n(e) Transitive triples (ttriple). This statistic counts the number of transitive triples; i.e.,\nedge sets of the form {h \u2192 i, i \u2192 j, h \u2192 j}. It corresponds to the 2-send, sibling, and\ncosibling terms in our model.\nNote that reducing the interaction data to a single directed graph has important modeling\nconsequences. As with the case of the snapshot-based actor-oriented model detailed above, it is\nimpossible to separate the 2-send, sibling, and cosibling effects, and the inability to include\nsecond-order interactions between group-level effects precludes a direct comparison with the\nestimated group-level effects from the proportional intensity model. Further, for a single directed\ngraph, there is no possibility of including a term corresponding to send, and it is impossible to\nquantify the time-dependence of the network effects.\nFigure 3 overleaf shows the fitted coefficients for the exponential random graph model. As\nwith the case of the actor-oriented model considered in Section 2.1 above, the estimated network\neffects agree qualitatively with those of Fig. 8 from the main text. Specifically, mutuality and\ntransitive triples have positive effects, while cyclic triples have a negligible effect (in contrast to\nthe case of Fig. 2 from Section 2.1 above).\nReferences\nAnderson, C. J., W. S., and B. Crouch (1999). A p\u2217 primer: Logit models for social networks.\nSoc. Networks 21, 37\u201366.\nHandcock, M. S., D. R. Hunter, C. T. Butts, S. M. Goodreau, P. N. Krivitsky, and M. Morris\n(2011). ergm: A package to fit, simulate and diagnose exponential-family models for networks.\nVersion 2.4-2. Project home page at http://statnetproject.org.\n\n\f6\n\nP. O. Perry and P. J. Wolfe\n\nReceiver\nSender\n1\nL\nT\nJ\nF\n\nL\n\nT\n\nJ\n\nF\n\n-2.61\n2.60\n0.63\n0.13\n0.25\n\n-1.49\n0.77\n0.69\n1.04\n0.49\n\n-0.87\n-0.09\n-0.60\n1.15\n0.49\n\n-0.55\n0.12\n-0.32\n0.27\n0.79\n\n(a) Trait effects\n\nVariate\nCoefficient\n(SE)\n\nmutual\n\nctriple\n\nttriple\n\n4.49\n\n0.15\n\n0.42\n\n(0.003)\n\n(0.290)\n\n(0.060)\n\n(b) Network effects\nFig. 3. Estimated coefficients for the exponential random graph model of Section 2.2. The model also\nincluded a term for each sender (not shown); furthermore, standard errors returned for the group-level\nedge effects were nonsensical, and so are not reported.\n\nHanneke, S., W. Fu, and E. P. Xing (2010). Discrete temporal models of social networks. Electron.\nJ. Statist. 4, 585\u2013605.\nHeard, N. A., D. J. Weston, K. Platanioti, and D. J. Hand (2010). Bayesian anomaly detection\nmethods for social networks. Ann. Appl. Statist. 4, 645\u2013662.\nKolar, M., L. Song, A. Ahmed, and E. P. Xing (2010). Estimating time-varying networks. Ann.\nAppl. Statist. 4, 94\u2013123.\nMalmgren, R. D., J. M. Hofman, L. A. Amaral, and D. J. Watts (2009). Characterizing individual\ncommunication patterns. In Proc. 15th ACM SIGKDD Intl Conf. Knowledge Discovery Data\nMining, pp. 607\u2013616. New York: Association for Computing Machinery.\nRipley, R. M. and T. A. B. Snijders (2011). RSiena: Simulation investigation for empirical\nnetwork analysis. R package version 1.0.12.167, http://CRAN.R-project.org/package=RSiena.\nSnijders, T. A. B. (2001). The statistical evaluation of social network dynamics. In M. E. Sobel\nand M. P. Becker (Eds.), Sociological Methodology \u2013 2001, Volume 31, pp. 361\u2013395. Boston\nand London: Basil Blackwell.\nSnijders, T. A. B. (2005). Models for Longitudinal Network Data, Chapter 11. Models and\nMethods in Social Network Analysis. New York: Cambridge University Press.\nSnijders, T. A. B., G. V. Van de Bunt, and C. E. G. Steglich (2010). Introduction to stochastic\nactor-based models for network dynamics. Soc. Netw. 32, 44\u201360.\n\n\f"}