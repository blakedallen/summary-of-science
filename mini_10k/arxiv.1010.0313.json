{"id": "http://arxiv.org/abs/1010.0313v1", "guidislink": true, "updated": "2010-10-02T09:05:54Z", "updated_parsed": [2010, 10, 2, 9, 5, 54, 5, 275, 0], "published": "2010-10-02T09:05:54Z", "published_parsed": [2010, 10, 2, 9, 5, 54, 5, 275, 0], "title": "Adjusted empirical likelihood with high-order precision", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1010.1002%2C1010.0313%2C1010.4903%2C1010.5705%2C1010.3832%2C1010.0203%2C1010.3159%2C1010.3489%2C1010.2044%2C1010.3592%2C1010.3081%2C1010.0791%2C1010.2470%2C1010.4106%2C1010.3079%2C1010.1884%2C1010.0338%2C1010.3487%2C1010.5642%2C1010.5222%2C1010.5981%2C1010.3252%2C1010.1780%2C1010.1736%2C1010.2849%2C1010.1137%2C1010.5929%2C1010.4015%2C1010.1646%2C1010.2672%2C1010.5069%2C1010.5937%2C1010.0354%2C1010.5545%2C1010.4131%2C1010.0974%2C1010.4169%2C1010.2466%2C1010.5463%2C1010.4024%2C1010.4217%2C1010.0123%2C1010.5424%2C1010.3613%2C1010.4508%2C1010.1860%2C1010.1998%2C1010.0837%2C1010.1334%2C1010.3213%2C1010.5073%2C1010.1529%2C1010.2733%2C1010.0379%2C1010.2289%2C1010.2272%2C1010.5695%2C1010.0230%2C1010.5048%2C1010.4801%2C1010.5178%2C1010.3867%2C1010.1664%2C1010.2898%2C1010.0452%2C1010.4400%2C1010.4289%2C1010.2519%2C1010.4845%2C1010.2296%2C1010.2553%2C1010.2674%2C1010.3191%2C1010.1000%2C1010.3341%2C1010.4791%2C1010.0800%2C1010.5930%2C1010.3352%2C1010.1008%2C1010.2226%2C1010.4848%2C1010.3143%2C1010.0851%2C1010.0421%2C1010.0699%2C1010.4778%2C1010.3875%2C1010.3106%2C1010.0246%2C1010.1503%2C1010.3048%2C1010.0001%2C1010.0400%2C1010.1672%2C1010.4658%2C1010.1685%2C1010.4961%2C1010.3234%2C1010.6214%2C1010.4026&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Adjusted empirical likelihood with high-order precision"}, "summary": "Empirical likelihood is a popular nonparametric or semi-parametric\nstatistical method with many nice statistical properties. Yet when the sample\nsize is small, or the dimension of the accompanying estimating function is\nhigh, the application of the empirical likelihood method can be hindered by low\nprecision of the chi-square approximation and by nonexistence of solutions to\nthe estimating equations. In this paper, we show that the adjusted empirical\nlikelihood is effective at addressing both problems. With a specific level of\nadjustment, the adjusted empirical likelihood achieves the high-order precision\nof the Bartlett correction, in addition to the advantage of a guaranteed\nsolution to the estimating equations. Simulation results indicate that the\nconfidence regions constructed by the adjusted empirical likelihood have\ncoverage probabilities comparable to or substantially more accurate than the\noriginal empirical likelihood enhanced by the Bartlett correction.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1010.1002%2C1010.0313%2C1010.4903%2C1010.5705%2C1010.3832%2C1010.0203%2C1010.3159%2C1010.3489%2C1010.2044%2C1010.3592%2C1010.3081%2C1010.0791%2C1010.2470%2C1010.4106%2C1010.3079%2C1010.1884%2C1010.0338%2C1010.3487%2C1010.5642%2C1010.5222%2C1010.5981%2C1010.3252%2C1010.1780%2C1010.1736%2C1010.2849%2C1010.1137%2C1010.5929%2C1010.4015%2C1010.1646%2C1010.2672%2C1010.5069%2C1010.5937%2C1010.0354%2C1010.5545%2C1010.4131%2C1010.0974%2C1010.4169%2C1010.2466%2C1010.5463%2C1010.4024%2C1010.4217%2C1010.0123%2C1010.5424%2C1010.3613%2C1010.4508%2C1010.1860%2C1010.1998%2C1010.0837%2C1010.1334%2C1010.3213%2C1010.5073%2C1010.1529%2C1010.2733%2C1010.0379%2C1010.2289%2C1010.2272%2C1010.5695%2C1010.0230%2C1010.5048%2C1010.4801%2C1010.5178%2C1010.3867%2C1010.1664%2C1010.2898%2C1010.0452%2C1010.4400%2C1010.4289%2C1010.2519%2C1010.4845%2C1010.2296%2C1010.2553%2C1010.2674%2C1010.3191%2C1010.1000%2C1010.3341%2C1010.4791%2C1010.0800%2C1010.5930%2C1010.3352%2C1010.1008%2C1010.2226%2C1010.4848%2C1010.3143%2C1010.0851%2C1010.0421%2C1010.0699%2C1010.4778%2C1010.3875%2C1010.3106%2C1010.0246%2C1010.1503%2C1010.3048%2C1010.0001%2C1010.0400%2C1010.1672%2C1010.4658%2C1010.1685%2C1010.4961%2C1010.3234%2C1010.6214%2C1010.4026&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Empirical likelihood is a popular nonparametric or semi-parametric\nstatistical method with many nice statistical properties. Yet when the sample\nsize is small, or the dimension of the accompanying estimating function is\nhigh, the application of the empirical likelihood method can be hindered by low\nprecision of the chi-square approximation and by nonexistence of solutions to\nthe estimating equations. In this paper, we show that the adjusted empirical\nlikelihood is effective at addressing both problems. With a specific level of\nadjustment, the adjusted empirical likelihood achieves the high-order precision\nof the Bartlett correction, in addition to the advantage of a guaranteed\nsolution to the estimating equations. Simulation results indicate that the\nconfidence regions constructed by the adjusted empirical likelihood have\ncoverage probabilities comparable to or substantially more accurate than the\noriginal empirical likelihood enhanced by the Bartlett correction."}, "authors": ["Yukun Liu", "Jiahua Chen"], "author_detail": {"name": "Jiahua Chen"}, "author": "Jiahua Chen", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1214/09-AOS750", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1010.0313v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1010.0313v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Published in at http://dx.doi.org/10.1214/09-AOS750 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "arxiv_primary_category": {"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.TH", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1010.0313v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1010.0313v1", "journal_reference": "Annals of Statistics 2010, Vol. 38, No. 3, 1341-1362", "doi": "10.1214/09-AOS750", "fulltext": "arXiv:1010.0313v1 [math.ST] 2 Oct 2010\n\nThe Annals of Statistics\n2010, Vol. 38, No. 3, 1341\u20131362\nDOI: 10.1214/09-AOS750\nc Institute of Mathematical Statistics, 2010\n\nADJUSTED EMPIRICAL LIKELIHOOD WITH HIGH-ORDER\nPRECISION\nBy Yukun Liu1 and Jiahua Chen2\nEast China Normal University and Nankai University, and\nUniversity of British Columbia\nEmpirical likelihood is a popular nonparametric or semi-parametric\nstatistical method with many nice statistical properties. Yet when the\nsample size is small, or the dimension of the accompanying estimating\nfunction is high, the application of the empirical likelihood method\ncan be hindered by low precision of the chi-square approximation\nand by nonexistence of solutions to the estimating equations. In this\npaper, we show that the adjusted empirical likelihood is effective at\naddressing both problems. With a specific level of adjustment, the\nadjusted empirical likelihood achieves the high-order precision of the\nBartlett correction, in addition to the advantage of a guaranteed solution to the estimating equations. Simulation results indicate that the\nconfidence regions constructed by the adjusted empirical likelihood\nhave coverage probabilities comparable to or substantially more accurate than the original empirical likelihood enhanced by the Bartlett\ncorrection.\n\n1. Introduction. In applications such as econometrics, statistical finance\nand biostatistics, general estimating equations (GEE) in the form E{g(X; \u03b8)} =\n0, where g(x; \u03b8) is a vector-valued function of the observation vector x and\nthe parameter vector \u03b8, are often used to define the parameters of interest\n[Hansen (1982), Liang and Zeger (1986), Kitamura and Stutzer (1997) and\nImbens, Spady and Johnson (1998)]. With a semi-parametric setup, scientists run a low risk of mis-specifying a probability model for the population\nunder investigation. Particularly when the parameter is over-identified, that\nis, when the dimension of g is larger than the dimension of \u03b8, the generalized moment method (GMM), the empirical likelihood (EL) method or its\nReceived December 2008; revised June 2009.\nSupported in part by the NNSF of China Grants 10601026.\n2\nSupported by the NSERC of Canada and by MITACS.\nAMS 2000 subject classifications. Primary 62G20; secondary 62E20.\nKey words and phrases. Bartlett correction, confidence region, Edgeworth expansion,\nestimating function, generalized moment method.\n1\n\nThis is an electronic reprint of the original article published by the\nInstitute of Mathematical Statistics in The Annals of Statistics,\n2010, Vol. 38, No. 3, 1341\u20131362. This reprint differs from the original in\npagination and typographic detail.\n1\n\n\f2\n\nY. LIU AND J. CHEN\n\nvariations can be used for statistical inference [Hansen (1982), Owen (1988),\nNewey and McFadden (1994), Qin and Lawless (1994), Imbens (1997), Smith\n(1997) and Newey and Smith (2004)]. Many researchers, however, find that\nthe finite sample properties of the statistics based on GMM or EL are often\nvery different from the asymptotic properties at sample sizes common in\napplications [Hall and La Scala (1990), DiCiccio, Hall and Romano (1991),\nCorcoran, Davison and Spady (1995), Burnside and Eichenbaum (1996),\nCorcoran (1998) and Tsao (2004)]. High-order approximations to the finite\nsample distribution based on the Bartlett correction or bootstrapping can be\nhelpful [DiCiccio, Hall and Romano (1991), Hall and Horowitz (1996), Brown\nand Newey (2002), Newey and Smith (2004) and Chen and Cui (2007)]. Yet\nthey do not always live up to their promise, particularly for high-dimensional\ndata [Corcoran, Davison and Spady (1995) and Tsao (2004)].\nWe propose a novel approach via adjusted empirical likelihood (AEL)\n[Chen, Variyath and Abraham (2008)] to achieve the high-order precision\npromised by the Bartlett correction. The AEL is obtained by adding a\npseudo-observation into the data set. Its principal utility is to overcome\nthe difficulty arising when the estimating equations have no solution; a solution is required in the EL approach. By using a conventional level of adjustment, Chen, Variyath and Abraham (2008) found the AEL improves\nthe approximation precision of the chi-square limiting distribution. More\nrecently, Emerson and Owen (2009) discussed the level of adjustment for inference on multivariate population mean. However, the optimal level of adjustment remains unknown. In this paper, we derive a high-order expansion\nof the adjusted empirical likelihood ratio statistic, specify an optimal level\nof adjustment that enables the high-order approximation, prove that the resulting AEL shares the same high-order precision as the Bartlett corrected\nEL (BEL) and construct a less biased estimator of the Bartlett correction\nfactor that effectively improves the approximation precision.\nAlthough the AEL and the BEL have the same high-order precision, their\nfinite sample performances differ. Simulation studies show that the AEL has\nbetter precision than the BEL in general, and especially under linear and\nasset-pricing models. The AEL with conventional level of adjustment, AEL0 ,\nis found to have comparable precisions to the AEL under many models\nconsidered, but it lacks some generality. In particular, the AEL improves\nover the AEL0 under linear and asset-pricing models.\n2. The EL and the Bartlett correction.\n2.1. The empirical likelihood. To convey the idea, suppose we have x1 , x2 ,\n. . . , xn as a random sample from a nonparametric population F (x) such that\nx \u2208 Rm with dimension m. Assume that the GEE model is defined by\nEg(X; \u03b8) = 0\n\n\fADJUSTED EMPIRICAL LIKELIHOOD\n\n3\n\nfor a q-dimensional estimating function g and a p-dimensional parameter \u03b8.\nThe profile empirical likelihood function of \u03b8 is defined as\n)\n( n\nn\nn\nX\nX\nY\n(1)\npi g(xi ; \u03b8) = 0 .\npi = 1,\npi : pi \u2265 0,\nLn (\u03b8) = sup\ni=1\n\ni=1\n\ni=1\n\nThe empirical log-likelihood ratio function is defined by Rn (\u03b8) = \u22122 log(nn \u00d7\nLn (\u03b8)) [see Owen (2001) and Qin and Lawless (1994)]. One celebrated property of the empirical likelihood is that under some general conditions,\npr{Rn (\u03b80 ) \u2264 x} = pr{\u03c72q \u2264 x} + O(n\u22121 )\n\nas n \u2192 \u221e where \u03b80 is the true parameter value. This property is most\nconvenient for the construction of confidence regions of \u03b8,\n(2)\n\n{\u03b8 : Rn (\u03b8) \u2264 c(1 \u2212 \u03b1; q)}\n\nwith c(1 \u2212 \u03b1; q) being the (1 \u2212 \u03b1)th quantile of the chi-square distribution\nwith q degrees of freedom, and 1 \u2212 \u03b1 being the pre-selected confidence level.\nSuch confidence regions are renowned for their data-driven shape, and there\nis no need to estimate any scalar parameters. For other results, such as when\n\u03b80 is replaced by its nonparametric maximum EL estimate \u03b8\u0302, we refer to Qin\nand Lawless (1994).\n2.2. The Bartlett correction of the EL. The precision of the confidence\nregion constructed by (2) can be poor, particularly when the sample size is\nsmall. To improve the precision of the coverage probability, we may calibrate\nthe distribution of Rn (\u03b80 ) by bootstrapping or by high-order approximations. We now review high-order approximation via the Bartlett correction.\nThe Bartlett correction for a smooth function of means was first established by DiCiccio, Hall and Romano (1991) while estimating questions by\nChen and Cui (2006, 2007). For ease of illustration, we consider the situation\nwhere p = q = 1 and g(x; \u03b8) = x \u2212 \u03b8. Under this model, the parameter \u03b8 is the\npopulation mean. The chi-square approximation has precision O(n\u22121 ) and\nthe confidence interval of \u03b8 based on the chi-square approximation may not\nhave accurate coverage probabilities. The Bartlett correction can improve\nthe approximation precision to O(n\u22122 ).\nP\nBy the Lagrange method, when the solution to ni=1 pi g(xi ; \u03b8) = 0 exists,\nwe have\nn\nX\nlog{1 + \u03bbg(xi ; \u03b8)}\nRn (\u03b8) =\ni=1\n\nfor a Lagrange multiplier \u03bb that is the solution to\n(3)\n\nn\nX\ni=1\n\ng(xi ; \u03b8)\n= 0.\n1 + \u03bbg(xi ; \u03b8)\n\n\f4\n\nY. LIU AND J. CHEN\n\nP\nLet \u03b1r = E{g(X; \u03b8)}r and Ar = n\u22121 ni=1 {g(xi ; \u03b8)}r \u2212 \u03b1r . Without loss of\ngenerality, we assume that either \u03b12 = 1 or we can replace g(x; \u03b8) with\n\u22121/2\n\u03b12 g(x; \u03b8). Assuming that \u03b8 is the true parameter value, we can write\n\u03bb = \u03bb1 + \u03bb2 + \u03bb3 + Op (n\u22122 )\nwith\n\u03bb1 = A1 ,\n\n\u03bb2 = \u03b13 A21 \u2212 A1 A2 ,\n\n\u03bb3 = A1 A22 + A21 A3 + 2\u03b123 A31 \u2212 3\u03b13 A21 A2 \u2212 \u03b14 A31 .\n\nUnder some moment conditions, \u03bbr = Op (n\u2212r/2 ) for r = 1, 2, 3. Substituting\nthese expansions into the expression for Rn (\u03b8), we get\n(4)\nwith\n\nRn (\u03b8) = n{R1 + R2 + R3 }2 + Op (n\u22123/2 )\nR1 = A1 ,\nR2 = 13 \u03b13 A21 \u2212 21 A1 A2 ,\n\nR3 = 38 A1 A22 + 94 \u03b123 A31 \u2212 56 \u03b13 A21 A2 + 31 A21 A3 \u2212 14 \u03b14 A31 .\n\nDiCiccio, Hall and Romano (1991) find that the cumulants of\nn(1 \u2212 b/n)(R1 + R2 + R3 )2\n\nmatch those of the \u03c721 distribution to the order of n\u22123/2 when\n(5)\n\nb = 12 \u03b14 \u2212 13 \u03b123 .\n\nFurthermore, since R1 + R2 + R3 are smooth functions of general sample\nmeans, the result of Bhattacharya and Ghosh (1978) implies that\npr{n(1 \u2212 b/n)(R1 + R2 + R3 )2 \u2264 x} = pr{\u03c721 \u2264 x} + O(n\u22122 ).\n\nMore details are in the Appendix.\nIn applications, the value b must be replaced by some root-n consistent\nestimator, and, in theory, the replacement does not affect the high-order\nasymptotic conclusion. Naturally, b is often replaced by a moment estimate.\nAnother way to improve the finite sample performance is to use bootstrap\ncalibration, that is, to estimate the sample distribution of the Rn (\u03b8) via a\nbootstrap resampling scheme [see, e.g., Hall and Horowitz (1996)]. There\nare situations where the solution pi 's to the constraints in (1) at \u03b8 = \u03b80\ndo not exist with nonnegligible probability. A convention adopted in this\nsituation is to define Rn (\u03b8) = \u221e. However, if pr{Rn (\u03b80 ) = \u221e} > \u03b1, then\npr{Rn (\u03b80 ) < c} < 1 \u2212 \u03b1 for any finite c. Consequently, a bootstrap scheme\ncan at most boost the coverage probability to 1 \u2212 pr{Rn (\u03b80 ) = \u221e} which is\nstill below the nominal level 1 \u2212 \u03b1. This problem is clearly also shared by\nthe Bartlett correction [see also Tsao (2004)].\n\n\fADJUSTED EMPIRICAL LIKELIHOOD\n\n5\n\n3. The AEL and the high-order approximation.\n3.1. The adjusted empirical likelihood. For each given \u03b8, the likelihood\nratio function Rn (\u03b8) is well defined only if the convex hull of\n(6)\n\n{g(xi ; \u03b8) : i = 1, 2, . . . , n}\n\ncontains the q-dimensional vector 0. When n is not large, or when a good\ncandidate (vector) value of \u03b8 is not available, this convex hull often fails\nto contain 0 [see, e.g., Chen, Variyath and Abraham (2008)]. Blindly setting Ln (\u03b8) = 0 as suggested in the literature fails to provide information\non whether \u03b8 is grossly unfit to the data or is in fact only slightly off an\nappropriate value. Let gi = g(xi ; \u03b8), i = 1, . . . , n, and\ngn+1 = \u2212an \u1e21n = \u2212an n\n\n\u22121\n\nn\nX\n\ngi\n\ni=1\n\nfor some an > 0. The adjusted (profile) empirical likelihood is defined as\n)\n(n+1\nn+1\nn+1\nX\nX\nY\n(7)\npi gi = 0\npi = 1,\npi : pi \u2265 0,\nLn (\u03b8; an ) = sup\ni=1\n\ni=1\n\ni=1\n\nand the adjusted empirical likelihood ratio function as\nRn (\u03b8; an ) = \u22122 log{(n + 1)n+1 Ln (\u03b8; an )}.\nBecause \u1e21n and gn+1 are on opposite sides of 0, the AEL is always well defined. Namely, its value is always nonzero. When an = op (n2/3 ), Chen, Variyath and Abraham (2008) showed that the first-order asymptotic properties\nof the EL are retained by the AEL, and a conventional an = max{1, log n/2}\nwas found useful in a number of examples. However, an optimal choice of\nan remains unsolved. We next recommend a specific an and show that the\nresulting AEL achieves the goal attained by the Bartlett correction.\n3.2. AEL with high-order precision. The level of adjustment at which the\nAEL has high-order precision is an = b/2, where b is the Bartlett correction\nfactor for the usual EL. This surprising relationship reveals an intrinsic\nrelationship between the AEL and the Bartlett correction. Indeed, the proof\nof the following result is built on the Bartlett correction.\nTheorem 1. Suppose that x1 , x2 , . . . , xn is a random sample from an\nm-variate nonparametric population F (x). Assume that the GEE model is\ndefined by\nEg(X; \u03b8) = 0,\n\n\f6\n\nY. LIU AND J. CHEN\n\nwhere \u03b8 is a p-dimensional parameter, g(X; \u03b8) is a q-dimensional estimating\nfunction, and its characteristic function satisfies Cram\u00e9r's condition,\nlim sup|E exp{itT g(X; \u03b8)}| < 1.\nktk\u2192\u221e\n\nAssume also that Ekg(X; \u03b8)k18 < \u221e and var(g(X; \u03b8)) is positive definite.\nLet \u03b80 be the true parameter value and an = a + Op (n\u22121/2 ). Then\nRn (\u03b80 ; an ) = n{R1 + R2 + R3a }T {R1 + R2 + R3a } + Op (n\u22123/2 ),\n\nwhere R1 , R2 and R3a will be given in (14) and (16). When a = b/2 where\nb is the Bartlett correction factor for the usual empirical likelihood,\npr{n{R1 + R2 + R3a }T {R1 + R2 + R3a } \u2264 x} = pr(\u03c72q \u2264 x) + O(n\u22122 ).\nAdding a pseudo-observation gn+1 results in a slightly different R3a as\ncompared to R3 in Section 2.2. This explains the choice of the notation.\nWhen q = 1, the Bartlett correction factor b = \u03b14 /2 \u2212 \u03b123 /3 > 0 unless\ng(X; \u03b8) degenerates. Hence, the pseudo-observation obtained by setting an =\nb/2 or its suitable estimator satisfies the condition an > 0 required by the\nAEL. When q > 1, it is uncertain whether b > 0 or not. While Theorem 1\nremains valid, there is a small probability that the AEL is not defined when\nb < 0. We can easily avoid this problem by adding two pseudo-observations.\nLet\n)\n(n+2\nn+2\nn+2\nX\nX\nY\n(8)\npi gi = 0\npi = 1,\npi : pi \u2265 0,\nLn (\u03b8; a1n , a2n ) = sup\ni=1\n\ni=1\n\ni=1\n\nand let the adjusted empirical likelihood ratio function be\n\nRn (\u03b8; a1n , a2n ) = \u22122 log{(n + 2)n+2 Ln (\u03b8; a1n , a2n )}\n\nwith gn+1 = \u2212a1n \u1e21 and gn+2 = a2n \u1e21. When a2n \u2212 a1n = b, the result of Theorem 1 remains.\nIn general, the Bartlett correction factor b can be written as the difference of two positive values. This decomposition gives us natural choices of\na1n and a2n for multidimensional estimating functions. In simulations, we\nadded a single pseudo-observation when q = 1 and two pseudo-observations\nwhen q \u2265 2. We also recommend this practice in applications. More detailed\ndiscussions about the Bartlett correction factor b are given in the next subsection.\nWhen q > p where the parameter is over-identified, it is more efficient to\nconstruct confidence regions with\n\u2206n (\u03b8; an ) = Rn (\u03b8; an ) \u2212 inf Rn (\u03b8; an ).\n\u03b8\n\nWhen an = 0, Chen and Cui (2007) show that \u2206n (\u03b80 ; 0) is also Bartlett\ncorrectable. The result of Theorem 1 remains valid as follows.\n\n\fADJUSTED EMPIRICAL LIKELIHOOD\n\n7\n\nTheorem 2. Assume the same conditions as in Theorem 1, and that\nthere exists a neighborhood of \u03b80 , N (\u03b80 ) and an integrable function, h(x),\nsuch that\nsup k\u2202 3 g(x; \u03b8)/\u2202\u03b8 3 k3 \u2264 h(x).\n\n\u03b8\u2208N (\u03b80 )\n\nThen at the level of adjustment an = a + Op (n\u22121/2 ),\n\u2206n (\u03b80 ; an ) = n{R1 + R2 + R3a }T {R1 + R2 + R3a } + Op (n\u22123/2 )\nfor some R1 , R2 and R3a , and there exists a Bartlett correction factor b\nsuch that when a = b/2,\npr{n{R1 + R2 + R3a }T {R1 + R2 + R3a } \u2264 x} = pr(\u03c72p \u2264 x) + O(n\u22122 ).\nThe expressions of the Bartlett correction factor b and Rj , j = 1, 2, in\nTheorem 2 are the same as in Chen and Cui (2007). When an = 0, R3a also\nbecomes their R3 . More details and a brief proof are given in the Appendix.\n3.3. Estimation of the Bartlett correction factor b. We first consider the\nestimation of b in the case of Theorem 1. Even for the simplistic one-sample\nproblem, Bartlett-corrected ordinary EL confidence intervals for the population mean often have lower than nominal coverage probabilities when\nthe Bartlett correction factor b is replaced by its moment estimator. The\nBartlett-corrected EL intervals with theoretical b are often much more satisfactory. Our investigation reveals that the moment estimator of b usually\ngrossly under estimates particularly when n is small, say n = 20, 30. See the\nsimulation results presented in the next section.\nLet us first examine the case of q = p = 1 where the Bartlett correction\nfactor is given by\nb=\n\n\u03b14\n\u03b123\n\u2212\n.\n2\u03b122 3\u03b132\n\nNote that we no longer\nassume \u03b12 = 1. The moment estimators of \u03b1r are\nP\ngiven by \u03b1\u0302r = n\u22121 ni=1 (gi \u2212 \u1e21)r . Since E \u03b1\u03022 = (n \u2212 1)\u03b12 /n, we estimate \u03b12\nby \u03b1\u03032 = n\u03b1\u03022 /(n \u2212 1) to reduce bias. In summary, we use the estimators given\nin the following table to construct a less-biased estimator of b:\nParameter\n\u03b12\n\u03b14\n\u03b122\n\u03b13\n\u03b123\n\u03b132\n\nEstimator\n\u03b1\u03032\n\u03b1\u03034\n\u03b1\u030322\n\u03b1\u03033\n\u03b1\u030333\n\u03b1\u0303222\n\nExpression\nn\u03b1\u03022 /(n \u2212 1)\n(n\u03b1\u03024 \u2212 6\u03b1\u030322 )/(n \u2212 4)\n\u03b1\u030322 \u2212 \u03b1\u03034 /n\nn\u03b1\u03023 /(n \u2212 3)\n\u03b1\u030323 \u2212 (\u03b1\u03026 \u2212 \u03b1\u030323 )/n\n\u03b1\u030332 .\n\n\f8\n\nY. LIU AND J. CHEN\n\nThe above choices are motivated as follows. Since\n4\u03b14 6\u03b122\n+\n+ O(n\u22122 ),\nn\nn\n\u03b14\nE \u03b1\u030322 = \u03b122 +\n+ O(n\u22122 ),\nn\n3\u03b13\nE \u03b1\u03023 = \u03b13 \u2212\n+ O(n\u22122 ),\nn\n\nE \u03b1\u03024 = \u03b14 \u2212\n\nwe estimate \u03b14 , \u03b122 and \u03b13 by \u03b1\u03034 = (n\u03b1\u03024 \u2212 6\u03b1\u030322 )/(n \u2212 4), \u03b1\u030322 = \u03b1\u030322 \u2212 \u03b1\u03034 /n\nand \u03b1\u03033 = n\u03b1\u03023 /(n \u2212 3), respectively. The biases of \u03b1\u03034 , \u03b1\u030322 and \u03b1\u03033 are of\norder O(n\u22122 ) compared to the O(n\u22121 ) biases of the corresponding moment\nestimators. Precise form of the O(n\u22121 ) bias of \u03b1\u030223 is complex. Hence, we\naim\nto reduce rather than completely eliminate the O(n\u22121 ) bias. Since \u03b1\u03033 \u2248\nP\nn\n1\n2\n3\n2\ni=1 gi , we have approximately E \u03b1\u03033 = \u03b13 and E \u03b1\u03033 = \u03b13 + var(\u03b1\u03033 ), and\nn\n2\napproximately var(\u03b1\u03033 ) = (\u03b16 \u2212 \u03b13 )/n.\nWhen q = p > 1, the expression for b is more complex. Let V (\u03b8) =\nvar{g(X; \u03b8)} be the covariance matrix. By eigenvalue decomposition, we\nmay write\nV (\u03b80 ) = P diag{\u03be1 , . . . , \u03beq }P T\nsuch that P P T = I and \u03be1 , . . . , \u03beq are eigenvalues of V (\u03b80 ). Furthermore, let\nY = P T g(X; \u03b80 ), and for any positive integers (r, s, . . . , t), define\n\u03b1rs***t = E{Y r Y s * * * Y t },\n\n(9)\n\nwhere Y t is the tth component of vector Y .\nIt can be seen that after g is transformed by multiplying P , \u03b1rr = \u03ber and\nrs\n\u03b1 = 0 for r 6= s. The Bartlett correction factor can then be written as\n\u001b\n\u001a\n1 1 X \u03b1rrss\n1 X \u03b1rst \u03b1rst\nb=\n\u2212\nq 2 r,s \u03b1rr \u03b1ss 3 r,s,t \u03b1rr \u03b1ss \u03b1tt\n\u001a\nX \u03b1rrss \u001b\n1 X \u03b1rrrr\n+\n=\nq r 2(\u03b1rr )2\n2\u03b1rr \u03b1ss\nr6=s\n\n\u001a\nX (\u03b1rst )2 \u001b\n1 X (\u03b1rrr )2 X (\u03b1rss )2\n\u2212\n+\n+2\nq r 3(\u03b1rr )3\n\u03b1rr (\u03b1ss )2\n\u03b1rr \u03b1ss \u03b1tt\nr<s<t\nr6=s\n\n\u001a\n\u001b\n\u001b\n\u001a\n(\u03b1rrr )2\n(\u03b1rss )2\n1 X \u03b1rrrr\n1 X \u03b1rrss\n\u2212\n\u2212\n+\n=\nq r 2(\u03b1rr )2 3(\u03b1rr )3\n2q\n\u03b1rr \u03b1ss \u03b1rr (\u03b1ss )2\nr6=s\n\n\u001a\nX (\u03b1rst )2 \u001b\n1 1 X (\u03b1rss )2\n+2\n.\n\u2212\nq 2\n\u03b1rr (\u03b1ss )2\n\u03b1rr \u03b1ss \u03b1tt\nr<s<t\nr6=s\n\n\fADJUSTED EMPIRICAL LIKELIHOOD\n\n9\n\nLet\n\u001a\n\u001a\n\u001b\n\u001b\n(\u03b1rrr )2\n(\u03b1rss )2\n1 X \u03b1rrss\n1 X \u03b1rrrr\n\u2212\n\u2212\n+\n,\nb1 =\nq r 2(\u03b1rr )2 3(\u03b1rr )3\nq r<s \u03b1rr \u03b1ss \u03b1rr (\u03b1ss )2\nb2 =\n\n1 X (\u03b1rss )2\n2 X (\u03b1rst )2\n+\n.\nq r<s \u03b1rr (\u03b1ss )2 q r<s<t \u03b1rr \u03b1ss \u03b1tt\n\nClearly, both b1 and b2 are positive and b = b1 \u2212 b2 . There can be other ways\nto decompose b. We have chosen the above decomposition so that both b1\nand b2 are of moderate size.\nNote that the Bartlett correction factor(s) depends on the unknown \u03b80 .\nIn applications, we first compute a maximum adjusted empirical likelihood\nestimate \u03b8\u0302 at an = log n/2, and use it as a tentative replacement of \u03b80 for\nestimating b or b1 and b2 . We decompose the sample variance of g(x; \u03b8) at\n\u03b8 = \u03b8\u0302 to obtain the orthogonal matrix P . We then obtain Yi = P T g(Xi ; \u03b8\u0302)\nand define the moment estimators as\nn\nX\nrs***t\n\u22121\n(10)\nYir Yis * * * Yit .\n\u03b1\u0302\n=n\ni=1\n\nTo reduce the bias in the estimation of b1 and b2 , we use the estimators\ngiven in the following table:\nParameter\n\u03b1rr\n\u03b1rrss\n\u03b1rst\nrst\n\u03b1 \u03b1rst\n\u03b1rr \u03b1ss\n\u03b1rr \u03b1ss \u03b1tt\n\nEstimator\n\u03b1\u0303rr\n\u03b1\u0303rrss\n\u03b1\u0303rst\n\u03b1\u0303rst,rst\n\u03b1\u0303rr,ss\n\u03b1\u0303rr,ss,tt\n\nExpression\nn\u03b1\u0302rr /(n \u2212 1)\nrrss\nrr\nss\n{n\u03b1\u0302\n\u2212 2\u03b1\u0303 \u03b1\u0303 \u2212 4I(r = s)\u03b1\u0303rr \u03b1\u0303rr }/(n \u2212 4)\nn\u03b1\u0302rst /(n \u2212 3)\nrst\nrst\n\u03b1\u0303 \u03b1\u0303 \u2212 (\u03b1\u0302rrsstt \u2212 \u03b1\u0303rst \u03b1\u0303rst )/n\n\u03b1\u0303rr \u03b1\u0303ss \u2212 \u03b1\u0303rrss /n\n\u03b1\u0303rr \u03b1\u0303ss \u03b1\u0303tt\n\nfor all 1 \u2264 r, s, t \u2264 q, and I(r = s) is the indicator function. We denote the\nresulting estimates as b\u03031 and b\u03032 . For q > 1, we add two pseudo-observations\nwith a1n = b\u03031 /2 and a2n = b\u03032 /2 in the simulations.\nTo examine the bias properties of the new estimator, we generated 10,000\nsets of random samples from a number of selected univariate, bivariate and\ntrivariate distributions. The population distributions are not important at\nthis stage, and they will be specified in the simulation section. We computed\nthe Bartlett correction factors and their average estimates for constructing\nconfidence regions of the population mean. The outcomes are given in Tables\n1 and 2. The moment estimators are denoted as bn and the new estimators\nas b\u0303n . Clearly, the new estimators are much less biased under the normal,\nexponential and chi-square distributions. Under mixture distributions, b\u0303n\noverestimates b, but the resulting AEL confidence intervals still have good\n\n\f10\n\nY. LIU AND J. CHEN\n\nTable 1\nBartlett correction factors and their average estimates for univariate population mean\nn\nb\nbn\nb\u0303n\nbn\nb\u0303n\n\n20\n30\n\nN (0, 1)\n\nExp(1)\n\n0.2N1 + 0.8N2\n\n\u03c721\n\n1.50\n1.16\n1.57\n1.26\n1.56\n\n3.17\n1.40\n3.19\n1.66\n3.17\n\n1.11\n1.14\n2.08\n1.15\n1.63\n\n4.83\n1.59\n5.56\n1.96\n5.12\n\ncoverage properties. We also examined the bias properties under a number\nof linear models. The results are given in Table 3. Again, b\u0303n is much less\nbiased. The model specifications are relegated to the simulation section.\nWhen q > p, we prefer \u2206n (a) for constructing confidence intervals as in\nTheorem 2. However, as indicated in Chen and Cui (2007), it is impractical\nto estimate b by the method of moments as it involves many terms and highorder moments. In simulations, we used a robustified bootstrap estimate of\nb suggested by Chen and Cui (2007).\n4. Applications.\n4.1. Confidence regions for population mean. A classical problem is the\nconstruction of confidence regions or testing a hypothesis about a specific\nvalue of the population mean based on a set of n independent and identically\ndistributed observations. Particularly for scalar observations, the standard\nTable 2\nBartlett correction factors and their average estimates for multivariate (q = 2, 3)\npopulation mean\n(a)\n\n(b)\n\n(c)\n\n(d)\n\nb\nbn\nb\u0303n\nbn\nb\u0303n\n\n3.21\n1.63\n2.93\n1.90\n3.06\n\n3.71\n1.67\n3.34\n1.98\n3.47\n\n1.68\n1.48\n2.55\n1.56\n2.18\n\n2.21\n1.46\n2.14\n1.64\n2.20\n\nb\nbn\nb\u0303n\nbn\nb\u0303n\n\n4.07\n2.27\n3.72\n2.67\n3.89\n\n3.84\n2.24\n3.47\n2.61\n3.64\n\n2.36\n1.98\n2.62\n2.13\n2.52\n\n2.67\n2.00\n2.62\n2.22\n2.67\n\nn\nq=2\n20\n30\nq=3\n30\n50\n\n\f11\n\nADJUSTED EMPIRICAL LIKELIHOOD\n\nTable 3\nBartlett correction factors and their average estimates under linear regression models\nN (0, 1)\nn\n30\n50\n100\n\nExp(1)\n\nb\n\nbn\n\nb\u0303n\n\nb\n\nbn\n\nb\u0303n\n\n3.55\n3.53\n3.90\n\n2.39\n2.74\n3.28\n\n3.56\n3.61\n3.86\n\n7.98\n7.92\n9.00\n\n2.61\n3.35\n4.58\n\n5.39\n6.16\n7.07\n\napproach is to use the Studentized sample mean,\n\u221a\nn(x\u0304n \u2212 \u03b8)\nTn (\u03b8) =\nsn\nfor both purposes where x\u0304n is the sample mean, and s2n is the sample variance. When the population distribution is normal, Tn (\u03b8) has a t-distribution\nwith n \u2212 1 degrees of freedom. The confidence interval or hypothesis test\ncalibrated by the t-distribution is found to be accurate even for nonnormal\npopulation distributions and for moderate sample size n. For multivariate\nobservations, the t-statistic is replaced by Hotelling's T 2 defined as\nTn2 (\u03b8) = n(X\u0304n \u2212 \u03b8)T Sn\u22121 (X\u0304n \u2212 \u03b8)\nwith X\u0304n the vector sample mean and Sn the sample covariance matrix.\nWhen the observations have a p-dimensional multivariate normal distribution, (n \u2212 p)Tn2 (\u03b8)/{p(n \u2212 1)} has an F -distribution with p and n \u2212 p degrees\nof freedom. The F -distribution often serves as a reference distribution for\nboth hypothesis tests and constructing confidence regions, whether or not\nthe normality assumption holds. Surprisingly, the normal-theory-based confidence regions have reasonably accurate coverage probabilities even when\nthe sample sizes are small and the population distributions deviate from the\nnormal. Thus they serve as a good barometer to gauge the performance of\na new method.\nThe EL and AEL counterparts are obtained by letting g(x; \u03b8) = x \u2212 \u03b8. For\nthe sake of comparison, we use the same simulation set-ups as in DiCiccio,\nHall and Romano (1991). We investigate the coverage probabilities of 90%,\n95% and 99% confidence intervals based on the following methods:\n(1)\n(2)\n(3)\n(4)\n(5)\n(6)\n\nHotelling's T 2 (including the univariate case), T2 ;\nThe usual empirical likelihood, EL;\nBartlett-corrected empirical likelihood with moment estimate bn , BEL;\nAdjusted empirical likelihood with moment estimate bn , AEL;\nBartlett-corrected empirical likelihood with b\u0303n , BEL*;\nAdjusted empirical likelihood with b\u0303n , AEL*;\n\n\f12\n\nY. LIU AND J. CHEN\nTable 4\nCoverage probabilities for one-sample population mean\n\nN (0, 1)\n\nn\n\nLevel\n\nT2\n\nEL\n\nBEL AEL BEL* AEL* BELt AELt\n\n20\n\n90\n95\n99\n90\n95\n99\n\n90.1\n95.1\n98.9\n90.2\n95.5\n99.1\n\n88.2\n93.2\n97.9\n89.0\n94.3\n98.7\n\n89.0\n94.0\n98.2\n89.7\n94.9\n98.8\n\n89.1\n94.0\n98.3\n89.8\n94.9\n98.8\n\n89.3\n94.2\n98.3\n90.0\n95.0\n98.8\n\n89.5\n94.4\n98.4\n90.0\n95.0\n98.8\n\n89.3\n94.2\n98.3\n89.9\n95.0\n98.9\n\n89.4\n94.3\n98.4\n89.9\n95.0\n98.9\n\n91.0\n95.4\n98.9\n91.1\n95.8\n99.1\n\n90\n95\n99\n90\n95\n99\n\n87.5\n92.0\n96.6\n87.6\n92.8\n97.1\n\n85.6\n91.2\n96.7\n86.7\n92.3\n97.6\n\n86.8\n91.8\n97.0\n87.7\n92.9\n97.9\n\n87.0\n91.9\n97.1\n87.8\n93.0\n97.9\n\n87.6\n92.3\n97.2\n88.2\n93.3\n98.0\n\n88.2\n92.8\n97.4\n88.5\n93.6\n98.0\n\n88.2\n92.8\n97.5\n88.6\n93.7\n98.2\n\n88.9\n93.5\n98.0\n88.9\n93.9\n98.3\n\n88.7\n93.4\n97.9\n89.0\n94.0\n98.4\n\n90\n95\n99\n90\n95\n99\n\n88.4\n92.8\n97.0\n88.7\n93.7\n97.8\n\n88.4\n93.3\n97.8\n89.1\n94.4\n98.8\n\n89.5\n94.3\n98.0\n89.9\n94.9\n99.1\n\n89.5\n94.3\n98.0\n89.9\n94.9\n99.1\n\n91.0\n95.0\n98.1\n90.3\n95.3\n99.2\n\n91.8\n95.5\n98.2\n90.4\n95.5\n99.3\n\n89.2\n94.1\n98.0\n89.7\n94.7\n99.0\n\n89.2\n94.1\n98.0\n89.8\n94.7\n99.0\n\n90.9\n95.2\n98.4\n91.2\n95.6\n99.3\n\n90\n95\n99\n90\n95\n99\n\n84.8\n89.2\n94.4\n85.9\n90.2\n95.2\n\n83.7\n89.3\n95.4\n85.4\n91.1\n96.5\n\n85.0\n90.4\n96.0\n86.5\n91.9\n96.8\n\n85.2\n90.5\n96.0\n86.7\n91.9\n96.8\n\n86.4\n91.3\n96.4\n87.7\n92.4\n97.0\n\n87.3\n92.0\n96.8\n88.2\n92.7\n97.2\n\n87.2\n92.2\n96.9\n88.2\n93.0\n97.3\n\n89.2\n93.8\n98.5\n88.9\n93.6\n97.7\n\n86.7\n91.7\n96.9\n87.8\n92.8\n97.3\n\n30\n\nExp(1)\n\n20\n\n30\n\n0.2N1 + 0.8N2\n\n20\n\n30\n\n\u03c721\n\n20\n\n30\n\nAEL0\n\n(7) Bartlett-corrected empirical likelihood with known b value, BELt ;\n(8) Adjusted empirical likelihood with known b value, AELt ;\n(9) Adjusted empirical likelihood with level of adjustment an = 21 log n, AEL0 .\nWe generated 10,000 samples from four distributions: (a) the standard\nnormal; (b) an exponential distribution with mean 1; (c) a normal mixture 0.2N (5, 1) + 0.8N (\u22121.25, 1); and (d) the \u03c721 distribution. The results\nare presented in Table 4 where 0.2N1 + 0.8N2 denotes the normal mixture\ndistribution.\nUnder the normal model, T 2 is optimal, yet we find that the AEL* is as\ngood within simulation error. The accuracy of the AEL* is consistently better than that of the BEL and BEL*. This is particularly true when the population distribution is exponential or chi-square. Under the mixture model,\nthe AEL* has a slightly higher than nominal coverage probability. Finally,\nwe remark that under the chi-square distribution, all the methods still have\n\n\fADJUSTED EMPIRICAL LIKELIHOOD\n\n13\n\nroom for improvement when n = 20. Our simulation results on EL and BEL\nare comparable to those reported in the literature.\nIn the multivariate case, we conducted simulation experiments for p = 2\nand p = 3. We used the following strategy to generate correlated trivariate\nobservations. We first generated a random observation D from the uniform\ndistribution on the interval [1, 2]. Given D, we generated X1 , X2 and X3\nfrom the distributions specified as follows:\n(a) X1 \u223c N (0, D 2 ), X2 \u223c Gamma(D \u22121 , 1), X3 \u223c \u03c72D ;\n(b) X1 \u223c Gamma(D, 1), X2 \u223c Gamma(D \u22121 , 1), X3 \u223c Gamma(4 \u2212 D, 1);\n(c) X1 \u223c 0.2N (5, D 2 )+0.8N (\u22121.25, D \u22122 ), X2 \u223c 0.2N (5, D \u22122 )+0.8N (\u22121.25,\nD 2 ), X3 \u223c N (0, D 2 );\n(d) X1 \u223c Poisson(D), X2 \u223c Poisson(D \u22121 ), X3 \u223c Poisson(4 \u2212 D).\nWhen p = 2, we used X1 and X2 in our simulation and generated 10,000\ndata sets with sample sizes n = 20 and 30. When p = 3, we also generated\n10,000 data sets but increased sample sizes to n = 30 and 50 to accommodate\nthe higher dimension. Table 5 presents the simulation results.\nWe observe that the AEL* outperforms all other methods, often substantially. Under the bivariate mixture model (c) at nominal level 95% and\nsample size n = 20, the AEL* has 93.7% coverage probability compared to\n91.1% for the BEL and 92.3% for the BEL*. This is significant because the\nAEL*, the BEL and the BEL* are known to be precise up to the same order\nn\u22122 . The difference in performances presumably comes from higher orders.\nWe remark here that the above discussion has not taken AELt and AEL0\ninto account. The AELt is only for theoretical interest and its performance\nindicates how far AEL can be improved by choosing a better estimator of\nb. The AEL0 is the AEL with a conventional level of adjustment suggested\nin Chen, Variyath and Abraham (2008). It has comparable performance to\nAEL*. Due to a lack of theoretical justification, the observed good performance is hard to generalize. We will continue to keep an eye on its performance.\n4.2. Linear regression. The empirical likelihood method can also be used\nto construct confidence regions for the regression coefficient \u03b2 in the following linear regression model:\n(11)\n\ny = xT \u03b2 + \u03b5,\n\nwhere \u03b2 is a p-dimensional parameter, x a p-dimensional fixed design point\nand y the scalar response. Chen (1993) showed that the empirical likelihood\nconfidence regions for \u03b2 are also Bartlett correctable. In comparison, by\nletting g(y, x; \u03b2) = x(y \u2212 xT \u03b2) the proposed AEL method (AEL*) directly\napplies.\n\n\f14\n\nY. LIU AND J. CHEN\nTable 5\nCoverage probabilities for one-sample multivariate (q = 2, 3) population mean\n\nq=2\n\n(a)\n\nn\n\nLevel\n\nT2\n\nEL\n\nBEL\n\nAEL\n\nBEL*\n\nAEL*\n\nBELt\n\nAELt\n\nAEL0\n\n20\n\n90\n95\n99\n90\n95\n99\n\n86.0\n91.3\n96.5\n87.2\n92.2\n97.0\n\n81.7\n87.7\n94.5\n85.1\n90.8\n96.5\n\n83.8\n89.3\n95.3\n86.5\n91.7\n97.0\n\n84.3\n89.8\n95.9\n86.7\n92.0\n97.2\n\n84.8\n90.1\n95.9\n87.0\n92.2\n97.2\n\n86.2\n91.6\n96.7\n87.8\n92.8\n97.5\n\n85.4\n90.6\n96.1\n87.4\n92.4\n97.4\n\n87.0\n92.2\n97.9\n88.0\n93.0\n97.6\n\n86.6\n91.8\n97.4\n88.2\n93.2\n97.8\n\n90\n95\n99\n90\n95\n99\n\n84.5\n89.5\n95.4\n85.9\n90.7\n96.1\n\n80.8\n86.8\n93.6\n84.5\n90.4\n96.3\n\n82.7\n88.4\n94.5\n86.0\n91.6\n96.8\n\n83.4\n89.1\n95.0\n86.3\n91.8\n97.0\n\n84.2\n89.6\n94.9\n86.8\n92.2\n97.1\n\n86.2\n91.1\n96.2\n87.6\n92.7\n97.4\n\n84.9\n90.0\n95.3\n87.1\n92.5\n97.3\n\n87.2\n92.5\n98.5\n88.0\n93.1\n97.8\n\n85.6\n91.1\n96.7\n87.6\n92.9\n97.6\n\n90\n95\n99\n90\n95\n99\n\n85.7\n90.6\n95.8\n87.9\n92.9\n97.2\n\n84.6\n89.9\n95.2\n87.4\n93.2\n98.0\n\n86.2\n91.1\n95.7\n88.9\n94.2\n98.3\n\n86.4\n91.5\n96.0\n89.0\n94.3\n98.4\n\n87.7\n92.3\n96.0\n89.6\n94.7\n98.5\n\n89.4\n93.7\n97.2\n90.0\n95.1\n98.8\n\n86.2\n91.2\n95.7\n88.9\n94.1\n98.3\n\n86.5\n91.4\n96.0\n89.0\n94.2\n98.4\n\n88.8\n93.2\n97.1\n90.7\n95.4\n98.7\n\n90\n95\n99\n90\n95\n99\n\n88.5\n93.3\n97.6\n88.4\n93.6\n98.0\n\n84.2\n90.2\n95.8\n86.4\n92.3\n97.2\n\n85.9\n91.3\n96.2\n87.6\n93.0\n97.6\n\n86.2\n91.6\n96.5\n87.7\n93.1\n97.7\n\n86.6\n91.8\n96.4\n87.9\n93.3\n97.8\n\n87.4\n92.5\n97.0\n88.2\n93.5\n97.9\n\n86.8\n91.8\n96.5\n88.0\n93.3\n97.8\n\n87.6\n92.4\n97.0\n88.3\n93.5\n97.9\n\n89.0\n93.7\n98.1\n89.8\n94.2\n98.4\n\n30\n\n(b)\n\n20\n\n30\n\n(c)\n\n20\n\n30\n\n(d)\n\n20\n\n30\n\nIn this simulation study, we examined the performance of the AEL*\nmethod based on model (11) with p = 2, the true parameter value \u03b20 =\n(1, 1)T , and the errors \u03b5i were generated from either a normal distribution\nor from a centralized exponential distribution as specified in Table 6. The\ndesign matrix of x of size n \u00d7 2 was taken from the first n rows in Table 1 of\nChen (1993). The simulation results also are given in Table 6. The improvement of the AEL* over the EL, BEL or BEL* is universal and substantial,\nparticularly under the nonnormal models when the sample sizes are small.\n4.3. An example where q > p. In this subsection, we examine the AEL\nthrough an asset-pricing model investigated by Hall and Horowitz (1996)\nand also by Imbens, Spady and Johnson (1998) expanded with q (q \u2265 2)\nmoment restrictions by Schennach (2007). The parameter of interest is de-\n\n\f15\n\nADJUSTED EMPIRICAL LIKELIHOOD\nTable 5\n(Continued)\n\nq=3\n\n(a)\n\nn\n\nLevel\n\nT2\n\nEL\n\nBEL\n\nAEL\n\nBEL*\n\nAEL*\n\nBELt\n\nAELt\n\nAEL0\n\n30\n\n90\n95\n99\n90\n95\n99\n\n85.2\n90.6\n96.2\n85.8\n91.2\n96.6\n\n81.5\n88.1\n94.8\n84.4\n90.7\n96.6\n\n83.8\n89.8\n95.6\n85.8\n91.9\n97.2\n\n84.6\n90.7\n96.4\n86.2\n92.2\n97.5\n\n84.9\n90.6\n96.1\n86.5\n92.2\n97.5\n\n86.5\n91.9\n97.1\n86.9\n92.7\n97.7\n\n85.3\n91.0\n96.2\n86.5\n92.4\n97.5\n\n87.2\n92.5\n97.9\n87.0\n92.8\n97.8\n\n86.0\n91.6\n97.0\n86.9\n92.7\n97.7\n\n90\n95\n99\n90\n95\n99\n\n85.3\n90.8\n96.4\n86.7\n92.0\n97.1\n\n81.4\n87.8\n95.1\n85.7\n91.1\n97.5\n\n83.6\n89.7\n95.9\n87.1\n92.2\n97.8\n\n84.4\n90.3\n96.5\n87.4\n92.5\n97.9\n\n84.8\n90.4\n96.3\n87.6\n92.6\n97.9\n\n86.1\n91.7\n97.1\n88.0\n92.8\n98.0\n\n85.2\n90.8\n96.4\n87.7\n92.8\n98.0\n\n86.7\n92.3\n97.6\n88.1\n93.1\n98.1\n\n86.0\n91.6\n97.2\n88.1\n93.1\n98.2\n\n90\n95\n99\n90\n95\n99\n\n88.0\n93.0\n97.6\n88.7\n93.5\n98.2\n\n84.7\n90.5\n96.5\n87.4\n93.2\n98.3\n\n86.7\n91.9\n97.0\n88.7\n94.1\n98.6\n\n87.0\n92.3\n97.3\n88.8\n94.2\n98.6\n\n87.2\n92.4\n97.2\n89.0\n94.3\n98.6\n\n88.0\n93.1\n98.0\n89.1\n94.4\n98.7\n\n86.9\n92.1\n97.1\n88.8\n94.2\n98.6\n\n87.4\n92.5\n97.3\n88.9\n94.2\n98.6\n\n88.8\n93.7\n98.1\n90.0\n94.9\n98.9\n\n90\n95\n99\n90\n95\n99\n\n88.4\n93.7\n98.1\n88.7\n94.0\n98.4\n\n84.2\n90.5\n96.4\n86.8\n92.9\n97.9\n\n86.1\n91.9\n97.2\n88.2\n93.7\n98.2\n\n86.6\n92.3\n97.4\n88.3\n93.8\n98.3\n\n86.7\n92.3\n97.3\n88.4\n93.8\n98.3\n\n87.3\n93.0\n97.7\n88.5\n93.9\n98.3\n\n86.7\n92.4\n97.3\n88.4\n93.8\n98.3\n\n87.3\n93.0\n97.7\n88.5\n93.9\n98.3\n\n88.4\n93.7\n98.3\n89.4\n94.4\n98.6\n\n50\n\n(b)\n\n30\n\n50\n\n(c)\n\n30\n\n50\n\n(d)\n\n30\n\n50\n\nfined through the following estimating equations:\n\uf8f6\n\uf8eb\nr(X, \u03b8)\n\uf8ec X2 r(X, \u03b8) \uf8f7\n\uf8f7\n\uf8ec\n(X \u2212 1)r(X, \u03b8) \uf8f7 = 0,\n(12)\nEg(X; \u03b8) \u2261 E \uf8ec\n\uf8f7\n\uf8ec 3\n..\n\uf8f8\n\uf8ed\n.\n(Xq \u2212 1)r(X, \u03b8)\n\nwhere r(X, \u03b8) = exp{\u22120.72 \u2212 \u03b8(X1 + X2 ) + 3X2 } \u2212 1, X = (X1 , X2 , . . . , Xq )\nand \u03b8 is a scalar parameter. Components of X are mutually independent\ni.i.d.\ni.i.d.\nand X1 , X2 \u223c N (0, 0.16), X3 , . . . , Xq \u223c \u03c721 . We generated data from the\nmodels with \u03b80 = 3, q = 2 and q = 3, respectively.\nAlthough Theorem 2 is applicable, precisely estimating b is not easy due to\nits complex expression. Instead, Chen and Cui (2007) proposed a bootstrap\nestimate. We adopted their strategy with a robust modification. Let \u2206m\nbe the sample median of \u2206\u2217n (\u03b8\u0302; 0) based on B = 300 bootstrap samples. We\n\n\f16\n\nY. LIU AND J. CHEN\nTable 6\nCoverage probabilities for the regression coefficient \u03b2\n\nN (0, 1)\n\nn\n\nLevel\n\nF -test\n\nEL\n\nBEL\n\nAEL\n\nBEL*\n\nAEL*\n\nBELt\n\nAELt\n\nAEL0\n\n30\n\n90\n95\n99\n90\n95\n99\n90\n95\n99\n\n90.0\n94.9\n99.3\n89.7\n95.0\n99.0\n89.6\n94.8\n99.0\n\n84.0\n90.1\n96.6\n86.9\n92.7\n97.7\n88.3\n93.8\n98.5\n\n85.7\n91.5\n97.3\n88.4\n93.6\n98.1\n89.1\n94.3\n98.6\n\n86.1\n92.0\n97.5\n88.5\n93.7\n98.2\n89.1\n94.4\n98.7\n\n86.6\n92.2\n97.4\n88.7\n93.8\n98.2\n89.2\n94.4\n98.7\n\n87.7\n93.3\n98.2\n88.9\n94.0\n98.2\n89.2\n94.5\n98.7\n\n86.6\n92.3\n97.5\n88.7\n93.8\n98.2\n89.2\n94.4\n98.7\n\n87.5\n93.2\n98.2\n89.0\n94.0\n98.3\n89.3\n94.5\n98.7\n\n87.4\n93.0\n98.1\n89.2\n94.2\n98.4\n89.4\n94.5\n98.8\n\n90\n95\n99\n90\n95\n99\n90\n95\n99\n\n87.9\n92.8\n97.7\n88.7\n93.8\n98.3\n88.9\n94.2\n98.5\n\n79.6\n86.4\n93.7\n83.7\n90.0\n96.3\n86.2\n92.2\n97.8\n\n81.9\n88.2\n94.7\n85.4\n91.3\n96.9\n87.3\n93.0\n98.1\n\n82.4\n88.8\n95.2\n85.6\n91.5\n97.1\n87.3\n93.0\n98.1\n\n83.6\n89.4\n95.3\n86.4\n92.1\n97.3\n87.8\n93.3\n98.2\n\n86.1\n91.6\n97.0\n87.5\n92.8\n97.8\n88.1\n93.6\n98.3\n\n85.7\n91.0\n96.3\n87.4\n92.9\n97.7\n88.4\n93.8\n98.3\n\n92.6\n98.5\n100.0\n89.0\n94.2\n98.9\n88.8\n94.2\n98.5\n\n83.5\n89.6\n95.9\n86.0\n91.8\n97.2\n87.4\n93.1\n98.1\n\n50\n\n100\n\nExp(1)\n\n30\n\n50\n\n100\n\nestimate b by\nb\u0302 = n(\u2206m /0.4549 \u2212 1),\n\nwhere 0.4549 is the median of the \u03c721 distribution. We generated samples of\nsizes n = 100 and 200. The average bootstrap estimates of b\u0302 are 31 and 58\nfor q = 2 and q = 3 over 1000 repetitions. We call them off-line estimates\nof b and carried out the corresponding simulations side-by-side with the\nbootstrap estimator b\u0302 for each sample generated.\nIn Table 7, we report the coverage probabilities of the nominal 90%,\n95% and 99% confidence intervals of the empirical likelihood (EL), the\nBartlett corrected empirical likelihood (BEL), the adjusted empirical likelihood [AEL(5)] and the adjusted empirical likelihood with conventional\nan = log(n)/2 (AEL0 ). Due to the exponential nature of g in \u03b8 in this example, the sample mean \u1e21 is unstable. For robustness, we computed gn+1\nwith the trimmed mean by removing five largest kgi k values.\nIn terms of the precision of the coverage probabilities, the AEL is better\nthan the BEL which is better than the EL and the AEL0 , and the latter\ntwo have similar performances. Even after the robustification, the bootstrap\nestimation of b ranges from \u221227 to 376 when n = 100. This observation\nindicates that neither the BEL nor the AEL is ready to be applied to models\nsimilar to the one in this example. The simulation results have instead shown\n\n\f17\n\nADJUSTED EMPIRICAL LIKELIHOOD\nTable 7\nSimulation results under the expanded asset-pricing model\nLevel\n\nEL\n\nBEL\n\nAEL(5)\n\nBEL\n\nBootstrapped b\nq=2\nn = 100\n\nn = 200\n\nn = 200\n\nAEL0\n\nOff-line b = 31\n\n90\n95\n99\n\n82.6\n88.4\n95.8\n\n86.5\n91.2\n96.7\n\n85.3\n92.6\n97.3\n\n87.4\n92.8\n97.3\n\n89.8\n95.4\n99.5\n\n82.7\n88.8\n95.9\n\n90\n95\n99\n\n83.9\n91.2\n96.9\n\n86.6\n92.6\n97.4\n\n85.1\n91.9\n97.6\n\n87.8\n93.1\n97.8\n\n87.2\n93.3\n98.2\n\n84.3\n91.4\n96.9\n\nBootstrapped b\nq=3\nn = 100\n\nAEL(5)\n\nOff-line b = 58\n\n90\n95\n99\n\n78.4\n85.7\n94.0\n\n84.9\n90.8\n96.1\n\n84.1\n90.4\n97.9\n\n87.4\n93.1\n97.7\n\n90.5\n96.7\n99.8\n\n79.8\n86.1\n94.0\n\n90\n95\n99\n\n82.5\n89.7\n96.1\n\n86.9\n92.7\n97.2\n\n86.5\n92.9\n98.5\n\n87.4\n93.3\n97.6\n\n89.8\n95.3\n99.2\n\n82.5\n89.8\n96.1\n\nthe potential of the AEL approach. We hope to further investigate this\nproblem in the future.\nAPPENDIX\nProof of Theorem 1. We now present the proof for the general case\nwhere g(x; \u03b8) is vector valued.\nIn addition to the notation introduced earlier, we further define\nn\n1X r s\nrs***t\nA\n=\nY Y * * * Y t \u2212 \u03b1rs***t ,\nn\ni\n\n\u03b1rs***t\n\nwhere\nis defined in (10). Without loss of generality, we assume that\n\u03b1rs = I(r = s) at \u03b8 = \u03b80 . By DiCiccio, Hall and Romano (1991), the solution\nto (3), before any adjustment, can be expanded as\n\u03bb = \u03bb1 + \u03bb2 + \u03bb3 + Op (n\u22122 )\nwith\n\u03bbr1 = Ar ,\nand\n\n\u03bbr2 = \u2212Ars As + \u03b1rst As At\n\n\u03bbr3 = Ars Atu Au + Arst As At + 2\u03b1rst \u03b1tuv As Au Av\n\u2212 3\u03b1rst Atu As Au \u2212 \u03b1rstu As At Au .\n\n\f18\n\nY. LIU AND J. CHEN\n\nHere we have used the summation convention according to which, if an\nindex occurs more than once in an expression, summation over the index is\nunderstood. Substituting these expansions into the expression for Rn (\u03b80 ),\nwe get\n(13)\n\nRn (\u03b80 ) = n{R1 + R2 + R3 }T {R1 + R2 + R3 } + Op (n\u22123/2 )\n\nwith\nR1r = Ar ,\n(14)\n\nR2r = 13 \u03b1rst As At \u2212 12 Ars As ,\n\nR3r = 83 Ars Ast At \u2212\n+\n\n5 rst tu s u\n5 stu rs t u\nA AA\n12 \u03b1 A A A \u2212 12 \u03b1\n4 rst tuv s u v\nA A A + 31 Arst As At \u2212 41 \u03b1rstu As At Au .\n9\u03b1 \u03b1\n\nRecall the usual Lagrange multiplier \u03bb solves f (\u03bb) = 0 where\nf (\u03b6) = n\n\n\u22121\n\nn\nX\ni=1\n\ng(xi ; \u03b8)\n.\n1 + \u03b6 T g(xi ; \u03b8)\n\nNow we work on the Lagrange multiplier after an adjustment at level an =\na + Op (n\u22121/2 ). Since \u03bba = Op (n\u22121/2 ), it must solve\na\nf (\u03bba ) \u2212 \u1e21 = Op (n\u22122 ).\nn\nA Taylor expansion of f (\u03bba ) gives\nf (\u03bba ) = f (\u03bb) +\n\n\u2202f (\u03bb)\n(\u03bba \u2212 \u03bb) + O((\u03bba \u2212 \u03bb)2 ).\n\u2202\u03bb\n\nSince f (\u03bb) = 0, it simplifies to\n\nNote that\n\n\u0012\n\u0013\na \u2202f (\u03bb) \u22121\n\u1e21 + Op (n\u22122 ).\n\u03bba \u2212 \u03bb =\nn\n\u2202\u03bb\n\u2202f (\u03bb)\n= \u2212E{g(X; \u03b80 )gT (X; \u03b80 )} + Op (n\u22121/2 )\n\u2202\u03bb\n\nand by assumption E{g(X; \u03b80 )gT (X; \u03b80 )} = I; thus we arrive at\n\u03bba = \u03bb \u2212 n\u22121 a\u1e21 + Op (n\u22122 ) = (1 \u2212 n\u22121 a)\u03bb + Op (n\u22122 ).\nThat is, the two Lagrange multipliers are nearly equal.\nNext, we quantify the effect of slightly different Lagrange multipliers on\nthe expansion of Rn (\u03b80 ; an ). We have\nRn (\u03b80 ; an ) = 2\n\nn\nX\ni=1\n\nlog{1 + (1 \u2212 n\u22121 a)\u03bbT gi }\n\n+ 2 log{1 \u2212 (1 \u2212 n\u22121 a)a\u03bbT \u1e21} + O(n\u22123/2 ).\n\n\fADJUSTED EMPIRICAL LIKELIHOOD\n\n19\n\nNote that\nlog{1 \u2212 (1 \u2212 n\u22121 a)a\u03bbT \u1e21} = \u2212a\u03bbT \u1e21 + Op (n\u22122 )\nand, surprisingly,\n2\n\nn\nX\ni=1\n\nlog{1 + (1 \u2212 n\u22121 a)\u03bbT gi } = Rn (\u03b80 ) + Op (n\u22123/2 ).\n\nTherefore, we must have\nR(\u03b80 ; an ) = Rn (\u03b80 ) \u2212 2aR1T R1 + Op (n\u22123/2 )\n\n(15)\n\nwhere R1 is defined in (14), and, consequently,\nRn (\u03b80 ; an ) = n{R1 + R2 + R3a }T {R1 + R2 + R3a } + Op (n\u22123/2 )\nwith\nR3a = R3 \u2212 n\u22121 aR1 .\n\n(16)\nDenote\nQn =\n\n\u221a\nn(R1 + R2 + R3a ),\n\nUn = (A1 , . . . , Aq , A11 , A12 , . . . , Aqq , A111 , A112 , . . . , Aqqq )T\nsuch that the super-indices in Arst satisfy 1 \u2264 r \u2264 s \u2264 t \u2264 q. Hence, Un has\nq(q + 1)(q + 2)/6 components, and each component is a centralized sample\nmean. Furthermore, Qn is a smooth vector-valued function of Un . According\nto Bhattacharya and Ghosh (1978), the Edgeworth expansion of a smooth\nfunction of the sample mean (vector valued) is given by its formal Edgeworth\nexpansion based on its cumulants. Depending on the required order of the\nexpansion, the appropriate lower-order cumulants must exist.\nIn this theorem, we look for an expansion of the density function of Qn\nup to order o(n\u22122 ). This expansion is determined by the first six cumulants\nof Un and the derivative of Qn with respect to Un . Note that we assumed\nthat the 18th moment of g(x; \u03b8) exists and the highest order in Un is three,\nhence all cumulants of Un up to order 6 exist. The cumulants of Qn can\nthen be obtained through those of Un .\nLet \u03bar,s,...,t (Qn ) denote the joint cumulant of the rth, sth, . . . , tth components of Qn . After some lengthy but routine algebraic work, we get\n\u03bar (Qn ) = \u2212n\u22121/2 \u03bcr + n\u22123/2 cr1 + o(n\u22122 ),\n\n\u22122\n\u03bar,s (Qn ) = I(r = s) + n\u22121 \u03b3 rs + n\u22122 crs\n2 + o(n ),\n\u22122\n\u03bar,s,t(Qn ) = n\u22123/2 crst\n3 + o(n ),\n\n\u03bar,s,t,u (Qn ) = n\u22122 crstu\n+ o(n\u22122 ),\n4\n\n\f20\n\nY. LIU AND J. CHEN\n\nwhere\n\u03bcr = 16 \u03b1rss ,\n\u03b3 rs = 21 \u03b1rstt \u2212 31 \u03b1rtu \u03b1stu \u2212\n\n1 rst tuu\n36 \u03b1 \u03b1\n\n\u2212 2aI(r = s)\n\nrst\nrstu are some nonrandom constants. Cumulants of orders\nand cr1 , crs\n2 , c3 , c4\nfive and six are o(n\u22122 ).\nLet fQn (z) and \u03c6(z) be the density functions of Qn and the q-variate standard normal distribution. The key consequence of the above computation is\nthe resultant formal Edgeworth expansion,\n)\n(\n4\nX\nn\u2212i/2 \u03c0i (z) + o(n\u22122 ) \u03c6(z)\nfQn (z) = 1 +\ni=1\n\nwith\n\n\u03c01 (z) = \u03bcr zr ,\n\u03c02 (z) = 12 (\u03b3 rs + \u03bcr \u03bcs ){zr zs \u2212 I(r = s)}\nand for some polynomials \u03c03 (z) and \u03c04 (z) which are of order no more than\nfour, the former is odd and the latter is even. Their specific forms are not\nneeded further and so are omitted.\nThe above expansion implies that\n)\n(\nZ\n4\nX\nn\u2212i/2 \u03c0i (z) \u03c6(z) dz + o(n\u22122 ).\n1+\npr{QTn Qn \u2264 x} =\nzT z<x\n\ni=1\n\nBecause \u03c01 (z) and \u03c03 (z) are odd functions, their integrations over the symmetric region are zero. For the same reason, the integrations of the zr zs\nterms in \u03c02 (z) when r 6= s over a symmetric region are also zero. We further\nnote that the expression of \u03b3 rs involves a, and it is simple to get\nZ\nZ\n1\n\u03c02 (z)\u03c6(z) dz = (b \u2212 2a)\n(zT z \u2212 q)\u03c6(z) dz,\n2\nzT z<x\nzT z<x\nwhere\n\n\u0012\n\u0013\n1 1 rrss 1 rst rst\nb=\n\u03b1\n\u2212 \u03b1 \u03b1\n.\nq 2\n3\nThis b is the Bartlett correction factor given in DiCiccio, Hall and Romano\n(1991). Its expression is simpler than the earlier one because we assumed\n\u03b1rs = I(r = s). Hence, when a = b/2, we have\nZ\n\u03c6(z) dz + O(n\u22122 ) = pr(\u03c72q \u2264 x) + O(n\u22122 ).\npr{QTn Qn \u2264 x} =\nzT z<x\n\nThis completes the proof. \u0003\n\n\f21\n\nADJUSTED EMPIRICAL LIKELIHOOD\n\nThe conclusion for Rn (\u03b80 ; a1n , a2n ) is obtained similarly.\nProof of Theorem 2. Expanding \u2206n (\u03b80 ; an ) and then computing its\ncumulants are by far the most demanding parts of the proof of Theorem\n2. The tasks are formidable. Fortunately, we find a short-cut by relating\n\u2206n (\u03b80 ; an ) to \u2206n (\u03b80 ; 0). By Chen and Cui (2007),\n\u2206n (\u03b80 ; 0) = Rn (\u03b80 ; 0) \u2212 inf Rn (\u03b8; 0)\n\u03b8\n\n= n{R1 + R2 + R3 }T {R1 + R2 + R3 } + Op (n\u22123/2 )\nfor some R1 , R2 and R3 ; some of which are different from those in DiCiccio,\nHall and Romano (1991). They have the same fundamental properties that\nenable P\nthe Bartlett correction. In addition, R1 equals the first p components\nn\n\u22121\nof n\ni=1 g(Xi ; \u03b80 ) after g is standardized in some way.\nWith some relatively routine algebra, we find\n)2\n(\nq\nn\nX\nX\nr\n\u22121\ng (Xi ; \u03b80 ) + Op (n\u22123/2 )\nn\nRn (\u03b80 ; an ) = Rn (\u03b80 ; 0) \u2212 2a\nr=1\n\ni=1\n\nand\ninf Rn (\u03b8; an ) = inf Rn (\u03b8; 0) \u2212 2a\n\u03b8\n\n\u03b8\n\nq\nX\n\n(\n\nn\u22121\n\nr=p+1\n\nn\nX\n\n)2\n\ng r (Xi ; \u03b80 )\n\ni=1\n\n+ Op (n\u22123/2 ).\n\nHence,\n\u2206n (\u03b80 ; an ) = \u2206n (0) \u2212 2a\n\np\nX\nr=1\n\n(\n\nn\u22121\n\nn\nX\n\ng r (Xi ; \u03b80 )\n\ni=1\n\nT\n\n)2\n\n= n{R1 + R2 + R3a } {R1 + R2 + R3a } + Op (n\u22123/2 ),\nwhere\nR3a = R3 \u2212\n\na\nR1 .\nn\n\nThis proves the first part of Theorem 2.\nAgain, according to Chen and Cui (2007), R1 + R2 + R3 have cumulants\nsuch that (1 \u2212 b/n)\u2206n (\u03b80 ; 0) is approximated by \u03c72p to n\u22122 precision. Taking advantage of their proof and using a similar derivation to the proof of\nTheorem 1, we find \u2206n (\u03b80 ; an ) with an = b/2 + Op (n\u22121/2 ) is approximated\nby \u03c72p to n\u22122 precision. This completes the proof. \u0003\n\n\f22\n\nY. LIU AND J. CHEN\n\nREFERENCES\nBhattacharya, R. N. and Ghosh, J. K. (1978). On the validity of the Edgeworth\nexpansion. Ann. Statist. 6 431\u2013451. MR0471142\nBrown, B. W. and Newey, W. K. (2002). Generalized method of moments, efficient bootstrapping, and improved inference. J. Bus. Econom. Statist. 20 507\u2013517.\nMR1945606\nBurnside, C. and Eichenbaum, M. (1996). Small-sample properties of GMM-based Wald\ntests. J. Bus. Econom. Statist. 14 294\u2013308.\nChen, J., Variyath, A. M. and Abraham, B. (2008). Adjusted empirical likelihood and\nits properties. J. Comput. Graph. Statist. 17 426\u2013443. MR2439967\nChen, S. X. (1993). On the accuracy of empirical likelihood confidence regions for linear\nregression model. Ann. Inst. Statist. Math. 45 621\u2013637. MR1252944\nChen, S. X. and Cui, H. J. (2006). On Bartlett correction of empirical likelihood in the\npresence of nuisance parameters. Biometrika 93 215\u2013220. MR2277752\nChen, S. X. and Cui, H. J. (2007). On the second-order properties of empirical likelihood\nwith moment restrictions. J. Econometrics 141 492\u2013516. MR2413478\nCorcoran, S. A. (1998). Bartlett adjustment of empirical discrepancy statistics.\nBiometrika 85 967\u2013972.\nCorcoran, S. A., Davison, A. C. and Spady, R. H. (1995). Reliable inference from\nempirical likelihood. Economics Working Paper 10, Nuffield College, Univ. Oxford.\nDiCiccio, T. J., Hall, P. and Romano, J. P. (1991). Empirical likelihood is Bartlettcorrectable. Ann. Statist. 19 1053\u20131061. MR1105861\nEmerson, S. and Owen, A. (2009). Calibration of the empirical likelihood method for a\nvector mean. Electron. J. Statist. 3 1161\u20131192.\nHall, P. and La Scala, B. (1990). Methodology and algorithms of empirical likelihood.\nInternat. Statist. Rev. 58 109\u2013127.\nHall, P. and Horowitz, J. L. (1996). Bootstrap critical values for tests based on\ngeneralized-method-of-moments estimators. Econometrica 64 891\u2013916. MR1399222\nHansen, L. P. (1982). Large sample properties of generalized method of moments estimators. Econometrica 50 1029\u20131054. MR0666123\nImbens, G. W. (1997). One-step estimators for over-identified generalized method of\nmoments models. Rev. Econom. Stud. 64 359\u2013383. MR1456135\nImbens, G. W., Spady, R. H. and Johnson, P. (1998). Informative theoretic approaches\nto inference in moment condition models. Econometrica 66 333\u2013357. MR1612246\nKitamura, Y. and Stutzer, M. (1997). An information-theoretic alternative to generalized method of moments estimation. Econometrica 65 861\u2013874. MR1458431\nLiang, K.-Y. and Zeger, S. L. (1986). Longitudinal data analysis using generalized\nlinear models. Biometrika 73 13\u201322. MR0836430\nNewey, W. K. and McFadden, D. (1994). Large sample estimation and hypothesis testing. In Handbook of Econometrics 4 2111\u20132245. North-Holland, Amsterdam.\nMR1315971\nNewey, W. K. and Smith, R. J. (2004). Higher order properties of GMM and generalized\nempirical likelihood estimators. Econometrica 72 219\u2013255. MR2031017\nOwen, A. B. (1988). Empirical likelihood ratio confidence intervals for a single functional.\nBiometrika 75 237\u2013249. MR0946049\nOwen, A. B. (2001). Empirical Likelihood. Chapman and Hall/CRC Press, New York.\nQin, J. and Lawless, J. (1994). Empirical likelihood and general equations. Ann. Statist.\n22 300\u2013325. MR1272085\nSchennach, S. M. (2007). Point estimation with exponentially tilted empirical likelihood.\nAnn. Statist. 35 634\u2013672. MR2336862\n\n\fADJUSTED EMPIRICAL LIKELIHOOD\n\n23\n\nSmith, R. J. (1997). Alternative semi-parametric likelihood approaches to generalized\nmethod of moments estimation. Economic Journal 107 503\u2013519.\nTsao, M. (2004). Bounds on coverage probabilities of the empirical likelihood ratio confidence regions. Ann. Statist. 32 1215\u20131221. MR2065203\nDepartment of Statistics\nEast China Normal University\nShanghai 200241\nChina\nE-mail: liuyk1982@yahoo.cn\n\nDepartment of Statistics\nUniversity of British Columbia\nVancouver, BC, V6T 1Z2\nCanada\nE-mail: jhchen@stat.ubc.ca\n\n\f"}