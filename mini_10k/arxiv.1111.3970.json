{"id": "http://arxiv.org/abs/1111.3970v1", "guidislink": true, "updated": "2011-11-16T21:28:10Z", "updated_parsed": [2011, 11, 16, 21, 28, 10, 2, 320, 0], "published": "2011-11-16T21:28:10Z", "published_parsed": [2011, 11, 16, 21, 28, 10, 2, 320, 0], "title": "A Tool for Model-Based Language Specification", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1111.1096%2C1111.6059%2C1111.5166%2C1111.4967%2C1111.6658%2C1111.2007%2C1111.4128%2C1111.5585%2C1111.3800%2C1111.4387%2C1111.3038%2C1111.0903%2C1111.5644%2C1111.6884%2C1111.2721%2C1111.2398%2C1111.2983%2C1111.6383%2C1111.4456%2C1111.1656%2C1111.2794%2C1111.6746%2C1111.0476%2C1111.3797%2C1111.4412%2C1111.1770%2C1111.2355%2C1111.2929%2C1111.6132%2C1111.5634%2C1111.0884%2C1111.0119%2C1111.7114%2C1111.4515%2C1111.6212%2C1111.0407%2C1111.0527%2C1111.0709%2C1111.1424%2C1111.4301%2C1111.7058%2C1111.4494%2C1111.1970%2C1111.5444%2C1111.0392%2C1111.4914%2C1111.4982%2C1111.1194%2C1111.3624%2C1111.5801%2C1111.0762%2C1111.0506%2C1111.0094%2C1111.2172%2C1111.5111%2C1111.6221%2C1111.0108%2C1111.6597%2C1111.3970%2C1111.0004%2C1111.5942%2C1111.1927%2C1111.5886%2C1111.1803%2C1111.3604%2C1111.1142%2C1111.2731%2C1111.5443%2C1111.5362%2C1111.3264%2C1111.1604%2C1111.2188%2C1111.6326%2C1111.1020%2C1111.6921%2C1111.4830%2C1111.6820%2C1111.3705%2C1111.5907%2C1111.3562%2C1111.5926%2C1111.7142%2C1111.7157%2C1111.3964%2C1111.4151%2C1111.6530%2C1111.1464%2C1111.4734%2C1111.4214%2C1111.3657%2C1111.2854%2C1111.5872%2C1111.4767%2C1111.4123%2C1111.2835%2C1111.2245%2C1111.1710%2C1111.3995%2C1111.2023%2C1111.0853%2C1111.1327&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A Tool for Model-Based Language Specification"}, "summary": "Formal languages let us define the textual representation of data with\nprecision. Formal grammars, typically in the form of BNF-like productions,\ndescribe the language syntax, which is then annotated for syntax-directed\ntranslation and completed with semantic actions. When, apart from the textual\nrepresentation of data, an explicit representation of the corresponding data\nstructure is required, the language designer has to devise the mapping between\nthe suitable data model and its proper language specification, and then develop\nthe conversion procedure from the parse tree to the data model instance.\nUnfortunately, whenever the format of the textual representation has to be\nmodified, changes have to propagated throughout the entire language processor\ntool chain. These updates are time-consuming, tedious, and error-prone.\nBesides, in case different applications use the same language, several copies\nof the same language specification have to be maintained. In this paper, we\nintroduce a model-based parser generator that decouples language specification\nfrom language processing, hence avoiding many of the problems caused by\ngrammar-driven parsers and parser generators.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1111.1096%2C1111.6059%2C1111.5166%2C1111.4967%2C1111.6658%2C1111.2007%2C1111.4128%2C1111.5585%2C1111.3800%2C1111.4387%2C1111.3038%2C1111.0903%2C1111.5644%2C1111.6884%2C1111.2721%2C1111.2398%2C1111.2983%2C1111.6383%2C1111.4456%2C1111.1656%2C1111.2794%2C1111.6746%2C1111.0476%2C1111.3797%2C1111.4412%2C1111.1770%2C1111.2355%2C1111.2929%2C1111.6132%2C1111.5634%2C1111.0884%2C1111.0119%2C1111.7114%2C1111.4515%2C1111.6212%2C1111.0407%2C1111.0527%2C1111.0709%2C1111.1424%2C1111.4301%2C1111.7058%2C1111.4494%2C1111.1970%2C1111.5444%2C1111.0392%2C1111.4914%2C1111.4982%2C1111.1194%2C1111.3624%2C1111.5801%2C1111.0762%2C1111.0506%2C1111.0094%2C1111.2172%2C1111.5111%2C1111.6221%2C1111.0108%2C1111.6597%2C1111.3970%2C1111.0004%2C1111.5942%2C1111.1927%2C1111.5886%2C1111.1803%2C1111.3604%2C1111.1142%2C1111.2731%2C1111.5443%2C1111.5362%2C1111.3264%2C1111.1604%2C1111.2188%2C1111.6326%2C1111.1020%2C1111.6921%2C1111.4830%2C1111.6820%2C1111.3705%2C1111.5907%2C1111.3562%2C1111.5926%2C1111.7142%2C1111.7157%2C1111.3964%2C1111.4151%2C1111.6530%2C1111.1464%2C1111.4734%2C1111.4214%2C1111.3657%2C1111.2854%2C1111.5872%2C1111.4767%2C1111.4123%2C1111.2835%2C1111.2245%2C1111.1710%2C1111.3995%2C1111.2023%2C1111.0853%2C1111.1327&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Formal languages let us define the textual representation of data with\nprecision. Formal grammars, typically in the form of BNF-like productions,\ndescribe the language syntax, which is then annotated for syntax-directed\ntranslation and completed with semantic actions. When, apart from the textual\nrepresentation of data, an explicit representation of the corresponding data\nstructure is required, the language designer has to devise the mapping between\nthe suitable data model and its proper language specification, and then develop\nthe conversion procedure from the parse tree to the data model instance.\nUnfortunately, whenever the format of the textual representation has to be\nmodified, changes have to propagated throughout the entire language processor\ntool chain. These updates are time-consuming, tedious, and error-prone.\nBesides, in case different applications use the same language, several copies\nof the same language specification have to be maintained. In this paper, we\nintroduce a model-based parser generator that decouples language specification\nfrom language processing, hence avoiding many of the problems caused by\ngrammar-driven parsers and parser generators."}, "authors": ["Luis Quesada", "Fernando Berzal", "Juan-Carlos Cubero"], "author_detail": {"name": "Juan-Carlos Cubero"}, "author": "Juan-Carlos Cubero", "links": [{"href": "http://arxiv.org/abs/1111.3970v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1111.3970v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.SE", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.SE", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.FL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1111.3970v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1111.3970v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "A Tool for Model-Based Language Specification\n\narXiv:1111.3970v1 [cs.SE] 16 Nov 2011\n\nLuis Quesada, Fernando Berzal, and Juan-Carlos Cubero\nDepartment of Computer Science and Artificial Intelligence, CITIC, University of Granada,\nGranada 18071, Spain\nlquesada@decsai.ugr.es, fberzal@decsai.ugr.es, jc.cubero@decsai.ugr.es\nFormal languages let us define the textual representation of data with precision. Formal grammars, typically in the form of BNF-like productions, describe the language syntax, which is then\nannotated for syntax-directed translation and completed with semantic actions. When, apart from\nthe textual representation of data, an explicit representation of the corresponding data structure\nis required, the language designer has to devise the mapping between the suitable data model\nand its proper language specification, and then develop the conversion procedure from the parse\ntree to the data model instance. Unfortunately, whenever the format of the textual representation has to be modified, changes have to propagated throughout the entire language processor\ntool chain. These updates are time-consuming, tedious, and error-prone. Besides, in case different applications use the same language, several copies of the same language specification have\nto be maintained. In this paper, we introduce a model-based parser generator that decouples\nlanguage specification from language processing, hence avoiding many of the problems caused by\ngrammar-driven parsers and parser generators.\n\nI. INTRODUCTION\n\nA formal language represents a set of strings [29]. Formal languages consist of an alphabet, which describes\nthe basic symbol or character set of the language, and a\ngrammar, which describes how to write valid sentences\nof the language. In Computer Science, formal languages\nare used, among other things, for the precise definition of\ndata formats and the syntax of programming languages.\nThe front-end of a language processor, such as an interpreter or compiler, determines the grammatical structure\ncorresponding to the textual representation of data conforming to a given language specification. Such grammatical structure is typically represented in the form of\na parse tree.\nMost existing language specification techniques [4] require the language designer to provide a textual specification of the language grammar. The proper specification\nof such a grammar is a nontrivial process that depends\non the lexical and syntactic analysis techniques to be\nused, since each kind of technique requires the grammar\nto comply with different constraints. Each analysis technique is characterized by its expression power and this\nexpression power determines whether a given analysis\ntechnique is suitable for a particular language. The most\nsignificant constraints on formal language specification\noriginate from the need to consider context-sensitivity,\nthe need of performing an efficient analysis, and some\ntechniques' inability to resolve conflicts caused by grammar ambiguities.\nIn its most general sense, a model is anything used\nin any way to represent something else. In such sense,\na grammar is a model of the language it defines. In\nSoftware Engineering, data models are also common.\nData models explicitly determine the structure of data.\nRoughly speaking, they describe the elements they represent and the relationships existing among them. From a\nformal point of view, it should be noted that data mod-\n\nels and grammar-based language specifications are not\nequivalent, even though both of them can be used to\nrepresent data structures. A data model can express relationships a grammar-based language specification cannot. Moreover, a data model does not need to comply\nwith the constraints a grammar-based language specification has to comply with. Hence describing a data\nmodel is generally easier than describing the corresponding grammar-based language specification.\nWhen both a data model and a grammar-based language processor are required, the implementation of the\nlanguage processor requires the language designer to\nbuild a grammar-based language specification from the\ndata model and also to implement the conversion from\nthe parse tree to the data model instance.\nWhenever the language specification has to be modified, the language designer has to manually propagate\nchanges throughout the entire language processor tool\nchain, from the specification of the grammar defining\nthe formal language (and its adaptation to specific parsing tools) to the corresponding data model. These updates are time-consuming, tedious, and error-prone. By\nmaking such changes labor-intensive, the traditional approach hampers the maintainability and evolution of the\nlanguage [31].\nMoreover, it is not uncommon that different applications use the same language. For example, the compiler, different code generators, and other tools within\nan IDE, such as the editor or the debugger, typically\nneed to grapple with the full syntax of a programming\nlanguage. Their maintenance typically requires keeping\nseveral copies of the same language specification in sync.\nAs an alternative approach, a language can also be\ndefined by a data model that, in conjunction with the\ndeclarative specification of some constraints, can be automatically converted into a grammar-based language specification [52].\nThis way, the data model representing the language\n\n\f2\ncan be modified as needed without having to worry about\nthe language processor and the peculiarities of the chosen parsing technique, since the corresponding language\nprocessor with be automatically updated.\nFurthermore, as the data model is the direct representation of a data structure, such data structure can be\nimplemented as an abstract data type (in object-oriented\nlanguages, as a set of collaborating classes). Following\nthe proper software design principles, that implementation can be performed without having to embed or mix\nsemantic actions with the language specification, as it is\ntypically the case with grammar-driven language processors.\nFinally, as the data model is not bound to a particular\nparsing technique, evaluating alternative and/or complementary parsing techniques is possible without having\nto propagate their constraints into the language model.\nTherefore, by using an annotated data model, modelbased language specification completely decouples language specification from language processing, which can\nbe performed using whichever parsing techniques that are\nsuitable for the formal language implicitly defined by the\nmodel.\nIn this paper, we introduce ModelCC, a model-based\ntool for language specification. As a parser generator that decouples language specification from language\nprocessing, it avoids many of the problems caused by\ngrammar-driven parsers and parser generators.\nSection II introduces formal grammars and surveys\nparsing algorithms and tools. Section III presents the\nphilosophy behind model-based language specification.\nSection IV comments on ModelCC building blocks. Section V describes the model constraints supported by\nModelCC, which declaratively define the features of the\nformal language defined by the model. Section VI shows\na prototypical example, which is used to discuss the advantages of model-based language specification over traditional grammar-based language specification. Lastly,\nSection VII presents our conclusions and the future work\nthat derives from our research.\n\nII. BACKGROUND\n\nIn this section, we introduce formal grammars (Subsection A), describe the typical architecture of language\nprocessor front-ends (Subsection B), survey key parsing\nalgorithms (Subsection C), and review existing lexer and\nparser generators (Subsection D).\n\ning to the language syntax. A grammar G is formally\ndefined [6] as the tuple (N, \u03a3, P, S), where:\n\u2022 N is the finite set of nonterminal symbols of the language, sometimes called syntactic variables, none of\nwhich appear in the language strings.\n\u2022 \u03a3 is the finite set of terminal symbols of the language, also called tokens, which constitute the language alphabet (i.e. they appear in the language\nstrings). Therefore, \u03a3 is disjoint from N .\n\u2022 P is a finite set of productions, each one of the form\n(\u03a3 \u222a N )\u2217 N (\u03a3 \u222a N )\u2217 \u2192 (\u03a3 \u222a N )\u2217 , where \u2217 is the\nKleene star operator, \u222a denotes set union, the part\nbefore the arrow is called the left-hand side of the\nproduction, and the part after the arrow is called\nthe right-hand side of the production.\n\u2022 S is a distinguished nonterminal symbol, S \u2208 N :\nthe grammar start symbol.\nFor convenience, when several productions share their\nleft-hand side, they can be grouped into a single production containing their the shared left-hand side and all\ntheir different right-hand sides separated by |.\nContext-free grammars are formal grammars in which\nthe left-hand side of each production consists of only a\nsingle nonterminal symbol. All their productions, therefore, are of the form N \u2192 (\u03a3 \u222a N )\u2217 . Context-free grammars generate context-free languages.\nA context-free grammar is said to be ambiguous if\nthere exists at least a string that can be generated by the\ngrammar in more than one way. In fact, some contextfree languages are inherently ambiguous (i.e. all contextfree grammars generating them are ambiguous).\nAn attribute grammar is a formal way to define attributes for the symbols in the productions of a formal\ngrammar, associating values to these attributes. Semantic rules annotate attribute grammar and define the value\nof an attribute in terms of the values of other attributes\nand constants [3]. They key feature of attribute grammars is that they let us transfer information from anywhere in the abstract syntax tree to anywhere else in a\ncontrolled and formal way, hence their frequent use in\nsyntax-directed translation.\nGraph grammars [13] allow the manipulation of graphs\nbased on productions: if the left-hand side of a production matches the working graph or a subgraph of it, it\ncan be replaced with the right-hand side of the production. These grammars can be used to define the syntax\nof visual languages.\n\nA. Formal Grammars\nB. The Architecture of Language Processors\n\nFormal grammars are used to specify the syntax of a\nlanguage [22, 24]. A grammar naturally describes the\nhierarchical structure of most language constructs [3].\nUsing a set of rules, a grammar describes how to form\nstrings from the language alphabet that are valid accord-\n\nThe architecture of a language-processing system decomposes language processing into several steps which\nare typically grouped into two phases: analysis and synthesis. The analysis phase, which is responsibility of the\n\n\f3\nlanguage processor front end, starts by breaking up its\ninput into its constituent pieces (lexical analysis or scanning) and imposing a grammatical structure upon them\n(syntax analysis or parsing). The language processor\nback end will later synthesize the desired target from the\nresults provided by the front end.\nA lexical analyzer, also called lexer or scanner, processes an input string conforming to a language specification and produces the tokens found within it. Lexical\nambiguities occur when a given input string simultaneously corresponds to several token sequences [43], which\nmay overlap.\nA syntactic analyzer, also called parser, processes input tokens and determines their grammatical structure\nwith respect to the given language grammar, usually in\nthe form of parse trees. In the absence of lexical ambiguities, the parser input consists of a stream of tokens,\nwhereas it will be a directed acyclic graph of tokens when\nlexical ambiguities are present. Syntactic ambiguities\noccur when a given set of tokens simultaneously corresponds to several parse trees [2].\nC. Scanning and Parsing Algorithms\n\nScanning and parsing algorithms are characterized by\nthe expression power of the languages they can apply\nto, their support for ambiguities or lack thereof, and the\nconstraints they impose on language specifications.\nTraditional lexers are based on a finite-state machine\nthat is built from a set of regular expressions [39], each\nof which describes a token type. The efficiency of regular\nexpression lexers is O(n), being n the input string length.\nLamb [51] is a lexer with lexical ambiguity support\nthat allows the specification of tokens not only by regular expressions, but also by arbitrary pattern matching\nclasses. Lamb also supports token type precedences. The\nefficiency of the Lamb lexer is, in the worst case, O(n2 t2 ),\nbeing n the input string length and t the number of different token types.\nEfficient parsers for specific subsets of context-free\ngrammars exist. These include top-down LL parsers,\nwhich construct a leftmost derivation of the input sentence, and bottom-up LR parsers, which construct a\nrightmost derivation of the input sentence.\nLL grammars were formally introduced in [37], albeit\nLL(k) parsers predate their name [46]. An LL parser is\ncalled an LL(k) parser if it uses k tokens of lookahead\nwhen parsing a sentence, while it is an LL(*) parser if it\nis not restricted to a finite k tokens of lookahead and it\ncan make parsing decisions by recognizing whether the\nfollowing tokens belong to a regular language [27, 44].\nWhile LL(k) parsers are always linear, LL(*) ranges from\nO(n) to O(n2 ).\nLR parsers were introduced by Knuth [33]. DeRemer\nlater developed the LALR [8, 10] and SLR [9] parsers\nthat are in use today. When parsing theory was originally\ndeveloped, machine resources were scarce, and so parser\nefficiency was the paramount concern [47]. Hence all the\n\naforementioned parsing algorithms parse in linear time\n(i.e. their efficiency is O(n), being n the input string\nlength) and they do not support syntactic ambiguities.\nEfficient LR and LL parsers for certain classes of ambiguous grammars are also possible by using simple disambiguating rules [2, 12].\nA general-purpose dynamic programming algorithm\nfor parsing context-free grammars was independently developed by Cocke [7], Younger [57], and Kasami [30]: the\nCYK parser. This general-purpose algorithm is O(n3 )\nfor ambiguous and unambiguous context-free grammars.\nThe Earley parser [11] is another general-purpose dynamic programming algorithm for parsing context-free\ngrammars that executes in cubic time (O(n3 )) in the\ngeneral case, quadratic time (O(n2 )) for unambiguous\ngrammars, and linear time (O(n)) for almost all LR(k)\ngrammars.\nFree from the requirement to develop efficient lineartime parsing algorithms, researchers have developed\nmany powerful nondeterministic parsing strategies following both the top-down approach (LL parsers) and the\nbottom-up approach (LR parsers).\nFollowing the top-down approach, Packrat parsers\n[15] and their associated Parsing Expression Grammars\n(PEGs) [16] preclude only the use of left-recursive grammar rules and force the rules to be ordered, that is, when\nan alternative succeeds, the following alternatives are\nignored. Even though they use backtracking, packrat\nparsers are linear rather than exponential because of the\nrule order and because they memoize partial results.\nFollowing the bottom-up approach, Generalized LR\n(GLR) parsers parse in linear to cubic time, depending on\nhow closely the grammar conforms to the underlying LR\nstrategy. The time required to run the algorithm is proportional to the degree of nondeterminism in the grammar. Bernard Lang is typically credited with the original\nGLR idea [34]. Later, Tomita used the algorithm for natural language processing [55]. Tomita's Universal parser\n[56], however, failed for grammars with epsilon rules (i.e.\nproductions with an empty right-hand side). Several extensions have been proposed that support epsilon rules\n[26, 40, 45, 53].\nGLR parsing is an optimization of Earley's algorithm\nand, like parsing expression grammars, tends to be scannerless. Being scannerless is necessary if a tool needs\nto support grammar composition (i.e. to easily integrate one language into another or create new grammars\nby modifying and composing pieces from existing grammars), unless lexical ambiguities are supported. The\nFence parser [50] is an optimized Earley-like algorithm\nthat works on top of the Lamb lexer [51], which provides\nsupport for lexical ambiguities. Hence, Fence is also suitable for grammar composition and as efficient as GLR\nparsers in practice.\nD. Lexer and Parser Generators\n\nLexer and parser generators are tools that take a language specification as input and produce a lexer or parser\n\n\f4\nas output. They can be characterized by their input syntax, their ability to specify semantic actions, and the\nparsing algorithms the resulting parsers implement.\nLex [35] and yacc [28] are commonly used in conjunction [36]. They are the default lexer generator and parser\ngenerator in many Unix environments and standard compiler textbooks use them as examples, e.g. [3]. Lex is\nthe prototypical regular-expression-based lexer generator, while yacc and its derivatives generate LALR parsers.\nJavaCC [38] is a parser generator that creates LL(k)\nparsers, albeit it has been superseded by ANTLR [48].\nANTLR is a scannerless parser generator that creates\nLL(*) parsers. ANTLR-generated parsers are linear in\npractice and greatly reduce speculation, reducing the\nmemoization overhead of pure packrat parsers.\nThe Rats! [23] packrat parser generator is a PEGbased tool that also optimizes memoization to improve its\nspeed and reduce its memory footprint. Like ANTLR, it\ndoes not accept left-recursive grammars. Unlike ANTLR,\nprogrammers do not have to deal with conflict messages,\nsince PEGs have no concept of a grammar conflict: they\nalways choose the first possible interpretation, which can\nlead to unexpected behavior.\nNLyacc [26] and Elkhound [40] are examples of GLR\nparser generators. Elkhound achieves yacc-like parsing\nspeeds when grammars are LALR(1) but suffers from the\npractical limitations of GLR parsers. Like PEG parsers,\nGLR parsers do not always do what is intended, in part\nbecause they accept ambiguous grammars and programmers have to detect ambiguities dynamically [47].\nYAJco [49] is an interesting tool that accepts, as input, a set of Java classes with annotations that specify\nthe prefixes, suffixes, operators, tokens, parentheses, and\noptional elements common in typical programming languages. As output, YAJco generates a BNF-like grammar specification for JavaCC [38]. Since YAJco is built\non top of a parser generator, the language designer has\nto be careful when annotating his classes, as the implicit grammar he is defining has to comply with the\nconstraints imposed by the underlying LL(k) parser generator.\nTo the best of our knowledge, no existing parser generator follows the approach we now proceed to describe.\n\nIII. MODEL-BASED LANGUAGE SPECIFICATION\n\nIn this section, we discuss the concepts of abstract\nand concrete syntax, analyze the potential advantages\nof model-based language specification, and compare our\nproposed approach with the traditional grammar-driven\nlanguage design process.\n\nA. Abstract Syntax and Concrete Syntaxes\n\nThe abstract syntax of a language is just a representation of the structure of the different elements of a lan-\n\nguage without the superfluous details related to its particular textual representation [32]. On the other hand,\na concrete syntax is a particularization of the abstract\nsyntax that defines, with precision, a specific textual or\ngraphical representation of the language. It should also\nbe noted that a single abstract syntax can be shared by\nseveral concrete syntaxes [32].\nFor example, the abstract syntax of the typical <if><then>-<optional else> statement in imperative programming languages could be described as the concatenation of a conditional expression and one or two statements. Different concrete syntaxes could be defined for\nsuch an abstract syntax, which would correspond to different textual representations of a conditional statement,\ne.g. {\"if\", \"(\", expression, \")\", statement, optional \"else\"\nfollowed by another statement} and {\"IF\", expression,\n\"THEN\", statement, optional \"ELSE\" followed by another statement, \"ENDIF\"}.\nThe idea behind mode-based language specification is\nthat, starting from a single abstract syntax model (ASM)\nrepresenting the core concepts in a language, language\ndesigners would later develop one or several concrete syntax models (CSMs). These concrete syntax models would\nsuit the specific needs of the desired textual or graphical representation. The ASM-CSM mapping could be\nperformed, for instance, by annotating the abstract syntax model with the constraints needed to transform the\nelements in the abstract syntax into their concrete representation.\n\nB. Advantages of Model-Based Language Specification\n\nFocusing on the abstract syntax of a language offers\nsome benefits [32] and provides some potential advantages to model-based language specification over the traditional grammar-based language specification approach:\n\u2022 When reasoning about the features a language\nshould include, specifying its abstract syntax seems\nto be a better starting point than working on its\nconcrete syntax details. In fact, we control complexity by building abstractions that hide details\nwhen appropriate [1].\n\u2022 Sometimes, different incarnations of the same abstract syntax might be better suited for different\npurposes (e.g. an human-friendly syntax for manual coding, a machine-oriented format for automatic code generation, a Fit-like [42] syntax for\ntesting, different architectural views for discussions\nwith project stakeholders...). Therefore, it might\nbe useful for a given language to support multiple\nsyntaxes.\n\u2022 Since model-based language specification is independent from specific lexical and syntactic analysis techniques, the constraints imposed by specific\nparsing algorithms do not affect the language de-\n\n\f5\nContext-Free\nGrammar\ne.g. BNF\n\nAttribute\nGrammar\n\nConceptual\nModel\n\ninstance\nof\ninput\nTextual\nRepresentation\n\nConcrete Syntax Model\n\ninstance\nof\noutput\n\nParser\n\nAbstract\nSyntax\nTree\n\nAbstract Syntax Model\n\nFigure 1 Traditional language processing approach.\n\nsign process. In principle, it might not be even necessary for the language designer to have advanced\nknowledge on parser generators when following a\nmodel-driven language specification approach.\n\u2022 A full-blown model-driven language workbench [18]\nwould allow the modification of a language abstract syntax model and the automatic generation\nof a working IDE on the run. The specification\nof domain-specific languages would become easier,\nas the language designer could play with the language specification and obtain a fully-functioning\nlanguage processor on the fly, without having to\nworry about the propagation of changes throughout the complete language processor tool chain.\nIn short, the model-driven language specification approach brings domain-driven design [14] to the domain of\nlanguage design. It provides the necessary infrastructure\nfor what Evans would call the 'supple design' of language\nprocessing tools: the intention-revealing specification of\nlanguages by means of abstract syntax models, the separation of concerns in the design of language processing\ntools by means of declarative ASM-CSM mappings, and\nthe automation of a significant part of the language processor implementation.\n\nC. Comparison with the Traditional Approach\n\nA diagram summarizing the traditional language design process is shown in Figure 1, whereas the corresponding diagram for the model-based approach proposed in this paper is shown in Figure 2.\nWhen following the traditional grammar-driven approach, the language designer starts by designing the\ngrammar corresponding to the concrete syntax of the\ndesired language, typically in BNF or a similar format. Then, the designer annotates the grammar with\nattributes and, probably, semantic actions, so that the\nresulting attribute grammar can be fed into lexer and\nparser generator tools that produce the corresponding\nlexer and parser, respectively. The resulting syntaxdirected translation process generates abstract syntax\n\nContext-Free\nGrammar\ne.g. BNF\n\nConceptual\nModel\n\ninstance\nof\ninput\nTextual\nRepresentation\n\nConcrete Syntax Model\n\ninstance\nof\noutput\n\nParser\n\nAbstract\nSyntax\nGraph\n\nAbstract Syntax Model\n\nFigure 2 Model-based language processing approach.\n\ntrees from the textual representation in the concrete syntax of the language.\nWhen following the model-driven approach, the language designer starts by designing the conceptual model\nthat represents the abstract syntax of the desired language, focusing on the elements the language will represent and their relationships. Instead of dealing with\nthe syntactic details of the language from the start, the\ndesigner devises a conceptual model for it (i.e. the abstract syntax model, or ASM), the same way a database\ndesigner starts with an implementation-independent conceptual database schema before he converts that schema\ninto a logical schema that can be implemented in the particular kind of DBMS that will host the final database.\nIn the model-driven language design process, the ASM\nwould play the role of entity-relationship diagrams in\ndatabase design and each particular CSM would correspond to the final table layout of the physical database\nschema in a relational DBMS.\nEven though the abstract syntax model of the language\ncould be converted into a suitable concrete syntax model\nautomatically, the language designer will often be interested in specifying the details of the ASM-CSM mapping.\nWith the help of constraints imposed over the abstract\nmodel, the designer will be able to guide the conversion\nfrom the ASM to its concrete representation using a particular CSM. This concrete model, when it corresponds\nto a textual representation of the abstract model, will\nbe described by a formal grammar. It should be noted,\nhowever, that the specification of the ASM is independent\nfrom the peculiarities of the desired CSM, as a database\ndesigner does not consider foreign keys when designing\nthe conceptual schema of a database. Therefore, the\ngrammar specification constraints enforced by particular parsing tools will not impose limits on the design of\nthe ASM. The model-driven language processing tool will\ntake charge of that and, ideally, it will employ the most\nefficient parsing technique that works for the language\nresulting from the ASM-CSM mapping.\nWhile the traditional language designer specifies the\ngrammar for the concrete syntax of the language, annotates it for syntax-directed processing, and obtains an abstract syntax tree that is an instance of the implicit con-\n\n\f6\nceptual model defined by the grammar, the model-based\nlanguage designer starts with an explicit full-fledged conceptual model and specifies the necessary constraints for\nthe ASM-CSM mapping. In both cases, parser generators\ncreate the tools that parse the input text in its concrete\nsyntax. The difference lies in the specification of the\ngrammar that drives the parsing process, which is handcrafted in the traditional approach and automaticallygenerated as a result of the ASM-CSM mapping in the\nmodel-driven process.\nAnother difference stems from the fact that the result\nof the parsing process in an instance of an implicit model\nin the grammar-driven approach while that model is explicit in the model-driven approach. An explicit conceptual model is absent in the traditional language design\nprocess albeit that does not mean that it does not exist.\nOn the other hand, the model-driven approach enforces\nthe existence of an explicit conceptual model, which lets\nthe proposed approach reap the benefits of domain-driven\ndesign.\nThere is a third difference between the grammar-driven\nand the model-driven approaches to language specification. While, in general, the result of the parsing process\nis an abstract syntax tree that corresponds to a valid\nparsing of the input text according to the language concrete syntax, nothing prevents the conceptual model designer from modeling non-tree structures. Hence the use\nof the 'abstract syntax graph' term in Figure 2. This\nmight be useful, for instance, for modeling graphical languages, which are not constrained by the linear nature of\nthe traditional syntax-driven specification of text-based\nlanguages.\nInstead of going from a concrete syntax model to an\nimplicit abstract syntax model, as it is typically done,\nthe model-based language specification process goes from\nthe abstract to the concrete. This alternative approach\nfacilitates the proper design and implementation of language processing systems by decoupling language processing from language specification, which is now performed by imposing declarative constraints on the ASMCSM mapping.\n\nestablishes the desired ASM-CSM mapping.\nIn this section, we introduce the basic constructs that\nallow the specification of abstract syntax models, while\nwe will discuss how model constraints help us establish a\nparticular ASM-CSM mapping in the following section\nof this paper. Basically, the ASM is built on top of\nbasic language elements, which might be viewed as the\ntokens in the model-driven specification of a language.\nModelCC provides the necessary mechanisms to combine\nthose basic elements into more complex language constructs, which correspond to the use of concatenation,\nselection, and repetition in the syntax-driven specification of languages.\nOur final goal is to allow the specification of languages\nin the form of abstract syntax models such as the one\nshown in Figure 29, which will be used as an example\nin Section VI. This model, in UML format, specifies\nthe abstract syntax model of the language supported by\na simple arithmetic calculator. The annotations that accompany the model provide the necessary information for\nestablishing the complete ASM-CSM mapping that corresponds to the traditional infix notation for arithmetic\nexpressions. Moreover, the model also incorporates the\nmethod that lets us evaluate such arithmetic expressions.\nTherefore, Figure 29 represents a complete interpreter for\narithmetic expressions in infix notation using ModelCC\n(its complete implementation as a set of cooperating Java\nclasses appears in Figure 30).\nAs mentioned above, the specification of the ASM in\nModelCC starts with the definition of basic language elements, which can be modeled as simple classes in an\nobject-oriented programming language. The ASM-CSM\nmapping of those basic elements will establish their correspondence to the tokens that appear in the concrete syntax of the language whose ASM we design in ModelCC.\nIn the following subsections, we describe the mechanisms\nprovided by ModelCC to implement the three main constructs that let us specify complete abstract syntax models on top of basic language elements.\n\nA. Concatenation\nIV. MODELCC MODEL SPECIFICATION\n\nOnce we have described model-driven language specification in general terms, we now proceed to introduce\nModelCC, a tool that supports our proposed approach to\nthe design of language processing systems. ModelCC, at\nits core, acts as a parser generator. Its starting abstract\nsyntax model is created by defining classes that represent\nlanguage elements and establishing relationships among\nthose elements (associations in UML terms). Once the\nabstract syntax model is established, its incarnation as\na concrete syntax is guided by the constraints imposed\nover language elements and their relationships as annotations on the abstract syntax model. In other words,\nthe declarative specification of constraints over the ASM\n\nConcatenation is the most basic construct we can use\nto combine sets of language elements into more complex\nlanguage elements. In textual languages, this is achieved\njust by joining the strings representing its constituent\nlanguage elements into a longer string that represents\nthe composite language element.\nIn ModelCC, concatenation is achieved by object composition. The resulting language element is the composite element and its members are the language elements\nthe composite element collates.\nWhen translating the ASM into a textual CSM, each\ncomposite element in a ModelCC model generates a production rule in the grammar representing the CSM. This\nproduction, with the nonterminal symbol of the composite element in its left-hand side, concatenates the nonter-\n\n\f7\nExpression\n\nAssign m en tStatem en t\n- id : Iden tifier\n- exp : Expression\n-id\n\n-exp\n\nIden tifi er\n\nUn ar yExpr ession\n\nExpression\n\nBin ar yExpr ession\nPar en th esizedExpr ession\n\nFigure 3 An assignment statement as an example of element\ncomposition (concatenation in textual CSM terms).\n\nFigure 4 Subtyping for representing choices in ModelCC.\n\nminal symbols corresponding to the constituent elements\nof the composite element in its right-hand side. By default, the order of the constituent elements in the production rule is given by the order in which they are specified in the object composition, but such an order is not\nstrictly necessary (e.g. many ambiguous languages might\nrequire unordered sequences of constituent elements and\neven some unambiguous languages allow for such flexibility).\nThe model in Figure 3 shows an example of object\ncomposition in ASM terms that corresponds to string\nconcatenation in CSM terms. In this example, an assignment statement is composed of an identifier, i.e. a\nreference to its l-value, and an expression, which provides its r-value. In a textual CSM, the composite AssignmentStatement element would be translated into the\nfollowing production rule: <AssignmentStatement> ::=\n<Identifier> <Expression>. Obviously, such production\nwould probably include some syntactic sugar in an actual programming language, either for avoiding potential ambiguities or just for improving its readability and\nwritability, but that is the responsibility of ASM-CSM\nmappings, which will be analyzed in Section V.\n\nB. Selection\n\nSelection is necessary as a language modeling primitive\noperation to represent choices, so that we can specify\nalternative elements in language constructs.\nIn ModelCC, selection is achieved by subtyping. Specifying inheritance relationships among language elements\nin an object-oriented context corresponds to defining 'isa' relationships in a more traditional database design setting. The language element we wish to establish alternatives for is the superelement (i.e. the superclass in OO or\nthe supertype in DB modeling), whereas the different alternatives are represented as subelements (i.e. subclasses\nin OO, subtypes in DB modeling). Alternative elements\nare always kept separate to enhance the modularity of\nModelCC abstract syntax models and their integration\nin language processing systems.\nIn the current version of ModelCC, multiple inheritance is not supported, albeit the same results can be\neasily simulated by combining inheritance and composition. We can define subelements for the different in-\n\nheritance hierarchies representing choices so that those\nsubelements are composed by the single element that\nappears as a common choice in the different scenarios.\nThis solution fits well with most existing programming\nlanguages, which do not always support multiple inheritance, and avoids the pollution of the shared element\ninterface in the ASM, which would appear as a side effect of allowing multiple inheritance in abstract syntax\nmodels.\nEach inheritance relationship in ModelCC, when converting the ASM into a textual CSM, generates a production rule in the CSM grammar. In those productions,\nthe nonterminal symbol corresponding to the superelement appears in its left-hand side, while the nonterminal\nsymbol of the subelement appears as the only symbol\nin the production right-hand side. Obviously, if a given\nsuperelement has k different subelements, k different productions will be generated representing the k alternatives\ndefined by the abstract syntax model.\nFor example, the model shown in Figure 4 illustrates how an arithmetic Expression can be an\nUnaryExpression, a BinaryExpression, or a ParenthesizedExpression in the language defined for a\nsimple calculator.\nThe grammar resulting from\nthe conversion of this ASM into a textual CSM\nwould be: <Expression> ::= <UnaryExpression> |\n<BinaryExpression> | <ParenthesizedExpression>.\n\nC. Repetition\n\nRepresenting repetition is also necessary in abstract\nsyntax models, since a language element might appear\nseveral times in a given language construct. When a variable number of repetitions is allowed, mere concatenation\ndoes not suffice.\nRepetition is also achieved though object composition\nin ModelCC, just by allowing different multiplicities in\nthe associations that connect composite elements to their\nconstituent elements. The cardinality constraints described in Section V.C can be used to annotate ModelCC models in order to establish specific multiplicities\nfor repeatable language elements.\nEach composition relationship representing a repeti-\n\n\f8\nOutputStatem en t\n- exps : Expression\n\n1..*\n-exps\n\nExpression\n\nFigure 5 Multiple composition for representing repetition in\nModelCC.\n\ntive structure in the ASM will lead to two additional\nproduction rules in the grammar defining a textual\nCSM: a recursive production of the form <ElementList>\n::= <Element> <ElementList> and a complementary production <ElementList> ::= <Element>, where\n<Element> is the nonterminal symbol associated to the\nrepeating element. Obviously, an equivalent non-leftrecursive derivation can also be obtained when needed.\nIt should also be noted that <ElementList> will take\nthe place of the nonterminal <Element> in the production derived from the composition relationship that connects the repeating element with its composite element\n(see the above section on how composition is employed\nto represent concatenation in ModelCC).\nIn practice, repeating elements will often appear separated in the concrete syntax of a textual language, hence\nrepeatable elements can be annotated with separators,\nas we will see in Section V.B. In case separators are\nemployed, the recursive production derived from repeatable elements will be of the form <ElementList> ::=\n<Element> <Separator> <ElementList>.\nWhen a repeatable language element is optional, i.e.\nits multiplicity can be 0, an additional epsilon production\nhas to be appended to the grammar defining the textual\nCSM derived from the ASM: <ElementList> ::= \u01eb.\nFor example, the model in Figure 5 shows that an OutputStatement can include several Expressions, which will\nbe evaluated for their results to be sent to the corresponding output stream. This ASM would result in the\nfollowing textual CSM grammar: <OutputStatement>\n::= <ExpressionList> for describing the composition and\n<ExpressionList> ::= <Expression> <ExpressionList>\n| <Expression> for allowing repetition.\nV. MODELCC MODEL CONSTRAINTS\n\nOnce we have examined the mechanisms that let us\ncreate abstract syntax models in ModelCC, we now proceed to describe how constraints can be imposed on such\nmodels in order to establish the desired ASM-CSM mapping. As soon as that ASM-CSM mapping is established,\nModelCC is able to generate the suitable parser for the\nconcrete syntax defined by the CSM.\nIn ModelCC, the constraints imposed over abstract\nsyntax models to define a particular ASM-CSM mapping\nare declared as metadata annotations on the model itself.\nNow supported by all the major programming platforms,\n\nmetadata annotations have been used in reflective programming and code generation [17]. Among many other\nthings, they can be employed for dynamically extending the features of your software development runtime\n[5] or even for building complete model-driven software\ndevelopment tools that benefit from the infrastructure\nprovided by your compiler and its associated tools [21].\nIn ModelCC, which supports language composition\nwithout being scannerless, metadata annotations are\nused for pattern specification, a necessary feature for\ndefining the lexical elements of the concrete syntax\nmodel, i.e. its tokens (Subsection A).\nAnnotations are also employed for defining delimiters\nin the concrete syntax model, whose use is common\nfor eliminating language ambiguities or just as syntactic sugar in many languages (Subsection B).\nA third group of ModelCC metadata annotations lets\nus impose cardinality constraints on language elements,\nwhich control element repeatability and optionality (Subsection C).\nFinally, a fourth set of metadata annotations lets us\nimpose evaluation order constraints in ModelCC, which\nare employed to declaratively resolve further ambiguities\nin the concrete syntax of a textual language, by establishing associativity, precedence, and composition constraints, the latter employed for resolving the ambiguities\nthat cause the typical shift-reduce conflicts in LR parsers\n(Subsection D).\nA summary of the complete set of annotations supported by ModelCC can be found at the end of this section, after the detailed description of each of the four\ngroups of ModelCC metadata annotations.\nA. Pattern Specification Constraints\n\nPattern specification constraints allow the specification\nof the lexical elements in a concrete syntax model, i.e.\nthe different token types defined for the concrete syntax\nof a textual language. It should be noted that, once a\nlanguage element is annotated with pattern specification\nconstraints, it cannot be a composite element since, as a\nlexical element, it cannot be composed of other elements.\nThe above constraint, which forces lexical elements to\nbe basic language elements in a ModelCC ASM, does\nnot reduce the flexibility of ModelCC for language composition. Language composition, typically achieved by\nscannerless parser generators, can also be achieved if the\nscanner supports lexical ambiguities. When lexical ambiguities are allowed, as in the Lamb scanning algorithm\n[51], the same string or even overlapping strings might return several tokens, which will later be processed by the\nparser consuming the output of the scanner supporting\nlexical ambiguities.\n1. The @Pattern annotation\n\nThe @Pattern annotation allows the specification of\nthe pattern that will be used to match a basic lan-\n\n\f9\n@Pattern (regExp=\"[a-zA-Z][_a-zA-Z0-9]*\")\nIden tifi er\n\nIn teger Liter al\n~ @Value value : lon g\n\nFigure 9 Value field specification example: Integer literals.\nFigure 6 Pattern specification example: Regular expression.\n[a-zA-Z][_a-zA-Z0-9]*\n\nreturn Identifier;\n\n[0-9]+ {\nyylval.value = atoi(yytext);\nreturn INTEGERLITERAL;\n}\n\nFigure 7 Implementation of Figure 6 in lex.\n@Pattern (match er=JavaDocRecogn izer,args=\"simple\")\n\nFigure 10 Implementation of Figure 9 using lex & yacc.\n\nJavaDoc\n\nFigure 8 Pattern specification example: Custom pattern\nmatching.\n\nguage element in the input string. Two mutually exclusive mechanisms are provided for pattern specification in\nModelCC: regular expressions and user-defined pattern\nmatching classes. Regular expressions can be specified in\nModelCC to build standard lexers, whereas custom pattern matching classes allow the language designer to use\nany custom-defined matching element to recognize basic\nlanguage elements in the input string. The custom pattern matching class can be anything, since it works as\na black box for ModelCC. It might even be a complete\nModelCC-generated parser, which could be used for the\nspecification of modular languages, a coarse form of language composition (e.g. think of the JavaScript scripts\nand CSS stylesheets within the HTML in a web page).\nWhen used with regular expressions, the @Pattern annotation includes an argument representing the regular\nexpression. This regular expression, specified as the regExp field of the annotation, corresponds to the traditional\ntoken type definition in lex-like scanners.\nWhen used with custom pattern matching classes, the\n@Pattern annotation is used to specify the name of the\nclass implementing the matching algorithm and its argument string. In this case, ModelCC resorts to the Lamb\nlexer [51], which will employ the pattern matching class\nspecified by the matcher field of the @Pattern annotation to process the input string. This Lamb-specific [51]\nlexical definition makes use of Lamb support for lexical ambiguities, overlapping tokens, and black-box token\nrecognizers.\nFor example, the @Pattern annotation in Figure 6 defines the typical Identifier token in programming languages, which can be specified by the following regular expression: [a-zA-Z][ a-zA-Z0-9]*. This specification\ncorresponds to the lex token definition shown in Figure\n7.\nThe example in Figure 8 illustrates the use of custom pattern matching classes in ModelCC. In this case,\nthe @Pattern annotation refers to the JavaDocRecognizer\nclass, which will be responsible for recognizing JavaDoc\ncomments as basic language elements in the shown ASM.\n\nArguments can also be specified when using the matcher\nfield of the @Pattern annotation with the help of its optional args field (\"simple\" in Figure 8).\nAs mentioned above, the ModelCC use of custom pattern matching algorithms for defining basic language elements has no counterpart in traditional lexer generators, hence an equivalent lex-like definition cannot be\nprovided. In ModelCC, the Lamb scanning algorithm\n[51] will be responsible for processing such token definitions.\n\n2. The @Value annotation\n\nThe @Value annotation can be used in combination\nwith the @Pattern annotation in ModelCC to indicate\nthe location where the recognized token value will be\nstored in the abstract syntax graph, so that value can\nbe used once the input string has been parsed.\nAssociated to a field of the class defining a basic language element, that field will contain the value obtained\nfrom the input string that matches the token type pattern specification.\nWhen a numeric or boolean field is annotated with\nthe @Value annotation, it is not necessary to specify the\ncorresponding @Pattern annotation for recognizing the\nnumeric or boolean tokens. When the @Value-annotated\nfield is not numeric nor boolean (e.g. a string, a single\ncharacter, or any non-primitive data type), the use of the\n@Pattern annotation is mandatory.\nElements from the ASM that contain a @Valueannotated numeric or boolean field are transformed into\ntheir corresponding token type lex-like definitions, even\nwhen no @Pattern annotation is present. ModelCC will\nalways perform the proper assignment of the recognized\ntoken to the @Value-annotated field.\nFor example, the model in Figure 9 defines an IntegerLiteral language element that recognizes long integer\nliterals. The proper regular expression for such literals\nwill be employed and, whenever an integer literal is found\nin the input string, its integer value will be stored in the\n@Value-annotated value field of the IntegerLiteral class.\nIf we had used lex & yacc, we would have had to type the\nlexical definition and semantic action shown in Figure 7.\nAs another example, Figure 11 shows how the @Value\n\n\f10\n@Pattern (regExp=\"\\\"[^\\\"]*\\\"\")\nStr in gLiter al\n~ @Value text : Strin g\n\nFigure 11 Value field specification example: Double-quoted\nstring literals.\n\\\"[^\\\"]*\\\" {\nint size,csize;\nsize = strlen(yytext)-2;\ncsize = sizeof(char)*(size+1);\nyylval.pval = malloc(csize);\nstrncpy(yylval.pval,yytext+1,size);\nyylval.pval[size] = '\\0';\nreturn STRINGLITERAL;\n}\n\nFigure 12 Implementation of Figure 11 using lex & yacc.\n\nannotation would be used in conjunction with the @Pattern annotation to define string literals surrounded by\ndouble quotes. A StringLiteral will be recognized whenever a pair of double quotes encloses a string not containing a double quote, a constraint that can be specified by\nthe following regular expression: \\\"[\u02c6\\\"]*\\\". The lex &\nyacc implementation of this string literal token type definition would be slightly more complex than the previous\nexample, as shown in Figure 12.\nB. Delimiter Constraints\n\nDelimiter constraints allow the specification of language element delimiters in a concrete syntax model. Delimiters include prefixes, suffixes, and separators. Such\nkinds of delimiters are often used to eliminate language\nambiguities and facilitate parsing, but they can appear\njust as syntactic sugar to make languages more readable.\nUsually, reserved words in programming languages act\njust as delimiters. As such, they will not appear in the\nlanguage abstract syntax model. They will be specified\nas metadata annotations in the ASM-CSM mapping corresponding to the concrete syntax of the language.\nIt should be noted that delimiters should always be\nspecified as constraints on the ASM-CSM mapping rather\nthan language elements in the ASM, since they do not\nprovide any relevant information from the perspective of\nthe abstract syntax model, even though they might be\nnecessary to define unambiguous textual languages.\n1. The @Prefix annotation\n\nThe @Prefix annotation allows the specification of prefixes for language elements and specific constituents in\ncomposite language elements.\nThe value field of the @Prefix annotation is used to\nspecify the list of regular expressions that define the prefixes that precede the corresponding language element\n\n@Prefix(\"main \")\nPr ogr am\n- main : Statemen t\n\n-main\n\nStatement\n\nFigure 13 @Prefix annotation example.\n\n(or a specific constituent element within a composite element) in the concrete syntax of a textual CSM.\nWhen converting the ASM into a textual CSM, ModelCC will include the specified prefixes in every production where the annotated element appears in the textual\nCSM grammar, just before the appearance of the annotated element. When the annotation is associated to\na constituent element within a composite language element, the sequence of prefixes will be included only in\nthe productions that correspond to the composite language element, preceding the annotated constituent element within their right-hand side.\nIt should be noted that, when the annotated element\nis repeatable, the sequence of prefixes appear only once,\npreceding the first instance of the annotated element.\nPrefixes will also be included in the CSM even when no\nelements appear in a repetition language construct (e.g.\nas when the opening parenthesis appears before an empty\nlist of arguments in a parameterless C-like function call).\nFor example, the model in Figure 13 specifies that\nthe textual representation of a Program will always be\npreceded by a \"main\" keyword prefix. The grammar\ndefining the textual CSM for this simple example is\n<ProgramMain> ::= \"main\" <Statement>.\n\n2. The @Suffix annotation\n\nThe @Suffix annotation allows the specification of suffixes for language elements and specific constituents in\ncomposite language elements.\nThe value field of the @Suffix annotation is used to\nspecify the list of regular expressions that define the suffixes that follow the corresponding language element (or a\nspecific constituent element within a composite element)\nin the concrete syntax of a textual CSM.\nWhen converting the ASM into a textual CSM, ModelCC will include the specified suffixes in every production where the annotated element appears in the textual\nCSM grammar, just after the appearance of the annotated element. When the annotation is associated to\na constituent element within a composite language element, the sequence of suffixes will be included only in\nthe productions that correspond to the composite language element, following the annotated constituent element within their right-hand side.\nIt should be noted that, when the annotated element\nis repeatable, the sequence of suffixes appear only once,\n\n\f11\n@Prefix(\"in put\")\n@Suffix(\";\")\nIn putStatem en t\n- ids : Iden tifier\n@Prefix(\"(\")\n@Suffix(\")\")\n\n@Suffix(\";\")\nVar iableDeclar ation\n- type : Type\n- ids : Iden tifier\n\n1..* @Separator(\",\")\nIden tifi er\n-ids\n\n1..*\nIden tifi er\n-ids\n\n-type\n\nType\n\nFigure 14 @Suffix annotation example.\n\nFigure 15 Default @Separator example.\n\njust after the last element in the sequence of repetitions.\nSuffixes will also be included in the CSM even when no\nelements appear in a repetition language construct (e.g.\nas when the closing parenthesis appears at the end of an\nempty list of arguments in a parameterless C-like function call).\nFor example, the model in Figure 14 specifies that the\ntextual representation of an InputStatement is preceded\nby an \"input\" keyword prefix and followed by a semicolon (\";\") as its suffix. It also contains a sequence of\nIdentifier s delimited by opening and closing parentheses: \"(\" as the prefix of the ids constituent of the InputStatement composite and \")\" as its suffix. The grammar defined by the ASM-CSM mapping specified by the\nannotations in Figure 14 is <InputStatement> ::= \"input\" \"(\" <IdentifierList> \")\" \"';\"; <IdentifierList> ::=\n<Identifier> <IdentifierList> | <Identifier>.\n\nthe sequence of regular expressions defining those default\nseparators in every recursive production rule generated\nfrom a repetition where the annotated element is repeatable. When the @Separator annotation accompanies a\nrepeatable element within a particular repetition construct, i.e. the ad hoc case, separators will only appear\nin the recursive production rule derived from that particular repetition construct, but not in other constructs\nwhere the constituent element might also be repeatable.\nAs an example of defining a default separator, Figure 15 illustrates how a comma (\",\") can be used\nas the default separator for Identifier s. Whenever a\nlist of Identifier s is needed within the language, a\ncomma will separate consecutive identifiers. In the\nexample, since a VariableDeclaration contains a Type\nand a set of Identifier s, they will be separated by\n\",\" in the textual CSM derived from the language\nASM. The grammar of the resulting CSM will include\nthe following productions: <VariableDeclaration> ::=\n<Type> <IdentifierList> \";\" and <IdentifierList> ::=\n<Identifier> \",\" <IdentifierList> | <Identifier>.\nAs an example illustrating the use of ad hoc separators, consider the model in Figure 16. Here, Identifier s\nare also separated by commas, but only within InputStatement s, i.e. \",\" is the ad hoc separator for identifiers\nwithin input statements, but lists of identifiers might employ different separators elsewhere. The grammar associated to the textual CSM derived from Figure 16 would\ninclude the following productions: <InputStatement>\n::= \"input\" \"(\" <InputStatementIdentifierList> \")\" \";\"\nand <InputStatementIdentifierList> ::= <Identifier>\n\",\" <InputStatementIdentifierList> | <Identifier>.\n\n3. The @Separator annotation\n\nThe @Separator annotation allows the specification\nof separators between consecutive instances of elements\nwithin a repetition. Separators can be defined in ModelCC by annotating a language element in the ASM or\njust its appearance within a particular repetition construct. In the first case, a default separator is established for the language element: the specified separator\nwill be used for separating consecutive instances of the\nannotated language element whenever a sequence of such\nlanguage elements appears in a textual CSM. In the second case, an ad hoc separator is defined: the specified\nseparator will be used only when consecutive instances\nof the language element appear within the context of the\nannotated repetition construct.\nThe ad hoc definition of separators with the @Separator annotation within repetition constructs can be used\nto override the default sequence of separators associated\nto the repeatable element in a repetition construct (or\njust to disable the use of separators for that specific repetition).\nTherefore, default separators are specified for language\nelements by the @Separator annotation. When converting the ASM into a textual CSM, ModelCC will include\n\nC. Cardinality Constraints\n\nA third group of ModelCC metadata annotations lets\nus impose cardinality constraints on language elements,\nwhich control element repeatability and optionality.\n1. The @Optional annotation\n\nThe @Optional annotation allows the specification of\noptional elements in textual CSMs.\nOptional elements naturally appear in language spec-\n\n\f12\n@Prefix(\"in put\")\n@Suffix(\";\")\nIn putStatem en t\n- ids : Iden tifier\n@Prefix(\"(\")\n@Suffix(\")\")\n@Separator(\",\")\n1..*\n-ids\n\n-if\nStatement\n-else\n@Prefix(\"else\")\n@Option al\nCon dition alStatem en t\n- con d : Expression\n- if : Statemen t\n- else : Statemen t\n\nIden tifi er\n\nFigure 16 Ad hoc @Separator example.\n\nifications and optionality could always be modeled by\nmeans of selection constructs. However, the declarative\nspecification of the optionality constraints is necessary to\navoid unnecessary duplication in the language model.\nWhen one of the constituent elements within a composite language element is optional, the textual representation of the composite element might include the optional\nelement, along with its corresponding delimiters, or not.\nIn the latter case, the missing element delimiters are not\nincluded in the textual representation the composite element either, even though a prefix and a suffix might have\nbeen defined for the missing constituent element.\nIf we performed a naive transformation of a composite language into a set of CFG production rules and the\ncomposite element includes i optional elements, 2i production rules would result with the composite element in\ntheir left-hand side and all the possible combinations of\noptional elements in their right-hand side. A more reasonable transformation employs just i ancillary epsilon\nproduction rules.\nFor example, the model in Figure 17 shows that a\nConditionalStatement contains an Expression, the Statement that will be run when the Expression evaluates to true, and, optionally, the Statement that will\nbe run when the Expression evaluates to false. The\ngrammar resulting from the model transformation into\na textual CSM will include the following two productions: <ConditionalStatement> ::= \"if \" <Expression>\n<Statement> <OptionalElse> and <OptionalElse> ::=\n\"else\" <Statement> | \u01eb.\n\n2. The @Minimum annotation\n\nThe @Minimum annotation, depicted as a minimum\nmultiplicity constraint in standard UML notation, allows\nthe specification of the lower bound for the multiplicity\nof repeatable language elements within repetition constructs. This lower bound is 1 by default.\nIt should be noted that, when the minimum multiplicity is 0, no elements might appear in a particular instance of the repetition. However, delimiters would still\nbe represented in the textual CSM unless the @Optional\n\n@Prefix(\"if\")\n@Suffix(\";\")\nExpression\n-con d\n\nFigure 17 @Optional element example: if-then-else statement.\n\n@Prefix(\"{\")\n@Suffix(\"}\")\nExpr ession Set\n- exps : Expression\n0..*\n-exps\n\nExpression\n@Separator(\",\")\n\nFigure 18 Minimum multiplicity example.\n\nannotation were explicitly employed.\nModelCC generates semantic actions that check that\nmultiplicity constraints are satisfied whenever they are\nspecified in the model. The Fence parser [50] allows\nsemantic actions to implement such multiplicity checks\nand, when they are not satisfied, the corresponding reduction is automatically inhibited.\nOther parser generators would require the explicit generation of a grammar representing the minimum cardinality constraint, i.e. when an element must appear at least i times within a repetition, two production rules would be necessary: <MinIElements> ::=\n<Element>... i times... <Element> <ElementList>\nand <ElementList> ::= <Element> <ElementList> | \u01eb.\nFor example, the model in Figure 18 specifies that\nan ExpressionSet, which might include 0 or more\nExpressions. In UML notation, no explicit @Minimum\nannotation is needed, since the minimum multiplicity\nconstraint in the exps association has the same purpose. The grammar corresponding to the textual CSM\nderived from Figure 18 would include the following\nproductions to represent the possibility of empty sets:\n<ExpressionSet> ::= \"{\" <OptionalExpressionList>\n\"}\"; <OptionalExpressionList> ::= <ExpressionList>\n| \u01eb;\n<ExpressionList> ::= <Expression> \",\"\n<ExpressionList> | <Expression>.\n\n\f13\n3. The @Maximum annotation\n\nThe @Maximum annotation, depicted as a maximum\nmultiplicity constraint in standard UML associations, allows the specification of the upper bound for the multiplicity of repeatable language elements within repetition\nconstructs. This upper bound is undefined by default.\nModelCC incorporates semantic actions that check\nthat multiplicity constraints are satisfied whenever they\nare specified in the model. The Fence parser [50] allows\nsemantic actions to implement such multiplicity checks\nso that, when they are not satisfied, the corresponding\nreduction is automatically inhibited. In other words, if\nan specific upper bound is surpassed for a list of elements, the generated parser would not recognize the list\nof elements as such, since it does not satisfy the cardinality constraint imposed by the maximum multiplicity\nannotation.\nOther parser generators would require the generation\nof more complex grammars to support maximum multiplicity constraints. In general, if i is the maximum\nmultiplicity, i alternative production rules would be necessary (assuming that the default minimum multiplicity\nholds, i.e. 1). When both the minimum i and the maximum j multiplicities are specified, one production would\nbe used for representing the minimum multiplicity constraint and j \u2212 i additional productions would be needed\nto enforce the maximum multiplicity constraint. More\ncomplex combinations of multiplicity constraints could\nalso be devised.\nFor example, the model in Figure 19 indicates that a\nProgram might have from 0 to 2 Parameter s. Here, both\na minimum and a maximum multiplicity annotations are\ninferred from the multiplicity of the UML association.\nThe grammar corresponding to the textual CSM derived from Figure 19 would include the following production rules: <Program> ::= <OptionalParameterList>;\n<OptionalParameterList> ::= <ParameterList> | \u01eb;\n<ParameterList> ::= <Parameter> <ParameterList>\n| <Parameter>, where the last production would be\naccompanied by a semantic action that would check\nwhether the maximum multiplicity constraint holds. If\nsuch feature were not available in our parsing algorithm\ngenerator, this last production would have to be replaced\nby a much more explicit (and potentially verbose) set of\nequivalent productions incorporating the maximum multiplicity constraint: <ParameterList> ::= <Parameter>\n| <Parameter> <Parameter>. This approach poses no\nproblems in this simple example, but it might get much\nmore complicated (no problem yet whenever the resulting\ngrammar is automatically generated by a model-driven\nlanguage specification tool).\n\nD. Evaluation Order Constraints\n\nA fourth set of ModelCC metadata annotations lets\nus impose evaluation order constraints, which are em-\n\nPr ogr am\n- pars : Parameter\n\n0..2\n-pars\n\nPar am eter\n\nFigure 19 Maximum multiplicity example.\n\nployed to declaratively resolve syntactic ambiguities in\nthe concrete syntax of a textual language by establishing\nassociativity, composition, and precedence constraints for\nCSMs.\n1. The @Associativity annotation\n\nThe @Associativity annotation allows the specification\nof the operator-like associativity of language elements.\nModelCC supports the following options for specifying\nassociativity constraints:\n\u2022 UNDEFINED, when no associativity is declared\n(by default), all possibilities are considered.\n\u2022 LEFT TO RIGHT, for left-associative operations\n(e.g. substraction, division, or function application).\n\u2022 RIGHT TO LEFT, for right-associative elements\n(e.g. exponentiation and function definition).\n\u2022 NON ASSOCIATIVE, for non-associative elements\n(e.g. cross of three vectors).\nThe specification of associativity constrains help us resolve ambiguities that might appear in recursive compositions (i.e. when using the composite design pattern\n[20] for modeling the ASM for operations without explicit\ndelimiters), where different interpretations of the input\nstring could be given unless the associativity constraints\nimpose an order on the reductions that can be performed\n(either left-to-right or right-to-left).\nFor each production in the CSM grammar where an\nthe nonterminal of a language element with associativity\nconstraints is preceded and/or followed by the nonterminal that appears on the left-hand side the production or\nany of its superclasses in the ASM, ModelCC generates\na semantic action enforcing that associativity constraint.\nThat semantic action, which inhibits the reduction of the\nproduction when the constraint is not met, is directly\nsupported by the Fence parsing algorithm [50]. Fence\ninhibits the corresponding reduction in three situations:\n\u2022 Whenever the element that follows a left-to-right\nassociative element was generated by a reduction\nof the same production.\n\u2022 Whenever the element that precedes a right-to-left\nassociative element was generated by a reduction\nof the same production.\n\n\f14\nExpression\n\n-if\n\n-e1\nStatement\n-e2\n\nBin ar yExpr ession\n- e1 : Expression\n- op : Bin aryOperator\n- e2 : Expression\n\n@Pattern (regExp=\"\\+|-\")\n@Associativity(LEFT_TO_RIGHT)\nBin ar yOper ator\n-op ~ @Value operator : ch ar\n\n-else\n@Prefix(\"else\")\n@Option al\nCon dition alStatem en t\n- con d : Expression\n- if : Statemen t\n- else : Statemen t\n@Prefix(\"if\")\n@Suffix(\";\")\n@Composition (EAGER)\nExpression\n\nFigure 20 Associativity constraint example.\n\n\u2022 Whenever an element that precedes or follows a\nnon-associative element was generated by a reduction of the same production.\nThe parsing algorithms implemented by other parser\ngenerators also offer mechanisms to enforce associativity\nconstraints.\nFor example, the model in Figure 20 establishes that BinaryOperator s are left-associative.\nThe grammar for the resulting textual CSM\nwould include the productions <Expression> ::=\n<BinaryExpression> and <BinaryExpression> ::=\n<Expression> <BinaryOperator> <Expression>, where\nassociativity is not explicit. Left-associativity will be\nimposed by the corresponding parser semantic action.\n2. The @Composition annotation\n\nThe @Composition annotation allows the specification\nof the suitable order of evaluation of compositions represented in a CSM, a situation that appears whenever\nthe composite design pattern [20] is present in the ASM,\nno delimiters are employed to eliminate potential ambiguities, and the composite contains several consecutive\ncomponents of the same type of the composite. When\nsuch composites are nested, different interpretations are\npossible unless we specify composition constraints in the\nCSM. This is the case of the typical shift-reduce conflicts\nthat appear in LR parsers when parsing nested if-thenelse statements.\nHence, a specific constraint on element composition\nmust be used to enforce a particular interpretation of\nsuch nested compositions in the ASM-CSM mapping.\nModelCC supports the following options for composition\nconstraints:\n\u2022 UNDEFINED, when no composition constraints\nare defined and potential ambiguities are taken into\naccount.\n\u2022 EAGER, when the matching of constituent elements is performed as soon as possible. This cor-\n\n-con d\n\nFigure 21 Composition constraint example.\n\nresponds to the typical interpretation of nested\nif-then-else statements in programming languages,\nwhere the else clause is attached to the innermost\nif statement.\n\u2022 LAZY, when the matching of constituent elements\nis deferred as much as possible. Then, a rightmost\nderivation is obtained; i.e. when an element might\naccompany any of two nested language constructs,\nit is associated to the outermost one.\n\u2022 EXPLICIT, when no composition constraints are\ndefined and any ambiguities should be resolved\nwith the help of delimiters.\nComposition order constraints are enforced by defining precedences for the productions in the grammar of\nthe resulting textual CSM. Establishing such precedences\nis possible in most parsing tools, including all yacc [28]\nderivatives and Fence [50]. When composition is eager,\nshift operations will precede reduce operations. In contrast, when composition is lazy, reduce operations will\nhave precedence over shift operations. Finally, when the\ncomposition order must be explicit in the CSM, the use\nof delimiters will determine whether shift or reduce operations are performed on a case by case basis.\nFor example, the model in Figure 21 represents typical if-then-else statements. In this case, the optional\nelse Statement of the eager ConditionalStatement will always match the innermost if statement when such statements are nested, e.g. in \"if E1 if E2 S1 else S2\",\nthe else clause will correspond to the E2 if statement.\nThe grammar for the resulting CSM will include the following productions: <ConditionalStatement> ::= \"if \"\n<Expression> <Statement> \";\" | \"if \" <Expression>\n<Statement> \"else\" <Statement> \";\". The parser will\nenforce the precedence of the second alternative over the\nfirst one, so that else clauses are parsed as usual.\n\n\f15\n@Separator(\",\")\n@Pattern (regExp=\"[a-zA-Z][_a-zA-Z0-9]*\")\nIden tifi er\n~ @Value n ame : Strin g\n\n@Prefix(\"output\")\n@Suffix(\";\")\n@Priority(precedes={Fun ction CallStatemen t})\nOutputStatem en t\n- exps : Expression\n\n@Priority(precedes={Iden tifier})\n@Pattern (regExp=\"fun c_[a-zA-Z0-9]*\")\n\n@Suffix(\";\")\nFun ction CallStatem en t\n- fun ction id : Iden tifier\n- exps : Expression\n\nFun ction Nam e\n~ @Value n ame : Strin g\n\n-fun ction id\nIden tifi er\n~ @Value n ame : Strin g\n\nFigure 22 Relative priority resolved by the lexical analyzer.\n\n@Pattern (regExp=\"[a-zA-Z][_a-zA-Z0-9]*\")\n\n3. The @Priority annotation\n\nThe @Priority annotation allows the specification of\nprecedences among language elements for eliminating\nambiguities in textual CSMs.\nModelCC implements two mechanisms to specify priority constraints in the ASM-CSM mapping:\n\u2022 A relative one, where precedence relationships are\nestablished between particular language elements\n(a precedes declaration indicates which language\nelements have lower priority than the current element).\n\u2022 An absolute one, where a numeric priority value\ndetermines the priority level for each language element (the lower the value, the higher the priority)\nUnless specified otherwise, all language elements have\nthe same priority. Precedences established among basic\nlanguage elements must be managed at the lexical analysis level. In ModelCC, the Lamb scanning algorithm\n[51] enforces those lexical precedences. The Fence parsing algorithm [50] manages all the remaining precedences\nthat can be established among the non-basic language elements that appear in concatenation, selection, and repetition constructs within the CSM.\nFor example, the model in Figure 22 establishes a (fictitious) relative priority constraint between function names\nand identifiers: a FunctionName will always precede an\nIdentifier. In case a string like \"func power\" is found in\nthe input string, it will be recognized as a FunctionName,\nbut not as an Identifier. Since the constraint is defined\nover basic language elements, the lexical analyzer generated by ModelCC will be responsible for identifying the\nright element in the input string.\nFigure 23 shows another example. In this case,\nthe model enforces relative priority constraints between\ncomposite language elements that will be resolver by\nthe parser generated by ModelCC. Here, output statements precede function calls so that a string like \"output(3+5,4+1);\" will be recognized as an OutputStatement but not as an FunctionCallStatement, even when\n\"output\" would be a perfectly valid indentifier. The\nModelCC lexer, which supports lexical ambiguities, will\n\n@Prefix(\"(\")\n@Suffix(\")\")\n\n@Prefix(\"(\")\n@Suffix(\")\")\n-exps 0..*\n\nExpression\n\n-exps 1..*\n\nFigure 23 Relative priority resolved by the syntactic analyzer.\n\nconsider \"output\" as an Identifier and also as a delimiter for output statements (i.e. its prefix keyword in the\nCSM).\n\nE. Summary of ModelCC ASM-CSM Constraints\n\nTable I summarizes the set of constraints supported by\nModelCC for establishing ASM-CSM mappings between\nabstract syntax models and their concrete representation\nin textual CSMs:\n\u2022 Pattern specification constraints are employed to\nspecify the textual representation of basic language\nelements in the CSM. They define the token types\nrecognized by the lexer and indicate where the recognized tokens will be stored in the ASM.\n\u2022 Delimiter constraints determine the prefixes, suffixes, and separators that will be used to mark the\nboundaries of language elements in the CSM. They\ncan be used for eliminating language ambiguities or\njust as syntactic sugar in text-based CSMs.\n\u2022 Cardinality constraints restrict the multiplicity of\nrepetitions and determine the optionality of language elements. The CSM must consider such constraints for defining the grammar that defines the\nlanguage recognized by the generated parser.\n\u2022 Finally, evaluation order constraints allow the explicit resolution of different kinds of lexical and syntactic ambiguities that might appear in the ASMCSM mapping.\n\n\f16\nConstraints on...\nPatterns\nDelimiters\n\nCardinality\n\nEvaluation\norder\n\nAnnotation\n@Pattern\n@Value\n@Prefix\n@Suffix\n@Separator\n@Optional\n@Minimum\n@Maximum\n@Associativity\n@Composition\n@Priority\n\nFunction\nPattern matching definition of basic language elements.\nField where the recognized input element will be stored.\nElement prefix(es).\nElement suffix(es).\nElement separator(s).\nOptional elements.\nMinimum element multiplicity.\nMaximum element multiplicity.\nElement associativity (e.g. left-to-right).\nEager or lazy composition for nested composites.\nElement precedence level/relationships.\n\nTable I Summary of the metadata annotations supported by ModelCC.\n\nVI. A WORKING EXAMPLE\n\nB. Conventional Implementation\n\nIn this section, we compare how an interpreter for\narithmetic expressions can be implemented using conventional tools and how it can be implemented using the\nmodel-driven approach using ModelCC. Albeit the calculator example in this section is necessarily simplistic,\nit already provides some hints on the potential benefits\nmodel-driven language specification can bring to more\nchallenging endeavors.\nFirst, we will outline the features we wish to include\nin our calculator language. Later, we will describe how\nan interpreter for this language is built using two of the\nmost established tools in use by language designers: lex\n& yacc on the one hand, ANTLR on the other. Finally,\nwe will implement the same language processor using\nModelCC by defining an abstract syntax model. This\nASM will be annotated to specify the required ASM-CSM\nmapping and it will also include the necessary logic for\nevaluating arithmetic expressions. This example will let\nus compare ModelCC against conventional parser generators and it will be used for discussing the potential\nadvantages provided by our model-driven language specification approach.\n\nUsing conventional tools, the language designer would\nstart by specifying the grammar defining the calculator\nlanguage in a BNF-like notation. The BNF grammar\nshown in in Figure 24 meets the requirements of our simple calculator, albeit it is not yet suitable for being used\nwith existing parser generators, since they impose specific\nconstraints on the format of the grammar depending on\nthe parsing algorithms they employ.\n\nA. Language Description\n\nOur calculator will employ classical arithmetic expressions in infix notation. The language will feature the\nfollowing capabilities:\n\u2022 Unary operators: +, and -.\n\u2022 Binary operators: +, -, *, and /, being - and /\nleft-associative.\n\u2022 Operator priorities: * and / precede + and -.\n\u2022 Parenthesized expressions.\n\u2022 Integer and floating-point literals.\n\n1. Lex & yacc implementation\n\nWhen using lex & yacc, the language designer converts the BNF grammar into a grammar suitable for LR\nparsing. A suitable lex/yacc implementation defining the\narithmetic expression grammar is shown in Figure 25.\nSince lex does not support lexical ambiguities, the\nUnaryOperator and BinaryOperator nonterminals from\nthe BNF grammar in Figure 24 have to be refactored\nin order to avoid the ambiguities introduced by the use\nof + and - both as unary and binary operators. A\ntypical solution consists of creating the UnaryOrPriority2BinaryOperator token type for representing them and\nthen adjusting the grammar accordingly. This token will\nact as an UnaryOperator in UnaryExpressions, and as a\nBinaryOperator in BinaryExpressions.\nA similar solution is necessary for distinguishing different operator priorities, hence different token types are\ndefined for each precedence level in the language, even\nthough they perform the same role from a conceptual\npoint of view. The order in which they are declared in\nthe yacc specification determines their relative priorities\n(please, note that these declarations are also employed to\ndefine operator associativity).\nUnfortunately, the requirement to resolve ambiguities\nby refactoring the grammar defining the language involves the introduction of a certain degree of duplication\nin the language specification: separate token types in the\n\n\f17\n<Expression> ::=\n|\n|\n|\n\n<ParenthesizedExpression>\n<BinaryExpression>\n<UnaryExpression>\n<LiteralExpression>\n\n<ParenthesizedExpression> ::= '(' <Expression> ')'\n<BinaryExpression> ::= <Expression> <BinaryOperator> <Expression>\n<UnaryExpression> ::= <UnaryOperator> <Expression>\n<LiteralExpression> ::= <RealLiteral>\n| <IntegerLiteral>\n<BinaryOperator> ::= '+' | '-' | '/' | '*'\n<UnaryOperator> ::= '+' | '-'\n<RealLiteral> ::= <IntegerLiteral> '.' | <IntegerLiteral> '.' <IntegerLiteral>\n<IntegerLiteral> ::= <Digit> <IntegerLiteral> | <Digit>\n<Digit> ::= '0' | '1' |'2' | '3' | '4' | '5' | '6' | '7' | '8' | '9'\n\nFigure 24 BNF grammar for the arithmetic expression language.\n\n// Lex specification ['calc.lex']\n%{\n#include \"y.tab.h\"\nextern YYSTYPE yylval;\n%}\n%%\n[0-9]+\\.[0.9]* return\n[0-9]+\nreturn\n\\+|\\return\n\\/|\\*\nreturn\n\\(\nreturn\n\\)\nreturn\n.\n;\n%%\n\nRealLiteral;\nIntegerLiteral;\nUnaryOrPriority2BinaryOperator;\nPriority1BinaryOperator;\nLeftParenthesis;\nRightParenthesis;\n\n// Yacc specification ['calc.yacc']\n%left UnaryOrPriority2BinaryOperator\n%left Priority1BinaryOperator\n%token IntegerLiteral RealLiteral LeftParenthesis RightParenthesis\n%start Expression\n%%\nExpression : RealLiteral\n| IntegerLiteral\n| LeftParenthesis Expression RightParenthesis\n| UnaryOrPriority2BinaryOperator Expression\n| Expression UnaryOrPriority2BinaryOperator Expression\n| Expression Priority1BinaryOperator Expression\n;\n%%\n#include \"lex.yy.c\"\nint main(int argc,char *argv[]) { yyparse(); }\nint yyerror(char *s) { printf(\"%s\",s); }\n\nFigure 25 lex & yacc specification of the arithmetic expression language.\n\n\f18\nlexer and multiple parallel production rules in the parser.\nOnce all ambiguities have been resolved, the language\ndesigner completes the lex & yacc introducing semantic\nactions to perform the necessary operations. In this case,\nalbeit somewhat verbose in C syntax, the implementation of an arithmetic expression evaluator is relatively\nstraightforward using the yacc $ notation, as shown in\nFigure 26. In our particular implementation of the calculator interpreter, carriage returns are employed to output results, hence our use of the ancillary Line token type\nand LineReturn nonterminal symbol.\n\n2. ANTLR implementation\n\nWhen using ANTLR, the language designer converts\nthe BNF grammar into a grammar suitable for LL parsing. An ANTLR specification of our arithmetic expression language is shown in Figure 27.\nSince ANTLR provides no mechanism for the declarative specification of token precedences, such precedences\nhave to be incorporated into the grammar. The usual solution involves the creation of different nonterminal symbols in the grammar, so that productions corresponding\nto the same precedence levels are grouped together. The\nproductions with expression1 and expression2 in their\nleft-hand side were introduced with this purpose in our\ncalculator grammar.\nLikewise, since ANTLR generates a LL(*) parser,\nwhich does not support left-recursion, left-recursive\ngrammar productions in the grammar shown in Figure\n24 have to be refactored. In our example, a simple solution involves the introduction of the expression3 nonterminal, which in conjunction with the aforementioned expression1 and expression2 nonterminals, eliminates leftrecursion from our grammar.\nOnce the grammar is adjusted to satisfy the constraints\nimposed by the ANTLR parser generator, the language\ndesigner can define the semantic actions needed to implement our arithmetic expression interpreter. The resulting ANTLR implementation is shown in Figure 28.\nThe streamlined syntax of the scannerless ANTLR parser\ngenerator makes this implementation significantly more\nconcise than the equivalent lex & yacc implementation.\nHowever, the constraints imposed by the underlying parsing algorithm forces explicit changes on the language\ngrammar (cf. BNF grammar in Figure 24).\n\nC. ModelCC Implementation\n\nWhen following a model-based language specification\napproach, the language designer starts by elaborating an\nabstract syntax model, which will later be mapped to\na concrete syntax model by imposing constraints on the\nabstract syntax model. These constraints can also be\nspecified as metadata annotations on the abstract syntax model and the resulting annotated model can be pro-\n\ncessed by automated tools, such as ModelCC, to generate\nthe corresponding lexers and parsers. Annotated models\ncan be represented graphically, as the UML diagram in\nFigure 29, or implemented using conventional programming languages, as the Java implementation listed in Figure 30.\nIn the current version of ModelCC, annotated models\nrepresenting the ASM and a particular ASM-CSM mapping are used to generate Lamb lexers [51] and Fence\nparsers [50], albeit traditional LL and LR parsers might\nalso be generated whenever the ASM-CSM mapping constraints make LL and LR parsing feasible.\nSince the abstract syntax model in ModelCC is not\nconstrained by the vagaries of particular parsing algorithms, the language design process can be focused on its\nconceptual design, without having to introduce artifacts\nin the design just to satisfy the demands of particular\ntools:\n\u2022 As we saw in the lex & yacc example, conventional\ntools, unless they are scannerless, force the creation\nof artificial token types in order to avoid lexical ambiguities, which leads to duplicate grammar production rules and semantic actions in the language\nspecification. As in any other software development\nproject, duplication hinders the evolution of languages and affects the maintainability of language\nprocessors. ModelCC, even though it is not scannerless, supports lexical ambiguities and each basic language element is defined as a separate and\nindependent entity, even when their pattern specification are in conflict. Therefore, duplication in\nthe language model does not have to be included\nto deal with lexical ambiguities: token type definitions do not have to be adjusted, duplicate syntactic constructs rules will not appear in the language\nmodel, and, as a consequence, semantic actions do\nnot have to be duplicated either.\n\u2022 As we also saw both in the lex & yacc calculator and in the ANTLR solution to the same problem, established parser generators require modifications to the language grammar specification in\norder to comply with parsing constraints, let it be\nthe elimination of left-recursion for LL parsers or\nthe introduction of new nonterminals to restructure the language specification so that the desired\nprecedence relationships are fulfilled. In the modeldriven language specification approach, the leftrecursion problem disappears since it is something\nthe underlying tool can easily deal with in a fully\nautomated way when an abstract syntax model is\nconverted into a concrete syntax model. Moreover,\nthe declarative specification of constraints, such as\nthe evaluation order constraints in Section V.D, is\northogonal to the abstract syntax model that defines the language. Those constraints determine\nthe ASM-CSM mapping and, since ModelCC takes\ncharge of everything in that conversion process, the\n\n\f19\n// Lex specification ['calc.lex']\n%{\n#include \"string.h\"\n#include \"y.tab.h\"\nextern YYSTYPE yylval;\n%}\n%%\n[0-9]+\\.[0.9]* { yylval.value = atof(yytext); return RealLiteral; }\n[0-9]+\n{ yylval.value = (double)atoi(yytext); return IntegerLiteral; }\n\\+|\\{\nif (yytext[0] == '+') yylval.operator = PLUSORADDITION;\nelse /* yytext[0] == '-' */ yylval.operator = MINUSORSUBSTRACTION;\nreturn UnaryOrPriority2BinaryOperator;\n}\n\\/|\\*\n{\nif (yytext[0] == '*') yylval.operator = MULTIPLICATION;\nelse /* yytext[0] == '/' */ yylval.operator = DIVISION;\nreturn Priority1BinaryOperator;\n}\n\\(\n{ return LeftParenthesis; }\n\\)\n{ return RightParenthesis; }\n\\n\n{ return LineReturn; }\n.\n;\n%%\n\n// Yacc specification ['calc.yacc']\n%left UnaryOrPriority2BinaryOperator\n%left Priority1BinaryOperator\n%token IntegerLiteral RealLiteral LeftParenthesis RightParenthesis\n%start Line\n%{\n#include <stdio.h>\n#define YYSTYPE attributes\ntypedef enum { PLUSORADDITION, MINUSORSUBSTRACTION, MULTIPLICATION, DIVISION } optype;\ntypedef struct {\noptype operator;\ndouble value;\n} attributes;\n%}\n%%\nExpression : RealLiteral\n{ $$.value = $1.value; }\n| IntegerLiteral\n{ $$.value = $1.value; }\n| LeftParenthesis Expression RightParenthesis { $$.value = $2.value; }\n| UnaryOrPriority2BinaryOperator Expression\n{\nif ($1.operator == PLUSORADDITION) $$.value = $2.value;\nelse /* $1.operator == MINUSORSUBSTRACTION */ $$.value = -$2.value;\n}\n| Expression UnaryOrPriority2BinaryOperator Expression\n{\nif ($2.operator == PLUSORADDITION) $$.value = $1.value+$3.value;\nelse /* $2.operator == MINUSORSUBSTRACTION */ $$.value = $1.value-$3.value;\n}\n| Expression Priority1BinaryOperator Expression\n{\nif ($2.operator == MULTIPLICATION) $$.value = $1.value*$3.value;\nelse /* $2.operator == DIVISION */ $$.value = $1.value/$3.value;\n}\n;\nLine\n: Expression LineReturn { printf(\"%f\\n\",$1.value); } ;\n%%\n#include \"lex.yy.c\"\nint main(int argc,char *argv[]) { yyparse(); }\nint yyerror(char *s) { printf(\"%s\",s); }\n\nFigure 26 Complete lex & yacc implementation of the arithmetic expression interpreter.\n\n\f20\n\ngrammar ExpressionEvaluator;\nexpression1 : expression2 ( '+' expression1 | '-' expression1 )* ;\nexpression2 : expression3 ( '*' expression2 | '/' expression2 )* ;\nexpression3 :\n|\n|\n|\n|\n;\n\n'(' expression1 ')'\n'+' expression1\n'-' expression1\nINTEGERLITERAL\nFLOATLITERAL\n\nINTEGERLITERAL : '0'..'9'+ ;\nFLOATLITERAL : ('0'..'9')+ '.' ('0'..'9')* ;\nNEWLINE : '\\r'? '\\n' ;\n\nFigure 27 ANTLR specification of the arithmetic expression language.\n\ngrammar ExpressionEvaluator;\nexpression1 returns [double value]\n: e=expression2 {$value = $e.value;}\n( '+' e2=expression1 {$value += $e2.value;}\n| '-' e2=expression1 {$value -= $e2.value;}\n)*\n;\nexpression2 returns [double value]\n: e=expression3 {$value = $e.value;}\n( '*' e2=expression2 {$value *= $e2.value;}\n| '/' e2=expression2 {$value -= $e2.value;}\n)*\n;\nexpression3 returns [double value]\n: '(' e=expression1 ')' {$value = $e.value;}\n| '+' e=expression1 {$value = $e.value;}\n| '-' e=expression1 {$value = -$e.value;}\n| i=INTEGERLITERAL {$value = (double)Integer.parseInt($i.text);}\n| f=FLOATLITERAL {$value = Double.parseDouble($f.text);}\n;\nINTEGERLITERAL : '0'..'9'+ ;\nFLOATLITERAL : ('0'..'9')+ '.' ('0'..'9')* ;\nNEWLINE : '\\r'? '\\n' ;\n\nFigure 28 Complete ANTLR implementation of the arithmetic expression interpreter.\n\n\f21\n-e1\n\n-exp\n\nExpression\n~ eval() : double\n\n-e2\n\n-exp\n\nLiteralExpression\n@Suffix(\")\")\n@Prefix(\"(\")\nIn teger Liter al\n- @Value value : in t\n\nRealLiter al\n- @Value value : double\n\nPar en th esizedExpr ession\n- exp : Expression\n\nBin ar yExpr ession\n- e1 : Expression\n- op : Bin aryOperator\n- e2 : Expression\n-op\n\nUn ar yExpr ession\n- op : Un aryOperator\n- exp : Expression\n-op\n\n@Associativity(LEFT_TO_RIGHT)\nBinaryOperator\n\nUnaryOperator\n\n~ eval(e1,e2 : Expression) : double\n\n~ eval(e : Expression ) : double\n\n@Priority(2)\n@Pattern (regExp=\"\\+\")\nAddition Oper ator\n@Priority(1)\n@Pattern (regExp=\"\\/\")\nDivision Oper ator\n\n@Priority(2)\n@Pattern (regExp=\"-\")\nSubstr action Oper ator\n@Priority(1)\n@Pattern (regExp=\"\\*\")\n\n@Pattern (regExp=\"\\+\")\nPlusOper ator\n\n@Pattern (regExp=\"-\")\n\nMultiplication Oper ator\n\nMin usOper ator\n\nFigure 29 ModelCC specification of the arithmetic expression language.\n\nlanguage designer does not have to modify the abstract syntax model just because a given parser\ngenerator might prefer its input in a particular format. This is the main benefit that results from\nraising your abstraction level in model-based language specification.\n\u2022 When changes in the language specification are necessary, as it is often the case when a software system\nis successful, the traditional language designer will\nhave to propagate changes throughout the entire\nlanguage processing tool chain, often introducing\nsignificant changes and making profound restructurings in the working code base. The changes can\nbe time-consuming, quite tedious, and extremely\nerror-prone. In contrast, modifications are more\neasily done when a model-driven language specification approach is followed. Any modifications in\na language will affect either to the abstract syntax model, when new capabilities are incorporated\ninto a language, or to the constraints that define\nthe ASM-CSM mapping, whenever syntactic details change or new CSMs are devised for the same\nASM. In either case, the more time-consuming, tedious, and error-prone modifications are automated\nby ModelCC, whereas the language designer can focus his efforts on the essential part of the required\nchanges.\n\u2022 Finally, traditional parser generators typically mix\n\nsemantic actions with the syntactic details of the\nlanguage specification. This approach, which is justified when performance is the top concern, might\nlead to poorly-designed hard-to-test systems when\nnot done with extreme care. Moreover, when different applications or tools employ the same language,\nany changes to the syntax of that language have to\nbe replicated in all the applications and tools that\nuse the language. The maintenance of several versions of the same language specification in parallel\nmight also lead to severe maintenance problems.\nIn contrast, the separation of concerns provided by\nModelCC, as separate ASM and ASM-CSM mappings, promotes a more elegant design for language\nprocessing systems. By decoupling language specification from language processing and providing a\nconceptual model for the language, different applications and tools can now use the same language\nwithout having duplicate language specifications.\nA similar result could be hand-crafted using traditional parser generators (i.e. making their implicit\nconceptual model explicit and working on that explicit model), but ModelCC automates this part of\nthe process.\nIn summary, while traditional language processing\ntools provide different mechanisms for resolving ambiguities and implementing language constraints, the solutions they provide typically interfere with the conceptual\nmodeling of languages: relatively minor syntactic details\n\n\f22\npublic abstract class Expression implements IModel {\npublic abstract double eval();\n}\n@Prefix(\"\\\\(\") @Suffix(\"\\\\)\")\npublic class ParenthesizedExpression extends Expression implements IModel {\nExpression e;\n@Override public double eval() { return e.eval(); }\n}\npublic abstract class LiteralExpression extends Expression implements IModel {\n}\npublic class UnaryExpression extends Expression implements IModel {\nUnaryOperator op;\nExpression e;\n@Override public double eval() { return op.eval(e); }\n}\npublic class BinaryExpression extends Expression implements IModel {\nExpression e1;\nBinaryOperator op;\nExpression e2;\n@Override public double eval() { return op.eval(e1,e2); }\n}\npublic class IntegerLiteral extends LiteralExpression implements IModel {\n@Value int value;\n@Override public double eval() { return (double)value; }\n}\npublic class RealLiteral extends LiteralExpression implements IModel {\n@Value double value;\n@Override public double eval() { return value; }\n}\npublic abstract class UnaryOperator implements IModel {\npublic abstract double eval(Expression e);\n}\n@Pattern(regExp=\"\\\\+\")\npublic class PlusOperator extends UnaryOperator implements IModel {\n@Override public double eval(Expression e) { return e.eval(); }\n}\n@Pattern(regExp=\"-\")\npublic class MinusOperator extends UnaryOperator implements IModel {\n@Override public double eval(Expression e) { return -e.eval(); }\n}\n@Associativity(AssociativityType.LEFT_TO_RIGHT)\npublic abstract class BinaryOperator implements IModel {\npublic abstract double eval(Expression e1,Expression e2);\n}\n@Priority(value=2) @Pattern(regExp=\"\\\\+\")\npublic class AdditionOperator extends BinaryOperator implements IModel {\n@Override public double eval(Expression e1,Expression e2) { return e1.eval()+e2.eval(); }\n}\n@Priority(value=2) @Pattern(regExp=\"-\")\npublic class SubstractionOperator extends BinaryOperator implements IModel {\n@Override public double eval(Expression e1,Expression e2) { return e1.eval()-e2.eval(); }\n}\n@Priority(value=1) @Pattern(regExp=\"\\\\*\")\npublic class MultiplicationOperator extends BinaryOperator implements IModel {\n@Override public double eval(Expression e1,Expression e2) { return e1.eval()*e2.eval(); }\n}\n@Priority(value=1) @Pattern(regExp=\"\\\\/\")\npublic class DivisionOperator extends BinaryOperator implements IModel {\n@Override public double eval(Expression e1,Expression e2) { return e1.eval()/e2.eval(); }\n}\n\nFigure 30 Complete Java implementation of the arithmetic expression interpreter using ModelCC: A set of Java classes define\nthe language ASM, metadata annotations specify the desired ASM-CSM mapping, and object methods implement arithmetic\nexpression evaluation.\n\n\f23\nmight significantly affect the structure of the whole language specification. Model-driven language specification,\nas exemplified by ModelCC, provides a cleaner separation\nof concerns: the abstract syntax model is kept separate\nfrom its incarnation in concrete syntax models, thereby\nseparating the specification of abstractions in the ASM\nfrom the particularities of their textual representation in\nCSMs.\n\nWe plan to study the possibilities tools such as ModelCC open up in different application domains, including traditional language processing systems (compilers\nand interpreters) [3], domain-specific languages (DSLs)\n[19, 25, 41] and language workbenches [18], model-driven\nsoftware development (MDSD) tools [54][21], natural language processing [29] in restricted domains, model induction, text mining applications, data integration, and\ninformation extraction.\n\nVII. CONCLUSIONS AND FUTURE WORK\n\nIn this paper, we have introduced ModelCC, a modelbased tool for language specification. ModelCC lets language designers create explicit models of the concepts\na language represents, i.e. the abstract syntax model\n(ASM) of the language. Then, that abstract syntax\ncan be represented in textual or graphical form, using\nthe concrete syntax defined by a concrete syntax model\n(CSM). ModelCC automates the ASM-CSM mapping by\nmeans of metadata annotations on the ASM, which let\nModelCC act as a model-based parser generator.\nModelCC is not bound to particular scanning and parsing techniques, so that language designers do not have to\ntweak their models to comply with the constraints imposed by particular parsing algorithms. ModelCC abstracts away many details traditional language processing tools have to deal with. It cleanly separates language specification from language processing. Given\nthe proper ASM-CSM mapping definition, ModelCCgenerated parsers are able to automatically instantiate\nthe ASM given an input string representing the ASM in\na concrete syntax.\nApart from being able to deal with ambiguous languages, ModelCC also allows the declarative resolution of\nany language ambiguities by means of constraints defined\nover the ASM. The current version of ModelCC also supports lexical ambiguities and custom pattern matching\nclasses. A fully-functional version of ModelCC is available at http://www.modelcc.org.\nThe proposed model-driven language specification approach promotes the domain-driven design of language\nprocessors. Its model-driven philosophy supports language evolution by improving the maintainability of languages processing system. It also facilitates the reuse of\nlanguage specifications across product lines and different applications, eliminating the duplication required by\nconventional tools and improving the modularity of the\nresulting systems.\nIn the future, ModelCC will incorporate a wider variety\nof parsing techniques and it will be able to automatically\ndetermine the most efficient parsing algorithm that is\nable to parse a particular language (the current version\nemploys the Fence parsing algorithm [50] on top of the\nLamb scanning algorithm [51]).\nModelCC will also be extended to support multiple\nconcrete syntax models for the same abstract syntax\nmodel.\n\nReferences\n[1] Harold Abelson and Gerald J. Sussman. Structure and\nInterpretation of Computer Programs. MIT Press, 2nd\nedition, 1996.\n[2] A. V. Aho, S. C. Johnson, and J. D. Ullman. Deterministic parsing of ambiguous grammars. Communications\nof the ACM, 18(8):441\u2013452, 1975.\n[3] Alfred V. Aho, Monica S. Lam, Ravi Sethi, and Jeffrey D.\nUllman. Compilers: Principles, Techniques, and Tools.\nAddison Wesley, 2nd edition, 2006.\n[4] Alfred V. Aho and Jeffrey D. Ullman. The Theory of\nParsing, Translation, and Compiling, Volume I: Parsing\n& Volume II: Compiling. Prentice Hall, Englewood Cliffs,\nN.J., 1972.\n[5] Fernando Berzal, Juan-Carlos Cubero, Nicol\u00e1s Mar\u0131\u0301n,\nand Mar\u0131\u0301a-Amparo Vila. Lazy types: Automating dynamic strategy selection. IEEE Software, 22(5):98\u2013106,\n2005.\n[6] Noam Chomsky. Three models for the description of\nlanguage. IRE Transactions on Information Theory,\n2(2):113\u2013123, 1956.\n[7] John Cocke and Jacob T. Schwartz. Programming languages and their compilers: Preliminary notes. Technical\nreport, Courant Institute of Mathematical Sciences, New\nYork University, 1970.\n[8] F. L. DeRemer. Practical translators for LR(k) languages. Technical report, Cambridge, MA, USA, 1969.\n[9] Franklin L. DeRemer. Simple LR(k) grammars. Communications of the ACM, 14(7):453\u2013460, 1971.\n[10] Franklin L. DeRemer and Thomas Pennello. Efficient\ncomputation of LALR(1) look-ahead sets. ACM Transactions on Programming Languages and Systems, 4(4):615\u2013\n649, 1982.\n[11] Jay Earley. An efficient context-free parsing algorithm.\nCommunications of the ACM, 13(2):94\u2013102, 1970.\n[12] Jay Earley. Ambiguity and precedence in syntax description. Acta Informatica, 4(2):183\u2013192, 1975.\n[13] Hartmut Ehrig and Gabriele Taentzer. Graphical representation and graph transformation. ACM Computing\nSurveys, vol. 31, no. 3es, art. 9, 1999.\n[14] Eric Evans. Domain-Driven Design: Tackling Complexity in the Heart of Software. Addison-Wesley, 2003.\n[15] Bryan Ford. Packrat parsing: Simple, powerful, lazy, linear time. In Proceedings of the 7th ACM SIGPLAN International Conference on Functional Programming, ICFP\n'02, pages 36\u201347, 2002.\n\n\f24\n[16] Bryan Ford. Parsing expression grammars: a recognitionbased syntactic foundation. In Proceedings of the 31st\nACM SIGPLAN-SIGACT Symposium on Principles of\nProgramming Languages, POPL '04, pages 111\u2013122,\n2004.\n[17] Martin Fowler.\nUsing metadata.\nIEEE Software,\n19(6):13\u201317, November 2002.\n[18] Martin Fowler.\nLanguage workbenches:\nThe\nkiller-app\nfor\ndomain\nspecific\nlanguages?,\n2005.\nhttp://martinfowler.com/articles/languageWorkbench.html.\n[19] Martin Fowler. Domain-Specific Languages. AddisonWesley Signature Series, 2010.\n[20] Erich Gamma, Richard Helm, Ralph Johnson, and John\nVlissides. Design patterns: Elements of reusable objectoriented software. Addison-Wesley, 1995.\n[21] Juli\u00e1n Garrido, M. \u00c1ngeles Martos, and Fernando\nBerzal. Model-driven development using standard tools.\nIn Proceedings of the 9th International Conference on\nEnterprise Information Systems, volume DISI of IDEAL\n2007, pages 433\u2013436, 2007.\n[22] Seymour Ginsburg. Algebraic and automata theoretic\nproperties of formal languages. North-Holland, 1975.\n[23] Robert Grimm. Better extensibility through modular\nsyntax. In Proceedings of the 2006 ACM SIGPLAN\nConference on Programming Language Design and Implementation, PLDI '06, pages 38\u201351, 2006.\n[24] Michael A. Harrison. Introduction to Formal Language\nTheory. Reading, Mass: Addison-Wesley Publishing\nCompany, 1978.\n[25] Paul Hudak. Building domain-specific embedded languages. ACM Computing Surveys, vol. 28, no. 4es, art.\n196, 1996.\n[26] Masayuki Ishii, Kazuhisa Ohta, and Hiroaki Saito. An\nefficient parser generator for natural language. In Proceedings of the 15th Conference on Computational Linguistics, volume 1, pages 417\u2013420, 1994.\n[27] Stanislaw Jarzabek and Tomasz Krawczyk. LL-Regular\ngrammars. Information Processing Letters, 4(2):31 \u2013 37,\n1975.\n[28] Stephen C. Johnson. YACC: Yet another compiler compiler. Computing Science Technical Report 32, AT&T\nBell Laboratories, 1979.\n[29] Daniel Jurafsky and James H. Martin. Speech and Language Processing: An Introduction to Natural Language\nProcessing, Computational Linguistics and Speech Recognition. Prentice Hall, 2nd edition, 2009.\n[30] Tadao Kasami. An efficient recognition and syntaxanalysis algorithm for context-free languages. Scientific\nreport AFCRL-65-758, Air Force Cambridge Research\nLab, Bedford, MA., 1965.\n[31] Lennart C. L. Kats, Eelco Visser, and Guido Wachsmuth.\nPure and declarative syntax definition: Paradise lost and\nregained. In Proceedings of the ACM International Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA'10), pages 918\u2013932,\n2010.\n[32] Anneke Kleppe. Towards the generation of a text-based\nIDE from a language metamodel. volume 4530 of Lecture\n\nNotes in Computer Science, pages 114\u2013129, 2007.\n[33] Donald E. Knuth. On the translation of languages from\nleft to right. Information and Control, 8(6):607\u2013639,\n1965.\n[34] Bernard Lang. Deterministic techniques for efficient nondeterministic parsers. In J. Loeckx, editor, Automata,\nLanguages and Programming, volume 14 of Lecture Notes\nin Computer Science, pages 255\u2013269. Springer Berlin /\nHeidelberg, 1974.\n[35] M. E. Lesk and E. Schmidt. Lex: A lexical analyzer\ngenerator. Technical report, AT&T Bell Laboratories,\n1975.\n[36] John R. Levine, Tony Mason, and Doug Brown. lex &\nyacc. O'Reilly, 2nd edition, 1992.\n[37] P. M. Lewis, II and R. E. Stearns. Syntax-directed transduction. Journal of the ACM, 15(3):465\u2013488, 1968.\n[38] Chuck McManis.\nLooking for lex and yacc for\nJava?\nyou don't know jack, 1996.\nJavaWorld,\nwww.javaworld.com/javaworld/jw-12-1996/jw-12jack.html.\n[39] R. McNaughton and H. Yamada. Regular expressions\nand state graphs for automata. IRE Transactions on\nElectronic Computers, EC-9(1):38\u201347, 1960.\n[40] Scott McPeak and George C. Necula. Elkhound: A\nfast, practical GLR parser generator. In Proceedings of\nthe International Conference on Compiler Constructor\n(CC04), volume 2985 of Lecture Notes in Computer Science, pages 73\u201388. Springer, 2004.\n[41] Marjan Mernik, Jan Heering, and Anthony M. Sloane.\nWhen and how to develop domain-specific languages.\nACM Computing Surveys, 37(4):316\u2013344, 2005.\n[42] Rick Mugridge and Ward Cunningham. Fit for Developing Software: Framework for Integrated Tests (Robert C.\nMartin). Prentice Hall PTR, 2005.\n[43] Jerzy R. Nawrocki. Conflict detection and resolution in\na lexical analyzer generator. Information Processing Letters, 38(6):323\u2013328, 1991.\n[44] Anton Nijholt. On the parsing of LL-Regular grammars.\nIn Antoni Mazurkiewicz, editor, Mathematical Foundations of Computer Science 1976, volume 45 of Lecture\nNotes in Computer Science, pages 446\u2013452. Springer\nBerlin / Heidelberg, 1976.\n[45] Rahman Nozohoor-Farshi. GLR parsing for epsilongrammars. In Masaru Tomita, editor, Generalized LR\nParsing, pages 61\u201376. Kluwer, 1991.\n[46] A. Oettinger. Automatic syntactic analysis and the pushdown store. In Proceedings of the 12th Symposium in\nApplied Mathematics, pages 104\u2013129, 1961.\n[47] Terence Parr and Kathleen Fisher. LL(*): The foundation of the ANTLR parser generator. In Proceedings of\nthe 32nd ACM SIGPLAN Conference on Programming\nLanguage Design and Implementation, PLDI '11, pages\n425\u2013436, 2011.\n[48] Terence J. Parr and Russell W. Quong. ANTLR: A\nPredicated-LL(k) parser generator. Software Practice\nand Experience, 25(7):789\u2013810, 1995.\n[49] Jaroslav Porub\u00e4n, Michal Forg\u00e1\u010d, and Miroslav Sabo.\nAnnotation-based parser generator. In Proceedings of the\nInternational Multiconference on Computer Science and\n\n\f25\nInformation Technology, IEEE Computer Society Press,\nvolume 4, pages 705\u2013712, 2009.\n[50] Luis Quesada, Fernando Berzal, and Francisco J. Cortijo. Fence: An efficient parser with ambiguity support\nfor model-driven language specification. ArXiv e-prints,\n2011. http://arxiv.org/abs/1107.4687.\n[51] Luis Quesada, Fernando Berzal, and Francisco J. Cortijo.\nLamb: A lexical analyzer with ambiguity support. In\nProceedings of the 6th International Conference on Software and Data Technologies, 2011. (in press).\n[52] Luis Quesada, Fernando Berzal, and Juan-Carlos\nCubero. A language specification tool for model-based\nparsing. In Proceedings of the 12th International Conference on Intelligent Data Engineering and Automated\nLearning, Lecture Notes in Computer Science, 2011. (in\npress).\n\n[53] Jan Rekers. Parser Generation for Interactive Environments. PhD thesis, University of Amsterdam, 1992.\n[54] Douglas C. Schmidt. Model-driven engineering. IEEE\nComputer, 39(2):25\u201331, 2006.\n[55] Masaru Tomita. Efficient Parsing for Natural Language:\nA Fast Algorithm for Practical Systems. Kluwer Academic Publishers, 1985.\n[56] Masaru Tomita and Jaime G. Carbonell. The universal\nparser architecture for knowledge-based machine translation. In Proceedings of the 10th International Joint Conference on Artificial Intelligence, volume 2, pages 718\u2013\n721, 1987.\n[57] Daniel H. Younger. Recognition and parsing of contextfree languages in time n3 . Information and Control,\n10:189\u2013208, 1967.\n\n\f"}