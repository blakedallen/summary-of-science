{"id": "http://arxiv.org/abs/astro-ph/0307219v1", "guidislink": true, "updated": "2003-07-10T17:26:09Z", "updated_parsed": [2003, 7, 10, 17, 26, 9, 3, 191, 0], "published": "2003-07-10T17:26:09Z", "published_parsed": [2003, 7, 10, 17, 26, 9, 3, 191, 0], "title": "An improved Markov-chain Monte Carlo sampler for the estimation of\n  cosmological parameters from CMB data", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=astro-ph%2F0307188%2Castro-ph%2F0307012%2Castro-ph%2F0307219%2Castro-ph%2F0307395%2Castro-ph%2F0307461%2Castro-ph%2F0307006%2Castro-ph%2F0307181%2Castro-ph%2F0307101%2Castro-ph%2F0307439%2Castro-ph%2F0307390%2Castro-ph%2F0307541%2Castro-ph%2F0307275%2Castro-ph%2F0307078%2Castro-ph%2F0307441%2Castro-ph%2F0307166%2Castro-ph%2F0307111%2Castro-ph%2F0307067%2Castro-ph%2F0307120%2Castro-ph%2F0307557%2Castro-ph%2F0307460%2Castro-ph%2F0307365%2Castro-ph%2F0307407%2Castro-ph%2F0307090%2Castro-ph%2F0307433%2Castro-ph%2F0307117%2Castro-ph%2F0307178%2Castro-ph%2F0307040%2Castro-ph%2F0307307%2Castro-ph%2F0307119%2Castro-ph%2F0307193%2Castro-ph%2F0307463%2Castro-ph%2F0307426%2Castro-ph%2F0307392%2Castro-ph%2F0307399%2Castro-ph%2F0307155%2Castro-ph%2F0307339%2Castro-ph%2F0307259%2Castro-ph%2F0307221%2Castro-ph%2F0307340%2Castro-ph%2F0307256%2Castro-ph%2F0307141%2Castro-ph%2F0307107%2Castro-ph%2F0307038%2Castro-ph%2F0307370%2Castro-ph%2F0307115%2Castro-ph%2F0307124%2Castro-ph%2F0307175%2Castro-ph%2F0307085%2Castro-ph%2F0307362%2Castro-ph%2F0307195%2Castro-ph%2F0307381%2Castro-ph%2F0307429%2Castro-ph%2F0307492%2Castro-ph%2F0307351%2Castro-ph%2F0307069%2Castro-ph%2F0307105%2Castro-ph%2F0307281%2Castro-ph%2F0307157%2Castro-ph%2F0307427%2Castro-ph%2F0307062%2Castro-ph%2F0307320%2Castro-ph%2F0307505%2Castro-ph%2F0307348%2Castro-ph%2F0307049%2Castro-ph%2F0307350%2Castro-ph%2F0307436%2Castro-ph%2F0307334%2Castro-ph%2F0307506%2Castro-ph%2F0307294%2Castro-ph%2F0307500%2Castro-ph%2F0307036%2Castro-ph%2F0307187%2Castro-ph%2F0307163%2Castro-ph%2F0307295%2Castro-ph%2F0307102%2Castro-ph%2F0307199%2Castro-ph%2F0307520%2Castro-ph%2F0307034%2Castro-ph%2F0307205%2Castro-ph%2F0307472%2Castro-ph%2F0307145%2Castro-ph%2F0307213%2Castro-ph%2F0307296%2Castro-ph%2F0307230%2Castro-ph%2F0307216%2Castro-ph%2F0307200%2Castro-ph%2F0307084%2Castro-ph%2F0307030%2Castro-ph%2F0307554%2Castro-ph%2F0307361%2Castro-ph%2F0307222%2Castro-ph%2F0307106%2Castro-ph%2F0307453%2Castro-ph%2F0307359%2Castro-ph%2F0307475%2Castro-ph%2F0307389%2Castro-ph%2F0307539%2Castro-ph%2F0307550%2Castro-ph%2F0307198%2Castro-ph%2F0307047%2Castro-ph%2F0307456&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "An improved Markov-chain Monte Carlo sampler for the estimation of\n  cosmological parameters from CMB data"}, "summary": "Markov-chain Monte Carlo sampling has become a standard technique for\nexploring the posterior distribution of cosmological parameters constrained by\nobservations of CMB anisotropies. Given an infinite amount of time, any MCMC\nsampler will eventually converge such that its stationary distribution is the\nposterior of interest. In practice, however, naive samplers require a\nconsiderable amount of time to explore the posterior distribution fully. In the\nbest case, this results only in wasted CPU time, but in the worse case can lead\nto underestimated confidence limits on the values of cosmological parameters.\nEven for the current CMB data set, the sampler employed in the widely-used\ncosmomc package does not sample very efficiently. This difficulty is yet more\npronounced for data sets of the quality anticipated for the Planck mission. We\nthus propose a new MCMC sampler for analysing total intensity CMB observations,\nwhich can be easily incorporated into the cosmomc software, but has rapid\nconvergence and produces reliable confidence limits. This is achieved by using\ndynamic widths for proposal distributions, dynamic covariance matrix sampling,\nand a dedicated proposal distribution for moving along well-known degeneracy\ndirections.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=astro-ph%2F0307188%2Castro-ph%2F0307012%2Castro-ph%2F0307219%2Castro-ph%2F0307395%2Castro-ph%2F0307461%2Castro-ph%2F0307006%2Castro-ph%2F0307181%2Castro-ph%2F0307101%2Castro-ph%2F0307439%2Castro-ph%2F0307390%2Castro-ph%2F0307541%2Castro-ph%2F0307275%2Castro-ph%2F0307078%2Castro-ph%2F0307441%2Castro-ph%2F0307166%2Castro-ph%2F0307111%2Castro-ph%2F0307067%2Castro-ph%2F0307120%2Castro-ph%2F0307557%2Castro-ph%2F0307460%2Castro-ph%2F0307365%2Castro-ph%2F0307407%2Castro-ph%2F0307090%2Castro-ph%2F0307433%2Castro-ph%2F0307117%2Castro-ph%2F0307178%2Castro-ph%2F0307040%2Castro-ph%2F0307307%2Castro-ph%2F0307119%2Castro-ph%2F0307193%2Castro-ph%2F0307463%2Castro-ph%2F0307426%2Castro-ph%2F0307392%2Castro-ph%2F0307399%2Castro-ph%2F0307155%2Castro-ph%2F0307339%2Castro-ph%2F0307259%2Castro-ph%2F0307221%2Castro-ph%2F0307340%2Castro-ph%2F0307256%2Castro-ph%2F0307141%2Castro-ph%2F0307107%2Castro-ph%2F0307038%2Castro-ph%2F0307370%2Castro-ph%2F0307115%2Castro-ph%2F0307124%2Castro-ph%2F0307175%2Castro-ph%2F0307085%2Castro-ph%2F0307362%2Castro-ph%2F0307195%2Castro-ph%2F0307381%2Castro-ph%2F0307429%2Castro-ph%2F0307492%2Castro-ph%2F0307351%2Castro-ph%2F0307069%2Castro-ph%2F0307105%2Castro-ph%2F0307281%2Castro-ph%2F0307157%2Castro-ph%2F0307427%2Castro-ph%2F0307062%2Castro-ph%2F0307320%2Castro-ph%2F0307505%2Castro-ph%2F0307348%2Castro-ph%2F0307049%2Castro-ph%2F0307350%2Castro-ph%2F0307436%2Castro-ph%2F0307334%2Castro-ph%2F0307506%2Castro-ph%2F0307294%2Castro-ph%2F0307500%2Castro-ph%2F0307036%2Castro-ph%2F0307187%2Castro-ph%2F0307163%2Castro-ph%2F0307295%2Castro-ph%2F0307102%2Castro-ph%2F0307199%2Castro-ph%2F0307520%2Castro-ph%2F0307034%2Castro-ph%2F0307205%2Castro-ph%2F0307472%2Castro-ph%2F0307145%2Castro-ph%2F0307213%2Castro-ph%2F0307296%2Castro-ph%2F0307230%2Castro-ph%2F0307216%2Castro-ph%2F0307200%2Castro-ph%2F0307084%2Castro-ph%2F0307030%2Castro-ph%2F0307554%2Castro-ph%2F0307361%2Castro-ph%2F0307222%2Castro-ph%2F0307106%2Castro-ph%2F0307453%2Castro-ph%2F0307359%2Castro-ph%2F0307475%2Castro-ph%2F0307389%2Castro-ph%2F0307539%2Castro-ph%2F0307550%2Castro-ph%2F0307198%2Castro-ph%2F0307047%2Castro-ph%2F0307456&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Markov-chain Monte Carlo sampling has become a standard technique for\nexploring the posterior distribution of cosmological parameters constrained by\nobservations of CMB anisotropies. Given an infinite amount of time, any MCMC\nsampler will eventually converge such that its stationary distribution is the\nposterior of interest. In practice, however, naive samplers require a\nconsiderable amount of time to explore the posterior distribution fully. In the\nbest case, this results only in wasted CPU time, but in the worse case can lead\nto underestimated confidence limits on the values of cosmological parameters.\nEven for the current CMB data set, the sampler employed in the widely-used\ncosmomc package does not sample very efficiently. This difficulty is yet more\npronounced for data sets of the quality anticipated for the Planck mission. We\nthus propose a new MCMC sampler for analysing total intensity CMB observations,\nwhich can be easily incorporated into the cosmomc software, but has rapid\nconvergence and produces reliable confidence limits. This is achieved by using\ndynamic widths for proposal distributions, dynamic covariance matrix sampling,\nand a dedicated proposal distribution for moving along well-known degeneracy\ndirections."}, "authors": ["Anze Slosar", "Michael Hobson"], "author_detail": {"name": "Michael Hobson"}, "author": "Michael Hobson", "arxiv_comment": "8 pages, 6 figures, submitted to MNRAS", "links": [{"href": "http://arxiv.org/abs/astro-ph/0307219v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/astro-ph/0307219v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "astro-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "astro-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/astro-ph/0307219v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/astro-ph/0307219v1", "journal_reference": null, "doi": null, "fulltext": "Mon. Not. R. Astron. Soc. 000, 1\u20138 (2003)\n\nPrinted 6 December 2018\n\n(MN LATEX style file v2.2)\n\nAn improved Markov-chain Monte Carlo sampler for the estimation\nof cosmological parameters from CMB data\nAn\u017ee Slosar and M.P. Hobson\n\narXiv:astro-ph/0307219v1 10 Jul 2003\n\nAstrophysics Group, Cavendish Laboratory, Madingley Road, Cambridge CB3 0HE\n\nAccepted -; received -; in original form 6 December 2018\n\nABSTRACT\n\nMarkov-chain Monte Carlo sampling has become a standard technique for exploring the\nposterior distribution of cosmological parameters constrained by observations of CMB\nanisotropies. Given an infinite amount of time, any MCMC sampler will eventually converge\nsuch that its stationary distribution is the posterior of interest. In practice, however, naive\nsamplers require a considerable amount of time to explore the posterior distribution fully. In\nthe best case, this results only in wasted CPU time, but in the worse case can lead to underestimated confidence limits on the values of cosmological parameters. Even for the current\nCMB data set, the sampler employed in the widely-used COSMO - MC package does not sample\nvery efficiently. This difficulty is yet more pronounced for data sets of the quality anticipated\nfor the Planck mission. We thus propose a new MCMC sampler for analysing total intensity\nCMB observations, which can be easily incorporated into the COSMO - MC software, but has\nrapid convergence and produces reliable confidence limits. This is achieved by using dynamic\nwidths for proposal distributions, dynamic covariance matrix sampling, and a dedicated proposal distribution for moving along well-known degeneracy directions.\nKey words: cosmic microwave background \u2013 methods: data analysis \u2013 methods: statistical.\n\n1 INTRODUCTION\nMarkov-chain Monte Carlo (MCMC) sampling is a universal technique used to explore high-dimensional density fields and has\nseveral advantages over more conventional grid-based approaches\n(see, for example, Gilks, Richardson & Speigelhalter 1995). In an\nastrophysical context, the MCMC approach was first applied to the\ndetermination of cosmological parameters from estimates of the\ntotal intensity cosmic microwave background (CMB) power spectrum by Christensen et al. (2001) and Knox, Christensen & Skordis\n(2001). More recently Lewis & Bridle (2002) released the publiclyavailable COSMO - MC software package for this purpose. MCMC\nsampling methods have also recently been applied to the detection\nand characterisation of Sunyaev-Zel'dovich clusters in maps of primordial CMB anisotropies (Hobson & McLachlan 2002).\nIn an MCMC algorithm, a Markov chain is constructed whose\nequilibrium distribution is the density field (or posterior) of interest\np(x). Thus, after propagating the Markov chain for a given burn-in\nperiod, one obtains (correlated) samples from p(x), provided the\nMarkov chain has converged. A Markov chain is characterised by\nthe fact that the state xn+1 is drawn from a distribution (or transition kernel) that depends only on the previous state of the chain\nxn , and not on any earlier state. In its simplest form an MCMC\nsampler can be constructed using the Metropolis algorithm as follows. At each step n in the chain, the next state xn+1 is chosen by\nfirst sampling a candidate point x\u2032 from some symmetric proposal\ndistribution q(x|xn ) = q(xn |x), which may in general depend on the\n\ncurrent state of the chain xn . The candidate point x\u2032 is then accepted\nwith probability\n(\n1\nif p(x\u2032 ) > p(x),\n\u03b1=\n(1)\n\u2032\np(x)/p(x ) otherwise.\nIf the candidate point is accepted, the next state becomes xn+1 = x\u2032 ,\nbut if the candidate is rejected, the chain does not move, so xn+1 =\nxn . In the limit of infinite number of chain steps, the density of the\nsamples is proportional to the density p(x), provided the proposal\nfunction: (i) satisfies detailed balance, which requires that the probability of proposing x\u2032 from x is the same as probability to proposing x from x\u2032 , and (ii) is such that every point in the parameter space\nhas a finite probability of being proposed.\nGiven an infinite number of steps any sampler satisfying the\nabove conditions will eventually reach a converged state in which\nthe samples are representative of target density p(x). In practice,\nhowever, the number of steps required to achieve convergence and\nfully explore the target density can vary dramatically depending\non the form of the proposal distribution. A good proposal function\nproduces candidate points that have a high probability of being accepted and ensures good mobility of the chain around the target\ndensity.\nA common choice for the proposal function, used for example by Knox et al. (2001), is a multivariate Gaussian centred on\nthe current chain position, with fixed widths \u03c3i in each parameter direction. There are, however, some problems associated with\nusing this proposal function alone as the single MCMC 'engine'.\n\n\f2\n\nAn\u017ee Slosar and M.P. Hobson\n\nFirstly, the proposal widths must be chosen with considerable care\nand tailored to the application in hand. If the proposal widths are\nset too large, the acceptance rate will be very low, so that the chain\nremains stuck at a single point for a considerable number of steps,\nsometimes indefinitely in practical terms. On the other hand, if the\nproposal widths are too narrow, the acceptance rate will be high,\nbut the chain has a limited mobility because it effectively executes\na random walk and thus diffuses only very slowly around the target\ndensity. In particular, this can lead to severely underestimated confidence limits on parameters and spurious peaks in the sample distribution associated with the initial chain position. A second problem with the standard multivariate Gaussian proposal distribution is\nthat, in high-dimensional problems, the degeneracy directions often\ntake the form of small 'tunnels' in the target density, which are unlikely to be explored by chance. Even with appropriate proposal\nwidths the chain must 'zig-zag' through such structures and therefore these degeneracy directions are likely to be undersampled.\nIn an attempt to speed up the sampling process, the COSMO MC package (Lewis & Bridle 2002) employs an number of devices that improve upon the simple multivariate Gaussian proposal\nfunction; these are explained in Section 2 below. This widely-used\npackage has proved very successful in analysing CMB power spectrum measurements from ground-based and balloon-bourne experiments. Nevertheless, as we show in Section 4, with the inclusion of\nWMAP data (Bennett et al. 2003), which is cosmic variance limited out to l \u2248 350, the COSMO - MC sampler still suffers from a\nnumber of the disadvantages listed above. In particular, it produces\nmarginalised probability distributions for some cosmological parameters that yield underestimates of confidence limits by up to a\nfactor of two. This undersampling of the target density is yet more\npronounced for cosmic variance limited CMB data out to l \u2248 2000,\nas is expected from the Planck mission.\nIn this paper, we therefore present a new sampler module\n(called COG ) that is trivially substituted for the existing sampler in\nthe COSMO - MC software. This sampler employs a number of strategies to avoid the difficulties encountered in the use of the standard\nmultivariate Gaussian proposal function and the native COSMO - MC\nsampler. These strategies are explained in detail in Section 3, but\nthe single most important advantage of the COG sampler is its use\nof the very well-known cosmological parameter degeneracies for\nCMB data (Efstathiou & Bond 1999), hence ensuring good mobility around the target density. In Section 4, we test the COG sampler\non the current CMB data set and a simulated data set of the quality\nexpected from the Planck mission. In addition to producing reliable\nmarginalised distributions, the COG sampler also requires far fewer\nevaluations of theoretical Cl spectra to explore the target density\nfully, and therefore provides speed up by a factor \u223c 4 over the standard COSMO - MC software when analysing the current CMB data\nset. In the analysis of the Planck-like data set, this speed increase\nrises to a factor of \u223c 50. Our conclusions are presented in Section 5.\n\n2 THE COSMO-MC SAMPLER\nThe COSMO - MC sampler uses CAMB (Lewis, Challinor & Lasenby\n2000) as its underlying theoretical CMB power spectrum generator. The proposal density employed in this single-chain sampler is\nbased on a multivariate Gaussian, but is tailored specifically to exploit the difference between 'fast' and 'slow' parameters in CAMB,\nin order to increase the speed with which the target density may be\nsampled.\nAt any given point xn in the chain, it is much quicker to cal-\n\nculate the theoretical Cl spectrum (and hence the value of the posterior) at the next candidate point x\u2032 if some of the parameter values are the same for both points. In particular, since the perturbation evolution is assumed linear, once the transfer function for\neach wavenumber has been computed, it is fast to calculate the Cl\nspectrum corresponding to changes in any parameters governing\nthe initial primoridal power spectra of scalar and tensor perturbations; these are thus termed 'fast' parameters. On the other hand, if\none changes parameters governing the perturbation evolution, the\nresulting Cl spectrum will be much slower to compute since it requires a detailed recalculation of the linear physics; these are thus\ntermed 'slow' parameters.\nIn detail, the basic sampler works as follows. First it performs\nan initial sampling of the target density with a proposal density\nbased on a multivariate Gaussian distribution determined by a set\nof user defined proposal widths \u03c3i , one for each parameter. It begins\nby placing the parameters in random order in a 'queue'. If the first\nparameter in the queue is fast, all the fast parameters are updated\nto obtain the next candidate point x\u2032 . If the first parameter in the\nqueue is slow, both this parameter and the next 0\u20132 parameters in\nthe queue are updated (the number of additionally updated parameters being drawn randomly from a uniform distribution). In either\ncase, the corresponding candidate point is then either accepted or\nrejected in the usual manner. In subsequent iterations, the above\nprocess is repeated, each time starting from the next parameter in\nthe queue. Once the entire queue has been looped over twice, the\nparameter order is again randomly reshuffled, and the process repeated. For each parameter that is updated, the new parameter value\nis drawn from a Gaussian distribution centred\nat the present pa\u221a\nrameter value and having width \u03c3\u2032i = \u03c3i / N,\n\u221a where N is the total\nnumber of parameters changed. The extra 1/ N factor ensures that\nproposals in which many parameters change still have a reasonable\nacceptance rate.\nAfter the initial sampling stage, one then has the option of performing a complete resampling of the the target distribution using\ninformation gained from the inital stage. In particular, the empirical covariance matrix of the initial set of samples is calculated,\nwhich is then diagonalised to obtain a set of principal directions\nwhich are taken as the new 'parameters'. These new parameters\nare then placed in random order in a queue as above, and at each\nproposal between 1 and 3 of them are updated (the precise number of updated parameters again being chosen at random). Each\ntime the queue has been looped through twice, it is again randomly\nreshuffled. We note that a covariance matrix for the standard 6parameter inflationary flat \u039bCDM model is provided in advance in\nthe COSMO - MC package. Thus, in this case, one can dispense with\nthe initial sampling stage altogether.\nIn spite of the increased sampling speed achieved by the above\ndevices, this basic sampler still suffers from the difficulties discussed in Section 1 Most notably, the user-supplied proposal widths\n\u03c3i must still be chosen with considerable care to avoid acceptance\nrates that are either too low (so the chain becomes stuck) or too\nhigh (so the chain mobility is limited, leading to underestimated\nconfidence limits). Also, the use of a multivariate Gaussian proposal function can lead to undersampling along narrow degeneracy\ndirections.\n\n3 THE COG SAMPLER\nThe\nthe\n\nCOG\n\nsampler is a replacement MCMC engine for\nsoftware. It may be downloaded from\n\nCOSMO - MC\n\n\fAn improved MCMC sampler for cosmology\nhttp://www.mrao.cam.ac.uk/\u223canze/cog\nand\nincluded\neasily into the COSMO - MC package. It does, however, also require\nthe Gnu Scientific Library for the integration of the degeneracy\nquantities discussed below.\nThe sampler is composed of four separate MCMC engines:\nfast parameter changes (E1), all parameter changes (E2), principal\ndirection changes (E3), degeneracy direction changes (E4); each of\nthese engines is explained below. At any given step in the chain,\nonly one of engines is used to propose the next candidate point x\u2032 .\nWhich engine is used is decided randomly at each step according\nto a set of relative probabilities fixed by the user at compilation. To\nallow for the engines to respond dynamically to the stucture of the\ntarget density, at regular intervals (the number of chain steps defining an 'interval' being fixed by the user at compliation: default 300)\nthe engines E1, E2 and E3 are overhauled. In particular, for E1 and\nE2, the proposal widths \u03c3i are adjusted to ensure reasonable acceptance rates (see below). For E3, the empirical covariance matrix\nof recent samples is recalculated. We note that an overhaul is only\nperformed after a rejection of a candidate point, thus ensuring that\ndetailed balance is maintained.\n\n3.1 Fast parameter changes\nDuring a fast parameter change (engine E1), only fast parameters\nin CAMB are updated. Each fast parameter is assigned a probability\npi of being updated in any given E1 proposal. These are defined by\nthe user at compilation. Note that the pi need not sum to unity. If\nN fast parameters are updated, each new parameter value is drawn\nfrom a Gaussian distribution\u221acentred at the present parameter value\nand having width \u03c3\u2032i = \u03c3i / N. For the first sampling interval the\n\u03c3i are those supplied by the user at compilation. In contrast to the\nCOSMO - MC sampler, however, the proposal width \u03c3i for each parameter is then updated at each overhaul, based on the acceptance\nrates achieved for that parameter in the previous sampling interval. If the average acceptance rate of a given parameter is less than\na user selected target \u03b2 (defined at compilation: default 0.4), it is\nlikely that the proposal width for this parameter is too large and so\nthe corresponding \u03c3i is decreased by a fixed factor (defined at compilation: default 0.8). Similarly, if the acceptance rate is less than\n\u03b2 the proposal width is probably too narrow and is thus increased\nby a fixed factor (defined at compilation: default 1.2). As we show\nin Section 4, the proposal width for each parameter eventually settles down to a stable value appropriate to the target density being\nsampled.\n\n3\n\neach overhaul. The eigenvectors and eigenvalues of the covariance\nmatrix are then determined, which yield the principal directions in\nwhich changes may be proposed and the corresponding Gaussian\nproposal widths. In an analogous manner to engines E1 and E2,\neach principal direction is assigned a probability pi of being updated (defined at compilation). Once again the pi need not sum to\nunity.\nThis approach has two advantages over the covariance matrix\nmethod used in the COSMO - MC sampler. Firstly, the covariance matrix corresponds to the local degeneracy directions and is thus optimised for the current position of the chain. Secondly, it alleviates\nthe need to run the entire sampling process twice, thus making the\ncomputation requirements considerably smaller.\n\n3.4 Degeneracy-direction changes\nThe degeneracy directions engine (E3) is the most important innovation in the COG sampler, and ensures good mobility of the\nchain around the target density. This engine takes advantage of the\nfact that there are degeneracies in cosmological parameter space\nthat are intrinsic to any CMB observation and cannot be broken\neven with cosmic-variance limited data. Some of these degeneracies have been extensively analysed in Efstathiou and Bond (1999).\nIn particular, we implement motion of the chain along the two most\nimportant degeneracies: namely the geometrical degeneracy and\nthe peak position degeneracy. In addition, we also implement motion of the chain along the degeneracy directions spanned by the\nparameters (zre , As ) and (\u03c9b , ns ). The probability pi of updating\nalong each degeneracy direction is defined at compilation (default\n0.25).\n\n3.4.1 Geometrical degeneracy\nThe geometrical degeneracy is a nearly exact degeneracy in cosmological parameter space for CMB data; it therefore allows large\nmovement of the chain in the space. According to Efstathiou and\nBond (1999), two cosmological models are degenerate if they have\nthe same physical matter densities \u03c9b and \u03c9dm , the same primordial\nscalar and tensor fluctuation spectra and the same value of parameter\n\u0010\n\u0011\n1/2\nR = \u03c91/2\n(2)\nm yS \u03c9k y ,\n\nwhere \u03c9m = \u03c9b + \u03c9dm , y is given by the integral\n3.2 All parameter changes\nThe all-parameter-change engine (E2) operates in an identical manner to E1, except that in this case the full set of fast and slow parameters may be updated.\n\ny=\n\nZ 1\nar\n\nda\n,\n[\u03c9m a + \u03c9k a2 + \u03c9\u039b a4 ]\n\n(3)\n\nsinh(x)\n.\nx\n\n(4)\n\nand\nS(x) =\n\n3.3 Principal-direction changes\nThe engine (E3) implements prinicipal-direction changes and\nmakes use of the covariance information collected from early samples. This engine is only switched-on once the chain has taken\na given number of steps (defined at compilation: default 200), at\nwhich point the empiricial covariance matrix of the parameters is\ncalculated using preceeding samples; an upper limit on the number\nof preceeding samples used in the calculation is defined at compilation (default 2000). The covariance matrix is then updated at\n\nFor a flat universe the function S equals unity, and for closed uni\u221a\nverses it simplifies to sinc( \u2212\u03c9k y). The integral (3) may be evaluated numerically, where the lower limit is obtained using the fitting formula for the redshift of recombination given by Hu and\nSugiyama (1995), namely\n=\n\n1048[1 + 0.00124\u03c9\u22120.738\n][1 + g1 \u03c9gm2 ] ,\nb\n\ng1\n\n=\n\ng2\n\n=\n\n0.0783\u03c9\u22120.238\n[1 + 39.5\u03c90.763\n]\u22121 ,\nb\nb\n\u22121\n0.560[1 + 21.1\u03c91.81\nb ] .\n\nzr\n\n(5)\n\n\f4\n\nAn\u017ee Slosar and M.P. Hobson\n\nThe quantity R is thus a function of the parameter set\n(\u03c9b , \u03c9m , \u03c9\u039b , \u03c9k ). These parameters can be calculated from the\nequivalent COSMO - MC parametrisation (\u03c9b , \u03c9dm , \u03a9k , h).\nWhen a geometric degeneracy change is proposed, the parameter R is calculated for the current chain position x. A fixed-width\nGaussian change in \u03c9\u039b is proposed and the \u03c9k direction is then\nsearched using a numerical minimiser until a model with a matching R is found. Finally, the new set of parameters are converted\nback to the standard COSMO - MC parametrisation for this new candidate point x\u2032 . The proposal width in \u03c9\u039b is set at compilation and\ncan be quite large (default 0.1), since the degeneracy is almost exact so candidate points should have a high acceptance rate. Indeed,\nthe difference in CMB power spectrum between models x and x\u2032 is\nbelow the level of cosmic variance. However, due to inaccuracies\nin above approximations, as well as intrinsic numerical inaccuracies in the CAMB code, the acceptance rate for these changes is\nless than unity. Finally, we note that although the numerical minimisation step involves many numerical integrations, the time spent\nsearching this space is negligible compared to the calculation of a\nsingle CMB power spectrum.\n3.4.2 Peak position degeneracy\nAnother important degeneracy is the first peak position degeneracy. Although not as exact as geometrical degeneracy it still allows\nthe chain to make large steps in the parameter space. Following\nEfstathiou & Bond (1999), the position of the first peak is approximately given by\n\u221a \u22121/2\nR\nld \u2248 0.746\u03c0 3ar\n(6)\nIs (\u03c9m , \u03c9b )\nwhere\n\u22121/2\n\nIs = ar\n\nZ ar\n0\n\np\n\nda\n(a + aeq )(1 + R)\n\n(7)\n\nin which aeq is the normalised scale factor at matter-radiation\nequality and R = (3\u03c1b /4\u03c1\u03b3 ). To a good approximation\n\u0013\n\u0012\n1.6813\n\u22121\n\u03c9m ,\n(8)\naeq = 24185\n1 + \u03b7\u03bd\nR = 30496\u03c9b a .\n(9)\nThus ld is also a function of the parameter set (\u03c9b , \u03c9m , \u03c9\u039b , \u03c9k ).\nSince \u03c9b and \u03c9m are not required to be fixed there is considerably more freedom in choosing which parameters to change. In the\npresent implementation \u03c9m is always changed with \u03c9b and \u03c9k being changed with some finite probability. The \u03c9\u039b direction is then\nnumerically searched for a model with a matching first peak position.\nWe note in passing that the third degeneracy mentioned in Efstathiou & Bond (1999), i.e. the height of the first peak degeneracy,\nis not very relevant to future analysis, since it is already broken by\nthe existing CMB dataset.\n3.4.3 The zre \u2013As degeneracy\nAnother well-known approximate physical degeneracy in the cosmological parameter space for CMB data is that between \u03c38 and\nexp(\u2212\u03c4) (see e.g. Lewis & Bridle 2002) This occurs because the\nCMB power spectrum on scales smaller than the horizon size at\nreionisation is damped by a factor exp(\u22122\u03c4), and \u03c328 scales with\nthe power in the primordial perturbation. The corresponding parameters in the COSMO - MC software are zre and As . We note that\n\nzre is a 'slow' parameter, whereas As is a 'fast' one. When a move\nin zre is proposed, the sampler additionally proposes up to 30 (or a\nnumber selected at the compilation time) proposals in As . The proposal probability distribution function for As is a half Gaussian with\nthe correct orientation (i.e. increasing zre requires increasing As and\ntherefore sampler always proposes change which has the right orientation with respect to the degeneracy direction). Since As is a fast\nparameter the computational cost is essentially just one CAMB call.\n3.4.4 The \u03c9b \u2013ns degeneracy\nThere is a weak degeneracy in the parameters \u03c9b \u2013ns . We have implemented a degeneracy sampling system that is analogous to that\ndescribed in the previous section with the slow parameter wb and\nthe fast parameter ns .\n3.5 Burn-in, convergence and annealing\nAs mentioned in Section 1, any MCMC sampler requires a burn-in\nperiod for the chain to reach equilibrium and hence sample from the\ntarget distribution p(x). Unfortunately, there exists no formula for\ndetermining the length of the burn-in period, or for confirming that\na chain has reached equilibrium. Indeed, the topic of convergence\nis still a matter of ongoing statistical research. Nevertheless, several convergence diagnostics for determining the length of burn-in\nhave been proposed. These employ a variety of theoretical methods and approximations that make use of the output samples from\nthe Markov chain. A review of such diagnostics is given by Cowles\n& Carlin (1994). It is worth noting that running several parallel\nchains, rather than a single long chain, can aid the diagnosis of\nconvergence, as discussed below in Section 4.\nIt is also useful during burn-in to employ an annealing schedule in which the target density is raised to some power \u03bb, which\nvaries gradually from zero to unity. Thus, one begins sampling from\na modified posterior with \u03bb = 0 and slowly raises \u03bb according to\nsome (geometric) annealing schedule until \u03bb = 1. This allows the\nchain to sample from remote regions of the posterior distribution,\nwhich in turn facilitates extensive chain mobility and ensures more\nreliable relaxation of the chain into the global optimum. This approach also has the convenient by-product of yielding an estimate\nfrom the burn-in samples of the Bayesian evidence for the model\nunder consideration (see, for example, Hobson & McLachlan 2002;\nSlosar et al. 2003).\n\n4 APPLICATION TO CMB DATA\nTo test the quality of our improved sampler, we have performed\nparameter estimation in a 7-parameter inflationary \u039bCDM model\nthe using the two separate data sets outlined below. We have compared the results from the COG sampler with those obtained using\nthe standard COSMO - MC software. For both samplers, the initial\nstarting position of the chain and the initial proposal widths \u03c3i\nfor each parameter were identical, and are listed in Table 1. Also\nlisted are the limits of the top-hat priors adopted for the parameters. Both the COSMO - MC and COG samplers were run until 6000\npost burn-in accepted samples had been collected for each chain.\nFor both samplers, eight independent chains were run on separate\nnodes of a Beowulf cluster. Thus, the total number of post burnin accepted samples was 48000. This approach also allows one to\ncompare samples obtained from different individual chains, which\naids the determination of convergence.\n\n\fAn improved MCMC sampler for cosmology\nx0\n\ntop-hat prior\n\n\u03c3i\n\n0.023\n0.127\n68\n13\n0.0\n1.0\n23\n\n(0.005,0.1)\n(0.01,0.9)\n(40,100)\n(6,20)\n(\u22120.3,0.3)\n(0.7,1.3)\n(10,50)\n\n0.01\n0.1\n15\n6\n0.06\n0.1\n15.0\n\nparameter\n\u03c9b\n\u03c9dm\nh\nzre\n\u03a9k\nns\nAs\n\nTable 1. The initial chain position x0 , the range of top-hat prior, and the\ninitial proposal width \u03c3i used for each parameter. The \u03c3i were chosen to\nbe small to give the original COSMO - MC sampler some chance of exploring\nthe cosmic variance limited model.\n\nFigure 1. The average acceptance rate as a function of the number of sampler calls for the COSMO - MC sampler (thin line) and the COG sampler (thick\nline) in the analysis of data set 1. The vertical lines indicate the end of the\nburn-in period for the COSMO - MC (thin dashed line) and COG (thick dashed\nline) samplers.\n\n4.1 Current CMB data\nThe first data set (data set 1) consists of WMAP, VSA, ACBAR and\nCBI band-power measurements of the total intensity CMB power\nspectrum (Bennett et al. 2003; Grainge et al. 2003; Kuo et al. 2003;\nPearson et al. 2003); for l < 800 only points from the WMAP experiment are used. In the calculation of the WMAP likelihood we\nuse an adapted version of the publicly-available code (Kogut et al.\n200; Hinshaw et al. 2003; Verde et al. 2003).\n\n4.1.1 Acceptance rates and sampler performance\nThe average acceptance rates for the COSMO - MC and COG samplers are plotted in Fig. 1 as a function of the number of calls to\nthe sampler. The original COSMO - MC sampler was supplied with\nthe precomputed basic 6-parameter covariance matrix that comes\nsupplied with the COSMO - MC software; this includes all the parameters given in Table 1 except for \u03a9k . For this last parameter,\nCOSMO - MC uses a Gaussian proposal distribution with the width\nindicated in the table. The provision of the covariance matrix in advance gives the COSMO - MC sampler some advantage as compared\nwith its own 'initial' sampling phase. Nevertheless, the COG sampler at first equals this acceptance rate, and very soon surpasses it,\nonce it has learnt the appropriate length scales of the posterior. After many samples, the acceptance rate for the COSMO - MC sampler\n\n5\n\nis found to be around 0.1. To obtain 6000 post burn-in accepted\nsamples, 65000 calls to the sampler were made. By contrast, the\naverage acceptance rate of the COG sampler is around 0.4 and only\n17000 calls to sampler were required.\nIn Fig. 2 (top panel), we plot the acceptance rates for each of\nthe four MCMC engines used in the COG sampler as a function of\nthe number of overhauls, which are performed after every 300 chain\nsteps. As one might expect, the engines E1 and E2 have acceptance\nrates of around 0.4, since the proposal widths for the parameters\nare chosen to achieve this target. More interestingly, the E3 engine also has an acceptance rate of almost 0.4, once equilibrium has\nbeen achieved. We note, however, that the initial acceptance rate for\nE3 is zero, since there are not enough samples to compute the covariance matrix. For E4 (degeneracy direction changes), one might\nhave expected the acceptance rate to be high, since the change in the\ntheoretical CMB power spectra corresponding to such a proposal is\ngenerally quite small. Nevertheless, inexactness in the degeneracies\nand small numerical inaccuracies in both in CAMB and the calculation of the degeneracy parameters means that the acceptance rate\nis reduced somewhat below unity, although its equilibrium value\nof around 0.6 is higher than for the other engines. Moreover, successful proposals along the degeneracy directions take the chain a\nconsiderable distance from its original position and are thus very\nimportant.\nIn Fig. 2 (middle and bottom panels), we plot the proposal\nwidths \u03c3i for the slow and fast parameters respectively, as a function of overhaul number; each width is expressed as a fraction of its\ninitial value as given in Table 1. We see that each proposal widths\ninitially decrease and then start oscillating around their equilibrium\nvalues. This oscillation could be avoided by adding a damping term\nto the proposal width change function, but we believe that oscillating gives the sampler opportunity to sample a larger range of distances and potentially escape local minima while at the same time\nmaintaining high acceptance rate. Additionally we note that the\nrequirement to maintain an acceptance rate of 0.4 means that the\nproposal widths are considerably smaller than widths of inferred\nuncertainties in parameters. We have performed simulations on a\nmultivariate Gaussian and results show that this is indeed an effective sampling technique.\n\n4.1.2 Inferred limits on cosmological parameters\nThe marginalised probability distributions of the cosmological parameters obtained from the COSMO - MC and COG samplers are\nshown in Fig. 3. We see that the distributions for the parameters \u03c9b ,\n\u03c9dm , ns , zre and As are consistent within the sampling uncertainties for the two samplers. We note, however, that the marginalised\ndistributions for h, \u03a9k , \u03a9m and \u03a9\u039b differ somewhat. In particular, we see that the distributions produced by the COSMO - MC sampler are significantly narrower than those obtained using the COG\nsampler. This provides a useful illustration of the poorer mobility of the chain in the COSMO - MC sampler along the geometrical\ndegeneracy. This leads to underestimation of the confidence limits\non the associated parameters. Indeed, in some cases, the limits are\nunderestimated by around a factor of two. Conversely, the explicit\ndegeneracy direction engine in the COG sampler allows its chain\nto move freely around the parameter space. This ensures that the\nmarginalised distributions reflect the proper structure of the posterior. It should be noted, however, that the underestimation of the\nconfidence limits by the COSMO - MC sampler is usually not a serious problem, since an informative prior on h breaks the geometrical\n\n\f6\n\nAn\u017ee Slosar and M.P. Hobson\n\nFigure 3. The marginalised distributions for the cosmological parameters as\ninferred from data set 1 using the original COSMO - MC sampler (thin line)\nand the COG sampler (thick line) with a chain length of 6500.\n\ndegeneracy sufficiently that the resulting marginalised distributions\nare reasonably accurate.\n\n4.2 Future CMB data\n\nFigure 2. Top: the acceptance rates in the analysis of data set 1 for each\nof the four MCMC engines used in the COG sampler as a function of the\nnumber of overhauls, which are performed after every 300 chain steps \u2013 fast\nparameter (E1: thin solid line), all parameters (E2: dashed line), principal\ndirections (E3: dotted line), degeneracy directions (E4: dot-dashed line).\nThe overall acceptance rate for the sampler is shown as the thick solid line.\nMiddle: the proposal widths \u03c3i for each slow parameter as a function of\noverhaul number. Each width is expressed as a fraction of its initial value\ngiven in Table 1, for each slow parameter as a function of overhaul number.\nBottom: as above, but for the fast parameters.\n\nThe second data set (data set 2) consists of simulated cosmicvariance limited measurements of the CMB power spectrum at each\nmultipole out to l = 2000. Such data is expected from the forthcoming Planck satellite mission. In detail, a target concordance\nmodel was chosen with parameter values \u03c9b = 0.023, \u03c9dm = 0.127,\nh = 0.68, ns = 1.0, zre = 16, As = 25 and \u03a9k = 0.0. The corresponding theoretical CMB power spectrum was calculated using\nCAMB with the flat-universe code switched off. In an earlier analysis of data set 2, we noticed that discontinuities occurred in the\nsample distribution which were associated with the switch over in\nthe CAMB code from flat universes to universes with arbitrary curvature. This inaccuracy in the CAMB code is only important when\nanalysing data of such high precision, and has been previously\nidentified (Lewis, private communication). To create data set 2, we\nassumed that the cosmic variance limit can be well-approximated\nby a Gaussian distribution centred on the true Cl value and having\na dispersion given by\nr\n2\n\u2206Cl =\nC.\n(10)\n2l + 1 l\nIn practice, with real data, one should take into account that the\nprobability of any given Cl value follows a \u03c72 -distribution; this is\nparticularly important at low l values.\n\n\fAn improved MCMC sampler for cosmology\n\n7\n\nFigure 4. As in Fig. 1, but for data set 2.\n\n4.2.1 Acceptance rates and sampler performance\nThe average acceptance rates for the COSMO - MC and COG samplers\nare plotted in Fig. 4 as a function of the number of calls to the sampler. Once again, the original COSMO - MC sampler was given the\nprecomputed basic 6-parameter covariance matrix that comes supplied with the COSMO - MC software, which gives the COSMO - MC\nsampler some initial advantage. One sees, however, that the COG\nsampler soon overtakes and, in this case, there is a very large difference between the equilibrium acceptance rates of the two samplers.\nAfter many samples, the acceptance rate for the COSMO - MC sampler is found to be around 0.01. Even after 70000 sampler calls for\neach chain, only around 600 post burn-in accepted samples were\nobtained for the best-performing chain. Conversely, the COG sampler achieved an equilibrium acceptance rate of 0.22, and required\nonly 28000 sampler calls to obtain 6000 post burn-in accepted samples for each chain. We also note that, as a result of the simulated\nannealing used in the COG sampler, it required only 3100 sampler\ncalls were required to burn-in, as compared with 10000 sampler\ncalls for COSMO - MC (in the latter case, the end of burn-in was determined interactively by examining the posterior values associated\nwith the chain samples).\nIn Fig. 5 (top panel), we plot the acceptance rates for each of\nthe four MCMC engines used in the COG sampler as a function of\nthe number of overhauls. Once again, by construction, the engines\nE1 and E2 have acceptance rates of around 0.4 once equilibrium has\nbeen achieved. For E3 (principal direction changes), we again see\nthat the initial acceptance rate is zero, since there are not enough\nsamples to compute the covariance matrix, but in this case the acceptance rate remains low, reaching an equilibrium value of only\n0.05. We believe this behaviour is associated with the fact that, for\ndata set 2, the corresponding multivariate Gaussian proposal distribution is a poorer approximation to the true posterior than for\ndata set 1. For E4 (degeneracy direction changes), we see that the\ninexactness in the degeneracies and small numerical inaccuracies\nin both in CAMB and the calculation of the degeneracy parameters have a more profound effect for the analysis of data set 2, resulting in a lower equilibrium acceptance rate of around 0.25. As\nfor data set 1, however, successful proposals along the degeneracy\ndirections take the chain a considerable distance from its original\nposition and are thus very important.\n\nFigure 5. As in Fig. 2, but for data set 2.\n\n4.2.2 Inferred limits on cosmological parameters\nThe marginalised probability distributions of the cosmological parameters obtained from the COG sampler are shown in Fig. 3. We\ndo not plot the corresponding distributions for the COSMO - MC sampler, because it was only able to produce a total of 1500 accepted\npost burn-in samples from 70000 sampler calls for each of the eight\nchains. This results in the corresponding marginalised distributions\nbeing dominated by sampling error.\nWe note that the distributions for each parameter produced\nby the COG sampler contain the corresponding true value at high\n\n\f8\n\nAn\u017ee Slosar and M.P. Hobson\nCOG ) is trivially substituted for the existing sampler in the COSMO -\n\nsoftware. In Section 4, we test the COG sampler on the current CMB data set and a simulated data set of the quality expected\nfrom the Planck mission. In each case, the sampler produces reliable marginalised distributions with considerably fewer sampler\ncalls than the native COSMO - MC sampler.\nIn future work, we intend to enhance the efficiency of the COG\nsampler still further by allowing communication between chains.\nAt present running several independent chains on different processors of a Beowulf cluster provides a useful means of diagnosing\nconvergence, but does not take advantage of the possibility of sharing the information obtained by the chains on the shape of the target density. In particular, we are investigating cross-chain proposals\nbased on genetic algorithms (see e.g. Davis 1991).\nMC\n\nACKNOWLEDGMENTS\nWe thank Charles McLachlan, Phil Marshall, John Skilling, Steve\nGull and Carolina \u00d6dman for many interesting conversations regarding Markov-chain Monte Carlo sampling. We are also grateful\nto Antony Lewis and Sarah Bridle for useful discussions and for\nmaking their COSMO - MC software publicly available. AS acknowledges the support of St. Johns College, Cambridge.\n\nREFERENCES\nFigure 6. As in Fig. 3, but for data set 2 and using the COG sampler only.\n\nprobability. For \u03c9b , \u03c9dm , ns , zre and As the distributions are reasonably smooth. However, the marginalised distributions for h, \u03a9k ,\n\u03a9m and \u03a9\u039b contain some additional features. In particular, we note\nthat each of these distributions contains a 'drop-out'; these occur\nat h \u2248 0.6 and h \u2248 0.8, \u03a9k \u2248 \u22120.05, \u03a9m \u2248 0.4 and \u03a9\u039b \u2248 0.6.\nThese features are, in fact, the projections of a single feature in\nthe multidimensional parameter space defining the geometrical degeneracy direction. We have separately examined the marginalised\ndistributions produced for each of the eight chains, and found that\nall of them contain these features. It is therefore most likely that\nthis feature is an artifact in the CAMB code. More importantly, setting aside these drop-outs, we see that the geometrical degeneracy\nis well-sampled, leading to wide tails on the marginalised distributions for \u03a9k , \u03a9m and \u03a9\u039b . This confirms the well-known result\nthat, even with CMB data of Planck quality, the spatial curvature\nof the universe cannot be well-constrained without the inclusion of\ninformative priors.\n\n5 DISCUSSION AND CONCLUSIONS\nWe have presented a fast Markov-chain Monte Carlo sampler tailored to the problem of estimating cosmological parameters from\nmeasurements of the CMB total intensity power spectrum. This\nsampler employs a number of strategies to avoid the difficulties\nencountered in the use of the standard multivariate Gaussian proposal function used, for example, in the COSMO - MC software package (Lewis & Bridle 2002). In particular, it achieves rapid convergence and produces reliable confidence limits by using dynamic\nwidths for proposal distributions, dynamic covariance matrix sampling, and a dedicated proposal distribution for moving along wellknown degeneracy directions. The new sampler module (called\n\nBennett C.L. et al., ApJ, in press (astro-ph/0302207)\nChristensen N., Meyer R., Knox L., Luey B., 2001,\nClass. Quant. Grav., 18, 2677\nCowles M.K., Carlin B.P., 1994, Technical Report 94-008, Division of Biostatistics, School of Public Heath, University of Minnesota\nDavis L., 1991, Handbook of Genetic Algorithms. van Nostrand\nReinhold, New York.\nKuo C.L. et al., 2003, ApJ, submitted (astro-ph/0212289)\nEfstathiou G., Bond J.R., 1999, MNRAS, 304, 75\nGilks W.R., Richardson S., Spiegelhalter D.J., 1995, in eds Gilks\nW.R., Richardson S., Spiegelhalter D.J., Markov Chain Monte\nCarlo in Practice. Chapman & Hall, London.\nGrainge K. et al., 2003, MNRAS, 341, L23\nHinshaw G. et al., 2003, ApJ, in press (astro-ph/0302217)\nHobson M.P., McLachlan C., 2002, MNRAS, 388, 365\nHu W., Sugiyama N., 1995, PRD, 50, 7173\nKogut A. et al., 2003, ApJ, in press (astro-ph/0302213)\nKnox L., Christensen N., Skordis C., 2001, ApJ, 563, L95\nLewis A.L., Bridle S.L., 2002, PRD, 66, 3511\nLewis A.L., Challinor A.D., Lasenby A.N., 2000, ApJ, 538, 473\nPearson T.J. et al. 2003, ApJ, 591,556\nSlosar A. et al., 2003, MNRAS, 341, L29\nVerde L. et al., 2003, ApJ, in press (astro-ph/0302218)\nThis paper has been typeset from a TEX/ LATEX file prepared by the\nauthor.\n\n\f"}