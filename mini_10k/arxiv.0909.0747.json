{"id": "http://arxiv.org/abs/0909.0747v1", "guidislink": true, "updated": "2009-09-03T20:00:14Z", "updated_parsed": [2009, 9, 3, 20, 0, 14, 3, 246, 0], "published": "2009-09-03T20:00:14Z", "published_parsed": [2009, 9, 3, 20, 0, 14, 3, 246, 0], "title": "Parameter Estimation from Time-Series Data with Correlated Errors: A\n  Wavelet-Based Method and its Application to Transit Light Curves", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0909.5020%2C0909.3042%2C0909.4065%2C0909.3742%2C0909.1877%2C0909.0946%2C0909.2453%2C0909.4139%2C0909.4733%2C0909.2474%2C0909.3641%2C0909.2888%2C0909.3216%2C0909.0794%2C0909.1454%2C0909.4740%2C0909.4050%2C0909.4311%2C0909.2841%2C0909.5068%2C0909.3882%2C0909.2740%2C0909.1681%2C0909.0056%2C0909.2723%2C0909.3652%2C0909.3576%2C0909.5646%2C0909.3418%2C0909.4471%2C0909.5559%2C0909.5060%2C0909.0866%2C0909.5675%2C0909.2988%2C0909.4627%2C0909.1831%2C0909.0282%2C0909.4854%2C0909.0864%2C0909.3508%2C0909.1720%2C0909.2390%2C0909.4743%2C0909.4478%2C0909.3962%2C0909.2915%2C0909.2437%2C0909.2961%2C0909.4644%2C0909.0030%2C0909.0430%2C0909.3499%2C0909.1376%2C0909.0975%2C0909.1146%2C0909.4704%2C0909.3156%2C0909.3200%2C0909.1416%2C0909.3391%2C0909.4890%2C0909.3496%2C0909.2073%2C0909.2774%2C0909.3097%2C0909.0958%2C0909.2181%2C0909.4908%2C0909.4017%2C0909.4271%2C0909.1914%2C0909.5100%2C0909.4782%2C0909.1804%2C0909.0195%2C0909.4751%2C0909.4998%2C0909.4136%2C0909.4517%2C0909.1051%2C0909.0457%2C0909.5458%2C0909.2152%2C0909.5610%2C0909.3063%2C0909.0903%2C0909.1814%2C0909.4716%2C0909.2131%2C0909.1465%2C0909.5041%2C0909.2986%2C0909.0461%2C0909.5146%2C0909.1986%2C0909.4115%2C0909.1259%2C0909.0747%2C0909.3579%2C0909.4520&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Parameter Estimation from Time-Series Data with Correlated Errors: A\n  Wavelet-Based Method and its Application to Transit Light Curves"}, "summary": "We consider the problem of fitting a parametric model to time-series data\nthat are afflicted by correlated noise. The noise is represented by a sum of\ntwo stationary Gaussian processes: one that is uncorrelated in time, and\nanother that has a power spectral density varying as $1/f^\\gamma$. We present\nan accurate and fast [O(N)] algorithm for parameter estimation based on\ncomputing the likelihood in a wavelet basis. The method is illustrated and\ntested using simulated time-series photometry of exoplanetary transits, with\nparticular attention to estimating the midtransit time. We compare our method\nto two other methods that have been used in the literature, the time-averaging\nmethod and the residual-permutation method. For noise processes that obey our\nassumptions, the algorithm presented here gives more accurate results for\nmidtransit times and truer estimates of their uncertainties.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0909.5020%2C0909.3042%2C0909.4065%2C0909.3742%2C0909.1877%2C0909.0946%2C0909.2453%2C0909.4139%2C0909.4733%2C0909.2474%2C0909.3641%2C0909.2888%2C0909.3216%2C0909.0794%2C0909.1454%2C0909.4740%2C0909.4050%2C0909.4311%2C0909.2841%2C0909.5068%2C0909.3882%2C0909.2740%2C0909.1681%2C0909.0056%2C0909.2723%2C0909.3652%2C0909.3576%2C0909.5646%2C0909.3418%2C0909.4471%2C0909.5559%2C0909.5060%2C0909.0866%2C0909.5675%2C0909.2988%2C0909.4627%2C0909.1831%2C0909.0282%2C0909.4854%2C0909.0864%2C0909.3508%2C0909.1720%2C0909.2390%2C0909.4743%2C0909.4478%2C0909.3962%2C0909.2915%2C0909.2437%2C0909.2961%2C0909.4644%2C0909.0030%2C0909.0430%2C0909.3499%2C0909.1376%2C0909.0975%2C0909.1146%2C0909.4704%2C0909.3156%2C0909.3200%2C0909.1416%2C0909.3391%2C0909.4890%2C0909.3496%2C0909.2073%2C0909.2774%2C0909.3097%2C0909.0958%2C0909.2181%2C0909.4908%2C0909.4017%2C0909.4271%2C0909.1914%2C0909.5100%2C0909.4782%2C0909.1804%2C0909.0195%2C0909.4751%2C0909.4998%2C0909.4136%2C0909.4517%2C0909.1051%2C0909.0457%2C0909.5458%2C0909.2152%2C0909.5610%2C0909.3063%2C0909.0903%2C0909.1814%2C0909.4716%2C0909.2131%2C0909.1465%2C0909.5041%2C0909.2986%2C0909.0461%2C0909.5146%2C0909.1986%2C0909.4115%2C0909.1259%2C0909.0747%2C0909.3579%2C0909.4520&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We consider the problem of fitting a parametric model to time-series data\nthat are afflicted by correlated noise. The noise is represented by a sum of\ntwo stationary Gaussian processes: one that is uncorrelated in time, and\nanother that has a power spectral density varying as $1/f^\\gamma$. We present\nan accurate and fast [O(N)] algorithm for parameter estimation based on\ncomputing the likelihood in a wavelet basis. The method is illustrated and\ntested using simulated time-series photometry of exoplanetary transits, with\nparticular attention to estimating the midtransit time. We compare our method\nto two other methods that have been used in the literature, the time-averaging\nmethod and the residual-permutation method. For noise processes that obey our\nassumptions, the algorithm presented here gives more accurate results for\nmidtransit times and truer estimates of their uncertainties."}, "authors": ["Joshua A. Carter", "Joshua N. Winn"], "author_detail": {"name": "Joshua N. Winn"}, "author": "Joshua N. Winn", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1088/0004-637X/704/1/51", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0909.0747v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0909.0747v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Accepted in ApJ. Illustrative code may be found at\n  http://www.mit.edu/~carterja/code/ . 17 pages", "arxiv_primary_category": {"term": "astro-ph.EP", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "astro-ph.EP", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "physics.data-an", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0909.0747v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0909.0747v1", "journal_reference": "Astrophys.J.704:51-67,2009", "doi": "10.1088/0004-637X/704/1/51", "fulltext": "A CCEPTED FOR PUBLICATION IN T HE A STROPHYSICAL J OURNAL\nPreprint typeset using LATEX style emulateapj v. 08/22/09\n\nPARAMETER ESTIMATION FROM TIME-SERIES DATA WITH CORRELATED ERRORS:\nA WAVELET-BASED METHOD AND ITS APPLICATION TO TRANSIT LIGHT CURVES\nJ OSHUA A. C ARTER AND J OSHUA N. W INN\n\narXiv:0909.0747v1 [astro-ph.EP] 3 Sep 2009\n\nDepartment of Physics, and Kavli Institute for Astrophysics and Space Research,\nMassachusetts Institute of Technology, Cambridge, MA 02139\nAccepted for publication in The Astrophysical Journal\n\nABSTRACT\nWe consider the problem of fitting a parametric model to time-series data that are afflicted by correlated\nnoise. The noise is represented by a sum of two stationary Gaussian processes: one that is uncorrelated in\ntime, and another that has a power spectral density varying as 1/ f \u03b3 . We present an accurate and fast [O(N)]\nalgorithm for parameter estimation based on computing the likelihood in a wavelet basis. The method is\nillustrated and tested using simulated time-series photometry of exoplanetary transits, with particular attention\nto estimating the midtransit time. We compare our method to two other methods that have been used in the\nliterature, the time-averaging method and the residual-permutation method. For noise processes that obey our\nassumptions, the algorithm presented here gives more accurate results for midtransit times and truer estimates\nof their uncertainties.\nSubject headings: methods: statistical - techniques: photometric - stars: planetary systems\n1. INTRODUCTION\n\nFrequently one wishes to fit a parametric model to timeseries data and determine accurate values of the parameters\nand reliable estimates for the uncertainties in those parameters. It is important to gain a thorough understanding of the\nnoise and develop appropriate methods for parameter estimation, especially at the research frontier, where the most interesting effects are often on the edge of detectability. Underestimating the errors leads to unjustified confidence in new results, or confusion over apparent contradictions between different data sets. Overestimating the errors inhibits potentially\nimportant discoveries.\nWhen the errors in the data are well understood and\nuncorrelated, the problem of parameter estimation is relatively straightforward (see, e.g., Bevington & Robinson 2003,\nGould 2003, Press et al. 2007). However, when the noise\nis not well-understood-and particularly when the noise exhibits correlations in time-the problem is more challenging\n(see, e.g., Koen & Lombard 1993, Beran 1994). Traditional\nmethods that ignore correlations often give parameter estimates that are inaccurate and parameter errors that are underestimated. Straightforward generalization of the traditional\nmethods is computationally intensive, with time-complexity\nO(N 2 ) in the worst cases (where N is the number of data\npoints). This makes certain analyses impractical.\nOur specific concern in this paper is the analysis of timeseries photometry of exoplanetary transits. During a transit,\na planet passes in front of the disk of its parent star, which is\nevident from the slight diminution in the light received from\nthe star. A model of a transit light curve may have many\nparameters, but we focus mainly on a single parameter, the\nmidtransit time tc , for three reasons. The first reason is the\nsimplicity of a single-parameter model. The second reason is\nthat tc is a unique piece of information regarding each transit\nevent, and as such, the accuracy cannot be improved by combining results from multiple transit observations. Instead one\nmust make the most of single-event observations even if they\nare afflicted by correlated noise. The third reason is that tranElectronic address: carterja@mit.edu; jwinn@mit.edu\n\nsit timing offers a means of discovering additional planets or\nsatellites by seeking anomalies in a sequence of transit times\ndue to gravitational perturbations [Holman & Murray (2005),\nAgol et al. (2005)].1\nBeginning with the work of Pont, Zucker, & Queloz (2006),\nit has been widely recognized that time-correlated noise (\"red\nnoise\") is a limiting factor in the analysis of transit light\ncurves. Many practitioners have attempted to account for correlated errors in their parameter estimation algorithms (see,\ne.g., Bakos et al. 2006, Gillon et al. 2006; Winn et al. 2007,\n2009; Southworth 2008). Among these schemes are the\n\"time-averaging\" method, in which the effects of correlations\nare assessed by computing the scatter in a time-binned version\nof the data (Pont et al. 2006) and the \"residual-permutation\"\nmethod, a variant of bootstrap analysis that preserves the time\nordering of the residuals (Jenkins et al. 2002).\nIn this paper we present an alternative method for parameter estimation in the presence of time-correlated noise, and\ncompare it to those two previously advocated methods. The\nmethod advocated here is applicable to situations in which\nthe noise is well described as the superposition of two stationary (time-invariant) Gaussian noise processes: one which\nis uncorrelated, and the other of which has a power spectral\ndensity varying as 1/ f \u03b3 .\nA more traditional approach to time-correlated noise is the\nframework of autoregressive moving average (ARMA) processes (see, e.g., Box & Jenkins 1976). The ARMA noise\nmodels can be understood as complementary to our 1/ f \u03b3\nmodel, in that ARMA models are specified in the time domain as opposed to the frequency domain, and they are\nmost naturally suited for modeling short-range correlations\n(\"short-memory\" processes) as opposed to long-range correlations (\"long-memory\" processes). Parameter estimation\nwith ARMA models in an astronomical context has been discussed by Koen & Lombard (1993), Konig & Timmer (1997),\nand Timmer et al. (2000). As we will explain, our method\naccelerates the parameter estimation problem by taking advantage of the discrete wavelet transform. It is based on the\n1 The transit duration is also expected to vary in the presence of additional\ngravitating bodies; see, e.g., Kipping (2009).\n\n\f2\nfact that a the covariance matrix of a 1/ f \u03b3 noise process is\nnearly diagonal in a wavelet basis. As long as the actual noise\nis reasonably well described by such a power law, our method\nis attractive for its simplicity, computational speed, and ease\nof implementation, in addition to its grounding in the recent\nliterature on signal processing.\nThe use of the wavelets in signal processing is widespread,\nespecially for the restoration, compression, and denoising of\nimages (see, e.g., Mallat 1999). Parameter estimation using\nwavelets has been considered but usually for the purpose of\nestimating noise parameters (Wornell 1996). An application\nof wavelets to the problem of linear regression with correlated\nnoise was given by Fadili & Bullmore (2002). What is new in\nthis work is the extension to an arbitary nonlinear model, and\nthe application to transit light curves.\nThis paper is organized as follows. In \u00a7 2, we review the\nproblem of estimating model parameters from data corrupted\nby noise, and we review some relevant noise models. In \u00a7 3\nwe present the wavelet method and those aspects of wavelet\ntheory that are needed to understand the method. In \u00a7 4,\nwe test the method using simulated transit light curves, and\ncompare the results to those obtained using the methods mentioned previously. In \u00a7 5 we summarize the method and the\nresults of our tests, and suggest some possible applications\nand extensions of this work.\n2. PARAMETER ESTIMATION WITH \"COLORFUL\" NOISE\n\nConsider an experiment in which samples of an observable\nyi are recorded at a sequence of times {ti : i = 1, . . . , N}. In the\ncontext of a transit light curve, yi is the relative brightness of\nthe host star. We assume that the times ti are known with negligible error. We further assume that in the absence of noise,\nthe samples yi would be given by a deterministic function,\ny(ti ) = f (ti ; p1 , . . . , pK ) = f (ti ; ~p), (no noise)\n\n(1)\n\nwhere ~p = {p1 , . . . , pK } is a set of K parameters that specify the function f . For an idealized transit light curve, those\nparameters may be the fractional loss of light \u03b4, the total duration T , and ingress or egress duration \u03c4 , and the midtransit\ntime tc , in the notation of Carter et al. (2008). More realistic functions have been given by Mandel & Agol (2002) and\nGim\u00e9nez (2007).\nWe further suppose that a stochastic noise process \u01eb(t) has\nbeen added to the data, giving\ny(ti ) = f (ti ; ~p) + \u01eb(ti). (with noise)\n\nin which case there is only one error parameter, \u03c3, specifying\nthe width of the distribution.\nIf the noise is correlated then it is characterized by a joint\nprobability distribution that is generally a function of all the\ntimes of observation. We assume that the function is a multivariate Gaussian function, in which case the noise process is\nentirely characterized by the covariance matrix\n\u03a3(ti ,t j ) = h\u01eb(ti )\u01eb(t j )i.\n\n(4)\n\nR(\u03c4 ) \u2261 h\u01eb(t)\u01eb(t + \u03c4 )i.\n\n(5)\n\nHere, the quantity h\u01ebi is the mean of the stochastic function \u01eb\nover an infinite number of independent realizations. We further assume that the covariance depends only on the difference in time between two samples, and not on the absolute\ntime of either sample. In this case, the noise source is said to\nbe stationary and is described entirely by its autocovariance\nR(\u03c4 ) (Bracewell 1965):\nThe parameter estimation problem is often cast in terms of\nfinding the set of parameters p\u0302k that maximize a likelihood\nfunction. For the case of Gaussian uncorrelated noise the\nlikelihood function is\n\u0012 2 \u0013\nN\nY\nr\n1\n\u221a\nexp \u2212 i 2 ,\n(6)\nL=\n2\n2\u03c3\u0302\n2\u03c0\u03c3\u0302\ni=1\nwhere ri is the residual defined as yi \u2212 f (ti ; ~p), and \u03c3\u0302 is an estimate of the single noise parameter \u03c3. Maximizing the likelihood L is equivalent to minimizing the \u03c72 statistic\n\u03c72 =\n\n\u03c3\u0302\n\ni\n\n.\n\n(7)\n\nIn transit photometry, the estimator \u03c3\u0302 of the noise parameter \u03c3 is usually not taken to be the calculated noise based on\nexpected sources such as shot noise. This is because the actual amplitude of the noise is often greater than the calculated\nvalue due to noise sources that are unknown or at least illquantified. Instead, \u03c3\u0302 is often taken to be the standard deviation of the data obtained when the transit was not occurring,\nor the value for which \u03c72 = Ndof for the best-fitting (minimum\u03c72 ) model. These estimates work well when the noise process\nis Gaussian, stationary, and uncorrelated. For the case of correlated noise, Eqn. (7) is replaced by (Gould 2003)\n\n(2)\n\nAs a stochastic function, ~\u01eb = {\u01eb(t1 ), . . . \u01eb(tN )} is characterized\nby its joint distribution function D(~\u01eb; ~\nq), which in turn depends on some parameters ~\nq and possibly also the times of\nobservation. The goal of parameter estimation is to use the\ndata y(ti ) to calculate credible intervals for the parameters ~p,\noften reported as best estimates p\u0302k and error bars \u03c3\u0302 pk with\nsome quantified degree of confidence. The estimate of ~p and\nthe associated errors depend crucially on how one models the\nnoise and how well one can estimate the relevant noise parameters ~q.\nIn some cases one expects and observes the noise to be uncorrelated. For example, the dominant noise source may be\nshot noise, in which case the noise process is an uncorrelated\nPoisson process that in the limit of large numbers of counts is\nwell-approximated by an uncorrelated Gaussian process,\n\u0012 2 \u0013\nN\nY\n\u01eb\n1\n2\n\u221a\n(3)\nexp \u2212 i 2 ,\nD(~\u01eb; ~q) = N (\u01eb; \u03c3 ) =\n2\n2\u03c3\n2\u03c0\u03c3\ni=1\n\nN \u0010 \u00112\nX\nri\n\n\u03c72 =\n\nN X\nN\nX\n\nri (\u03a3\u0302\u22121 )i j r j .\n\n(8)\n\ni=1 j=1\n\nThe case of uncorrelated noise corresponds to \u03a3\u0302i j = \u03c3\u0302 2 \u03b4i j .\nIt is at this point where various methods for modeling correlated noise begin to diverge. One approach is to estimate \u03a3\u0302\nfrom the sample autocovariance R\u0302(\u03c4 ) of the time series, just as\n\u03c3\u0302 can be estimated from the standard deviation of the residuals in the case of uncorrelated noise. However, the calculation of \u03c72 has a worst-case time-complexity of O(N 2 ) and\niterative parameter estimation techniques can be prohibitively\nslow. One might ameliorate the problem by truncating the covariance matrix at some maximum lag, i.e., by considering the\ntruncated \u03c72 statistic\n\u03c72 (L) =\n\nN\nL\nX\nX\ni=1\n\nl=\u2212L\n1<i+l<N\n\nri (\u03a3\u0302\u22121 )i(i+l) ri+l ,\n\n(9)\n\n\f3\nbut in the presence of long-range correlations one needs\nto retain many lags to obtain accurate parameter estimates.\n(In \u00a7 4.3, we will give an example where 50\u201375 lags were\nneeded.) Alternatively, one may model the autocorrelation\nfunction and therefore the covariance matrix using an autoregressive moving-average (ARMA) model with enough\nterms to give a good fit to the data (see, e.g., Koen & Lombard 1993). Again, though, in the presence of long-range correlations the model covariance matrix will be non-sparse and\ncomputationally burdensome.\nPont et al. (2006) presented a useful simplification in the\ncontext of a transit search, when data are obtained on many\ndifferent nights. In such cases it is reasonable to approximate the covariance matrix as block-diagonal, with different\nblocks corresponding to different nights. Pont et al. (2006)\nalso gave a useful approximation for the covariance structure\nwithin each block, based on the variance in boxcar-averaged\nversions of the signal. Ultimately their procedure results in\nan equation resembling Eqn. (7) for each block, but where \u03c3\u0302\nis the quadrature sum of \u03c3w (the \"white noise\") and \u03c3r (the\n\"red noise,\" estimated from the boxcar-averaged variance). In\nthis paper, all our examples involve a single time series with\nstationary noise properties, and the net effect of the Pont et\nal. (2006) method is to enlarge the parameter errors by a factor\ns\n\u0012 \u00132\n\u03c3r\n(10)\n\u03b2 = 1+\n\u03c3w\nrelative to the case of purely white noise (\u03c3r = 0). We will\nrefer to this method as the \"time-averaging\" method.\nAnother approach is to use Eqn. (7) without any modifications, but to perform the parameter optimization on a large\ncollection of simulated data sets that are intended to have the\nsame covariance structure as the actual data set. This is the\nbasis of the \"residual permutation\" method that is also discussed further in \u00a7 4.4. As mentioned above, this method is\na variant of a bootstrap analysis that takes into account timecorrelated noise. More details on both the time-averaging and\nresidual-permutation methods are given in \u00a7 4.4.\nOur approach in this paper was motivated by the desire to\nallow for the possibility of long-range correlations, and yet to\navoid the slowness of any method based on Eqn. (9) or other\ntime-domain methods. Rather than characterizing the noise in\nthe time domain, we characterize it by its Power Spectral Density (PSD) S( f ) at frequency f , defined as the square of the\nFourier transform of \u01eb(t), or equivalently, the Fourier transform of the autocovariance R(\u03c4 ). We restrict our discussion to\nnoise sources with a PSD\nS( f ) =\n\nA\nf\u03b3\n\n(11)\n\nfor some A > 0 and spectral index \u03b3. For the special case of\nuncorrelated noise, \u03b3 = 0 and S( f ) is independent of f . This\ntype of noise has equal power density at all frequencies, which\nis why it is called \"white noise,\" in an analogy with visible\nlight. As \u03b3 is increased, there is an increasing preponderance\nof low-frequency power over high-frequency power, leading\nto longer-range correlations in time.\nNoise with a power spectrum 1/ f \u03b3 is ubiquitous in nature\nand in experimental science, including astrophysics (see, e.g.,\nPress 1978). Some examples of 1/ f \u03b3 noise are shown in\nFig. 1 for a selection of spectral indices. In an extension of\nthe color analogy, \u03b3 = 1 noise is sometimes referred to as\n\n\"pink noise\" and \u03b3 = 2 noise as \"red noise.\" The latter is\nalso known as a Brownian process, although not because of\nthe color brown but instead because of the Scottish botanist\nRobert Brown. However, as we have already noted, the term\n\"red noise\" is often used to refer to any type of low-frequency\ncorrelated noise.\nHere we do not attempt to explain how 1/ f \u03b3 noise arises\nin a given situation. Instead we assume that the experimenter\nhas done his or her best to understand and to reduce all sources\nof noise as far as possible, but despite these efforts there remains a component of 1/ f \u03b3 noise. In transit photometry these\ncorrelations often take the form of \"bumps,\" \"wiggles,\" and\n\"ramps\" in a light curve and are often attributed to differential atmospheric extinction, instrumental artifacts such as\nimperfect flat-fielding, and stellar granulation or other astrophysical effects. The method presented in this paper is essentially a model of the likelihood function that retains the\nessential information in the covariance matrix without being\nprohibitively expensive to compute and store. It is based on a\nwavelet-based description, the subject of the next section.\n3. WAVELETS AND 1/ f \u03b3 NOISE\n\nOne may regard a time series with N points as a vector in\nan N-dimensional space that is spanned by N orthonormal unit\nvectors, one for each time index (the \"time basis\"). The computational difficulty with correlated noise is that the sample\ncovariance matrix \u03a3\u0302 is not diagonal in the time basis, nor is it\nnecessarily close to being diagonal in realistic cases. This motivates a search for some alternative basis spanning the data\nspace for which the covariance matrix is diagonal or nearly\ndiagonal. For example, if the noise took the form of additive\nquasiperiodic signals, it would be logical to work in a Fourier\nbasis instead of the time basis.\nThe mathematical result that underpins our analysis algorithm is that in the presence of 1/ f \u03b3 noise, the covariance\nmatrix is nearly diagonal in a suitable wavelet basis. Before\ngiving the details of the algorithm we will briefly review the\nwavelet transform. Our discussion is drawn primarily from\nWornell (1996), Teolis (1998), Daubechies (1988), and Mallat (1999). Practical details and an sample implementation of\nthe wavelet transform are given by Press et al. (2007).\nA wavelet is a function that is analogous to the sine and\ncosine functions of the Fourier transform. Some properties\nthat wavelets share with sines and cosines are that they are\nlocalized in frequency space, and they come in families that\nare related by translations and dilations. Wavelets are unlike\nsine and cosine functions in that wavelets are strongly localized in time. A wavelet basis is derived from a single \"mother\nwavelet\" \u03c8(t), which may have a variety of functional forms\nand analytic properties. The individual basis functions are\nformed through translations and dilations of \u03c8(t). The choice\nof mother wavelet depends on the specific application. We restrict our focus to dyadic orthogonal wavelet bases with basis\nfunctions\n\u03c8nm (t) = \u03c8(2mt \u2212 n)\n\n(12)\n\nfor all integers m and n, and we further require \u03c8(t) to have\none or more vanishing moments.2 In this case, the pair of\n2 In particular it is required that the mother wavelet \u03c8(t) has zero mean.\nThis is a necessary and sufficient condition to ensure the invertibility of the\nwavelet transform.\n\n\f4\n\nF IG . 1.- Examples of 1/ f \u03b3 noise. Uncorrelated (white) noise corresponds to \u03b3 = 0. \"Pink\" noise corresponds to \u03b3 = 1. \"Red\" noise or Brownian motion\ncorresponds to \u03b3 = 2. These time series were generated using the wavelet-based method described in \u00a7 4.\n\nequations analogous to the Fourier series and its inversion is\n\u01eb(t) =\n\n\u221e\nX\n\n\u221e\nX\n\nm\n\u01ebm\nn \u03c8n (t)\n\nm=\u2212\u221e n=\u2212\u221e\nZ \u221e\n\u01eb(t)\u03c8nm (t)dt\n\u01ebm\nn =\n\u2212\u221e\n\n(13)\n(14)\n\nwhere \u01ebm\nn is referred to as the wavelet coefficient of \u01eb(t) at\nresolution m and translation n.\n3.1. The wavelet transform as a multiresolution analysis\n\nWe will see shortly that some extra terms are required in\nEqn. (14) for real signals with some minimum and maximum\nresolution. To explain those terms it is useful to describe the\nwavelet transform as a multiresolution analysis, in which we\nconsider successively higher-resolution approximations of a\nsignal. An approximation with a resolution of 2m samples per\nunit time is a member of a resolution space Vm . Following\nWornell (1996) we impose the following conditions:\n1. if f (t) \u2208 Vm then for some integer n, f (t \u2212 2\u2212mn) \u2208 Vm\n2. if f (t) \u2208 Vm then f (2t) \u2208 Vm+1 .\n\nThe first condition requires that Vm contain all translations (at\nthe resolution scale) of any of its members, and the second\ncondition ensures that the sequence of resolutions is nested:\nVm is a subset of the next finer resolution Vm+1 . In this way, if\n\u01ebm (t) \u2208 Vm is an approximation to the signal \u01eb(t), then the next\nfiner approxmation \u01ebm+1 (t) \u2208 Vm+1 contains all the information\nencoded in \u01ebm (t) plus some additional detail dm (t) defined as\ndm (t) \u2261 \u01ebm+1 (t) \u2212 \u01ebm(t).\n\n(15)\n\nWe may therefore build an approximation at resolution M by\nstarting from some coarser resolution k and adding successive\ndetail functions:\n\u01ebM (t) = \u01ebk (t) +\n\nM\nX\nm=k\n\ndm (t)\n\n(16)\n\nThe detail functions dm (t) belong to a function space Wm (t),\nthe orthogonal complement of the resolution Vm .\nWith these conditions and definitions, the orthogonal basis functions of Wm are the wavelet functions \u03c8nm (t), obtained by translating and dilating some mother wavelet \u03c8(t).\nThe orthogonal basis functions of Vm are denoted \u03c6m\nn (t), obtained by translating and dilating a so-called \"father\" wavelet\n\u03c6(t). Thus, the mother wavelet spawns the basis of the detail\nspaces, and the father wavelet spawns the basis of the resolution spaces. They have complementary characteristics, with\nthe mother acting as a high-pass filter and the father acting as\na low-pass filter.3\nIn Eqn. (16), the approximation \u01ebk (t) is a member of Vk ,\nwhich is spanned by the functions \u03c6kn (t), and dm (t) is a member of Wm , which is spanned by the functions \u03c8nm (t). Thus we\nmay rewrite Eqn. (16) as\n\u01ebM (t) =\n\n\u221e\nX\n\n\u01edkn \u03c6kn (t) +\n\nn=\u2212\u221e\n\nM X\n\u221e\nX\n\nm\n\u01ebm\nn \u03c8n (t).\n\n(17)\n\nm=k n=\u2212\u221e\n\nm\nThe wavelet coefficients \u01ebm\nn and the scaling coefficients \u01edn are\ngiven by\nZ \u221e\nm\n\u01eb(t)\u03c8nm (t)dt\n(18)\n\u01ebn =\n\u2212\u221e\nZ \u221e\n\u01edm\n\u01eb(t)\u03c6m\n(19)\nn =\nn (t)dt\n\u2212\u221e\n\nEqn. (17) reduces to the wavelet-only equation (13) for the\ncase of a continuously sampled signal \u01eb(t), when we have access to all resolutions m from \u2212\u221e to \u221e.4\nThere are many suitable choices for \u03c6 and \u03c8, differing in\nthe tradeoff that must be made between smoothness and lo3 More precisely, the wavelet and scaling functions considered here are\n\"quadrature mirror filters\" (Mallat 1999).\n4 The signal must also be bounded in order for the approximation to the\nsignal at infinitely coarse resolution to vanish, i.e., limk\u2192\u2212\u221e \u01ebk (t) = 0.\n\n\f5\ncalization. The simplest choice is due to Haar (1910):\n\u001a\n1 if 0 < t \u2264 1\n\u03c6(t) = 0 otherwise .\n\uf8f1\n\uf8f2 1 if \u2212 21 < t \u2264 0\n\u03c8(t) = \u22121 if 0 < t \u2264 12\n\uf8f3\n0 otherwise\n\nanalysis using this basis. Press et al. (2007) provide code to\nimplement the wavelet transform in this basis.\n(20)\n(21)\n\nThe left panel of Fig. 2 shows several elements of the approximation and detail bases for a Haar multiresolution analysis.\nThe left panels of Fig. 3 illustrate a Haar multiresolution analysis for an arbitrarily chosen signal \u01eb(t), by plotting both the\napproximations \u01ebm (t) and details dm (t) at several resolutions\nm. The Haar analysis is shown for pedagogic purposes only.\nIn practice we found it advantageous to use the more complicated fourth-order Daubechies wavelet basis, described in the\nnext section, for which the elements and the multiresolution\nanalysis are illustrated in the right panels of Fig. 2-3.\n3.2. The Discrete Wavelet Transform\n\nReal signals are limited in resolution, leading to finite M\nand k in Eqn. (17). They are also limited in time, allowing\nonly a finite number of translations Nm at a given resolution\nm. Starting from Eqn. (17), we truncate the sum over n and\nreindex the resolution sum such that the coarsest resolution is\nk = 1, giving\n\u01ebM (t) =\n\nN1\nX\n\n\u01ed1n \u03c61n (t) +\n\nn=1\n\nNm\nM X\nX\n\nm\n\u01ebm\nn \u03c8n (t)\n\n(22)\n\nm=2 n=1\n\nwhere we have taken t = 0 to be the start of the signal. Since\nthere is no information on timescales smaller than 2\u2212M , we\nneed only consider \u01ebM (ti ) at a finite set of times ti :\n\u01eb(ti ) =\n\nN1\nX\nn=1\n\n\u01ed1n \u03c61n (ti ) +\n\nNm\nM X\nX\n\nm\n\u01ebm\nn \u03c8n (ti ).\n\n(23)\n\nm=2 n=1\n\nEqn. (23) is the inverse of the Discrete Wavelet Transform\n(DWT). Unlike the continuous transform of Eqn. (13), the\nDWT must include the coarsest level approximation (the first\nterm in the preceding equation) in order to preserve all the\ninformation in \u01eb(ti ). For the Haar wavelet, the coarsest approximation is the mean value. For data sets with N = n0 2M\nuniformly spaced samples in time, we will have access to a\nmaximal scale M, as in Eqn. (23), with Nm = n0 2m\u22121 .\nA crucial point is the availability of the Fast Wavelet Transform (FWT) to perform the DWT (Mallat 1989). The FWT is\na pyramidal algorithm operating on data sets of size N = n0 2M\nreturning n0 (2M \u2212 1) wavelet coefficients and n0 scaling coefficients for some n0 > 0, M > 0. The FWT is a computationally efficient algorithm that is easily implemented (Press et al.\n2007) and has O(N) time-complexity (Teolis 1998).\nDaubechies (1988) generalized the Haar wavelet into a\nlarger family of wavelets, categorized according to the number of vanishing moments of the mother wavelet. The Haar\nwavelet has a single vanishing moment and is the first member\nof the family. In this work we used the most compact member (in time and frequency), \u03c8 =4 D and \u03c6 =4 A, which is well\nsuited to the analysis of 1/ f \u03b3 noise for 0 < \u03b3 < 4 (Wornell\n1996). We plot 4Dnm and 4Am\nn in the time-domain for several n,\nm in Fig. 2, illustrating the rather unusual functional form of\n4D. The right panel of Fig. 3 demonstrates a multiresolution\n\n3.3. Wavelet transforms and 1/ f \u03b3 noise\n\nAs alluded in \u00a7 3, the wavelet transform acts as a nearly diagonalizing operator for the covariance matrix in the presence\nof 1/ f \u03b3 noise. The wavelet coefficients \u01ebm\nn of such a noise\nprocess are zero-mean, nearly uncorrelated random variables.\nSpecifically, the covariance between scales m, m\u2032 and translations n, n\u2032 is (Wornell 1996, p. 65)\n\u0001\nm\u2032\n2 \u2212\u03b3m\n(24)\n\u03b4m,m\u2032 \u03b4n,n\u2032 .\nh\u01ebm\nn \u01ebn\u2032 i \u2248 \u03c3r 2\n\nThe wavelet basis is also convenient for the case in which\nthe noise is modeled as the sum of an uncorrelated component\nand a correlated component,\n\u01eb(t) = \u01eb0 (t) + \u01eb\u03b3 (t),\n\n(25)\n\nwhere \u01eb0 (t) is a Gaussian white noise process (\u03b3 = 0) with a\nsingle noise parameter \u03c3w , and \u01eb\u03b3 (t) has S( f ) = A/ f \u03b3 . In the\ncontext of transit photometry, white noise might arise from\nphoton-counting statistics (and in cases where the detector is\nwell-calibrated, \u03c3w is a known constant), while the \u03b3 6= 0 term\nrepresents the \"rumble\" on many time scales due to instrumental, atmospheric, or astrophysical sources. For the noise\nprocess of Eqn. (25) the covariance between wavelet coefficients is\n\u0001\nm\u2032\n2 \u2212\u03b3m\n(26)\nh\u01ebm\n+ \u03c3w2 \u03b4m,m\u2032 \u03b4n,n\u2032 .\nn \u01ebn\u2032 i \u2248 \u03c3r 2\nand the covariance betwen the scaling coefficients \u01edm\nn is\n2 \u2212\u03b3m\nm\ng(\u03b3) + \u03c3w2\nh\u01edm\nn \u01edn i \u2248 \u03c3r 2\n\n(27)\n\nwhere g(\u03b3) is a constant of order unity; for the purposes of\nthis work g(1) = (2 ln 2)\u22121 \u2248 0.72 (Fadili & Bullmore 2002).\nEqns. (26) and (27) are the key mathematical results that form\nthe foundation of our algorithm. For proofs and further details, see Wornell (1996).\nIt should be noted that the correlations between the wavelet\nand scaling coefficients are small but not exactly zero. The decay rate of the correlations with the resolution index depends\non the choice of wavelet basis and on the spectral index \u03b3.\nBy picking a wavelet basis with a higher number of vanishing\nmoments, we hasten the decay of correlations. This is why\nwe chose the Daubechies 4th-order basis instead of the Haar\nbasis. In the numerical experiments decribed in \u00a7 4, we found\nthe covariances to be negligible for the purposes of parameter\nestimation. In addition, the compactness of the Daubechies\n4th-order basis reduces artifacts arising from the assumption\nof a periodic signal that is implicit in the FWT.\n3.4. The whitening filter\n\nGiven an observation of noise \u01eb(t) that is modeled as in\nEqn. (25), we may estimate the \u03b3 6= 0 component by rescaling the wavelet and scaling coefficients and filtering out the\nwhite component:\n\u0013\nN1 \u0012\nX\n\u03c3r2 2\u2212\u03b3 g(\u03b3)\n\u01ed1 \u03c61 (t) +\n(28)\n\u01eb\u03b3 (t) =\n\u03c3r2 2\u2212\u03b3 g(\u03b3) + \u03c3w2 n n\nn=1\n\u0013\nNm \u0012\nM X\nX\n\u03c3r2 2\u2212\u03b3m\nm\n\u01ebm\n(29)\nn \u03c8n (t).\n\u03c3r2 2\u2212\u03b3m + \u03c3w2\nm=2 n=1\n\nWe may then proceed to subtract the estimate of the correlated component from the observed noise, \u01eb0 (t) = \u01eb(t) \u2212 \u01eb\u03b3 (t)\n\n\f6\n\nF IG . 2.- Examples of discrete wavelet and scaling functions, for N = 2048. Left.-Haar wavelets and the corresponding father wavelets, also known as\nm\nm\n2nd-order Daubechies orthonormal wavelets or 2Dnm and 2Am\nn . Right.-4th-order Daubechies orthonormal wavelets, or 4Dn and 4An .\n\nF IG . 3.- Illustration of a multiresolution analysis, for the function \u01eb(t) = sin[4\u03c0(t/1024)3 ] (dashed line). Plotted are the approximations \u01ebm (t) to the function\nat successive resolutions, along with the detail functions dm (t). Left.-Using the Haar wavelet basis. Right.-Using the 4th-order Daubechies wavelet basis.\n\n(Wornell 1996, p. 76). In this way the FWT can be used to\n\"whiten\" the noise.\n\n3.5. The wavelet-based likelihood\n\nArmed with the preceding theory, we rewrite the likelihood\nfunction of Eqn. (6) in the wavelet domain. First we transform\nthe residuals ri \u2261 yi \u2212 f (ti ; ~\np), giving\nm\nm\nrnm = ym\np) = \u01ebm\nn \u2212 f n (~\n\u03b3,n + \u01eb0,n\nr\u0304n1 = \u02331n \u2212 f \u0304n1 (~p) = \u01ed1\u03b3,n + \u01ed10,n\n\n(30)\n(31)\n\nm\nwhere ym\np) are the discrete wavelet coefficients of\nn and f n (~\nthe data and the model. Likewise, \u02331n and f \u0304n1 (~p) are the n0\nscaling coefficients of the data and the model. Given the diagonal covariance matrix shown in Eqns. (26) and (27), the\nlikelihood L is a product of Gaussian functions at each scale\n\nm and translation n:\n\uf8f1\n\"\nm\u22121\n\u00012 #\uf8fc\nM nY\n02\n\uf8fd\n\uf8f2Y\nrnm\n1\np\nexp\n\u2212\nL=\n2\n2\n\uf8fe\n\uf8f3\n2\u03c3W\n2\u03c0\u03c3W\nm=2 n=1\n\uf8f1\n\uf8fc\n\"\n\u00012 #\uf8fd\nn0\n\uf8f2Y\nr\u0304n1\n1\nq\n\u00d7\nexp \u2212\n\uf8f3\n2\u03c3S2 \uf8fe\n2\u03c0\u03c3 2\nn=1\n\n(32)\n\nS\n\nwhere\n\n2\n\u03c3W\n= \u03c3r2 2\u2212\u03b3m + \u03c3w2\n\n\u03c3S2 = \u03c3r2 2\u2212\u03b3 g(\u03b3) + \u03c3w2\n\n(33)\n(34)\n\nare the variances of the wavelet and scaling coefficients respectively. For a data set with N points, calculating the likelihood function of Eqn. (32) requires multiplying N Gaussian\nfunctions. The additional step of computing the FWT of the\nresiduals prior to computing L adds O(N) operations. Thus,\n\n\f7\nthe entire calculation has a time-complexity O(N).\nFor this calculation we must have estimators of the three\nnoise parameters \u03b3, \u03c3r and \u03c3w . These may be estimated separately from the model parameters ~p, or simultaneously with\nthe model parameters. For example, in transit photometry, the\ndata obtained outside of the transit may be used to estimate\nthe noise parameters, which are then used in Eqn. (32) to estimate the model parameters. Or, in a single step we could maximize Eqn. (32) with respect to all of \u03b3, \u03c3r , \u03c3w and ~p. Fitting\nfor both noise and transit parameters simultaneously is potentially problematic, because some of the correlated noise may\nbe \"absorbed\" into the choices of the transit parameters, i.e.,\nthe errors in the noise parameters and transit parameters are\nthemselves correlated. This may cause the noise level and the\nparameter uncertainties to be underestimated. Unfortunately,\nthere are many instances when one does not have enough outof-transit data for the strict separation of transit and noise parameters to be feasible.\nIn practice the optimization can be accomplished with an\niterative routine [such as AMOEBA, Powell's method, or a\nconjugate-gradient method; see Press et al. (2007)]. Confidence intervals can then be defined by the contours of constant\nlikelihood. Alternatively one can use a Monte Carlo Markov\nChain [MCMC; see, e.g., Gregory (2005)], in which case the\njump-transition likelihood would be given by Eqn. (32). The\nadvantages of the MCMC method have led to its adoption by\nmany investigators (see, e.g., Holman et al. 2006, Burke et\nal. 2007, Collier Cameron et al. 2007). For that method, computational speed is often a limiting factor, as a typical MCMC\nanalysis involves several million calculations of the likelihood\nfunction.\n3.6. Some practical considerations\n\nSome aspects of real data do not fit perfectly into the\nrequirements of the DWT. The time sampling of the data\nshould be approximately uniform, so that the resolution scales\nof the multiresolution analysis accurately reflect physical\ntimescales. This is usually the case for time-series photometric data. Gaps in a time series can be fixed by applying the\nDWT to each uninterrupted data segment, or by filling in the\nmissing elements of the residual series with zeros.\nThe FWT expects the number of data points to be an integral multiple of some integral power of two. When this is not\nthe case, the time series may be truncated to the nearest such\nboundary; or it may be extended using a periodic boundary\ncondition, mirror reflection, or zero-padding. In the numerical experiments described below, we found that zero-padding\nhas negligible effects on the calculation of likelihood ratios\nand parameter estimation.\nThe FWT generally assumes a periodic boundary condition\nfor simplicity of computation. A side effect of this simplication is that information at the beginning and end of a time series are artificially associated in the wavelet transform. This\nis one reason why we chose the 4th-order Daubechies-class\nwavelet basis, which is well localized in time, and does not\nsignificantly couple the beginning and the end of the time series except on the coarsest scales.\n4. NUMERICAL EXPERIMENTS WITH TRANSIT LIGHT CURVES\n\nWe performed many numerical experiments to illustrate and\ntest the wavelet method. These experiments involved estimating the parameters of simulated transit light curves. We also\ncompared the wavelet analysis to a \"white\" analysis, by which\nwe mean a method that assumes the errors to be uncorrelated,\n\nand to two other analysis methods drawn from the literature.\nBecause we used simulated transit light curves with known\nnoise and transit parameters, the \"truth\" was known precisely,\nallowing both the absolute and relative merits of the methods\nto be evaluated.\n4.1. Estimating the midtransit time: Known noise parameters\n\nIn this section we consider the case in which the noise parameters \u03b3, \u03c3r , and \u03c3w are known with negligible error. We\nhave in mind a situation in which a long series of out-of-transit\ndata are available, with stationary noise properties.\nWe generated transit light curves with known transit parameters ~p, contaminated by an additive combination of a\nwhite and a correlated (1/ f \u03b3 ) noise source. Then we used an\nMCMC method to estimate the transit parameters and their\n68.3% confidence limits. (The technique for generating noise\nand the MCMC method are described in detail below.) For\neach realization of a simulated light curve, we estimated transit parameters using the likelihood defined either by Eqn. (6)\nfor the white analysis, or Eqn. (32) for the wavelet analysis.\nFor a given parameter pk , the estimator p\u0302k was taken to be\nthe median of the values in the Markov chain and \u03c3\u0302 pk was\ntaken to be the standard deviation of those values. To assess\nthe results, we considered the \"number-of-sigma\" statistic\nN \u2261 ( p\u0302k \u2212 pk ) /\u03c3\u0302 pk .\n\n(35)\n\nIn words, N is the number of standard deviations separating\nthe parameter estimate p\u0302k from the true value pk . If the error\nin pk is Gaussian, then a perfect analysis method should yield\nresults for N with an expectation value of 0 and variance of\n1. If we find that the variance of N is greater than one, then\nwe have underestimated the error in p\u0302k and we may attribute\ntoo much significance to the result. On the other hand, if the\nvariance of N is smaller than one, then we have overestimated\n\u03c3 pk and we may miss a significant discovery. If we find that\nthe mean of N is nonzero then the method is biased.\nFor now, we consider only the single parameter tc , the time\nof midtransit. The tc parameter is convenient for this analysis as it is nearly decoupled from the other transit parameters\n(Carter et al. 2008). Furthermore, as mentioned in the introduction, the measurement of the midtransit time cannot be\nimproved by observing other transit events, and variations in\nthe transit interval are possible signs of additional gravitating\nbodies in a planetary system.\nThe noise was synthesized as follows. First, we generated\na sequence of N = 1024 independent random variables obeying the variance conditions from Eqns. (26) and (27) for 1023\nwavelet coefficients over 9 scales and a single scaling coefficient at the coarsest resolution scale. We then performed the\ninverse FWT of this sequence to generate our noise signal. In\nthis way, we could select exact values for \u03b3, \u03c3r , and \u03c3w . We\nalso needed to find the single parameter \u03c3 for the white-noise\nanalysis; it is not simply related to the parameters \u03b3, \u03c3r , and\n\u03c3w . In practice, we found \u03c3 by calculating the median sample\nvariance among 104 unique realizations of a noise source with\nfixed parameters \u03b3, \u03c3r , and \u03c3w .\nFor the transit model, we used the analytic formulas of\nMandel & Agol (2002), with a planet-to-star ratio of R p /R\u22c6 =\n0.15, a normalized orbital distance of a/R\u22c6 = 10, and an orbital inclination of i = 90\u25e6 , as appropriate for a gas giant planet\nin a close-in orbit around a K star. These correspond to a\nfractional loss of light \u03b4 = 0.0225, duration T = 1.68 hr, and\npartial duration \u03c4 = 0.152 hr. We did not include the effect\n\n\f8\nof limb darkening, as it would increase the computation time\nand has little influence on the determination of tc (Carter et\nal. 2009). Each simulated light curve spanned 3 hr centered\non the midtransit time, with a time sampling of 11 s, giving\n1024 uniformly spaced samples. A noise-free light curve is\nshown in Fig. 4.\nFor the noise model, we chose \u03c3w = 1.35 \u00d7 10\u22123 and \u03b3 = 1,\nand tried different choices for \u03c3r . We denote by \u03b1 the ratio\nof the rms values of the correlated noise component and the\nwhite noise component.5 The example in Fig. 4 has \u03b1 = 1/3.\nAs \u03b1 is increased from zero, the correlated component becomes more important, as is evident in the simulated data\nplotted in Fig. 5. Our choice of \u03c3w corresponds to a precision of 5.8 \u00d7 10\u22124 per minute-equivalent sample, and was inspired by the recent work by Johnson et al. (2009) and Winn\net al. (2009), which achieved precisions of 5.4 \u00d7 10\u22124 and\n4.0 \u00d7 10\u22124 per minute-equivalent sample, respectively. Based\non our survey of the literature and our experience with the\nTransit Light Curve project (Holman et al. 2006, Winn et\nal. 2007), we submit that all of the examples shown in Fig. 5\nare \"realistic\" in the sense that the bumps, wiggles, and ramps\nresemble features in actual light curves, depending on the instrument, observing site, weather conditions, and target star.\nFor a given choice of \u03b1, we made 10,000 realizations of the\nsimulated transit light curve with 1/ f noise. We then constructed two Monte Carlo Markov Chains for tc starting at\nthe true value of tc = 0. One chain was for the white analysis, with a jump-transition likelihood given by Eqn. (6). The\nother chain was for the wavelet analysis, using Eqn. (32) instead. Both chains used the Metropolis-Hastings jump condition, and employed perturbation sizes such that \u224840% of\njumps were accepted. Initial numerical experiments showed\nthat the autocorrelation of a given Markov chain for tc is\nsharply peaked at zero lag, with the autocorrelation dropping\nbelow 0.2 at lag-one. This ensured good convergence with\nchain lengths of 500 (Tegmark et al. 2004). Chain histograms\nwere also inspected visually to verify that the distribution was\nsmooth. We recorded the median \u02c6tc and standard deviation \u03c3\u0302tc\nfor each chain and constructed the statistic N for each separate analysis (white or wavelet). Finally, we found the median\nand standard deviation of N over all 10,000 noise realizations.\nFig. 6 shows the resulting distributions of N , for the particular case \u03b1 = 1/3. Table 1 gives a collection of results for\nthe choices \u03b1 = 0, 1/3, 2/3, and 1. The mean of N is zero\nfor both the white and wavelet analyses: neither method is\nbiased. This is expected, because all noise sources were described by zero-mean Gaussian distributions. However, the\nwidths of the distributions of N show that the white analysis underestimates the error in tc . For a transit light curve\nconstructed with equal parts white and 1/ f noise (\u03b1 = 1), the\nwhite analysis gave an estimate of tc that differs from the true\nvalue by more than 1 \u03c3 nearly 80% of the time. The factor by\nwhich the white analysis underestimates the error in tc appears\nto increase linearly with \u03b1. In contrast, for all values of \u03b1, the\nwavelet analysis maintains a unit variance in N , as desired.\nThe success of the wavelet method is partially attributed to\nthe larger (and more appropriate) error intervals that it returns\nfor \u02c6tc . It is also partly attributable to an improvement in the\naccuracy of \u02c6tc itself: the wavelet method tends to produce \u02c6tc\nvalues that are closer to the true tc . This is shown in the final\n5 We note that although \u03c3 is the rms of the white noise component, \u03c3 is\nw\nr\ngenerally not the rms of the correlated component. The notation is unfortunate, but follows that of Wornell (1996).\n\nTABLE 1\nE STIMATES OF MID - TRANSIT TIME , tc , FROM DATA WITH KNOWN NOISE\nPROPERTIES\n\n\u03b1\n\nh\u03c3\u0302tc i [sec]\n\nhN i\n\n\u03c3N\n\nprob(N > 1)\n\nprob(best)a\n\nWhite\n\n0\n1/3\n2/3\n1\n\n4.1\n4.3\n5.0\n5.9\n\n+0.004\n\u22120.005\n+0.005\n\u22120.036\n\n0.95\n1.93\n3.04\n3.82\n\n29%\n61%\n75%\n79%\n\n50%\n39%\n35%\n34%\n\nWavelet\n\n0\n1/3\n2/3\n1\n\n4.0\n7.2\n11.5\n16.0\n\n+0.005\n\u22120.004\n\u22120.004\n\u22120.001\n\n0.95\n0.93\n0.94\n0.95\n\n29%\n28%\n28%\n29%\n\n50%\n61%\n65%\n66%\n\nMethod\n\na\n\nThe probability that the analysis method (white or wavelet) returns an estimate\nof tc that is closer to the true value than the other method.\n\ncolumn in Table (1), where we report the percentage of cases\nin which the analysis method (white or wavelet) produces an\nestimate of tc that is closer to the truth. For \u03b1 = 1 the wavelet\nanalysis gives more accurate results 66% of the time.\n4.2. Estimating the midtransit time: Unknown noise\n\nparameters\nIn this section we consider the case in which the noise parameters are not known in advance. Instead the noise parameters must be estimated based on the data. We did this by including the noise parameters as adjustable parameters in the\nMarkov chains. In principle this could be done for all three\nnoise parameters \u03b3, \u03c3r , and \u03c3w , but for most of the experiments presented here we restricted the problem to the case\n\u03b3 = 1. This may be a reasonable simplification, given the preponderance of natural noise sources with \u03b3 = 1 (Press 1978).\nSome experiments involving noise with \u03b3 6= 1 are described at\nthe end of this section.\nWe also synthesized the noise with a non-wavelet technique, to avoid \"stacking the deck\" in favor of the wavelet\nmethod. We generated the noise in the frequency domain, as\nfollows. We specified the amplitudes of the Fourier coefficients using the assumed functional form of the power spectral density [S( f ) \u221d 1/ f ], and drew the phases from a uniform\ndistribution between \u2212\u03c0 and \u03c0. The correlated noise in the\ntime domain was found by performing an inverse Fast Fourier\nTransform. We rescaled the noise such that the rms was \u03b1\ntimes the specified \u03c3w . The normally-distributed white noise\nwas then added to the correlated noise to create the total noise.\nThis in turn was added to the idealized transit model.\nFor each choice of \u03b1, we made 10,000 simulated transit\nlight curves and analyzed them with the MCMC method described previously. For the white analysis, the mid-transit\ntime tc and the single noise parameter \u03c3 were estimated using\nthe likelihood defined via Eqn. (6). For the wavelet analysis\nwe estimated tc and the two noise parameters \u03c3r and \u03c3w using\nthe likelihood defined in Eqn. (32).\nTable 3 gives the resulting statistics from this experiment, in\nthe same form as were given in Table 1 for the case of known\nnoise parameters. (This table also includes some results from\n\u00a7 4.4, which examines two other methods for coping with correlated noise.) Again we find that the wavelet method produces a distribution of N with unit variance, regardless of\n\u03b1; and again, we find that the white analysis underestimates\nthe error in tc . In this case the degree of error underestimation is less severe, a consequence of the additional freedom\n\n\f9\n\nF IG . 4.- Constructing a simulated transit light curve with correlated noise. The total noise is the sum of uncorrelated Gaussian noise with standard deviation\n\u03c3w (upper left panel) and correlated noise with a power spectral density S( f ) \u221d 1/ f and an rms equal to \u03c3w /3 (upper right panel). The total noise (middle left\npanel) is added to an idealized transit model (middle right panel) to produce the simulated data (bottom panel).\n\nin the noise model to estimate \u03c3 from the data. The wavelet\nmethod also gives more accurate estimates of tc than the white\nmethod, although the contrast between the two methods is\nsmaller than it was with for the case of known noise parameters.\nOur numerical results must be understood to be illustrative,\nand not universal. They are specific to our choices for the\nnoise parameters and transit parameters. Via further numerical experiments, we found that the width of N in the white\nanalysis is independent of \u03c3w , but it does depend on the time\nsampling. In particular, the width grows larger as the time\nsampling becomes finer (see Table 2). This can be understood\nas a consequence of the long-range correlations. The white\nanalysis assumes that the increased number of data points will\nlead to enhanced precision, whereas in reality, the correlations\nnegate the benefit of finer time sampling.\nTable 4 gives the results of additional experiments with \u03b3 6=\n1. In those cases we created simulated noise with \u03b3 6= 1 but in\nthe course of the analysis we assumed \u03b3 = 1. The correlated\n\nTABLE 2\nE FFECT OF TIME SAMPLING\nON THE WHITE ANALYSIS\n\nNa\n\nCadence [sec]\n\n\u03c3N\n\n256\n512\n1024\n2048\n4096\n\n42.2\n21.1\n10.5\n5.27\n2.63\n\n1.72\n2.04\n2.69\n3.49\n4.39\n\na\n\nThe number of samples in a\n3 hr interval.\n\nnoise fraction was set to \u03b1 = 1/2 for these tests. The results\nshow that even when \u03b3 is falsely assumed to be unity, the\nwavelet analysis still produces better estimates of tc and more\nreliable error bars than the white analysis.\n\n\f10\n\nF IG . 5.- Examples of simulated transit light curves with different ratios \u03b1 = rmsr /rmsw between the rms values of the correlated noise component and white\nnoise component.\n\nF IG . 6.- Histograms of the number-of-sigma statistic N for the midtransit time tc . Each distribution shows the probability of estimating a value for tc that\ndiffers by N \u03c3 from the true value. The simulated data were created by adding an idealized transit model to a noise source that is the sum of uncorrelated noise\nand 1/ f noise with equal variances (\u03b1 = 1; see the text).\n\n\f11\n\nTABLE 3\nE STIMATES OF tc\n\u03b1\n\nh\u03c3\u0302tc i [sec]\n\nhN i\n\n\u03c3N\n\nprob(N > 1)\n\nprob(better)a\n\nWhite\n\n0\n1/3\n2/3\n1\n\n4.0\n4.2\n4.9\n5.8\n\n\u22120.011\n+0.010\n+0.012\n+0.023\n\n0.97\n1.70\n2.69\n3.28\n\n31%\n57%\n73%\n78%\n\n\u2212\n\u2212\n\u2212\n\u2212\n\nWavelet\n\n0\n1/3\n2/3\n1\n\n4.5\n6.9\n11.2\n15.7\n\n\u22120.009\n\u22120.003\n\u22120.005\n\u22120.007\n\n0.90\n1.03\n1.07\n1.09\n\n26%\n33%\n35%\n36%\n\n50%\n56%\n57%\n57%\n\nTime-averaging\n\n0\n1/3\n2/3\n1\n\n4.4\n6.8\n11.6\n17.6\n\n\u22120.006\n+0.009\n\u22120.012\n+0.007\n\n0.88\n1.15\n1.24\n1.21\n\n26%\n36%\n40%\n38%\n\n50%\n50%\n50%\n50%\n\nResidual-permutation\n\n0\n1/3\n2/3\n1\n\n3.5\n6.6\n11.8\n17.3\n\n\u22120.012\n+0.013\n\u22120.014\n+0.008\n\n1.16\n1.24\n1.28\n1.30\n\n37%\n37%\n38%\n38%\n\n50%\n50%\n49%\n48%\n\nMethod\n\na\n\nFROM DATA WITH UNKNOWN NOISE PROPERTIES\n\nThe probability that the analysis method returns an estimate of tc that is closer to the true\nvalue than the white analysis.\n\n\f12\nTABLE 4\nE STIMATES OF tc\n\nFROM DATA WITH UNKNOWN NOISE PROPERTIES\n\nMethod\n\n\u03b3a\n\nh\u03c3\u0302tc i [sec]\n\nhN i\n\n\u03c3N\n\nprob(N > 1)\n\nprob(best)b\n\nWhite\n\n0.5\n1.5\n\n4.5\n4.6\n\n\u22120.025\n+0.020\n\n1.34\n3.10\n\n47%\n77%\n\n50%\n32%\n\nWavelet\n\n0.5\n1.5\n\n6.7\n6.9\n\n\u22120.021\n+0.002\n\n0.97\n1.17\n\n30%\n39%\n\n50%\n68%\n\na\n\nThe spectral exponent of the Power Spectral Density, S( f ) \u221d 1/ f \u03b3 .\nThe probability that the analysis method (white or wavelet) returns an estimate\nof tc that is closer to the true value than the other method.\nb\n\n4.3. Runtime analysis of the time-domain method\n\nHaving established the superiority of the wavelet method\nover the white method, we wish to show that the wavelet\nmethod is also preferable to the more straightforward approach of computing the likelihood function in the time domain with a non-diagonal covariance matrix. The likelihood\nin this case is given by Eqn. (8).\nThe time-domain calculation and the use of the covariance\nmatrix raised two questions. First, how well can we estimate\nthe autocovariance R(\u03c4 ) from a single time series? Second,\nhow much content of the resulting covariance matrix needs to\nbe retained in the likelihood calculation for reliable parameter estimation? The answer to the first question depends on\nwhether we wish to utilize the sample autocorrelation as the\nestimator of R(\u03c4 ) or instead use a parametric model (such as\nan ARMA model) for the autocorrelation. In either case, our\nability to estimate the autocorrelation improves with number\nof data samples contributing to its calculation. The second\nquestion is important because retaining the full covariance\nmatrix would cause the computation time to scale as O(N 2 )\nand in many cases the analysis would be prohibitively slow.\nThe second question may be reframed as: what is the minimum number of lags L that needs to be considered in computing the truncated \u03c72 of Eqn. (9), in order to give unit variance\nin the number-of-sigma statistic for each model parameter?\nThe time-complexity of the truncated likelihood calculation\nis O(NL). If L . 5 then the time-domain method and the\nwavelet method may have comparable computational timecomplexity, while for larger L the wavelet method would offer\nsignificant advantage.\nWe addressed these questions by repeating the experiments\nof the previous sections using a likelihood function based on\nthe truncated \u03c72 statistic. We assumed that the parameters of\nthe noise model were known, as in \u00a7 4.1. The noise was synthesized in the wavelet domain, with \u03b3 = 1, \u03c3w = 0.00135, and\n\u03b1 set equal to 1/3 or 2/3. The parameters of the transit model\nand the time series were the same as in \u00a7 4.1. We calculated\nthe \"exact\" autocovariance function R(l) at integer lag l for\na given \u03b1 by averaging sample autocovariances over 50,000\nnoise realizations. Fig. 7 plots the autocorrelation [R(l)/R(0)]\nas a function of lag for \u03b1 = 1/3, 2/3. We constructed the\nstationary covariance \u03a3i j = R(|i \u2212 j|) and computed its inverse\n(\u03a3\u22121 )i j for use in Eqn. (9).\nThen we used the MCMC method to find estimates and errors for the time of midtransit, and calculated the number-ofsigma statistic N as defined in Eqn. (35). In particular, for\neach simulated transit light curve, we created a Markov chain\nof 1, 000 links for tc , using \u03c72 (L) in the jump-transition like-\n\nlihood. We estimated tc and \u03c3tc , and calculated N . We did\nthis for 5, 000 realizations and determined \u03c3N , the variance in\nN , across this sample. We repeated this process for different\nchoices of the maximum lag L. Fig. (8) shows the dependence\nof \u03c3N upon the maximum lag L.\nThe time-domain method works fine, in the sense that when\nenough non-diagonal elements in the covariance matrix are\nretained, the parameter estimation is successful. We find that\n\u03c3N approaches unity as L\u2212\u03b2 with \u03b2 = 0.15, 0.25 for \u03b1 = 1/3,\n2/3, respectively. However, to match the reliability of the\nwavelet method, a large number of lags must be retained. To\nreach \u03c3N = 1.05, we need L \u2248 50 for \u03b1 = 1/3 or L \u2248 75\nfor \u03b1 = 2/3. In our implementation, the calculation based on\nthe truncated covariance matrix [Eqn. (9)] took 30\u201340 times\nlonger than the calculation based on the wavelet likelihood\n[Eqn. (32)].\nThis order-of-magnitude penalty in runtime is bad enough,\nbut the real situation may be even worse, because one usually\nhas access to a single noisy estimate of the autocovariance\nmatrix. Or, if one is using an ARMA model, the estimated parameters of the model might be subject to considerable uncertainty as compared to the \"exact\" autocovariance employed in\nour numerical experiments. If it is desired to determine the\nnoise parameters simultaneously with the other model parameters, then there is a further penalty associated with inverting\nthe covariance matrix at each step of the calculation for use\nin Eqn. (9), although it may be possible to circumvent that\nparticular problem by modeling the inverse-covariance matrix\ndirectly.\n\nF IG . 7.- Autocorrelation functions of correlated noise. The noise was\ncomputed as the sum of white noise with \u03c3w = 0.00135 and 1/ f noise with\nan rms equal to \u03b1\u03c3w , for \u03b1 = 1/3 or 2/3.\n\n4.4. Comparison with other methods\n\nIn this section we compare the results of the wavelet method\nto two methods for coping with correlated noise that are\ndrawn from the recent literature on transit photometry. The\nfirst of these two methods is the \"time averaging\" method\nthat was propounded by Pont et al. (2006) and used in various forms by Bakos et al. (2006), Gillon et al. (2006), Winn\net al. (2007, 2008, 2009), Gibson et al. (2008), and others. In\none implementation, the basic idea is to calculate the sample\n\n\f13\n\nF IG . 8.- Accuracy of the truncated time-domain likelihood in estimating\nmidtransit times. Plotted is the variance in the number-of-sigma statistic \u03c3N\nfor the midtransit time tc , as a function of the maximum lag in the truncated\nseries. The estimates of tc were found using the truncated likelihood given in\nEqn. (9).\n\nvariance of unbinned residuals, \u03c3\u030212 , and also the sample variance of the time-averaged residuals, \u03c3\u0302n2 , where every n points\nhave been averaged (creating m time bins). In the absence of\ncorrelated noise, we expect\n\u03c3\u0302 2 \u0010 m \u0011\n.\n(36)\n\u03c3\u0302n2 = 1\nn m\u22121\n\nIn the presence of correlated noise, \u03c3\u0302n2 differs from this expectation by a factor \u03b2\u0302n2 . The estimator \u03b2\u0302 is then found by\naveraging \u03b2\u0302n over a range \u2206n corresponding to time scales\nthat are judged to be most important. In the case of transit\nphotometry, the duration of ingress or egress is the most relevant time scale (corresponding to averaging time scales on\nthe order of tens of minutes, in our example light curve). A\nwhite analysis is then performed, using the noise parameter\n\u03c3 = \u03b2\u03c31 instead of \u03c31 . This causes the parameter errors \u03c3\u0302 pk to\nincrease by \u03b2 but does not change the parameter estimates p\u0302k\nthemselves.6\nA second method is the \"residual permutation\" method that\nhas been used by Jenkins et al. (2002), Moutou et al. (2004),\nSouthworth (2008), Bean et al. (2008), Winn et al. (2008),\nand others. This method is a variant of a bootstrap analysis,\nin which the posterior probability distribution for the parameters is based on the collection of results of minimizing \u03c72 (assuming white noise) for a large number of synthetic data sets.\nIn the traditional bootstrap analysis the synthetic data sets are\nproduced by scrambling the residuals and adding them to a\nmodel light curve, or by drawing data points at random (with\nreplacement) to make a simulated data set with the same number of points as the actual data set. In the residual permutation method, the synthetic data sets are built by performing\na cyclic permutation of the time indices of the residuals, and\n6 Alternatively one may assign an error to each data point equal to the\nquadrature sum of the measurement error and an extra term \u03c3r (Pont et\nal. 2006). For cases in which the errors in the data points are all equal or\nnearly equal, these methods are equivalent. When the errors are not all the\nsame, it is more appropriate to use the quadrature-sum approach of Pont et\nal. (2006). In this paper all our examples involve homogeneous errors.\n\nthen adding them to the model light curve. In this way, the\nsynthetic data sets have the same bumps, wiggles, and ramps\nas the actual data, but they are translated in time. The parameter errors are given by the widths of the distributions in\nthe parameters that are estimated from all the different realizations of the synthetic data, and they are usually larger than\nthe parameter errors returned by a purely white analysis.\nAs before, we limited the scope of the comparison to the\nestimation of tc and its uncertainty. We created 5,000 realizations of a noise source with \u03b3 = 1 and a given value of \u03b1 (either\n0, 1/3, 2/3, or 1). We used each of the two approximate methods (time-averaging and residual-permutation) to calculate \u03b2\u0302\nand its uncertainty based on each of the 5,000 noise realizations. Then we found the median and standard deviation of\n\u03b2\u0302/\u03b2 over all 5,000 realizations. Table (3) presents the results\nof this experiment.\nBoth methods, time-averaging and residual-permutation,\ngave more reliable uncertainties than the white method. However they both underestimated the true uncertainties by approximately 15-30%. Furthermore, neither method provided\nmore accurate estimates of tc than did the white method. For\nthe time-averaging method as we have implemented it, this\nresult is not surprising, for that method differs from the white\nmethod only in the inflation of the error bars by some factor\n\u03b2. The parameter values that maximize the likelihood function were unchanged.\n4.5. Alternative noise models\n\nWe have shown the wavelet method to work well in the\npresence of 1/ f \u03b3 noise. Although this family of noise processes encompasses a wide range of possibilities, the universe\nof possible correlated noise processes is much larger. In this\nsection we test the wavelet method using simulated data that\nhas correlated noise of a completely different character. In\nparticular, we focus on a process with exclusively short-term\ncorrelations, described by one of the aforementioned autoregressive moving-average (ARMA) class of parametric noise\nmodels. In this way we test our method on a noise process\nthat is complementary to the longer-range correlations present\nin 1/ f \u03b3 noise, and we also make contact between our method\nand the large body of statistical literature on ARMA models.\nFor 1/ f \u03b3 noise we have shown that time-domain parameter estimation techniques are slow. However, if the noise\nhas exclusively short-range correlations, the autocorrelation\nfunction will decay with lag more rapidly than a power law,\nand the truncated-\u03c72 likelihood [Eqn. (9)] may become computationally efficient. ARMA models provide a convenient\nanalytic framework for parameterizing such processes. For a\ndetailed review of ARMA models and their use in statistical\ninference, see Box & Jenkins (1976). Applications of ARMA\nmodels to astrophysical problems have been described by in\nKoen & Lombard (1993), Konig & Timmer (1997) and Timmer et al. (2000).\nTo see how the wavelet method performs on data with shortrange correlations we constructed synthetic transit data in\nwhich the noise is described by a single-parameter autoregressive [AR(1; \u03c8)] model. An AR(1; \u03c8) process \u01eb(ti ) is defined\nby the recursive relation\n\u01eb(ti ) = \u03b7(ti ) + \u03c8\u01eb(ti\u22121)\n\n(37)\n\nwhere \u03b7(ti ) is an uncorrelated Gaussian process with width\nparameter \u03c3 and \u03c8 is the sole autoregressive parameter. The\n\n\f14\nautocorrelation \u03b3(l) for an AR(1; \u03c8) process is\n\u03b3(l) =\n\n\u03c32\n\u03c8l .\n1 \u2212 \u03c82\n\n(38)\n\nAn AR(1;\u03c8) process is stationary so long as 0 < \u03c8 < 1 (Box &\nJenkins 1976). The decay length of the autocorrelation function grows as \u03c8 is increased from zero to one. Figure (9) plots\nthe autocorrelation function of a process that is an additive\ncombination of an AR(1; \u03c8 = 0.95) process and a white noise\nprocess. The noise in our synthetic transit light curves was the\nsum of this AR(1; \u03c8 = 0.95) process, and white noise, with\n\u03b1 = 1/2 (see Fig 9). With these choices, the white method\nunderestimates the error in tc , while at the same time the synthetic data look realistic.\nWe proceeded with the MCMC method as described previously to estimate the time of mid-transit. All four methods\nassessed in the previous section were included in this analysis,\nfor comparison. Table 5 gives the results. The wavelet method\nproduces more reliable error estimates than the white method.\nHowever, the wavelet method no longer stands out as superior to the time-averaging method or the residual-permutation\nmethod; all three of these methods give similar results. This\nillustrates the broader point that using any of these methods\nis much better than ignoring the noise correlations. The results also show that although the wavelet method is specifically tuned to deal with 1/ f \u03b3 noise, it is still useful in the\npresence of noise with shorter-range correlations.\nIt is beyond the scope of this paper to test the applicability of the wavelet method on more general ARMA processes.\nInstead we suggest the following approach when confronted\nwith real data [see also Beran (1994)]. Calculate the sample\nautocorrelation, and power spectral density, based on the outof-transit data or the residuals to an optimized transit model.\nFor stationary processes these two indicators are related as\ndescribed in \u00a7 2. Short-memory, ARMA-like processes can\nbe identified by large autocorrelations at small lags or by finite power spectral density at zero frequency. Long-memory\nprocesses (1/ f \u03b3 ) can be identified by possibly small but nonvanishing autocorrelation at longer lags. Processes with shortrange correlations could be analyzed with an ARMA model\nof the covariance matrix [see Box & Jenkins (1976)], or the\ntruncated-lag covariance matrix, although a wavelet-based\nanalysis may be sufficient as well. Long-memory processes\nare best analyzed with the wavelet method as described in this\npaper.\nIt should also be noted that extensions of ARMA models have been developed to mimic long-memory, 1/ f \u03b3 processes. In particular, fractional autoregressive integrated\nmoving-average models (ARFIMA) describe \"nearly\" 1/ f \u03b3\nstationary processes, according to the criterion described by\nBeran (1994). As is the case with ARMA models, ARFIMA\nmodels enjoy analytic forms for the likelihood in the timedomain. Alas, as noted by Wornell (1996) and Beran (1994),\nthe straightforward calculation of this likelihood is computationally expensive and potentially unstable. For 1/ f \u03b3 processes, the wavelet method is probably a better choice than\nany time-domain method for calculating the likelihood.\n4.6. Transit timing variations estimated from a collection of\n\nlight curves\nWe present here an illustrative calculation that is relevant\nto the goal of detecting planets or satellites through the perturbations they produce on the sequence of midtransit times\n\nF IG . 9.- An example of an autoregressive noise process with complementary characteristics to a 1/ f \u03b3 process. The top panel shows the sum of an\nAR(1) process with \u03c8 = 0.95 and white noise. The correlated and uncorrelated components have equal variances (\u03b1 = 0.5).\n\nof a known transiting planet. Typically an observer would fit\nthe midtransit times tc,i , to a model in which the transits are\nstrictly periodic:\ntc,i = tc,0 + Ei P\n\n(39)\n\nfor some integers Ei and constants tc,0 and P. Then, the residuals would be computed by subtracting the best-fit model from\nthe data, and a test for anomalies would be performed by assessing the likelihood of obtaining those residuals if the linear model were correct. Assuming there are N data points\nwith normally-distributed, independent errors, the likelihood\nis given by a \u03c72 -distribution, prob(\u03c72, Ndof ), where\nX \u0014 tc,i \u2212 (tc,0 + Ei P) \u00152\n(40)\n\u03c72 =\n\u03c3tc,i\ni\n\nand Ndof = N \u2212 2 is the number of degrees of freedom. Values\nof \u03c72 with a low probability of occurrence indicate the linear\nmodel is deficient, that there are significant anomalies in the\ntiming data, and that further observations are warranted.\nWe produced 10 simulated light curves of transits of the\nparticular planet GJ 436b, a Neptune-sized planet transiting\nan M dwarf (Butler et al. 2004, Gillon et al. 2007) which has\nbeen the subject of several transit-timing studies (see, e.g.,\nRibas et al. 2008, Alonso et al. 2008, Coughlin et al. 2008).\nOur chosen parameters were R p /R\u22c6 = 0.084, a/R\u22c6 = 12.25,\ni = 85.94 deg, and P = 2.644 d. This gives \u03b4 = 0.007, T = 1 hr,\nand \u03c4 = 0.24 hr. We chose limb-darkening parameters as appropriate for the SDSS r band (Claret 2004). We assumed that\n10 consecutive transits were observed, in each case giving 512\nuniformly-sampled flux measurements over 2.5 hours centered on the transit time. Noise was synthesized in the Fourier\ndomain (as in \u00a7 4.2), with a white component \u03c3w = 0.001 and a\n1/ f component with rms 0.0005 (\u03b1 = 1/2). The 10 simulated\nlight curves are plotted in Fig. (10). Visually, they resemble\nthe best light curves that have been obtained for this system.\nTo estimate the midtransit time of each simulated light\ncurve, we performed a wavelet analysis and a white analysis,\nallowing only the midtransit time and the noise parameters to\n\n\f15\nTABLE 5\nE STIMATES OF tc\n\nFROM DATA WITH AUTOREGRESSIVE CORRELATED NOISE\n\nMethod\n\nh\u03c3\u0302tc i [sec]\n\nhN i\n\n\u03c3N\n\nprob(N > 1)\n\nprob(better)a\n\nWhite\nWavelet\nTime-averaging\nResidual-permutation\n\n4.5\n8.7\n9.9\n10.2\n\n\u22120.010\n\u22120.016\n\u22120.010\n\u22120.010\n\n2.50\n1.33\n1.25\n1.23\n\n70%\n44%\n40%\n38%\n\n\u2212\n51%\n49%\n51%\n\na The probability that the analysis method returns an estimate of t that is closer to the\nc\ntrue value than the white analysis.\n\nTABLE 6\nL INEAR FITS\n\nTO ESTIMATED MIDTRANSIT TIMES\n\nMethod\n\nFitted Period / True Period\n\n\u03c7\u03022 /Ndof\n\nprob(\u03c72 < \u03c7\u03022 )\n\nWhite\nWavelet\n\n1.00000071 \u00b1 0.00000043\n1.00000048 \u00b1 0.00000077\n\n2.25\n0.93\n\n98%\n51%\n\nvary while fixing the other parameter values at their true values. We used the same MCMC technique that was described\nin \u00a7 4.2. Each analysis method produced a collection of 10\nmidtransit times and error bars. These 10 data points were\nthen fitted to the linear model of Eqn. (39). Fig. (11) shows\nthe residuals of the linear fit (observed \u2212 calculated). Table 6\ngives the best-fit period for each analysis (wavelet or white),\nalong with the associated values of \u03c72 .\nAs was expected from the results of \u00a7 4.2, the white analysis gave error bars that are too small, particularly for epochs 4\nand 7. As a result, the practitioner of the white analysis would\nhave rejected the hypothesis of a constant orbital period with\n98% confidence. In addition, the white analysis gave an estimate for the orbital period that is more than 1\u03c3 away from\nthe true value, which might have complicated the planning\nand execution of future observations. The wavelet method, in\ncontrast, neither underestimated nor overestimated the errors,\ngiving \u03c72 \u2248 Ndof in excellent agreement with the hypothesis\nof a constant orbital period. The wavelet method also gave an\nestimate for the orbital period within 1\u03c3 of the true value.\n\n4.7. Estimation of multiple parameters\nThus far we have focused exclusively on the determination\nof the midtransit time, in the interest of simplicity. However,\nthere is no obstacle to using the wavelet method to estimate\nmultiple parameters, even when there are strong degeneracies\namong them. In this section we test and illustrate the ability of\nthe wavelet method to solve for all the parameters of a transit\nlight curve, along with the noise parameters.\nWe modeled the transit as in \u00a7\u00a7 4.1 and 4.2. The noise\nwas synthesized in the frequency domain (as in \u00a7 4.2), using\n\u03c3w = 0.0045, \u03b3 = 1, and \u03b1 = 1/2. The resulting simulated light\ncurve is the upper time series in Fig. 12. We used the MCMC\nmethod to estimate the transit parameters {R p /R\u22c6 , a/R\u22c6 , i,tc }\nand the noise parameters {\u03c3r , \u03c3w } (again fixing \u03b3 = 1 for simplicity). The likelihood was evaluated with either the wavelet\n\nF IG . 10.- Simulated transit observations of the \"Hot Neptune\" GJ 436.\nArbitrary vertical offsets have been applied to the light curves, to separate\nthem on the page.\n\n\f16\n\nF IG . 11.- Transit timing variations estimated from simulated transit observations of GJ 436b. Each panel shows the residuals (observed \u2212 calculated)\nof a linear fit to the estimated midtransit times. The midtransit times were\nestimated with a wavelet analysis and also with a white analysis, as described\nin the text. The dashed lines indicate the 1 \u03c3 errors in the linear model.\n\nmethod [Eqn. (32)] or the white method [Eqn. (6)].\nFig. 13 displays the results of this analysis in the form of the\nposterior distribution for the case of tc , and the joint posterior\nconfidence regions for the other cases. The wavelet method\ngives larger (and more appropriate) confidence regions than\nthe white analysis. In accordance with our previous findings,\nthe white analysis underestimates the error in tc and gives an\nestimate of tc that differs from the true value by more than\n1\u03c3. The wavelet method gives better agreement. Both analyses give an estimate for R p /R\u22c6 that is smaller than the true\nvalue of 0.15, but in the case of the white analysis, this shift\nis deemed significant, thereby ruling out the correct answer\nwith more than 95% confidence. In the wavelet analysis, the\ntrue value of R p /R\u22c6 is well within the 68% confidence region. Both the wavelet and white analyses give accurate values of a/R\u22c6 and the inclination, and the wavelet method reports larger errors. As shown in Fig. (13), the wavelet method\nwas successful at identifying the parameters (\u03b1 and \u03c3w ) of the\nunderlying 1/ f noise process.\nFig. 12 shows the best-fitting transit model, and also illustrates the action of the \"whitening\" filter that was described\nin \u00a7 3.4. The jagged line plotted over the upper time series is\nthe best estimate of the 1/ f contribution to the noise, found\nby applying the whitening filter [Eqn. (29)] to the data using\nthe estimated noise parameters. The lower time series is the\nwhitened data, in which the 1/ f component has been subtracted. Finally, in Fig. 14 we compare the estimated 1/ f\nnoise component with the actual 1/ f component used to generate the data. Possibly, by isolating the correlated component\nin this way, and investigating its relation to other observable\nparameters, the physical origin of the noise could be identified\nand understood.\n5. SUMMARY AND DISCUSSION\n\nIn this paper we have introduced a technique for parameter\nestimation based on fitting a parametric model to a time series that may be contaminated by temporally correlated noise\nwith a 1/ f \u03b3 power spectral density. The essence of the technique is to calculate the likelihood function in a wavelet basis. This is advantageous because a broad class of realistic\nnoise processes produce a nearly diagonal covariance matrix\nin the wavelet basis, and because fast methods for computing\n\nF IG . 12.- Wavelet analysis of a single simulated transit light curve. Top.-\nSimulated light curve with correlated noise. The jagged line is the bestfitting transit model plus the best-fitting model of the 1/ f component of the\nnoise. Bottom.-Simulated light curve after applying the whitening filter of\nEqn. (29), using the noise parameters estimated from the wavelet analysis.\nThe solid line is the best-fitting transit model.\n\nwavelet transforms are available. We have tested and illustrated this technique, and compared it to other techniques, using numerical experiments involving simulated photometric\nobservations of exoplanetary transits.\nFor convenience we summarize the likelihood calculation\nhere:\n\u2022 Given the N data points y(ti ) obtained at evenly-spaced\ntimes ti , subtract the model fi (ti ; ~p) with model parameters ~p to form the N residuals r(ti ) \u2261 y(ti ) \u2212 f (ti ; ~p).\n\u2022 If N is not a multiple of a power of two, either truncate\nthe time series or enlarge it by padding it with zeros,\nuntil N = n0 2M for some n0 > 0, M > 0.\n\u2022 Apply the Fast Wavelet Transform (FWT) to the residuals to obtain n0 (2M \u2212 1) wavelet coefficients rnm and n0\nscaling coefficients r\u0304n1 .\n\u2022 For stationary, Gaussian noise built from an additive\ncombination of uncorrelated and correlated noise (with\nPower Spectral Density S( f ) \u221d 1/ f \u03b3 ), the likelihood\nfor the residuals r(ti ) is given by\n\uf8f1\n\"\nm\u22121\n\u0001 #\uf8fc\nM nY\n02\n\uf8f2Y\nm 2 \uf8fd\nr\n1\np\nL=\nexp \u2212 n 2\n2\n\uf8f3\n\uf8fe\n2\u03c3\n2\u03c0\u03c3\nW\nW\nm=2 n=1\n\uf8fc\n\uf8f1\n\"\n\u00012 #\uf8fd\nn0\n\uf8f2Y\nr\u0304n1\n1\nq\n(41)\n\u00d7\nexp \u2212\n\uf8f3\n2\u03c3S2 \uf8fe\n2\u03c0\u03c3 2\nn=1\n\nS\n\nwhere\n\n2\n\u03c3W\n= \u03c3r2 2\u2212\u03b3m + \u03c3w2\n\n\u03c3S2 = \u03c3r2 2\u2212\u03b3 g(\u03b3) + \u03c3w2\n\n(42)\n(43)\n\nfor some noise parameters \u03c3w > 0, \u03c3r > 0 and g(\u03b3) =\nO(1) [e.g., g(1) \u2248 0.72].\n\n\f17\n\nF IG . 13.- Results of parameter estimation for the simulated light curve of Fig. 12. Results for both the wavelet method (solid lines) and the white method\n(dashed lines) are compared. The upper left panel shows the posterior distribution for the midtransit time. The other panels show confidence contours (68.3%\nand 95.4%) of the joint posterior distribution of two parameters. The true parameter values are indicated by dotted lines.\n\nF IG . 14.- Isolating the correlated component. Plotted are the actual and\nestimated 1/ f components of the noise in the simulated light curve plotted in\nFig. (12). The estimated 1/ f signal was found by applying the wavelet filter,\nEqn. (29), to the residuals.\n\nThe calculation entails the multiplication of N terms and has\nan overall time-complexity of O(N). With this prescription\nfor the likelihood function, the parameters may be optimized\nusing any number of traditional algorithms. For example, the\nlikelihood may be used in the jump-transition probability in a\nMonte Carlo Markov Chain analysis, as we have done in this\nwork.\nAmong the premises of this technique are that the correlations among the wavelet and scaling coefficients are small\n\nenough to be negligible. In fact, the magnitude of the correlations at different scales and times are dependent on the\nchoice of wavelet basis and the spectral index \u03b3 describing\nthe power spectral density of the correlated component of the\nnoise. We have chosen for our experiments the Daubechies\n4th-order wavelet basis which seems well-suited to the cases\nwe considered. A perhaps more serious limitation is that the\nnoise should be stationary. Real noise is often nonstationary.\nFor example, photometric observations are noisier during periods of poor weather, and even in good conditions there may\nbe more noise at the beginning or end of the night when the\ntarget is observed through the largest airmass. It is possible\nthat this limitation could be overcome with more elaborate\nnoise models, or by analyzing the time series in separate segments; future work on these topics may be warranted.\nApart from the utility of the wavelet method, we draw the\nfollowing conclusions based on the numerical experiments of\n\u00a7 3. First, any analysis that ignores possible correlated errors\n(a \"white\" analysis in our terminology) is suspect, and any 2\u2013\n3\u03c3 results from such an analysis should be regarded as provisional at best. As shown in \u00a7\u00a7 4.1, 4.2, and 4.6, even data that\nappear \"good\" on visual inspection and that are dominated by\nuncorrelated noise may give parameter errors that are underestimated by a factor of 2\u20133 in a white analysis. Second, using\nany of the methods described in 4.4 (the wavelet method, the\ntime-averaging method, or the residual-permutation method)\nis preferable to ignoring correlated noise altogether.\n\n\f18\nThroughout this work our main application has been estimation of the parameters of a single time series or a few\nsuch time series, especially determining the midtransit times\nof transit light curves. One potentially important application\nthat we have not discussed is the detection of transits in a\ndatabase of time-series photometry of many stars. Photometric surveys such as the ground-based HAT (Bakos et al. 2007)\nand SuperWASP (Pollacco et al. 2006), and space-based missions such as Corot (Baglin et al. 2003) and Kepler (Borucki\net al. 2003) produce tens to hundreds of thousands of time series, spanning much longer intervals than the transit durations.\nIt seems likely that the parameters of a noise model could be\nvery well constrained using these vast databases, and that the\napplication of a wavelet-based whitening filter could facili-\n\ntate the detection of transits and the elimination of statistical\nfalse positives. Popular techniques for dealing with correlated\nnoise in large photometric databases are those of Tamuz et\nal. (2005), Kov\u00e1cs et al. (2005), and Pont et al. (2006). A\npriority for future work is to compare these methods with a\nwavelet-based method, by experimenting with realistic survey\ndata.\nWe are grateful to Frederic Pont and Eric Feigelson for very\ndetailed and constructive critiques of an early version of this\nmanuscript. We also thank Scott Gaudi and Jason Eastman\nfor helpful comments. This work was partly supported by the\nNASA Origins program (grant no. NNX09AB33G).\n\nREFERENCES\nAgol, E., Steffen, J., Sari, R., & Clarkson, W. 2005, MNRAS, 359, 567\nAlonso, R., Barbieri, M., Rabus, M., Deeg, H. J., Belmonte, J. A., &\nAlmenara, J. M. 2008, A&A, 487, L5\nBaglin, A. and the COROT team 2003, Advances in Space Research, 31, 345\nBakos, G. \u00c1., et al. 2006, ApJ, 650, 1160\nBakos, G. \u00c1., et al. 2007, ApJ, 656, 552\nBean, J. L., et al. 2008, A&A, 486, 1039\nBeran, J. 1994, Statistics for Long-Memory Processes (London: Chapman &\nHall)\nBevington, P. R., & Robinson, D. K. 2003, Data reduction and error analysis\nfor the physical sciences, 3rd ed. (Boston, MA: McGraw-Hill)\nBorucki, W. J., et al. 2003, Proc. SPIE, 4854, 129\nBouchy, F., Pont, F., Melo, C., Santos, N. C., Mayor, M., Queloz, D., &\nUdry, S. 2005, A&A, 431, 1105\nBox, G. E. P., & Jenkins, G. M. 1976, Holden-Day Series in Time Series\nAnalysis, Revised ed., San Francisco: Holden-Day, 1976,\nBracewell, R. The Fourier Transform and Its Applications. McGraw-Hill\nElectrical and Electronic Engineering Series, Terman, F., Ed. New York:\nMcGraw-Hill, 1965, pg. 115\nBurke, C. J., et al. 2007, ApJ, 671, 2115\nButler, R. P., Vogt, S. S., Marcy, G. W., Fischer, D. A., Wright, J. T., Henry,\nG. W., Laughlin, G., & Lissauer, J. J. 2004, ApJ, 617, 580\nCarter, J. A., Yee, J. C., Eastman, J., Gaudi, B. S., & Winn, J. N. 2008, ApJ,\n689, 499\nClaret, A. 2004, A&A, 428, 1001\nCollier Cameron, A., et al. 2007, MNRAS, 380, 1230\nCoughlin, J. L., Stringfellow, G. S., Becker, A. C., L\u00f3pez-Morales, M.,\nMezzalira, F., & Krajci, T. 2008, ApJ, 689, L149\nDaubechies, I. 1988, Communications on Pure and Applied Mathematics,\n41, 7, 909\nFadili, M.J. & Bullmore, E.T. 2002, Neuroimage, 15, 217\nGibson, N. P., et al. 2008, A&A, 492, 603\nGillon, M., Pont, F., Moutou, C., Bouchy, F., Courbin, F., Sohy, S., &\nMagain, P. 2006, A&A, 459, 249\nGillon, M., et al. 2007, A&A, 472, L13\nGillon, M., et al. 2009, A&A, 496, 259\nGim\u00e9nez, A. 2007, A&A, 474, 1049\nGould, A. 2003, ArXiv Astrophysics e-prints, arXiv:astro-ph/0310577\nGregory, P. C. 2005, Bayesian Logical Data Analysis for the Physical\nSciences: A Comparative Approach with Mathematica Support\n(Cambridge Univ. Press, UK).\nHaar, A., Zur Theorie der Orthogonalen Funktionensysteme., Math. Annal.,\nVol. 69, pp. 331-371, 1910\n\nHolman, M. J., & Murray, N. W. 2005, Science, 307, 1288\nHolman, M. J., et al. 2006, ApJ, 652, 1715\nJenkins, J. M., Caldwell, D. A., & Borucki, W. J. 2002, ApJ, 564, 495\nJohnson, J. A., Winn, J. N., Cabrera, N. E., & Carter, J. A. 2009, ApJ, 692,\nL100\nKipping, D. M. 2009, MNRAS, 392, 181\nKoen, C., & Lombard, F. 1993, MNRAS, 263, 287\nKonig, M., & Timmer, J. 1997, A&AS, 124, 589\nKov\u00e1cs, G., Bakos, G., & Noyes, R. W. 2005, MNRAS, 356, 557\nMallat, S. G. 1989, IEEE Transactions on Pattern Analysis and Machine\nIntelligence, 11, 674\nMallat, S. A Wavelet Tour of Signal Processing, London:AP Professional,\n1997\nMandel, K., & Agol, E. 2002, ApJ, 580, L171\nPercival D.B., & A.T. Walden. Spectral Analysis for Physical Applications:\nMultitaper and Conventional Univariate Techniques. Cambridge:\nCambridge University Press, 1993\nPollacco, D. L., et al. 2006, PASP, 118, 1407\nPont, F., Zucker, S., & Queloz, D. 2006, MNRAS, 373, 231\nPress, W. H. 1978, Comments on Astrophysics, 7, 103\nPress, William H., Teukolsky, Saul A., Vetterling, William T., & Flannery,\nBrian P. 2007, Numerical Recipes: The Art of Scientific Computing, 3rd\ned. (New York: Cambridge University Press)\nRibas, I., Font-Ribera, A., & Beaulieu, J.-P. 2008, ApJ, 677, L59\nSouthworth, J. 2008, MNRAS, 386, 1644\nTamuz, O., Mazeh, T., & Zucker, S. 2005, MNRAS, 356, 1466\nTeolis, A. Computational Signal Processing with Wavelets.\nBoston:Birkh\u00e4user, 1998\nTimmer, J., Schwarz, U., Voss, H. U., Wardinski, I., Belloni, T., Hasinger,\nG., van der Klis, M., & Kurths, J. 2000, Phys. Rev. E, 61, 1342\nUdalski, A., Szymanski, M. K., Kubiak, M., Pietrzynski, G., Soszynski, I.,\nZebrun, K., Szewczyk, O., & Wyrzykowski, L. 2004, Acta Astronomica,\n54, 313\nWinn, J. N., et al. 2007, AJ, 133, 1828\nWinn, J. N., et al. 2008, ApJ, 683, 1076\nWinn, J. N., Holman, M. J., Carter, J. A., Torres, G., Osip, D. J., & Beatty, T.\n2009, AJ, 137, 3826\nWornell, G. Signal Processing with Fractals: A Wavelet-Based Approach.\nPrentice Hall Signal Processing Series, Oppenheim, A., Ed. Upper Saddle\nRiver, NJ:Prentice Hall Press, 1996\n\n\f"}