{"id": "http://arxiv.org/abs/math/0503529v1", "guidislink": true, "updated": "2005-03-24T10:22:35Z", "updated_parsed": [2005, 3, 24, 10, 22, 35, 3, 83, 0], "published": "2005-03-24T10:22:35Z", "published_parsed": [2005, 3, 24, 10, 22, 35, 3, 83, 0], "title": "The long-run behavior of the stochastic replicator dynamics", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0503191%2Cmath%2F0503030%2Cmath%2F0503727%2Cmath%2F0503351%2Cmath%2F0503122%2Cmath%2F0503504%2Cmath%2F0503103%2Cmath%2F0503572%2Cmath%2F0503426%2Cmath%2F0503432%2Cmath%2F0503123%2Cmath%2F0503009%2Cmath%2F0503394%2Cmath%2F0503299%2Cmath%2F0503036%2Cmath%2F0503196%2Cmath%2F0503560%2Cmath%2F0503478%2Cmath%2F0503185%2Cmath%2F0503634%2Cmath%2F0503435%2Cmath%2F0503521%2Cmath%2F0503530%2Cmath%2F0503418%2Cmath%2F0503359%2Cmath%2F0503612%2Cmath%2F0503485%2Cmath%2F0503552%2Cmath%2F0503449%2Cmath%2F0503675%2Cmath%2F0503221%2Cmath%2F0503703%2Cmath%2F0503020%2Cmath%2F0503487%2Cmath%2F0503295%2Cmath%2F0503692%2Cmath%2F0503431%2Cmath%2F0503353%2Cmath%2F0503614%2Cmath%2F0503705%2Cmath%2F0503152%2Cmath%2F0503465%2Cmath%2F0503386%2Cmath%2F0503107%2Cmath%2F0503178%2Cmath%2F0503024%2Cmath%2F0503080%2Cmath%2F0503204%2Cmath%2F0503160%2Cmath%2F0503728%2Cmath%2F0503424%2Cmath%2F0503376%2Cmath%2F0503070%2Cmath%2F0503158%2Cmath%2F0503492%2Cmath%2F0503003%2Cmath%2F0503012%2Cmath%2F0503385%2Cmath%2F0503201%2Cmath%2F0503398%2Cmath%2F0503347%2Cmath%2F0503460%2Cmath%2F0503520%2Cmath%2F0503378%2Cmath%2F0503666%2Cmath%2F0503089%2Cmath%2F0503018%2Cmath%2F0503291%2Cmath%2F0503527%2Cmath%2F0503607%2Cmath%2F0503403%2Cmath%2F0503700%2Cmath%2F0503723%2Cmath%2F0503262%2Cmath%2F0503088%2Cmath%2F0503589%2Cmath%2F0503529%2Cmath%2F0503084%2Cmath%2F0503067%2Cmath%2F0503400%2Cmath%2F0503597%2Cmath%2F0503690%2Cmath%2F0503060%2Cmath%2F0503269%2Cmath%2F0503688%2Cmath%2F0503133%2Cmath%2F0503546%2Cmath%2F0503472%2Cmath%2F0503687%2Cmath%2F0503062%2Cmath%2F0503651%2Cmath%2F0503108%2Cmath%2F0503486%2Cmath%2F0503677%2Cmath%2F0503498%2Cmath%2F0503684%2Cmath%2F0503308%2Cmath%2F0503649%2Cmath%2F0503098%2Cmath%2F0503367%2Cmath%2F0503637&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The long-run behavior of the stochastic replicator dynamics"}, "summary": "Fudenberg and Harris' stochastic version of the classical replicator dynamics\nis considered. The behavior of this diffusion process in the presence of an\nevolutionarily stable strategy is investigated. Moreover, extinction of\ndominated strategies and stochastic stability of strict Nash equilibria are\nstudied. The general results are illustrated in connection with a discrete war\nof attrition. A persistence result for the maximum effort strategy is obtained\nand an explicit expression for the evolutionarily stable strategy is derived.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0503191%2Cmath%2F0503030%2Cmath%2F0503727%2Cmath%2F0503351%2Cmath%2F0503122%2Cmath%2F0503504%2Cmath%2F0503103%2Cmath%2F0503572%2Cmath%2F0503426%2Cmath%2F0503432%2Cmath%2F0503123%2Cmath%2F0503009%2Cmath%2F0503394%2Cmath%2F0503299%2Cmath%2F0503036%2Cmath%2F0503196%2Cmath%2F0503560%2Cmath%2F0503478%2Cmath%2F0503185%2Cmath%2F0503634%2Cmath%2F0503435%2Cmath%2F0503521%2Cmath%2F0503530%2Cmath%2F0503418%2Cmath%2F0503359%2Cmath%2F0503612%2Cmath%2F0503485%2Cmath%2F0503552%2Cmath%2F0503449%2Cmath%2F0503675%2Cmath%2F0503221%2Cmath%2F0503703%2Cmath%2F0503020%2Cmath%2F0503487%2Cmath%2F0503295%2Cmath%2F0503692%2Cmath%2F0503431%2Cmath%2F0503353%2Cmath%2F0503614%2Cmath%2F0503705%2Cmath%2F0503152%2Cmath%2F0503465%2Cmath%2F0503386%2Cmath%2F0503107%2Cmath%2F0503178%2Cmath%2F0503024%2Cmath%2F0503080%2Cmath%2F0503204%2Cmath%2F0503160%2Cmath%2F0503728%2Cmath%2F0503424%2Cmath%2F0503376%2Cmath%2F0503070%2Cmath%2F0503158%2Cmath%2F0503492%2Cmath%2F0503003%2Cmath%2F0503012%2Cmath%2F0503385%2Cmath%2F0503201%2Cmath%2F0503398%2Cmath%2F0503347%2Cmath%2F0503460%2Cmath%2F0503520%2Cmath%2F0503378%2Cmath%2F0503666%2Cmath%2F0503089%2Cmath%2F0503018%2Cmath%2F0503291%2Cmath%2F0503527%2Cmath%2F0503607%2Cmath%2F0503403%2Cmath%2F0503700%2Cmath%2F0503723%2Cmath%2F0503262%2Cmath%2F0503088%2Cmath%2F0503589%2Cmath%2F0503529%2Cmath%2F0503084%2Cmath%2F0503067%2Cmath%2F0503400%2Cmath%2F0503597%2Cmath%2F0503690%2Cmath%2F0503060%2Cmath%2F0503269%2Cmath%2F0503688%2Cmath%2F0503133%2Cmath%2F0503546%2Cmath%2F0503472%2Cmath%2F0503687%2Cmath%2F0503062%2Cmath%2F0503651%2Cmath%2F0503108%2Cmath%2F0503486%2Cmath%2F0503677%2Cmath%2F0503498%2Cmath%2F0503684%2Cmath%2F0503308%2Cmath%2F0503649%2Cmath%2F0503098%2Cmath%2F0503367%2Cmath%2F0503637&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Fudenberg and Harris' stochastic version of the classical replicator dynamics\nis considered. The behavior of this diffusion process in the presence of an\nevolutionarily stable strategy is investigated. Moreover, extinction of\ndominated strategies and stochastic stability of strict Nash equilibria are\nstudied. The general results are illustrated in connection with a discrete war\nof attrition. A persistence result for the maximum effort strategy is obtained\nand an explicit expression for the evolutionarily stable strategy is derived."}, "authors": ["Lorens A. Imhof"], "author_detail": {"name": "Lorens A. Imhof"}, "author": "Lorens A. Imhof", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1214/105051604000000837", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/math/0503529v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/math/0503529v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Published at http://dx.doi.org/10.1214/105051604000000837 in the\n  Annals of Applied Probability (http://www.imstat.org/aap/) by the Institute\n  of Mathematical Statistics (http://www.imstat.org)", "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "60H10, 60J70, 92D15, 92D25. (Primary)", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/math/0503529v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/math/0503529v1", "journal_reference": "Annals of Applied Probability 2005, Vol. 15, No. 1B, 1019-1045", "doi": "10.1214/105051604000000837", "fulltext": "arXiv:math/0503529v1 [math.PR] 24 Mar 2005\n\nThe Annals of Applied Probability\n2005, Vol. 15, No. 1B, 1019\u20131045\nDOI: 10.1214/105051604000000837\nc Institute of Mathematical Statistics, 2005\n\nTHE LONG-RUN BEHAVIOR OF THE STOCHASTIC\nREPLICATOR DYNAMICS\nBy Lorens A. Imhof\nAachen University\nFudenberg and Harris' stochastic version of the classical replicator dynamics is considered. The behavior of this diffusion process\nin the presence of an evolutionarily stable strategy is investigated.\nMoreover, extinction of dominated strategies and stochastic stability\nof strict Nash equilibria are studied. The general results are illustrated in connection with a discrete war of attrition. A persistence\nresult for the maximum effort strategy is obtained and an explicit\nexpression for the evolutionarily stable strategy is derived.\n\n1. Introduction. The deterministic replicator dynamics is one of the\nmost widely used dynamical models to describe the evolution of a population under selection. The evolution is governed by a symmetric twoplayer game with n pure strategies, 1, . . . , n. Let ajk denote the pay-off\nto a player using strategy j against an opponent playing strategy k. Let\nA = (ajk ). Suppose that every individual of the population is programmed\nto play one fixed pure strategy. For every point of time t \u2265 0, let \u03b6j (t) denote the size of the subpopulation whose individuals play strategy j, and\nlet \u03bej (t) = \u03b6j (t)/[\u03b61 (t) + * * * + \u03b6n (t)] denote the proportion of j-players in the\npopulation. If the population state is \u03be(t) = (\u03be1 (t), . . . , \u03ben (t))T , then {A\u03be(t)}j\nis the average pay-off to individuals playing j, when individuals are paired\nat random. Suppose that the pay-off represents the increase of fitness, measured as the number of offspring per unit of time. Then\nd\u03b6j (t)\n(1.1)\n= \u03b6j (t){A\u03be(t)}j ,\nj = 1, . . . , n,\ndt\nand so\nd\u03bej (t)\n(1.2)\n= \u03bej (t)[{A\u03be(t)}j \u2212 \u03be(t)T A\u03be(t)],\nj = 1, . . . , n.\ndt\nReceived September 2003; revised June 2004.\nAMS 2000 subject classifications. 60H10, 60J70, 92D15, 92D25.\nKey words and phrases. Asymptotic stochastic stability, evolutionarily stable strategy,\ninvariant measure, Lyapunov function, Nash equilibrium, recurrence, stochastic differential\nequation, war of attrition.\n\nThis is an electronic reprint of the original article published by the\nInstitute of Mathematical Statistics in The Annals of Applied Probability,\n2005, Vol. 15, No. 1B, 1019\u20131045. This reprint differs from the original in\npagination and typographic detail.\n1\n\n\f2\n\nL. A. IMHOF\n\nThis is the deterministic replicator dynamics of Taylor and Jonker (1978).\nSee Hofbauer and Sigmund (1998) and Nowak and Sigmund (2004) for detailed discussions from a biological point of view and Weibull (1995) for a\ndescription in an economic context. See also Hofbauer and Sigmund (2003)\nfor an extensive survey of deterministic evolutionary game dynamics.\nRecently, models of evolutionary dynamics which incorporate stochastic\neffects have attracted substantial interest. The seminal paper of Foster and\nYoung (1990) seems to be the first that presents a continuous-time replicator model based on a stochastic differential equation. Kandori, Mailath and\nRob (1993) study a related discrete-time system. The present paper investigates the stochastic replicator dynamics introduced by Fudenberg and Harris\n(1992). This model is related to that of Foster and Young, but exhibits a\nboundary behavior that appears to be more realistic from a biological perspective. Following Fudenberg and Harris (1992), consider the stochastic\nvariant of (1.1),\n(1.3)\n\ndZj (t) = Zj (t)[{AX(t)}j dt + \u03c3j dWj (t)],\n\nj = 1, . . . , n,\n\nwhere (W1 (t), . . . , Wn (t))T = W (t) is an n-dimensional Brownian motion,\n\u03c31 , . . . , \u03c3n are positive coefficients and\nX(t) = (X1 (t), . . . , Xn (t))T =\n\n1\n(Z1 (t), . . . , Zn (t))T .\nZ1 (t) + * * * + Zn (t)\n\nThe evolution of the population state X(t) is then given by the stochastic\nreplicator dynamics\n(1.4)\n\ndX(t) = b(X(t)) dt + C(X(t)) dW (t),\n\nwhere\nb(x) = [diag(x1 , . . . , xn ) \u2212 xxT ][A \u2212 diag(\u03c312 , . . . , \u03c3n2 )]x\nand\nC(x) = [diag(x1 , . . . , xn ) \u2212 xxT ] diag(\u03c31 , . . . , \u03c3n )\n\nfor x \u2208 \u2206 = {y \u2208 (0, 1)n : y1 + * * * + yn = 1}. In many interesting situations,\nthe deterministic differential equation (1.2) has a stationary point in \u2206,\nwhich corresponds to a population state where every pure strategy is present.\nIn fact every Nash equilibrium is stationary. On the other hand, the only\nstationary points for the stochastic differential equation (1.4) are the vertices\nof \u2206, corresponding to populations consisting of one common type of players.\nA series of important results on the behavior of the stochastic replicator\ndynamics have been established for the case where the underlying game has\ntwo pure strategies. For example, Fudenberg and Harris (1992) and Saito\n(1997) examine properties of ergodic distributions, Amir and Berninghaus\n\n\fSTOCHASTIC REPLICATOR DYNAMICS\n\n3\n\n(1998) establish a result on equilibrium selection and Corradi and Sarin\n(2000) provide an asymptotic analysis. However, a large part of the arguments used there is tailored to the case n = 2 and cannot be extended to the\ngeneral case n > 2. This is because when n = 2 one basically deals with onedimensional diffusion processes, and many of the tools available for these\nprocesses are not applicable to higher-dimensional diffusions, which correspond to games with three or more pure strategies. In particular, in the\ngeneral case, an approach via analyzing a closed form expression of the stationary distribution is not possible.\nThe present paper investigates (1.4) in the general case n \u2265 2. Section 2\nestablishes a connection between stable behavior of the processes X(t) and\nthe static concept of an evolutionarily stable strategy (ESS), which has been\nintroduced by Maynard Smith and Price (1973). Under suitable conditions,\nit is shown that if an ESS exists, then X(t) is recurrent and the stationary\ndistribution concentrates mass in a small neighborhood of the ESS. Explicit\nbounds for the expected time to reach that neighborhood are also given. Section 3 investigates dominated strategies. It is shown that the probability that\nthe frequency of a dominated strategy is above a prescribed level decreases\nexponentially quickly to zero. Interestingly, it turns out that, depending on\nthe sizes of the stochastic terms, weakly dominated strategies may become\nextinct in the stochastic model (1.4) even if they survive in the deterministic\nmodel (1.2). In Section 4 a sufficient condition is derived for a Nash equilibrium to be asymptotically stochastically stable. In this connection another\nexample emerges which shows that the deterministic model and the stochastic model can lead to quite different predictions: In the Prisoner's Dilemma,\nthe strategy \"defect\" is a strict Nash equilibrium and becomes predominant\nunder (1.2), but may become extinct under (1.4).\nBy way of illustration, a discrete variant of the war of attrition is analyzed\nin some detail in the last section. This is a model which describes conflicts\nthat are settled by display rather than violence; see Maynard Smith (1982).\nA rather general theorem on the persistence of the maximum effort strategy\nis obtained as a consequence of the results in Section 2. Furthermore, explicit expressions for ESSs are derived; the ESSs are given in terms of linear\ncombinations of Chebyshev polynomials of the second kind evaluated along\nthe imaginary axis. This yields a fairly accurate picture of the long-run behavior of the stochastic replicator dynamics when the conflicts are modeled\nby a war of attrition.\nHofbauer and Sigmund [(1998), Section 7.5] show that the deterministic\nreplicator equation is, in a sense, equivalent to the deterministic Lotka\u2013\nVolterra equation. The behavior of solutions to this equation under random perturbations has recently been investigated by Khasminskii and Klebaner (2001), Klebaner and Liptser (2001) and Skorokhod, Hoppensteadt\nand Salehi [(2002), Section 11]. There is almost no overlap with the results\npresented here.\n\n\f4\n\nL. A. IMHOF\n\n2. Stochastic replicator dynamics and evolutionarily stable strategies.\nThe concept of a Nash equilibrium is too weak to yield reasonable convergence or stability results for (1.4). A somewhat stronger concept, which\nis of fundamental importance in evolutionary game theory, is that of an evolutionarily stable strategy (ESS), introduced by Maynard Smith and Price\n(1973). The closure \u2206 of \u2206 is also referred to as the set of mixed strategies.\nA strategy p \u2208 \u2206 is said to be an ESS if the following two conditions hold:\n(i) pT Ap \u2265 qT Ap for all q \u2208 \u2206,\nand\n(ii) if q 6= p and pT Ap = qT Ap, then pT Aq > qT Aq.\n\nThis static concept lies between that of a Nash and a strict Nash equilibrium,\nand turns out to be particularly relevant to the long-run analysis of (1.4).\nFor x \u2208 \u2206, let Px denote the probability measure corresponding to the\nprocess X(t) with initial condition X(0) = x, and let Ex denote expectation\nwith respect to Px . Note that Px {X(t) \u2208 \u2206 for all t \u2265 0} = 1 for all x \u2208 \u2206.\nLet P (t, x, G) = Px {X(t) \u2208 G} for all Borel subsets G \u2282 \u2206. Let \u03c4G = inf{t >\n0 : X(t) \u2208 G}. For \u03b4 > 0, let U\u03b4 (x) = {y \u2208 \u2206 : ky \u2212 xk < \u03b4}, where k * k denotes\nthe Euclidean norm. Let ej denote the jth unit vector in Rn and let 1 \u2208\nRn denote the vector all of whose entries are 1. The mixed strategy ej is\nidentified with the pure strategy j. The matrix A is said to be conditionally\nnegative definite if\nyT Ay < 0\n\nfor all y \u2208 Rn such that 1T y = 0, y 6= 0.\n\nTheorem 2.1. Let X(t) be given by the stochastic replicator dynamics\n(1.4) and let p \u2208 \u2206 be an ESS for the underlying pay-off matrix A. Set A =\n1\nT\n2 (A+ A ), and let \u03bb2 be the second largest eigenvalue (counting multiplicity)\nof\nA\u2212\n\n1\n1\n1T A1 T\n11 .\nA11T \u2212 11T A +\nn\nn\nn2\n\nThen\n(2.1)\n\n\u03bb2 < 0.\n\nDefine \u03ba > 0 by\nn\n1X\n1\n,\n\u03ba =\npj \u03c3j2 \u2212 Pn\n2 j=1\n2 j=1 \u03c3j\u22122\n2\n\nand suppose that\n(2.2)\n\n\u03ba<\n\nn q\n|\u03bb2 | min pj .\n1\u2264j\u2264n\nn\u22121\n\n\f5\n\nSTOCHASTIC REPLICATOR DYNAMICS\n\nThen X(t) is recurrent, there exists a unique invariant probability measure \u03c0\non \u2206, and for every initial value x \u2208 \u2206, the transition probabilities\nP (t, x, *)\np\nconverge to \u03c0 in total variation. Moreover, for every \u03b4 > \u03ba/ |\u03bb2 |,\n\u03ba2\n,\n|\u03bb2 |\u03b42\nd(x, p)\nEx \u03c4U \u03b4 (p) \u2264\n,\n|\u03bb2 |\u03b42 \u2212 \u03ba2\n\n(a)\n\n\u03c0{U\u03b4 (p)} \u2265 1 \u2212\n\n(2.3)\n(b)\nand for every t > 0,\n(2.4)\n\n1\nEx\nt\nP\n\nZ\n\n0\n\nt\n\n\u001a\n\n\u001b\n\n1 d(x, p)\n+ \u03ba2 ,\nkX(s) \u2212 pk ds \u2264\n|\u03bb2 |\nt\n2\n\nwhere d(x, p) = j : pj >0 pj log(pj /xj ) is the Kullback\u2013Leibler distance between x and p.\nInequalities (2.1), (2.3)(b) and (2.4) also hold if the ESS p \u2208 \u2206, provided\nthat A is conditionally negative definite.\nRemark 2.1. The quantity |\u03bb2 | can be interpreted as a measure of how\nstrongly the ESS p attracts X(t) to a neighborhood of p.\nRemark 2.2. Foster and Young (1990) point out that, in view of its local character, the ESS condition is not \"quite the right concept of dynamical\nstability in a biological context.\" It is therefore not surprising that in the\nabove theorem the ESS condition is augmented by some additional requirement: that \u03ba be not too large and that A be conditionally negative definite\nif p \u2208 \u2202\u2206. The second condition is easily seen to be satisfied in the examples\nin Section 5. Bapat and Raghavan [(1997), Section 4.1] provide some criteria\nto check whether a given matrix is conditionally negative definite.\nThe proof of Theorem 2.1 requires the following auxiliary result.\nLemma 2.1. Let A \u2208 Rn\u00d7n , n \u2265 2, be a conditionally negative definite\nmatrix and let \u03bb2 be the second largest eigenvalue of\nD := A \u2212\n\n1\n1\n1T A1 T\nA11T \u2212 11T A +\n11 ,\nn\nn\nn2\n\nwhere A = 12 (A + AT ). Then\nxT Ax\n= \u03bb2 < 0.\nxT 1=0 xT x\nmax\nx6=0\n\n\f6\n\nL. A. IMHOF\n\nProof. Note first that\n(2.5)\n\nxT Dx = xT Ax\n\nfor all x \u2208 Rn such that 1T x = 0.\n\nThe vector 1 is an eigenvector of D corresponding to the eigenvalue \u03bb1 = 0.\nThus if \u03bb is another eigenvalue of D with corresponding eigenvector y, then\n1T y = 0. It then follows from (2.5) and the assumption that A is conditionally negative definite that\n\u03bb=\n\nyT Dy yT Ay\n= T \u2264 0.\nyT y\ny y\n\nThus \u03bb1 = 0 is the largest eigenvalue of D, and the variational description\nof \u03bb2 , the second largest eigenvalue, and (2.5) yield\nxT Ax\nxT Dx\n=\nmax\n< 0.\nxT 1=0 xT x\nxT 1=0 xT x\n\n\u03bb2 = max\n\n\u0003\n\nx6=0\n\nx6=0\n\nProof of Theorem 2.1. Let L denote the second-order differential\noperator associated with X(t), that is,\n(2.6) Lf (x) =\n\nn\nX\n\nbj (x)\n\nj=1\n\nn\n\u2202 2 f (x)\n\u2202f (x) 1 X\n\u03b3jk (x)\n+\n,\n\u2202xj\n2 j,k=1\n\u2202xj \u2202xk\n\nf \u2208 C 2 (\u2206),\n\nwhere\nbj (x) = xj (ej \u2212 x)T [A \u2212 diag(\u03c312 , . . . , \u03c3n2 )]x,\nn\nX\n\n\u03b3jk (x) =\n\ncj\u03bd (x)ck\u03bd (x),\n\n\u03bd=1\n\n\u001a\n\ncjk (x) =\n\nxj (1 \u2212 xj )\u03c3j ,\n\u2212xj xk \u03c3k ,\n\nj = k,\nj 6= k.\n\nSuppose first that p \u2208 \u2206, and set g(x) = d(x, p) =\nx \u2208 \u2206. Then, for all x, g(x) \u2265 0 and\nLg(x) = \u2212\n\nn\nX\n\nj=1\n\n+\n\n1\n2\n\nP\n\nj\n\npj log(pj /xj ) for all\n\npj (ej \u2212 x)T [A \u2212 diag(\u03c312 , . . . , \u03c3n2 )]x\n\nn\nX\n\npj\n\n\u03c3j2\n\nj=1\n\n= (x \u2212 p)T Ax \u2212\n\n\u2212 2xj \u03c3j2\n1\n2\n\nn\nX\n\nj=1\n\n+\n\nn\nX\n\nx2k \u03c3k2\n\nk=1\n\nx2j \u03c3j2 +\n\n1\n2\n\nn\nX\n\nj=1\n\n!\n\npj \u03c3j2 .\n\n\f7\n\nSTOCHASTIC REPLICATOR DYNAMICS\n\nAs p is evolutionarily stable, (x\u2212 p)T Ap \u2264 0. Since p \u2208 \u2206, A is conditionally\nnegative definite. This follows from the proof of Haigh's theorem (1975).\nHence, in view of Lemma 2.1,\n(x \u2212 p)T Ax \u2264 (x \u2212 p)T A(x \u2212 p) \u2264 \u03bb2 kx \u2212 pk2\nP\n\nand \u03bb2 < 0. The Cauchy\u2013Schwarz inequality gives 1 \u2264 ( nj=1 x2j \u03c3j2 )\nP\nP\nso that \u2212 nj=1 x2j \u03c3j2 \u2264 \u2212( nj=1 \u03c3j\u22122 )\u22121 . It now follows that\nLg(x) \u2264 \u03bb2 kx \u2212 pk2 + \u03ba2 ,\n\n(2.7)\n\nPn\n\n\u22122\nj=1 \u03c3j ,\n\nx \u2208 \u2206.\n\nSuppose that \u03b42 > \u03ba2 /|\u03bb2 |. For every x \u2208 \u2206 \\U\u03b4 (p), Lg(x) \u2264 \u03bb2 \u03b42 + \u03ba2 , and it\nfollows by It\u00f4's formula that g(X(t))\u2212 (\u03bb2 \u03b42 + \u03ba2 )t is a local supermartingale\non [0, \u03c4U \u03b4 (p) ). Hence [cf. proof of Theorem 5.3 in Durrett (1996), page 268]\ng(x) \u2265 (|\u03bb2 |\u03b42 \u2212 \u03ba2 )Ex \u03c4U \u03b4 (p) , proving (2.3)(b).\nTo prove recurrence, consider the transformed process Y (t) = \u03a8(X(t)),\nwhere \u03a8 : \u2206 \u2192 Rn\u22121 is defined by \u03a8(x) = (log(x1 /xn ), . . . , log(xn\u22121 /xn ))T .\nOne has\ndYj (t) = {(ej \u2212 en )T A\u03a8\u22121 (Y (t)) \u2212 21 (\u03c3j2 \u2212 \u03c3n2 )} dt + \u03c3j dWj (t) \u2212 \u03c3n dWn (t),\nj = 1, . . . , n \u2212 1,\nwhere \u03a8\u22121 (y) = (1 + ey1 + * * * + eyn\u22121 )\u22121 (ey1 , . . . , eyn\u22121 , 1)T . Note that the\nsecond-order differential operator associated with Y (t) is uniformly elliptic.\nIt will\np next be shown that \u2202U\u03b40 has positive distance from \u2202\u2206 for some \u03b40 >\n\u03ba/ |\u03bb2 |. This implies that \u03a8(U\u03b40 ) is a compact set. In view of (2.3)(b) it will\nthen follow that Y (t) is recurrent [Bhattacharya (1978) and Khas'minskii\n(1960)] and the transition probabilities converge in total variation to the\nunique stationary probability measure [Durrett (1996), Chapter p\n7]. The same\napplies then to X(t). By (2.2), one may\nchoose\n\u03b4\nsuch\nthat\n\u03ba/\n|\u03bb2 | < \u03b40 <\n0\nP\n(n/(n \u2212 1)) minj pj . Suppose y \u2208 Rn , nj=1 yj = 1 and ky \u2212 pk = \u03b40 . Let j0\nbe such that |yj0 \u2212 pj0 | = max1\u2264j\u2264n |yj \u2212 pj |, and set\n\u0012\n\npj \u2212 y j 0\npj \u2212 y j 0\n,..., 0\nz = y j 0 \u2212 pj 0 , 0\nn\u22121\nn\u22121\n\n\u0013T\n\n\u2208 Rn .\n\nOne may verify that z is majorized by y \u2212 p in the sense of Definition A.1\nin Marshall and Olkin [(1979), page 7], and it follows from Proposition C.1\nin Marshall and Olkin [(1979), page 64] that\n\u03b402\n\n=\n\nn\nX\n\n2\n\n(yj \u2212 pj ) \u2265\n\nj=1\n\nn\nX\n\nj=1\n\nzj2\n\n\u0012\n\n\u0013\n\n1\n= 1+\n(yj0 \u2212 pj0 )2\nn\u22121\n\nn\nmax (yj \u2212 pj )2 .\n=\nn \u2212 1 1\u2264j\u2264n\n\n\f8\n\nL. A. IMHOF\n\nThus, for every j, yj \u2265 min1\u2264k\u2264n pk \u2212 (n \u2212 1)\u03b40 /n > 0, showing that the\ndistance between \u2202U\u03b40 and \u2202\u2206 is positive.\nFor K > g(x) let \u03c4\u0303K = inf{t > 0 : g(X(t)) = K}. Then, by Dynkin's formula and (2.7),\n0 \u2264 Ex g(X(t \u2227 \u03c4\u0303K )) = g(x) + Ex\n\u2264 g(x) + \u03bb2 Ex\n\nZ\n\nt\u2227\u03c4\u0303K\n\n0\n\nZ\n\nt\u2227\u03c4\u0303K\n\nLg(X(s)) ds\n\n0\n\nkX(s) \u2212 pk2 ds + \u03ba2 Ex (t \u2227 \u03c4\u0303K ).\n\nIf K \u2192 \u221e, then t \u2227 \u03c4\u0303k \u2192 t, and (2.4) follows by the bounded convergence\ntheorem. To prove (2.3)(a), let \u03c7U C (p) denote the indicator function of\n\u03b4\n\nC\n\nU \u03b4 (p) = \u2206 \\ U \u03b4 (p). Then, by (2.4),\nC\n\n\u03c0(U \u03b4 (p)) = lim Ex\nt\u2192\u221e\n\n\u2264 lim Ex\nt\u2192\u221e\n\n1\nt\n\n1\nt\n\nZ\n\nt\n\n\u03c7U C (p) (X(s)) ds\n\n0\n\nZ\n\n0\n\n\u03b4\n\nt\n\nkX(s) \u2212 pk2\n\u03ba2\nds\n\u2264\n.\n\u03b42\n|\u03bb2 |\u03b42\n\nAn inspection of the above arguments shows that if A is conditionally negative definite, then (2.1), (2.3)(b) and (2.4) hold if the ESS p \u2208 \u2202\u2206. In this\ncase, however, X(t) need not be recurrent. \u0003\nIf p is an ESS for A, then there exists a constant c \u2208 R such that {Ap}j = c\nfor all j \u2208 {1, . . . , n} with pj > 0; see Hofbauer and Sigmund [(1998), page\n63]. Thus\n[diag(p1 , . . . , pn ) \u2212 ppT ]Ap = 0,\nso that the drift vector b(x) of the stochastic differential equation (1.4) will\nin general not be zero at x = p. If, however, p is an ESS for the modified\npay-off matrix B = A \u2212 diag(\u03c312 , . . . , \u03c3n2 ), then b(p) = 0. From this point of\nview it is more natural to investigate the distance between X(t) and an ESS\nfor B. A simple modification of the proof of Theorem 2.1 yields the following\nresult. The analogous results on recurrence and the stationary distribution\nare omitted for brevity.\nTheorem 2.2. Let X(t) be given by the stochastic replicator dynamics\n(1.4) with underlying pay-off matrix A. Let p \u2208 \u2206 be an ESS for the modified\npay-off matrix A\u2212 diag(\u03c312 , . . . , \u03c3n2 ). Suppose also that A\u2212 diag( 21 \u03c312 , . . . , 12 \u03c3n2 )\nis conditionally negative definite. Then for every initial state x \u2208 \u2206 and\nevery t > 0,\n1\n(2.8) Ex\nt\n\nZ\n\n0\n\nt\n\n(\n\n)\n\nn\n1 d(x, p) 1 X\npj (1 \u2212 pj )\u03c3j2 ,\nkX(s) \u2212 pk ds \u2264 \u2032\n+\n|\u03bb2 |\nt\n2 j=1\n2\n\n\fSTOCHASTIC REPLICATOR DYNAMICS\n\nwhere d(x, p) =\nof\n\nP\n\nj : pj >0 pj\n\nA\u2212\n\n9\n\nlog(pj /xj ) and \u03bb\u20322 is the second largest eigenvalue\n\n1\n1\n1T A1 T\n11 ,\nA11T \u2212 11T A +\nn\nn\nn2\n\nwhere A = 12 [A + AT \u2212 diag(\u03c312 , . . . , \u03c3n2 )].\nRemark 2.3. If the ESS p \u2208 \u2206, it follows that A \u2212 diag(\u03c312 , . . . , \u03c3n2 ) is\nconditionally negative definite, so that in this case, the assumption that\nA \u2212 diag( 12 \u03c312 , . . . , 21 \u03c3n2 ) should be conditionally negative definite is not very\nrestrictive. To compare (2.4) and (2.8) note that |\u03bb\u20322 | > |\u03bb2 | and\nn\nn\n1X\n1X\n1\n+\npj (1 \u2212 pj )\u03c3j2 \u2264 \u2212 Pn\npj \u03c3j2 .\n2 j=1\n2 j=1 \u03c3j\u22122 2 j=1\n\n3. Extinction of dominated strategies. This section is concerned with\nthe evolution of strategies that are inferior to other strategies in the sense\nof domination.\nA strategy p \u2208 \u2206 is said to be weakly dominated by strategy q \u2208 \u2206 if\npT Ar \u2264 qT Ar\n\nfor all r \u2208 \u2206\n\nwith strict inequality for some r. If the inequality is strict for all r, then p\nis said to be strictly dominated by q.\nFor the deterministic replicator dynamics (1.2), Akin (1980) has shown\nthat strictly dominated pure strategies become extinct; more precisely, their\nfrequencies in the population converge to zero. Theorem 3.1 establishes that\nunder the stochastic replicator dynamics (1.4) even pure strategies that are\nonly weakly dominated become extinct under a suitable condition on the\ndiffusion coefficients \u03c31 , . . . , \u03c3n . Theorem 3.1 also gives an upper bound for\nthe probability that at a given point of time t the frequency of a dominated\nstrategy is above a prescribed value \u03b5 > 0. The bound converges exponentially quickly to zero as t \u2192 \u221e.\nTheorem 3.1. Let X(t) be given by (1.4). Suppose that the pure strategy\nk is weakly dominated by some mixed strategy p \u2208 \u2206. Set c1 = minq\u2208\u2206 pT Aq\u2212\neTk Aq and suppose that \u03c31 , . . . , \u03c3n are such that\n(3.1)\n\nc2 = \u2212\n\nn\n\u03c3k2 1 X\npj \u03c3j2 < c1 .\n+\n2\n2 j=1\n\nThen for every initial state x \u2208 \u2206,\n\n\u221a\nPx {Xk (t) = o(exp[\u2212(c1 \u2212 c2 )t + 3\u03c3max t log log t ])} = 1,\n\n\f10\n\nL. A. IMHOF\n\nand for 0 < \u03b5 < 1 and t > 0,\nPx {Xk (t) > \u03b5} < 1 \u2212 \u03a6\n\n\u001a\n\n\u001b\n\nc3 (x) + log \u03b5 + (c1 \u2212 c2 )t\n\u221a\n,\n\u03c3max 2t\n\nwhere \u03a6(v)\nis the normal distribution function, \u03c3max = max{\u03c31 , . . . , \u03c3n } and\nP\nc3 (x) = nj=1 pj log(xj /xk ).\n\nProof. Let H(t) = log Xk (t)\u2212\nformula,\nH(t) = H(0) +\n\nZ\n\nt\n\n0\n\nPn\n\nj=1 pj\n\nlog Xj (t) for t \u2265 0. Then, by It\u00f4's\n\neTk AX(s) \u2212 pT AX(s) \u2212\n\n+ \u03c3k Wk (t) \u2212\n\nn\nX\n\nn\n\u03c3k2 1 X\npj \u03c3j2 ds\n+\n2\n2 j=1\n\npj \u03c3j Wj (t)\n\nj=1\n\nf (t),\n\u2264 H(0) + (c2 \u2212 c1 )t + \u03c3\u0303 W\n\nP\n\nP\n\nf (t) = [\u03c3k Wk (t) \u2212 n pj \u03c3j \u00d7\nwhere \u03c3\u0303 = [(1 \u2212 pk )2 \u03c3k2 + j6=k p2j \u03c3j2 ]1/2 and W\nj=1\n\u221a\nWj (t)]/\u03c3\u0303 is a standard Brownian motion. Clearly, \u03c3\u0303 \u2264 2\u03c3max . It follows\nthat Px -almost surely,\n\u221a\nlim sup Xk (t) exp[(c1 \u2212 c2 )t \u2212 3\u03c3max t log log t ]\nt\u2192\u221e\n\n\u221a\n\u2264 lim sup exp[H(t) + (c1 \u2212 c2 )t \u2212 3\u03c3max t log log t ]\nt\u2192\u221e\n\n\u221a\nf (t) \u2212 3\u03c3max t log log t ] = 0\n\u2264 lim sup exp[\u2212c3 (x) + \u03c3\u0303 W\nt\u2192\u221e\n\nby the law of the iterated logarithm. Moreover,\nPx {Xk (t) > \u03b5} \u2264 Px {H(t) > log \u03b5}\n\n\u2264 Px {\u2212c3 (x) + (c2 \u2212 c1 )t + \u03c3\u0303W (t) > log \u03b5}\n\u001a\n\n\u001b\n\nc3 (x) + log \u03b5 + (c1 \u2212 c2 )t\n\u221a\n<1\u2212\u03a6\n.\n\u03c3max 2t\n\n\u0003\n\nRemark 3.1. Condition (3.1) is always satisfied if k is strictly dominated by p and \u03c31 = * * * = \u03c3n . The condition is also satisfied when k is\nmerely weakly dominated and \u03c3k > \u03c3j for every j 6= k. Thus if the diffusion\ncoefficient corresponding to a weakly dominated strategy is large enough,\nits frequency converges to zero. This behavior is different from the behavior\nof weakly dominated strategies under the deterministic replicator dynamics where weakly dominated strategies may well persist with any prescribed\npositive population share; see Weibull [(1995), Example 3.4, page 84]. This\n\n\fSTOCHASTIC REPLICATOR DYNAMICS\n\n11\n\ndifference between the deterministic and the stochastic population dynamics\nagrees with the findings of Alvarez (2000) which show that, under mild conditions, \"increased stochastic fluctuations decrease the expected population\ndensity.\" Cabrales (2000) proves that in a similar stochastic model iteratively strictly dominated strategies become rare, provided stochastic effects\nare sufficiently small.\nRemark 3.2.\n\nIn the situation of Theorem 3.1,\nPx {Xk (t) > \u03b5} = o(e\u2212\u03b3t ),\n\nt \u2192 \u221e,\n\n2 ). This is easily verified using the bound\nfor any 0 < \u03b3 < (c1 \u2212 c2 )2 /(4\u03c3max\n2\n1 \u2212 \u03a6(v) \u2264 exp(\u2212v /2), v > 0.\n\nRemark 3.3. The assumptions of Theorem 3.1 may be satisfied even\nif the pure strategy k is not dominated by any other pure strategy. For\nexample, let\n\uf8eb\n\n2 2\nA = \uf8ed4 1\n1 4\n\n\uf8f6\n\n2\n1\uf8f8\n4\n\nand\n\n\u03c322 + \u03c332\n< 1 + \u03c312 .\n2\n\nThen the pure strategy 1 is strictly dominated by p = (0, 12 , 12 )T and, according to Theorem 3.1, X1 (t) \u2192 0 almost surely, even though neither strategy\n2 nor strategy 3 dominates strategy 1.\n4. Stochastic stability of Nash equilibria. The last section dealt with the\nextinction of pure strategies that were inferior to at least one strategy. The\npresent section investigates strategies that can be regarded as being locally\nsuperior to all other strategies. The relevant concept is that of a strict Nash\nequilibrium.\nA strategy p \u2208 \u2206 is called a Nash equilibrium if\npT Ap \u2265 qT Ap\n\nfor all q \u2208 \u2206.\n\nIf the inequality is strict for all q 6= p, then p is a strict Nash equilibrium.\nIn other words, a Nash equilibrium is a best reply to itself, and a strict\nNash equilibrium is the unique best reply to itself. Only pure strategies can\nbe strict Nash equilibria; see Weibull [(1995), page 15]. Thus if nearly the\nwhole population plays a strict Nash equilibrium, then the highest pay-off is\nobtained by exactly that strategy so that natural selection would not favor\nany other strategy. This suggests that a strict Nash equilibrium should be\nan asymptotically stable state, which is indeed the case under the deterministic replicator dynamics (1.2). This need not be the case for the stochastic\nreplicator dynamics (1.4), as is illustrated by the following example.\n\n\f12\n\nL. A. IMHOF\n\nExample. Consider the Prisoner's Dilemma game [Hofbauer and Sigmund (1998), page 101] with two pure strategies: 1 = co-operate, 2 = defect,\nand pay-off matrix\nA=\n\n\u0012\n\na11\na21\n\n\u0013\n\na12\n,\na22\n\na21 > a11 > a22 > a12 .\n\nHere strategy 2 is a strict Nash equilibrium and under (1.2), limt\u2192\u221e \u03be2 (t) = 1\nfor all initial states \u03be(0) \u2208 \u2206. On the other hand, if\n\u03c322 \u03c312\n>\n+ max{a21 \u2212 a11 , a22 \u2212 a12 },\n2\n2\nthen condition (3.1) of Theorem 3.1 is satisfied with k = 2, p = (1, 0)T ,\nso that Px {limt\u2192\u221e X1 (t) = 1} for all x \u2208 \u2206. This is a reasonable behavior,\nbecause if all players co-operate, then the received pay-off, a11 , is larger than\na22 , the pay-off they receive when all players defect. Thus the stochastic\nmodel may explain the spread of co-operative behavior, which could not be\nobserved in the deterministic model. This fact agrees with results of Nowak,\nSasaki, Taylor and Fudenberg (2004) who study a discrete-time Markov\nchain to explain the emergence of co-operation in a finite population that\nplays the Prisoner's Dilemma game.\nThe next theorem gives a sufficient condition for a strict Nash equilibrium\nto be asymptotically stochastically stable. Notice that a pure strategy k is\na strict Nash equilibrium if and only if akk > ajk for all j 6= k.\nTheorem 4.1. Let X(t) be given by (1.4). Let k be a strict Nash equilibrium. Suppose that \u03c3k is so small that\nakk > ajk + \u03c3k2\n\n(4.1)\n\nfor all j 6= k.\n\nThen ek is asymptotically stochastically stable. That is, for any neighborhood\nU of ek and for any \u03b5 > 0 there is a neighborhood V of ek such that\n\u001a\n\n\u001b\n\nPx X(t) \u2208 U for all t \u2265 0, lim X(t) = ek \u2265 1 \u2212 \u03b5\nt\u2192\u221e\n\nfor every initial state x \u2208 V \u2229 \u2206.\nProof. The proof is an application of the stochastic Lyapunov method.\nConsider the Lyapunov function \u03c6(y) = 1 \u2212 yk . Evidently, \u03c6(y) \u2265 0 for all\ny \u2208 \u2206 with equality if and only if y = ek . It will be shown that there is a\nconstant c > 0 and a neighborhood V0 of ek such that\n(4.2)\n\nL\u03c6(y) \u2264 \u2212c\u03c6(y)\n\nfor all y \u2208 V0 \u2229 \u2206,\n\n\f13\n\nSTOCHASTIC REPLICATOR DYNAMICS\n\nwhere L is the differential operator given by (2.6). The assertion then follows\nfrom Theorem 4 and Remark 2 in Gichman and Skorochod [(1971), pages\n314 and 315]. Write B = A \u2212 diag(\u03c312 , . . . , \u03c3n2 ). For all y \u2208 \u2206,\nL\u03c6(y) = \u2212yk (ek \u2212 y)T By\n= yk\n\nX\n\n\u03bc6=k\n\u03bd6=k\n\n+ yk2\n\ny\u03bc b\u03bc\u03bd y\u03bd \u2212 yk (1 \u2212 yk )\n\n(\n\n\u2212(1 \u2212 yk )bkk +\n\nX\n\n\u03bc6=k\n\u03bd6=k\n\ny\u03bc b\u03bc\u03bd y\u03bd \u2264 \u03b2\n\nX\n\n\u03bc6=k\n\ny\u03bc\n\nX\n\n\u03bd6=k\n\ny\u03bd = \u03b2(1 \u2212 yk )2 ,\n\nbk\u03bd y\u03bd\n\n\u03bd6=k\n\n)\n\ny\u03bc b\u03bck .\n\n\u03bc6=k\n\nLet \u03b2 = max{|b\u03bc\u03bd | : \u03bc, \u03bd = 1, . . . , n}. Then\nX\n\nX\n\n\u2212\n\nX\n\n\u03bd6=k\n\nbk\u03bd y\u03bd \u2264 \u03b2(1 \u2212 yk ).\n\nMoreover, condition (4.1) ensures that for some \u03b1 > 0, b\u03bck \u2264 bkk \u2212 \u03b1 for all\n\u03bc 6= k, so that\n\u2212(1 \u2212 yk )bkk +\n\nX\n\n\u03bc6=k\n\ny\u03bc b\u03bck \u2264 \u2212(1 \u2212 yk )bkk + (bkk \u2212 \u03b1)\n\nX\n\n\u03bc6=k\n\ny\u03bc = \u2212\u03b1(1 \u2212 yk ).\n\nHence\nL\u03c6(y) \u2264 2\u03b2yk (1 \u2212 yk )2 \u2212 \u03b1yk2 (1 \u2212 yk ) = \u2212yk {(\u03b1 + 2\u03b2)yk \u2212 2\u03b2}\u03c6(y),\nwhich proves (4.2) with V0 = {y \u2208 \u2206 : yk >\n\n1 \u03b1+4\u03b2\n2 \u03b1+2\u03b2 }\n\nand c = \u03b14 . \u0003\n\nRemark 4.1. Condition (4.1) means that k is a strict Nash equilibrium\nwith respect to the modified pay-off matrix B. If k is only a neutrally stable\nstrategy with respect to B [see Weibull (1995), Definition 2.4, page 46],\nthen, by Proposition 2.7 of Weibull [(1995), page 48], L\u03c6(y) = \u2212yk (ek \u2212\ny)T By \u2264 0 for all y in a certain neighborhood of ek . Hence in this case\nTheorem 4 of Gichman and Skorochod [(1971), page 314] yields that ek is\nstill stochastically stable.\nTheorem 4.1 says that if the population is in a state sufficiently near to a\nstrict Nash equilibrium ek , then, with probability close to 1, that equilibrium\nwill actually be selected by the stochastic replicator dynamics in the sense\nthat limt\u2192\u221e X(t) = ek . If there are several strict Nash equilibria and the\ninitial state is not close to any of them, it is neither clear which one will be\nselected nor in fact if any will be selected at all. The next theorem establishes\nthat when the underlying game is a coordination game, that is, every pure\nstategy is a strict Nash equilibrium, then it is almost certain that one of the\nequilibria will be selected.\n\n\f14\n\nL. A. IMHOF\n\nTheorem 4.2. Let A be the pay-off matrix of a co-ordination game and\nlet X(t) be given by (1.4). Suppose that, for every k, \u03c3k is so small that\nakk > ajk + \u03c3k2 for all j 6= k. Then, for every initial state x \u2208 \u2206,\n\u001a\n\n\u001b\n\nPx lim X(t) = ek for some k = 1.\nt\u2192\u221e\n\nThe proof hinges on the following theorem, which is of interest in its own\nright. It states that for any underlying game, X(t) will come arbitrarily close\nto one of the points e1 , . . . , en in finite time.\nTheorem 4.3. Let A be an arbitrary pay-off matrix, let X(t) be given\nby (1.4) and let x \u2208 \u2206. Let \u03b5 > 0. Consider the hitting time\n\u03c4\u03b5 = inf{t > 0 : Xk (t) \u2265 1 \u2212 \u03b5 for some k \u2208 {1, . . . , n}}.\nThen Ex \u03c4\u03b5 < \u221e. Moreover,\n\u001a\n\n\u001b\n\nPx sup max{X1 (t), . . . , Xn (t)} = 1 = 1.\nt>0\n\nProof. For \u03b1 > 0 and y \u2208 \u2206 define\n\u03c6\u03b1 (y) = \u03c6(y) = ne\u03b1 \u2212\n\nn\nX\n\ne\u03b1yk .\n\nk=1\n\nLet B = A \u2212 diag(\u03c312 , . . . , \u03c3n2 ) and let L be given by (2.6). Then\nL\u03c6(y) = \u2212\u03b1\n\nn\nX\n\nk=1\n\nT\n\n\u03b1yk\n\nyk (ek \u2212 y) Bye\n\n(\n\nLet \u03b2 > 0 be such that\n|(ek \u2212 y)T By| \u2264 \u03b2\n\nfor all y \u2208 \u2206 and k \u2208 {1, . . . , n}.\n\nLet \u03c3min = min{\u03c31 , . . . , \u03c3n }. Then\nL\u03c6(y) \u2264 \u03b1\n\nn\nX\n\nk=1\n\n\u03b1yk\n\nyk e\n\n\u001b\n\n\u001a\n\n2\n\u03b1\u03c3min\nyk (1 \u2212 yk )2 .\n\u03b2\u2212\n2\n\nLet \u03b1 > 0 be so large that\n\u03b1\n\n)\n\nn\nX\n\u03b12 X\n\u2212\nyk2 \u03c3k2 (1\u2212 yk )2 +\n\u03c3j2 yj2 e\u03b1yk .\n2 k=1\nj6=k\n\n2\n\u03c3min\ny(1 \u2212 y)2 \u2265 n\u03b2 + 1\n2\n\nfor all y \u2208\n\n\u0014\n\n\u0015\n\n1\n,1 \u2212 \u03b5 .\nn\n\n\f15\n\nSTOCHASTIC REPLICATOR DYNAMICS\n\nSuppose that y \u2208 \u2206 is such that yk \u2264 1 \u2212 \u03b5 for all k = 1, . . . , n. Then there\nis at least one yk in [ n1 , 1 \u2212 \u03b5], and so\nL\u03c6(y) \u2264 \u03b1\u03b2\n\nX\n\nyk e\u03b1yk + \u03b1\n\nk : yk <1/n\n\n\u2264 \u03b1\u03b2(n \u2212 1)\n\nX\n\nk : yk \u2208[1/n,1\u2212\u03b5]\n\nyk e\u03b1yk {\u2212(n \u2212 1)\u03b2 \u2212 1}\n\ne\u03b1/n\ne\u03b1/n\n+\u03b1\n{\u2212(n \u2212 1)\u03b2 \u2212 1}\nn\nn\n\ne\u03b1/n\n.\nn\nThus, by Dynkin's formula, for every T < \u221e,\n\u2264 \u2212\u03b1\n\n0 \u2264 Ex \u03c6{X(\u03c4\u03b5 \u2227 T )} = \u03c6(x) + Ex\n\nZ\n\n\u03c4\u03b5 \u2227T\n\nL\u03c6(X(s)) ds\n\n0\n\ne\u03b1/n\nEx (\u03c4\u03b5 \u2227 T ).\nn\n\n\u2264 ne\u03b1 \u2212 \u03b1\n\nLetting T \u2192 \u221e, one obtains by monotone convergence that Ex \u03c4\u03b5 < n2 e\u03b1 /\u03b1 <\n\u221e.\nChoosing \u03b5 = 1/m, one obtains in particular that\nPx\n\n\u001a\n\n1\nsup max{X1 (t), . . . , Xn (t)} \u2265 1 \u2212\nm\nt>0\n\nfor every m \u2208 N. Hence\n\u001a\n\n\u001b\n\n=1\n\n\u001b\n\nPx sup max{X1 (t), . . . , Xn (t)} = 1\nt>0\n\n= Px\n\n(\n\n\u221e \u001a\n\\\n\nm=1\n\n1\nsup max{X1 (t), . . . , Xn (t)} \u2265 1 \u2212\nm\nt>0\n\n\u001b)\n\n= 1.\n\n\u0003\n\nProof of Theorem 4.2. Let \u03b5 > 0 and suppose that akk > ajk + \u03c3k2\nfor all j, k = 1, . . . , n with j 6= k. Then, for every k, there exists, by Theorem\n4.1, some \u03b4k > 0 such that\n\u001a\n\n\u001b\n\nPx lim X(t) = ek > 1 \u2212 \u03b5\nt\u2192\u221e\n\nif xk \u2265 1 \u2212 \u03b4k .\n\nSet \u03c4 = inf{t \u2265 0 : Xk (t) \u2265 1\u2212\u03b4k for some k} and F = {limt\u2192\u221e X(t) = ek forsome k}.\nLet \u03c7F denote the indicator function of F . According to Theorem 4.3, \u03c4 is\nPx -almost surely finite, and so, by the strong Markov property of It\u00f4 diffusions,\nPx (F ) = Ex EX(\u03c4 ) \u03c7F \u2265 1 \u2212 \u03b5.\nAs \u03b5 > 0 was arbitrary, the assertion follows. \u0003\n\n\f16\n\nL. A. IMHOF\n\n5. A discrete war of attrition. Theorems 2.1 and 2.2 show that an ESS,\nif it exists, gives precise information about the long-run behavior of the\nstochastic replicator dynamics. In this section explicit expressions are derived for ESSs for a discrete variant of the war of attrition, introduced by\nMaynard Smith and Price (1973). See Maynard Smith (1982) and Bishop\nand Cannings (1978) for a detailed discussion and extensions.\nIn the discrete symmetric war of attrition each player selects a pure strategy j \u2208 {0, 1, . . . , n}, which determines the maximum length of time, cj , the\nplayer is willing to display for. The contest progresses until one of the players\nhas reached his chosen limit; this player leaves and the other player obtains\na reward. The value of the reward is constant or a decreasing function of\nthe length of the contest. Both players incur a cost given by the length of\nthe contest. If both players have chosen the same length of time, the reward\nis shared.\nSpecifically, the pay-off matrix A = (ajk ), j, k = 0, . . . , n, is given by\najk =\n\n(5.1)\nwhere\n\n\uf8f1\n\uf8f4\n\uf8f2 vvk \u2212 ck ,\nk\n\n\u2212 ck ,\n\u2212cj ,\n\n\uf8f4\n\uf8f3 2\n\n0 \u2264 c0 < c1 < * * * < cn\n\nj > k,\nj = k,\nj < k,\n\nand v0 \u2265 v1 \u2265 * * * \u2265 vn > 0.\n\nThe corresponding stochastic replicator dynamics is\n(5.2)\n\ndX(t) = b(X(t)) dt + C(X(t)) dW (t),\n\nwhere W (t) denotes an (n + 1)-dimensional Brownian motion and, for x =\n(x0 , . . . , xn )T ,\nand\n\nb(x) = [diag(x0 , . . . , xn ) \u2212 xxT ][A \u2212 diag(\u03c302 , . . . , \u03c3n2 )]x\nC(x) = [diag(x0 , . . . , xn ) \u2212 xxT ] diag(\u03c30 , . . . , \u03c3n ).\n\nTheorem 2.2 suggests to consider ESSs not only of A but also of the\nmodified pay-off matrix B = (bjk ), j, k = 0, . . . , n, with\n(5.3)\n\nbjk =\n\nand\n\n\uf8f1\n\uf8f4\n\uf8f2 vvk \u2212 ck ,\nk\n\n\u2212 ck \u2212 \u03c1k ,\n\u2212cj ,\n\n\uf8f4\n\uf8f3 2\n\nj > k,\nj = k,\nj < k,\n\nvk\n.\n2\nThe following lemma ensures that the pay-off matrices A and B satisfy\nthe assumptions in Theorems 2.1 and 2.2. The proof is in the Appendix.\n0 \u2264 c0 < c1 < * * * < cn ,\n\nv0 \u2265 v1 \u2265 * * * \u2265 vn > 0,\n\n0 \u2264 \u03c1k <\n\n\f17\n\nSTOCHASTIC REPLICATOR DYNAMICS\n\nLemma 5.1. For the war of attrition with pay-off matrix given by (5.1) or (5.3)\nthere exists a unique ESS, and the pay-off matrix is conditionally negative\ndefinite.\nThe next theorem is a basic persistence result for the replicator dynamics,\nsaying that with probability close to 1 the maximum effort strategy, that\nis, strategy n, will not die out. For j = 0, . . . , n, let ej denote the (j + 1)st\ncolumn of the unit matrix of order n + 1.\nTheorem 5.1. Let X(t) be given by the stochastic replicator dynamics\n(5.2) with initial state x \u2208 \u2206. Let \u03b5 > 0. Then there exists \u03c3 \u2217 = \u03c3 \u2217 (\u03b5) > 0\nsuch that\n\u001a\n\n\u001b\n\nPx lim sup Xn (t) > 0 \u2265 1 \u2212 \u03b5,\nprovided that \u03c30 , . . . , \u03c3n\n\nt\u2192\u221e\n\u2217\n<\u03c3 .\n\nProof. Let p be the ESS for A. It will first be shown that pn > 0.\nSuppose that this is not the case, so that m := max{j : pj > 0} < n. Then\neTm+1 Ap \u2264 eTm Ap, see Hofbauer and Sigmund [(1998), page 63]. As pj = 0\nfor j > m,\neTm Ap =\n\nm\u22121\nX\nj=0\n\neTm+1 Ap =\n\nm\nX\n\n(vj \u2212 cj )pj +\n\n\u0012\n\n\u0013\n\nvm\n\u2212 cm pm ,\n2\n\n(vj \u2212 cj )pj .\n\nj=0\n\nThus\n0 \u2264 eTm Ap \u2212 eTm+1 Ap = \u2212\n\nvm\npm < 0;\n2\n\na contradiction. Hence pn > 0.\nBy Theorem 2.1 and Lemma 5.1, for all t > 0,\n1\nEx\nt\n\nZ\n\nt\n\n0\n\n)\n\n(\n\nn\n1 d(x, p) 1 X\npj \u03c3j2 ,\n+\n|Xn (s) \u2212 pn |2 ds \u2264\n|\u03bb2 |\nt\n2 j=1\n\nwhere \u03bb2 6= 0 depends only on A. Choose t0 > 0 and \u03c3 \u2217 > 0 such that\nd(x, p) p2n \u03b5\n,\n<\n|\u03bb2 |t0\n16\n\n(\u03c3 \u2217 )2 p2n \u03b5\n<\n.\n|\u03bb2 |\n8\n\n|Xn (s) \u2212 pn |2 ds \u2264\n\np2n \u03b5\n8\n\nThus if \u03c30 , . . . , \u03c3n < \u03c3 \u2217 , then\nEx\n\n1\nt\n\nZ\n\n0\n\nt\n\nfor all t \u2265 t0 .\n\n\f18\n\nL. A. IMHOF\n\nNow consider the increasing sequence of events\n\u001b\n\n\u001a\n\npn\nfor all s \u2265 t0 + \u03bc ,\nF\u03bc = Xn (s) \u2264\n2\n\n\u03bc = 1, 2, . . . .\n\nFor every \u03bc,\np2n \u03b5\n1\n\u2265\n8\n2(t0 + \u03bc)\nS\u221e\n\nso that Px (\n\nZ\n\nF\u03bc\n\n\u03bc=1 F\u03bc ) \u2264 \u03b5.\n\n\u001a\n\nZ\n\n2(t0 +\u03bc)\nt0 +\u03bc\n\n|Xn (s) \u2212 pn |2 ds dPx \u2265\n\np2n\nPx (F\u03bc ),\n8\n\nHence\n\u001b\n\nPx lim sup Xn (t) > 0 \u2265 Px\nt\u2192\u221e\n\n\u221e\n\\\n\nF\u03bcC\n\n\u03bc=1\n\n!\n\n\u2265 1 \u2212 \u03b5.\n\n\u0003\n\nIn general the ESS for a discrete war of attrition may have a fairly complicated structure. Cressman [(2003), Section 7.4] describes a broad approach\nto calculating ESSs for these games using backward induction. Whittaker\n(1996) has recently solved several closely related resource allocation problems based on a multiple trial war of attrition. The following theorem gives\nan explicit expression for the ESS in the case where the \u03c1k and the vk are\nconstant and cj = j for all strategies j. Combining Lemma 5.1 and Theorems 2.1, 2.2 and 5.2, one obtains a fairly complete picture of the long-run\nbehavior of the stochastic replicator dynamics when the conflicts are modeled by a war of attrition.\nLet Um (x) denote the\u221amth Chebyshev polynomial of the second kind, and\nlet U\u22121 (x) \u2261 0. Let i = \u22121.\nTheorem 5.2. Consider the war of attrition with pay-off matrix B =\n(bjk ), j, k = 0, . . . , n, where\n(5.4)\n\nbjk =\n\n\uf8f1\n\uf8f4\n\uf8f2 vv \u2212 k,\n\n\u2212 k \u2212 \u03c1,\n\u2212j,\n\n\uf8f4\n\uf8f32\n\nj > k,\nj = k,\nj < k,\n\nand 0 \u2264 \u03c1 < 21 v. The unique ESS p is given as follows. If the reward v is so\nlarge that v \u2265 2n + 2\u03c1, then\np0 = * * * = pn\u22121 = 0,\n\npn = 1.\n\nOtherwise there is a unique index s \u2208 {0, . . . , n \u2212 1} such that\n(5.5)\n\nn\u22121+\u03c1\u2264\n\nv\n+ s < n + \u03c1,\n2\n\n\f19\n\nSTOCHASTIC REPLICATOR DYNAMICS\n\nand\npk =\n\n\u001a\n\n\u0013k\n\n\u0012\n\n\u0013\n\nv\n\u00d7 us\u2212k+1 + s + 1 \u2212 n + + \u03c1 us\u2212k\n2\n\u0013\n\u001b\n\u0012\nv\n+ \u03c1 us\u2212k\u22121 ,\n+ (s + 1 \u2212 n)\n2\n\n(5.6)\n\n(5.7)\n\n\u0012\n\nv\n1\n\u2212 \u2212\u03c1\nc\n2\n\npk = 0,\npn =\n\n\u0012\n\n0 \u2264 k \u2264 s,\n\ns + 1 \u2264 k \u2264 n \u2212 1,\n\u0013s+1\n\n1\nv\n\u2212 \u2212\u03c1\nc\n2\n\n,\n\nwhere\nuk = (\u2212i\u03b3)k Uk\n\n\u0012\n\n\u0013\n\ni(2\u03c1 + 1)\n,\n\u2212\n2\u03b3\n\n\u03b3=\n\ns\n\nv2\n\u2212 \u03c12\n4\n\nand\nc = \u2212us+2 + (n \u2212 s \u2212 1 \u2212 2\u03c1)us+1 + {2\u03c1(n \u2212 s \u2212 1) + \u03b3 2 }us\n\u2212 (n \u2212 s \u2212 1)\u03b3 2 us\u22121 .\n\nThe proof of this theorem requires some auxiliary results, which are proved\nin the Appendix.\nIt was shown in the proof of Theorem 5.1 that for the war of attrition\n(5.3), strategy n is always contained in the support of the ESS. The next\nlemma states that for j < n, strategy j can belong to the support only if\nthe corresponding cost cj is below a certain threshold. This is the discrete\nanalogue of Theorem 7 of Bishop and Cannings (1978). The lemma explains\nin particular the choice of s in Theorem 5.2.\nLemma 5.2. Let p be the ESS for the war of attrition with pay-off matrix\nB = (bjk ), j, k = 0, . . . , n, described by (5.3). If j < n and cj \u2265 cn + \u03c1n \u2212 21 vn ,\nthen pj = 0.\nThe next two lemmas give explicit formulas for determinants related to\nthe pay-off matrix of a war of attrition. Let Jk denote the k \u00d7 k matrix with\nall entries equal to 1 and let 1k denote the k \u00d7 1 vector all of whose entries\nare 1.\nLemma 5.3. Let B \u2208 R(n+1)\u00d7(n+1) be given by (5.3). For k = 0, . . . , n,\nlet B (k) denote the matrix obtained from B by replacing column k with the\n\n\f20\n\nL. A. IMHOF\n\nvector 1n+1 . Then\ndet B\n\n(n)\n\n=\n\nn\u22121\nY\u0012\nj=0\n\nvj\n\u2212 \u2212 \u03c1j\n2\n\nand, for k = 0, . . . , n \u2212 1,\nen\u2212k + ck Jn\u2212k )\ndet B (k) = det(B\n\n\u0013\n\nk\u22121\nY\u0012\nj=0\n\n\u2212\n\n\u0013\n\nvj\n\u2212 \u03c1j ,\n2\n\nen\u2212k is the (n \u2212 k) \u00d7 (n \u2212 k) principal submatrix of B situated in the\nwhere B\nbottom right-hand corner.\n\nLet B \u2208 R(n+1)\u00d7(n+1) be given by (5.4) with 0 \u2264 \u03c1 < 21 v. Set\n\nLemma 5.4.\n\u03b3=\n\nq\n\n1 2\n4v\n\n\u2212 \u03c12 . Then\n\ndet B =\n\n\u0012\n\n\u0013\n\nv\n\u2212 \u03c1 (\u2212i\u03b3)n\u22121\n2\n\u001a\n\n\u00d7 \u2212i\u03b3Un\n\n\u0012\n\n\u0013\n\n\u0012\n\n\u0013\n\n\u0012\n\ni(2\u03c1 + 1)\nv\ni(2\u03c1 + 1)\n+ \u03c1 Un\u22121 \u2212\n+\n\u2212\n2\u03b3\n2\n2\u03b3\n\n\u0013\u001b\n\n.\n\nProof of Theorem 5.2. Let B be given by (5.4). Suppose first that\nv \u2265 2n + 2\u03c1. Then j \u2265 n + \u03c1 \u2212 21 v for every j = 0, . . . , n \u2212 1. Thus if p is the\nESS, then, by Lemma 5.2, pj = 0 for j = 0, . . . , n \u2212 1, so that p = en .\nSuppose next that 2\u03c1 < v < 2n + 2\u03c1. Define s \u2208 {0, . . . , n \u2212 1} by (5.5) and\ndefine p \u2208 Rn+1 by (5.6), (5.7) and (5.8). It will be shown that\n(5.8)\n\n{Bp}j = {Bp}n\n\nif 0 \u2264 j \u2264 s,\n\n(5.9)\n\n{Bp}j \u2264 {Bp}n\n\nif s + 1 \u2264 j \u2264 n \u2212 1.\n\nIt will also be shown that p \u2208 \u2206. Since, by Lemma 5.1, any principal submatrix of B is conditionally negative definite, it will then follow from Haigh's\n(1975) theorem that p is the ESS.\nFor m = 0, . . . , n set\n\uf8ee\n\nb00\n\uf8ef ..\nBm = \uf8f0 .\n\nb0m\n.. \uf8fa\n. \uf8fb.\n. . . bmm\n\nbm0\n\nAccording to Lemma 5.4,\n(5.10)\n\ndet Bm =\n\n\u0012\n\nv\n\u2212\u03c1\n2\n\n\uf8f9\n\n...\n\n\u0013\u001a\n\num +\n\n\u0012\n\n\u0013\n\n\u001b\n\nv\n+ \u03c1 um\u22121 .\n2\n\n\f21\n\nSTOCHASTIC REPLICATOR DYNAMICS\n\nSet\n\n\uf8ee\n\nb00\n\uf8ef ..\n\uf8ef .\n\nB =\uf8ef\n\n\uf8f0 bs0\n\n...\n\nb0s\n..\n.\n\n\uf8f9\n\nb0n\n.. \uf8fa\n. \uf8fa\n\uf8fa\n\n(k)\n\nbsn \uf8fb\nbnn\n\n{B p\u0304}j = {Bp}j ,\n\n0 \u2264 j \u2264 s,\n\n. . . bss\n. . . bns\n\nbn0\n\nand\n\n\uf8f6\n\n\uf8eb\n\np0\n\uf8ec .. \uf8f7\n\uf8ec . \uf8f7\n\n\uf8f7.\n\uf8ed ps \uf8f8\n\np\u0304 = \uf8ec\n\npn\n\nFor k = 0, . . . , s + 1 let B denote the matrix obtained from B by replacing\ncolumn k with the vector 1s+2 . As pk = 0 for s + 1 \u2264 k \u2264 n \u2212 1,\n(5.11)\n\n{B p\u0304}s+1 = {Bp}n .\n\nThe matrix B is again of the form (5.3). It follows from Lemma 5.3 that for\nevery k \u2264 s \u2212 1,\ndet B\n\n(k)\n\n\u0012\n\n\u0013k\n\n\u0012\n\n\u0013k\n\nv\n= \u2212 \u2212\u03c1\n2\n\n\uf8ee\n\nbk+1,k+1 + k\n\uf8ef\n..\n\uf8ef\n.\n\ndet \uf8ef\n\n\uf8f0 bs,k+1 + k\n\nbn,k+1 + k\n\n. . . bk+1,s + k\n..\n.\n...\n...\n\nbs,s + k\nbn,s + k\n\n\uf8f9\n\nbk+1,n + k\n\uf8fa\n..\n\uf8fa\n.\n\uf8fa\n\nbs,n + k \uf8fb\nbn,n + k\n\nv\n= \u2212 \u2212\u03c1\n2\n\uf8eev\n\uf8f9\n\u2212\u03c1\u22121\n\u22121\n...\n\u22121\n\u22121\n\uf8ef2\n\uf8fa\n\uf8ef\n\uf8fa\nv\n\uf8ef v\u22121\n\uf8fa\n\u2212\n\u03c1\n\u2212\n2\n.\n.\n.\n\u22122\n\u22122\n\uf8ef\n\uf8fa\n2\n\uf8ef\n\uf8fa\n.\n.\n.\n.\n\uf8ef\n\uf8fa.\n\u00d7 det \uf8ef\n..\n..\n..\n..\n\uf8fa\n\uf8ef\n\uf8fa\nv\n\uf8ef v\u22121\n\uf8fa\n\u2212\n\u03c1\n\u2212\n(s\n\u2212\nk)\n\u2212(s\n\u2212\nk)\nv\n\u2212\n2\n.\n.\n.\n\uf8ef\n\uf8fa\n2\n\uf8f0\n\uf8fb\nv\nv\u22121\nv \u2212 2 . . . v \u2212 (s \u2212 k)\n\u2212 \u03c1 \u2212 (n \u2212 k)\n2\nDenote the matrix in the previous line by Q. To calculate det Q augment\nQ from the left by the (s \u2212 k + 1) \u00d7 1 vector (v, . . . , v)T and put on top of\nthe matrix thus obtained the 1 \u00d7 (s \u2212 k + 2) vector ( 12 v \u2212 \u03c1, 0, . . . , 0). This\ngives a matrix which is equal to Bs\u2212k+1 except for the element in the lower\nright-hand corner, which is 21 v \u2212 \u03c1 \u2212 n + k, while the corresponding element\nof Bs\u2212k+1 is 12 v \u2212 \u03c1 \u2212 s + k \u2212 1. Hence\n#\n\" v\n\u0012\n\u0013\u22121\nv\n\u2212\u03c1\n01\u00d7(s\u2212k+1)\ndet Q =\ndet 2\n\u2212\u03c1\n2\nv1s\u2212k+1\nQ\n=\n\n\u0012\n\n\u0013\u22121\n\nv\n\u2212\u03c1\n2\n\n{det Bs\u2212k+1 \u2212 (n \u2212 s \u2212 1) det Bs\u2212k },\n\nand so, by (5.10),\ndet B\n\n(k)\n\n\u0012\n\n\u0013k \u0014\n\nv\n= \u2212 \u2212\u03c1\n2\n\nus\u2212k+1 +\n\n\u0012\n\n\u0013\n\nv\n+ \u03c1 us\u2212k\n2\n\n\f22\n\nL. A. IMHOF\n\n\u001a\n\n\u0012\n\n\u0013\n\nv\n+ \u03c1 us\u2212k\u22121\n\u2212 (n \u2212 s \u2212 1) us\u2212k +\n2\n\n\u001b\u0015\n\n= cpk ,\nprovided k \u2264 s \u2212 1. Similarly, det B\nLemma 5.3 that\ndet B\n\n(s+1)\n\n(s)\n\n= cps , and it follows directly from\n\u0013s+1\n\n\u0012\n\nv\n= \u2212 \u2212\u03c1\n2\n\nThus\n\n\uf8eb\n\n(0)\n\n= cpn .\n\n\uf8f6\n\ndet B\n\uf8f7\n\uf8ec\n..\ncp\u0304 = \uf8ed\n\uf8f8.\n.\n(s+1)\ndet B\n\n(5.12)\n\nLet adj B denote the adjugate matrix of B. It is readily verified that\n\uf8eb\n\n\uf8f6\n\n(0)\n\ndet B\n\uf8f7\n\uf8ec\n..\n(adj B )1s+2 = \uf8ed\n\uf8f8,\n.\n(s+1)\ndet B\n\n(5.13)\nand therefore\n\n1\ndet B\n1s+2 .\nB p\u0304 = B(adj B )1s+2 =\nc\nc\nIn view of (5.11) this proves the first claim (5.8).\nIf s < j < n, then, by (5.5),\nbjn = \u2212j \u2264 \u2212s \u2212 1 \u2264\n\nv\n\u2212 n \u2212 \u03c1 = bnn ,\n2\n\nand so\n{Bp}j =\n\ns\nX\n\nbjk pk + bjn pn =\n\nk=0\n\ns\nX\n\nk=0\n\nbnk pk + bjn pn \u2264\n\nproving the second claim (5.9).\nFinally, to show that p \u2208 \u2206 set\n\u0012\n\n\u0013\n\ns\nX\n\nk=0\n\nbnk pk + bnn pn = {Bp}n ,\n\n\u0012\n\n\u0013\n\nv\nv\ntj = uj + s + 1 \u2212 n + + \u03c1 uj\u22121 + (s + 1 \u2212 n)\n+ \u03c1 uj\u22122 ,\n2\n2\nso that the first s + 1 entries of p can be written as\npk =\n\n\u0012\n\n\u0013k\n\nv\n1\n\u2212 \u2212\u03c1\nc\n2\n\nts\u2212k+1 ,\n\n0 \u2264 k \u2264 s.\n\nj = 1, 2, . . . ,\n\n\f23\n\nSTOCHASTIC REPLICATOR DYNAMICS\n\nIn view of (5.5),\nv\n\u2212 \u03c1 \u2212 n + s < 0,\n2\n\u0012\n\u0013\u0012\n\u0013\nv\nv\nt2 =\n+\u03c1\n\u2212 \u03c1 \u2212 n + s + 1 \u2212 (2\u03c1 + 1)t1 > 0.\n2\n2\nt1 =\n\nUsing the recurrence relation for the Chebyshev polynomials [Szeg\u00f6 (1975),\nequation (4.7.17), page 81] one may verify that\nuk = \u2212(2\u03c1 + 1)uk\u22121 + \u03b3 2 uk\u22122 ,\n\nk \u2265 1.\n\nTherefore,\ntk = \u2212(2\u03c1 + 1)tk\u22121 + \u03b3 2 tk\u22122 ,\n\nk \u2265 3.\n\nIt now follows by induction that (\u22121)k tk > 0 for all k. A short calculation\nshows that c = \u2212ts+2 + ( 12 v \u2212 \u03c1)ts+1 , so that (\u22121)s+1 c > 0. (In particular,\nc 6= 0, which has hitherto been tacitly assumed.) It is thus obvious that\npk \u2265 0 for 0 \u2264 k \u2264 n.\nP\nTo verify that nk=0 pk = 1 note that by (5.7), (5.12) and (5.13),\nn\nX\n\npk = pn +\n\nk=0\n\ns\nX\n\n1\npk = 1Ts+2 (adj B )1s+2 .\nc\nk=0\n\nBy a well-known determinantal formula for partitioned matrices [Gantmacher (1959), page 46],\n1Ts+2 (adj B )1s+2 = det B \u2212 det(B \u2212 1s+2 1Ts+2 ).\nObserving that, by (5.10),\ndet B = det Bs+1 \u2212 (n \u2212 s \u2212 1) det Bs\n=\n\n\u0012\n\n\u0013\u0014\n\nv\n\u2212\u03c1\n2\n\nus+1 +\n\n\u0012\n\n\u0013\n\n\u001a\n\n\u0012\n\n\u0013\n\nv\nv\n+ \u03c1 us \u2212 (n \u2212 s \u2212 1) us +\n+ \u03c1 us\u22121\n2\n2\n\n\u001b\u0015\n\nand\ndet(B \u2212 1s+2 1Ts+2 ) =\n\n\u0012\n\n\u0013\u22121\n\nv\n\u2212\u03c1\n2\n\n\u0012\n\n{det Bs+2 \u2212 (n \u2212 s \u2212 1) det Bs+1 }\n\u0013\n\n\u001a\n\n\u0012\n\n\u0013\n\n\u001b\n\nv\nv\n+ \u03c1 us+1 \u2212 (n \u2212 s \u2212 1) us+1 +\n+ \u03c1 us ,\n= us+2 +\n2\n2\none obtains that 1Ts+2 (adj B )1s+2 = c, so that\n\nPn\n\nk=0 pk\n\n= 1. \u0003\n\n\f24\n\nL. A. IMHOF\n\nAPPENDIX\nP\n\nProof of Lemma 5.1. As qT Bq = qT Aq \u2212 nj=0 qj2 \u03c1j \u2264 qT Aq for all\nq \u2208 Rn+1 , it suffices to show that A is conditionally negative definite. Define\nthe n \u00d7 n matrix D by djk = 21 (bjk + bkj ) \u2212 bj0 \u2212 b0k + b00 , j, k = 1, . . . , n.\nThus\ndjk = vmin{j,k} \u2212 2cmin{j,k} \u2212 v0 + 2c0 .\nFor k = 1, . . . , n let fk be the n \u00d7 1 vector whose first k \u2212 1 entries are 0 and\nwhose remaining entries are 1. Then D can be written as\nD=\n\nn\nX\n\n(vk \u2212 vk\u22121 \u2212 2(ck \u2212 ck\u22121 ))fk fkT ,\n\nk=1\n\nshowing that D is negative definite. This implies that A is conditionally\nnegative definite; see Haigh (1975).\nThe existence of an ESS now follows, since in a game with conditionally\nnegative definite pay-off matrix, a Nash equilibrium, which always exists,\nmust be an ESS. To prove uniqueness suppose p and q are ESSs. Then\npT Bp \u2265 qT Bp and qT Bq \u2265 pT Bq, so that (p \u2212 q)T B(p \u2212 q) \u2265 0. Since B\nis conditionally negative definite, this implies p = q. \u0003\nProof of Lemma 5.2. The assertion is obviously true if pj = 0 for all\nj < n, so assume pj > 0 for some j < n. Let m := max{j : j < n, pj > 0}.\nThen pm > 0 and, as in the proof of Theorem 5.1, pn > 0, so that eTm Bp =\neTn Bp, see Hofbauer and Sigmund [(1998), page 63]. Since pj = 0 if m + 1 \u2264\nj \u2264 n \u2212 1,\neTm Bp =\n\nm\u22121\nX\nk=0\n\neTn Bp =\n\nm\nX\n\n(vk \u2212 ck )pk +\n\n(vk \u2212 ck )pk +\n\nk=0\n\nThus\n0 = eTn Bp \u2212 eTm Bp =\n\n\u0012\n\n\u0012\n\n\u0012\n\n\u0013\n\nvm\n\u2212 cm \u2212 \u03c1m pm \u2212 cm pn ,\n2\n\u0013\n\nvn\n\u2212 cn \u2212 \u03c1n pn .\n2\n\u0013\n\n\u0012\n\n\u0013\n\nvm\nvn\n+ \u03c1m pm +\n\u2212 cn \u2212 \u03c1n + cm pn ,\n2\n2\n\nand it follows that vn /2 \u2212 cn \u2212 \u03c1n + cm < 0. That is, cn + \u03c1n \u2212 vn /2 > cm .\nNow suppose that j < n and cj \u2265 cn + \u03c1n \u2212 vn /2. Then cj > cm , and since\nthe sequence (c\u03bc ) is increasing, j > m. Thus pj = 0. \u0003\nProof of Lemma 5.3. Suppose 1 \u2264 k \u2264 n \u2212 1. For j = 0, . . . , k \u2212 1,\nadd vj \u2212 cj times column k of B (k) , that is, the vector 1n+1 , to column j.\n\n\f25\n\nSTOCHASTIC REPLICATOR DYNAMICS\n\nFor j = k + 1, . . . , n, add ck times column k to column j. The matrix thus\nobtained can be partitioned as\n\uf8ee\n\nD\n\uf8f00\n0\n\n1k\n1\n1n\u2212k\n\n\uf8f9\n\n\u2217\n\uf8fb,\n0\ne\nBn\u2212k + ck Jn\u2212k\n\nwhere D is a k \u00d7 k upper triangular matrix with diagonal elements \u2212v0 /2 \u2212\n\u03c10 , . . . , \u2212vk\u22121 /2 \u2212 \u03c1k\u22121 . The assertion is now obvious. The proof is similar\nfor k = 0 and k = n. \u0003\nLemma A.1. Let \u03b31 , \u03b32 , x \u2208 R, \u03b31 , \u03b32 > 0. The determinant of the n \u00d7 n\ntridiagonal matrix\n\uf8ee\n\nx\n\uf8ef \u2212\u03b32\n\uf8ef\n\uf8ef 0\nDn (x) = \uf8ef\n\uf8ef ***\n\uf8ef\n\uf8f0 0\n0\n\n\u03b31\nx\n\u2212\u03b32\n***\n0\n0\n\n0\n\u03b31\nx\n***\n0\n0\n\n0\n0\n\u03b31\n***\n0\n0\n\n...\n...\n...\n***\n...\n...\n\nn/2\n\n\u0012\n\n0\n0\n0\n***\n\u2212\u03b32\n0\n\n0\n0\n0\n***\nx\n\u2212\u03b32\n\nis given by\n(A.1)\n\nn\n\ndet Dn (x) = i (\u03b31 \u03b32 )\n\nUn\n\n\uf8f9\n\n0\n0 \uf8fa\n\uf8fa\n0 \uf8fa\n\uf8fa\n***\uf8fa\n\uf8fa\n\u03b31 \uf8fb\nx\n\n\u0013\n\nix\n.\n\u2212 \u221a\n2 \u03b31 \u03b32\n\nProof. Note first that\ndet D2 (x) = x2 + \u03b31 \u03b32 .\n\ndet D1 (x) = x,\n\nExpanding det Dn (x) along the last column, one obtains that, for n > 2,\ndet Dn (x) = x det Dn\u22121 (x) + \u03b31 \u03b32 det Dn\u22122 (x).\nDenote the expression on the right-hand side of (A.1) by hn (x). Then\nh2 (x) = x2 + \u03b31 \u03b32 ,\n\nh1 (x) = x,\n\nand, by the recurrence formula for the Chebyshev polynomials [Szeg\u00f6 (1975),\n(4.7.17), page 81], for n > 2,\n\u0012\n\nix\nhn (x) = in\u22121 (\u03b31 \u03b32 )(n\u22121)/2 xUn\u22121 \u2212 \u221a\n2 \u03b31 \u03b32\n\n\u0013\n\n= xhn\u22121 (x) + \u03b31 \u03b32 hn\u22122 (x).\nNow the assertion follows by induction. \u0003\n\n\u0012\n\nix\n\u2212 in (\u03b31 \u03b32 )n/2 Un\u22122 \u2212 \u221a\n2 \u03b31 \u03b32\n\n\u0013\n\n\f26\n\nL. A. IMHOF\n\nProof of Lemma 5.4. Define the n \u00d7 n matrices F and G by\n\uf8eev\n\uf8f9\n\u2212\u03c1\n\uf8ef2\n\uf8fa\n\uf8ef\n\uf8fa\nv\n\uf8ef v\n\uf8fa\n\u2212\u03c1\n\uf8ef\n\uf8fa\n2\n\uf8ef\n\uf8fa\nv\n\uf8ef\n\uf8fa,\nF =\uf8ef v\nv\n\u2212\u03c1\n\uf8fa\n\uf8ef\n\uf8fa\n2\n\uf8ef .\n\uf8fa\n..\n\uf8ef ..\n\uf8fa\n.\n\uf8f0\n\uf8fb\nv\nv\nv\nv\n... v\n\u2212\u03c1\n2\n\uf8ee\n\uf8f9\n\u22121 \u22121 \u22121 . . . \u22121\n\uf8ef \u22121 \u22122 \u22122 . . . \u22122 \uf8fa\n\uf8ef\n\uf8fa\n\uf8ef\n\uf8fa\nG = \uf8ef \u22121 \u22122 \u22123 . . . \u22123 \uf8fa .\n\uf8ef ..\n..\n..\n.. \uf8fa\n\uf8f0 .\n.\n.\n. \uf8fb\n\u22121 \u22122 \u22123 . . . \u2212n\n\nLet I denote the n \u00d7 n unit matrix. Then\n\u0013\n\u0012\n\u0013\n\u0012\nv\nv\n\u2212 \u03c1 det(F + G) =\n\u2212 \u03c1 det G det(G\u22121 F + I).\ndet B =\n2\n2\nIt is easily seen that det G = (\u22121)n . Moreover,\n\uf8ee\n\n\u22122 1\n\uf8ef 1\n\u22122 1\n\uf8ef\n\uf8ef\n1 \u22122\n\uf8ef\nG\u22121 = \uf8ef\n..\n\uf8ef\n.\n\uf8ef\nso that\n\n\u22121\n\nG\n\n\uf8f0\n\n\uf8ee\n\n2\u03c1 + 1\n\uf8ef\n\uf8ef v\n\uf8ef\u2212 \u2212 \u03c1\n\uf8ef 2\n\uf8ef\n\n\uf8ef\n\uf8ef\nF +I =\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8ef\n\uf8f0\n\nv\n\u2212\u03c1\n2\n2\u03c1 + 1\nv\n\u2212 \u2212\u03c1\n2\n\nv\n\u2212\u03c1\n2\n2\u03c1 + 1\n..\n\nIt now follows by Lemma A.1 that\ndet B =\n\n\u0012\n\n\u0013\n\n\u001a\n\n\u0012\n\n.\n\n1\n..\n.\n1\n\n\uf8f9\n\n..\n\n.\n\u22122\n1\n\n\u0012\n\n\u0013\n\n\u22121\n\n\uf8f9\n\nv\n\u2212\u03c1\n2\nv\n\u2212 \u2212\u03c1\n2\n\nv\ni(2\u03c1 + 1)\n\u2212 \u03c1 (\u22121)n in \u03b3 n Un \u2212\n2\n2\u03b3\n\u2212\n\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa,\n\uf8fa\n\uf8fa\n1 \uf8fb\n\n\u0013\n\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa.\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fa\n\uf8fb\n\n..\n\n.\nv\n2\u03c1 + 1\n\u2212\u03c1\n2\nv\nv\n\u2212 \u2212\u03c1 \u2212 +\u03c1+1\n2\n2\n\n\u0012\n\ni(2\u03c1 + 1)\nv\n+ \u03c1 in\u22121 \u03b3 n\u22121 Un\u22121 \u2212\n2\n2\u03b3\n\n\u0013\u001b\n\n\f27\n\nSTOCHASTIC REPLICATOR DYNAMICS\n\n= (\u2212i\u03b3)n\n\n\u001a\u0012\n\n\u0013\n\n\u0012\n\n\u0013\n\n\u0012\n\ni(2\u03c1 + 1)\ni(2\u03c1 + 1)\nv\n\u2212 \u03c1 Un \u2212\n+ i\u03b3Un\u22121 \u2212\n2\n2\u03b3\n2\u03b3\n\n\u0013\u001b\n\n. \u0003\n\nREFERENCES\nAkin, E. (1980). Domination or equilibrium. Math. Biosci. 50 239\u2013250. MR642308\nAlvarez, L. H. R. (2000). On the comparative static properties of the expected population density in the presence of stochastic fluctuations. J. Math. Biol. 40 432\u2013442.\nMR1761532\nAmir, M. and Berninghaus, S. (1998). Scale functions in equilibrium selection games.\nJournal of Evolutionary Economics 8 1\u201313.\nBapat, R. B. and Raghavan, T. E. S. (1997). Nonnegative Matrices and Applications.\nCambridge Univ. Press. MR1449393\nBhattacharya, R. N. (1978). Criteria for recurrence and existence of invariant measures\nfor multidimensional diffusions. Ann. Probab. 6 541\u2013553. MR494525\nBishop, D. T. and Cannings, C. (1978). A generalized war of attrition. J. Theoret. Biol.\n70 85\u2013124. MR472121\nCabrales, A. (2000). Stochastic replicator dynamics. International Economic Review 41\n451\u2013481. MR1760461\nCorradi, V. and Sarin, R. (2000). Continuous approximations of stochastic evolutionary\ngame dynamics. J. Econom. Theory 94 163\u2013191. MR1791297\nCressman, R. (2003). Evolutionary Dynamics and Extensive Form Games. MIT Press.\nMR2004666\nDurrett, R. (1996). Stochastic Calculus. CRC Press, Boca Raton, FL. MR1398879\nFoster, D. and Young, P. (1990). Stochastic evolutionary game dynamics. Theoret.\nPopulation Biol. 38 219\u2013232. [Corrigendum Theoret. Population Biol. 51 (1997) 77\u201378.]\nMR1075000\nFudenberg, D. and Harris, C. (1992). Evolutionary dynamics with aggregate shocks.\nJ. Econom. Theory 57 420\u2013441. MR1180005\nGantmacher, F. R. (1959). The Theory of Matrices 1. Chelsea, New York. MR1657129\nGichman, I. I. and Skorochod, A. W. (1971). Stochastische Differentialgleichungen.\nAkademie Verlag, Berlin. MR346905\nHaigh, J. (1975). Game theory and evolution. Adv. in Appl. Probab. 7 8\u201311.\nHofbauer, J. and Sigmund, K. (1998). Evolutionary Games and Population Dynamics.\nCambridge Univ. Press. MR1635735\nHofbauer, J. and Sigmund, K. (2003). Evolutionary game dynamics. Bull. Amer. Math.\nSoc. (N.S.) 40 479\u2013519. MR1997349\nKandori, M., Mailath, G. J. and Rob, R. (1993). Learning, mutation, and long run\nequilibria in games. Econometrica 61 29\u201356. MR1201702\nKhas'minskii, R. Z. (1960). Ergodic properties of recurrent diffusion processes and stabilization of the solution to the Cauchy problem for parabolic equations. Theory Probab.\nAppl. 5 179\u2013196. MR133871\nKhasminskii, R. Z. and Klebaner, F. C. (2001). Long term behavior of solutions of\nthe Lotka\u2013Volterra system under small random perturbations. Ann. Appl. Probab. 11\n952\u2013963. MR1865029\nKlebaner, F. C. and Liptser, R. (2001). Asymptotic analysis and extinction in a\nstochastic Lotka\u2013Volterra model. Ann. Appl. Probab. 11 1263\u20131291. MR1878298\nMarshall, A. W. and Olkin, I. (1979). Inequalities: Theory and Majorization and Its\nApplications. Academic Press, New York. MR552278\nMaynard Smith, J. (1982). Evolution and the Theory of Games. Cambridge Univ. Press.\n\n\f28\n\nL. A. IMHOF\n\nMaynard Smith, J. and Price, G. R. (1973). The logic of animal conflict. Nature 246\n15\u201318.\nNowak, M. A., Sasaki, A., Taylor, C. and Fudenberg, D. (2004). Emergence of\ncooperation and evolutionary stability in finite populations. Nature 428 646\u2013650.\nNowak, M. A. and Sigmund, K. (2004). Evolutionary dynamics of biological games.\nScience 303 793\u2013799.\nSaito, M. (1997). A note on ergodic distributions in two-agent economies. J. Math.\nEconom. 27 133\u2013141. MR1431151\nSkorokhod, A. V., Hoppensteadt, F. C. and Salehi, H. (2002). Random Perturbation\nMethods with Applications in Science and Engineering. Springer, New York. MR1912425\nSzeg\u00f6, G. (1975). Orthogonal Polynomials. Amer. Math. Soc., Providence, RI.\nTaylor, P. D. and Jonker, L. B. (1978). Evolutionarily stable strategies and game\ndynamics. Math. Biosci. 40 145\u2013156. MR489983\nWeibull, J. W. (1995). Evolutionary Game Theory. MIT Press, Cambridge, MA.\nMR1347921\nWhittaker, J. C. (1996). The allocation of resources in a multiple trial war of attrition\nconflict. Adv. in Appl. Probab. 28 933\u2013964. MR1404316\nInstitut f\u00fcr Statistik\nAachen University\nD-52056 Aachen\nGermany\ne-mail: imhof@stochastik.rwth-aachen.de\n\n\f"}