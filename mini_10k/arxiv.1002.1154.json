{"id": "http://arxiv.org/abs/1002.1154v1", "guidislink": true, "updated": "2010-02-05T08:51:44Z", "updated_parsed": [2010, 2, 5, 8, 51, 44, 4, 36, 0], "published": "2010-02-05T08:51:44Z", "published_parsed": [2010, 2, 5, 8, 51, 44, 4, 36, 0], "title": "Performance Analysis of Software to Hardware Task Migration in Codesign", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1002.2383%2C1002.4348%2C1002.2571%2C1002.4814%2C1002.2691%2C1002.1069%2C1002.0384%2C1002.1504%2C1002.4934%2C1002.0736%2C1002.2459%2C1002.4352%2C1002.3926%2C1002.4119%2C1002.3830%2C1002.0540%2C1002.1154%2C1002.2918%2C1002.1917%2C1002.4470%2C1002.1092%2C1002.1343%2C1002.2415%2C1002.2890%2C1002.2160%2C1002.3741%2C1002.1921%2C1002.1401%2C1002.4778%2C1002.1957%2C1002.3012%2C1002.4985%2C1002.3353%2C1002.3290%2C1002.2049%2C1002.2359%2C1002.0163%2C1002.3232%2C1002.2562%2C1002.2328%2C1002.4512%2C1002.2064%2C1002.2117%2C1002.0904%2C1002.2028%2C1002.3977%2C1002.4827%2C1002.2257%2C1002.0391%2C1002.0992%2C1002.4128%2C1002.4507%2C1002.0396%2C1002.1486%2C1002.3018%2C1002.0787%2C1002.2060%2C1002.0072%2C1002.1903%2C1002.3563%2C1002.2187%2C1002.4435%2C1002.1072%2C1002.3105%2C1002.3037%2C1002.4674%2C1002.1560%2C1002.3557%2C1002.3013%2C1002.2436%2C1002.0893%2C1002.5035%2C1002.0760%2C1002.3647%2C1002.4788%2C1002.3415%2C1002.2077%2C1002.0575%2C1002.4497%2C1002.2073%2C1002.5045%2C1002.0054%2C1002.0307%2C1002.3595%2C1002.3324%2C1002.4881%2C1002.3213%2C1002.4307%2C1002.3065%2C1002.2289%2C1002.0907%2C1002.0983%2C1002.0670%2C1002.4042%2C1002.4803%2C1002.3795%2C1002.0158%2C1002.1117%2C1002.1909%2C1002.0148%2C1002.3410&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Performance Analysis of Software to Hardware Task Migration in Codesign"}, "summary": "The complexity of multimedia applications in terms of intensity of\ncomputation and heterogeneity of treated data led the designers to embark them\non multiprocessor systems on chip. The complexity of these systems on one hand\nand the expectations of the consumers on the other hand complicate the\ndesigners job to conceive and supply strong and successful systems in the\nshortest deadlines. They have to explore the different solutions of the design\nspace and estimate their performances in order to deduce the solution that\nrespects their design constraints. In this context, we propose the modeling of\none of the design space possible solutions: the software to hardware task\nmigration. This modeling exploits the synchronous dataflow graphs to take into\naccount the different migration impacts and estimate their performances in\nterms of throughput.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1002.2383%2C1002.4348%2C1002.2571%2C1002.4814%2C1002.2691%2C1002.1069%2C1002.0384%2C1002.1504%2C1002.4934%2C1002.0736%2C1002.2459%2C1002.4352%2C1002.3926%2C1002.4119%2C1002.3830%2C1002.0540%2C1002.1154%2C1002.2918%2C1002.1917%2C1002.4470%2C1002.1092%2C1002.1343%2C1002.2415%2C1002.2890%2C1002.2160%2C1002.3741%2C1002.1921%2C1002.1401%2C1002.4778%2C1002.1957%2C1002.3012%2C1002.4985%2C1002.3353%2C1002.3290%2C1002.2049%2C1002.2359%2C1002.0163%2C1002.3232%2C1002.2562%2C1002.2328%2C1002.4512%2C1002.2064%2C1002.2117%2C1002.0904%2C1002.2028%2C1002.3977%2C1002.4827%2C1002.2257%2C1002.0391%2C1002.0992%2C1002.4128%2C1002.4507%2C1002.0396%2C1002.1486%2C1002.3018%2C1002.0787%2C1002.2060%2C1002.0072%2C1002.1903%2C1002.3563%2C1002.2187%2C1002.4435%2C1002.1072%2C1002.3105%2C1002.3037%2C1002.4674%2C1002.1560%2C1002.3557%2C1002.3013%2C1002.2436%2C1002.0893%2C1002.5035%2C1002.0760%2C1002.3647%2C1002.4788%2C1002.3415%2C1002.2077%2C1002.0575%2C1002.4497%2C1002.2073%2C1002.5045%2C1002.0054%2C1002.0307%2C1002.3595%2C1002.3324%2C1002.4881%2C1002.3213%2C1002.4307%2C1002.3065%2C1002.2289%2C1002.0907%2C1002.0983%2C1002.0670%2C1002.4042%2C1002.4803%2C1002.3795%2C1002.0158%2C1002.1117%2C1002.1909%2C1002.0148%2C1002.3410&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The complexity of multimedia applications in terms of intensity of\ncomputation and heterogeneity of treated data led the designers to embark them\non multiprocessor systems on chip. The complexity of these systems on one hand\nand the expectations of the consumers on the other hand complicate the\ndesigners job to conceive and supply strong and successful systems in the\nshortest deadlines. They have to explore the different solutions of the design\nspace and estimate their performances in order to deduce the solution that\nrespects their design constraints. In this context, we propose the modeling of\none of the design space possible solutions: the software to hardware task\nmigration. This modeling exploits the synchronous dataflow graphs to take into\naccount the different migration impacts and estimate their performances in\nterms of throughput."}, "authors": ["Dorsaf Sebai", "Abderrazak Jemai", "Imed Bennour"], "author_detail": {"name": "Imed Bennour"}, "author": "Imed Bennour", "arxiv_comment": "International Journal of Computer Science Issues, IJCSI, Vol. 7,\n  Issue 1, No. 1, January 2010,\n  http://ijcsi.org/articles/Performance-Analysis-of-Software-to-Hardware-Task-Migration-in-Codesign.php", "links": [{"href": "http://arxiv.org/abs/1002.1154v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1002.1154v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.PF", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.PF", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1002.1154v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1002.1154v1", "journal_reference": "International Journal of Computer Science Issues, IJCSI, Vol. 7,\n  Issue 1, No. 1, January 2010,\n  http://ijcsi.org/articles/Performance-Analysis-of-Software-to-Hardware-Task-Migration-in-Codesign.php", "doi": null, "fulltext": "IJCSI International Journal of Computer Science Issues, Vol. 7, Issue 1, No. 1, January 2010\nISSN (Online): 1694-0784\nISSN (Print): 1694-0814\n\n64\n\nPerformance Analysis of Software to Hardware Task\nMigration in Codesign\nDorsaf SEBAI1,2, Abderrazak JEMAI1,2 and Imed BENNOUR3\n1\n\nLIP2 Laboratory, Faculty of Science of Tunis, Tunisia\n\n2\n\n3\n\nINSAT, B.P. 676, 1080 Tunis Cedex, Tunisia\n\nE\u03bcE laboratory, Faculty of sciences at Monastir, Tunisia\n\nAbstract\nThe complexity of multimedia applications in terms of intensity\nof computation and heterogeneity of treated data led the\ndesigners to embark them on multiprocessor systems on chip.\nThe complexity of these systems on one hand and the\nexpectations of the consumers on the other hand complicate the\ndesigners job to conceive and supply strong and successful\nsystems in the shortest deadlines. They have to explore the\ndifferent solutions of the design space and estimate their\nperformances in order to deduce the solution that respects their\ndesign constraints. In this context, we propose the modeling of\none of the design space possible solutions: the software to\nhardware task migration. This modeling exploits the\nsynchronous dataflow graphs to take into account the different\nmigration impacts and estimate their performances in terms of\nthroughput.\nKeywords: Multiprocessor systems on chip, Synchronous\ndataflow, Performance estimation, Software to hardware task\nmigration.\n\n1. Introduction\nThe enhancement of multimedia applications reaches its\nculminating point because of the growing consumers\nneeds in all domestic and professional audio video\ndomains. To answer these needs more and more rigid,\nthe embedded systems rapidly evolve towards\nmultiprocessor systems on chip (MPSoCs) particularly\nthose based on networks on chip (NoCs) as\ncommunication architecture. The number of processors\nper chip, the diversity of their types as well as their\ncommunications complicate the MPSoCs design; without\nforgetting the multimedia applications complexity in\nterms of computation intensity and data abundance and\nheterogeneity. So, the principal challenge of designers is\nto face this NoC-based MPSoC design complexity and\nprovide robust systems in the shortest delays. To deal\nwith these conflicting design challenges, designers have\nto estimate principal characteristics of the final system\nearly in the design process of MPSoCs; which results in\na final implementation where productivity and quality\nare simultaneously guaranteed.\n\nDesigners must control the ever growing MPSoC Design\nSpace Exploration (DSE) where different choices are\ninvestigated in order to determine the appropriate choice\nthat leads to a fair compromise between the different\nconflicting design objectives. Typically, the performance\nestimation is an important part of the DSE. Different\nchoices of the application parallelization, the target\nplatform and the mapping of the application onto the\nplatform need to be estimated in terms of different\nquality criteria. If the constraints (energy consumption,\nthroughput, etc.) drawn by the designers are not\nachieved, modifications should be brought to the\napplication decomposition and/or the platform and/or the\nproposed mapping in order to find an MPSoC\nconfiguration that meets the designers constraints.\nIn recognition of the growing need to the MPSoC\nperformance estimation, different approaches aim at\nestimating the overall system performance. In [1], three\napproaches are defined. First, the simulation-based\napproach is based on an evaluation of the system\nbehavior by means of simulation (native execution,\nInstruction Set Simulator, etc.) in different abstraction\nlevels. Kai Huang and al [2] exploits the Simulink\nplatform to simulate the multimedia applications on\ndifferent hardware platforms. The H.264 decoder is used\nas a case study to validate this work. Its simulation on\ndifferent platforms (change of the processors type and\nnumber) estimates the number of consumed cycles per\nprocessor for execution and communication. In the same\nway, Teresa Medina Leon [3] proposes the MJPEG\ndecoder simulation on the MiniNoC platform to estimate\nthe time required for a frame decoding. The MiniNoC\nplatform, implemented in C++, simulates in the register\ntransfer level a platform composed of four mini MIPS\nprocessors displayed in four nodes that communicate\nwith each other via a mini NoC composed of four\nrouters. Second, the trace based approach consists in\ncollecting the application execution traces. Designers\noperate a single simulation at the beginning of the design\n\n\f65\n\nIJCSI International Journal of Computer Science Issues, Vol. 7, Issue 1, No. 1, January 2010\nISSN (Online): 1694-0784\nISSN (Print): 1694-0814\n\nphase from which they extract traces of the application\nexecution on the target platform. These traces can be, for\ninstance, the size of the transferred data on the\ncommunication platform, the number of transactions\nbetween every pair of tasks, the execution times of\ndifferent tasks, etc. The collected traces are organized in\nthe form of a Communication Analysis Graph (CAG).\nThe CAG analysis allows the designers to produce\nseveral statistics about the system performances. The\ntrace based approach is generally used when the initial\nsimulation is difficult to reproduce. This approach was\nexploited in [4] to lead to the optimal communication\nmapping on a predefined target architecture assuming\nthat the application is already partitioned and mapped.\nTraces collected in this work serve at calculating, for\nevery edge of the CAG, a weight that reflects the\nfrequency, the volume and the criticism of transactions\nbetween every communicating unity. Finally, the static\napproach that tries to avoid the computationally\nprohibitive and exhaustive simulation, makes use of\n\"static\" models such as graphs, mathematical equations,\nUML components [5] and XML tags to estimate the\nMPSoCs performances.\nIn this paper, we opt for static approach using exactly the\nSynchronous DataFlow Graphs (SDFGs) to model\napplications as well as their mapping on target platforms.\nSDFGs are extremely used for MPSoCs performance\nestimation since they fit well with the characteristics of\nstreaming multimedia applications. Moreover, they can\nmodel many mapping decisions of an application on\nNoC-based MPSoC adding new actors and edges to the\ninitial SDFG of the application. Among the several\ndesign flows [6] [7] [8] that make use of SDFGs as a\nmodel of computation, we focus in this paper on the\npredictable design flow established by Sander Stuijk [9].\nThese design flows do not model the migration of the\napplication software tasks to hardware ones. They just\nassume that executing tasks on hardware blocks requires\nhalf the number of cycles as executing them on general\npurpose processors.\nSo, the principal motivation that governs this work is the\nconsideration of one of these DSE alternatives: the\nsoftware to hardware task migration. The migration\nperformance estimation refines the choice of the optimal\nsolution from the design space. It is a solution adopted to\nface part of the design problems; using a hardware block\ninstead of a software task running on a general-purpose\nmicroprocessor which is not fast enough to achieve\ndesign goals. If the migration solution of a given task\nrespects the constraints fixed by the designers, this\nsolution will be adopted, otherwise the migration of other\ntasks can be performed to satisfy the design constraints.\nIn this context, we begin by defining the impacts that are\ncaused by the migration of a software task to a hardware\none. Second, we opt to model these impacts using SDFG.\nThe latter takes charge of application modeling in the\nform of graphs from which designers can estimate the\napplication throughput.\n\nThe paper is organized as follows. The next section\nintroduces the MPSoCs performance estimation using\nSDFGs. Section 3 details the software to hardware task\nmigration impacts as well as their SDFG modeling. The\ncase study of the MJPEG decoder is given in Section 4.\nConclusions and perspectives are drawn in Section 5.\n\n2. MPSoC\nSDFGs\n\nperformance\n\nestimation\n\nby\n\nSeeing that this paper focuses on the MPSoCs\nperformance estimation using SDFGs, we will first\nintroduce the MPSoCs as well as their architecture and\nprovide an overview of the most important SDFGs\nproperties. Then, the predictable design flow will be\npresented as a flow case that uses SDFGs to estimate the\nperformance of multimedia applications, mapped on\nMPSoCs, in terms of throughput.\n\n2.1 Multiprocessor systems on chip architecture\nThe increasing and exponential complexity of\nmultimedia applications has widely promoted the use of\nSoCs composed of several processors. The processors\nnumber and diversity per chip require a powerful\ncommunication infrastructure that supports numerous\ntransactions between processors. Therefore, bus based\nSoCs have rapidly induced bottlenecks and led to the\nNoC emergence for their flexibility and scalability. The\nNoC based MPSoC architecture is composed of a set of\ntiles connected via the NoC. Every tile is formed by a\nprocessor (P), a local memory (M), a network interface\n(NI) that connects tiles to the NoC and a communication\nassist (CA). The latter is responsible for the data transfer\nbetween the local memory of the tile and the network\ninterface.\nThe NoC is a set of routers connected to each other by\nlinks according to a determined topology. Routers are\nreferenced by two addresses X and Y reflecting their\nrespective positions in two dimensions width and length.\nIn addition, every router is connected to its immediate\nneighbors in the two dimensions X and Y.\nTile\n\nTile\nM\n\nP\n\nCA\n\nM\n\nP\n\nCA\n\nNI\n\nNI\n\nR\n\nR\n\nNoC\nFig. 1 NoC based MPSoC architecture\n\n\f66\n\nIJCSI International Journal of Computer Science Issues, Vol. 7, Issue 1, No. 1, January 2010\nISSN (Online): 1694-0784\nISSN (Print): 1694-0814\n\n2.2 Synchronous dataflow graphs\nSDFG, proposed by Lee and Messerschmitt [10], is a\nmodel of computation used to model multiprocessor\napplications and analyze their temporal behavior during\ndesign phase. Fig. 2 illustrates a simple SDFG example\nformed by two actors A and B. Each actor presents an\napplication task having a given execution time. Edges\nbetween A and B model data communicated between\neach other. We have to mention that the self-edge of\nactor B as well its initial token allow the control of the\nactor internal state. It assures that actor B can only begin\nits next execution when it finishes its current one. In\nSDFGs, data are communicated in the form of tokens\nwhich is a data container where a fixed amount of data\ncan be saved. For instance, edge from B to A contains 2\ninitial tokens used to launch the SDFG execution.\n1\n\n2\n\n3\n\nA\n\nB\n2\n\n1\n\nMPSoC configuration which proposes the mapping of\nthe application SDFG actors on the target platform as\nwell as the scheduling of their communications. The\nopen source tool SDF3 [12] is the implementation of the\npredictable design flow. It also implements algorithms\nfor the SDFGs generation, visualization, transformation\nand analysis.\nThe predictable design flow consists of four phases. The\n\u00ab memory dimensioning \u00bb phase takes an interest in\nmemory allocations of all edges in the application SDFG.\nThe second phase \u00ab constraint refinement \u00bb specifies the\nconstraints that edges must respect in terms of latency\nand bandwidth. \u00ab Tile binding and scheduling \u00bb phase\nproposes the mapping and scheduling of all actors in the\napplication SDFG on the target platform tiles while\nrespecting the throughput constraint. The last phase \u00ab\nNoC routing and scheduling \u00bb takes charge of\ncommunications mapping and scheduling on the\nplatform NoC. Each phase produces a SDFG that models\nphase decisions adding new actors and edges to the\ninitial application SDFG. We detail the memory-aware\nand the binding-aware SDFGs generated respectively by\nthe first and third phase.\n\nFig. 2 SDFG example\n\nNumbers in the extremities of the arcs, named rates,\ndesignate the number of tokens consumed and produced\nby an actor during its firing. In the SDFG example of\nFig. 2, actor A consumes 1 token and produces 2 tokens\nwhereas actor B consumes 1 token and produces 3\ntokens. Since default rates are equal to 1, rates \"1\" can be\nnot mentioned in the SDFG to avoid the graph\nobstruction.\nA fundamental property of SDFGs is that every time an\nactor fires it consumes the same amount of tokens from\nits input ports and produces the same amount of tokens\non its output ports. In addition, an actor can only begin\nits execution when tokens necessary for its firing are\navailable in all its input edges. Actor A of the SDFG\nexample fires as soon as at least 1 token is available in its\nincoming edge (edge from B to A).\n\nThe memory-aware SDFG models the memory\nallocations made by the first phase of the flow. Actors of\nwhich tokens size exceeds the storage capacity of tiles\nlocal memories will be stored in shared memory tiles.\nDuring its firing, actor B of Fig. 3a consumes i tokens\nand produces o tokens. Consumed tokens have a large\nsize and must be stored in a remote memory. So, actor B\nmust operate remote accesses to bring these tokens in\ncase of need. These remote accesses to the remote\nmemory are modeled as shown in the SDFG of Fig. 3b.\n\n(a) Actor B before memory allocation\n\nSDFGs are widely exploited to derive the applications\nthroughput using analytical methods. SDFG throughput\nis formally defined as the average number of the SDFG\niterations per time unit. Literature evokes two equivalent\nmethods of SDFG throughput computation: Maximal\nCycle Mean [11] and self-timed execution [9] methods.\n\n2.3 Case of predictable design flow\nThe predictable design flow [9] enables designers to map\nan application SDFG on NoC based MPSoC platform\nwhile respecting a throughput constraint and minimizing\nthe platform resources usage in terms of processors,\nmemories and bandwidths. The flow takes as entrance\nthe application SDFG, the throughput constraint fixed by\nthe designer and the target platform. It generates an\n\n(b) Actor B after memory allocation\nFig. 3 Memory-aware SDFG [9]\n\nActor B is henceforth modeled by two actors B1 and B2.\nThe remote memory is modeled by two actors m1 and\nm2. While actor B2 operates its (i)th execution, actors B1\nand m1 pre-fetch data necessary for the (i+1)th execution\nof actor B2 from the remote memory. Actors B2 and m2\nare in charge of actor B execution. They also fetch data\n\n\fIJCSI International Journal of Computer Science Issues, Vol. 7, Issue 1, No. 1, January 2010\nISSN (Online): 1694-0784\nISSN (Print): 1694-0814\n\nfrom the remote memory when the pre-fetch phase\ncannot look for all data necessary for the (i+1)th\nexecution of actor B2. Actors Ai and Ao as well as their\ncycles with actors m1 and B2 reserve respectively the\ninput and output behavior of actor B. As for number n, it\nrepresents the number of times actor B fires. When n\ntokens are available in the entrance of actor Ai, it fires.\nIts execution produces n successive executions of actors\nB1, B2, m1 and m2. These n executions provide n tokens\nin the entrance of actor Ao what induces its firing. The\nAo execution allows then next n successive executions of\nactors B1, B2, m1 and m2.\nThe binding-aware SDFG models mapping decisions of\nthe predictable design flow third phase. Edges whose\nsource and destination actors A and B are mapped to the\nsame tile are modeled with a back-edge from A to B. As\nshown in Fig. 4a, the back-edge has \u03b1tile-n initial tokens\nwhich present the remaining free memory space for the\ncommunication between A and B. We notice that \u03b1 tile,\n\u03b1src and \u03b1dst parameters are computed by the first phase of\nthe flow. \u03b1tile designates the memory, in tokens, required\nfor the communication between A and B when they are\nmapped to the same tile. \u03b1src and \u03b1dst designate the\nmemory required respectively in source and destination\ntiles when A and B are mapped to different tiles.\n\n67\n\nActor as considers the worst case where a token\nnecessary for the execution of actor B arrives at the end\nof its TDMA time slot. Therefore, actor as models the\ntime that actor B has to wait to reach its next TDMA slot\nand consume its token.\n\n3. Software to hardware task migration\n3.1 Migration impacts\nSoftware to hardware task migration must be considered\nin the precocious design steps to estimate its gain\ncompared to a pure software application. According to\nthis gain, designers will take the decision for or against\nthe hardware implementation of one or several tasks of\nthe application.\n\u2022 Impact 1: The hardware task execution time:\nThe first migration impact is the remarkable decrease in\nthe execution time of the hardware task compared to the\nsoftware one. The hardware implementation of the\nmigrated task will be executed on special purpose\nhardware and integrated circuits to perform the task\nfunction; what causes a significant reduction on its\nexecution time when compared to its execution on a\ngeneral purpose processor. Executing tasks on hardware\nblocks may require less than half the number of cycles as\nexecuting them on processors.\n\u2022 Impact 2: The migrated task workload:\n\n(a) Actors A and B mapped on the same tile\n\n(b) Actors A and B mapped on different tiles\nFig. 4 Binding-aware SDFG [9]\n\nEdges of which the source and destination actors A and\nB are mapped to different tiles are bound to a connection\nof the platform NoC as shown in the Fig. 4b. The\nremaining free memory spaces for the communication\nbetween A and B in the source and destination tiles are\nrespectively modeled by the back-edges from ac to A and\nfrom B to ac. Actor ac models the sending latency of a\ntoken via the connection. Actor a\u03c1 presents the minimal\nlatency, calculated by the second phase of the flow,\nbetween the production and the consumption of a token\ncommunicated between A and B over the connection.\n\nThis impact draws attention to the workload of the\nsoftware task that disappears once it is executed\nseparately on a hardware block. To clarify the idea, we\nwill consider a simple example of two tasks T1 and T2\nexecuted on the same processor with a TDMA period of\n100 time units. Before migration, T1 has 30% of the total\nTDMA period and T2 takes the remaining 70% for its\nexecution. If we consider the worst case in which a token\nneeded to fire task T1 arrives exactly at the end of its\ntime slice, it has to wait the time slice of T2 (70 time\nunits) before it can fire. After migrating T2 from\nsoftware to hardware, T1 will be the only task executed\non the processor and the whole TDMA wheel size of the\nprocessor will be at its disposal. Therefore, T1 has no\nlonger to wait the time slice allocated to T2 which\nspeeds-up its firing and obviously its throughput.\n\u2022 Impact 3: The migrated task communication:\nOne of the important aspects that must be considered in\nthe software to hardware task migration is the type of\ncommunication that will be used to transfer data from\nsoftware tasks to hardware blocks and vice versa. Since\nwe work at the system level, we will not consider the\ncommunication details such as data synchronization,\nwrappers to integrate the hardware blocks, etc. Different\ntypes of Software/Hardware (SH), Hardware/Software\n(HS) and Hardware/Hardware (HH) communications can\n\n\f68\n\nIJCSI International Journal of Computer Science Issues, Vol. 7, Issue 1, No. 1, January 2010\nISSN (Online): 1694-0784\nISSN (Print): 1694-0814\n\nbe distinguished. In this work, we will focus on three\ncommunication types that we have named SH1, HS1 and\nHH1.\n\nT1\nT1\n1\n1\n\nTable 1: SH1, HS1 and HH1 communications\n\nDescription\n\nSH1\n\nHardware\nBlock\n\nCPU\n\nMemory\n\nT2\n1\n\nNI\n\nMemory\n\nArchitecture\n\nHW Block\n\nThe\nsoftware\ntask\nexecuted on a generalpurpose processor sends\nits output data to the\nbuffer of the hardware\nblock.\n\nCPU\n\nNoC\nHW Block\n\nHS1\n\nThe\nsoftware\ntask\nexecuted on a generalpurpose processor reads\nits input data from the\nbuffer of the hardware\nblock.\n\n(b) After migration of T2\n\nCPU\n\nFig. 5 SH1 communication with T1 and T2 in the same tile before\nmigration\n\nHW Block\n\nHH1\n\nThe producing hardware\nblock sends its output\ndata to the buffer of the\nconsuming\nhardware\nblock.\n\nHW Block\n\n\u2022 Impact 4: The communication overhead:\n\nIf we consider that, before migration, tasks T1 and T2\nare mapped in different tiles. The migration of task T2\nwill not cause a communication overhead since tasks T1\nand T2 already communicate via the NoC before the\nmigration occurs.\nCPU\n\nCPU\n\nT1\n1\n\nT2\n1\n\nThis impact is the direct result of the hardware task\ncommunication with other software and hardware tasks.\nIt depends on the initial mapping of the migrated task\nbefore the migration, the mapping of its communicating\ntasks and the sense of the communication. Therefore,\nevery communication type will be treated apart.\nTo explicit the case of the SH1 communication overhead,\nwe will first consider the example of two software tasks\nT1 and T2 mapped on the same tile. Hence, T1 and T2\ncommunicate locally in the memory of the tile and do not\nneed to transfer data via the NoC. If we decide the task\nT2 migration, tasks T1 and T2 are no more mapped on\nthe same tile and have henceforth to send their\ncommunicated data via the NoC. The usage of the NoC\nleads to an additional load that does not exist before T2\nmigration.\n\nMemory\n\nMemory\n\nNI\n\nNI\n\nNoC\n\n(a) Before migration of T2\n\nHardware\nBlock\n\nCPU\nT1\n1\n\nMemory\n\nT2\n1\n\nNI\n\nMemory\n\nCPU\nT1\n1\n\nNoC\nT2\n1\n\nMemory\n(b) After migration of T2\nNI\n\nNoC\n(a) Before migration of T2\n\nFig. 6 SH1 communication with T1 and T2 in different tiles before\nmigration\n\nAs already seen in the SH1 communication, the\nmigration of task T2 produces a communication\noverhead if the initial software tasks T1 and T2 are\nmapped to the same tile before the migration. If tasks T1\nand T2 are bound to different tiles before the migration\n\n\f69\n\nIJCSI International Journal of Computer Science Issues, Vol. 7, Issue 1, No. 1, January 2010\nISSN (Online): 1694-0784\nISSN (Print): 1694-0814\n\noccurs, a communication overhead takes place. In fact, in\nthe case of the HS1 communication type, the hardware\nblock does not send data to the consuming software task.\nThe hardware task saves its output data in its local\nmemory (1); then the software task must read (2) and\nbring the data necessary for its firing from the memory\nof the hardware block (3) as shown in Fig. 7. Therefore,\nthese remote accesses create an extra load of\ncommunication via the NoC.\nCPU\n\nz CPU\n\nT1\n1\n\nT2\n1\n\nHardware\nBlock\n\nz CPU\nT2\n1\n\nT1\n1\n\nMemory\n\nMemory\n\nNI\n\nNoC\n(a) Before migration of T2\n\nMemory\n\nMemory\n\nNI\n\nNI\n\nHardware\nBlock\n\nHardware\nBlock\n\nT1\n1\n\nT2\n1\n\nMemory\n\nMemory\n\nNoC\n\n(a) Before migration of T2\n\nNoC\nHardware\nBlock\n\nCPU\nT1\n\nT2\n1\n\nMemory\n\n(b) After migration of T2\nFig. 8 HH1 communication\n(1)\n\nMemory\n\nNI\n(3)\n(2)\n\nNoC\n\n(b) After migration of T2\nFig. 7 HS1 communication with T1 and T2 in different tiles before\nmigration\n\nIn the ultimate case, the HH communication overhead,\nwe treat the case of a software task T2 that\ncommunicates with a hardware task T1. The migration of\ntask T2 does not engender any extra communication load\nsince T1 and T2 communicate via the NoC before the\nmigration occurs. As shown in Fig. 8, task T2, before\nmigration, sends its data via the NoC to the memory of\nthe hardware block. After the migration takes place, task\nT2 still sends its output to the hardware block memory.\n\n3.2 Migration modeling\nWe will eventually make use of the predictable design\nflow transformations; so as to have a system-level model\nthat considers all the migration impacts. We have to\nnotice that the communication overhead impact is the\ndirect result of the used communication type. So, the\nmodeling of the migrated task communication impact\n(impact 3) includes the modeling of the communication\noverhead impact (impact 4).\n\u2022 Impact 1 Modeling: Concerning the first migration\nimpact, we can act on the execution times of actors that\nmodel the hardware tasks in the SDFG. The execution\ntimes of actors that model the migrated tasks will be\nreduced compared to their execution times before\nmigration.\n\u2022 Impact 2 Modeling: In [13], TDMA time slice\nallocations are modeled by increasing the execution time\nof every actor firing with the fraction of the TDMA time\nwhich is reserved by other actors. It means that the worst\ncase is considered; that is why the firing of a given actor\nis usually postponed by the TDMA time allocated to\nother actors. Since the migrated task workload will\ndisappear after migration, we will not consider its\nTDMA time in the execution time of the software task\nthat was executed on the same processor on which the\nmigrated task was also executed.\n\n\f70\n\nIJCSI International Journal of Computer Science Issues, Vol. 7, Issue 1, No. 1, January 2010\nISSN (Online): 1694-0784\nISSN (Print): 1694-0814\n\n\u2022 Impact 3 Modeling: The binding-aware SDFG, used by\nthe third phase of the predictable design flow to model\nthe SS communication, can be used to model the SH1\nand the HH1 communications. In fact, SS, SH1 and HH1\ncommunications use the same principle to transfer data\nvia the NoC:\no In the SS communication, the software task T1\nsends data to the local memory of the tile on which\nsoftware task T2 is mapped.\no In the SH1 communication, the software task T1\nsends data to the local memory of the hardware\ntask T2.\no In the HH1 communication, the hardware task T1\nsends data to the local memory of the hardware\ntask T2.\nAs we can notice, in these three types of communication,\ndata are usually transferred from the producing task T1\nto the local memory of the consuming task T2. The\ndifference consists in the extremities of the\ncommunication either they are software or hardware.\nTherefore, the SH1 and HH1 communications can be\nmodeled by the same SDFG shown in Fig. 4b.\nAs explained in Table 1, during an HS1 communication,\nthe hardware task stores its output in its local memory;\nthen the consuming software task operates remote\naccesses to the memory of the hardware block to fetch\ndata necessary for its firing. This communication type\nhas the same principle of tasks that do not have enough\nspace in their tiles to store their data. So, they have to\nstore their data in a shared memory; then they will bring\nthem in case of need. Hence, to model the HS1\ncommunication, we propose the memory-aware SDFG\nalready illustrated in Fig. 3b.\n\none. RE reorders the pixels to rebuild the decompressed\nimage.\n\n4.2 Mapped MJPEG decoder before migration\nReferring to the MJPEG decoder implementation, the\nresulting SDFG of the MJPEG decoder decoding video\nframes of resolution 32*24 is shown in Fig. 9. Actors\nIZZ, IQ, IDCT and CC operate on blocks of 8 by 8 pixels\nso that a token is equivalent to a block of 8 by 8 pixels.\nActors VLD and RE operates on the whole image hence\non 12 = (32/8) * (24/8) matrices of 8 by 8 pixels.\n\nFig. 9 MJPEG decoder SDFG\n\nThe platform on which the MJPEG decoder will be\nmapped, in this case study, is formed by three tiles T1,\nT2 and T3 having each one a total TDMA wheel size of\n100000 time units. Then, we assume that the VLD and\nIZZ actors are mapped on the same tile T1, actors IQ and\nIDCT on the tile T2 and actors CC and RE on the tile T3.\nThe actors execution times before the mapping (ETBM)\ndeduced from [3] [15], the TDMA time slices allocated\nto each actor in the tile on which is mapped (TDMA) and\nthe resulting execution times of actors after the mapping\n(ETAM) are summarized in Table 2.\nTable 2: Actors mapping and TDMA allocations in the MJPEG\ndecoder SDFG\n\n4. Motion JPEG decoder case study\n\nTiles\n\n4.1 Motion JPEG decoder\n\nActors\nETBM\nTDMA\nETAM (*)\n\nThe motion JPEG decoder is a multimedia application\nwhose building blocks are used in many image and video\nprocessing algorithms. The first block VLD performs\nvariable length decoding. IZZ reorders the stream of\npixels coefficients according an inverse zigzag sequence.\nIQ and IDCT functional blocks respectively operate the\ninverse quantization and the inverse discrete cosine\ntransform. CC and RE are not specified in the official\nMJPEG standard [14] but they are necessary to adapt the\npixel stream to output peripherals. CC allows color\nconversion from the YCbCr color scheme to the RGB\n\nTile T1\n\nTile T2\n\nTile T3\n\nVLD\n\nIZZ\n\nIQ\n\nIDCT\n\nCC\n\nRE\n\n2082463\n50000\n2132463\n\n24791\n50000\n74791\n\n49582\n10000\n139582\n\n99165\n90000\n109165\n\n74374\n20000\n154374\n\n892484\n80000\n912484\n\nLegend :\nETBM = Execution Time Before Mapping (clk)\nETAM = Execution Time After Mapping (clk)\n(*)\nETAM(actor) = ETBM(actor) + TDMA(other actors mapped on\nthe same tile)\n\nTo model this proposed mapping, we used the bindingaware graph transformations already detailed above. The\nresulting SDFG of the mapped MJPEG decoder is\npresented in Fig. 10.\n\n\f71\n\nIJCSI International Journal of Computer Science Issues, Vol. 7, Issue 1, No. 1, January 2010\nISSN (Online): 1694-0784\nISSN (Print): 1694-0814\n\nActor\nET (clk)\n\nVLD\n2132463\n\nIZZ\n74791\n\nIQ\n139582\n\nIDCT\n109165\n\nCC\n154374\n\nRE\n912484\n\nac1/ac2\n252047(*)\n\na\u03c11/a\u03c12\n105(**)\n\nas1\n90000\n\nas2\n80000\n\n(*)\n\nET(ac1) = latency of the connection + [size of a communicated token/bandwidth of the connection] = L(c) + [sz/\u03b2]\n= 3 + [1024/0.00406278] = 252047 time units.\nET(ac2) = L(c) + [sz/\u03b2] = 3 + [512/0.00203139] = 252047 time units.\n(**)\nET(a\u03c11) = TE(a\u03c12) = latency calculated by the fifth step of the predictable design flow = \u03c1 = 100000 time units.\nFig. 10 Mapped MJPEG decoder before migration\n\nAfter presenting the SDFG of the mapped MJPEG\ndecoder of Fig. 10 with the SDF3 XML format [16], we\ninject the resulting XML file to the throughput\ncomputation algorithm implemented by the SDF3 tool.\nThe algorithm output is a throughput equal to 13,6\nframes/second (f/s). We notice that obtained throughputs\nare computed for processors frequency of 100 MHz.\nThe most CPU greedy tasks of the MJPEG decoder are\nVLD (35%) and IDCT (20%) [3]. Therefore, we will\nrespectively migrate the VLD and IDCT actors to\nhardware blocks. Then, we will evaluate the MJPEG\ndecoder throughput after migration.\n\n4.3 Mapped MJPEG decoder after VLD migration\nPreserving the same mapping as before the migration, the\nSDGF of Fig. 11a models the MJPEG decoder having\nthe VLD task migrated to a hardware block. The\nmodeling of the migration impacts detailed above will be\napplied to this particular migration case:\n\u2022 Impact 1: We assume that the execution time of the\nmigrated VLD will be reduced to the half of its execution\n\ntime before migration. Therefore, its execution time is\nhenceforth equal to 1041231 = 2082463/2.\n\u2022 Impact 2: Before the migration occurs, VLD and IZZ\nactors shared the processor of the tile T1. That is why\nIZZ firing is postponed by the TDMA time slice\nallocated to actor VLD. Once the VLD actor is migrated\nto a hardware block, the IZZ actor has no longer to wait\nthe 50000 clock cycles reserved to VLD actor as TDMA\ntime slice.\n\u2022 Impact 3: Since actor IZZ requires a block of 8 by 8\npixels for its (i+1)th execution, this block can be entirely\npre-fetched during its (i)th execution and the fetch\nmechanism is no more needed. So, the HS1\ncommunication between VLD and IZZ actors is modeled\nby the memory-aware SDFG of Fig. 3b removing the m\nactor.\nThe throughput of the MJPEG decoder after the\nmigration of the VLD actor is equal to 15.58 f/s. We\nremind that this throughput is obtained using images of\n32*24 resolution and processors frequency of 100 MHz.\nThe VLD hardware implementation allows the decoding\nof 2 extra frames per second compared to the decoding\nthroughput before migration.\n\n\f72\n\nIJCSI International Journal of Computer Science Issues, Vol. 7, Issue 1, No. 1, January 2010\nISSN (Online): 1694-0784\nISSN (Print): 1694-0814\n\nActor\nET(clk)\n\nVLD\n1041231\n\nIZZ2\n24791\n\nIZZ1\n10000\n\nIQ\n139582\n\nIDCT\n109165\n\nCC\n154374\n\nRE\n912484\n\nac1/ac2\n252047\n\na\u03c11/a\u03c12\n105\n\nas1\n90000\n\nas2\n80000\n\nr1/r2\n1\n\nm1\n262047(*)\n\n(*) We suppose that the time necessary for the actor m1 to pre-fetch data in the memory of the HW block is equal to 10000 time\nunits. The latency required to transfer data pre-fetched from the HW block memory to the SW task that requests the data (IZZ2) is\nadded to the execution time of the actor m1: ET(m1)=10000 + 252047.\n(a) VLD Migration\n\nActor\nET(clk)\n\nVLD\n2132463\n\nIZZ\n74791\n\nIQ\n49582\n\nIDCT\n49582\n\nRE\n912484\n\nCC1\n104\n\nCC2\n154374\n\nac1/ac2\n252047\n\na\u03c11/a\u03c12\n105\n\nas1\n0\n\nas2\n0\n\nr1/r2\n1\n\nm1\n262047\n\n(b) IDCT Migration\nFig. 11 Mapped MJPEG decoder after migration\n\n4.4 Mapped MJPEG decoder after IDCT migration\nThe second considered case is the migration of the IDCT\ntask to a hardware block. Fig. 11b presents the SDFG of\nthe mapped MJPEG decoder after the IDCT migration as\nwell as its actors execution times:\n\u2022 Impact 1: The execution time of the IDCT actor after\nmigration is equal to 49582 clock cycles (99165/2).\n\u2022 Impact 2: The execution time of the IQ actor does not\nconsider the 90000 TDMA time slice reserved to the\nIDCT actor since the latter is executed as a separate\nhardware block.\n\n\u2022 Impact 3: The SH1 communication between the\nsoftware actor IQ and the hardware actor IDCT is\nmodeled by the binding-aware SDFG of Fig. 4b. The\nmemory-aware SDFG is employed to model the HS1\ncommunication between IDCT and CC actors.\nThe MJPEG decoder throughput after IDCT migration is\nequal to 17,23 f/s which mean a gain of about 4 f/s.\nTable 3 summarizes the obtained throughputs before and\nafter migration.\nTable 3: The Migration gain of the MJPEG decoder\n\n13,6\n\nThroughput without Migration (f/s)\nThroughput with Migration (f/s)\nMigration Gain (f/s)\n\nVLD\n15,58\n1,98\n\nIDCT\n17,23\n3,63\n\n\fIJCSI International Journal of Computer Science Issues, Vol. 7, Issue 1, No. 1, January 2010\nISSN (Online): 1694-0784\nISSN (Print): 1694-0814\n\n5. Conclusions and perspectives\nIn this paper, we have proposed a SDF model that\nconsiders the software to hardware task migration\nimpacts exploiting graphs used by the predictable design\nflow to model applications mapped to NoC-based\nMPSoCs. The proposed model was applied to the real\nmultimedia application MJPEG decoder to estimate the\nmigration performances in terms of throughput. The\nexperimental results show that, using this model, the\nmigration of VLD and IDCT tasks of the MJPEG\ndecoder leads to respective throughput increases of about\n2 and 4 frames per second.\nThe proposed migration model is particularly useful\nwhen designers want to take decisions for or against\ntasks hardware implementation during design phase.\nOnce programmed, our proposition allows the migration\nperformance estimation in clearly reduced deadlines\n(seconds) compared to its performance estimation using\nsimulations (hours). This gain, at the level of design\ntime, amounts to the high level migration modeling that\nwe have proposed. Designers can explore several\nmigration cases and estimate their performances in tiny\ndelays to cope with the constantly increasing MPSoCs\ndesign complexity and time-to-market pressure.\nWe suggest as continuation to this work the\nimplementation of the proposed migration model to\nautomate its use and facilitate its applicability. Moreover,\nthe migration model can be refined exploiting the\nGuaranteed Throughput Channel proposed in [11].\n\nReferences\n[1] Ahmed Amine Jerraya, Wayne Wolf, \" Multiprocessor\nSystems-on-chips \", Morgan Kaufmann Publishers, 2005.\n[2] Kai Huang, Sang-il Han, Popovici K., Brisolara, L., Guerin\nX., Lei Li, Xiaolang Yan, Soo-lk Chae, Carro L., Jerraya, A.A.,\n\" Simulink-Based MPSoC Design Flow : Case Study of\nMotion-JPEG and H.264 \", Zhejiang Univ., Zhejiang, Design\nAutomation Conference, DAC 2007, 44th ACM/IEEE, June\n2007.\n[3] M. Teresa Medina Leon, \" Fast modelling and analysis of\nNoC-based MPSoCs \", master, Eindhoven University of\nTechnology, September 2006.\n[4] Kanishka Lahiri, Anand Raghunathan, Sujit Dey, \" Efficient\nExploration of the SoC Communication Architecture Design\nSpace \", In Computer Aided Design, IEEE/ACM International\nConference, 2000.\n[5] Jean-Luc Dekeyser, Abdoulaye Gamati\u00e9, Anne Etien, \"\nUsing the UML Profile for MARTE to MPSoC Co-Design \",\nFirst International Conference on Embedded Systems &\nCritical Applications, Tunisie, May 2008.\n[6] J. Hu, and R. Marculescu, \" Communication and task\nscheduling of application-specific networks-on-chip \", IEEE\nProceedings: Computers and Digital Techniques, 152(5):643\u2013\n651, September 2005.\n[7] O. Moreira, J.-D. Mol, M. Bekooij, and J. van Meerbergen,\n\" Multiprocessor resource allocation for hard-real-time\nstreaming with a dynamic job-mix \", In 11th Real Time and\nEmbedded Technology and Applications Symposium, RTAS\n05, Proceedings, pages 332\u2013341. IEEE, 2005.\n\n73\n\n[8] A.D. Pimentel, C. Erbas, and S. Polstra, \" A systematic\napproach to exploring embedded system architectures at\nmultiple abstraction levels \", IEEE Transactions on Computers,\n55(2):99\u2013112, February 2006.\n[9] Sander Stuijk, \" Predictable Mapping of Streaming\nApplications on Multiprocessors \", thesis, Eindhoven\nUniversity of Technology, 2007.\n[10] E. Lee, and D.Messerschmitt, \" Synchronous dataflow \",\nProceedings of the IEEE, 75(9) :1235_1245, September 1987.\n[11] Arno Moonen, Marco Bekooij, and Jef van Meerbergen, \"\nTiming analysis model for network based multiprocessor\nSystems \", Proceedings of the 5th progress symposium on\nembedded systems, ISBN 90-73461-41-3, October 2004.\n[12] S. Stuijk, M.C.W. Geilen, and T. Basten. \" SDF3 : SDF\nFor Free \" In 6th International Conference on Application of\nConcurrency to System Design, ACSD 06, Proceedings, pages\n276_278, IEEE, 2006.\n[13] M. Bekooij, R. Hoes, O. Moreira, P. Poplavko, M.\nPastrnak, B. Mesman, J.D. Mol, S. Stuijk, V. Gheorghita, and J.\nvan Meerbergen, \" Dynamic and Robust Streaming in and\nbetween Connected Consumer-Electronic Devices \", pages 81\u2013\n108, Springer, May 2005.\n[14] International Telecommunications Union, Information\ntechnology \u2013 Digital compression and coding of continuoustone still images \u2013 Requirements and guidelines\n(Recommendation T.81), http://www.itu.int.\n[15] Jos\u00e9 C. Prats Ortiz, \" Design of components for a NoCbased MPSoC platform \", master, Eindhoven University of\nTechnology, June 2005.\n[16] http://www.es.ele.tue.nl/sdf3.\nDorsaf SEBAI received the Engineer degree from the National\nInstitute of Applied Sciences and Technology, Tunisia in 2008 in\nnetworks and computer sciences. She received the Master\ndegree from the Polytechnic School of Tunisia in 2009 in\nElectronic Systems and Communication Networks. Actually, she\nis working as Assistant at the National Institute of Applied\nSciences and Technology in Tunis. She is preparing to begin her\nthesis.\nAbderrazak JEMAI received the Engineer degree from the\nUniversity of Tunis, Tunisia in 1988 and the DEA and \"Doctor\"\ndegrees from the University of Grenoble, France, in 1989 and\n1992, respectively, all in computer sciences. From 1989 to 1992\nhe prepared his thesis on simulation of RISC processors and\nparallel architectures. He became an Assistant Professor at the\nENSI university in Tunis in 1993 and a Maitre-Assistant\nProfessor at the INSAT university in Tunis since 1994. He was\nthe principal investigator for the \"Synthesis and Simulation of\nVLSI circuits\" project at the ENSI/Microelectronic group, the\nsimulation module in AMICAL at TIMA in Grenoble and the\n\"Performance evaluation of MPSoC\" project in LIP2/FST\nLaboratory in Tunis.\nImed BENNOUR received the Master and Ph.D. degrees in CS\nfrom the University of Montreal in 1992 and 1996. He has served\nas scientist at Nortel Telecom Company in Ottawa. He is\ncurrently working as Assistant Professor at the University of\nMonastir, Tunisia. His current research and teaching interests\nare mainly Systems on Chips design methodologies,\nhardware/software verification and high-level synthesis.\n\n\f"}