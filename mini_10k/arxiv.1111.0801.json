{"id": "http://arxiv.org/abs/1111.0801v3", "guidislink": true, "updated": "2011-12-29T11:33:49Z", "updated_parsed": [2011, 12, 29, 11, 33, 49, 3, 363, 0], "published": "2011-11-03T11:26:28Z", "published_parsed": [2011, 11, 3, 11, 26, 28, 3, 307, 0], "title": "Perfectly Balanced Allocation With Estimated Average Using Expected\n  Constant Retries", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1111.7159%2C1111.0650%2C1111.2494%2C1111.0801%2C1111.1492%2C1111.6405%2C1111.2015%2C1111.6120%2C1111.4140%2C1111.6447%2C1111.1941%2C1111.5483%2C1111.2106%2C1111.2414%2C1111.4161%2C1111.1869%2C1111.4651%2C1111.0351%2C1111.5888%2C1111.0139%2C1111.3100%2C1111.6892%2C1111.3042%2C1111.3009%2C1111.0534%2C1111.7155%2C1111.0998%2C1111.3011%2C1111.5047%2C1111.6973%2C1111.5747%2C1111.3139%2C1111.1034%2C1111.0543%2C1111.3748%2C1111.6687%2C1111.4810%2C1111.3541%2C1111.0250%2C1111.1833%2C1111.4024%2C1111.2616%2C1111.2454%2C1111.1977%2C1111.7299%2C1111.5548%2C1111.0792%2C1111.6355%2C1111.1326%2C1111.6166%2C1111.3191%2C1111.5506%2C1111.4695%2C1111.4705%2C1111.1814%2C1111.5194%2C1111.5665%2C1111.4949%2C1111.1707%2C1111.1029%2C1111.6537%2C1111.7262%2C1111.3101%2C1111.3311%2C1111.4930%2C1111.0271%2C1111.2513%2C1111.4363%2C1111.0025%2C1111.1709%2C1111.6030%2C1111.1868%2C1111.6336%2C1111.0809%2C1111.4938%2C1111.4189%2C1111.2175%2C1111.6796%2C1111.6861%2C1111.1403%2C1111.5124%2C1111.2433%2C1111.2837%2C1111.1111%2C1111.1061%2C1111.4060%2C1111.6350%2C1111.5347%2C1111.4316%2C1111.6327%2C1111.5427%2C1111.6835%2C1111.4079%2C1111.1473%2C1111.1807%2C1111.6891%2C1111.5438%2C1111.1358%2C1111.2610%2C1111.4960%2C1111.7223&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Perfectly Balanced Allocation With Estimated Average Using Expected\n  Constant Retries"}, "summary": "Balanced allocation of online balls-into-bins has long been an active area of\nresearch for efficient load balancing and hashing applications.There exists a\nlarge number of results in this domain for different settings, such as parallel\nallocations~\\cite{parallel}, multi-dimensional allocations~\\cite{multi},\nweighted balls~\\cite{weight} etc. For sequential multi-choice allocation, where\n$m$ balls are thrown into $n$ bins with each ball choosing $d$ (constant) bins\nindependently uniformly at random, the maximum load of a bin is $O(\\log \\log n)\n+ m/n$ with high probability~\\cite{heavily_load}. This offers the current best\nknown allocation scheme. However, for $d = \\Theta(\\log n)$, the gap reduces to\n$O(1)$~\\cite{soda08}.A similar constant gap bound has been established for\nparallel allocations with $O(\\log ^*n)$ communication rounds~\\cite{lenzen}.\n  In this paper we propose a novel multi-choice allocation algorithm,\n\\emph{Improved D-choice with Estimated Average} ($IDEA$) achieving a constant\ngap with a high probability for the sequential single-dimensional online\nallocation problem with constant $d$. We achieve a maximum load of $\\lceil m/n\n\\rceil$ with high probability for constant $d$ choice scheme with\n\\emph{expected} constant number of retries or rounds per ball. We also show\nthat the bound holds even for an arbitrary large number of balls, $m>>n$.\nFurther, we generalize this result to (i)~the weighted case, where balls have\nweights drawn from an arbitrary weight distribution with finite variance,\n(ii)~multi-dimensional setting, where balls have $D$ dimensions with $f$\nrandomly and uniformly chosen filled dimension for $m=n$, and (iii)~the\nparallel case, where $n$ balls arrive and are placed parallely in the bins. We\nshow that the gap in these case is also a constant w.h.p. (independent of $m$)\nfor constant value of $d$ with expected constant number of retries per ball.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1111.7159%2C1111.0650%2C1111.2494%2C1111.0801%2C1111.1492%2C1111.6405%2C1111.2015%2C1111.6120%2C1111.4140%2C1111.6447%2C1111.1941%2C1111.5483%2C1111.2106%2C1111.2414%2C1111.4161%2C1111.1869%2C1111.4651%2C1111.0351%2C1111.5888%2C1111.0139%2C1111.3100%2C1111.6892%2C1111.3042%2C1111.3009%2C1111.0534%2C1111.7155%2C1111.0998%2C1111.3011%2C1111.5047%2C1111.6973%2C1111.5747%2C1111.3139%2C1111.1034%2C1111.0543%2C1111.3748%2C1111.6687%2C1111.4810%2C1111.3541%2C1111.0250%2C1111.1833%2C1111.4024%2C1111.2616%2C1111.2454%2C1111.1977%2C1111.7299%2C1111.5548%2C1111.0792%2C1111.6355%2C1111.1326%2C1111.6166%2C1111.3191%2C1111.5506%2C1111.4695%2C1111.4705%2C1111.1814%2C1111.5194%2C1111.5665%2C1111.4949%2C1111.1707%2C1111.1029%2C1111.6537%2C1111.7262%2C1111.3101%2C1111.3311%2C1111.4930%2C1111.0271%2C1111.2513%2C1111.4363%2C1111.0025%2C1111.1709%2C1111.6030%2C1111.1868%2C1111.6336%2C1111.0809%2C1111.4938%2C1111.4189%2C1111.2175%2C1111.6796%2C1111.6861%2C1111.1403%2C1111.5124%2C1111.2433%2C1111.2837%2C1111.1111%2C1111.1061%2C1111.4060%2C1111.6350%2C1111.5347%2C1111.4316%2C1111.6327%2C1111.5427%2C1111.6835%2C1111.4079%2C1111.1473%2C1111.1807%2C1111.6891%2C1111.5438%2C1111.1358%2C1111.2610%2C1111.4960%2C1111.7223&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Balanced allocation of online balls-into-bins has long been an active area of\nresearch for efficient load balancing and hashing applications.There exists a\nlarge number of results in this domain for different settings, such as parallel\nallocations~\\cite{parallel}, multi-dimensional allocations~\\cite{multi},\nweighted balls~\\cite{weight} etc. For sequential multi-choice allocation, where\n$m$ balls are thrown into $n$ bins with each ball choosing $d$ (constant) bins\nindependently uniformly at random, the maximum load of a bin is $O(\\log \\log n)\n+ m/n$ with high probability~\\cite{heavily_load}. This offers the current best\nknown allocation scheme. However, for $d = \\Theta(\\log n)$, the gap reduces to\n$O(1)$~\\cite{soda08}.A similar constant gap bound has been established for\nparallel allocations with $O(\\log ^*n)$ communication rounds~\\cite{lenzen}.\n  In this paper we propose a novel multi-choice allocation algorithm,\n\\emph{Improved D-choice with Estimated Average} ($IDEA$) achieving a constant\ngap with a high probability for the sequential single-dimensional online\nallocation problem with constant $d$. We achieve a maximum load of $\\lceil m/n\n\\rceil$ with high probability for constant $d$ choice scheme with\n\\emph{expected} constant number of retries or rounds per ball. We also show\nthat the bound holds even for an arbitrary large number of balls, $m>>n$.\nFurther, we generalize this result to (i)~the weighted case, where balls have\nweights drawn from an arbitrary weight distribution with finite variance,\n(ii)~multi-dimensional setting, where balls have $D$ dimensions with $f$\nrandomly and uniformly chosen filled dimension for $m=n$, and (iii)~the\nparallel case, where $n$ balls arrive and are placed parallely in the bins. We\nshow that the gap in these case is also a constant w.h.p. (independent of $m$)\nfor constant value of $d$ with expected constant number of retries per ball."}, "authors": ["Sourav Dutta", "Souvik Bhattacherjee", "Ankur Narang"], "author_detail": {"name": "Ankur Narang"}, "author": "Ankur Narang", "links": [{"href": "http://arxiv.org/abs/1111.0801v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1111.0801v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.DS", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1111.0801v3", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1111.0801v3", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Perfectly Balanced Allocation With Estimated Average Using\nExpected Constant Retries\n\narXiv:1111.0801v3 [cs.DS] 29 Dec 2011\n\nSourav Dutta, Souvik Bhattacherjee, and Ankur Narang\nIBM Research, New Delhi, India\n{sodutta3, souvikbh, annarang}@in.ibm.com\n\nAbstract\nBalanced allocation of online balls-into-bins has long been an active area of research for efficient\nload balancing and hashing applications. There exists a large number of results in this domain for\ndifferent settings, such as parallel allocations [1], multi-dimensional allocations [5], weighted balls [4]\netc. For sequential multi-choice allocation, where m balls are thrown into n bins with each ball choosing\nd (constant) bins independently uniformly at random, the maximum load of a bin is O(log log n) + m/n\nwith high probability [3]. This offers the current best known allocation scheme. However, for d =\n\u0398(log n), the gap reduces to O(1) [11]. A similar constant gap bound has been established for parallel\nallocations with O(log\u2217 n) communication rounds [14].\nIn this paper we propose a novel multi-choice allocation algorithm, Improved D-choice with Estimated Average (IDEA) achieving a constant gap with a high probability for the sequential singledimensional online allocation problem with constant d. We achieve a maximum load of \u2308m/n\u2309 with\nhigh probability for constant d choice scheme with expected constant number of retries or rounds per\nball. We also show that the bound holds even for an arbitrary large number of balls, m >> n. Further,\nwe generalize this result to (i) the weighted case, where balls have weights drawn from an arbitrary\nweight distribution with finite variance, (ii) multi-dimensional setting, where balls have D dimensions\nwith f randomly and uniformly chosen filled dimension for m = n, and (iii) the parallel case, where n\nballs arrive and are placed parallely in the bins. We show that the gap in these case is also a constant\nw.h.p. (independent of m) for constant value of d with expected constant number of retries per ball.\n\n1\n\n\f1 Introduction\nA central research area in the domain of randomized algorithms is the occupancy problem for balls-intobins processes [2, 8, 3, 14, 16]. The framework of the problem involves the analysis of the online allocation,\nwherein a set of independent balls is to be assigned to a set of bins. The occupancy problem helps to model\nseveral realistic problems into a formal mathematical structure, and hence opens an active area of work in\nprobability theory as well as in computer science.\nIn the classical \"balls-into-bins\" problem, m balls are sequentially thrown into n bins, where each ball\nis placed into one of the bins independently and uniformly at random (i.u.r.). The natural question then is\nto analyze the maximum load in any of the bins. Mapping the problem to the application domain, we may\nconsider the balls to be jobs or tasks and the bins to be servers. The problem then reduces to scheduling the\njobs with balanced load allocations among the servers.\nProbably one of the earliest applications of randomized load balancing is in the context of hashing.\nFor the chaining method during hash clash, the length of the lists in the hash buckets are a measure of the\nretrieval complexity. For a uniform hash function, the length of the lists follow the same distribution as the\nnumber of balls in a bin in this case.\nThe advent of parallel and distributed systems required efficient online load balancing among the servers\nto improve the throughput of the system. Dependence on a centralized environment for uniform load balancing is highly undesirable for such systems due to high communication complexity. With the introduction\nof the Cloud Computing paradigm, the placement of virtual machines (VMs) on servers provided a new\ndimension to the applicability of the randomized balanced allocation study.\nOther applications such as the design of Multimedia or Data Servers use disk arrays where a data\nunit is partitioned and stored in a distributed fashion. These applications demand even (balanced) access of the disks on retrieval [19] and Karp in [13] discusses applications in video-on-demand (termed\nk-orientability [8]). The balls into bins problem accurately describes these applications only when the balls\nhave uniform weights. Other applications assume the loads to be of different weights to model its various\ndimensions.\nThis paper tackles the problem of sequential online allocation of balls into bins. Assuming we have n\nbins and m balls arriving one at a time are to be thrown into these bins, the problem is to devise an efficient\nalgorithm such that the allocation of the balls is nearly balanced among all the bins. In formal terms, the\nload in each of the bins should be as close to the average, (m/n) as possible. We initially study the case\nof single-dimensional sequential placement of uniform weighted balls into bins problem and then extend\nit for the general weighted case. Finally we also observe that IDEA provides the same result w.h.p. for\nmulti-dimensional balls-into-bins problem for m = n.\nIn this context, we define Gap to be the difference between the heaviest loaded bin and the average load.\nThe currently best known algorithm bounds Gap to O(log log n) with high probability using the symmetric\nd-choice placement strategy [2, 16]. In the d-choice method, each ball selects d bins i.u.r. among the n bins\nand is allocated to the least loaded bin among them. It is well-known that if d = \u0398(log n) choice, the gap is\nO(1) [11].\nIn this paper we propose a novel algorithm, Improved D-choice with Estimated Average, (IDEA) for\nefficient placement of the balls in the bins. We prove that this technique provides a constant Gap with\nhigh probability (w.h.p.) even when d is kept constant, albeit with an expected constant number of retries\nor rounds per ball. We further extend the result to show that the guarantee also holds true for the heavily\nloaded case, i.e. m >> n w.h.p. Our technique is different from the typical greedy d-choice process in that\nit places the ball in the bin that has load equal-to or lower than the estimated average of that bin. Using\nexpected constant number of retries such a bin can be found for each ball and hence the load in each bin\ntends towards the estimated average which also tends towards the actual average, resulting in constant upper\n\n1\n\n\fbound on the gap. Our strategy is also different from the typical asymmetric strategy [22] where in case of\ntie over the load, the leftmost bin gets the ball. Our result can have profound implication both theoretically\nand practically on the online load balancing algorithms.\nThe outline of the paper is as follows: Section 2 presents an introduction to the known works and results\nin this domain. In Section 3 we propose the detailed outline of the IDEA algorithm for allocating the balls\ninto the bins. Section 4 provides the theoretical proof for bounding the Gap to a constant quantity with high\nprobability. Section 5 provides insights into the execution of the IDEA algorithm. Section 6.1 depicts its\nextension for the general weighted balls case, Section 6.2 exhibits similar results for the multi-dimensional\nscenario, and Section 6.3 proposes the protocol for achieving the same results for the parallel scenario.\nFinally, Section 7 concludes the paper.\n\n2 Related Work\nThe study of \"balls-into-bins\" problem dates back to the study of hashing by Gonnet. He showed that when\nn balls are thrown into n bins i.u.r., the fullest bin has an expected load of (1 + o(1)) log n/ log log n [12].\nThe maximum loaded bin in this approach was shown to be O(log n/ log log\np n) w.h.p. [9]. It was also shown\nthat for m \u2265 n log n balls, a bin can have a maximum load of m/n + \u0398( m log n/n).\nAzar et al. [2] showed that if the balls chose sequentially from d \u2265 2 bins i.u.r. (called Greedy[d]\nalgorithm) and greedily selected the bin currently with the lowest load, the Gap could be bounded by\nO(log log n/ log d) w.h.p. However, the solution worked only for the case when m = n. They also showed\nthat the bound is stochastically optimal, i.e. any other greedy approach using the placement information of\nthe previous balls to place the current ball majorizes to their approach. However, if the alternatives are drawn\nfrom separate groups with different rules for tie breaking, it results in different allocations. [22] presents such\nan asymmetric strategy and using witness tree based analysis proves that this leads to an improvement in\nlog(n)\nthe load balance to O( log\nd log(\u03c6d ) ) w.h.p. where, \u03c62 is the golden ratio and \u03c6d is a simple generalization.\nOur algorithm is different from both these techniques in that it uses the estimated gap as the criterion for\nchoosing the bin and makes potentially multiple retries, where in each retry d bins are chosen i.u.r.\nFor the heavily loaded case, m >> n, the bound of O(log log n/ log d) w.h.p. was later proven in [3]\nusing sophisticated techniques in two main high level steps. In the first step, they show that when the number\nof balls is polynomially bounded by the number of bins the gap can be bounded by O(ln ln(n)), using the\nconcept of layered induction and some additional tricks. In particular, they consider the entire distribution\nof the bins in the analysis (while in typical m = O(n) case the bins with load smaller than the average\ncould be ignored). In the second step, they extend this result to general m >> n case, by showing that\nthe multiple-choice processes are fundamentally different from the classical single-choice process in that\nthey have short memory. This property states that given some initial configuration with gap \u2206, after adding\npoly(n) more balls the initial configuration is forgotten. The proof of the short memory property is done by\nanalyzing the mixing time of the underlying Markov chain describing the load distribution of the bins. The\nstudy of the mixing time is via a new variant of the coupling method (called neighboring coupling). It was\nalso shown that when d = \u0398(log n) the gap becomes O(1) [11].\nCole et al. [7] showed that the two-choice paradigm can be applied effectively in a different context,\nnamely, that of routing virtual circuits in interconnection networks with low congestion. They showed how\nto incorporate the two-choice approach to a well-studied paradigm due to Valiant for routing virtual circuits\nto achieve significantly lower congestion.\nKunal et.al. [20] prove that for weighted balls (weight distribution with finite fourth moment) and m >>\nn, the expected gap is independent of the number of balls and is less than nc , where c depends on the weight\ndistribution. They first prove the weak gap theorem which says that w.h.p Gap(t) < t2/3 . Since in the\nweighted case the d choice process is not dominated by the one choice process, they prove the weak gap\n2\n\n\ftheorem via a potential function argument. Then, the short memory theorem is proved. While in [3] the\nshort memory theorem is proven via coupling, [20] uses similar coupling arguments but defines a different\ndistance function and use a sophisticated argument to show that the coupling converges.\nThe (1 + \u03b2)-choice scheme [17] proved that if a ball chooses with \u03b2 \u2208 (0, 1) probability the least loaded\nbin of d = 2 randomly chosen bin, and otherwise i.u.r. a single bin, the Gap becomes independent of m and\nis given by O(log n/\u03b2).\nIn the parallel setting, [14] showed that a constant bound on the gap is possible with O(log\u2217 n) communication rounds. Adler et.al. [1] consider parallel balls and bins with multiple rounds. They present analysis\nlog(n)\nlog(n)\n) bound on the gap (for m = O(n)) using O( loglog(d)\n+ O(d)) rounds of communication.\nfor O( loglog(d)\nFor offline balls-into-bins problem, using maximum flow computations it was shown that the maximum\nload of a bin w.h.p. is \u2308m/n\u2309 + 1. [8] showed that for m > cn log n balls, where c is a sufficiently large\nconstant, a perfect distribution of the balls was possible w.h.p. However, no such similar result is found in\nthe literature for the online sequential case for constant d choice.\nMitzenmacher et. al. in [5] addresses both the single choice and d-choice paradigm for multidimensional\nballs and bins under the assumption that the balls are uniform D-dimensional (0, 1) vectors, where each ball\nhas exactly f populated dimensions. They show that the gap for multidimensional balls and bins, using the\ntwo-choice process, is bounded by O(log log(nD)). We provide a better bound of O(1) w.h.p. for m = n\ncase.\nIn this paper, we study a novel online sequential allocation algorithm for balls-into-bins based on a\nconstant d-choice strategy and prove a constant gap bound both for m = n and the heavily loaded case\nm >> n along with for the general weighted balls and multi-dimensional scenario.\n\n3 The IDEA Algorithm\nIn this section we discuss the execution of the Improved D-choice with Estimated Average (IDEA) algorithm. We consider there are n bins and m balls which arrive in an online fashion. We initially assume\nthat the balls are of uniform weights and are numbered according to the order of their arrival. In hashing\napplications, the number of the balls based on their arrival order plays no role in assisting better or faster\nretrieval. Hence, this assumption does not decrease the complexity of the problem at hand. Later we also\nprovide a blueprint of the case when such a numbering of the balls in not allowed and the weighted balls\ncase with the weights of the balls drawn from an arbitrary distribution with finite variance.\nGiven each bin has an accurate knowledge of the average number of balls in the system, m/n it is easy\nto distribute the balls so as to obtain a perfectly balanced allocation. IDEA operates on the above principle,\nwhere each bin independently calculates a fairly good estimate of the current average number of balls in the\nsystem. Each bin is then loaded nearly equal to its estimated average value. In the remainder of this section\nwe show how each bin independently estimates its average which we later prove, with a high probability, to\nbe very close to the actual average, m/n. We also show that each bin is then loaded close to its estimated\naverage value, giving a maximum load of \u2308m/n\u2309 with a constant gap allocation w.h.p.\nThe IDEA algorithm initially works as in the d-choice algorithm. On arrival of a ball bj , it i.u.r. chooses\nd bins (d is constant) as its possible candidates for placement. Each bin, Bi , i \u2208 [1, n] is characterised by\n\u02c6\ntwo parameters: (i) Current Load, Lji , and (ii) Current Estimated Average, Aji . For each bin we define its\n\u02c6\nestimated gap, Gapji as the difference between its current load and its current estimated average. Formally,\n\u02c6\n\u02c6\nGapji = Lji \u2212 Aji .\n\u02c6\nThe ball bj is then allocated to the bin having the lowest value of Gapji among the d chosen bins. Given\n\u02c6 This\nthe definition of Gap (in Section 1) we would like to place the ball in a bin with negative or zero Gap.\n\n3\n\n\fAlgorithm 1: IDEA Algorithm\nRequire: Number of bins (n), Number of balls (m) and Maximum iteration (\u03b3)\nEnsure: Balanced Allocation of Balls-into-Bins\nfor all bin Bi , i \u2208 [1, n] do\nInitialize the load, LBi and estimated average, A\u02c6Bi to 0\nend for\nfor all ball bj , j \u2208 [1, m] do\nloop \u2190 0\nwhile loop \u2264 \u03b3 do\nChoose d bins, C = {Bin1 , Bin2 , * * * Bind } i.u.r. from the n bins\n\u02c6\nif set C contains at least one bin with negative or zero estimated gap, Gap\u02c6Bini = LBini \u2212 ABin\ni\nthen\nBreak while\nend if\nloop \u2190 loop + 1\nend while\n\u02c6B\nPlace ball bj in the bin, B \u2208 C having the lowest estimated gap, Gap\nLB \u2190 LB + 1\nfor all bins, Bini \u2208 C do\n\u02c6 > \u2308j/n\u2309 then\nif ABin\ni\nf lag \u2190 1\nelse\nf lag \u2190 0\nend if\nif f lag = 0 then\n\u02c6 + 1/d\n\u02c6 \u2190 ABin\nABin\ni\ni\nend if\nend for\nend for\n\nwould ensure that the loads in the bins be close to their estimated average values and thus lead to a lower\n\u02c6 i , it re-chooses its candidate\nGap. Hence, if in the d choice a ball selects no bin with negative or zero Gap\n\u02c6 i , this re-choosing will be carried\nd bins. To boost the probability of a ball choosing a bin having such Gap\nout \u03b3 times, where \u03b3 will later be shown to be approximately a constant.\nThe current estimated average for each of the d bins finally selected by the ball is then incremented by\n1/d. In the next paragraph we discuss the selection of such an increment value. We intuitively argue that\nfor each bin if \u00c2i is finally close to the actual average (m/n) w.h.p., and its load Li is nearly equal to its\nestimated average, the overall Gap in the system will be minimized and the maximum load of a bin will be\n\u2308m/n\u2309. The pseudo-code of IDEA algorithm is shown in Algorithm 1.\nThe probability that a bin is chosen by a ball in its d choice is given by d/n. So when n balls arrive a bin\nwill be chosen d times on expectation. For each such choice the estimated average of the bin is incremented\nby 1/d (Algorithm 1). Hence, its final estimated average will be 1, which is indeed the actual average of\nthe system. However, from Lemma1 we observe that a bin might be chosen d log n times or lesser w.h.p.\nSince we increase the estimated average by 1/d, the estimated average may increase beyond 1 in such cases.\nHence the estimated average of a bin may be greater that 1 in two situations:\n4\n\n\f(i) Not more than n balls have arrived, but the bin has been chosen close to d log n times, or\n(ii) More than n balls have arrived.\nFor case (i), the estimated average of the bin should still remain 1, while in the other case, the estimated\naverage should be increased as usual. It is here that the numbering of the balls come into effect. If the\nestimated average of a bin goes beyond 1 and the next ball which selects this bin has a number less than n,\nthe bin knows that it may be chosen d log n times and hence refrains from increasing its estimated average\nuntil a ball with number more than n selects it. Similarly when the estimated average of a bin increases\nbeyond \u03b1, \u03b1 \u2208 N, it checks if the next ball selecting it has a number greater than \u03b1n. Thus the balls\ncommunicate their numbers as well while choosing the d candidate bins.\nHowever in the scenario where numbering of the balls is forbidden, to differentiate between the two\ncases, we use the sampling technique among the bins. A bin with estimated average just above \u03b1, in this\ncase chooses log n bins i.u.r. and communicates with them for their estimated average. If the average of\nthe estimated averages of the sampled bins is less than 1, the bin comprehends that case (i) has happened,\ni.e., it is receiving more than d balls out of n balls and thus refrains from increasing its estimated average.\nHowever, if the average of the estimated averages are 1, the bin decides that more than \u03b1n balls are arriving\nand increases its estimated value as usual. The probability that the error in the sampled average is greater\nthan \u01eb, a small constant, is given by n1 for constant number of samples when m > n log n and by log n\nsampled choice for m < n log n scenario (sampling theorem). Hence w.h.p. of 1 \u2212 n2 we obtain the right\ndecision for each bin. In Appendix A we discuss in detail the proof for this claim, and also show that the total\nnumber of such sampling done is less than communication done if d = log n. More intelligent sampling\nmethods as that of Reservoir Sampling [21], Subset-Sum Sampling [10, 6] or a combination of Sampling and\nSketching [18, 15] may be used to obtain a better estimates. The study and effects of such methods are not\ndiscussed as a part of this paper.\nHence, we find that IDEA dynamically adapts its estimated average to be closer to the actual average\nof the system. In either case, the estimated average of a bin is increased by at most 1 for every n balls.\n\n4 Theoretical Framework\nIn this section, we provide a theoretical proof of the constant gap performance of the IDEA algorithm.\nFirst, we bound the number of balls that may select each bin. We then establish that each ball in the IDEA\n\u02c6 with a high probability, which makes the load of\nalgorithm chooses at least one bin having negative Gap\neach bin converge to its estimated average value. Finally, we bound the Gap of the system to a constant\nvalue w.h.p. We assume m balls to arrive in an online fashion and there are n bins.\nLemma 1. If each ball chooses d bins i.u.r. out of n bins, each bin is chosen by\nand by at most md\nn log n balls with high probability.\n\nmd\nn\n\nballs on expectation,\n\nProof. Define Y1 , Y2 , * * * Ym to be indicator random variables corresponding to balls b1 , b2 , * * * , bm respectively. Let Yi = 1 represent the event that the ball bi chose bin B as one of its d candidate bins, otherwise\nYi = 0, \u2200i \u2208 [1, m]. Since the balls choose d bins i.u.r., the probability that bin B is chosen among the d\nbins, or Pr(Yi ) = 1, is given by d/n. Let XP\nbe a random variable depicting the number of balls that chose\nB among its d candidate bins. Hence, X = m\ni=1 Yi . The expected value of X is,\nE[X] = E[\n\nm\nX\ni=1\n\nYi ] =\n\nm\nX\ni=1\n\nE[Yi ] =\n\nm\nX\nd\nmd\n=\nn\nn\ni=1\n\n5\n\n[By Linearity of Expectation]\n\n(1)\n\n\fApplying Chernoff's bound on X we obtain,\ne\u03b4\n\nP (X > (1 + \u03b4)E[X]) <\n\n(1+\u03b4)\n\n(1 + \u03b4)\n\ne\u03b4\nmd\n)<\n(1+\u03b4)\nn\n(1 + \u03b4)\nSubstituting \u03b4 = log n \u2212 1 we have,\n\u2234 P (X > (1 + \u03b4)\n\nP (X >\n\nn\nmd\nelog n\u22121\n=\nlog n) <\nn\n(log n)log n\ne(log n)log n\n\n(2)\n\nLet y = (log n)log n . Hence, log y = log n log log n. We have,\n\u21d2 log(y/n) = log n (log log n \u2212 1) = log n (log log n \u2212 log log ee )\nFor large values of n, log log(n/ee ) \u2265 1, giving log(y/n) \u2265 log n. Therefore, we have y > n2 .\nSubstituting in Eq. (2),\n1\nmd\nlog n) <\nP (X >\nn\nen\n\nHence, bin B is chosen by at most\n\n(3)\nmd\nn\n\nlog n balls with a high probability of 1 \u2212\n\n1\nen .\n\nLemma 2. At any iteration, the estimated average of each bin is approximately equal to the current average\nwith high probability.\nProof. We assume here that Z balls have already arrived and have been placed among the n bins. The\nnumber of balls that chose bin B among its d candidates is Zd\nn on expectation, since each bin can be chosen\nby a ball with a probability of nd . The number of such balls is also bounded by Zd\nn log n with high probability\n(by Lemma 1). However, a bin does not increment its estimated average by more than d times for every n\nballs. For each choice the bin B increases its estimated average by d1 . Hence the current value of A\u02c6B is\ngiven by,\nZ\nZd 1\n* =\n, which is the current average.\nA\u02c6B =\nn d\nn\n\nHence, the estimated average \u00c2 of any bin is nearly equal to the actual average w.h.p.\nObservation 1. The variance of the estimated average of a bin B for n balls is,\nn\nn\n1 X\n1 X\nX\nYi ] = 2\nV ar[Yi ]\nV ar[A\u02c6B ] = V ar[ ] = V ar[ .\nd\nd i=1\nd i=1\n\n=\n\n1 d\nd\n1\n1\n.n (1 \u2212 ) = \u2212\nd2 n\nn\nd n\n\n[From Lemma 1]\n\n\u02c6 over all the bins is zero after every n balls.\nLemma 3. The amortized sum of the estimated gap, Gap\nProof. Each ball chooses d candidate bins i.u.r. and is finally allocated to the bin having the least estimated\ngap. Hence for all the d chosen bins, their estimated average is increased by 1/d. The bin which receives\nthe ball witness an increase in its actual load by 1. Hence, overall its estimated gap increases by 1 \u2212 1/d.\nHowever, for the remaining d \u2212 1 bins their loads remain the same, and thus their estimated gap decreases\nby 1/d. Hence the overall change in estimated gap over the d chosen bins is 1 \u2212 1/d + (d \u2212 1)(\u22121/d) = 0.\nInitially, since the sum of the estimated gaps of the bins was 0, the lemma holds.\nConsidering a batch of n balls arriving in the system, a bin may be selected more than d times (Lemma 1).\nIn such case, the bin samples other bins for their current estimated average value, and depending on it may or\n6\n\n\fmay not increase its estimated average as discussed in Section 3. As such the change in the overall estimated\ngaps in this round will not add up to 0. Such a scenario occurs when a bin is selected more than d times in\nthe batch of n balls. Such a bin may not increase its estimated average, and IDEA experiences a positive\nchange in the overall estimated gap of the system for such a round.\nHowever, it can be observed that for a batch of n balls, the total number of bins that are selected by the\nballs is exactly nd. Since we consider a bin to have been selected more than d times, there exists at least\none bin which was selected less than d times. Assume a bank to exist, which loans a unit credit to the bin,\nselected more than d times for n balls, per extra selection. If such a bin is selected d + c times over a period\nof n incoming balls, the total credit units in the bank is exactly c. However, since the number of selections\nare fixed, the total holes in the system will also be exactly be equal to c. Hole in a bin refers to the difference\nof d and the number of times the bin has been selected by n balls, for bins selected less than d times. Each\nsuch bin can be considered to have extra unit credit points per hole, which it returns to the bank after n balls\nhave been allocated to the system. Since the number of credits in the bank is exactly equal to the number of\nextra credits held by the bins in the system, after n balls the total credit points of the bank will be 0.\nIt can easily be observed that the total credits in the system is always a non-negative quantity. Since the\nbins are chosen by the balls i.u.r., all the bins are selected nearly the same number of times over a period of n\nballs, no bins tends to accumulate a large quantity of extra credits that it always keeps returning to the bank.\nThis factor helps to maintain the estimated average of each bin close to the actual average of the system.\nHence, combining both the settings, we prove that on an amortized notion, the sum of the estimated gap in\nall the bins is 0 after every n balls.\nCorollary 1. The sum of the estimated gap over all bins is zero for arbitrary small number of balls allocated\nin the system.\nProof. Let the number of balls being allocated in the system be a function of n, f (n). Given the constraint\nthat the value of f (n) is not a constant, the arguments of Lemma 3 still holds true. Consider, f (n) = n\u01eb ,\nwhere \u01eb is arbitrary small respecting the constraint that f (n) is not a constant. Thus, the sum of the estimated\ngap in the system is 0 after f (n) balls have been allocated to the bins.\n\u02c6 is \u0398(n).\nLemma 4. The number of bins having a zero or negative estimated gap, Gap\nProof. In Lemma 3 and Cor. 1, we show that the sum of the estimated gap of the bins is 0 even when\narbitrarily small number of balls are allocated to the bins. As such the number of bins with positive estimated\ngap cannot increase by more than n\u01eb .\n\u02c6 \u03b2 bins with negative estimated gap, and \u03b8 bins having 0 estimated\nLet there be \u03b1 bins with positive Gap,\ngap. Hence, \u03b1 + \u03b2 + \u03b8 = n. We would like to establish a lower bound on \u03b2 + \u03b8. In order to have minimum\n\u02c6 the value of the gap should be minimum for bins with a positive\nnumber of bins with negative or zero Gap,\ngap and maximum for bins with a negative gap. The minimum positive estimated gap for a bin is Z(1\u2212 d\u22121\nd )\nwhen Z(d \u2212 1) balls have arrived in the system, of which only Z balls have been committed into the bin.\nThe maximum negative estimated average that a bin may have in this case is \u2212 Z(d\u22121)\n. Hence,\nd\nd\u22121\nZ(d \u2212 1)\n)) + \u03b2.(\u2212\n) + \u03b8.0 = 0\nd\nd\n\u2234 \u03b1 = \u03b2(d \u2212 1)\n\n\u03b1.(Z(1 \u2212\n\n[From Lemma 3]\n\n\u02c6 is \u0398(n).\nAs \u03b1 + \u03b2 + \u03b8 = n, we have d\u03b2 + \u03b8 = n. Hence, the number of bins with zero or negative Gap\nFor each round of f (n) balls, the number of bins with zero or negative estimated gap may decrease by\nf (n). Consider that in round k, the number of bins with zero or negative gap is N (ck ). In the (k + 1)th\nround, the number of such bins may become N (ck ) \u2212 f (n). However, as f (n) is considered to be very\n7\n\n\fsmall, in the order notation the number of such bins still remains \u0398(n). We contradict the existence of\nany additive influence of f (n) per round by the argument of amortized analysis in the above lemma and its\ncorresponding corollary.\nLemma 5. Each ball chooses at least one bin having negative estimated gap among its d choices w.h.p. in\n\u03b3 rounds.\nProof. Each ball selects independently and uniformly at random d candidate bins for its placement\n\u0001 n\u0001among\nd\nthe n bins. Hence the probability that bin Bi is chosen as a candidate for ball bj is, Pij = n\u22121\nd\u22121 / d = n .\n\u02c6 The probability that neither of these bins are selected as\nLet there be c bins with zero\nor negative Gap.\nn\u2212c\u0001 n\u0001\ncandidate by a ball = d / d . The ball may re-select its candidates at most \u03b3 times. Therefore, the\n\u0001 n\u0001\u0001\u03b3\nprobability that neither of the c bins are selected in any of the \u03b3 tries = n\u2212c\n. Hence the probability\nd / d\n\u02c6\nthat at least one bin with negative Gap is selected in the \u03b3 iteration is given by,\nP (at least one selected) = 1 \u2212\n\nn\u2212c\nd\u0001\nn\nd\n\n\u0001 !\u03b3\n\n\u22481\u2212\n\n1\n2d\u03b3\n\n[Assuming c = n/2 from Lemma 4]\n\n(4)\n\nFor d = 2 and \u03b3 = 2, we obtain a probability of around 0.94. However, with \u03b3 = log n, the probability\nbecomes nearly 1 \u2212 n1 . Further, we can show that approximately constant number of retries suffice.\nLet the number of bins with positive gap at any point of time be n1\u2212\u01eb , where 0 \u2264 \u01eb \u2264 1. The probability\nPbneg with which a bin with a zero or negative gap is chosen in \u03b3 iterations is given by,\nn1\u2212\u01eb\nd\u0001\nn\nd\n\nPbneg = 1 \u2212\n\n\u0001 !\u03b3\n\nFor a zero or a negative bin to be chosen with a high probability, we need Pbneg \u2265 1 \u2212 n1\u03c6 , where \u03c6 > 0.\n\u0011\n\u0010\n1\u2212\u01eb\n\u03c6\n. Hence, at least one such bin is chosen by each ball in\nHence for 1 \u2212 ( n n )d\u03b3 > 1 \u2212 n1\u03c6 . Thus, \u03b3 > d\u01eb\napproximately constant \u03b3 re-polls or rounds per ball w.h.p.\nIn the next lemma, we show that in practice only a couple of retries are needed to get a bin with zero or\nnegative estimated gap.\nLemma 6. The expected number of rounds, \u03b3 per ball to find a bin with zero or negative estimated gap is\nconstant.\nProof. Let pi denote the probability that we find a zero or a negative bin at iteration i. Therefore, we have\npi =\n\ni\u22121\nY\n1\n\nPpos\n\n!\n\n* Pneg =\n\ni\u22121\nY\n1\n\n\u0013\n\u0012\n1\n2d \u2212 1\n1\n=\n*\n1\n\u2212\n2d\n2d\n2id\n\nwhere Ppos is the probability of selecting a bin with a positive estimated gap and Pneg is the probability of\nselecting a bin with a zero or negative gap. The expected number of rounds per ball, \u03b3 to find a zero or a\nnegative gap is given by,\nlog n\n\nE[\u03b3] =\nLet,\n\nX\n\nd\n\u0001X\ni\nipi = 2 \u2212 1\n2id\ni=1\n\nd\n\n(5)\n\nlog n\nd\n\nS(i) =\n\nX i\n2id\ni=1\n\n(6)\n\nlog n\n\nd\nX\nS(i)\ni\n\u2234 d =\n(i+1)d\n2\n2\ni=1\n\n8\n\n(7)\n\n\fSubtracting Eq. (7) from Eq. (6), we have\n\u0012\n\u0013\n1\n1\nlog n\n1\n1 \u2212 d S(i) = d \u2212 1+log n + d d\n2\n2\nd2\n2 (2 \u2212 1)\n\u2234 S(i) \u2248\n\n2d\n\n(8)\n\n2\n\n(2d \u2212 1)\n\nSubstituting Eq. (8) in Eq. (5), we have\nE[\u03b3] \u2248 1 +\n\n1\n2d \u2212 1\n\n(9)\n\n\u21d2 E[\u03b3] < 2\n\nGiven the number of bins having negative of zero estimated gap to always remain \u0398(n), the number of\nretries per balls remains constant throughout the execution of the IDEA algorithm.\nLemma 7. The load of each bin tends to its estimated average.\n\u02c6 with high probability 1\u2212 1\u03c6 (Lemma 5)\nProof. IDEA places each ball into a bin with zero or negative Gap,\nn\n\u02c6 increases. Thus, the probability that this bin will again\nusing \u03b3 retries. When a ball is placed in a bin, its Gap\nget a ball lowers. On the other hand, the bins that had been chosen but the ball was not placed in them have\na decrease in their estimated gap. Hence, the probability that a ball is placed in them increases. So, a bin\n\u02c6 has a higher probability of a ball being allocated to it, whereby its estimated gap\nwith a negative or zero Gap\ntends towards 0 (in case of negative estimated gap-ed bins). On the other hand, bins with positive estimated\ngap receive a ball with low probability even when chosen as candidates, and their estimated gap decreases\ntowards 0. Hence, we observe that the estimated gap of any bin tends towards 0. Since, estimated gap is\nthe difference of the load and the estimated average of a bin and the gap tends to zero, the load of the bins\nbecomes nearly equal to their estimated average w.h.p.\nTheorem 1. The maximum load in any bin is \u2308m/n\u2309 + \u0398(1) w.h.p using the IDEA allocation algorithm\nfor the sequential, on-line and unweighted balls-into-bins problem.\nProof. Using the above lemmas we observe that the estimated average of each bin finally becomes \u2308m/n\u2309\nand the load in each bin is equal to its estimated average w.h.p. Hence the maximum load in any bin is\n\u2308m/n\u2309 + \u0398(1) w.h.p.\nCorollary 2. The IDEA algorithm provides a perfectly balanced allocation with constant gap.\nProof. Since the maximum loaded bin has a load of \u2308m/n\u2309 + \u0398(1) w.h.p. (Theorem 1), the Gap is of \u0398(1)\nproviding a perfectly balanced allocation for the balls-into-bins problem with constant gap.\n\n5 Discussion\nWe note that the Greedy[d] algorithm can also retry \u03b3 times to find a bin of even lower total number of\nballs that what it could do in a single round. Still, the distribution of the balls in bins will be different than\nthe IDEA algorithm because the IDEA algorithm explicitly uses the expected gap to make the decision of\nwhere the ball is placed. The key question is can the Greedy[d] algorithm give a constant gap and the answer\nis negative for a single retry because of the well known lower bound of O(ln ln(n)) [2], while for multiple\nretries \u03b3 has to be \u0398(log(n)) [11] to achieve a constant gap. IDEA however requires only constant (< 2)\n\u03c6\nretries with\nretries in the expectation (Lemma 6), to achieve the constant gap. Further, it requires \u03b3 = d\u01eb\nhigh probability (Lemma 5).\n9\n\n\fA bin, B is chosen by d balls among n balls on expectation. However, the bin may be chosen \u03b1d times,\n0 \u2264 \u03b1 \u2264 1 among the first \u03c1 balls that arrive. As such, the Greedy[d] choice algorithm will place the\nballs in empty or lesser loaded bins if available. In the remaining balls, B is chosen (1 \u2212 \u03b1)d times. Now,\nfor large values of \u03b1, even if all these balls are placed in it, B will have a load far less than the average of\nthe system. So the Gap increases. However, for IDEA with large \u03b1 values, the estimated average for B\nwill be large and hence its estimated gap will be significantly lower than the other bins. So, it has a higher\nprobability of a ball being allocated to it. Thus, when the remaining balls arrive and a small fraction of them\nare placed in B, its load will still be closer to the actual average as compared to the d-choice algorithm. This\nsensitivity towards skewness in the random choices also enables IDEA to arrive at a better allocation than\nthe d-choice.\n\n6 Extended Framework\n6.1 Weighted Case\nIn this section we consider the weighted case of the balls-into-bins problem where the balls have weights\ndrawn from a distribution \u03c7 with an expected weight W \u2217 , such that the weight of any ball W has a finite\nvariance and can be bounded by (W \u2217 \u2212 k) \u2264 W \u2264 (W \u2217 + k), where k is a constant. We apply the IDEA\nalgorithm and show that the gap is also constant w.h.p. in such scenarios.\nTheorem 2. The maximum load in any bin is W \u2217 (\u2308m/n\u2309 + \u0398(1)) w.h.p using the IDEA allocation algorithm for the sequential, on-line and weighted balls-into-bins problem.\nProof. Reworking the lemmas stated in Section 4 we observe that the estimated average of each bin converges to W \u2217 \u2308m/n\u2309 and that the load in each bin tends to its estimated average w.h.p. Hence the maximum\nload in any bin is given by W \u2217 (\u2308m/n\u2309 + \u0398(1)) w.h.p. The complete proofs of the lemmas for the weighted\ncase is provided in Appendix B.\nCorollary 3. The IDEA algorithm provides a perfectly balanced weighted allocation with constant gap\neven for the general weighted case of the Balls-into-bins problem.\nProof. From Theorem 2 we observe that as the maximum load is W \u2217 (\u2308m/n\u2309 + \u0398(1)). Hence IDEA\nprovides a perfectly balanced allocation for the weighted case w.h.p. having a constant gap of W \u2217 \u0398(1).\n\n6.2 Multi-Dimensional Case\nIn this section, we consider the multidimensional (md), variant of the balls and bins problem. One multidimensional variant, proposed by [5] is as follows: Consider throwing m balls into n bins, where each ball is\na uniform D-dimensional\n\u0001 (0-1) vector of weight f . Here, each ball has exactly f non-zero entries chosen\nD\nuniformly among all f possibilities. The average load in each dimension for each bin is given as mf /nD.\nLet l(a, b) be the load in the dimension a for the bth bin. The gap in a dimension (across the bins)\nis given by gap(a) = maxb l(a, b)avg(a), where avg(a) is the average load in the dimension a. The\nmaximum gap across all the dimensions, maxa gap(a), then determines the load balance across all the\nbins and the dimensions. Thus, for the multidimensional balanced allocation problem, the objective is to\nminimize the maximum gap (across any dimension). We refer to the multidimensional ball as md-ball and\nthe multidimensional bin as md-bin.\nIn another variation of multidimensional balanced allocation the constraint of uniform distribution for\npopulated entries is removed. Here again, each ball is a D dimensional 0-1 vector and each ball has exactly\nf populated dimensions, but these populated dimensions can have an arbitrary distribution. In the third\n10\n\n\fvariation that is most general of the three, the number of populated dimensions, f , may be different across\nthe balls, where f then is a random variable with an appropriate distribution.\nEach md-ball has f populated dimensions, where f could be constant across the balls or a random\nvariable with a given distribution. Let, si (t) denote the sum of the loads (minus corresponding\ndimension\nPD\nd\naverages) across all D dimensions for the bin i at time t, expressed as si (t) =\nd=1 xi . This reduces\nthe problem to that of the scalar weighted case. The IDEA algorithm works based on the sum of the\ndimensions for each bin. Also, for each choice of the bin, its estimated average is now incremented by fd .\nTheorem 3. For the multi-dimensional scenario, the IDEA algorithm provides a constant gap for uniform\ndistribution of the f populated dimensions for each ball with m = n.\nProof. Following the analysis in Section 6.1, the Gap in the system is bounded by \u0398(1). Hence, the difference of the number of balls in the maximum bin and the actual average of the system is constant. For\nm = n, the average is 1 and so the number of balls in the maximum bin is also a constant. Given a uniform\ndistribution of the f populated dimensions of each ball over D, the Gap is bounded by \u0398(1).\n\n6.3 Parallel Case\nIn this section we describe the algorithmic protocol to extend IDEA for the parallel balls-into-bins scenario.\nIn the parallel scenario multiple balls are allocated to bins simultaneously in a single round. The remain\nballs are considered for allocation in the next round. This process is repeated until all the balls are allocated.\nLater in this section we will show that the proposed protocol ensures that the algorithm completes in a finite\nnumber of rounds. We consider that in any round, r, a bin may accept only one ball.\nLet x balls be simultaneously allocated in round r. We observe that the outcome of round r can be\nobtained by sequentially allocating x balls by IDEA. Hence any round in the parallel case can be replaced\nby a series of sequential processes of IDEA. Hence the gap remains constant even in the parallel case with\nIDEA.\nAlgorithm 2: Communication Protocol\nRequire: Number of bins (n), Number of choices per ball (d)\nEnsure: Parallel execution of IDEA\nStep 1. Each ball, Bi chooses d bins as candidates for allocation, and stores the choices as Mi .\nStep 2. Ball Bi queries its chosen bins (Mi ) for the estimated gap.\nStep 3. The bins queries returns their estimated gap to the corresponding balls.\nStep 4. Ball Bi selects the bin bi with the lowest estimated gap among its chosen bins and sends a\nconfirmation message, C1i .\nStep 5. A bin bj receiving a C1i message confirms allocation of ball Bi and sends it a message C2ij . If a\nbin receives multiple C1i messages, it arbitrarily selects one of them.\nStep 6. Ball Bi after receiving C2ij sends message IN C to all its d chosen bins (Mi ) and commits to\nbin bj .\nStep 7. All the bins in Mi receiving IN C message increments their estimated average by d1 .\n\nThe communication protocol, as given in Algorithm 2 ensures that there is no deadlock in the system\nand that each bin accepts at most one ball in each round. Since the allocation of a ball into a bin is done by\ntwo-way handshaking between the ball and the bin, a bin may receive multiple confirmations from the balls\nbut will accept only one of them, and since each ball makes a single choice of the bin where it prefers to be\n\n11\n\n\fallocated, deadlock in the system is avoided. The update of the estimated average of the bins receiving the\nIN C message is similar to that of the sequential IDEA with the use of sampling.\nWe now prove that the algorithm terminates in finite number of rounds to guarantee a constant gap.\nTheorem 4. IDEA in the parallel scenario using the communication protocol described in Algorithm 2\nprovides a constant gap in expected O(log log n) rounds.\nProof. Since each round of the parallel case of IDEA can be simulated with multiple sequential processes\nof it, IDEA along with the communication protocol described above provides a constant gap.\nWe observe that the execution of IDEA is identical to that of the ordinary d-choice algorithm except\nfor the parameter on which the allocations of the balls are done. Hence Theorem 21 of [1] stating that the\nThreshold(1) for parallel cases terminates after at most log log n + O(1) steps, holds in our case as well.\nHowever, each ball will select a bin zero or negative estimated gap in \u03b3 retries. Hence the total number\nof rounds taken by IDEA in the parallel setting will be given by \u03b3 log log n. The expected value of \u03b3 is\na constant (Lemma 6). Hence the expected number of rounds for the algorithm to terminate is given by\nO(log log n).\nIt can easily been observed that this protocol still provides a constant gap even for the heavily loaded\ncase when m >> n.\n\n7 Conclusions\nThis paper proposes the Improved D-choice with Estimated Average, IDEA algorithm which w.h.p. provides a perfectly balanced allocation for the sequential, online and uniform weighted balls-into-bins problem. We propose a better metric for greedy placement of the balls using the estimated average of the system\nfor each bin. We show that for a constant d choice and expected constant number of rounds per ball, the\nmaximum loaded bin in IDEA is \u2308m/n\u2309 + \u0398(1) w.h.p. This result holds for m = n case as well as the\nheavily loaded scenario where m >> n. We also extends the solution for the general weighted case (with\nm >> n) to show similar results for balls with weights taken from an arbitrary distribution with finite variance and for the multi-dimensional case with m = n for uniform distribution of f populated dimensions\nover the D total dimensions. We also propose a communication protocol which in conjunction with IDEA\nprovides a constant gap with expected O(log log n) rounds.\n\n12\n\n\fReferences\n[1] M. Adler, S. Chakrabarti, M. Mitzenmacher, and L. Rasmussen. Parallel Randomized Load Balancing. In STOC,\npages 238\u2013247, 1995.\n[2] Y. Azar, A. Z. Broder, A. R. Karlin, and E. Upfal. Balanced Allocations. SIAM J. of Computing, 29(1):180\u2013200,\n1999.\n[3] P. Berenbrink, A. Czumaj, A. Steger, and B. V\u00f6cking. Balanced Allocations: The Heavily Loaded Case. SIAM\nJ. of Computing, 35(6):1350\u20131385, 2006.\n[4] P. Berenbrink, F. Meyer auf der Heide, and K. Schr\u00f6der. Allocating Weighted Jobs in Parallel. Theor. Comput.\nSyst., 32:361\u2013386, 1999.\n[5] A. Broder and M. Mitzenmacher. Multidimensional Balanced Allocations. In SODA, pages 195\u2013196, 2005.\n[6] E. Cohen, N. Duffield, H. Kaplan, C. Lund, and M. Thorup. Stream sampling for variance-optimal estimation of\nsubset sums. In SODA, pages 1255\u20131264, 2009.\n[7] R. Cole, B. Maggs, F. M. auf der Heide, M. Mitzenmacher, A. Richa, K. Schroder, R. Sitaraman, and B. Vocking.\nRandomized protocols for low congestion circuit routing in multi-stage interconnection networks. In Thirteith\nAnnual Symposium ACM symposium on the Theory of Computing, pages 378 \u2013 388, May 1998.\n[8] A. Czumaj, C. Riley, and C. Scheideler. Perfectly Balanced Allocations. In Workshop on Randomization and\nApproximation Techniques in Computer Science, pages 240\u2013251, 2003.\n[9] D. Dubhashi and D. Ranjan. Balls and Bins: A Study in Negative Dependencies. Random Structures and\nAlgorithms, 13:99\u2013124, 1996.\n[10] N. Duffield, C. Lund, and M. Thorup. Learn more, sample less: Control of volume and variance in network\nmeasurement. IEEE TRANSACTIONS IN INFORMATION THEORY, 51:1756\u20131775, 2005.\n[11] P. B. Godfrey. Balls and Bins with Structure: Balanced Allocations on Hypergraphs. In SODA, 2008.\n[12] G. H. Gonnet. Expected Length of the Longest Probe Sequence in Hash Code Searching. J. of ACM, 28(2):289\u2013\n304, 1981.\n[13] R. M. Karp. Random graphs, random walks, differential equations and the probabilistic analysis of algorithms.\nIn STACS, pages 1\u20132, 1998.\n[14] C. Lenzen and R. Wattenhofer. Tight Bounds for Parallel Randomized Load Balancing. In STOC, 2001.\n[15] P. Li, K. W. Church, and T. J. Hastie. A sketch-based sampling algorithm on sparse data, 2006.\n[16] M. Mitzenmacher. The Power of Two Choices in Randomized Load Balancing. PhD thesis, University of\nCalifornia at Berkeley, 1996.\n[17] Y. Peres, K. Talwar, and U. Wieder. The (1+\u03b2)-choice process and weighted balls-into-bins. In SODA, pages\n1613\u20131619, 2010.\n[18] F. Rusu and A. Dobra. Sketching sampled data streams. In ICDE, pages 381\u2013392, 2009.\n[19] P. Sanders, S. Egner, and J. Korst. Fast concurrent access to parallel disks. Algorithmica, 35(1):21\u201355, 2003.\n[20] K. Talwar and U. Wieder. Balanced allocations: The Weighted Case. In Proceedings of the thirty-ninth annual\nACM symposium on Theory of computing, STOC '07, pages 256\u2013265, New York, NY, USA, 2007. ACM.\n[21] J. S. Vitter. Random sampling with a reservoir. ACM Trans. Math. Softw., 11(1):37\u201357, 1985.\n[22] B. Vocking. How asymmetry helps load balancing. In FOCS, pages 131 \u2013 141, 1999.\n\n13\n\n\fA\n\nSampling\n\nAllocation of balls-into-bins for a single choice procedure has a Poisson distribution approximately. We\nleverage this fact for the d choice scenario to show that the sampling done by the IDEA algorithm fairly\naccurately updates the estimated average of the bins w.h.p.\nLet \u03bb be the mean of the number of times a bin is chosen. Hence \u03bb = md\nn . Also assume the sample size\nto be N . Define X to be the sum of the number of times the sampled bins to have been chosen. Since the\nnumber of times a bin is chosen is a random variable that follows Poisson's distribution (for a single choice\nprocess) and the choices of the bins are independent Poisson distributions each with mean \u03bb = dm/n, the\ncharacteristics of the sample of size N , also follows a Poisson distribution with mean N \u03bb. We would like X\nto be bounded in the region [ N\u03b2\u03bb , \u03b2N \u03bb] w.h.p., where \u03b2 is arbitrarily close to 1. Applying Chernoff's bound\nwe have,\nP(\n\nN\u03bb\nN\u03bb\n\u2264 X \u2264 N \u03bb\u03b2) = 1 \u2212 (P (X \u2264\n) + P (X \u2265 N \u03bb\u03b2))\n\u03b2\n\u03b2\n\n(10)\n\nGiven Poisson's tail bound,\nP (X \u2265 N \u03bb\u03b2) \u2264\n\nSubstituting \u03b2 = 1 +\n\n1\n2\u03c9\n\ne\u2212N \u03bb (\u03bbe)N \u03bb\u03b2\n(N \u03bb\u03b2)N \u03bb\u03b2\n\neN \u03bb(\u03b2\u22121)\n=\n=\n\u03b2 N \u03bb\u03b2\n\n\u0012\n\ne\u03b2\u22121\n\u03b2\u03b2\n\nfor some large \u03c9 > 1, Eq. (11) becomes equal to\n\n\u0013N \u03bb\n1\ne 2\u03c9\n\n(11)\n!N \u03bb\n\n. Approxi1+ 1\n(1+ 21\u03c9 ) 2\u03c9\nmating ex to be less than 1 + x + x2 for small values of x, we observe that the above fraction is less than 1.\nReplacing the fraction with \u03b11 , where \u03b1 > 1 and substituting it in Eq. (11) with the expected value of \u03bb, we\nhave,\n\u0012 \u0013N. md\nn\n1\nP (X \u2265 N \u03bb\u03b2) \u2264\n\u03b1\n\n(12)\n\nFor m > n log n, Eq. (12) becomes\nP (X \u2265 N \u03bb\u03b2) \u2264\n\n\u0012\n\n1\n\u03b1log n\n\n\u0013N d\n\n=\u0012\n\n1\n\u03b1\n\n\u0013N d \u2248\nn\n\nlog \u03b1\nlog \u03b1 e\n\n1\nnN d+c\n\n[where c is a constant]\n\nHence, we observe that a constant number of samples suffices to guarantee high probability for bounding X\nwithin the factor of \u03b2 when m > n log n. However when m < n log n, we need N = log n samples for the\nsame guarantee to hold. Similar results can thus be obtained for P (X \u2264 N\u03b2\u03bb ). Hence Eq. (10) becomes,\nP(\n\nN\u03bb\nN\u03bb\n2\n\u2264 X \u2264 N \u03bb\u03b2) = 1 \u2212 (P (X \u2264\n) + P (X \u2265 N \u03bb\u03b2)) \u2265 1 \u2212\n\u03b2\n\u03b2\nn\n\nTherefore, IDEA needs to sample constant or log n bins for the cases m < n log n or m > n log n\nrespectively, for efficiently and accurately updating the estimated average of each bin to be close to that of\nthe actual average of the system w.h.p.\nWe also calculate the total number of samplings (amount of communication) done by the IDEA algorithm in the case m < n log n. On arrival of n balls, the expected number of times a bin is chosen is given\nby d. However, this is bounded by d log n w.h.p. A bin will sample N other bins only when it is chosen\n14\n\n\fmore than d times when n balls have been thrown. Using the Poisson's tail bound, in the general case when\nnk balls have been thrown (k \u2208 [1.. log n]) the probability of a bin being chosen \u03b2\u03bb times (\u03b2 > 1) is given\nby Pr(k) =\n\ne\u2212\u03bbk (\u03bbk e)\u03b2\u03bbk\n,\n(\u03b2\u03bbk )\u03b2\u03bbk\n\nwhere \u03bbk is the expected number of times a bin is chosen when nk balls have been\n\nthrown. Hence, the expected number of total samplings, E[Samples] done when total n log n balls have\nbeen thrown is given by,\nE[Samples] =\n\nlog\nXn\n\nnd P r(k) < nd\n\n[By algebraic manipulations]\n\nk=1\n\nSince, d is a constant, the expected number of samplings done by IDEA is O(n) and the total communication\ndone by IDEA is less than that in the naive case when d = log n.\n\nB Theoretical Framework for the Weighted Case\nIn this section, we provide a theoretical proof of the constant gap performance of the weighted version of\nthe IDEA algorithm. We follow the same proof sketch as in the case of ball with unit weight. Further, we\ntoo assume here m balls and n bins, m \u226b n.\nLemma 8. If each weighted ball chooses d bins i.u.r. out of n bins, each bin is chosen by\nexpectation, and by at most md\nn log n weighted balls with high probability.\n\nmd\nn\n\nballs on\n\nProof. Similar to Proof of Lemma 1.\nLemma 9. At any iteration, the estimated average of each bin is approximately equal to the current average\nw.h.p.\nProof. We assume here that Z balls have already arrived and have been placed among the n bins. The\nnumber of balls that chose bin B among its d candidates is Zd\nn on expectation, since each bin can be chosen\nd\nby a ball with a probability of n . The number of such balls is also bounded by (1 + log n) Zd\nn with high\nprobability (by Lemma 1). However, a bin does not increment its estimated average by more than d times\nwhen n balls are thrown. For each selection of bin B, it increases its estimated average by W\nd , which is\nW \u2217 \u2212k\nW\nW \u2217 +k\n\u02c6\nbounded by d \u2264 d \u2264 d . Hence the current value of AB is given by,\nZd W \u2217 \u00b1 k\nZ (W \u2217 \u00b1 k)\nA\u02c6B =\n*\n=\n, which is the current average.\nn\nd\nn\n\nHence, the estimated average \u00c2 of any bin is nearly equal to the actual average w.h.p.\n\u02c6 over all the bins is zero.\nLemma 10. The amortized sum of the estimated gap, Gap\nProof. Each ball chooses d candidate bins uniformly and randomly and is finally allocated to the bin having\nthe lowest estimated gap. Hence for all the d chosen bins, their estimated average increases by W/d. The\nload of d \u2212 1 bins which do not receive the ball remains same, and thus their estimated gap decreases by\nthe above factor. However, \u0001for the bin in which the ball is placed, its load increases by 1 and its estimated\ngap increases by W 1 \u2212 d1 . Applying the arguments presented in the proof of Lemma 3 and Cor. 1,\u0001we\nobserve that the sum of change of the estimated gap over the d chosen bins in any iteration is W 1 \u2212 d1 +\n(d \u2212 1) \u2212W\nd = 0. Using similar analysis applied in the proof of Lemma 3 it can be shown that the sum of\nthe estimated gap is zero by amortized analysis.\n\n15\n\n\fCorollary 4. The sum of the estimated gap over all bins is zero for arbitrary small number of balls allocated\nin the system.\nProof. Similar to Proof of Corollary 1.\n\u02c6 is \u0398(n).\nLemma 11. The number of bins having a zero or negative estimated gap, Gap\nProof. Using the arguments presented in the above lemmas, we provide a sketch of the proof below similar\n\u02c6 \u03b2 bins with negative estimated gap, and \u03b8 bins\nto that of Lemma 4. Let there be \u03b1 bins with positive Gap,\nhaving 0 estimated gap. Hence, \u03b1+\u03b2+\u03b8 = n. We would like to establish a lower bound on \u03b2+\u03b8. In order to\n\u02c6 the value of the gap should be minimum for bins\nhave minimum number of bins with negative or zero Gap,\nwith a positive gap and maximum for bins with a negative gap. The minimum positive estimated gap for a\n\u0001\nPZ(d\u22121)\nbin is ZWmin \u2212 d1 i=1\nWi \u2248 Z(W \u2217 \u00b1 k) 1 \u2212 d\u22121\nwhen Z(d \u2212 1) balls have arrived in the system, of\nd\nwhich only Z balls have been committed into the bin. We have Wmin = min{W1 , W2 , . . . , WZ(d\u22121) }. The\nmaximum negative estimated average that a bin may have in this case is \u2212\nHence,\n\u03b1.(Z(W \u2217 \u00b1 k)(1 \u2212\n\nZ(W \u2217 \u00b1 k)(d \u2212 1)\nd\u22121\n)) + \u03b2.(\u2212\n) + \u03b8.0 = 0\nd\nd\n\nPZ(d\u22121)\ni=1\n\nd\n\nWi\n\n\u2248 \u2212 Z(d\u22121)(W\nd\n\n\u2217 \u00b1k)\n\n.\n\n[From Lemma 3]\n\n\u2234 \u03b1 = \u03b2(d \u2212 1)\n\n\u02c6 is \u0398(n).\nFurther, \u03b1 + \u03b2 + \u03b8 = n. Hence, d\u03b2 + \u03b8 = n. So, the number of bins with zero or negative Gap\nArguing similarly in the lines of Corollary 1, we can claim that the gap is still \u0398(n) even when each\nround has f (n) = n\u01eb balls, where f (n) is not a constant.\nLemma 12. Each ball chooses at least one bin having negative estimated gap among its d choices w.h.p. in\n\u03b3 rounds.\nProof. Similar to Proof of Lemma 5.\nLemma 13. The expected number of rounds, \u03b3 per ball to find a bin with zero or negative estimated gap is\nconstant.\nProof. Similar to Proof of Lemma 6.\nLemma 14. The load of each bin tends to its estimated average.\nProof. Similar to Proof of Lemma 7.\n\n16\n\n\f"}