{"id": "http://arxiv.org/abs/1203.3478v1", "guidislink": true, "updated": "2012-03-15T11:17:56Z", "updated_parsed": [2012, 3, 15, 11, 17, 56, 3, 75, 0], "published": "2012-03-15T11:17:56Z", "published_parsed": [2012, 3, 15, 11, 17, 56, 3, 75, 0], "title": "Playing games against nature: optimal policies for renewable resource\n  allocation", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1203.2477%2C1203.5578%2C1203.1061%2C1203.3433%2C1203.2888%2C1203.2094%2C1203.5685%2C1203.1842%2C1203.3836%2C1203.2521%2C1203.6613%2C1203.3895%2C1203.4856%2C1203.1878%2C1203.5424%2C1203.0330%2C1203.4926%2C1203.4012%2C1203.6815%2C1203.6304%2C1203.4299%2C1203.6442%2C1203.6233%2C1203.3256%2C1203.1844%2C1203.5694%2C1203.6601%2C1203.2357%2C1203.1744%2C1203.4798%2C1203.4189%2C1203.3426%2C1203.6741%2C1203.1605%2C1203.1204%2C1203.5845%2C1203.2942%2C1203.0486%2C1203.1600%2C1203.0899%2C1203.5375%2C1203.5931%2C1203.2339%2C1203.5091%2C1203.0847%2C1203.2318%2C1203.1607%2C1203.0880%2C1203.0935%2C1203.5464%2C1203.0358%2C1203.1250%2C1203.4922%2C1203.1671%2C1203.3774%2C1203.3551%2C1203.6901%2C1203.5803%2C1203.2964%2C1203.3338%2C1203.6054%2C1203.2965%2C1203.4208%2C1203.5158%2C1203.3567%2C1203.0438%2C1203.2209%2C1203.4370%2C1203.4753%2C1203.3695%2C1203.0576%2C1203.3529%2C1203.1714%2C1203.0052%2C1203.5023%2C1203.4970%2C1203.2245%2C1203.4215%2C1203.5411%2C1203.2622%2C1203.3678%2C1203.5052%2C1203.3888%2C1203.3887%2C1203.1212%2C1203.0070%2C1203.1590%2C1203.5580%2C1203.5810%2C1203.4703%2C1203.3049%2C1203.4348%2C1203.4507%2C1203.3478%2C1203.6024%2C1203.5604%2C1203.5941%2C1203.6760%2C1203.6467%2C1203.3082%2C1203.6311&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Playing games against nature: optimal policies for renewable resource\n  allocation"}, "summary": "In this paper we introduce a class of Markov decision processes that arise as\na natural model for many renewable resource allocation problems. Upon extending\nresults from the inventory control literature, we prove that they admit a\nclosed form solution and we show how to exploit this structure to speed up its\ncomputation. We consider the application of the proposed framework to several\nproblems arising in very different domains, and as part of the ongoing effort\nin the emerging field of Computational Sustainability we discuss in detail its\napplication to the Northern Pacific Halibut marine fishery. Our approach is\napplied to a model based on real world data, obtaining a policy with a\nguaranteed lower bound on the utility function that is structurally very\ndifferent from the one currently employed.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1203.2477%2C1203.5578%2C1203.1061%2C1203.3433%2C1203.2888%2C1203.2094%2C1203.5685%2C1203.1842%2C1203.3836%2C1203.2521%2C1203.6613%2C1203.3895%2C1203.4856%2C1203.1878%2C1203.5424%2C1203.0330%2C1203.4926%2C1203.4012%2C1203.6815%2C1203.6304%2C1203.4299%2C1203.6442%2C1203.6233%2C1203.3256%2C1203.1844%2C1203.5694%2C1203.6601%2C1203.2357%2C1203.1744%2C1203.4798%2C1203.4189%2C1203.3426%2C1203.6741%2C1203.1605%2C1203.1204%2C1203.5845%2C1203.2942%2C1203.0486%2C1203.1600%2C1203.0899%2C1203.5375%2C1203.5931%2C1203.2339%2C1203.5091%2C1203.0847%2C1203.2318%2C1203.1607%2C1203.0880%2C1203.0935%2C1203.5464%2C1203.0358%2C1203.1250%2C1203.4922%2C1203.1671%2C1203.3774%2C1203.3551%2C1203.6901%2C1203.5803%2C1203.2964%2C1203.3338%2C1203.6054%2C1203.2965%2C1203.4208%2C1203.5158%2C1203.3567%2C1203.0438%2C1203.2209%2C1203.4370%2C1203.4753%2C1203.3695%2C1203.0576%2C1203.3529%2C1203.1714%2C1203.0052%2C1203.5023%2C1203.4970%2C1203.2245%2C1203.4215%2C1203.5411%2C1203.2622%2C1203.3678%2C1203.5052%2C1203.3888%2C1203.3887%2C1203.1212%2C1203.0070%2C1203.1590%2C1203.5580%2C1203.5810%2C1203.4703%2C1203.3049%2C1203.4348%2C1203.4507%2C1203.3478%2C1203.6024%2C1203.5604%2C1203.5941%2C1203.6760%2C1203.6467%2C1203.3082%2C1203.6311&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this paper we introduce a class of Markov decision processes that arise as\na natural model for many renewable resource allocation problems. Upon extending\nresults from the inventory control literature, we prove that they admit a\nclosed form solution and we show how to exploit this structure to speed up its\ncomputation. We consider the application of the proposed framework to several\nproblems arising in very different domains, and as part of the ongoing effort\nin the emerging field of Computational Sustainability we discuss in detail its\napplication to the Northern Pacific Halibut marine fishery. Our approach is\napplied to a model based on real world data, obtaining a policy with a\nguaranteed lower bound on the utility function that is structurally very\ndifferent from the one currently employed."}, "authors": ["Stefano Ermon", "Jon Conrad", "Carla P. Gomes", "Bart Selman"], "author_detail": {"name": "Bart Selman"}, "author": "Bart Selman", "arxiv_comment": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)", "links": [{"href": "http://arxiv.org/abs/1203.3478v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1203.3478v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1203.3478v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1203.3478v1", "journal_reference": null, "doi": null, "fulltext": "Playing games against nature:\noptimal policies for renewable resource allocation\n\nStefano Ermon\nDepartment of Computer Science\nCornell University\nermonste@cs.cornell.edu\n\nJon Conrad\nDepartment of Applied Economics\nCornell University\njmc16@cornell.edu\n\nAbstract\nIn this paper we introduce a class of Markov decision processes that arise as a natural model for\nmany renewable resource allocation problems.\nUpon extending results from the inventory control literature, we prove that they admit a closed\nform solution and we show how to exploit this\nstructure to speed up its computation.\nWe consider the application of the proposed\nframework to several problems arising in very\ndifferent domains, and as part of the ongoing effort in the emerging field of Computational Sustainability we discuss in detail its application to\nthe Northern Pacific Halibut marine fishery. Our\napproach is applied to a model based on real\nworld data, obtaining a policy with a guaranteed\nlower bound on the utility function that is structurally very different from the one currently employed.\n\n1\n\nIntroduction\n\nThe problem of devising policies to optimally allocate resources over time is a fundamental decision theoretic problem with applications arising in many different fields. In\nfact, such decisions may involve a variety of different resources such as time, energy, natural and financial resources, in allocation problems arising in domains as diverse as natural resources management, crowdsourcing,\nsupply chain management, QoS and routing in networks,\nvaccine distribution and pollution management.\nA particularly interesting class of such problems involves\npolicies for the allocation of renewable resources. A key\nand unique aspect of such a resource type is the fact that, by\ndefinition, its stock is constantly replenished by an intrinsic\ngrowth process. The most common example are perhaps\nliving resources, such as fish populations or forests, that increase constantly by natural growth and reproduction, but\nless conventional resources such as users in a social com-\n\nCarla Gomes, Bart Selman\nDepartment of Computer Science\nCornell University\n{gomes,selman}@cs.cornell.edu\n\nmunity or in a crowdsourcing project share the same intrinsic growth feature due to social interactions.\nA common feature of the growth processes presented is that\nthey are density dependent, in the sense that the growth\nrate depends on the amount of resource available. This fact\ncreates a challenging management problem when the aim\nof the intervention is to optimally use the resource, for instance by harvesting a fish population or by requiring some\neffort from a crowdsourcing community, especially when\neconomic aspects are factored in. We face a similar challenge in vaccine distribution problems, where the growth\nrate of infections is again density dependent and the objective is to reduce its spreading.\nThis study, in particular, has been motivated by the alarming consideration that many natural resources are endangered due to over-exploitation and generally poorly managed. For instance, the Food and Agricultural Organization\nestimates in their most recent report that 7% of marine fish\nstocks are already depleted, 1% are recovering from depletion, 52% are fully exploited and 17% are overexploited\n([1]).\nOne of the most fundamental aspects of the problem seems\nto be the lack of an effective way to handle the uncertainty\naffecting the complex dynamics involved. While in most of\nthe works in the literature [6, 7] these growth processes are\nmodeled with deterministic first-order difference or differential equations, this approach often represents an oversimplification. In fact their intrinsic growth is often affected\nby many variables and unpredictable factors. For example,\nin the case of animal populations such as fisheries, both\nweather and climate conditions are known to affect both\nthe growth and the mortality in the population. Other variable ecological factors such as the availability of food or\nthe interaction with other species also influence their natural dynamics to the point that it is very difficult even to\nobtain reliable mathematical models to describe their dynamics.\nOn the other hand, stochastic differential equations can easily incorporate these variable factors and therefore represent a more robust description. However, obtaining a prob-\n\n\fabilistic description of such systems is far from easy. In\nfact, even if in principle uncertainty could be reduced by\ncollecting and analyzing more data, it is generally believed\nthat complex and stochastic systems, such a marine environments, could never become predictable (to the point\nthat the authors of [13] believe that \"predictability of anything as complex as marine ecosystem will forever remain\na chimera\").\nMoreover, there are situations of \"radical uncertainty\" ([8])\nor ambiguity where a stochastic description is not feasible\nbecause the probabilities are not quantifiable. For instance,\nmany fundamental environmental issues that we are facing, such as those surrounding the climate change debate,\ninvolve ambiguity in the sense of scientific controversies or\nirreducible beliefs that cannot be resolved.\nIn the context of stochastic optimization, there are two\nmain ways to deal with uncertainty. The first one involves\na risk management approach, where it is assumed that the\nprobabilities of the stochastic events are known a priori or\nare learned from experience through statistical data analysis. Within this framework, decisions are taken according\nto stochastic control methods. Using tools such as risksensitive Markov decision processes ([12, 15]), it is also\npossible to encode into the problem the attitude towards\nrisk of the decision maker by using an appropriate utility\nfunction. In particular the degree of risk aversion can be\ncontrolled by sufficiently penalizing undesirable outcomes\nwith the utility function. When a fine grained stochastic description is not available, worst-case game theoretic frameworks, that are inherently risk averse, play a fundamental role because it is often crucial to devise policies that\navoid catastrophic depletion. This type of approach, where\nthe problem of data uncertainty is addressed by guaranteeing the optimality of the solution for the worst realizations\nof the parameters, is also known in the literature as robust\noptimization ([3, 5]), and has been successfully applied to\nuncertain linear, conic quadratic and semidefinite programming.\nIn this paper, we present a class of Markov decision processes that arise as a natural model for many resource management problems. Instead of formulating the optimization problem in a traditional form as a maximization of an\nexpected utility, we tackle the management problems in a\ngame theoretic framework, where the optimization problem\nis equivalent to a dynamic game against nature. This formulation is a particular type of Markov game [14] (sometimes called a stochastic game [16]) where there are only\ntwo agents (the manager and nature) and they have diametrically opposed goals.\nAs mentioned before, although this formulation is more\nconservative, it also eliminates the very difficult task of estimating the probabilities of the stochastic events affecting\nthe system. In a context where the emphasis in the literature has traditionally been on the study of expected utilities,\n\nthis approach represents a new perspective. Moreover, the\npolicies thus obtained provide a lower bound on the utility\nthat can be guaranteed to be achieved, no matter the outcomes of the stochastic events. For this class of problems,\nwe are able to completely characterize the optimal policy\nwith a theoretical analysis that extends results from the inventory control literature, obtaining a closed form solution\nfor the optimal policy.\nAs part of the new exciting research area of Computational\nSustainability ([10]), where techniques from computer science and related fields are applied to solve the pressing sustainability challenges of our time, we present an application\nof the proposed framework to the Northern Pacific Halibut\nfishery, one of the largest and most lucrative fisheries of the\nNorthwestern coast. In particular, our method suggests the\nuse of a cyclic scheme that involves periodic closures of the\nfishery, a policy that is structurally different from the one\nusually employed, that instead tries to maintain the stock\nat a given size with appropriate yearly harvests. However,\nthis framework is interesting in its own right and, as briefly\nmentioned before, it applies to a variety of other problems\nthat share a similar mathematical structure and that arise\nin very different domains. For example, we can apply our\nframework to pollution problems, where a stock of pollutants is evolving over time due to human action, and the\nobjective is to minimize the total costs deriving from the\npresence of a certain stock of pollutants and the costs incurred with cleanups, but also to crowdsourcing and other\nproblems.\n\n2\n\nMDP Formulation\n\nIn this section, we will formulate the optimization problem\nas discrete time, continuous space Markov decision process. Whenever possible, we will use a notation consistent\nwith the one used in [4]. Even if we will consider only a\nfinite horizon problem, the results can be extended to the\ninfinite horizon case with limiting arguments. To make the\ndescription concrete, the model will be mostly described\nhaving a natural resource management problem in mind.\nWe consider a dynamical system evolving over time according to\nxn+1 = f (xn \u2212 hn , wn ),\n(1)\nwhere xn \u2208 R denotes the stock of a renewable resource\nat time n. By using a discrete time model we implicitly assume that replacement or birth processes occur in regular,\nwell defined \"breeding seasons\", where f (*) is a reproduction function that maps the stock level at the end of one\nseason to the new stock level level at the beginning of the\nnext season. The control or decision variable at year n is\nthe harvest level hn (occurring between two consecutive\nbreeding seasons), that must satisfy 0 \u2264 hn \u2264 xn .\nAs mentioned in the introduction, the function f (*) cap-\n\n\ftures the intrinsic replenishment ability of renewable resources, that in many practical applications (such as fisheries or forestry) is density dependent: growth rate is high\nwhen the habitat is underutilized but it decreases when\nthe stock is larger and intraspecific competition intensifies.\nSpecific properties of reproduction functions f (*) will be\ndiscussed in detail later, but we will always assume that\nthere is a finite maximum stock level denoted by m.\nTo compensate for the higher level description of the complex biological process we are modeling, we introduce uncertainty into the model through wn , a random variable that\nmight capture, for example, the temperature of the water,\nan uncontrollable factor that influences the growth of the\nresource. Given the worst case framework we are considering, we will never make assumptions on the probability distribution of wn but only on its support (or, in other words,\non the possible outcomes). In fact in an adversarial setting\nit is sufficient to consider all possible scenarios, each one\ncorresponding to an action that nature can take against the\npolicy maker, without assigning them a weight in a probabilistic sense.\nGiven the presence of stochasticity, it is convenient to consider closed loop optimization approaches, where decisions\nare made in stages and the manager is allowed to gather information about the system between stages. In particular,\nwe assume that the state of the system xn \u2208 R is completely observable. For example, in the context of fisheries\nthis means that we assume to know exactly the level of the\nstock xn when the harvest level hn is to be chosen. In\nthis context, a policy is a sequence of rules used to select\nat each period a harvest level for each possible stock size.\nIn particular, an admissible policy \u03c0 = {\u03bc1 , . . . , \u03bcN } is a\nsequence of functions, each one mapping stocks sizes x to\nharvests h, so that for all x and for all i\n0 \u2264 \u03bci (x) \u2264 x.\n\n(2)\n\nWe assume that the marginal harvesting cost g(x) increases\nas the stock size x decreases. We include time preference\ninto the model by considering a fixed discount factor \u03b1 =\n1/(1 + \u03b4) ( 0 \u2264 \u03b1 \u2264 1), where \u03b4 > 0 is a discount rate.\nFor any given horizon length N , we consider the problem\nof finding an admissible policy \u03c0 = {\u03bci }i\u2208[1,N ] that maximizes\n\u03c0\n(x) =\nCN\n\nmin\nw1 , . . . , wN\nwi \u2208 W (xi )\n\nN\nX\n\n\u03b1n (R(xn ) \u2212 R(xn \u2212 hn ) \u2212 K\u03b40 (hn ))\n\nn=1\n\nwhere xn is subject to (1) and hn = \u03bcn (xn ), with initial\ncondition x1 = x and\n\u001a\n1 if x > 0,\n\u03b40 (x) =\n0 otherwise.\nThis is a Max-Min formulation of the optimization problem, where the goal is to optimize the utility in a worst-case\nscenario. As opposed to the maximization of an expected\nutility ([17, 18]), this formulation is inherently risk averse.\nAn advantage of this formulation is that there is no need to\ncharacterize the probability distribution of the random variables wk explicitly, but only to determine their support. In\nfact, one should consider all the possible scenarios, without\nworrying about the probabilities of their occurrence.\n\n3\n\nMain Results\n\n3.1\n\nMinimax Dynamic Programming\n\n\u03c0\nA policy \u03c0 is called an optimal N -period policy if CN\n(x)\nattains its supremum over all admissible policies at \u03c0 for\nall x. We call\n\u03c0\nCN (x) = sup CN\n(x),\n\n2.1\n\n\u03c0\u2208\u03a0\n\nResource Economics\n\nWe now consider the economic aspects of the model. We\nsuppose that the revenue obtained from a harvest h is proportional to h through a fixed price p, and that harvesting\nis costly. In particular we assume that there is\n\nthe optimal value function, where \u03a0 represents the set of\nall admissible policies.\nAs a consequence of the principle of optimality([4]), the\ndynamic programming equation for this problem reads:\nC0 (x)\nCn (x)\n\n\u2022 a fixed set-up cost K each time a harvest is undertaken\n\u2022 a marginal harvest cost g(x) per unit harvested when\nthe stock size is x\nIt follows that the utility derived from a harvest h from an\ninitial stock x is\nZ x\ng(y)dy \u2212 K , R(x) \u2212 R(x \u2212 h) \u2212 K, (3)\nph \u2212\n\nR(x) = px \u2212\n\nZ\n\nx\n\ng(y)dy.\n0\n\n0,\nmax\n\nmin R(xn ) \u2212 R(xn \u2212 hn )\n\n0\u2264hn \u2264x wn \u2208W\n\n\u2212K\u03b40 (hn ) + \u03b1Cn\u22121 (f (x \u2212 hn , wn ))\nfor all n > 0. The latter equation can be rewritten in terms\nof the remaining stock z = x \u2212 hn (the post decision state)\nas\n\nx\u2212h\n\nwhere\n\n=\n=\n\n\u0012\n\nCn (x) = \u03b1 max\n0\u2264z\u2264x\n\u0013\nR(x) \u2212 R(z) \u2212 K\u03b40 (x \u2212 z) + min Cn\u22121 (f (z, wn )) .\nwn \u2208W\n\n(4)\n\n\fThis formulation of the problem is effectively analogous\nto a game against nature in the context of a two-person\nzero-sum game. The objective is in fact devising the value\nof z that maximizes the utility, but assuming that nature\nis actively playing against the manager with the opposite\nintention.\nIt can be shown (see [4]) that Cn (x), the revenue function\nassociated with an optimal policy, is the (unique) solution\nto equation (4). From equation (4) we see that an optimal\npolicy, when there are n periods left and the stock level is\nx, undertakes a harvest if and only if there exists 0 \u2264 z \u2264 x\nsuch that\n\n\u2022 If \u03b2(*) is nondecreasing and concave on I\nand \u03c8(*) is nondecreasing and K-concave on\n[inf x\u2208I \u03b2(x), supx\u2208I \u03b2(x)] then the composition\n\u03c8 \u25e6 \u03b2 is K-concave on I.\n\u2022 Let \u03b21 (x), . . . , \u03b2N (x) be a family of functions such\nthat \u03b2i (x) is Ki -concave. Then \u03b3(x) = mini \u03b2i (x) is\n(maxi Ki )-concave.\n\u2022 If \u03b2(*) is a continuous, K-concave function on the interval [0, m], then there exists scalars 0 \u2264 S \u2264 s \u2264 m\nsuch that\n\u2013 \u03b2(S) \u2265 \u03b2(q) for all q \u2208 [0, m].\n\u2013 Either s = m and \u03b2(S) \u2212 K \u2264 \u03b2(m) or s < m\nand \u03b2(S) \u2212 K = \u03b2(s) \u2265 \u03b2(q) for all q \u2208 [s, m).\n\u2013 \u03b2(*) is a decreasing function on [s, m].\n\u2013 For all x \u2264 y \u2264 s, \u03b2(x) \u2212 K \u2264 \u03b2(y).\n\nR(x) \u2212 R(z) \u2212 K + \u03b1 min Cn\u22121 (f (z, wn )) >\nwn \u2208W\n\n\u03b1 min Cn\u22121 (f (x, wn )).\nwn \u2208W\n\nIn fact, an action should be taken if and only if its associated benefits are sufficient to compensate the fixed cost\nincurred. By defining\n(5)\n\nThe proof is not reported here for space reasons, but can\nbe found in [9]. Similar results for K-convex functions are\nproved in [4].\n\nwe have that an optimal policy, when there are n periods\nleft and the stock level is x, undertakes a harvest if and\nonly if there exists 0 \u2264 z \u2264 x such that\n\nIn the following section we will prove by induction the Kconcavity of the functions Pn (x), n = 1, . . . , N . This will\nallow us to characterize the structure of the optimal policy\nby using the last assertion of Lemma 1.\n\nPn (x) = \u2212R(x) + \u03b1 min Cn\u22121 (f (x, wn )),\nwn \u2208W\n\nPn (z) \u2212 K > Pn (x).\n\n(6)\n\nTo examine this kind of relationship it is useful to introduce\nthe notion of K-concavity, a natural extension of the Kconvexity property originally introduced by Scarf in [19]\nto study inventory control problems.\n3.2\n\nPreliminaries on K-concavity\n\nA function \u03b2(*) is K-concave if given three points x < y <\nz, \u03b2(y) exceeds the secant approximation to \u03b2(y) obtained\nusing the points \u03b2(x) \u2212 K and \u03b2(z). Therefore for K = 0\nno slack is allowed and one recovers the standard definition\nof concavity. Formally\nDefinition 1. A real valued function \u03b2(*) is K-concave if\nfor all x, y, x < y, and for all b > 0\n\u03b2(x) \u2212 \u03b2(y) \u2212 (x \u2212 y)\n\n\u03b2(y + b) \u2212 \u03b2(y)\n\u2264 K.\nb\n\n(7)\n\nWe state some useful results concerning K-concavity:\nLemma 1. The following properties hold:\n\u2022 A concave function is 0-concave and hence Kconcave for all K \u2265 0 .\n\u2022 If \u03b21 (q) and \u03b22 (q) are respectively K1 -concave and\nK2 -concave for constants K1 \u2265 0 and K2 \u2265 0,\nthen a\u03b21 (q) + b\u03b22 (q) is (aK1 + bK2 )-concave for any\nscalars a > 0 and b > 0.\n\n3.3\n\nOn the Optimality of (S \u2212 s) policies\n\nSuppose that we can prove that Pn (x) is continuous and\nstrictly K-concave. Then by Lemma 1 there exists Sn , sn\nwith the properties proved in the last point of the Lemma.\nIt is easy to see that condition (6) is satisfied only if x > s,\nin which case the optimal value of the remaining stock\nz would be precisely Sn . In conclusion, if we can prove\nthe continuity and K-concavity of the functions Pn (x),\nn = 1, . . . , N , then following feedback control law, known\nas a nonstationary (S \u2212 s) policy, is optimal:\nAt period n, a harvest is undertaken if and only if the\ncurrent stock level is greater than sn ; in that case the stock\nis harvested down to Sn .\nThis policy is known in the inventory control literature as a\nnonstationary (S \u2212s) policy 1 , because the levels Sn and sn\nare time dependent. Since it is assumed that the marginal\nharvest cost g(x) is a non increasing function, we define x0\nto be the zero profit level such that g(x0 ) = p. If g(x) < p\nfor all x, we define x0 = 0. As a consequence for all\nx > x0 we have that R\u2032 (x) \u2265 0 so that R (defined in\nequation (3)) is non decreasing. Moreover if the marginal\nharvest cost g(x) is a non increasing function, then R is\nconvex.\n1\nFor the sake of consistency, we call sn the threshold value\nthat governs the decision, even if in our case Sn \u2264 sn .\n\n\fWe also need to make an assumption on the concavity of\nR(*). In particular the marginal cost function g is allowed\nto decrease but not by too much. Let m Rbe an upper bound\nx\non the possible values of x and G(x) = 0 g(t)dt, then we\nneed\n\u0013\n\u0012\n1\u2212\u03b1\n,\n(8)\n\u03c4 = G(m) \u2212 mg(m) < K\n\u03b1\n\nnondecreasing, consider the case 0 \u2264 x1 < x2 \u2264 sn+1 :\n\n\u03b1\n\nCn+1 (x2 ) \u2212 Cn+1 (x1 ) =\n\u0013\nmin Cn (f (x2 , wn )) \u2212 min Cn (f (x1 , wn )) .\n\nwn \u2208W\n\nmin\n\nwn \u2208W (x2 )\n\nThe main result is the following theorem, where we show\nthat if some assumptions are satisfied, the optimal policy is\nof (S \u2212 s) type. The key point of this inductive proof is\nto show that the K-concavity property is preserved by the\nDynamic Programming operator.\nTheorem 1. For any setup cost K > 0 and any positive\ninteger N , if f (*, w) is nondecreasing and concave for any\nw and if g is non increasing and satisfies condition (8),\nthen the functions Pn (x) defined as in (5) are continuous\nand K-concave for all n = 1, . . . , N . Hence there exists a\nnon-stationary (S \u2212 s) policy that is optimal. The resulting optimal present value functions Cn (x) are continuous,\nnondecreasing and K-concave for all n = 1, . . . , N .\nProof. From equation (8) we know that there exists a number k such that\n(9)\n\nThe proof is by induction on N . The base case N = 0\nis trivial because C0 (x) = 0 for all x, and therefore it\nis continuous, nondecreasing and k-concave. Now we\nassume that Cn (x) is continuous, nondecreasing and kconcave, and we show that Pn+1 (x) is continuous and Kconcave, and that Cn+1 (x) is continuous, nondecreasing\nand k-concave.\nSince f (*, w) is nondecreasing and concave for all w,\nCn (f (z, wn )) is K-concave by Lemma (1). By Lemma\n1\n\nwn \u2208W\n\nIf for all x2 > x1 \u2265 0,\n\na condition that implies the \u03c4 -concavity of R.\n\n(K + \u03c4 )\u03b1 < k < K.\n\n\u0012\n\nf (x2 , wn ) \u2265\n\nmin\n\nwn \u2208W (x1 )\n\nf (x1 , wn ),\n\nthen Cn+1 (x2 ) \u2212 Cn+1 (x1 ) \u2265 0 because Cn (x) is nondecreasing. For the case sn+1 < x1 < x2 and sn+1 \u2265 x0 :\nCn+1 (x2 ) \u2212 Cn+1 (x1 ) = \u03b1(R(x2 ) \u2212 R(x1 )) \u2265 0,\nbecause R is nondecreasing on that interval. It must be the\ncase that Sn+1 > x0 because harvesting below x0 is not\nprofitable and reduces the marginal growth of the stock, so\ngiven that sn+1 \u2265 Sn+1 \u2265 x0 we conclude that Cn+1 (x)\nis nondecreasing. It remains to show that Cn+1 (x) is kconcave, and by equation (9) it is sufficient to show that it\nis (K + \u03c4 )\u03b1-concave. To show that definition (7) holds for\nCn+1 (x), we consider several cases.\nWhen x < y \u2264 sn+1 , according to equation (10) we have\nthat Cn+1 (x) = \u03b1(Pn+1 (x) + R(x)) and therefore equation (7) holds by Lemma 1 because Pn+1 is K-concave and\nR(*) is \u03c4 -concave. Similarly when sn+1 < x < y, equation (7) holds because R(*) is \u03c4 -concave.\nWhen x \u2264 sn+1 < y equation (7) reads\nCn+1 (y + b) \u2212 Cn+1 (y)\n\u2264\nCn+1 (x) \u2212 Cn+1 (y) \u2212 (x \u2212 y)\nb\n\u0013\n\u0012\nR(y + b) \u2212 R(y)\n\u2264\n\u03b1 K + R(x) \u2212 R(y) \u2212 (x \u2212 y)\nb\n\u03b1(K + \u03c4 ).\nbecause Pn+1 (x) \u2264 Pn+1 (Sn+1 ) and R(*) is \u03c4 -concave.\n\n4\n\nConsistency and Complexity\n\nmin Cn\u22121 (f (z, wn ))\n\nwn \u2208W\n\nEven if Theorem 1 completely describes the structure of the\noptimal policy, in general there is no closed form solution\nfor the values of Sn and sn , that need to be computed numerically. In order to use the standard dynamic programming approach, the state, control and disturbance spaces\nmust be discretized, for instance using an evenly spaced\ngrid. Since we are assuming that those spaces are bounded,\nwe obtain in this way discretized sets with a finite number\nof elements. We can then write DP like equations for those\n\u001a\n\u03b1(Pn+1 (x) + R(x))\nif x \u2264 sn+1 , points, using an interpolation of the value function for the\nCn+1 (x) =\n\u03b1(Pn+1 (Sn+1 ) + R(x) \u2212 K) if x > sn+1 . points that are not on the grid. The equations can be then\nsolved recursively, obtaining the semi-optimal action to be\n(10)\ntaken for each point of the grid, that can then be extended\nThe continuity of Cn+1 (x) descends from the continuby interpolation to obtain an approximate solution to the\nity of Pn+1 (x) and because by definition Pn+1 (sn+1 ) +\noriginal problem.\nR(sn+1 ) = Pn+1 (Sn+1 ) + R(sn+1 ) \u2212 K. To show it is\n\nis also K-concave. Again using Lemma 1, if \u2212R(x)\nis concave, then by equation (5) Pn+1 (x) is K-concave.\nThe continuity of Pn+1 (x) is implied by the continuity of\nCn (x) and R(x).\nGiven that Pn+1 (x) is K-concave and continuous, the optimal action is to harvest down to Sn+1 if and only if the\ncurrent stock level is greater than sn+1 , so we have\n\n\fThe standard dynamic programming algorithm involves\nO(|X||W ||U ||T |) arithmetic operations, where |X| is the\nnumber of discretized states, |W | the number of possible\noutcomes of the (discretized) uncontrollable events, |U | the\nmaximum number of possible discretized actions that can\nbe taken in any given state and T is the length of the time\nhorizon. However, the priori knowledge of the structure of\nthe optimal policy can be used to speed up the computation. In fact it is sufficient to find s (for example by bisection) and compute the optimal control associated with any\nstate larger than s to completely characterize the policy for\na given time step. The complexity of this latter algorithm\nis O(|W ||U ||T | log |X|).\n\n5\n\nCase Study: the Pacific Halibut\n\nAs part of the ongoing effort in the emerging field of Computational Sustainability, we consider an application of our\nframework to the Pacific Halibut fishery.\nThe commercial exploitation of the Pacific halibut on the\nNorthwestern coastline of North America dates back to the\nlate 1800s, and it is today one of the region's largest and\nmost profitable fisheries.The fishery developed so quickly\nthat by the early 20th century it was starting to exhibit\nsigns of overfishing. After the publication of scientific reports which demonstrated conclusively a sharp decline of\nthe stocks, governments of the U.S. and Canada signed a\ntreaty creating the International Pacific Halibut Commission (IPHC) to rationally manage the resource. The IPHC\ncommission controls the amount of fish caught annually by\ndeciding each year's total allowable catch (TAC), that is\nprecisely the decision variable hn of our optimization problem.\n5.1\n\nManagement Problem Formulation\n\nTo develop a bioeconomic model of the fishery, we have\nextracted data 2 from the IPHC annual reports on estimated\nbiomass xt , harvest ht and effort Et (measured in thousands of skate soaks) for Area 3A (one of the major regulatory areas in which waters are divided) for a 33 years period\nfrom 1975 to 2007. To model the population dynamics, we\n2\n\nData is available from the authors upon request.\n\n200\nEffort H1000 sk. soaksL , Stock H10^6 poundsL\n\nAs with all discretization schemes, we need to discuss the\nconsistency of the method. In particular, we would like\n(uniform) convergence to the solution of the original problem in the limit as the discretization becomes finer. It is\nwell known that in general this property does not hold.\nHowever in this case Theorem 1 guarantees the continuity\nof Cn , that in turn implies the consistency of the method,\neven if the policy itself is not continuous as a function of\nthe state([4]). Intuitively, discrepancies are possible only\naround the threshold sn , so that they tend to disappear as\nthe discretization becomes finer.\n\nhist. stock\n150\n\nest. stock\nhist. effort\nest. effort\n\n100\n\n50\n\n0\n1975\n\n1980\n\n1985\n\n1990\n\n1995\n\n2000\n\n2005\n\nYear\n\nFigure 1: Fitted models (11) and (13) compared to historical data (in bold).\nconsider the Beverton-Holt model that uses the following\nreproduction function\nxn+1 = f (sn ) = (1 \u2212 m)sn +\n\nr0 sn\n,\n1 + sn /M\n\n(11)\n\nwhere sn = xn \u2212hn is the stock remaining after fishing (escapement) in year n. This model can be considered as a discretization of the continuous-time logistic equation. Here,\nparameter m represents a natural mortality coefficient, r0\ncan be interpreted as a reproduction rate and M (r0 \u2212m)/m\nis the carrying capacity of the environment. The (a priori)\nmortality coefficient we use is m = 0.15, that is the current\nworking value used by the IPHC. The values of r0 and M\nare estimated by ordinary least square fitting to the historical data. Estimated values thus obtained are reported in\ntable 1, while the fitted curve is shown in figure 1.\nParameter\nq\nb\np\nK\nc\n\u03b4\nm\nM\nr0\n\nValue\n9.07979 10\u22127\n2.55465\n4, 300, 000$ / (106 pounds)\n5, 000, 000$\n200, 000$ / 1000 skate soaks\n0.05\n0.15\n196.3923 106 pounds\n0.543365\n\nTable 1: Base case parameter set.\nFollowing [18], we suppose that the system is affected by\nstochasticity in the form of seasonal shocks wn that influence only the new recruitment part\nxn+1 = f (sn , wn ) = (1 \u2212 m)sn + wn\n\nr0 sn\n. (12)\n1 + sn /M\n\n\fInstead of assuming an a priori probability distribution for\nwn or trying to learn one from data (that in our case would\nnot be feasible given current scarce data availability), we\nwill make use of the framework developed in the previous\nsections. In particular we will (a priori) assume that wn are\nrandom variables all having the same finite support that we\nwill learn from data, but we will not make any assumption\non the actual weight distribution. With our data, we obtain\nthat wn \u2208 [1 \u2212 0.11, 1 + 0.06] = Iw .\nFor the economic part of the model, we start by modeling\nthe relationship between a harvest ht that brings the population level from xt to xt \u2212 ht and the effort Et needed to\naccomplish this result. We will a priori assume that there is\na marginal effort involved, so that\n\n5.2\n\nOptimal Policy\n\nBy using the dynamic programming approach on the problem discretized with a step size of 0.25 \u00d7 106 pounds,\nwe compute the optimal policy for a management horizon of N = 33 years, that is the length of our original\ntime series. As predicted by Theorem 1, the optimal policy\n\u03c0 \u2217 = {\u03bc1 , . . . , \u03bcN } for the model we constructed for area\n3A is a non stationary (S \u2212 s) policy. In figure 2(a) we plot\nthe function \u03bc1 (*) to be used in the first year (the values of\nS1 and s1 are 133 and 176.75 respectively). In words, the\noptimal policy dictates that at period n a harvest is to be\nundertaken if and only if the current stock level is greater\nthan sn ; in that case the stock is harvested down to Sn .\nOptimal policy and escapement\n500\n\nEt =\n\nZ\n\nxt\nxt \u2212ht\n\n1\ndy\nqy b\n\nharvest\nescapement\n\n450\n\n(13)\n\n400\n\n6\n\nstock (10 pounds)\n\n350\n300\n250\n200\n150\n\nS\n\n100\n50\n0\n\ns\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\n600\n\nstock (106 pounds)\n\n(a) Optimal rule for selecting harvests in the first year.\nOptimal state and control trajectories\n200\n180\n160\n140\n\n6\n\nstock (10 pounds)\n\nfor some q and b. This is inspired by the fact that less effort is required when the stock is abundant, and can also\nbe interpreted as an integral of infinitesimal Cobb-Douglas\nproduction functions (a standard economic model for productivity) where b and g are the corresponding elasticities.\nEstimated values obtained by least squares fitting are reported in table 1, while the resulting curve is compared with\nhistorical data in figure 1.\nCosts involved in the Halibut fishery are divided into two\ncategories: fixed costs and variable costs. Fixed costs include costs that are independent of the number and the duration of the trips a vessel makes (therefore generically independent from the effort Et ). For example, vessel repairs\ncosts, license and insurance fees, mooring and dockage fees\nare typically considered fixed costs. We will denote with\nK the sum of all the fixed costs, that will be incurred if and\nonly if a harvest is undertaken.\nVariable costs include all the expenses that are dependent\non the effort level. Variable costs typically include fuel,\nmaintenance, crew wages, gear repair and replacement. We\nassume that the total variable costs are proportional to the\neffort Et (measured in skate soaks) according to a constant\nc. Parameter c is set to 200, 000$ for 1000 skate soaks\n(200$/skate) as estimated in [2]. Following the analysis of\nthe historical variable and fixed costs for the halibut fishery\ncarried on in [11], we assume K = 5, 000, 000$ for area\n3A. The unit price p for the halibut is set to 4, 300, 000$/\n106 pounds, as in [2].\nIf we further assume a fixed discount rate \u03b4 = 0.05, we\nobtain a formulation of management problem for the Halibut fishery in Area 3A that fits into the framework described in the previous section. In particular, the problem for an N years horizon is that of finding an admissible policy \u03c0 = {\u03bci }i\u2208[1,N ] that maximizes the revenue\n\u03c0\nCN\n(x) where xRn is subject to (12), hn = \u03bcn (xn ) and\nx\nR(x) = px \u2212 c 0 qy1b dy.\n\nstock\nharvest\n\n120\n100\n80\n60\n40\n20\n0\n\n0\n\n5\n\n10\n\n15\n20\ntime (years)\n\n25\n\n30\n\n35\n\n(b) Stock trajectory and corresponding optimal harvests.\n\nFigure 2: The optimal policy.\nThe trajectory of the system when it is managed using the\noptimal policy is shown in figure 2, together with the corresponding optimal harvests. As we can see, the optimal policy is pulsing, in the sense that it involves periodic closures\nof the fishery, when no harvest should be undertaken so that\n\n\fthe fish stock has time to recover. Of course, this kind of\npolicy could be acceptable in practice only in combination\nwith some rotation scheme among the different Areas, so\nthat a constant yearly production can be sustained.\n\nOptimal state and control trajectories with rolling horizon\n200\n180\n160\n140\n\nTo see the advantage of the optimal (S \u2212 s) policy, we\ncompare it with the historical harvest proportions and with\na CPP policy that uses the historical average harvest rate\na = 0.1277. Table 2 summarizes the discounted revenues\ncorresponding to an initial stock size x1 = 90.989 million\npounds, that is the estimated stock size in 1975.\nPolicy\nOptimal S \u2212 s\nHistorical rates\nAverage CPP\nRolling Horizon\n\nDisc. revenue ($)\n9.05141 \u00d7 108\n7.06866 \u00d7 108\n6.51849 \u00d7 108\n8.73605 \u00d7 108\n\nLoss ($)\n\u2212\n1.98275 \u00d7 108\n2.53292 \u00d7 108\n3.1536 \u00d7 107\n\nTable 2: Policy Comparison\nCompared to the historical policy or the CPP policy, revenues for the optimal (S \u2212 s) policy are about 35% higher,\nas reported in table 2. Notice that the comparison is done\nassuming a worst case realization of the stochasticity, or in\nother words that the nature is actively playing against the\nmanager.\nNotice that the large harvest prescribed by the optimal\n(S \u2212 s) policy in the last year is an artifact of the finite\nhorizon effect, caused by the fact that there is no reason\nnot to exhaust the resource at the end of the management\nhorizon (as long as it is profitable to harvest it). However\nit does not affect the comparison significantly due to the\ndiscount rate. In fact the (discounted) revenue for the entire last large harvest only accounts for less than 8% of the\ntotal revenue. This is confirmed by looking at the results\nobtained with a rolling horizon strategy that always picks\nthe optimal action with a 33-years long management horizon in mind. As shown in figure 3, this (suboptimal) strategy is not affected by the finite horizon effect. The rolling\nhorizon strategy still involves periodic closures of the fishery and significantly outperforms the historical policies, as\nreported in table 2.\nTo further clarify that the pulsing nature of the optimal harvests is not an artifact of the finite horizon, it is also interesting to notice that the theoretical results on the optimality of (S \u2212 s) policies and the corresponding pulsing\n\nstock (106 pounds)\n\nThis scheme is very different from the Constant Proportional Policy (CPP) that has been traditionally used to manage the Halibut fishery. In fact a CPP works by choosing\nthe yearly TAC as a fixed fraction of the current stock level\nxt , and is aimed at maintaining the exploited stock size\n(the escapement) at a given fixed level. This policy can\nbe seen as a simplified version of an (S \u2212 s) policy where\nthe two levels do not depend on the stage n and coincide,\nthus defining the target stock size.\n\nstock\nharvest\n\n120\n100\n80\n60\n40\n20\n0\n\n0\n\n5\n\n10\n\n15\n20\ntime (years)\n\n25\n\n30\n\n35\n\nFigure 3: Harvests and stock trajectory with the rolling\nhorizon strategy.\n\nharvests can be carried over to the infinite horizon case via\nlimiting arguments. The high level argument is that the optimal value function Cn (x) converges uniformly to C(x)\nas n \u2192 \u221e, while Pn (x) converges uniformly to a function\nP (x) as n \u2192 \u221e. Given that by Theorem 1 Pn (x) is continuous and K-concave for all n, we have that P (x) must be\nalso continuous and K-concave. Using an argument similar to the one developed in section 3.3 and by using Lemma\n1, one can show that there exists S and s such that the optimal stationary policy for the infinite horizon problem is an\n(S \u2212 s) policy.\n\n6\n\nConclusions\n\nIn this paper, we have analyzed the optimality of (S\u2212s) polices for a fairly general class of stochastic discrete-time resource allocation problems. When a non stationary (S \u2212 s)\npolicy is used, a harvest is undertaken at period n if and\nonly if the current stock level is greater than sn ; in that case\nthe stock is harvested down to Sn . The framework developed is quite general and can be applied to problems arising\nin very different domains, such as natural resource management, crowdsourcing, pollution management. When assumptions of Theorem 1 are met, we have shown that there\nexists a non stationary (S \u2212 s) policy that maximizes the\nutility in a worst case scenario.\nA fundamental advantage of the game theoretic approach\nis that it completely avoids the problem of evaluating the\nprobability distributions of the random variables describing the uncertainty affecting those systems, a task that is\ndifficult or even impossible to accomplish in many practical circumstances. Given the consensus reached by the scientific community on the importance of understanding the\nrole of uncertainty when dealing with renewable resources,\nwe believe that worst-case scenario frameworks such as the\n\n\fone described here provide new insights and will become\nincreasingly important.\nTo contribute to the effort of the Computational Sustainability community in tackling the fundamental sustainability challenges of our time, we consider an application of\nour model to a marine natural resource. This type of natural resources are in fact widely believed to be endangered\ndue to over exploitation and generally poorly managed. Using Gulf of Alaska Pacific halibut data from the International Pacific halibut Commission (IPHC) annual reports,\nwe formulated a real world case study problem that fits into\nour framework. In particular, our approach defines a policy\nwith a guaranteed lower bound on the utility function that is\nstructurally very different from the one currently employed.\nAs a future direction, we plan to study the effects of partial observability on the optimal policies by moving into a\nPOMDP framework. Moreover, we aim at extending the\nresults presented here to the multidimensional case by extending the theory on the so-called (\u03c3, S) policies from the\ninventory control literature.\n\n7\n\nAcknowledgments\n\nThis research is funded by NSF Expeditions in Computing\ngrant 0832782.\n\nReferences\n\n[9] S. Ermon, J. Conrad, C. Gomes, and B. Selman. Playing games against nature: optimal policies for renewable resources allocation. Technical report.\n[10] C. Gomes.\nComputational Sustainability Computational Methods for a Sustainable Environment,Economy, and Society. The Bridge, National\nAcademy of Engineering, 39(4), 2009.\n[11] F.R. Homans and J.E. Wilen. A model of regulated\nopen access resource use. Journal of Environmental\nEconomics and Management, 32(1):1\u201321, 1997.\n[12] R.A. Howard and J.E. Matheson. Risk-sensitive\nMarkov decision processes. Management Science,\n18(7):356\u2013369, 1972.\n[13] T. Lauck, C.W. Clark, M. Mangel, and G.R. Munro.\nImplementing the precautionary principle in fisheries\nmanagement through marine reserves. Ecological Applications, 8(sp1):72\u201378, 1998.\n[14] M.L. Littman. Markov games as a framework for\nmulti-agent reinforcement learning. In Proceedings\nof the eleventh international conference on machine\nlearning, volume 157, page 163. Citeseer, 1994.\n[15] S.I.\nMarcus,\nE.\nFern\u00e1ndez-Gaucherand,\nD. Hern\u00e1ndez-Hernandez, S. Coraluppi, and P. Fard.\nRisk sensitive Markov decision processes. Systems\nand Control in the Twenty-First Century, 29, 1997.\n\n[1] Review of the state of world marine fishery resources.\nFAO Fisheries Technical Paper - T457.\n\n[16] G. Owen. Game theory. Third Edition. Academic\nPress, 1995.\n\n[2] M. Ang, Jon M. Conrad, and David R. Just. Proportional Harvest Policies: An Application to the Pacific\nHalibut. Technical report.\n\n[17] W.J. Reed. A stochastic model for the economic management of a renewable animal resource. Mathematical Biosciences, 22(1):313\u2013337, 1974.\n\n[3] A. Ben-Tal and A. Nemirovski. Robust optimization\u2013\nmethodology and applications. Mathematical Programming, 92(3):453\u2013480, 2002.\n\n[18] W.J. Reed. Optimal escapement levels in stochastic\nand deterministic harvesting models. Journal of Environmental Economics and Management, 6(4):350\u2013\n363, 1979.\n\n[4] D.P. Bertsekas. Dynamic programming and optimal\ncontrol. Athena Scientific Belmont, MA, 1995.\n[5] D. Bertsimas and M. Sim. Robust discrete optimization and network flows. Mathematical Programming,\n98(1):49\u201371, 2003.\n[6] C.W. Clark. Mathematical bioeconomics: the optimal management of renewable resources. Wiley New\nYork:, 1990.\n[7] J.M. Conrad. Resource economics. Cambridge University Press, 1999.\n[8] L. Doyen and C. B\u00e9n\u00e9. Sustainability of fisheries\nthrough marine reserves: a robust modeling analysis.\nJournal of Environmental Management, 69(1):1\u201313,\n2003.\n\n[19] H. Scarf. The Optimality of (S, s) Policies in the\nDynamic Inventory Problem. Stanford mathematical\nstudies in the social sciences, page 196, 1960.\n\n\f"}