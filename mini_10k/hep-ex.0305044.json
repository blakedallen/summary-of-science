{"id": "http://arxiv.org/abs/hep-ex/0305044v3", "guidislink": true, "updated": "2003-05-27T12:20:46Z", "updated_parsed": [2003, 5, 27, 12, 20, 46, 1, 147, 0], "published": "2003-05-16T08:02:21Z", "published_parsed": [2003, 5, 16, 8, 2, 21, 4, 136, 0], "title": "Challenging the challenge: handling data in the Gigabit/s range", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=hep-ex%2F0305079%2Chep-ex%2F0305030%2Chep-ex%2F0305096%2Chep-ex%2F0305044%2Chep-ex%2F0305016%2Chep-ex%2F0305106%2Chep-ex%2F0305069%2Chep-ex%2F0305077%2Chep-ex%2F0305066%2Chep-ex%2F0305065%2Chep-ex%2F0305021%2Chep-ex%2F0305073%2Chep-ex%2F0305040%2Chep-ex%2F0305110%2Chep-ex%2F0305091%2Chep-ex%2F0305014%2Chep-ex%2F0305009%2Chep-ex%2F0305081%2Chep-ex%2F0305015%2Chep-ex%2F0305039%2Chep-ex%2F0305013%2Chep-ex%2F0305061%2Chep-ex%2F0305048%2Chep-ex%2F0305104%2Chep-ex%2F0305088%2Chep-ex%2F0305046%2Chep-ex%2F0305023%2Chep-ex%2F0305109%2Chep-ex%2F0305042%2Chep-ex%2F0305098%2Chep-ex%2F0305026%2Chep-ex%2F0305008%2Chep-ex%2F0305064%2Chep-ex%2F0305002%2Chep-ex%2F0305085%2Chep-ex%2F0305020%2Chep-ex%2F0305051%2Chep-ex%2F0305052%2Chep-ex%2F0305076%2Chep-ex%2F0305103%2Chep-ex%2F0305067%2Chep-ex%2F0305036%2Chep-ex%2F0305086%2Chep-ex%2F0207084%2Chep-ex%2F0207092%2Chep-ex%2F0207073%2Chep-ex%2F0207044%2Chep-ex%2F0207037%2Chep-ex%2F0207091%2Chep-ex%2F0207071%2Chep-ex%2F0207055%2Chep-ex%2F0207086%2Chep-ex%2F0207028%2Chep-ex%2F0207054%2Chep-ex%2F0207031%2Chep-ex%2F0207045%2Chep-ex%2F0207060%2Chep-ex%2F0207058%2Chep-ex%2F0207052%2Chep-ex%2F0207057%2Chep-ex%2F0207017%2Chep-ex%2F0207027%2Chep-ex%2F0207067%2Chep-ex%2F0207036%2Chep-ex%2F0207001%2Chep-ex%2F0207024%2Chep-ex%2F0207082%2Chep-ex%2F0207010%2Chep-ex%2F0207021%2Chep-ex%2F0207061%2Chep-ex%2F0207085%2Chep-ex%2F0207009%2Chep-ex%2F0207018%2Chep-ex%2F0207053%2Chep-ex%2F0207043%2Chep-ex%2F0207075%2Chep-ex%2F0207023%2Chep-ex%2F0207080%2Chep-ex%2F0207096%2Chep-ex%2F0207047%2Chep-ex%2F0207063%2Chep-ex%2F0207066%2Chep-ex%2F0207083%2Chep-ex%2F0207013%2Chep-ex%2F0207098%2Chep-ex%2F0207051%2Chep-ex%2F0207064%2Chep-ex%2F0207093%2Chep-ex%2F0207022%2Chep-ex%2F0207034%2Chep-ex%2F0207065%2Chep-ex%2F0207099%2Chep-ex%2F0207050%2Chep-ex%2F0207059%2Chep-ex%2F0207020%2Chep-ex%2F0207077%2Chep-ex%2F0207094%2Chep-ex%2F0207033%2Chep-ex%2F0207011%2Chep-ex%2F0207039%2Chep-ex%2F0207097&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Challenging the challenge: handling data in the Gigabit/s range"}, "summary": "The ALICE experiment at CERN will propose unprecedented requirements for\nevent building and data recording. New technologies will be adopted as well as\nad-hoc frameworks, from the acquisition of experimental data up to the transfer\nonto permanent media and its later access. These issues justify a careful,\nin-depth planning and preparation. The ALICE Data Challenge is a very important\nstep of this development process where simulated detector data is moved from\ndummy data sources up to the recording media using processing elements and\ndata-paths as realistic as possible. We will review herein the current status\nof past, present and future ALICE Data Challenges, with particular reference to\nthe sessions held in 2002 when - for the first time - streams worth one week of\nALICE data were recorded onto tape media at sustained rates exceeding 300 MB/s.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=hep-ex%2F0305079%2Chep-ex%2F0305030%2Chep-ex%2F0305096%2Chep-ex%2F0305044%2Chep-ex%2F0305016%2Chep-ex%2F0305106%2Chep-ex%2F0305069%2Chep-ex%2F0305077%2Chep-ex%2F0305066%2Chep-ex%2F0305065%2Chep-ex%2F0305021%2Chep-ex%2F0305073%2Chep-ex%2F0305040%2Chep-ex%2F0305110%2Chep-ex%2F0305091%2Chep-ex%2F0305014%2Chep-ex%2F0305009%2Chep-ex%2F0305081%2Chep-ex%2F0305015%2Chep-ex%2F0305039%2Chep-ex%2F0305013%2Chep-ex%2F0305061%2Chep-ex%2F0305048%2Chep-ex%2F0305104%2Chep-ex%2F0305088%2Chep-ex%2F0305046%2Chep-ex%2F0305023%2Chep-ex%2F0305109%2Chep-ex%2F0305042%2Chep-ex%2F0305098%2Chep-ex%2F0305026%2Chep-ex%2F0305008%2Chep-ex%2F0305064%2Chep-ex%2F0305002%2Chep-ex%2F0305085%2Chep-ex%2F0305020%2Chep-ex%2F0305051%2Chep-ex%2F0305052%2Chep-ex%2F0305076%2Chep-ex%2F0305103%2Chep-ex%2F0305067%2Chep-ex%2F0305036%2Chep-ex%2F0305086%2Chep-ex%2F0207084%2Chep-ex%2F0207092%2Chep-ex%2F0207073%2Chep-ex%2F0207044%2Chep-ex%2F0207037%2Chep-ex%2F0207091%2Chep-ex%2F0207071%2Chep-ex%2F0207055%2Chep-ex%2F0207086%2Chep-ex%2F0207028%2Chep-ex%2F0207054%2Chep-ex%2F0207031%2Chep-ex%2F0207045%2Chep-ex%2F0207060%2Chep-ex%2F0207058%2Chep-ex%2F0207052%2Chep-ex%2F0207057%2Chep-ex%2F0207017%2Chep-ex%2F0207027%2Chep-ex%2F0207067%2Chep-ex%2F0207036%2Chep-ex%2F0207001%2Chep-ex%2F0207024%2Chep-ex%2F0207082%2Chep-ex%2F0207010%2Chep-ex%2F0207021%2Chep-ex%2F0207061%2Chep-ex%2F0207085%2Chep-ex%2F0207009%2Chep-ex%2F0207018%2Chep-ex%2F0207053%2Chep-ex%2F0207043%2Chep-ex%2F0207075%2Chep-ex%2F0207023%2Chep-ex%2F0207080%2Chep-ex%2F0207096%2Chep-ex%2F0207047%2Chep-ex%2F0207063%2Chep-ex%2F0207066%2Chep-ex%2F0207083%2Chep-ex%2F0207013%2Chep-ex%2F0207098%2Chep-ex%2F0207051%2Chep-ex%2F0207064%2Chep-ex%2F0207093%2Chep-ex%2F0207022%2Chep-ex%2F0207034%2Chep-ex%2F0207065%2Chep-ex%2F0207099%2Chep-ex%2F0207050%2Chep-ex%2F0207059%2Chep-ex%2F0207020%2Chep-ex%2F0207077%2Chep-ex%2F0207094%2Chep-ex%2F0207033%2Chep-ex%2F0207011%2Chep-ex%2F0207039%2Chep-ex%2F0207097&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The ALICE experiment at CERN will propose unprecedented requirements for\nevent building and data recording. New technologies will be adopted as well as\nad-hoc frameworks, from the acquisition of experimental data up to the transfer\nonto permanent media and its later access. These issues justify a careful,\nin-depth planning and preparation. The ALICE Data Challenge is a very important\nstep of this development process where simulated detector data is moved from\ndummy data sources up to the recording media using processing elements and\ndata-paths as realistic as possible. We will review herein the current status\nof past, present and future ALICE Data Challenges, with particular reference to\nthe sessions held in 2002 when - for the first time - streams worth one week of\nALICE data were recorded onto tape media at sustained rates exceeding 300 MB/s."}, "authors": ["T. Anticic", "J. P. Baud", "F. Carena", "W. Carena", "M. Collignon", "F. Collin", "B. Couturier", "R. Divia`", "J. D. Durand", "D. Favretto", "J. M. Jouanigot", "J. C. Marin", "A. K. Mohanty", "B. Panzer-Steidel", "B. Polichtchouk", "F. Rademakers", "H. Renshall", "K. Schossmaier", "M. Schulz", "P. Vande Vyvre", "A. Vascotto"], "author_detail": {"name": "A. Vascotto"}, "author": "A. Vascotto", "arxiv_comment": "Talk from the 2003 Computing in High Energy and Nuclear Physics\n  (CHEP03), La Jolla, Ca, USA, March 2003, 9 pages, PDF. PSN MOGT007", "links": [{"href": "http://arxiv.org/abs/hep-ex/0305044v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/hep-ex/0305044v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "hep-ex", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "hep-ex", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/hep-ex/0305044v3", "affiliation": "for the ALICE collaboration", "arxiv_url": "http://arxiv.org/abs/hep-ex/0305044v3", "journal_reference": null, "doi": null, "fulltext": "CHEP03, La Jolla, California, March 24-28, 2003\n\n1\n\nChallenging the challenge: handling data in the Gigabit/s range\nT.Anticic, F.Carena, W.Carena, R.Divi\u00e0, D.Favretto, J.C.Marin, A.K.Mohanty, B.Polichtchouk,\nF.Rademakers, K.Schossmaier, P.Vande Vyvre, A.Vascotto for the ALICE collaboration\nCERN, Geneva, CH-1211, Switzerland\nJ.P.Baud, M.Collignon, F.Collin, B.Couturier, J.D.Durand, J.M.Jouanigot, B.Panzer-Steidel,\nH.Renshall, M.Schulz\nCERN, Geneva, CH-1211, Switzerland\nThe ALICE experiment at CERN will propose unprecedented requirements for event building and data recording. New\ntechnologies will be adopted as well as ad-hoc frameworks, from the acquisition of experimental data up to the transfer onto\npermanent media and its later access. These issues justify a careful, in-depth planning and preparation. The ALICE Data\nChallenge is a very important step of this development process where simulated detector data is moved from dummy data\nsources up to the recording media using processing elements and data-paths as realistic as possible. We will review herein the\ncurrent status of past, present and future ALICE Data Challenges, with particular reference to the sessions held in 2002 when \u2013\nfor the first time \u2013 streams worth one week of ALICE data were recorded onto tape media at sustained rates exceeding\n300 MB/s.\n\n1. INTRODUCTION\nAll the experiments installed at the LHC collider at\nCERN announced out of the usual requirements. Data\nstreams of unprecedented rates and volumes will be\nestablished between detectors, computer farms (online and\noffline) and mass storage systems. A reliable and effective\ncooperation will be expected from several components,\nhardware and software, in-house, public domain and\ncommercial. Final objectives: satisfy the initial\nrequirements, allow subsequent expansions and ensure the\ndesired performance with the maximum reliability. The\nALICE experiment [1], with its very high-volume data\nstreams, makes no exception to the rule. To guarantee the\nviability and reliability of the ALICE Data Acquisition,\nData Handling and Permanent Data Storage systems,\nperiodic tests are held in collaboration with the ALICE\nOnline and Offline teams together with the CERN central\nservices (Permanent Data Storage, Operating System\ndeployment and support, centralized data repository and\ndistribution, networking) \u2013 the so called ALICE Data\nChallenges. In this paper we review the past experiences\nof the ALICE Data Challenges, the achieved milestones\nduring the current production period and the future plans.\n\n2. ALICE AND THE DATA CHALLENGES\nThe main purpose of the ALICE experiment is to study\nstrongly interacting matter under conditions of extreme\ntemperature and density using beams of heavy ions, such\nas those of lead. The particles in the beams will collide\nthousands of times per second and each collision will\ngenerate an event containing up to thousands of charged\nparticles. Thus, every second, the characteristics of\nthousands of particles will have to be recorded. A central\nALICE event, with lead beams, contains approximately\ntwo orders of magnitude more data than ATLAS or CMS\nevents with a proton beam.\n\n2.1. ALICE running parameters\nThe data stream of ALICE will be made of several types\nof events, each with its own unique signature. Central and\nMOGT007\n\nMinimum Bias events will be acquired with a relatively\nlow rate \u2013 around 10 events per second \u2013 for a high data\nvolume of 10 to 40 Megabytes per event. Dielectron\nevents \u2013 where a partial readout scheme (channels with\nuninteresting data will not be read out) will be used \u2013\nshould produce a higher rate data stream (about 100 events\nper second) for a smaller data volume (1 to 4 Megabytes\nper event). To complete the list, there will be events with\nDimuon trigger signatures, which are expected to generate\nsome 1500 events per second for a data size of 200 to 750\nKilobytes per event. In summary, there will be three types\nof event, each one contributing to about one third of the\nfinal data volume going through the ALICE Data\nAcquisition system. Adjustments made in real time to the\nbehavior of the trigger system will avoid the starvation of\nsome classes of events due to congested data paths\nbetween the detectors and the Data Acquisition system.\nAll these factors will create a global data stream with a\nrather complex structure.\nThe ALICE detector is expected to be ready to run with\nthe above parameters for one month a year, 24 hours a day\nand the maximum achievable availability. The data flow\nbetween the Data Acquisition system and the Permanent\nData Storage will be limited to a throughput of 1.25\nGigabytes per second, for a grand total of 1 Petabytes\nproduced during the lead beam period. Another half a\nPetabyte will be created each year during the proton beam\nperiod. This will result in a yearly production of 1.5\nPetabytes of data to be recorded, catalogued, labeled and\nmade available for later processing. Higher data volumes\nare expected inside the Data Acquisition system, where\nseveral data compression and filter stages will take place\nat various places.\nIn a summary, several challenges are proposed to the\nALICE collaboration:\n1. Handling of low-rate, high-volume events.\n2. Handling of high-rate, low-volume events.\n3. Online Filtering and Data Compression stages.\n4. Handling of high-volume stream to Permanent Data\nStorage\n5. Effectiveness, reliability and availability for all of\nthe points above.\n\n\fCHEP03, La Jolla, California, March 24-28, 2003\nIndexing and access to the experimental data for\ndistribution and processing functions (filtering,\nreconstruction, analysis) during and after data\ncollection and recording.\nTo perform all these tasks, many packages have to be\ndeveloped, debugged and validated. Commercial and\nOpen-Source products have to be evaluated, installed,\nconfigured and tuned. Common software has to be agreed\nupon, developed and integrated. Hardware must be built or\npurchased, evaluated, assembled, validated and put in\noperation. This is clearly a highly challenging task,\nspanning over several years and covering many\ndisciplines. That is where the ALICE Data Challenges\nplay a vital role in the preparation process.\n\n2.2. The ALICE Data Acquisition System\narchitecture\nThe ALICE Data Acquisition System (DAQ)\narchitecture will be based on a data-driven approach.\nUnder the control of a three-level trigger system, the Front\nEnd Electronics (FEEs) \u2013 located as closed as possible to\nthe detectors \u2013 will readout, format and validate the event\nraw data at a \"local\" level (ranging from a complete\ndetector to a sector or a sub-sector of the same). All\naccepted events will be shipped via a custom-designed\npoint-to-point optical link called Detector Data Link\n(DDL) to a Local Data Concentrator (LDC), a commodity\nPC located a few hundred meters away from the\ninteraction point. The LDC will validate the event,\neventually perform local event building (for LDCs with\nmultiple incoming DDLs), run data compression and other\ndata analysis functions and finally move the raw data to\nthe event builder, running on a Global Data Collector\n(GDC). On the GDC \u2013 again based on a commodity PC \u2013\nthe full event will be assembled in the host memory and\nwill be made available for further processing stages and\nfor recording. The Permanent Data Storage system (PDS)\nwill perform data recording functions and will provide\naccess to the event data and catalogues for all successive\nanalysis stages.\n\nLooking at the main data flow, while the FEEs and the\nDDLs will be based on custom-designed components, the\nLDCs, GDCs and the PDS, together with their associated\nnetworks, will be built using commodity hardware. The\nactual technologies to be used for the final ALICE setup\nwill be decided as late as possible and will eventually be\nupgraded during the lifetime of the experiment. A staged\ninstallation strategy has been decided in order to add\nprogressively new material during the first two years of\ndata taking, as soon as higher rates will be required. This\nwill allow a considerable reduction in the overall expenses\nas well as a more efficient final system.\n\n2.3. Requirements and planning for the\nALICE Data Challenges\nTarget of the ALICE Data Challenge is to put together\nall the elements available at a given moment in time and to\ncreate a chain as complete as possible, from the data\nsources (simulated at different levels) to the Permanent\nData Storage. State-of-the-art technologies are for the first\ntime integrated into a single chain to evaluate the\nindividual and global behaviors. Components are installed\nand tuned to match the relations with the rest of the chain.\nBy achieving \u2013 year after year \u2013 more challenging targets,\nwe expect to setup, right before LHC startup, a system up\nto the requirements of the ALICE experiment.\nIn Figure 2 is the planning of the ALICE Data\nChallenges as function of the targeted data rates through\nand recorded by the Data Acquisition system in agreement\nwith the deployment planning of the LCG1 testbed, where\nthe Challenges do and are expected to take place.\n3000\n\nDAQ bandwith\n\nMBytes/s\n\n6.\n\n2\n\n2500\n\nMass Storage bandwith\n\n2000\n\nTape bandwith\n\n1500\n1000\n\n500\n0\n\n1998 1999 2000 2001 2002 2003 2004 2005 2006\n\nFigure 2: ALICE Data Challenges bandwith planning.\nAs we can see from Figure 2, the target is to\nprogressively increase the data rates until something as\nclose as possible to the final ALICE requirements \u2013 in\nagreement with the available hardware resources allocated\nto the exercise \u2013 shall be met. We expect this will happen\nat last one year before LHC startup.\n\nFigure 1: ALICE Data Acquisition System architecture.\n\nMOGT007\n\n1\n\nLCG stands for LHC Computing Grid Project, for more\ninformation see http://lcg.web.cern.ch/LCG\n\n\fCHEP03, La Jolla, California, March 24-28, 2003\nSeen the unprecedented quantity of data to be stored in\nthe Permanent Data Storage, we may witness problems of\nscalability, data query, data retrieval and concurrent data\naccess. Therefore, the volume of recorded data during the\nData Challenges needs also to be planned based upon the\nrequirements of the ALICE experiment. A set of\nmilestones has been established concerning the data\nvolumes. These milestones can be seen in Figure 3.\n\n3\n\nOperating Systems such as Linux, new \u2013 for the Data\nAcquisition culture \u2013 processors (Intel Pentium),\nPermanent Data Storage systems (CASTOR) and hardware\narchitectures (IDE-based disk and tape servers), tape\ntechnologies (linear tape technologies such as the STK\n9940 series) and networking solutions (Ethernet trunking,\nGigabit and 10 Gigabit technologies).\n\n3. THE ALICE DATA CHALLENGE IV\nTBytes to Mass Storage\n\nThe ALICE Data Challenge IV took place between June\nand December 2002. Equipment from the ALICE DAQ\ngroup and from the LCG testbed was used throughout the\nvarious phases of the exercise. New versions of already\nused packages (DATE, CASTOR) went for the first time\nin operation.\n\n1600\n1400\n1200\n1000\n800\n600\n\n3.1. Planned objectives\n\n400\n200\n0\n1999 2000\n\n2001 2002\n\n2003 2004\n\n2005 2006\n\nFigure 3: ALICE Data Challenges recorded data planning.\nSimilarly to the bandwith planning, the milestones of the\nrecorded data planning will reach the expected\nrequirements from the ALICE collaboration in time for the\nLHC startup.\n\n2.4. ALICE Data Challenges: past and\npresent\nThe first ALICE Data Challenge took place in 1998. In\nthat year, several novel technologies and tools were used\nfor the very first time for data acquisition systems at\nCERN \u2013 within ALICE test beams and elsewhere: Fast\nEthernet links, high bandwidth network backbones, new\nPermanent Data Storage media and equipment, Unixbased (within ALICE: Solaris and AIX) data acquisition\nsystems, early prototypes for the ALICE Data Acquisition\nand test beam environment (DATE) package, specialized\nstorage systems such as HPSS and in-house packages and\nstorage access libraries (direct ancestors to the current\nCERN advanced storage manager \u2013 CASTOR). The raise\nof concerns about possible interoperability and functional\nproblems justified the setting and operation of a dummy\ndata acquisition chain during periods of reduced activity at\nCERN.\nThe exercise was considered to be very fruitful. Several\nproblems were spotted, eventually solved, and a\nconsiderable work of debugging and tuning took place in a\nrelatively \"relaxed\" environment, where reliability and\navailability of the complete system was somehow less\ncritical than in an equivalent production setup. The\ndecision was therefore taken to periodically repeat this\nactivity [2].\nFour Data Challenges have been held so far. Each of\nthem replaced existing components with more recent\nversions and introduced new elements in the chain:\nMOGT007\n\nThe following objectives were proposed for the ALICE\nData Challenge IV:\n1. Scalability test for the Data Acquisition system\nto control and handle hundred of nodes.\n2. Data transfer inside the Data Acquisition\nsystem at 650 MB/s minimum sustained\nthroughput for a few hours.\n3. Data recording to Permanent Data Storage at\n200 MB/s minimum sustained throughput for\nseven consecutive days.\n4. 200 TB of data being recorded to Permanent\nData Storage.\n\n3.2. The components\nAs usual for the ALICE Data Challenges, the target was\nto use the latest available hardware and software\ncomponents, namely:\n1. Network technologies: trunking, backbone\nswitching, Gigabit and 10 Gigabit Ethernet.\n2. Commodity hardware: hosts, network interface\ncards, tape units and tape robots.\n3. ALICE Data Acquisition system (DATE [3]\nv4) with its services (readout, monitoring,\nconfiguration, control, event building, event\nrecording, messaging system).\n4. ALICE fabric monitoring software (AFFAIR\n[4]) to assess the behavior of the components\nof the Data Acquisition system and the\ninterface to the Permanent Data Storage.\n5. ALICE Offline software: objectification of raw\ndata, handling of event objects, recording and\ninterfacing to the Permanent Storage System.\n6. CERN Advanced Storage Manager (CASTOR\n[5]) \u2013 deployed on CPU servers, DISK servers\nand TAPE servers \u2013 for Permanent Data\nStorage functions.\n7. Operating system (Linux) with its kernel,\nsystem and user libraries, drivers, file systems\n(local and networked), network daemons\n\n\f4\n\nCHEP03, La Jolla, California, March 24-28, 2003\n(standard and custom designed) plus all CERNspecific add-ons and configurations.\nAll the above components were \u2013 in one-way or another\n\u2013 deployed for the first time within an ALICE Data\nChallenge.\n\nCERN, including the ALICE DAQ lab and the workstation\nused for operation and control. Several trunks were\ndeployed between switches whenever the requested\nbandwith exceeded the capacity of a single link.\nLDCs & GDCs\n\n3.3. Hardware setup\nThe hardware setup used for the ALICE Data Challenge\nIV can be split in four partitions:\n1. DAQ emulation and support.\n2. CASTOR support.\n3. Networking.\n4. Infrastructure.\nThe ALICE DAQ group and the ADC, CS and DS\ngroups of the CERN/IT division jointly provided the\nenvironment to support the ALICE Data Challenge IV.\nTwo computer farms \u2013 both located on the CERN main\nsite but quite far apart \u2013 were effectively seen as one big\nunit thanks to the excellent CERN network backbone and\nto the uniform deployment of Operating Systems,\npackages and environments provided by the CERN Linux,\nASIS2 and AFS teams. Software could be shared without\nproblems on all the machines with no need for explicit\ncopying or recompilation processes. NFS guaranteed the\nrequired effectiveness, reliability and reconfiguration\ncapabilities requested by the exercise \u2013 all issues about its\nscaling capabilities being dropped as more and more\nmachines were flawlessly added to the test setup.\nThe hosts used for the test were all SMP-based. The\nmain production periods took place on the LCG testbed,\nbased on boards equipped with dual Pentium III running at\n~1 GHz, an architecture that matches well the planning\nfrom the ALICE DAQ software for LDCs and GDCs. To\nevaluate the behavior of systems equipped with more\nCPUs, some tests were performed on specialized servers\nbelonging to the ALICE DAQ group test environment.\nSuch a challenging exercise required an out-of-theordinary network setup. The test made use of CERN\nbackbone resources as well as of dedicated equipment.\nCore of the network architecture were two high-bandwith\nswitches \u2013 based on Gigabit Ethernet technologies \u2013\ndirectly linked to a set of satellite switches each handling a\ngroup of up to twelve hosts.\nFigure 4 shows the network setup for the LCG testbed,\nwhere the raw DATE performance and the Data Challenge\nproduction periods took place. In the centre of the diagram\nare the two central switches \u2013 Extreme Networks Summit\n7i with 32 Gigabit Ethernet ports each \u2013 while LDCs,\nGDCs and DISK servers were connected to smaller 3COM\n4900 switches (16 Gigabit Ethernet ports each). The\nstandard CERN backbone, supported by Enterasys\nSSR8600 routers (28 Gigabit Ethernet ports) guaranteed\nthe liaison with the TAPE servers and with the rest of\n2\n\nASIS stands for \"The Application Software Installation\nServer\", more information is available at the Web address\nhttp://asis.web.cern.ch/asis/\n\nMOGT007\n\n3\n\n3\n\nDISK servers\n\n3\n\n3\n\n2\n\n2\n\n2\n\n8\nCPU servers\n\n2\n3\n\n3\n\n3\n\n3\n\nLDCs & GDCs\n\nBackbone\n(4 Gbps)\n\n16 TAPE servers\n(distributed)\n\nFigure 4: LCG testbed network setup.\nDuring the exercise, equivalent 10 Gigabit Ethernet\ndevices, in evaluation at CERN, have also been tested in\nnetwork architectures similar to the one described above.\n\n3.4. Software components\nFor the deployment of the ALICE Data Challenge IV we\ntook standard, out-of-the-box components, integrated by\nad-hoc configuration and installation tools.\nThe three CERN-developed packages that played a key\nrole in the Challenge were DATE, CASTOR and ROOT.\nDATE \u2013 the name stands for Data Acquisition and Test\nEnvironment \u2013 is the framework of the ALICE Data\nAcquisition systems, also used for R&D and test beams\nsupport. The release used \u2013 identified as version 4 \u2013\nintroduced several novelties, including new run control,\ndata recording and event building packages. More scalable\nthan its predecessors, DATE version 4 made a better use\nof the system resources for large-scale setups \u2013 such as the\none deployed during the ALICE Data Challenge IV.\nIncluded in DATE were also a Configurable LDC\nEmulator (COLE) \u2013 capable of producing a ALICE-like\ndata traffic pattern \u2013 and A Fine Fabric and Application\nInformation Recorder (AFFAIR) package providing the\nrequired run-time global and local behavioral monitoring\ncapabilities throughout the whole Data Acquisition\nsystem. All the information collected with AFFAIR was\npromptly published on WWW for immediate feedback.\nSeveral of the graphs presented in this paper have been\nextracted from the pages published via AFFAIR.\nThe CERN Advanced Storage Manager (CASTOR\nV1.4.1.7) package played a key role for the support of the\ndata created by DATE during the exercise. CASTOR\nprovided a common access library and a set of transparent\nmigration engines to a unique name space, integrating\nseveral mass storage systems placed at different levels and\nsupport medias. All this under the pressure of hundreds of\nmachines producing data at their maximum speed for a\nperiod of several days. Monitoring tools and public status\n\n\f5\n\nCHEP03, La Jolla, California, March 24-28, 2003\n\n7.00\n6.00\n\nM B /s\n\n50\n40\n\nLDC CPU usage\n\nGDC CPU usage\n\nTransfer speed\n\n5.00\n4.00\n\n% C P U /M B\n\n8.00\n\n60\n\n30\n3.00\n20\n\n2.00\n\n10\n\n1.00\n\n0\n\n0.00\n\n25\n\n20\n\n15\n\n10\n\n00\n\n00\n\n00\n\n00\n\n0\n\nSocket size (KB)\n\nFigure 5: Peer to peer tests on dual-CPU hosts.\nThe same test, run on quad-CPU hosts, returned higher\nnetwork performance for similar CPU usage, effect due to\nthe large total CPU capacity and to the fact that the Linux\nkernel has proved to be able to make use of more than one\nCPU for its internal tasks. The platforms used for this test\nwere HP Netservers with 4 Xeon CPUs running at 700\nMHz, Linux kernel 2.4.19 and 3COM 996 as NICS with\ntg3 driver. The top performance was of 110 MB/s (very\nclose to the Gigabit Ethernet wire speed) for\n1.9 %/CPU/Megabyte on the event builders and\n1.4 %/CPU/Megabyte on the data producers. Details on\none of the quad-CPU tests \u2013 correlating the event size to\nthe achieved throughput \u2013 are reported in Figure 6.\n110\n5.00\n\n100\n90\n\nM B /s\n\n70\nTransfer speed\n\n60\n\nGDC CPU usage\n\nLDC CPU usage\n\n3.00\n\n50\n2.00\n\n40\n\n% C P U /M B\n\n4.00\n\n80\n\n30\n1.00\n\n20\n10\n0\n\n0.00\n20\n\n18\n\n16\n\n14\n\n12\n\n00\n\n00\n\n00\n\n00\n\n00\n\n00\n\n0\n\n0\n\n0\n\n0\n\n10\n\n80\n\n60\n\n40\n\n20\n\nMOGT007\n\n9.00\n\n70\n\n0\n\nSeveral peer to peer tests were made to evaluate the\nbehavior of the key network components, namely the\nDATE recording library, the architecture of the DATE\nevent builder data receiving engine and the various system\nlibraries required by the data recording process. The tests\ntook place in the ALICE DAQ test setup. As we did not\nneed a complete Data Acquisition system, only a subset of\nthe Data Acquisition components was used for this test.\nThe chain included a minimal skeleton and the DATE\nrecording library on one side and a data sink on the\nreceiving end, using the same architectures as for the\nDATE recorder and event builder packages. Both sides of\nthe test were extended to allow precise measurements for\nkey system and network resources. The outcomes of these\ntests were very encouraging and more than validated the\neffectiveness of all the above components.\nOne of the issues to be analyzed during the peer-to-peer\ntests was the transfer speed and relative load on the\nsending and receiving CPUs. The results gave different\nresults on dual-CPU and quad-CPU machines.\nOn dual-CPU hosts, whose architecture well matches\nthe requirements for the ALICE LDCs and the low-cost\nALICE GDCs, performances of up to 83 MB/s were\nreached with a usage of 1.5 %/CPU/Megabyte on the\nLDCs and 2.1 %/CPU/Megabyte on the GDCs. The\nmachines used for this test were equipped with two\nPentium III CPUs running at 1 GHz, Linux Kernel 2.4.18\nand NetGear GA620 NICs with acenic driver. Detailed\nfigures from one of the tests \u2013 where the correlation\n\n10.00\n80\n\n50\n\n3.5. Peer to peer tests\n\nbetween socket sizes and throughputs for fixed-size events\n\u2013 are reported in Figure 5.\n\n0\n\npages were provided to configure, operate and control the\nbehavior of the system in real time.\nA common Operating System was used throughout the\ntest setup. Linux RedHat 7.2, kernels 2.2 and 2.4, as\nprovided by the CERN Linux support team, was deployed\non all the machines. The standard installation procedure\navailable at CERN was used. A configuration of the\nsystem parameters was performed to appropriately size\ncommon resources such as IPC shared memory block size\nand TCP/IP socket size, to import the central distribution\nrepository and to install the required network services.\nThis required no changes in the kernel itself and could be\ndone either on the fly or during the boot procedure of the\nOperating System. AFS was installed on all the machines\nbut was not used at runtime: its role was to support the\nASIS environment, for distribution of system images and\nCERN-wide packages. A special ALICE\u2013developed driver\nfor the support of shared pinned memory was installed on\nsome of the machines used to run peer-to-peer tests.\nThe ALICE collaboration makes intensive use of the\nROOT framework. To support the DATE built-in\npackages based on ROOT, including the ALICE Mock\nData Challenge objectifier (ALIMDC), ROOT V3.03 was\ninstalled and distributed via NFS. Run-time libraries were\nalso distributed via NFS and automatically loaded by\nDATE whenever this was required.\n\nEvent size (KB)\n\nFigure 6: Peer to peer tests on quad-CPU hosts.\nDuring the peer-to-peer tests we have also done some\nmeasurements on the possible correlation between runtime\nparameters (Operating System level and user code level)\nand data traffic behavior. The most surprising conclusion\nwe have achieved was that the old rule of thumb \"the\nbigger the socket, the better the performance\" seems not\nbe any longer true. We have witnessed a degradation of\nthe throughput whenever the socket exceeded a certain\nsize (variable with the architecture, the payload and other\nuser code parameters). Furthermore the size of the user\nDATE raw data buffer proved to have a significant effect\non the overall performance, following a similar pattern as\nin the case of the socket size.\n\n\f6\n\nCHEP03, La Jolla, California, March 24-28, 2003\n\nTarget of the scalability tests was to correlate the\nstability and usability of the Data Acquisition system as a\nfunction of the number of LDCs and GDCs, on a scale as\nclose as possible to the one of the final ALICE Data\nAcquisition system.\nFor this exercise, the accent was placed on the\nscalability of all the components. Data transfer had to give\nits proof of feasibility and nothing more. Key elements to\nvalidate were: the state machines controlling the whole\nsystem, the operator user interface, the communication\nlibraries, the system I/O libraries, the usage of the system\nI/O libraries, the distribution system for images, libraries\nand configuration parameters, the information and error\nlogging facilities and the behavior of the system as a\nwhole.\n\nFigure 7: Status & control window during scalability tests.\nThe system reacted very well. No hard limitations were\nfound in any of the components. As shown in Figure 7, a\nmaximum configuration of 79 LDCs and 79 GDCs \u2013\nrunning on 79 dual-role PCs \u2013 could be controlled with\nvery acceptable latencies (a delay of ~15 seconds was\nmeasured during the start of run phase). The Operating\nSystem, together with the communication, run-time and\ngraphics library accomplished their tasks without\nproblems. The Operator graphic interface could effectively\ndescribe the evolution of the Data Acquisition System\nstartup procedure even on such a large set of nodes with an\nexcellent quality of visual hints and diagnostic\ninformation.\n\n3.\n\nThe ALICE Mock Data Challenge objectifier,\nto create ALICE data objects and to write them\nin ROOT format.\n4. The CERN Advanced STORage manager\nCASTOR, to handle the Permanent Data\nStorage access (read, write, migration,\noperation, monitoring).\n5. A Fine Fabric and Application Information\nRecorder AFFAIR, a monitoring system for\nLDCs and GDCs.\nThe chain was setup little by little, not necessarily in the\norder given above. At times, intermediate components\nwere tested in isolation. In other tests, small parts of the\nchain were put in operation, to evaluate the\ninterdependence of the various components. The outcomes\nof this type of exercises proved to be a valuable aid for\ntuning, debugging and validation of the test environment.\nThe LDC emulator was setup to produce one of two\ntraffic patterns: either the so-called \"flat traffic\", where all\nthe LDCs would create an identical event, or an \"ALICElike traffic\", where a model of the forecasted ALICE raw\ndata was followed. Tests were run with both types of\ntraffic with different results.\nUsing flat data traffic, scalability tests were run up to the\nrecording stage of DATE. Here we have observed a good\nbehavior of the whole system excepted for an undesired\nphenomenon at the output of some of the network\nswitches. As can be seen in Figure 4 above, the LDCs and\nthe GDCs were all connected to one of the \"satellite\"\n3COM 4900 switches and \u2013 via a triple Gigabit Ethernet\ntrunk \u2013 to one of the two central Summit 7i. We therefore\nexpected the outgoing data traffic from each of the 3COM\nswitches to reach throughputs of the order of three times\nthe throughput of a single Gigabit Ethernet link.\nUnfortunately this was not what we have measured.\n600.00\n500.00\nDistributed\n\nMB/s total\n\n3.6. Scalability tests\n\nSame sw itch\n\n400.00\n300.00\n200.00\n100.00\n0.00\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n# LDCs\n\nFigure 8: Scalability test of outgoing data trunks.\n\n3.7. Staging of the production period\nThe ALICE Data Challenge IV was planned on a\nproduction chain based on the following components:\n1. The ALICE LDC emulator COLE, to create a\ndata stream according to the test requirements.\n2. The ALICE Data Acquisition and Test\nEnvironment DATE, to acquire, build and\nrecord the ALICE raw data.\n\nMOGT007\n\nAs we can see in Figure 8, by distributing the LDCs\nevenly on all the 3COM switches we demonstrated how\nthe Summit 7i switch could effectively absorb the\ngenerated traffic without problems (top line in the graph).\nWe then increased the outgoing traffic local to one single\n3COM 4900 switch (we did this by adding more LDCs to\na single switch, rather than distributing them across\nmultiple switches). We had expected a saturation\nthroughput of O(300) MB/s \u2013 the throughput equivalent to\n\n\fCHEP03, La Jolla, California, March 24-28, 2003\nabout three LDCs writing onto a triple Gigabit Ethernet\ntrunk. We have instead observed only two thirds of that, a\nthroughput of 220 Megabytes per second. Therefore, we\nknew we could use an outgoing capacity per 3COM switch\nequivalent to \"only\" two Gigabit Ethernet links. The\nincoming capacity of the 3COM switches and their triple\nGigabit Ethernet trunk \u2013 on the other hand \u2013 reached the\nexpected values and was never a problem.\nWe therefore had to take into account this \"outgoing\ntraffic\" limitation for all the 3COM switches. To make\nthings more difficult, we had also to make provisions for\nthe outgoing traffic being written by DATE into itself and\nby DATE into the Permanent Data Storage. With the\ncomplete chain in place, we had to plan for a double load\non all the outgoing links from the 3COM switches (half of\nthe traffic created by the Data Acquisition system and half\nof the traffic created by the streaming from CASTOR to\nthe Permanent Data Storage). We therefore had to redefine the topology of the whole test setup according to\nthese findings.\nAnother problem came from the setup and operation of\nthe computer farm. First of all, as all the machines were\nnot available at the same time, the installation had to be\ndone in stages. The Operating System, the framework, the\nproducts and all the annexed facilities had also to be\nre-installed on several nodes (due to updates, uniform\ndeployment procedure and publication of new features).\nTo make things more complicated, we have observed\nseveral dead on arrival (about 10% of the hosts), some\nfailed-on-installation (another 25% of the hosts) and a few\ndead-on-operation machines. Hosts' installation, restart\nand topological re-distribution took a considerable amount\nof manpower and we have never been able to use a system\nup to its planned run-time capacity. It is also true that the\ninstallation procedure took very little resources and was\nalmost totally automated. The standard CERN Linux\ninstallation scheme, run jointly with a special script to\ninstall and configure the extra resources required by the\nALICE Data Challenge, made a full reload of a node a\nroutine procedure.\nFor the ALICE Data Challenge IV we made plans to use\nthe new generation of StorageTek (STK) linear magnetic\ntape drives model 9940B, whose cartridges can accept up\nto 200 Gigabytes of data at a sustained rate of 30 MB/s.\nThe units were delivered quite late and could be included\nin the test chain only at the very last moment. Clearly, this\nreduced considerably our flexibility for the deployment of\nthe test and imposed hard constraints on the production\nperiod.\nDuring the setup phase we have also noticed an issue\narising from an incompatibility between the ALICE Mock\nData Challenge output stream and the CASTOR input\nstreams. Throughputs were very poor and the hosts'\nresources (hardware and software) were clearly badly\nused. We later found out (unfortunately too late for the\nALICE Data Challenge) that this was due to an\narchitectural mismatch between the two components. We\nwere therefore obliged to exclude the ALIMDC process\nfrom the ALICE Data Challenge chain and to replace it\nMOGT007\n\n7\n\nwith a simpler front-end to the CASTOR system, writing\nraw DATE events into it. This proved to amply satisfy our\nrequirements in time for the production period of the\nALICE Data Challenge IV.\nSeveral tests were performed on CASTOR. Some tests\nwere run in isolation while other tests included a complete\nchain. The system behaved well if the incoming data\nremained below the maximum throughput that could be\naccepted by the tape devices. If instead the incoming\nthroughput would exceed this value, CASTOR\nperformances would degrade considerably, well below the\nmaximum expected value.\nDuring the planning phase for the ALICE Data\nChallenge we expected to integrate in the test setup new\nnetwork technologies, namely some 10-Gigabit Ethernet\nequipment CERN had received in evaluation. This was\ndone during the tuning stage of the final production period.\nThe transition between the Gigabit Ethernet and the 10Gigabit switches went almost transparently (we have seen\nsome small troubles with the NFS distribution of the\nimages and of the configuration files) and \u2013 at first \u2013 the\nresults looked promising. Unfortunately we quickly\nencountered serious problems \u2013 total unrecoverable freeze\nof parts of the network \u2013 that forced us to switch back to\nthe original setup based on Gigabit Ethernet. The problem\nwas later identified as an issue related to the integration of\na special ASIC used to handle the communication inside\nthe 10 Gigabit Ethernet switches. The manufacturer issued\na fix, unfortunately too late to reintegrate the now\n(apparently) working material in the ALICE Data\nChallenge setup.\n\n3.8. Production periods\nDuring the ALICE Data Challenge IV, milestones were\ndistributed over two production periods.\nThe first production period was held in July 2002, when\nhigh-rate raw data was transferred within DATE over a\nrelative short period, target being 650 MB/s sent from the\nevent builder to the null device.\nThe second period has the objective to achieve 200\nMegabytes per second sustained to tape for a minimum of\n7 consecutive days and to create at the same time a data set\nof about 200 TB of data in Permanent Data Storage (PDS).\nFor this milestone the complete chain (LDCs to GDCs to\nCASTOR to tapes) had to be active. For this reason, we\nhad to wait for the delivery of the required tape units (this\nhappened in late November 2002), to go through a\nsuccessive validation period and \u2013 finally \u2013 to coordinate\nthe allocation of a considerable amount of CERN public\nresources. The second test session was started on\nDecember 6th, 2002.\n\n3.9. Outcomes\nThe ALICE Data Challenge IV can be considered as a\ncomplete success. As we will see, both milestones have\nbeen met \u2013 if not exceeded \u2013 using production-like\nsoftware and standard tools and services.\n\n\fCHEP03, La Jolla, California, March 24-28, 2003\nThe first milestone \u2013 sustained throughput of 650 MB/s\nthrough DATE \u2013 was met on July 2nd 2002, when event\nbuilding reached the aggregate throughput of 1.8\nGigabytes per second.\n\n8\n\nlater to be removed from the test setup) and by some\nreconfigurations that followed. The measures made with\nAFFAIR over the test period are shown in Figure 10.\n\nFigure 10: sustained throughput milestone monitoring.\nFigure 9: DATE raw event building throughput.\nThe graph reported in Figure 9 shows the monitoring\ninformation published by AFFAIR on a Data Acquisition\nsystem composed of 40 LDCs and 38 GDCs writing fixed\nsize and fixed pattern events of 40 Megabytes each (1\nMegabyte per LDC) to the null device. Incidentally, the\n1.8 GB/s is also the theoretical limit imposed by the output\ntrunks from the eight 3COM switches (~220 MB/s per\ntrunk distributed on 8 trunks). The above throughput is\ntherefore the theoretical maximum that we could have\nsqueezed out of the deployed network topology. The\nmilestone was quickly achieved and no major problems\nwere encountered. The only issue behind this milestone\nwas the unavailability of several machines (dead on\narrival, failed on installation, failed on operation) that\nrequired a careful and detailed optimization of the\navailable resources. Little Operating System tuning was\nneeded and on the LDCs and the GDCs we had plenty of\nspare system resources available. The LDCs had about 1\u20444\nof one CPU free and the GDCs had about 1 CPU free. The\ntest was run on the LCG testbed, with hosts based on dualPentium III CPUs.\nThe second milestone required more detailed setup and\ncareful tuning. The only fact that we had to make intensive\nuse of public CERN resources (network backbone, tape\nrobots, tape units, tape libraries, servers) imposed hard\nconstraints on the schedule of the various test phases. It\nwas also the first time that CASTOR v1.4.1.7 was attached\nto a stream carrying such a bandwith. If we add the fact\nthat several of the hardware components had never been\nused before on a system of this scale, we clearly might\nhave had the perfect recipe for a disaster. This was not the\ncase: all components behaved as expected and we had \u2013 at\nleast at first \u2013 very little problems to get things going.\nPrevious tests demonstrated how the deployed PDS setup\ncould not accept more than a given amount of data and we\ntherefore limited ourselves to this amount (well above our\nplanning requirements). We also opted for a \"relaxed\"\noperator intervention policy, limited to working hours and\nto a few occasional checks after hours or during the\nweekend. With all this is mind, the system performed as\nexpected, even recovering from some degradations\nintroduced by the failure of one of the tape units (that had\nMOGT007\n\nAfter a sharp ramp-up period on the December 6th \u2013\nwhen not-yet-full disks could accept data at nominal\nbandwith \u2013 the system behaved well for four days, when \u2013\nafter a first warning sign in the evening of the 9th \u2013 one\ntape unit failed and the whole system had to be\nreconfigured. Following this phase, the throughput\nreturned to the nominal value on December 11th to remain\nstable until the end of the test. The final results were: a\npeak rate of 310 Megabytes per second (ramp-up period\nexcluded), a sustained rate of 280 Megabytes per second\nand 180 Terabytes moved onto Permanent Data Storage\nfor a time period of seven consecutive days.\n\n4. FUTURE DATA CHALLENGES\nWe feel that several important issues have not been\nadequately confronted during the ALICE Data Challenge\nIV. They have since been reviewed and will play a role in\nthe planning of the future ALICE Data Challenges.\nALICE-like data pattern must be correctly deployed.\nALICE will not move data streams of complex structure\nand this will be an important factor for all future tests and\nproduction periods. This may imply the use of different\nnetwork topologies, the deployment of new network\ntechnologies (NICs and switches) and the allocation of\ndedicated tuning and setup periods in our program of\nwork.\nOnline handling of the data coming from the LDC\nemulators must be tried out. This shall include the\nobjectification of raw data events and some on-the-fly\nreconstruction processing. In the ALICE Data Challenge\nIV these objectives had to be dropped due to time\nconstraints and lack of resources. Furthermore, data\nanalysis implies a certain structure and format of the data,\nto be agreed between the ALICE Online and Offline\nteams. Good progresses have been made on this issue and\nwe are confident for future Challenges, when we expect\nROOT objects to be stored and distributed to some\nselected Tiers outside CERN. The ALICE Environment \u2013\nAliEn \u2013 [6] is ready for integration to the ALICE Data\nChallenge setup and shall be soon tested in \"real life\"\nconditions.\n\n\fCHEP03, La Jolla, California, March 24-28, 2003\nSo far we have always emulated the data stream created\nfrom the ALICE detectors via a software module. Since\nsome time now, a hardware data source emulator is\navailable from the ALICE Data Acquisition group. For the\nfuture data challenge we expect to integrate at least one\ncomplete chain at the input of the data streams and to feed\nthis into the raw data path. This will be an important\nmilestone, as we will have \u2013 for the first time \u2013 the ALICE\nreadout card (the pRORC) part of an ALICE-like Data\nAcquisition system. We expect to setup the Detector Data\nLink (DDL) chain in the ALICE DAQ lab, directly linked\nby the CERN backbone to the LCG test setup via a Gigabit\nEthernet uplink.\nThe 300 MB/s barrier to PDS observed in 2002 will\nhave to be broken. We have already reached the milestone\nplanned for the ALICE Data Challenge year 2003 (300\nMegabytes per second). However, the LCG testbed plans\nan upgrade to 450 Megabytes per second for the year 2003\nand we shall profit from this extra bandwith. We know\nthat the Data Acquisition system is capable of throughputs\nmuch higher than that, so we have good hopes in what the\nforthcoming host computers, network and tape\ntechnologies will be able to give to us.\n\n5. CONCLUSIONS\nThe ALICE Data Challenge IV proved to be a valuable\ninput for future developments as well as a successful\nexercise to achieve very important \u2013 for CERN and for the\nALICE collaboration \u2013 milestones. A rather significant set\nof equipment was put together to form an ALICE-like\nData Acquisition setup. The output data stream was\nsuccessfully recorded onto Permanent Data Storage with\nexcellent rates, reliability and stability. Commercial\ncomponents and CERN in-house packages integrated at\nthe best of expectations. All the milestones were met \u2013\nseveral even exceeded \u2013 and we are now between one and\nthree years ahead of the proposed planning. This does not\n\nMOGT007\n\n9\n\nmean that we are out of work, on the contrary. The ALICE\ncollaboration has stringent and difficult requirements that\nwill always justify the deployment of new, more\ndemanding ALICE Data Challenges. New technologies,\nproducts, libraries and developments will require the\npreparation, setup and operation of similar exercises. Only\nin this way we will be able to guarantee a reasonable level\nof confidence in the complete data chain once the first\nevents will be triggered at the LHC collider: by\nchallenging the challenge.\n\nReferences\n[1]\n[2]\n\n[3]\n[4]\n\n[5]\n[6]\n\n\"ALICE Technical Proposal for A Large Ion\nCollider Experiment at the CERN LHC\",\nCERN/LHCC/95-71, 15 December 1995.\nJ.P.Baud, W.Carena, F.Carminati, M.Collignon,\nF.Colin, R.Divi\u00e0, J.D.Durand, S.Jarp,\nJ.M.Jouanigot, B.Panzer, F.Rademakers, P.Saiz,\nK.Schossmaier, P.Vande Vyvre, A.Vascotto for the\nALICE collaboration, \"The ALICE Data\nChallenges\", CHEP 2001, Beijing, China,\nSeptember 2001.\nALICE DAQ Project, \"ALICE DATE User's\nGuide\", ALICE note ALICE-INT-2002-036,\nNovember 2002.\nT.Anti\u010di\u0107, R.Piska\u010d, V.\u0160ego, \"AFFAIR, A Flexible\nFabric and Application Information Recorder\",\nALICE note ALICE-PR-2002-168, 20 September\n2002.\nJ.-P.Baud, O.B\u00e4rring, J.-D.Durand, \"CASTOR\nProject Status\", CHEP 2000, Padova, Italy,\nFebruary 2000.\nP.Buncic, A.Peters, P.Saiz on behalf for the ALICE\nCollaboration, \"AliEn Resource Brokers\", this\nconference.\n\n\f"}