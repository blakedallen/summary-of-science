{"id": "http://arxiv.org/abs/1102.1348v1", "guidislink": true, "updated": "2011-02-07T16:11:07Z", "updated_parsed": [2011, 2, 7, 16, 11, 7, 0, 38, 0], "published": "2011-02-07T16:11:07Z", "published_parsed": [2011, 2, 7, 16, 11, 7, 0, 38, 0], "title": "The computation of Greeks with multilevel Monte Carlo", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1102.2432%2C1102.0377%2C1102.0533%2C1102.3560%2C1102.1348%2C1102.2983%2C1102.0465%2C1102.1504%2C1102.0393%2C1102.0645%2C1102.2943%2C1102.0091%2C1102.0453%2C1102.4324%2C1102.0707%2C1102.1351%2C1102.0231%2C1102.1509%2C1102.2607%2C1102.4043%2C1102.2333%2C1102.1262%2C1102.4918%2C1102.4393%2C1102.3320%2C1102.3001%2C1102.1519%2C1102.0160%2C1102.4444%2C1102.1365%2C1102.0332%2C1102.1696%2C1102.5572%2C1102.5524%2C1102.0314%2C1102.0037%2C1102.4202%2C1102.5045%2C1102.3692%2C1102.1359%2C1102.2776%2C1102.4002%2C1102.4013%2C1102.5067%2C1102.0990%2C1102.5492%2C1102.0884%2C1102.5089%2C1102.3216%2C1102.3531%2C1102.4704%2C1102.0327%2C1102.2383%2C1102.3540%2C1102.4250%2C1102.0188%2C1102.3045%2C1102.3694%2C1102.5454%2C1102.1189%2C1102.0209%2C1102.1247%2C1102.0747%2C1102.3385%2C1102.5759%2C1102.1948%2C1102.5601%2C1102.4438%2C1102.0791%2C1102.5701%2C1102.1942%2C1102.0070%2C1102.4305%2C1102.0161%2C1102.1238%2C1102.3889%2C1102.3666%2C1102.1839%2C1102.4471%2C1102.5565%2C1102.1300%2C1102.1675%2C1102.4959%2C1102.4995%2C1102.1563%2C1102.0394%2C1102.2912%2C1102.4886%2C1102.0432%2C1102.3201%2C1102.4656%2C1102.1158%2C1102.0541%2C1102.5467%2C1102.4711%2C1102.0463%2C1102.1445%2C1102.2617%2C1102.0238%2C1102.5355%2C1102.1511&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The computation of Greeks with multilevel Monte Carlo"}, "summary": "We study the use of the multilevel Monte Carlo technique in the context of\nthe calculation of Greeks. The pathwise sensitivity analysis differentiates the\npath evolution and reduces the payoff's smoothness. This leads to new\nchallenges: the inapplicability of pathwise sensitivities to non-Lipschitz\npayoffs often makes the use of naive algorithms impossible. These challenges\ncan be addressed in three different ways: payoff smoothing using conditional\nexpectations of the payoff before maturity; approximating the previous\ntechnique with path splitting for the final timestep; using of a hybrid\ncombination of pathwise sensitivity and the Likelihood Ratio Method. We\ninvestigate the strengths and weaknesses of these alternatives in different\nmultilevel Monte Carlo settings.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1102.2432%2C1102.0377%2C1102.0533%2C1102.3560%2C1102.1348%2C1102.2983%2C1102.0465%2C1102.1504%2C1102.0393%2C1102.0645%2C1102.2943%2C1102.0091%2C1102.0453%2C1102.4324%2C1102.0707%2C1102.1351%2C1102.0231%2C1102.1509%2C1102.2607%2C1102.4043%2C1102.2333%2C1102.1262%2C1102.4918%2C1102.4393%2C1102.3320%2C1102.3001%2C1102.1519%2C1102.0160%2C1102.4444%2C1102.1365%2C1102.0332%2C1102.1696%2C1102.5572%2C1102.5524%2C1102.0314%2C1102.0037%2C1102.4202%2C1102.5045%2C1102.3692%2C1102.1359%2C1102.2776%2C1102.4002%2C1102.4013%2C1102.5067%2C1102.0990%2C1102.5492%2C1102.0884%2C1102.5089%2C1102.3216%2C1102.3531%2C1102.4704%2C1102.0327%2C1102.2383%2C1102.3540%2C1102.4250%2C1102.0188%2C1102.3045%2C1102.3694%2C1102.5454%2C1102.1189%2C1102.0209%2C1102.1247%2C1102.0747%2C1102.3385%2C1102.5759%2C1102.1948%2C1102.5601%2C1102.4438%2C1102.0791%2C1102.5701%2C1102.1942%2C1102.0070%2C1102.4305%2C1102.0161%2C1102.1238%2C1102.3889%2C1102.3666%2C1102.1839%2C1102.4471%2C1102.5565%2C1102.1300%2C1102.1675%2C1102.4959%2C1102.4995%2C1102.1563%2C1102.0394%2C1102.2912%2C1102.4886%2C1102.0432%2C1102.3201%2C1102.4656%2C1102.1158%2C1102.0541%2C1102.5467%2C1102.4711%2C1102.0463%2C1102.1445%2C1102.2617%2C1102.0238%2C1102.5355%2C1102.1511&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We study the use of the multilevel Monte Carlo technique in the context of\nthe calculation of Greeks. The pathwise sensitivity analysis differentiates the\npath evolution and reduces the payoff's smoothness. This leads to new\nchallenges: the inapplicability of pathwise sensitivities to non-Lipschitz\npayoffs often makes the use of naive algorithms impossible. These challenges\ncan be addressed in three different ways: payoff smoothing using conditional\nexpectations of the payoff before maturity; approximating the previous\ntechnique with path splitting for the final timestep; using of a hybrid\ncombination of pathwise sensitivity and the Likelihood Ratio Method. We\ninvestigate the strengths and weaknesses of these alternatives in different\nmultilevel Monte Carlo settings."}, "authors": ["Sylvestre Burgos", "M. B. Giles"], "author_detail": {"name": "M. B. Giles"}, "author": "M. B. Giles", "arxiv_comment": "Technical Report (December 2010)", "links": [{"href": "http://arxiv.org/abs/1102.1348v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1102.1348v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "q-fin.CP", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "q-fin.CP", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "65B99", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1102.1348v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1102.1348v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:1102.1348v1 [q-fin.CP] 7 Feb 2011\n\nTechnical report\nThe computation of Greeks with\nMultilevel Monte Carlo\nSylvestre Burgos, M.B. Giles\nOxford-Man Institute of Quantitative Finance\nUniversity of Oxford\nDecember 2010\nAbstract\nWe study the use of the multilevel Monte Carlo technique [2, 3]\nin the context of the calculation of Greeks. The pathwise sensitivity analysis [5] differentiates the path evolution and reduces the payoff's smoothness. This leads to new challenges:\nthe inapplicability of pathwise sensitivities to non-Lipschitz payoffs often makes the use of\nnaive algorithms impossible.\nThese challenges can be addressed in three different ways: payoff smoothing using conditional expectations of the payoff before maturity [5]; approximating the previous technique\nwith path splitting for the final timestep [1]; using of a hybrid combination of pathwise sensitivity and the Likelihood Ratio Method [4]. We investigate the strengths and weaknesses\nof these alternatives in different multilevel Monte Carlo settings.\n\n1\n\nIntroduction\n\nIn mathematical finance, Monte Carlo methods are used to compute the price of an option by estimating the expected value E(P). P is the payoff function that depends on an\nunderlying asset's scalar price S(t) which satisfies an evolution SDE of the form\ndS(t) = a(S,t) dt + b(S,t) dWt ,\n\n0 \u2264 t \u2264 T,\n\nS(0) given,\n\n(1)\n\nThis is just one use of Monte Carlo in finance. In practice the prices are often quoted and\nused to calibrate our market models; the option's sensitivities to market parameters, the socalled Greeks, reflect the exposure to different sources of risk. Computing these is essential\nto hedge portfolios and is therefore even more important than pricing the option itself. This\nis why our research focuses on getting fast and accurate estimates of Greeks through Monte\nCarlo simulations.\n\n1\n\n\f1.1\n\nMultilevel Monte Carlo\n\nLet us consider a standard Monte Carlo method using a discretisation with first order weak\nconvergence (e.g. the Milstein scheme). Achieving a root-mean square error of O(\u03b5) requires a variance of order O(\u03b5 2 ), hence O(\u03b5 \u22122 ) independent paths. It also requires a discretisation bias of order O(\u03b5 \u22121 ), thus O(\u03b5 \u22121 ) timesteps, giving a total computational cost\nO(\u03b5 \u22123 ).\nGiles' multilevel Monte Carlo technique reduces this cost to O(\u03b5 \u22122 ) under certain conditions. The idea is to write the expected payoff with a fine discretisation using 2\u2212L uniform\ntimesteps as a telescopic sum. Let P\u0302l be the simulated payoff with a discretisation using 2l\nuniform timesteps,\nL\n\nE(P\u0302L ) = E(P\u03020 ) + \u2211 E(P\u0302l \u2212 P\u0302l\u22121 )\n\n(2)\n\nl=1\n\nWe then use Monte Carlo estimators using Nl independent samples\n1\nNl\n\nE(P\u0302l \u2212 P\u0302l\u22121 ) \u2248 \u0176l =\n(i)\n\nNl\n\n(i)\n\n\u2211 (P\u0302l\n\n(i)\n\n\u2212 P\u0302l\u22121 )\n\n(3)\n\ni=1\n\n(i)\n\nThe small corrective term P\u0302l \u2212 P\u0302l\u22121 comes from the difference between a fine and a coarse\ndiscretisation of the same leading Brownian motion. Its magnitude depends on the strong\nconvergence properties of the scheme used. Let Vl be the variance of a single sample\n(i)\n(i)\nP\u0302l \u2212 P\u0302l\u22121 . The next theorem shows that what determines the efficiency of the multilevel\napproach is the convergence speed of Vl as l \u2192 \u221e.\nTo ensure a better efficiency we may modify (3) and use different estimators of P\u0302 on\nthe fine and coarse levels of \u0176l as long as the telescoping sum property is respected, that is\nL\n\nc\nE(P\u0302L ) = E(P\u03020 ) + \u2211 E(P\u0302l f \u2212 P\u0302l\u22121\n)\n\n(4)\n\nl=1\n\nwith\nE(P\u0302l f ) = E(P\u0302lc ).\n\n(5)\n\nTheorem 1.1. Let P be a function of a solution to (1) for a given Brownian path W (t); let\nP\u0302l be the corresponding approximation using the discretisation at level l, i.e. with 2l steps\nof width hl = 2\u2212l T .\nIf there exist independent estimators \u0176l of computational complexity Cl based on Nl\nsamples and there are positive constants \u03b1 \u2265 12 , \u03b2 , c1 , c2 , c3 such that\n\u001a\nE(P\u03020 )\nif l = 0\n1. E(\u0176l ) =\nE(P\u0302l \u2212 P\u0302l\u22121 ) if l > 0\n2. |E(P\u0302l \u2212 P)| \u2264 c1 h\u03b1l\n3. V(\u0176l ) \u2264 c2 hl Nl\u22121\n\u03b2\n\n4. Cl \u2264 c3 Nl h\u22121\nl\nThen there is a constant c4 such that for any \u03b5 < e\u22121 , there are values for L and Nl reL\n\nsulting in a multilevel estimator \u0176 = \u2211 \u0176l with a mean-square-error MSE = E((\u0176 \u2212 E(P))2 ) <\nl=0\n\n\u03b5 2 with a complexity C bounded by\n\n2\n\n\f\uf8f1\n\u22122\n\uf8f2 c4 \u03b5\nC\u2264\nc \u03b5 \u22122 (log \u03b5)2\n\uf8f3 4 \u22122\u2212(1\u2212\u03b2 )/\u03b1\nc4 \u03b5\n\nif \u03b2 > 1\nif \u03b2 = 1\nif 0 < \u03b2 < 1\n\n(6)\n\nProof. See [3].\nWe usually know \u03b1 thanks to the literature on weak convergence. Results in [6] give\n\u03b1 = 1 for the Milstein scheme, even in the case of discontinuous payoffs. \u03b2 is related\nto strong convergence and is practically what determines the efficiency of the multilevel\napproach. Its value depends on the payoff shape and is usually not known a priori.\n\n1.2\n\nMonte Carlo Greeks\n\nLet us briefly recall two classic methods used to compute Greeks in a Monte Carlo setting:\nthe pathwise sensitivities and the Likelihood Ratio Method. More details can be found in\n[5].\n\nPathwise sensitivities\nLet \u015c = (\u015cn )n\u2208[0,N] be the simulated values of the asset at the discretisation times and\n\u0174 = (\u0174n )n\u2208[1,N] be the corresponding set of Brownian increments. Assuming that the\npayoff P(\u015c) is Lipschitz, we can use the chain rule and write\n\u2202 V\u0302\n\u2202\n=\n\u2202\u03b8\n\u2202\u03b8\n\nZ\n\nZ\n\nP(\u015c(\u03b8 , \u0174 )) p(\u0174 )d\u0174 =\n\nN\n\n\u2202 P(\u015c) \u2202 \u015c(\u03b8 , \u0174 )\np(\u0174 )d\u0174\n\u2202\u03b8\n\u2202 \u015c\n\nN\n\nwhere d\u0174 = \u220f d\u0174k and p(\u0174 ) = \u220f p(\u0174k ) is a multivariate Normal probability density\nk=1\n\nk=1\n\nfunction.\n\u2202 \u015c\nby differentiating the discretisation of (1) with respect to \u03b8 and iterating\nWe obtain\n\u2202\u03b8\nthe resulting formula.The limitation of this technique is that it requires the payoff to be\nLipschitz and piecewise differentiable.\n\nLikelihood Ratio Method\nThe Likelihood Ratio Method consists in writing\n\u0002\n\u0003 Z\nV = E P(\u015c) = P(\u015c)p(\u03b8 , \u015c) d\u015c\n\n(7)\n\nThe dependence on \u03b8 comes through the probability density function p(\u03b8 , \u015c); assuming\nsome conditions discussed in [5], we can write\n\u0014\n\u0015\nZ\nZ\n\u2202V\n\u2202 p(\u015c)\n\u2202 log p(\u015c)\n\u2202 log p(\u015c)\n= P(\u015c)\nd\u015c = P(\u015c)\np(\u015c) d\u015c = E P(\u015c)\n(8)\n\u2202\u03b8\n\u2202\u03b8\n\u2202\u03b8\n\u2202\u03b8\nN\n\nwith\n\nd\u015c = \u220f d\u015ck\n\nN\n\nand\n\nk=1\n\np(\u015c) = \u220f p(\u015ck |\u015ck\u22121 )\nk=1\n\nThe main limitation of the method is that the estimator's variance is O(N), becoming\ninfinite as we refine the discretisation.\n\n3\n\n\f1.3\n\nMultilevel Monte Carlo Greeks\n\nBy combining the elements of sections 1.1 and 1.2 together, we write\nL\n\u2202 E(P) \u2202 E(P\u0302L ) \u2202 E(P\u03020 )\n\u2202 E(P\u0302l \u2212 P\u0302l\u22121 )\n\u2202V\n=\n\u2248\n=\n+\u2211\n\u2202\u03b8\n\u2202\u03b8\n\u2202\u03b8\n\u2202\u03b8\n\u2202\u03b8\nl=1\n\n(9)\n\nAs in (3), we define the multilevel estimators\n\u01760 =\n\nwhere\n\n2\n\nN0\u22121\n\nM\n\n\u2202 P\u03020\n\u2211 \u2202\u03b8\ni=1\n\n(i)\n\nand\n\n\u0176l =\n\nNl\u22121\n\nNl\n\n\u2202 P\u0302l\n\u2211( \u2202 \u03b8\ni=1\n\n(i)\n\n(i)\n\n\u2202 P\u0302l\u22121\n\u2212\n)\n\u2202\u03b8\n\n(10)\n\n\u2202 P\u03020 \u2202 P\u0302l\u22121 \u2202 P\u0302l\n,\n,\nare computed with the techniques presented in section 1.2.\n\u2202\u03b8 \u2202\u03b8 \u2202\u03b8\n\nEuropean call\n\nWe first consider a Lipschitz payoff. That of the European call is\nP = (ST \u2212 K)+ = max(0, ST \u2212 K)\nWe illustrate the techniques by computing delta (\u03b4 ) and vega (\u03bd), the sensitivities to the\nasset's initial value S0 and to its volatility \u03c3 .\n\n2.1\n\nPathwise sensitivities\n\nWe consider the Black-Scholes model: the asset's evolution is modelled by a geometric\nBrownian motion dS(t) = r S(t)dt + \u03c3 S(t)dWt . We use the Milstein scheme for its good\nstrong convergence properties. For timesteps of width h,\n\u0013\n\u0012\n\u03c32\n2\n\u015cn+1 = \u015cn * 1 + r h + \u03c3 \u2206Wn +\n(\u2206Wn \u2212 h) := \u015cn * Dn\n(11)\n2\nSince the payoff is Lipschitz, we can use pathwise sensitivities. The differentiation of\nequation (11) gives\n\uf8f1\n\uf8f4\n\u2202 \u015c\n\u2202 \u015cn+1 \u2202 \u015cn\n\uf8f4\n\uf8f2 0 = 1,\n=\n* Dn\n\u2202 S0\n\u2202 S0\n\u2202 S0\n(12)\n\uf8f4\n\uf8f4 \u2202 \u015c0 = 0, \u2202 \u015cn+1 = \u2202 \u015cn * D + \u015c \u2206W + \u03c3 (\u2206W 2 \u2212 h)\u0001\n\uf8f3\nn\nn\nn\nn\n\u2202\u03c3\n\u2202\u03c3\n\u2202\u03c3\nTo compute \u0176l we use a fine and a coarse discretisation with N f = 2l and Nc = 2l\u22121 uniform\ntimesteps respectively. We denote these by the superscripts (l) and (l\u22121) . We take Nl samples\nto compute\n\uf8f9\n\uf8ee\uf8eb\n\uf8f6(l)\n!\n(i)\n(i) (l\u22121)\nNl\n1\n\u2202 P \u2202 \u015cNc\n\uf8ef\uf8ed \u2202 P \u2202 \u015cN f \uf8f8\n\uf8fa\n\u0176l =\n\u2212\n\uf8f0\n\uf8fb\n\u2211\nNl i=1\n\u2202 SN f \u2202 \u03b8\n\u2202 SNc \u2202 \u03b8\nWe use the same leading Brownian motion for the fine and coarse discretisations: we\nfirst generate the fine Brownian increments \u0174 = (\u2206W1 , \u2206W2 , . . . , \u2206WN f ) and then use \u0174 c =\n(\u2206W1 + \u2206W2 , . . . , \u2206WN f \u22121 + \u2206WN f ) as the coarse level's increments.\n\n4\n\n\fEstimated complexity and analysis\nUnless otherwise stated, the simulations used to illustrate this paper use the parameters\nS0 = 100, K = 100, r = 0.05, \u03c3 = 0.20, T = 1.\nIn figure 1 we plot (V(\u0176l )) as a function of (1/hl ) in a log-log plot. We then measure\nthe slopes for the different estimators: this gives a numerical estimate of the parameter \u03b2\nin theorem 1.1. Combining this with the theorem, we get an estimated complexity of the\nmultilevel algorithm (table 1). This gives the following results :\n\nFigure 1: Pathwise sensitivities, European call : V(\u0176l )(l)\n\nTable 1: Pathwise sensitivities, European call : estimated complexity\nEstimator\n\u03b2\nValue\n\u2248 2.0\nDelta\n\u2248 0.8\nVega\n\u2248 1.0\n\nMLMC Complexity\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122.2 )\nO(\u03b5 \u22122 log \u03b5 2 )\n\nGiles has shown in [2] that \u03b2 = 2 for the value's estimator. For Greeks, the convergence is degraded by the discontinuity of \u2202\u2202 PS = 1S>K : a fraction O(hl ) of the paths\nhas a final value \u015c which is O(hl ) from the discontinuity K. For these paths, there is\n(l)\n(l\u22121)\na O(1) probability that \u015cN f and \u015cNc are on different sides of the strike K, implying\n\u0012\n\u0013(l) \u0010\n\u0011(l\u22121)\n\u2202 P \u2202 \u015cN f\n\u2202 P \u2202 \u015cNc\n\u2212\n= O(1). Thus V(\u0176l ) = O(hl ), and \u03b2 = 1 for the Greeks.\n\u2202 SN \u2202 \u03b8\n\u2202 SN \u2202 \u03b8\nf\n\nc\n\n5\n\n\f2.2\n\nPathwise sensitivities and Conditional Expectations\n\nWe have seen that the payoff's lack of smoothness prevents the variance of Greeks' estimators \u0176l from decaying quickly and limits the potential benefits of the multilevel approach. To improve the convergence speed, we can use conditional expectations [5]. Instead of simulating the whole path, we stop at the penultimate step and then\nfor every\n\u0001\nfixed set \u0174 = (\u2206Wk )k\u2208[1,N\u22121] , we consider the full distribution of \u015cN |\u0174 . With an =\n\u0001\n\u0001\na \u015cN\u22121 (\u0174 ), (N \u2212 1)h and bn = b \u015cN\u22121 (\u0174 ), (N \u2212 1)h , we can write\n\u015cN (\u0174 , \u0174N ) = \u015cN\u22121 (\u0174 ) + an (\u0174 )h + bn (\u0174 ) \u0174N\n\u0001\nWe hence get a normal distribution for \u015cN |\u0174 .\n\u015cN \u2212 \u03bc\u0174\n1\n\u221a exp \u2212\np(\u015cN |\u0174 ) =\n2\u03c3\u01742\n\u03c3\u0174 2\u03c0\n\n(13)\n\n\u00012 !\n(14)\n\n\u0001\n\u03bc\u0174 = \u015cN\u22121 + a \u015cN\u22121 , (N\u221a\n\u2212 1)h h\n\u0001\nwith\n\u03c3\u0174 = b \u015cN\u22121 , (N \u2212 1)h h\n\u0002\n\u0001 \u0003\nWe can thus compute E P \u015cN |\u0174 . Using the chain rule, we get\n\u001a\n\ni\n\u0002\n\u0003\u0003\n\u0002\n\u0003\n\u0002\n1 M h\n(m)\nE P(\u015cN )|\u0174 (m)\nV\u0302 = E P(\u015cN ) = E\u0174 E\u2206WN P(\u015cN )|\u0174 \u2248\n\u2211\nM m=1\n\n(15)\n\nHere with \u03c6 the normal probability density function,\n\u03a6 the normal cumulative distribu\u221a\ntion functions, \u03b1 = (1 + rh)\u015cN\u22121 (\u0174 ) and \u03b2 = \u03c3 h\u015cN\u22121 (\u0174 ), we get\n\u0012\n\u0013\n\u0012\n\u0013\n\u03b1 \u2212K\n\u03b1 \u2212K\nE(P(\u015cN )|\u0174 ) = \u03b2 \u03c6\n+ (\u03b1 \u2212 K) \u03a6\n(16)\n\u03b2\n\u03b2\nThis expected payoff is infinitely differentiable with respect to the input parameters. We\ncan apply the pathwise sensitivities technique to this smooth function at time (N \u2212 1) h. The\nmultilevel estimator for the Greek is then\n\uf8ee\n\uf8f9\n!\n!\n(i) (l)\n(i) (l\u22121)\nNl\n\u2202 P\u0302f\n1\n\u2202 P\u0302c\n\uf8fb\n\u0176l = \u2211 \uf8f0\n\u2212\n(17)\nNl 1\n\u2202\u03b8\n\u2202\u03b8\nAt the fine level we use (16) with h = h f and \u0174 f = (\u2206W1 , \u2206W2 , . . . , \u2206WN f \u22121 ) to get\nE(P(\u015cN f )|\u0174 f ) . We then use\n\u0012\n\n\u2202 P\u0302f\n\u2202\u03b8\n\n\u0013(l)\n=\n\n\u2202 \u015cN f \u22121 \u2202 E(P(\u015cN f )|\u0174 f ) \u2202 E(P(\u015cN f )|\u0174 f )\n+\n\u2202\u03b8\n\u2202 SN f \u22121\n\u2202\u03b8\n\n(18)\n\nAt the coarse level, directly using E(P(\u015cNc )|\u0174c ) leads to an unsatisfactorily low convergence rate of V(\u0176l ). As explained in (4) we use a modified estimator. The idea is to include\nthe final fine Brownian increment in the computation of the expectation over the last coarse\ntimestep. This guarantees that the two paths will be close to one another and helps achieve\nbetter variance convergence rates.\n\n6\n\n\f\u015c still follows a simple Brownian motion with constant drift and volatility on all coarse\nsteps. With \u0174c = (\u2206W1 + \u2206W2 , . . . , \u2206WN f \u22123 + \u2206WN f \u22122 ) and given that the Brownian increment on the first half of the final step is \u2206WN f \u22121 , we get\n\u00012 !\n\u015cNc \u2212 \u03bc\u0174c\n1\n\u221a exp \u2212\np(\u015cNc |\u0174c , \u2206WN f \u22121 ) =\n(19)\n2\u03c3\u01742\n\u03c3\u0174c 2\u03c0\nc\n(\n\u0001\n\u0001\n\u03bc\u0174c = \u015cNc \u22121 (\u0174c ) + a \u015cNc \u22121 ,p\n(Nc \u2212 1)hc hc + b \u015cNc \u22121 , (Nc \u2212 1)hc \u2206WN f \u22121\n\u0001\nwith\n\u03c3\u0174c = b \u015cNc \u22121 , (Nc \u2212 1)hc\nhc /2\n\u0002\n\u0003\nFrom this distribution we derive E P(\u015cNc )|\u0174c , \u2206WN f \u22121 , which leads to the same payoff\nformula\nas\nbefore\nwith\n\u03b1c = (1 + r hc + \u03c3 \u2206WN f \u22121 ) \u015cNc \u22121 (\u0174c )\nand\np\n\u03b2c = \u03c3 hc \u015cNc \u22121 (\u0174c ). Using it as the coarse level's payoff does not introduce any bias.\nUsing the tower property we check that it satisfies condition (5),\n\u0002 \u0002\n\u0003 \u0003\n\u0002\n\u0003\nE\u2206WN f \u22121 E P(\u015cNc )|\u0174c , \u2206WN f \u22121 |\u0174c = E P(\u015cNc )|\u0174c\n\nEstimated complexity and analysis\nOur numerical experiments show the benefits of the conditional expectation technique on\nthe European call:\n\nFigure 2: Pathwise sensitivities and conditional expectations,\nEuropean call : V(\u0176l )(l)\n\n7\n\n\fTable 2: Pathwise sensitivities and conditional expectations,\nEuropean call : estimated complexity\nEstimator\n\u03b2\nValue\n\u2248 2.0\nDelta\n\u2248 1.5\nVega\n\u2248 2.0\n\nMLMC Complexity\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122 )\n\n\u221a\nA fraction O( hl ) of the paths arrive in the area around the strike where the conditional\n\u2202 E(P(\u015cN )|\u0174 )\n\u22121/2\nexpectation\nis neither close to 0 nor 1. In this area, its slope is O(hl\n). The\n\u2202 \u015cN f \u22121\n\u221a\ncoarse and fine paths differ by O(hl ), we thus have O( hl ) difference between the coarse\n3/2\nand fine Greeks' estimates. Reasoning as in [2] we get V\u0174 (E\u2206WN (...|\u0174 )) = O(hl ) for the\nGreeks' estimators. This is the convergence rate observed for \u03b4 ; the higher convergence\nrate of \u03bd is not explained yet by this rough analysis and will be investigated in our future\nresearch.\nThe main limitation of this approach is that in many situations it leads to complicated\nintegral computations. Path splitting, to be discussed next, may represent a useful numerical\napproximation to this technique.\n\n2.3\n\nSplit pathwise sensitivities\n\nThis\n\u0002 technique\u0003 is based\n\u0002 on the previous one.\n\u0003 The idea is to avoid the tricky computation of\nE P(\u015cN f )|\u0174 f and E P(\u015cNc )|\u0174c , \u2206WN f \u22121 . We get numerical estimates of these values by\n\"splitting\" every path simulation on the final timestep.\nAt the fine level: for every simulated path \u0174 f = (\u2206W1 , \u2206W2 , . . . , \u2206WN f \u22121 ), we simulate\n(i)\n\na set of d final increments (\u2206WN f )i\u2208[1,d] which we average to get\n\u0002\n\u0003 1\nE P(\u015cN f )|\u0174 f \u2248\nd\n\nd\n\n(i)\n\n\u2211 P(\u015cN (\u0174 f , \u2206WN\nf\n\nf\n\n))\n\n(20)\n\ni=1\n\nAt the coarse level we use \u0174c = (\u2206W1 + \u2206W2 , . . . , \u2206WN f \u22123 + \u2206WN f \u22122 ). As before (still\nassuming a constant drift and volatility on the final coarse step),\n\u0002 we improve\n\u0003 the convergence rate of V(\u0176l ) by reusing \u2206WN f \u22121 in our estimation of E P(\u015cNc )|\u0174c . We can do\n(i)\n\n(i)\n\nso by constructing the final coarse increments as (\u2206WNc )i\u2208[1,d] = (\u2206WN f \u22121 + (\u2206WN f ))i\u2208[1,d]\nand using these to estimate\n\u0002\n\u0003 1\nE(P(\u015cNc )|\u0174c ) = E P(\u015cNc )|\u0174c , \u2206WN f \u22121 \u2248\nd\n\nd\n\n(i)\n\n\u2211 P(\u015cN (\u0174c , \u2206WN\nc\n\nc\n\n))\n\ni=1\n\nTo get the Greeks, we simply compute the corresponding pathwise sensitivities.\n\nEstimated complexity and choice of the number of splittings\nAs expected this method yields higher values of \u03b2 than simple pathwise sensitivities: the\nconvergence rates increase and tend to the rates offered by conditional expectations as d\nincreases and the approximation gets more precise.\n\n8\n\n\fFigure 3: Pathwise sensitivities and path splitting,\nEuropean call : V(\u0176l )(l)\n\nTable 3: Pathwise sensitivities and path splitting,\nEuropean call : estimated complexity\nEstimator\nValue\nDelta\nVega\n\nd\n10\n500\n10\n500\n10\n500\n\n\u03b2\n\u2248 2.0\n\u2248 2.0\n\u2248 1.0\n\u2248 1.5\n\u2248 1.6\n\u2248 2.0\n\nMLMC Complexity\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122 (log \u03b5)2 )\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122 )\n\nTaking a constant number of splittings d for all levels is actually not optimal; For\nGreeks, we can write the variance of the estimator as\n\u0013(l) \u0012\n\u0013(l\u22121)\n\u0012\n\u2202 P\u0302f\n1\n\u2202 P\u0302c\nV(\u0176l ) = V\u0174 f (E(\n\u2212\n|\u0174 f ))\nNl\n\u2202\u03b8\n\u2202\u03b8\n\u0012\n\u0013(l) \u0012\n\u0013(l\u22121)\n\u2202 P\u0302f\n1\n\u2202 P\u0302c\n+\nE (V(\n|\u0174 f ))\n\u2212\nNl d \u0174 f\n\u2202\u03b8\n\u2202\u03b8\n3/2\n\n(21)\n\nAs explained in section 2.2 we have V\u0174 f (E(...|\u0174 f )) = O(hl ) for the Greeks. We also\n\n9\n\n\fhave E\u0174 f (V(...|\u0174 f )) = O(hl ) for similar reasons. We optimise the variance at a fixed computational cost by choosing d such that the two terms of the sum are of similar order. Taking\n\u22121/2\nd = O(hl\n) is therefore optimal.\n\n2.4\n\nVibrato Monte Carlo\n\nSince the previous method uses pathwise sensitivity analysis, it is not applicable when\npayoffs are discontinuous. To address this limitation, we use the Vibrato Monte Carlo\nmethod introduced by Giles [4]. This hybrid method combines pathwise sensitivities and\nthe Likelihood Ratio Method.\nWe consider again equation (15). We now use the Likelihood Ratio Method on the last\ntimestep and with the notations of section 2.2 we get\n\u0014\n\u0014\n\u0015\u0015\n\u0001 \u2202 (log p(\u015cN |\u0174 ))\n\u2202 V\u0302\n= E\u0174 E\u2206WN P \u015cN\n|\u0174\n(22)\n\u2202\u03b8\n\u2202\u03b8\nWe can write p(\u015cN |\u0174 )) as p(\u03bc\u0174 , \u03c3\u0174 ). This leads to the estimator\n\u2202 V\u0302\n1\n\u2248\n\u2202\u03b8\nNl\n\nNl\n\n\u2211\n\nm=1\n\n\u0014\n\u0015\n\u0001 \u2202 (log p) (m)\n\u2202 \u03bc\u0174 (m)\nE\u2206WN P \u015cN\n|\u0174\n(\n\u2202\u03b8\n\u2202 \u03bc\u0174\n\u0014\n\u0015\n\u0001 \u2202 (log p) (m)\n\u2202 \u03c3\u0174 (m)\n+\nE\u2206WN P \u015cN\n|\u0174\n)\n\u2202\u03b8\n\u2202 \u03c3\u0174\n\n(23)\n\n\u2202 \u03bc\u0174 (m)\n\u2202 \u03c3\u0174 (m)\nand\nwith pathwise sensitivities.\n\u2202\u03b8\n\u2202\u03b8\n(m,i)\n(i)\nWith \u015cN = \u015cN (\u0174 (m) , \u2206WN ), we substitute the following estimators into (23)\n\nWe compute\n\n\uf8f1\n!\n\u0015\n\u0014\n\u0010\n\u0011 \u015c(m,i) \u2212 \u03bc (m)\nd\n\uf8f4\n\u0001 \u2202 (log p) (m)\n1\n\uf8f4\n(m,i)\nN\n\u0174\n\uf8f4\n\u2248 \u2211 P \u015cN\n|\u0174\nE\u2206WN P \u015cN\n\uf8f4\n\uf8f4\n\uf8f4\n\u2202 \u03bc\u0174\nd i=1\n\u03c3\u01742 (m)\n\uf8f2\n\uf8eb\n\u0010\n\u00112 \uf8f6\n(m,i)\n\u0014\n\u0015\n\u0010\n\u0011\n\u015cN \u2212 \u03bc\u0174 (m) \uf8f7\n\uf8f4\n\u0001 \u2202 (log p) (m)\n1 d\n1\n\uf8f4\n(m,i) \uf8ec\n\uf8f4\nE\u2206WN P \u015cN\n|\u0174\n\u2248 \u2211 P \u015cN\n+\n\uf8f4\n\uf8f8\n\uf8ed\u2212\n\uf8f4\n\uf8f4\n\u2202 \u03c3\u0174\nd i=1\n\u03c3\u0174 (m)\n\u03c3\u01743 (m)\n\uf8f3\nIn a multilevel setting: at the fine level we can use (23) directly. At the coarse level, for\nthe same reasons as in section 2.3, we reuse the fine brownian increments to get efficient\nestimators. We take\n(\n\u0174c = (\u2206W1 + \u2206W2 , . . . , \u2206WN f \u22123 + \u2206WN f \u22122 )\n(24)\n(i)\n(i)\n(\u2206WNc )i\u2208[1,d] = (\u2206WN f \u22121 + (\u2206WN f ))i\u2208[1,d]\nWe use the chain rule to verify that condition (5) is verified on the last coarse step. With\n\n10\n\n\fthe notations of equation (19) we derive the following estimators\n#\n#\n#\n\" \"\n\"\n\u0001 \u2202 (log pc ) (m)\n\u0001 \u2202 (log pc ) (m)\n(m)\n|\u0174c\n= E E P \u015cNc\n|\u0174c , \u2206WN f \u22121 |\u0174c\nE\u2206WNc P \u015cNc\n\u2202 \u03bc\u0174c\n\u2202 \u03bc\u0174c\n\uf8eb\n\uf8f6\n(m,i)\n\u0010\n\u0011\nd\n\u015c\n\u2212\n\u03bc\n(m)\n1\nNc\n(m,i)\n\u0174c \uf8f8\n\u2248 \u2211 \uf8edP \u015cNc\n2\nd i=1\n\u03c3 (m)\n\u0174c\n#\n#\n#\n\" \"\n\"\n\u0001 \u2202 (log p) (m)\n\u0001 \u2202 (log p) (m)\n(m)\nE\u2206WNc P \u015cNc\n|\u0174c\n= E E P \u015cNc\n|\u0174c , \u2206WN f \u22121 |\u0174c\n\u2202 \u03c3\u0174c\n\u2202\u03c3\n\uf8eb \u0174c\n\u0010\n\u00112 \uf8f6\n(m,i)\n\u015cNc \u2212 \u03bc\u0174 (m) \uf8f7\n1 d \u0010 (m,i) \u0011 \uf8ec\n1\nc\n\u2248 \u2211 P \u015cNc\n+\n\uf8ed\u2212\n\uf8f8\n3\nd i=1\n\u03c3\u0174 (m)\n\u03c3 (m)\nc\n\n\u0174c\n\n(25)\n\nEstimated complexity\nOur numerical experiments show the following convergence rates for d = 10:\n\nFigure 4: Vibrato Monte Carlo, European call : V(\u0176l )(l)\n\n11\n\n\fTable 4: Vibrato Monte Carlo, European call : estimated complexity\nEstimator\n\u03b2\nValue\n\u2248 2.0\nDelta\n\u2248 1.5\nVega\n\u2248 2.0\n\nMLMC Complexity\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122 )\n\nAs in section 2.3, this is an approximation of the conditional expectation technique, and\nso getting the same convergence rates was expected.\n\n3\n\nEuropean digital call\n\nThe European digital call's payoff is P = 1ST >K . The discontinuity of the payoff makes the\ncomputation of Greeks more challenging. We cannot apply pathwise sensitivities, and so\nwe use conditional expectations or Vibrato Monte Carlo.\n\n3.1\n\nPathwise sensitivities and conditional expectations\n\nWith the same notation as in section 2.2 we compute the conditional expectations of the\ndigital call's payoff.\n\u0012\n\u0013\n\u0012\n\u0013\n\u03b1 \u2212K\n\u03b1c \u2212 K\nE(P(\u015cN f )|\u0174 ) = \u03a6\nE(P(\u015cNc )|\u0174c , \u2206WN f \u22121 ) = \u03a6\n\u03b2\n\u03b2c\nThe simulations give figure 5 and table 5.\n\nTable 5: Pathwise sensitivities and conditional expectations,\ndigital call : estimated complexity\nEstimator\n\u03b2\nValue\n\u2248 1.4\nDelta\n\u2248 0.5\nVega\n\u2248 0.6\n\nMLMC Complexity\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122.5 )\nO(\u03b5 \u22122.4 )\n\n12\n\n\fFigure 5: Pathwise sensitivities and conditional expectations,\ndigital call: V(\u0176l )(l)\n\n3.2\n\nVibrato Monte Carlo\n\nThe Vibrato technique can be applied in the same way as with the European call. We get\nfigure 6 and table 6.\n\nTable 6: Vibrato Monte Carlo, digital call : estimated complexity\nEstimator\n\u03b2\nValue\n\u2248 1.3\nDelta\n\u2248 0.3\nVega\n\u2248 0.5\n\n3.3\n\nMLMC Complexity\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122.7 )\nO(\u03b5 \u22122.5 )\n\nAnalysis\n\nThe analysis presented in section 2.2 explains why we expected \u03b2 = 3/2 for the value's\nestimator.\n\u221a\nA fraction O( h) of all paths arrive in the area around the payoff where\n(\u2202 E(P(\u015cN )|\u0174 )/\u2202 \u015cN\u22121 ) is not close to 0 ; there its derivative is O(h\u22121\nl ) and we have\n|\u015cN f \u2212 \u015cNc | = O(hl ). For these paths, we thus have O(1) difference between the fine and\ncoarse Greeks' estimates. This explains the experimental \u03b2 \u2248 1/2.\n\n13\n\n\fFigure 6: Vibrato Monte Carlo, digital call : V(\u0176l )(l)\n\n4\n\nEuropean lookback call\n\nThe lookback call's value depends on the values that the asset takes before expiry. Its payoff\nis P(T ) = (ST \u2212 min (St )).\nt\u2208[0,T ]\n\nAs explained in [2], the natural discretisation P\u0302 = (\u015cN \u2212 min \u015cn ) is not satisfactory. To\nn\nregain good convergence rates, we approximate the behaviour within each fine timestep\n[tn ,tn+1 ] of width h f as a simple Brownian motion with constant drift anf and volatility bnf\nf\nconditional on the simulated values \u015cnf and \u015cn+1\n. As shown in [5] we can then simulate the\nlocal minimum\n!\nr\u0010\n\u00112\n1\nf\nf\nf\nf\nf 2\nf\n(26)\n\u015cn + \u015cn+1 \u2212\n\u015cn+1 \u2212 \u015cn \u2212 2(bn ) h f logUn\n\u015cn,min =\n2\nwith Un a uniform random variable on [0, 1]. We define the fine level's payoff this way\nchoosing bnf = b(\u015cnf ,tn ) and considering the minimum over all timesteps to get the global\nminimum of the path.\nAt the coarse level we still consider a simple Brownian motion on each timestep of\nwidth hc = 2h f . To get high strong convergence rates, we reuse the fine increments by\ndefining a midpoint value for each step\nc\n\u015cn+1/2\n=\n\n\u0001\n1 c\nc\n\u015cn + \u015cn+1\n\u2212 bcn (\u2206Wn+1 \u2212 \u2206Wn+1/2 )\n2\n\n14\n\n(27)\n\n\fWhere (\u2206Wn+1 \u2212 \u2206Wn+1/2 ) is the difference of the corresponding fine Brownian increments\non [tn+1/2 ,tn+1 ] and [tn ,tn+1/2 ]. Conditional on this value, we then define the minimum over\nthe whole step as the minimum of the minimum over each half step, that is\n!\n\"\nr\u0010\n\u00112\n1\nc\nc\nc\nc\n\u2212 \u015cnc \u2212 (bcn )2 hc logU1,n ,\n\u015cn,min = min\n\u015cn + \u015cn+1/2 \u2212\n\u015cn+1/2\n2\n!#\nr\u0010\n\u00112\n1\nc\nc\nc\nc\n(28)\n\u015cn+1/2\n\u015cn+1\n\u2212 \u015cn+1/2\n\u2212 (bcn )2 hc logU2,n\n+ \u015cn+1\n\u2212\n2\nwhere U1,n and U2,n are the values we sampled to compute the minima of the corresponding\ntimesteps at the fine level. Once again we use the tower property to check that condition\n(5) is verified and that this coarse-level estimator is adequate.\n\n4.1\n\npathwise sensitivities\n\nUsing the treatment described above, we can then apply straighforward pathwise sensitivities to compute the multilevel estimator. This gives the following results:\n\nFigure 7: Pathwise sensitivities, lookback call : V(\u0176l )(l)\n\nGiles has proved that for the value's estimator, \u03b2 = 2 \u2212 \u03b7 for all \u03b7 > 0. In the Black &\nScholes model, we can prove that V = S0 \u03b4 . We therefore expected \u03b2 \u2248 2 for \u03b4 too. The\nstrong convergence speed of \u03bd's estimator cannot be derived that easily and will be analysed\nin our future research.\n\n15\n\n\fTable 7: Pathwise sensitivities, lookback call : estimated complexity\nEstimator\n\u03b2\nValue\n\u2248 1.9\nDelta\n\u2248 1.9\nVega\n\u2248 1.3\n\nMLMC Complexity\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122 )\n\n4.2 Conditional Expectations, path splitting or Vibrato Monte\nCarlo\nUnlike the regular call option, the payoff of the lookback call is perfectly smooth and so\ntherefore there is no benefit from using conditional expectations and associated methods.\n\n5\n\nEuropean barrier call\n\nBarrier options are contracts which are activated or deactivated when the underlying asset\nS reaches a certain barrier value B. We consider here the down-and-out call for which the\npayoff can be written as\nP = (ST \u2212 K)+ 1 min (S ) > K\n(29)\nt\u2208[0,T ]\n\nt\n\nBoth the naive estimators and the approach used with the lookback call are unsatisfactory here: the discontinuity induced by the barrier results in a higher variance than before.\nTherefore we use the approach developed in [2] where we compute the probability pn that\nthe minimum of the interpolant crosses the barrier within each timestep. This gives the\nconditional expectation of the payoff conditional on the Brownian increments of the fine\npath:\nN f \u22121\n\u0001\nP\u0302 f = (\u015cNf f \u2212 K)+ \u220f 1 \u2212 p\u0302nf\n(30)\nn=0\n\nwith\np\u0302nf = exp\n\nf\n\u22122(\u015cnf \u2212 B)+ (\u015cn+1\n\u2212 B)+\n\n!\n\n(bnf )2 h f\n\nc\nAt the coarse level we define the payoff similarly: we first simulate a midpoint value \u015cn+1/2\nc\nas before and then define p\u0302n the probability of not hitting B in [tn ,tn+1 ], that is the probability\nof not hitting B in [tn ,tn+1/2 ] and [tn+1/2 ,tn+1 ]. Thus\n\nP\u0302c = (\u015cNc c \u2212 K)+\n\nNc \u22121\n\n\u220f (1 \u2212 p\u0302cn ) = (\u015cNc\n\nc\n\nn=0\n\nwith\n\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2 p\u0302n,1 = exp\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3 p\u0302n,2 = exp\n\n\u2212 K)+\n\nNc \u22121\n\n\u220f ((1 \u2212 p\u0302n,1 )(1 \u2212 p\u0302n,2 ))\n\nn=0\n\nc\n\u22122(\u015cnc \u2212 B)+ (\u015cn+1/2\n\u2212 B)+\n\n!\n\n(bcn )2 h f\n!\nc\nc\n\u22122(\u015cn+1/2 \u2212 B)+ (\u015cn+1\n\u2212 B)+\n(bcn )2 h f\n\n16\n\n(31)\n\n\f5.1\n\nPathwise sensitivities\n\n\u0001(l)\n\u0001(l\u22121)\nThe multilevel estimators \u0176l = P\u0302 f\n\u2212 P\u0302c\nare Lipschitz with respect to all (\u015cnf )n=1...N f\nc\nand (\u015cn )n=1...Nc , so we can use pathwise sensitivities to compute the Greeks. Our numerical\nsimulations give\n\nFigure 8: Pathwise sensitivities, barrier call : V(\u0176l )(l)\n\nTable 8: Pathwise sensitivities, barrier call : estimated complexity\nEstimator\n\u03b2\nValue\n\u2248 1.6\nDelta\n\u2248 0.6\nVega\n\u2248 0.6\n\nMLMC Complexity\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122.4 )\nO(\u03b5 \u22122.4 )\n\n17\n\n\fGiles proved \u03b2 = 32 \u2212 \u03b7 (\u03b7 > 0) for the value's estimator. We are currently working on\na numerical analysis supporting the observed convergence rates for the Greeks.\n\n5.2\n\nConditional Expectations\n\nThe low convergence rates observed in the previous section come from from both the discontinuity at the barrier and from the lack of smoothness of the call around K. To address\nthe latter, we can use the techniques described in section 1. Since path splitting and Vibrato Monte Carlo offer rates that are at best equal to those of conditional expectations, we\nimplement conditional expectations to see the maximum benefits we can get.\nComputing conditional expectations is slightly trickier than in section 2. We must indeed take into account the probability that the path will hit the barrier B during the final\ntimestep. Reusing the notations of part 2.2 and defining\n\uf8f1\n\uf8f4\n\uf8f4 \u03b1\u0303 = 2B + (\u22121 + rh) \u015cN\u22121 (\u0174 )\n\uf8f2\nL = max(K, B)\n\u0012\n\u0013\n(32)\n2r(B \u2212 \u015cN\u22121 )\n\uf8f4\n\uf8f4\n\uf8f3 D(\u03c3 , \u015cN\u22121 ) = exp\n\u03c3 2 \u015cN\u22121\nat the fine level we get\n\u0013\n\u0013\n\u0012\n\u03b2\n\u03b1 \u2212L\n(L \u2212 \u03b1)2\n(33)\n+ \u221a exp \u2212\nE(P(\u015cN |\u0174 )) =(\u03b1 \u2212 K)\u03a6\n\u03b2\n2\u03b2 2\n2\u03c0\n\u0014\n\u0012\n\u0013\u0015\n\u0013\n\u0012\n\u03b1\u0303 \u2212 L\n\u03b2\n(L \u2212 \u03b1\u0303)2\n\u2212 D(\u03c3 , \u015cN\u22121 ) (\u03b1\u0303 \u2212 K)\u03a6\n+ \u221a exp \u2212\n\u03b2\n2\u03b2 2\n2\u03c0\n\u0012\n\nAs before we then adapt this formula to the coarse level to compute\nE(P(\u015cNc )|\u0174c ) = E(E(P(\u015cNc )|\u0174c , \u2206WN f \u22121 )|\u0174c )\n\n(34)\n\nDoing so actually leads to long impractical formulae, especially when computing the Greeks.\nThe idea of the conditional expectation technique is to smoothen the payoff. We can quickly\nestimate the method's maximum benefits by replacing the true payoff by a smooth Lipschitz\napproximation: this introduces a bias but also eliminates all the problems due to the lack of\nregularity around the strike.\nFor example we can replace the payoff P = (ST \u2212 K)+ 1 min (S ) > K by the smooth\nt\u2208[0,T ]\n\nt\n\napproximation\n\u0012\n\u0012\n\u0013\n\u0012\n\u0013\u0013\n\u03b2\n(K \u2212 ST )2\nST \u2212 K\nP\u0303 = \u221a exp \u2212\n1 min (S ) > K\n+ (ST \u2212 K)\u03a6\nt\n2\u03b2 2\n\u03b2\n2\u03c0\nt\u2208[0,T ]\n\n(35)\n\n\u221a\nwhere \u03b2 = \u03c3 h\u2217 ST for some arbitrary h\u2217 that controls the width of the smoothing. For\nexample we take h\u2217 = 1/64 and we obtain the following results:\nWe see in figure 9 and table 9 that the maximum benefits of these techniques are only\nmarginal. The barrier appears to be responsible for most of the variance of the multilevel\nestimators.\n\n18\n\n\fFigure 9: Pathwise sensitivities and payoff smoothing,\nbarrier call : V(\u0176l )(l)\n\nTable 9: Pathwise sensitivities and payoff smoothing,\nbarrier call : estimated complexity\nEstimator\n\u03b2\nValue\n\u2248 1.7\nDelta\n\u2248 0.7\nVega\n\u2248 0.7\n\n5.3\n\nMLMC Complexity\nO(\u03b5 \u22122 )\nO(\u03b5 \u22122.3 )\nO(\u03b5 \u22122.3 )\n\nNon-constant timestepping\n\nAs illustrated in figure 10, the level at which V(\u0176l ) reaches its asymptotic convergence\nspeed depends on the value of B. When B is far from S0 , the regime appears quickly (figure\n10a), when B gets closer to S0 , it takes longer (figure 10b). Practically this can be a problem\nwhen B \u2248 S0 as the simulations may not reach the very fine levels at which the complexity\nanalysis based on the asymptotic value of \u03b2 is relevant.\nIn the case represented in figure 10b the variance first increases before eventually converging towards 0. This illustrates the fact that in some cases it may be interesting to start\nthe multilevel algorithm at a level l > 0 where problems related specifically to coarseness\ndo not appear and where the variance is low enough for our application (it must be at least\nlower than than the variance of the equivalent monolevel estimator).\nThe variance's bad behaviour is related to the distribution of paths leaking out of the\n\n19\n\n\fFigure 10: Pathwise sensitivities (Vega), barrier call : V(\u0176l )(l)\n(a) B = 85, S0 = 100\n\n(b) B = 95, S0 = 100\n\nbarrier over time: we plot in figure 11 the density of first barrier crossings on the time\ninterval [0, T ]. We can show analytically that the width of the observed \"peak\" of the\n\nFigure 11: Density of first barrier crossings on [0,1]\n(a) B = 85, S0 = 100\n\n(b) B = 95, S0 = 100\n\ncrossing density function is\n\u0012\n\nlog(S0 /B)\n\u03c4 =O\n\u03c3\n\n\u00132\n(36)\n\nThis means that as B tends to S0 , almost all paths going \"down and out\" do so in a very short\ntime interval [0, \u03c4]. On timesteps [tn ,tn+1 ] outside of this interval, most paths are far away\nfrom the barrier and both \u2202\u2202p\u0302\u03b8n and \u2202\u2202p\u03b8n are close to 0 and hardly contribute to the variance\nof the multilevel estimator.\nMorally the problem at the low levels is that the timesteps are much too large compared\nto the characteristic time \u03c4: the interval that is responsible for most of V(\u0176l ) is covered by\nonly one step as long as hl \u2265 \u03c4.\nWe hope to address this issue with adapted timestepping. Instead of taking constant\ntimesteps of width h = T /N we use power timesteps to refine the discretisation in the time\n\n20\n\n\finterval [0, \u03c4]. We write t = u\u03b3 and then split [0, T (1/\u03b3) ] into equal steps of u. We want more\nsteps in [0, \u03c4]. Taking half of all timesteps in [0, \u03c4] means that we must choose \u03b3 such that\nu = 1/2 corresponds to \u03c4, that is\n\u0013\n\u0012 \u0013\u03b3 \u0012\nlog(S0 /B) 2\n1\n2\n=\n\u21d2\u03b3 =\n[log \u03c3 \u2212 log (log(S0 /B))]\n2\n\u03c3\nlog 2\n\n(37)\n\nFigure 12 shows for B = 95 the evolution of V(\u0176l ) for \u03b4 (fig. 12a) and for \u03bd (fig. 12b)\nwith constant timesteps (red) and with power timesteps (blue). We see that with power\ntimesteps, the variance is lower at fine levels and reaches its asymptotic convergence speed\nfaster than before. Nevertheless we note that these benefits may be practically cancelled\nby the higher variance of the method at the coarsest levels, especially if we need rough\nestimates and stay at very low levels.\n\nFigure 12: V(\u0176l ), B = 95, power (blue) and constant (red) steps\n(a) \u03b4\n\n(b) \u03bd\n\nConclusion and future work\nIn this paper we have shown for a range of cases how multilevel techniques could be used\nto reduce the computational complexity of Monte Carlo Greeks.\nSmoothing a Lipschitz payoff with conditional expectations reduces the complexity\ndown to O(\u03b5 \u22122 ). From this technique we derive the Path splitting and Vibrato methods:\nthey offer the same efficiency and avoid intricate integral computations. Payoff smoothing\nand Vibrato also enable us to extend the computation of Greeks to discontinuous payoffs\nwhere the pathwise sensitivity approach is not applicable. Numerical evidence shows that\nwith well-constructed estimators these techniques provide computational savings even with\nexotic payoffs.\nSo far we have mostly relied on numerical estimates of \u03b2 to estimate the complexity of\nthe algorithms. Our current analysis is somewhat crude ; this is why our current research\nnow focuses on getting a rigorous numerical analysis of the algorithms' complexity.\n\n21\n\n\fReferences\n[1]\n\nA. Asmussen and P. Glynn. Stochastic Simulation. Springer, New York, 2007.\n\n[2]\n\nM.B. Giles. Improved multilevel Monte Carlo convergence using the Milstein\nscheme. In A. Keller, S. Heinrich, and H. Niederreiter, editors, Monte Carlo and\nQuasi-Monte Carlo Methods 2006, pages 343\u2013358. Springer-Verlag, 2007.\n\n[3]\n\nM.B. Giles. Multilevel Monte Carlo path simulation. Operations Research, 56(3),\npages 607\u2013617, 2008.\n\n[4]\n\nM.B. Giles. Vibrato Monte Carlo sensitivities. In P. L'Ecuyer and A. Owen, editors,\nMonte Carlo and Quasi-Monte Carlo Methods 2008, pages 369\u2013382. Springer, 2009.\n\n[5]\n\nP. Glasserman. Monte Carlo Methods in Financial Engineering. Springer, New York,\n2004.\n\n[6]\n\nP.E. Kloeden and E. Platen. Numerical Solution of Stochastic Differential Equations.\nSpringer, Berlin, 1992.\n\n22\n\n\f"}