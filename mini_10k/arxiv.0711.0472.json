{"id": "http://arxiv.org/abs/0711.0472v1", "guidislink": true, "updated": "2007-11-03T19:30:25Z", "updated_parsed": [2007, 11, 3, 19, 30, 25, 5, 307, 0], "published": "2007-11-03T19:30:25Z", "published_parsed": [2007, 11, 3, 19, 30, 25, 5, 307, 0], "title": "Order estimation of Markov chains", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0711.4400%2C0711.3375%2C0711.1114%2C0711.3569%2C0711.2678%2C0711.0673%2C0711.1089%2C0711.0469%2C0711.4243%2C0711.3949%2C0711.4995%2C0711.1155%2C0711.2400%2C0711.1565%2C0711.4862%2C0711.1255%2C0711.4123%2C0711.4653%2C0711.4324%2C0711.0148%2C0711.1656%2C0711.1112%2C0711.3250%2C0711.3274%2C0711.0999%2C0711.1231%2C0711.2022%2C0711.4431%2C0711.3943%2C0711.4068%2C0711.1416%2C0711.0241%2C0711.4751%2C0711.0478%2C0711.3793%2C0711.0493%2C0711.0512%2C0711.2841%2C0711.2847%2C0711.2743%2C0711.3960%2C0711.1811%2C0711.2948%2C0711.1546%2C0711.3859%2C0711.1958%2C0711.4934%2C0711.4652%2C0711.1916%2C0711.2364%2C0711.3081%2C0711.2999%2C0711.3915%2C0711.1126%2C0711.0007%2C0711.3757%2C0711.0206%2C0711.2301%2C0711.4085%2C0711.2230%2C0711.4381%2C0711.3450%2C0711.0472%2C0711.1891%2C0711.3711%2C0711.1754%2C0711.3791%2C0711.4908%2C0711.0188%2C0711.1412%2C0711.2341%2C0711.4616%2C0711.2048%2C0711.1407%2C0711.4376%2C0711.3300%2C0711.2433%2C0711.0197%2C0711.4112%2C0711.4522%2C0711.2214%2C0711.2227%2C0711.4981%2C0711.1077%2C0711.1472%2C0711.1143%2C0711.3467%2C0711.2338%2C0711.2269%2C0711.0740%2C0711.3947%2C0711.0443%2C0711.1081%2C0711.4778%2C0711.1709%2C0711.2436%2C0711.2432%2C0711.2805%2C0711.4191%2C0711.3181%2C0711.0709&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Order estimation of Markov chains"}, "summary": "We describe estimators $\\chi_n(X_0,X_1,...,X_n)$, which when applied to an\nunknown stationary process taking values from a countable alphabet ${\\cal X}$,\nconverge almost surely to $k$ in case the process is a $k$-th order Markov\nchain and to infinity otherwise.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0711.4400%2C0711.3375%2C0711.1114%2C0711.3569%2C0711.2678%2C0711.0673%2C0711.1089%2C0711.0469%2C0711.4243%2C0711.3949%2C0711.4995%2C0711.1155%2C0711.2400%2C0711.1565%2C0711.4862%2C0711.1255%2C0711.4123%2C0711.4653%2C0711.4324%2C0711.0148%2C0711.1656%2C0711.1112%2C0711.3250%2C0711.3274%2C0711.0999%2C0711.1231%2C0711.2022%2C0711.4431%2C0711.3943%2C0711.4068%2C0711.1416%2C0711.0241%2C0711.4751%2C0711.0478%2C0711.3793%2C0711.0493%2C0711.0512%2C0711.2841%2C0711.2847%2C0711.2743%2C0711.3960%2C0711.1811%2C0711.2948%2C0711.1546%2C0711.3859%2C0711.1958%2C0711.4934%2C0711.4652%2C0711.1916%2C0711.2364%2C0711.3081%2C0711.2999%2C0711.3915%2C0711.1126%2C0711.0007%2C0711.3757%2C0711.0206%2C0711.2301%2C0711.4085%2C0711.2230%2C0711.4381%2C0711.3450%2C0711.0472%2C0711.1891%2C0711.3711%2C0711.1754%2C0711.3791%2C0711.4908%2C0711.0188%2C0711.1412%2C0711.2341%2C0711.4616%2C0711.2048%2C0711.1407%2C0711.4376%2C0711.3300%2C0711.2433%2C0711.0197%2C0711.4112%2C0711.4522%2C0711.2214%2C0711.2227%2C0711.4981%2C0711.1077%2C0711.1472%2C0711.1143%2C0711.3467%2C0711.2338%2C0711.2269%2C0711.0740%2C0711.3947%2C0711.0443%2C0711.1081%2C0711.4778%2C0711.1709%2C0711.2436%2C0711.2432%2C0711.2805%2C0711.4191%2C0711.3181%2C0711.0709&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We describe estimators $\\chi_n(X_0,X_1,...,X_n)$, which when applied to an\nunknown stationary process taking values from a countable alphabet ${\\cal X}$,\nconverge almost surely to $k$ in case the process is a $k$-th order Markov\nchain and to infinity otherwise."}, "authors": ["G. Morvai", "B. Weiss"], "author_detail": {"name": "B. Weiss"}, "author": "B. Weiss", "links": [{"href": "http://arxiv.org/abs/0711.0472v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0711.0472v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0711.0472v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0711.0472v1", "arxiv_comment": null, "journal_reference": "IEEE Trans. Inform. Theory 51 (2005), no. 4, 1496--1497", "doi": null, "fulltext": "arXiv:0711.0472v1 [math.PR] 3 Nov 2007\n\nGuszt\u00e1v MORVAI and Benjamin WEISS:\n\nOrder Estimation of Markov Chains\n\nIEEE Trans. Inform. Theory 51 (2005), no. 4, 1496\u20131497.\n\nAbstract\nWe describe estimators \u03c7n (X0 , X1 , . . . , Xn ), which when applied\nto an unknown stationary process taking values from a countable alphabet X , converge almost surely to k in case the process is a k-th\norder Markov chain and to infinity otherwise.\n\nKeywords: Stationary processes, Markov chains, order estimation\nMathematics Subject Classifications (2000)62M05, 60G25, 60G10\n\n\f1\n\nIntroduction\n\nWhen faced with an unknown stationary and ergodic stochastic process\nX1 , X2 , . . . , Xn , . . . one may try to determine various properties of this process from the successive observations up to time n. For example, one might\ntry to estimate the entropy of the process. Several schemes of the form\ngn (X1 , . . . , Xn ) are known which will converge almost surely to the entropy\nof the process {Xn } cf. Bailey [1], Csisz\u00e1r and Shields [2], Csisz\u00e1r [3], Ornstein and Weiss [8], [7], [9], Kontoyiannis, Algoet, Suhov and Wyner [6]\nand Ziv [10]. However, if one just wants to determine whether or not the\nprocess has positive entropy (often associated with the popular notion of\nchaos) then there is no sequence of two valued functions en (X1 , . . . , Xn ) \u2208\n{ZERO, P OSIT IV E} with the property that almost surely, en stabilize at\nZERO for all zero entropy processes and at P OSIT IV E for all positive\nentropy processes. (While this result does not appear explicitly in Ornstein\namd Weiss [7], it can be readily established using a very simple variant of\nthe construction given there in \u00a7 4.)\nA similar situation obtains in testing for membership in the class of k-th\norder Markov chains. One can estimate the order of a Markov chain by e.g\nthe method of Csisz\u00e1r and Shields [2] or Csisz\u00e1r [3]. They show that the\nminimum description length Markov estimator will converge almost surely\nto the correct order if the alphabet size is bounded a priori. Without this\nassumption they show that this is no longer true. To accomplish their goals\nthey study the large scale typicality of Markov sample paths. A further\nnegative result is that of Bailey [1] who showed that no two valued test\nexists for testing mixing Markov vs. not mixing Markov.\nWe will present a more direct estimator for the order of a Markov chain\nwhich also uses the fact that there are universal rates for the convergence\nof empirical k-block distributions in this class. Our approach enables us to\ndispense with the assumption that the alphabet size is bounded, indeed it\nmay even be infinite, as long as there is a finite memory. In addition we will\nshow that if the process is not a Markov chain then the estimate for the order\nwill tend to infinity. This is in complete analogy with the entropy estimation\nthat we mentioned earlier.\n\n1\n\n\f2\n\nThe Order Estimator\n\nLet {Xn }\u221e\nn=\u2212\u221e be a stationary and ergodic time series taking values from a\ndiscrete (finite or countably infinite) alphabet X . (Note that all stationary\ntime series {Xn }\u221e\nn=0 can be thought to be a two sided time series, that is,\n\u221e\nn\n{Xn }n=\u2212\u221e . ) For notational convenience, let Xm\n= (Xm , . . . , Xn ), where\nn\nm \u2264 n. Note that if m > n then Xm is the empty string.\n0\nLet p(x0\u2212k ) and p(y|x0\u2212k ) denote the distribution P (X\u2212k\n= x0\u2212k ) and the\n0\nconditional distribution P (X1 = y|X\u2212k\n= x0\u2212k ), respectively.\nA discrete alphabet stationary time series is said to be a Markov chain if for\n0\n0\nsome K \u2265 0, for all y \u2208 X , i \u2265 1 and z\u2212K\u2212i+1\n\u2208 X K+i , if p(z\u2212K\u2212i+1\n)>0\nthen\n0\n0\np(y|z\u2212K+1\n) = p(y|z\u2212K\u2212i+1\n).\nThe order of a Markov chain is the smallest such K.\nIn order to estimate the order we need to define some explicit statistics.\n0\nFor k \u2265 0 let Sk denote the support of the distribution of X\u2212k\nas\nSk = {x0\u2212k \u2208 X k+1 : p(x0\u2212k ) > 0}.\nDefine\n\u2206k = sup\n\nsup\n\n1\u2264i (z 0\n,x)\u2208Sk+i\n\u2212k\u2212i+1\n\n0\n0\np(x|z\u2212k+1\n) \u2212 p(x|z\u2212k\u2212i+1\n) .\n\u2308 n \u2309\u22121\n\nWe will divide the data segment X0n into two parts: X0 2\n\nand X\u2308nn \u2309 . Let\n\n(1)\n\n2\n\n\u2308 n \u2309\u22121\n\nSn,k denote the set of strings with length k + 1 which appear at all in X0 2\nThat is,\n\n.\n\nn\n(1)\nt\n= x0\u2212k }.\nSn,k = {x0\u2212k \u2208 X k+1 : \u2203k \u2264 t \u2264 \u2308 \u2309 \u2212 1 : Xt\u2212k\n2\n(2)\n\nFor a fixed 0 < \u03b3 < 1 let Sn,k denote the set of strings with length k + 1\nwhich appear more than n1\u2212\u03b3 times in X\u2308nn \u2309 . That is,\n2\n\nn\n(2)\nt\nSn,k = {x0\u2212k \u2208 X k+1 : #{\u2308 \u2309 + k \u2264 t \u2264 n : Xt\u2212k\n= x0\u2212k } > n1\u2212\u03b3 }.\n2\nLet\n\n(1)\n\nSkn = Sn,k\n2\n\n\\\n\n(2)\n\nSn,k .\n\n\f0\nFor notational convenience, let C(x|z\u2212k+1\n: [n1 , n2 ]) denote the empirical\n0\n0\nconditional probability of X1 = x given X\u2212k+1 = z\u2212k+1\nfrom the samples\n(Xn1 , . . . , Xn2 ), that is,\n0\nC(x|z\u2212k+1\n: [n1 , n2 ]) =\n\nt\n0\n#{n1 + k \u2264 t \u2264 n2 : Xt\u2212k\n= (z\u2212k+1\n, x)}\nt\n0\n#{n1 + k \u2212 1 \u2264 t \u2264 n2 \u2212 1 : Xt\u2212k+1\n= z\u2212k+1\n}\n\nwhere 0/0 is defined as 0.\nWe define the empirical version of \u2206k as follows:\n\u02c6 nk = max\n\u2206\n\n1\u2264i\u2264n\n\nmax\n\n0\nn\n(z\u2212k\u2212i+1\n,x)\u2208Sk+i\n\nn\nn\n0\n0\nC(x|z\u2212k+1\n: [\u2308 \u2309, n]) \u2212 C(x|z\u2212k\u2212i+1\n: [\u2308 \u2309, n]) .\n2\n2\n\nObserve, that by ergodicity, for any fixed k,\n\u02c6 n \u2265 \u2206k almost surely.\nlim inf \u2206\nk\nn\u2192\u221e\n\n(1)\n\nWe define an estimate \u03c7n for the order from samples X0n as follows. Let\nbe arbitrary. Set \u03c70 = 0, and for n \u2265 1 let \u03c7n be the smallest\n0 < \u03b2 < 1\u2212\u03b3\n2\n\u02c6 n \u2264 n\u2212\u03b2 .\n0 \u2264 kn < n such that \u2206\nkn\nTHEOREM. If the stationary and ergodic time series {Xn } taking values\nfrom a discrete alphabet happens to be a Markov chain with any finite order\nthen \u03c7n equals to the order eventually almost surely, and if it is not Markov\nwith any finite order then \u03c7n \u2192 \u221e almost surely.\nApplication: Let M > 0 be arbitrary. The goal is to decide if the discrete\nalphabet stationary and ergodic time series is a Markov chain with order\nless than M or not. One may use \u03c7n and say YES if \u03c7n < M and say NO\notherwise. By the Theorem, eventually, the answer will be correct.\n\n3\n\nProof of the Theorem\n\nProof: If the process is a Markov chain, it is immediate that for all k greater\nthan or equal the order, \u2206k = 0. For k less than the order \u2206k > 0. If the\nprocess is not a Markov chain with any finite order then \u2206k > 0 for all k.\nThus by (1) if the process is not Markov then \u03c7n \u2192 \u221e and if it is Markov\n3\n\n\fthen \u03c7n is greater or equal the order eventually almost surely. We have to\nshow that \u03c7n is less or equal the order eventually almost surely provided that\nthe process is a Markov chain.\nAssume that the process is a Markov chain with order k. Let n \u2265 k. We will\nestimate the probability of the undesirable event as follows:\nn\n\n\u02c6 n > n\u2212\u03b2 |X0\u2308 2 \u2309 ) \u2264\nP (\u2206\nk\nn\nX\ni=1\n\nP(\n\nmax\n\n0\nn\n(z\u2212k\u2212i+1\n,x)\u2208Sk+i\n\nn\nn\n\u2308n\u2309\n0\n0\n: [\u2308 \u2309, n]) > n\u2212\u03b2 |X0 2 ).\nC(x|z\u2212k+1\n: [\u2308 \u2309, n]) \u2212 C(x|z\u2212k\u2212i+1\n2\n2\n\nWe can estimate each probability in the sum as the sum of two terms:\nn\nn\n\u2309\n\u2308n\n0\n0\n\u2212\u03b2\n2\nC(x|z\n:\n[\u2308\n\u2309,\nn])\n\u2212\nC(x|z\n:\n[\u2308\n\u2309,\nn])\n>\nn\n|X\n0 )\n\u2212k+1\n\u2212k\u2212i+1\n0\nn\n2\n2\n(z\u2212k\u2212i+1 ,x)\u2208Sk+i\nn\n\u2308n\u2309\n0\n0\n) > 0.5n\u2212\u03b2 |X0 2 )\n: [\u2308 \u2309, n]) \u2212 p(x|z\u2212k+1\n\u2264 P ( 0 max n C(x|z\u2212k+1\n2\n(z\u2212k\u2212i+1 ,x)\u2208Sk+i\nn\n\u2308n\u2309\n0\n0\n) \u2212 C(x|z\u2212k\u2212i+1\n: [\u2308 \u2309, n]) > 0.5n\u2212\u03b2 |X0 2 ).\n+ P ( 0 max n p(x|z\u2212k+1\n(z\u2212k\u2212i+1 ,x)\u2208Sk+i\n2\n\nP(\n\nmax\n\nWe overestimate these probabilities. For any m \u2265 0 and x0\u2212m define \u03c3im (x0\u2212m )\nas the time of the i-th ocurrence of the string x0\u2212m in the data segment X\u2308nn \u2309 ,\n2\nthat is, let \u03c30m (x0\u2212m ) = \u2308 n2 \u2309 + m \u2212 1 and for i \u2265 1 define\nm\nt\n\u03c3im (x0\u2212m ) = min{t > \u03c3i\u22121\n(x0\u2212m ) : Xt\u2212m\n= x0\u2212m }.\n\nNow\nn\nn\n\u2309\n\u2308n\n0\n0\n\u2212\u03b2\n2\n)\nC(x|z\n:\n[\u2308\n\u2309,\nn])\n\u2212\nC(x|z\n:\n[\u2308\n\u2309,\nn])\n>\nn\n|X\n0\n\u2212k+1\n\u2212k\u2212i+1\n0\nn\n2\n2\n(z\u2212k\u2212i+1 ,x)\u2208Sk+i\n\u2264 P(\nmax\nsup\n\nP(\n\nmax\n\n(1)\n0\n(z\u2212k+1\n,x)\u2208Sn,k j>n1\u2212\u03b3\n\nj\n1X\n\u2308n\u2309\n0\n\u2212\u03b2\n1{X k\u22121 0\n|X0 2 )\n=x} \u2212 p(x|z\u2212k+1 ) > 0.5n\n(z\n\u03c3r\n)\nj r=1\n\u2212k+1\n\n+ P(\n\nmax\n\n(1)\n\nsup\n\n0\n(z\u2212k\u2212i+1\n,x)\u2208Sn,k+i j>n1\u2212\u03b3\n\nj\n1X\n\u2308n\u2309\n\u2212\u03b2\n0\n|X0 2 )\n1{X k+i\u22121 0\n=x} \u2212 p(x|z\u2212k+1 ) > 0.5n\n\u03c3r\n(z\n)\nj r=1\n\u2212k\u2212i+1\n\n4\n\n\f(1)\n\n\u2308n\u2309\n\n(1)\n\nSince both Sn,k and Sn,k+i depend solely on X0 2 we get\nP(\n\nmax\n\n0\nn\n(z\u2212k\u2212i+1\n,x)\u2208Sk+i\n\nj\n1X\n0\n1{X k\u22121 0\nP(\n=x} \u2212 p(x|z\u2212k+1 )\n\u03c3r\n(z\n)\nj\n\u2212k+1\n1\u2212\u03b3\n(1) j=\u2308n\nr=1\n\u2309\n\u221e\nX\n\nX\n\n\u2264\n\nn\nn\n\u2308n\u2309\n0\n0\nC(x|z\u2212k+1\n: [\u2308 \u2309, n]) \u2212 C(x|z\u2212k\u2212i+1\n: [\u2308 \u2309, n]) > n\u2212\u03b2 |X0 2 )\n2\n2\n\n0\n(z\u2212k+1\n,x)\u2208Sn,k\n\n\u2308n\u2309\n\n> 0.5n\u2212\u03b2 |X0 2 )\n\u221e\nX\n\nX\n\n+\n\n1\u2212\u03b3 \u2309\n(1)\n0\n(z\u2212k\u2212i+1\n,x)\u2208Sn,k+i j=\u2308n\n\nP(\n\nj\n1X\n1{X k+i\u22121 0\n=x}\n\u03c3r\n(z\n)\nj r=1\n\u2212k\u2212i+1\n\n\u2308n\u2309\n\n0\n\u2212p(x|z\u2212k+1\n) > 0.5n\u2212\u03b2 |X0 2 ).\n\nEach of these represents the deviation of an empirical count from its mean.\n0\nThe variables in question are independent since whenever the block z\u2212k+1\n0\noccurs the next term is chosen using the same distribution p(x|z\u2212k+1 ). Thus\nby Hoeffding's inequality (cf. Hoeffding [5] or Theorem 8.1 of Devroye et.\nal. [4]) for sums of bounded independent random variables and since the\n(1)\n(1)\ncardinality of both Sn,k and Sn,k+i is not greater than (n + 2)/2, we have\nP(\n\n0\nn\n(z\u2212k\u2212i+1\n,x)\u2208Sk+i\n\n\u22642\nThus\n\nmax\n\nn\nn\n\u2308n\u2309\n0\n0\n: [\u2308 \u2309, n]) > n\u2212\u03b2 |X0 2 )\nC(x|z\u2212k+1\n: [\u2308 \u2309, n]) \u2212 C(x|z\u2212k\u2212i+1\n2\n2\n\n\u221e\nn+2 X\n\u22122\u03b2\n2e\u22122n j .\n2 j=\u2308n1\u2212\u03b3 \u2309\n\n\u2308n\u2309\n\n\u02c6 n > n\u2212\u03b2 |X0 2 ) \u2264 n(n + 2)4e\u22122n\nP (\u2206\nk\n\n\u22122\u03b2+1\u2212\u03b3\n\n.\n\nIntegrating both sides we get\n\u02c6 n > n\u2212\u03b2 ) \u2264 n(n + 2)4e\u22122n\u22122\u03b2+1\u2212\u03b3 .\nP (\u2206\nk\nThe right hand side is summable provided 2\u03b2 + \u03b3 < 1 and the Borel-Cantelli\n\u02c6 n \u2264 n\u2212\u03b2 eventually) = 1. Thus \u03c7n \u2264 k eventually\nLemma yields that P (\u2206\nk\nalmost surely provided the process is Markov with order k. The proof of the\nTheorem is complete.\n\n5\n\n\fReferences\n[1] D. H. Bailey, Sequential Schemes for Classifying and Predicting Ergodic\nProcesses. Ph. D. thesis, Stanford University, 1976.\n[2] I. Csisz\u00e1r and P. Shields, \"The consistency of the BIC Markov order\nestimator,\" Annals of Statistics., vol. 28, pp. 1601-1619, 2000.\n[3] I. Csisz\u00e1r, \"Large-scale typicality of Markov sample paths and consistency of MDL order estimators ,\" IEEE Transactions on Information\nTheory, vol. 48, pp. 1616-1628, 2002.\n[4] L Devroye, L. Gy\u00f6rfi, G. Lugosi, A Probabilistic Theory of Pattern\nRecognition. Springer-Verlag, New York, 1996.\n[5] W. Hoeffding, \"Probability inequalities for sums of bounded random\nvariables ,\" Journal of the American Statistical Association, vol. 58, pp.\n13-30, 1963.\n[6] I. Kontoyiannis, P. Algoet, Yu.M. Suhov, A.J. Wyner, \"Nonparametric\nentropy estimation for stationary processes and random fields, with application to English text,\" IEEE Transactions on Information Theory,\nvol. 44, pp. 1319\u20131327, 1998.\n[7] D. S. Ornstein and B. Weiss, \"How sampling reveals a process,\" The\nAnnals of Probability, vol. 18, pp. 905\u2013930, 1990.\n[8] D. S. Ornstein and B. Weiss, \"Entropy and data compression schemes,\"\nIEEE Transactions on Information Theory, vol. 39, pp. 78\u201383, 1993.\n[9] D. S. Ornstein and B. Weiss, \"Entropy and recurrence rates for stationary random fields,\" IEEE Transactions on Information Theory, vol. 48,\npp. 1699\u20131697, 2002.\n[10] J. Ziv, \" Coding theorems for individual sequences. IEEE Transactions\non Information Theory, vol. 24, pp. 405\u2013412, 1978.\n\n6\n\n\f"}