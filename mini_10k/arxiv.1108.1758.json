{"id": "http://arxiv.org/abs/1108.1758v2", "guidislink": true, "updated": "2011-10-12T14:22:40Z", "updated_parsed": [2011, 10, 12, 14, 22, 40, 2, 285, 0], "published": "2011-08-08T17:22:47Z", "published_parsed": [2011, 8, 8, 17, 22, 47, 0, 220, 0], "title": "Reweighting and Unweighting of Parton Distributions and the LHC W lepton\n  asymmetry data", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1108.5083%2C1108.1284%2C1108.4176%2C1108.0947%2C1108.5335%2C1108.0095%2C1108.2252%2C1108.2634%2C1108.6190%2C1108.1471%2C1108.6191%2C1108.1486%2C1108.1272%2C1108.2578%2C1108.0233%2C1108.5595%2C1108.5999%2C1108.2511%2C1108.5354%2C1108.2323%2C1108.4108%2C1108.0417%2C1108.4367%2C1108.0714%2C1108.1768%2C1108.0323%2C1108.5045%2C1108.4933%2C1108.1587%2C1108.1962%2C1108.0760%2C1108.2124%2C1108.1758%2C1108.5678%2C1108.0850%2C1108.0259%2C1108.4090%2C1108.6186%2C1108.5948%2C1108.2321%2C1108.5813%2C1108.1929%2C1108.5565%2C1108.0189%2C1108.5191%2C1108.0112%2C1108.4529%2C1108.0999%2C1108.1451%2C1108.2392%2C1108.5949%2C1108.3920%2C1108.0918%2C1108.4020%2C1108.1623%2C1108.3737%2C1108.1965%2C1108.3929%2C1108.0593%2C1108.3574%2C1108.3875%2C1108.5387%2C1108.0246%2C1108.4887%2C1108.5311%2C1108.1315%2C1108.2469%2C1108.2186%2C1108.0794%2C1108.2037%2C1108.3134%2C1108.3559%2C1108.5060%2C1108.3754%2C1108.0060%2C1108.4059%2C1108.1857%2C1108.1321%2C1108.1145%2C1108.2407%2C1108.5874%2C1108.0945%2C1108.4516%2C1108.4340%2C1108.5108%2C1108.1306%2C1108.3364%2C1108.4347%2C1108.1382%2C1108.0367%2C1108.3693%2C1108.3082%2C1108.0113%2C1108.6307%2C1108.5808%2C1108.3808%2C1108.5166%2C1108.2723%2C1108.1458%2C1108.2038%2C1108.0671&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Reweighting and Unweighting of Parton Distributions and the LHC W lepton\n  asymmetry data"}, "summary": "We develop in more detail our reweighting method for incorporating new\ndatasets in parton fits based on a Monte Carlo representation of PDFs. After\nrevisiting the derivation of the reweighting formula, we show how to construct\nan unweighted PDF replica set which is statistically equivalent to a given\nreweighted set. We then use reweighting followed by unweighting to test the\nconsistency of the method, specifically by verifying that results do not depend\non the order in which new data are included in the fit via reweighting. We\napply the reweighting method to study the impact of LHC W lepton asymmetry data\non the NNPDF2.1 set. We show how these data reduce the PDF uncertainties of\nlight quarks in the medium and small x region, providing the first solid\nconstraints on PDFs from LHC data.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1108.5083%2C1108.1284%2C1108.4176%2C1108.0947%2C1108.5335%2C1108.0095%2C1108.2252%2C1108.2634%2C1108.6190%2C1108.1471%2C1108.6191%2C1108.1486%2C1108.1272%2C1108.2578%2C1108.0233%2C1108.5595%2C1108.5999%2C1108.2511%2C1108.5354%2C1108.2323%2C1108.4108%2C1108.0417%2C1108.4367%2C1108.0714%2C1108.1768%2C1108.0323%2C1108.5045%2C1108.4933%2C1108.1587%2C1108.1962%2C1108.0760%2C1108.2124%2C1108.1758%2C1108.5678%2C1108.0850%2C1108.0259%2C1108.4090%2C1108.6186%2C1108.5948%2C1108.2321%2C1108.5813%2C1108.1929%2C1108.5565%2C1108.0189%2C1108.5191%2C1108.0112%2C1108.4529%2C1108.0999%2C1108.1451%2C1108.2392%2C1108.5949%2C1108.3920%2C1108.0918%2C1108.4020%2C1108.1623%2C1108.3737%2C1108.1965%2C1108.3929%2C1108.0593%2C1108.3574%2C1108.3875%2C1108.5387%2C1108.0246%2C1108.4887%2C1108.5311%2C1108.1315%2C1108.2469%2C1108.2186%2C1108.0794%2C1108.2037%2C1108.3134%2C1108.3559%2C1108.5060%2C1108.3754%2C1108.0060%2C1108.4059%2C1108.1857%2C1108.1321%2C1108.1145%2C1108.2407%2C1108.5874%2C1108.0945%2C1108.4516%2C1108.4340%2C1108.5108%2C1108.1306%2C1108.3364%2C1108.4347%2C1108.1382%2C1108.0367%2C1108.3693%2C1108.3082%2C1108.0113%2C1108.6307%2C1108.5808%2C1108.3808%2C1108.5166%2C1108.2723%2C1108.1458%2C1108.2038%2C1108.0671&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We develop in more detail our reweighting method for incorporating new\ndatasets in parton fits based on a Monte Carlo representation of PDFs. After\nrevisiting the derivation of the reweighting formula, we show how to construct\nan unweighted PDF replica set which is statistically equivalent to a given\nreweighted set. We then use reweighting followed by unweighting to test the\nconsistency of the method, specifically by verifying that results do not depend\non the order in which new data are included in the fit via reweighting. We\napply the reweighting method to study the impact of LHC W lepton asymmetry data\non the NNPDF2.1 set. We show how these data reduce the PDF uncertainties of\nlight quarks in the medium and small x region, providing the first solid\nconstraints on PDFs from LHC data."}, "authors": ["NNPDF Collaboration", "Richard D. Ball", "Valerio Bertone", "Francesco Cerutti", "Luigi Del Debbio", "Stefano Forte", "Alberto Guffanti", "Nathan P. Hartland", "Jose I. Latorre", "Juan Rojo", "Maria Ubiali"], "author_detail": {"name": "Maria Ubiali"}, "author": "Maria Ubiali", "arxiv_comment": "34 pages, 24 figures: published version", "links": [{"href": "http://arxiv.org/abs/1108.1758v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1108.1758v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "hep-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "hep-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "hep-ex", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1108.1758v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1108.1758v2", "journal_reference": null, "doi": null, "fulltext": "Edinburgh 2011/15\nIFUM-981-FT\nFR-PHENO-2011-013\nRWTH TTK-11-32\n\narXiv:1108.1758v2 [hep-ph] 12 Oct 2011\n\nReweighting and Unweighting of Parton Distributions\nand the LHC W lepton asymmetry data\nThe NNPDF Collaboration:\nRichard D. Ball1 , Valerio Bertone2 , Francesco Cerutti3 , Luigi Del Debbio1 ,\nStefano Forte4 , Alberto Guffanti2,5 , Nathan P. Hartland1 , Jos\u00e9 I. Latorre3 , Juan Rojo4\nand Maria Ubiali6 .\n1\n\nTait Institute, University of Edinburgh,\nJCMB, KB, Mayfield Rd, Edinburgh EH9 3JZ, Scotland\n2 Physikalisches Institut, Albert-Ludwigs-Universit\u00e4t Freiburg,\nHermann-Herder-Strasse 3, D-79104 Freiburg i. B., Germany\n3 Departament d'Estructura i Constituents de la Mat\u00e8ria, Universitat de Barcelona,\nDiagonal 647, E-08028 Barcelona, Spain\n4 Dipartimento di Fisica, Universit\u00e0 di Milano and INFN, Sezione di Milano,\nVia Celoria 16, I-20133 Milano, Italy\n5 The Niels Bohr International Academy and Discovery Center,\nThe Niels Bohr Institute, Blegdamsvej 17, DK-2100 Copenhagen, Denmark\n6 Institut f\u00fcr Theoretische Teilchenphysik und Kosmologie, RWTH Aachen University,\nD-52056 Aachen, Germany\n\nAbstract:\nWe develop in more detail our reweighting method for incorporating new datasets in\nparton fits based on a Monte Carlo representation of PDFs. After revisiting the derivation\nof the reweighting formula, we show how to construct an unweighted PDF replica set which\nis statistically equivalent to a given reweighted set. We then use reweighting followed by\nunweighting to test the consistency of the method, specifically by verifying that results do\nnot depend on the order in which new data are included in the fit via reweighting. We\napply the reweighting method to study the impact of LHC W lepton asymmetry data on\nthe NNPDF2.1 set. We show how these data reduce the PDF uncertainties of light quarks\nin the medium and small x region, providing the first solid constraints on PDFs from LHC\ndata.\n\n1\n\n\fContents\n1 Introduction\n\n3\n\n2 Reweighting\n2.1 Integration over the data space . . . . . . . . . . . . . . . . . . . . . . . . .\n2.2 Weights for a given \u03c7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.3 Multiple experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n5\n5\n6\n7\n\n3 Unweighting\n9\n3.1 The unweighting method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n3.2 Testing unweighting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n4 Consistency\n4.1 Multiple Reweighting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.2 Tevatron Inclusive Jets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.3 Jet and Drell-Yan data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n15\n15\n16\n18\n\n5 The W asymmetry at the LHC\n20\n5.1 Inclusion of individual experiments . . . . . . . . . . . . . . . . . . . . . . . 20\n5.2 Combination of ATLAS and CMS data . . . . . . . . . . . . . . . . . . . . . 24\n6 Global PDFs including LHC data\n26\n6.1 Tevatron W asymmetry data . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n6.2 Combining LHC and Tevatron W asymmetry data . . . . . . . . . . . . . . 26\n7 Conclusions and outlook\n\n32\n\n2\n\n\f1\n\nIntroduction\n\nIn a series of previous papers [1\u20139], we constructed increasingly accurate sets of parton\ndistributions (PDFs), using a Monte Carlo approach coupled to the use of neural networks\nas underlying interpolating functions. By definition, a PDF set provides a representation\nof a probability density in the space of parton distributions, i.e. a probability density in\na space of functions [10\u201312]. We have performed various tests that confirm that NNPDF\nparton sets do indeed behave in a way which is consistent with the desired statistical\nproperties of functional probability densities.\nAn advantage of providing a Monte Carlo representation of this PDF probability density is that new information (such as might be provided by new experimental data) can\nbe included, using Bayes' theorem, by reweighting an existing PDF set, without having\nto perform a new PDF fit [13, 14]: it is possible to determine a reweighting factor for\neach Monte Carlo replica in such a way that the information contained in the new data\nis included by simply computing weighted averages. This approach was first successfully\ndeveloped and implemented in Ref. [14], where it was explicitly shown, in studies involving CDF and D0 inclusive jet data, that results obtained by reweighting are equivalent to\nthose found by including the new data in the fit.\nReweighting takes a set of equally likely PDF replicas generated by importance sampling, and assigns to them weights reflecting their relative probabilities in the light of new\ndata not included in the original fit. In this paper we develop a second technique, which\nwe call 'unweighting', which takes the reweighted set and replaces it with a new set of\nreplicas which are again all equally probable. This new set of replicas can then be used\nin precisely the same way as a fitted set. Even though no new information is gained by\nunweighting, presenting reweighted PDFs in the same form as a corresponding refitted set\nhas various obvious practical advantages.\nFurthermore, unweighting allows us to perform a highly nontrivial test of the reweighting procedure: namely, we take two new independent datasets, and use them to sequentially improve an existing set of replicas. This may then be done in either order, or indeed\nby treating them as one (combined) dataset. All three methods should yield equivalent\nresults. Checking that this is the case provides a strong test of the method. However this\ncan only be done if after each reweighting we unweight, because our simple closed-form\nexpression for the weights can only be used for the reweighting of an equally probable (i.e.\nunweighted) set of PDFs.\nWe perform this check by first taking the NNPDF2.0 NLO DIS+DY fit [7], based\non deep-inelastic and Drell-Yan data only, and taking as new datasets the CDF [15] and\nD0 [16] Run II inclusive jet data. This completes and refines the studies of Ref. [14],\nwhere it was verified that the inclusion of the combined CDF+D0 jet data by reweighting\nor refitting gives equivalent results. We then perform a second check using as the prior the\nNNPDF2.1 DIS fit [8], based on deep-inelastic data only, and taking as new datasets the\nE605 [17] Drell-Yan and Tevatron inclusive jet data. This provides a somewhat different\ntest, because while the D0 and CDF data used in the previous test measure the same\nobservable in the same kinematic region, the Drell-Yan and jet data affect different PDFs\nin different kinematic regions.\nBesides its practical usefulness, the combined reweighting plus unweighting procedure\nis important because it allows one, at least in principle, to perform a global PDF fit by\nsequentially including new data by reweighting a generic prior distribution of PDFs [13]. If\n3\n\n\fthe information contained in the new data is sufficiently precise, and the prior distribution\nsufficently broad, the results will the be largely independent of the prior one starts from:\nthis would then give completely unbiased PDFs. In practice, this procedure is unlikely to\nbe viable because, in order to get accurate results, the prior set of PDF replicas would\nhave to be huge. However, the equivalence of PDFs obtained from reweighting with those\ndetermined using a fitting procedure (such as the NNPDF sets) confirms that the latter\nare also unbiased.\nFollowing the success of these consistency tests, we use reweighting to evaluate the\nimpact on the NNPDF2.1 NLO fit Ref. [8] of recent LHC data on the W -lepton asymmetry\nfrom the ATLAS and CMS collaborations. Using unweighting, we are able to produce a\nnew PDF set, NNPDF2.2, which incorporates the effect of these data and the older W lepton asymmetry from D0.\nThe outline of this paper is as follows. In Sec. 2 we revisit the derivation of the\nreweighting method, in particular the determination of the weights in terms of the \u03c72\nof the fit of the new data to each replica, and we discuss some subtle issues that were\nnot tackled in Ref. [14], related to the definition of the measure in data space and to the\ninclusion by reweighting of multiple data sets. Then, in Sec. 3 we present our method of\nunweighting reweighted PDF sets, to give a set of replicas which are all equally probable,\nand show that indeed the unweighted set is equivalent to the original reweighted set.\nWe follow this in Sec. 4 with a study of the consistency of the combined reweighting\nand unweighting procedure, when applied to more than one dataset in turn. After this\ntheoretical study, we turn to phenomenology by using the method to investigate the impact\nof LHC measurement of the W lepton asymmetry on PDFs. First, we show in Sec. 5\nhow these data reduce the PDF uncertainties of light quarks in the medium and small\u2013x\nregion, providing the first solid constraints on PDFs from LHC data, and then in Sect. 6\nwe construct a new set of NLO PDFs, NNPDF2.2, which includes, on top of all the data\nused to determine NNPDF2.1 PDFs, also the D0 W asymmetry data already discussed in\nRef. [14] and the LHC data discussed in Sect. 5.\n\n4\n\n\f2\n\nReweighting\n\nIn this section we revisit the derivation of the weight formula for reweighting ensembles\nof PDFs. In particular we discuss some of the more subtle issues in the formal proof\npresented in Ref. [14]. The derivation of the formula for the computation of the weights is\nnontrivial because we are dealing with probability densities in multidimensional spaces. In\nparticular we need to avoid the ambiguities that can appear when dealing with conditional\nprobabilities with respect to an event of probability zero, the so-called Borel-Kolmogorov\nparadox [18]. The conditional probabilities need to be defined carefully as integrations of\nconditional probability densities over finite volumes, in the limit when these volumes are\ntaken to zero.\n\n2.1\n\nIntegration over the data space\n\nBayes' theorem can be stated in terms of probability densities:\nP(f |y)Df P(y)dn y = P(y|f )dn y P(f )Df ,\n\n(1)\n\nwhere Df is the integration measure in the space of PDFs, and dn y is the integration\nmeasure in the space of data. The latter is an n-dimensional real space, where n is the\nnumber of data points used for reweighting. P(f ) is the prior density in the space of the\nPDFs: it is represented by the set {fk } of PDF replicas. These are all equally probable,\ne.g., the expected PDF is simply determined as the average over the set {fk }, and are\ndetermined by importance sampling by starting from experimental data [11]. P(f |y) is\ninstead the new probability density, given the n data points y. Note that here, unlike in\nRef. [14], we do not make explicit the dependence of conditional probabilities on generic\nprior information K (which includes the data used to determine the prior PDF, external\nparameters such as \u03b1s , and theoretical assumptions such as the use of perturbative QCD at\na given order). P(y) is the prior density in the space of data, and we do not need to specify\nits explicit form, since it can be fixed by requiring P(f |y) to be correctly normalised. The\nonly relevant property of P(y) is that it does not depend on the PDFs f .\nIn order to define the probability density P(f |y) at a given point y, we can integrate\nEq. (1) in a small sphere S\u01eb of radius \u01eb centered at y. Integrating the left-hand side of\nEq. (1) over S\u01eb we obtain\nZ\n\u0002\n\u0003\nP(f |y \u2032 )Df P(y \u2032 )dn y \u2032 = n\u22121 \u01ebn \u03a9n P(y) P(f |y)Df ,\n(2)\nS\u01eb\n\nwhere \u03a9n is the solid angle in n dimensions. Integrating the right-hand side similarly, we\ncan cancel the volume factors on each side and thus take the limit \u01eb \u2192 0, to give\nP(f |y)Df =\n\nP(y|f )\nP(f )Df .\nP(y)\n\n(3)\n\nNow P(y|f ) is the likelihood density for the data y: assuming these data to be normally\ndistributed about central values y[f ] (which of course depend on the PDF f ),\n\u0001\nP(y|f ) = (2\u03c0)\u2212n/2 (det\u03c3)\u22121 exp \u2212 21 (y \u2212 y[f ])\u03c3 \u22121 (y \u2212 y[f ]) ,\n(4)\n5\n\n\fwhere \u03c3 is the experimental covariance matrix. The only dependence on f is through the\nvalue of\n\u03c72 (y, f ) \u2261 (y \u2212 y[f ])\u03c3 \u22121 (y \u2212 y[f ]) .\n(5)\nIt now follows from Eqs. (3-5) that\nP(f |y)Df \u221d exp(\u2212 21 \u03c7(y, f )2 ) P(f )Df,\n\n(6)\n\nwith a constant of proportionality that depends on\nR y, but not on f , and can thus be fixed\nif necessary through the normalization condition P(f |y)Df = 1.\n\n2.2\n\nWeights for a given \u03c7\n\nThis is all fine so far as it goes, but is not sufficient to give us a reweighting of our ensemble\nof PDFs equivalent to a refitting. The reason for this is that when we fit PDFs, we do not\ndemand that the predictions y[f ] coincide with the data points y, but rather that the figure\nof merit \u03c72 (y, f ) is optimized. Thus rather than integrating both sides of Eq. (1) over the\nsmall spheres S\u01eb , we should integrate over all y subject only to the single constraint that\n\u03c72 (y, f ) = \u03c72 , for some fixed value \u03c7. It is convenient to choose as a parameter \u03c7, rather\nthan \u03c72 , because we can interpret \u03c7 as the radial co-ordinate in a system of spherical polar\nco-ordinates in function space, centered at y \u2032 = y[f ].\nThe left-hand side of Eq. (1) thus becomes\nZ\n\u03b4(\u03c7 \u2212 \u03c7(y \u2032 , f ))P(f |y \u2032 )Df P(y \u2032 )dn y \u2032 \u221d P(f |\u03c7)Df ,\n(7)\nthus defining P(f |\u03c7) up to an overall constant (independent of f ). We can evaluate it by\nperforming the same integration over the right-hand side of Eq. (1), since the dependence\non P(f ) factorises:\nZ\n1 2\n\u03b4(\u03c7 \u2212 \u03c7(y \u2032 , f ))P(y \u2032 |f )dn y \u2032 P(f ) Df = 21\u2212n/2 (\u0393(n/2))\u22121 \u03a9n \u03c7n\u22121 e\u2212 2 \u03c7 P(f )Df , (8)\nwhere we have used Eq. (4) for the likelihood, and performed the integral over y \u2032 in\nspherical co-ordinates. Comparing Eq. (7) and Eq. (8) we thus find\n1\n\n2\n\nP(f |\u03c7)Df \u221d \u03c7(n\u22121) e\u2212 2 \u03c7 P(f )Df .\n\n(9)\n\nIn order to define the weight to be associated to each replica, we need to define the\nprobability for each replica by integrating the probability density over a finite volume, and\nthen send that volume to zero. For a given replica fk we thus integrate \u03c7\u2032 over the region\n\u03c7k < \u03c7\u2032 < \u03c7k + \u01eb, where \u03c7k = \u03c7(y, fk ):\nZ \u03c7k +\u01eb\nd\u03c7\u2032 P(fk |\u03c7\u2032 ) = \u01ebP(fk |\u03c7k ) .\n(10)\n\u03c7k\n\nNote that this corresponds to integrating Eq. (7) over a spherical shell, centered on y[fk ],\nof radius \u03c7k and thickness \u01eb. The thickness of the shell is independent of the choice of\nreplica: if it were not, we would bias the result.\n\n6\n\n\fIt is easy to see using Eq. (9) that Eq. (10) gives the formula derived in Ref. [14] for\nthe weights: since the replicas in the prior distribution all have equal probability, P(fk )\nis independent of the choice of replica fk , and the weights are\n1\n\n2\n\nwk \u221d P(fk |\u03c7k ) \u221d \u03c7kn\u22121 e\u2212 2 \u03c7k .\n\n(11)\n\nThe constant of proportionality may be fixed by normalizing the sum of the weights to\nthe number of replicas.\nThe factor of \u03c7kn\u22121 takes account of the fact that when there are many data points,\nlarger values of \u03c7k have a larger phase space available to them, while very small values\nare phase space suppressed: however good the model it is always very unlikely that the\ntheoretical prediction will give exactly the right result for a large number of measurements.\nThis is not a trivial result: it depends critically on choosing the correct volume upon which\nto integrate in the space of the new data y. Starting from the same probability density,\nbut using a different integration volume would produce a different result. Hence we need\nto justify our particular choice of volume.\nIn this respect, we note that our choice includes all points in the space of y with a particular \u03c72 , and that the thickness of the shell is independent of its radius \u03c7(y, f ) or centre\ny[f ], in the same way that in Eq. (2) the radius of the little sphere was also independent\nof y[f ]. The ultimate justification in both cases is that the probability measure dn y on\nthe space y is uniform, i.e. that equal volumes have equal probability: this assumption\nis of course implicit from the start, since without it the likelihood Eq. (4) would not be\nGaussian.\nNote that although the above argument is most naturally expressed using \u03c7 as a coordinate in function space we would get the same weights wk if we were to instead use \u03c72 ,\nor indeed a conditional dependence on any other monotonic function of \u03c7, so long as we\nuse the same volume in the space of data to define the weights. To see this, note that for\nexample\nZ\nP(f |\u03c72 )Df \u221d\n\n\u03b4(\u03c72 \u2212 \u03c72 (y \u2032 , f ))P(f |y \u2032 )Df P(y \u2032 )dn y \u2032 ,\n\n(12)\n\nso that, comparing with Eq. (7),\nP(f |\u03c72 ) = P(f |\u03c7)/(2\u03c7) .\n\n(13)\n\nAs expected, we thus have P(f |\u03c7)d\u03c7 = P(f |\u03c72 )d\u03c72 . If we work with P(f |\u03c72 ), in order to\nbe sure to use the same volume in the space of data (i.e. a spherical shell of thickness \u01eb)\nwe must now integrate over the interval \u03c72k < (\u03c7\u2032 )2 < \u03c72k + 2\u03c7k \u01eb:\nwk \u221d\n\nZ\n\n\u03c72k +2\u03c7k \u01eb\n\n\u03c72k\n\nd\u03c7\u20322 P(fk |\u03c7\u20322 ) ,\n\n(14)\n\nwhich then yields exactly the same weight Eq. (11) as obtained using Eq. (10).\n\n2.3\n\nMultiple experiments\n\nLet us now discuss the implications of the above prescription for reweighting with more\nthan one set of data. Suppose we are given a set of new data {y}, which is made of\ntwo independent subsets {y1 } and {y2 }, containing respectively n1 and n2 data points,\n7\n\n\fsuch as for example a dataset which includes results from two independent experimental\nmeasurements (of the same, or of different observables).\nWhen the two sets of data are used for reweighting simultaneously, the only quantity\nthat matters is the total \u03c72 of the two experiments. Since we assumed the experiments to\nbe independent, \u03c72 = \u03c721 + \u03c722 , where \u03c7i \u2261 \u03c7(yi , f ), and the probability density is therefore\ngiven by Eq. (9) above:\n1\n\n1\n\n2\n\n2\n\nP(f |\u03c7) \u221d (\u03c721 + \u03c722 ) 2 (n1 +n2 \u22121) e\u2212 2 (\u03c71 +\u03c72 ) .\n\u03c722 .\n\n(15)\n\nClearly the individual values of \u03c72 of the two sets need not each be fixed to \u03c721 and\nHence even though the likelihood factorizes,\nP(y1 y2 |f ) = P(y2 |f )P(y1 |f ) ,\n\n(16)\n\nP(f |\u03c7) 6= P(f |\u03c72 )P(f |\u03c71 ) .\n\n(17)\n\nthe weights do not:\nInstead they are determined through the more complicated relation (see Eqs. (7) and (8))\nZ\nP(f |\u03c7) \u221d \u03b4(\u03c7 \u2212 (\u03c721 + \u03c722 )1/2 ) P(y2\u2032 |f )dn2 y2\u2032 P(y1\u2032 |f )dn1 y1\u2032 .\n(18)\nWith Gaussian likelihoods Eq. (4), the integrals can be evaluated to give Eq. (15).\nThis means that if we wish to proceed sequentially, then after weighting with the first\ndata set, with the usual weights \u03c7n1 1 \u22121 exp(\u2212 12 \u03c721 ), the weights for the second data set are\nnot given by\nw2 k \u221d \u03c7n2 2k\u22121 exp(\u2212 21 \u03c722 k ),\n(19)\nbut rather by\n1 +1\nw2|1 k \u221d (\u03c721 k + \u03c722 k )(n1 +n2 \u22121)/2 \u03c71\u2212n\nexp(\u2212 12 \u03c722 k ).\nk\n\n(20)\n\nThis perhaps appears odd at first sight, but is as it should be: the first dataset has altered\nthe probability distribution of the PDFs, and thus the probabilities of the replicas before\nthe second dataset can be considered must necessarily change. This is taken into account\nof by the dividing out the phase space factor of the first dataset, and multiplying by that\nof the combined dataset.\nNevertheless, it is possible to factorize the reweightings due to more than one dataset,\nif rather than attempting successive reweightings of the same set of replicas, one first\nturns the original weighted set into an unweighted set, and then computes the second set\nof weights using this set. This procedure will be discussed in detail in Sec. 4: however\nbefore we can do this we must first develop a procedure for unweighting.\n\n8\n\n\f3\n\nUnweighting\n\nIn this section we present a method to unweight reweighted PDF sets so that they can\nbe used without the need for including weights for individual replicas. The starting point\nis a set of Nrep reweighted replicas. Each replica, identified by the index k = 1, . . . , Nrep ,\ncarries a weight wk defined in Eq. (11), determined by comparing each of the replicas of\nthe original unweighted distribution to the new experimental information. Our goal is\n\u2032\nto unweight this PDF set in order to obtain a new set of Nrep\nreplicas with all weights\nequal to unity, but with the same probability distribution of the original weighted set, i.e.\nsuch that any moment of the probability distribution computed from the weighted and\n\u2032 \u2192 \u221e.\nunweighted set would be the same in the limit in which Nrep\n\n\u2032\nFigure 1: Graphical representation of the construction of a set of Nrep\nunweighted replicas from a\n\nset of Nrep = 20 weighted ones. Each segment is in one-to-one correspondence to a replica, and its\n\u2032\n\u2032\nlength is proportional to the weight of the replica. The cases of Nrep\n\u226b Nrep (top) and Nrep\n= 10\n(bottom) are shown.\n\n9\n\n\f3.1\n\nThe unweighting method\n\nThe basic idea for constructing the unweighted set consists of selecting replicas from the\nweighted set of Nrep replicas in such a way that replicas carrying a relatively high weight\nare chosen repeatedly, while those with vanishingly small weight disappear from the final\nunweighted set. The method is depicted graphically in Fig. 1. We start by subdividing\na line of unit length into Nrep segments, in such a way that for each replica the length\nof the corresponding segment is proportional to the weight of the replica, and thus to\nits probability. The ordering of the segments is random. In order to extract a set of\n\u2032\nNrep\nreplicas that faithfully represents this distribution, we draw another unit interval\n\u2032 segments all of equal length 1/N \u2032 . We\ndirectly below the first, and subdivide it into Nrep\nrep\nthen select replicas from the original weighted set by taking a number of copies of each\nreplica equal to the number of lower segments whose right edge is contained in the upper\nsegment corresponding to that specific replica. A little thought shows that the (all equally\n\u2032\nreplicas in the lower set are then chosen according to the probabilities of\nprobable) Nrep\nthe Nrep replicas in the upper set.\n\u2032\nTo see this, note that, if the number of Nrep\nreplicas is large enough, (top plot in\n\u2032 ) will be contained in each upper\nFig. 1) then at least one lower segment (width 1/Nrep\nsegment, and the original probability distribution is reproduced. This case is however\n\u2032\nunrealistic, as it would require Nrep\nto be as large as the ratio between the highest and\nlowest weight, which can be very large indeed. It is also unnecessary, because the amount\nof information carried by the weighted set is measured by its Shannon entropy, which can\nbe used to determine the effective number of unweighted replicas Neff which carry the same\n\u2032\nsignificantly\ninformation [14]. Hence, it is pointless to include a number of replicas Nrep\nlarger than Neff , as no information is then gained. Because by construction Neff \u2264 Nrep\nthe more realistic situation is depicted in the bottom plot of Fig. 1: for the larger weights\nseveral unweighted segments are contained in a weighted one, but for the smaller weights\nthere are often none at all, since we only select a replica if the edge of a lower segment\nis contained in the upper segment corresponding to that replica. Which replica is chosen\namong many all with equally small weight is of course entirely random, since the ordering\nof the replicas is random.\nWe can now formulate the unweighting algorithm quantitatively. We start with a set\nof Nrep replicas, each carrying a weight wk Eq. 11; as in Ref. [14], we normalize the weights\naccording to\nNrep\nX\nwk = Nrep .\n(21)\nk=1\n\nThe probability of each replica is determined given its weight as\nwk\n.\npk =\nNrep\n\n(22)\n\nWe then define probability cumulants\nPk \u2261 Pk\u22121 + pk =\n\nk\nX\n\npj ,\n\n(23)\n\nj=0\n\nwhere in the last step we take P0 = 0. By construction, 0 \u2264 Pk \u2264 1 and Pk\u22121 \u2264 Pk .\nIndeed, the cumulants provide the co-ordinate of the edge of the k-th upper segment in\nthe plot of Fig. 1, with origin at the left edge of the unit interval.\n10\n\n\fThe unweighted set is then constructed as follows. We start with Nrep weights wk , and\nwe determine Nrep new weights\n\u2032\nNrep\n\nwk\u2032\n\n=\n\n\u0011 \u0010\nX \u0010 j\nj \u0011\n\u03b8\n\u2212\nP\n\u03b8\nP\n\u2212\n.\nk\u22121\nk\n\u2032\n\u2032\nNrep\nNrep\n\n(24)\n\nj=1\n\nThe weights wk\u2032 are either zero or positive integers, and they satisfy the normalization\ncondition\nNrep\nX\n\u2032\nNrep\n\u2261\nwk\u2032 :\n(25)\nk=1\n\nin fact, they correspond to the graphical counting procedure described previously. The\nunweighted set is then simply constructed by taking wk\u2032 copies of the k-th replica, for all\nk = 1, . . . , Nrep . The probability of replica k in the new unweighted set is then given by\np\u2032k =\n\nwk\u2032\n.\n\u2032\nNrep\n\n(26)\n\nlim\n\np\u2032k = pk ,\n\n(27)\n\nAs a consequence we have\n\u2032 \u2192\u221e\nNrep\n\ni.e. the unweighted set reproduces the probabilities of the weighted set in the limit of large\nsample size, as it ought to.\nAs already mentioned, even though exact identity of the reweighted and unweighted\nprobability distribution holds in the limit Eq. (27), the amount of information contained\nin the weighted set corresponds to Neff \u2264 Nrep unweighted replicas, with Neff determined\nas in Eq. (10) of Ref. [14] from the Shannon entropy. Therefore for practical applications\n\u2032\nit is advisable to take Nrep\n< Neff - though there is nothing in principle wrong with\n\u2032\ntaking Nrep > Neff , this would just lead to a highly redundant replica set. We will study\n\u2032\nin an explicit example below.\nthe dependence of unweighted results on Nrep\n\n11\n\n\fDistance between central values\n\nDistance between PDF uncertainties, Nrep=100\n4\n\n\u03a3\n3.5 Tg\n3\nV\n3 \u2206\nS\ns+\n2.5 s-\n\nNNPDF2.0 (rw,1000) vs NNPDF2.0 (uw,100)\n\nd[ \u03c3q(x,Q02) ]\n\nd[ q(x,Q02) ]\n\n4\n\n2\n1.5\n\n\u03a3\n3.5 Tg\n3\nV\n3 \u2206\nS\ns+\n2.5 s2\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n1e-05\n\n0.0001\n\n0.001\n\n0.01\n\n0.1\n\n1\n\nNNPDF2.0 (rw,1000) vs NNPDF2.0 (uw,100)\n\n0\n1e-05\n\n0.0001\n\n0.001\n\nx\n\n0.01\n\n0.1\n\n1\n\nx\n\nFigure 2: Distance between central values (left) and uncertainties (right) of the reweighted and\nunweighted PDFs determined from Nrep = 1000 replicas of NNPDF2.0 DIS+DY reweighted with\nTevatron jet data, as described in the text. The corresponding distances between refitted and\nreweighted PDFs were shown in Fig. 2 of Ref. [14].\n\nUnweighting of ( NNPDF2.0DIS+DY 1000 + TeVJets(RW) )\n\nUnweighting of ( NNPDF2.0DIS+DY 1000 + TeVJets(RW) )\n\nShannon Entropy ( N'rep )\n\n3\n\nN'eff\nN'rep\n\n1000\n\n2.5\n\n500\n\n2\n1.5\n1\n\n100\n0.5\n50\n0\n50\n\n100\n\n500\n\n1000\n\nN'rep\n\n50\n\n100\n\n500\n\n1000\n\nN'rep\n\n\u2032\n\u2032\nFigure 3: Left: the relative Shannon entropy HR (Nrep\n) Eq. (28) as function of Nrep\nfor the\n\nreweighted and unweighted PDFs described in the caption of Fig. 2. Right: the effective number\n\u2032\n\u2032\nof replicas of the unweighted set Neff\nas function of Nrep\n. The dashed vertical line denotes the\n\u2032\nvalue Nrep = Neff . In all plots a moving average of 25 replicas has been performed to smooth out\nrandom fluctuations.\n\n3.2\n\nTesting unweighting\n\nAs a proof of concept of the unweighting technique, we will apply it to the two cases\ndiscussed in Ref. [14]: the reweighting of NNPDF2.0 DIS+DY with Tevatron inclusive\njet data and the reweighting of NNPDF2.0 with the D0 muon and inclusive electron W\nlepton asymmetry data.\nFirst, we consider the reweighting of NNPDF2.0 DIS+DY [7] with the Tevatron inclusive jet data [15, 19]. As discussed in Ref. [14], starting with Nrep = 1000 NNPDF2.0\nDIS+DY replicas, after reweighting with jet data the effective number of replicas is\nNeff = 334. A reasonable choice for the size of the unweighted set would be any number\n\u2032 = 100. We perform the unweighting following the proceless than this: here we chose Nrep\ndure discussed above. The comparison between the reweighted PDFs and the unweighted\nset can be made quantitative by determining the distances between PDFs and uncertain12\n\n\fDistance between central values\n\nDistance between PDF uncertainties\n\n\u03a3\n3.5 Tg\n3\nV\n3 \u2206\nS\ns+\n2.5 s-\n\n4\n\nNNPDF2.0+Wasy --- (RW,1000) vs (UW,100)\n\nd[ \u03c3q(x,Q02) ]\n\nd[ q(x,Q02) ]\n\n4\n\n2\n1.5\n\n\u03a3\n3.5 Tg\n3\nV\n3 \u2206\nS\ns+\n2.5 s2\n1.5\n\n1\n\n1\n\n0.5\n\n0.5\n\n0\n1e-05\n\n0.0001\n\n0.001\n\n0.01\n\n0.1\n\n1\n\nNNPDF2.0+Wasy --- (RW,1000) vs (UW,100)\n\n0\n1e-05\n\n0.0001\n\nx\n\n0.001\n\n0.01\n\n0.1\n\n1\n\nx\n\nFigure 4: Distance between central values (left) and uncertainties (right) of the reweighted and\nunweighted PDFs determined from Nrep = 1000 replicas of NNPDF2.0 DIS+DY reweighted with\nD0 W -lepton asymmetry data, as described in the text.\n\nties. Distances were defined in Appendix A of Ref. [7], and in Ref. [14] in the weighted\ncase; recall that distances d \u223c 1 correspond to statistically identical distributions, while\n(with Nrep = 100 replicas) d \u223c 7 corresponds to distributions which are statistically inequivalent, but agree to one sigma. The distances between the reweighted PDF set and\nthe same PDF set after unweighting are shown in Fig. 2. The corresponding distances\nbetween reweighted and refitted PDFs were shown in Fig. 2 of Ref. [14]. It is clear that\nthe distances between reweighted and unweighted sets are generally smaller than those\nbetween the reweighted and the refitted sets, and they all fluctuate about d \u223c 1, showing\nstatistical equivalence (with the possible exception of the light sea asymmetry at small x,\nwhich is subject to very large uncertainties). We conclude that there is no significant loss\nof accuracy in the reweighting due to the unweighting.\nWe can now study the information contained in the unweighted set as the number of\n\u2032\nis varied. To this purpose, we compute the relative Shannon\nunweighted replicas Nrep\nentropy between the unweighted set and the original weighted set, defined as\nNrep\n\u2032\nHR (Nrep\n)\n\n=\n\nX\nk=1\n\np\u2032k ln\n\np\u2032k\n,\npk\n\n(28)\n\n\u2032 . If the starting\nwhere p\u2032k are the probabilities Eq. (26), defined for each value of Nrep\n\u2032 \u223cN\nnumber of replicas Nrep is large enough that Nrep\nrep is already in the asymptotic region\n\u2032 )\n\u2032\n\u223c Nrep the relative entropy HR (Nrep\nwhere Eq. (24) holds, then clearly for large Nrep\n\u2032\n\u2032\nshould fall to zero. For lower values of Nrep HR (Nrep ) measures the information loss\nbetween the original weighted set and the unweighted one.\n\u2032 ). It is clear that H (N \u2032 ) falls linearly as a function\nIn Fig. 3 we display HR (Nrep\nR\nrep\n\u2032\nof Nrep up to Neff , as more and more of the information in the weighted set is included.\n\u2032 \u223cN\n\u2032\nAround Nrep\neff the slope of the fall changes abruptly, and HR (Nrep ) then falls slowly\n\u2032\n\u2032\nto zero as Nrep increases, being already close to zero when Nrep \u223c Neff . This can also be\n\u2032 of the unweighted set as\nseen by computing directly the effective number of replicas Neff\n\u2032\na function of Nrep , which can be determined using Eq. (10) of Ref. [14], with the weights\nwk\u2032 Eq. (24) and N = Nrep . Note that the result is nontrivial because some of the wk\u2032 are\n\u2032\ncomes about only\nzero, others are integers larger than one, and the dependence on Nrep\nthrough the definition of the weights Eq. (24). The result is also shown in Fig. 3: at first\n\n13\n\n\fUnweighting of ( NNPDF2.0 1000 + TeVWlasy(RW) )\n\nUnweighting of ( NNPDF2.0 1000 + TeVWlAsy(RW) )\n\nShannon Entropy ( N'rep )\n\n3\n\nN'eff\nN'rep\n\n1000\n\n2.5\n\n500\n\n2\n1.5\n1\n\n100\n0.5\n50\n0\n50\n\n100\n\n500\n\n1000\n\nN'rep\n\n50\n\n100\n\n500\n\n1000\n\nN'rep\n\nFigure 5: Same as Fig. 3, but for the pair of reweighted and unweighted PDFs described in the\ncaption of Fig. 4.\n\u2032 grows linearly as a function of N \u2032 , and is in fact very nearly equal to it. However\nNeff\nrep\n\u2032\n\u2248 Neff , the linear growth breaks off abruptly, and saturates at the\nwhen it reaches Nrep\n\u2032 = N , which is reached asymptotically. Hence our expectation is borne out by\nvalue Neff\neff\nthese plots: the amount of information in the unweighted set increases with the number\n\u2032 , but only up to the point N \u2032\nof unweighted replicas Nrep\nrep \u2248 Neff , after which nothing is\n\u2032\ngained by further increasing Nrep .\nWe now repeat the same analysis for the unweighting of the NNPDF2.0 set, reweighted\nwith the inclusive electron and muon D0 Run\u2013II W lepton asymmetry data [20, 21]. The\nreweighting procedure for these data was presented in detail in Ref. [14]. The effective\nnumber of replicas, after reweighting a starting set of Neff = 1000 replicas, is in this case\n\u2032\n= 100, as in\nNeff = 356. Again, we can choose the size of the unweighted set to be Nrep\nthe case above, and we perform the unweighting following the same procedure as before.\nIn Fig. 4 we show the distance between the reweighted and unweighted sets, and\nin Fig. 5 we plot the relative entropy between these two sets and the effective number\nof replicas in the unweighted set as a function of the number of unweighted replicas.\nThe conclusions are the same as before: the unweighted set is indistinguishable from the\n\u2032 is of the same order\nreweighted one, provided that the number of unweighted replicas Nrep\nas the effective number of reweighted replicas Neff . In the sequel we will thus feel free\nto use unweighted replica sets instead of their weighted counterparts, to which they are\nessentially equivalent.\n\n14\n\n\f4\n4.1\n\nConsistency\nMultiple Reweighting\n\nAs we discussed in Sec. 2.3, when adding two new datasets to a set of prior PDFs, one\nway to proceed is to treat them as a single combined dataset, as in Eq. (15), i.e., with\nweights \u03c7(n\u22121) exp(\u2212\u03c72 /2) with \u03c72 = \u03c721 + \u03c722 and n = n1 + n2 . However, it should also\nbe possible to treat them separately, weighting with first one dataset, then the other. If\nwe do this using Eq. (20) then by construction we get the same answer that we would get\nby including the two sets at once, but this is trivial, because in the weights Eq. (20) the\neffect of the first weighting is divided out.\nHowever, we can test non-trivially that two subsequent weightings by two independent\ndatasets commute by incorporating the unweighting procedure. Formally we define the operation R\u0302 as reweighting with the weights given by Eq. (11), and an unweighting operation\n\u00db , as described in Sec. 3.1. Note that because the unweighting operator is a projection\noperator, it has no inverse. Weighting an existing PDF set by incorporating information\nfrom a new dataset then consists of the combined 'weighting' operation \u0174 = \u00db R\u0302. The\nweighting operation takes a set of replicas {fk }, all equally probable, and replaces it with\na subset which are again all equally probable, but the selection of which reflects information contained in the new dataset that was used in the reweighting R\u0302. Clearly \u0174 has no\ninverse, since it projects onto a lower dimensional space.\nNow consider two datasets: the set of replicas produced by the action of weighting with\nthe first dataset, \u01741 , can be subject to a further weighting with the second dataset \u01742 .\nNow of course the formula used to evaluate the weights used for the second reweighting\nmust again be given by Eq. (11): the subset of replicas produced by \u01741 are again all\nequally probable, so the second reweighting must work in precisely the same way as the\nfirst. The only difference is that \u01742 acts only on those replicas produced by the action of\n\u01741 .\nNow for consistency it cannot matter in what order we perform these two weightings,\nand indeed their combined effect must be the same as for a single weighting \u017412 , which\ntreats the two datasets as a single dataset: \u017412 = \u01742 \u01741 = \u01741 \u01742 , or more explicitly\n\u00db R\u030212 = \u00db R\u03022 \u00db R\u03021 = \u00db R\u03021 \u00db R\u03022 .\n\n(29)\n\nSo, for weighting to be consistent it must satisfy two nontrivial conditions: the combination\nproperty, and the commutation property. Clearly the first always implies the second (if\n\u01741 \u01742 = \u017412 , clearly \u01742 \u01741 = \u01741 \u01742 , because R\u030212 is performed using weights determined\nthrough the total \u03c72 = \u03c721 +\u03c722 ), but not the reverse (we might have \u01742 \u01741 = \u01741 \u01742 6= \u017412\nif the formula Eq. (11) was incorrect).\nIn the remaining part of this Section we present two tests of the combination and\ncommutation properties when two datasets are included. First, we consider sets of data\nfor the same observable (the one-jet inclusive cross-section) in the same kinematic region\nby two different experiments. Then, we consider data for two different observables (a\njet cross-section and a Drell-Yan cross section) which affect different PDFs in different\nkinematic regions.\n\n15\n\n\fData points\nNeff\n\nCDF\n76\n290.8\n\nD0\n110\n565.8\n\nCDF+D0\n186\n334.5\n\nTable 1: Datasets used in the Tevatron Run II inclusive jet reweighting exercise. For each\nset the number of data points and the effective number of replicas of the reweighted set\nof Nrep = 1000 replicas are given.\nCDF/D0 Inclusive Jets - xg(x,Q2)\n\nCDF/D0 Inclusive Jets - xg(x,Q 2), ratio to NNPDF2.0 DIS+DY\n0\n\nxg[x,Q20]\n\n0\n\nxg[x,Q2]\n\n0\n\n1\n\nPrior (NNPDF 2.0 DIS+DY)\nRefitted (NNPDF 2.0)\nW(CDF+D0)\nW(CDF)W(D0)\n\n0.8\n\nW(D0)W(CDF)\n\n3\n\nPrior (NNPDF 2.0 DIS+DY)\nRefitted (NNPDF 2.0)\nW(CDF+D0)\nW(CDF)W(D0)\nW(D0)W(CDF)\n\n2.5\n\n2\n\n0.6\n\n1.5\n\n1\n0.4\n0.5\n0.2\n\n0\n\n-0.5\n0\n0.2\n\n0.25\n\n0.3\n\n0.35\n\n0.4\n\n0.45\n\n0.5\n\n0.55\n\n0.6\n\n0.65\n\n-1\n0.2\n\n0.7\n\nx\n\n0.25\n\n0.3\n\n0.35\n\n0.4\n\n0.45\n\n0.5\n\n0.55\n\n0.6\n\n0.65\n\n0.7\n\nx\n\nFigure 6: Comparison of the large-x gluon PDF for prior set, reweighted sets with different\nsuccessive reweighting orders and refitted set, when the jet data of Table 1 are included in\nthe NNPDF2.0 NLO DIS+DY fit. Results are shown at Q2 = 2 GeV2 , both in absolute\nscale (left) and as a ratio to the prior (right).\n\n4.2\n\nTevatron Inclusive Jets\n\nThe first exercise we present is an extension of the reweighting proof-of-concept in Section 4\nof [14]. There, Run II Tevatron inclusive jet data production were included by reweighting\na PDF set extracted from a NLO fit to DIS and Drell-Yan data (NNPDF2.0 DIS+DY) and\nthe results compared to those obtained from a fit which included the same DIS, Drell-Yan\nand inclusive jet datasets all treated in the same way (NNPDF2.0).\nIn this Section we look again at the inclusion via reweighting of the same datasets,\nnamely the CDF Run II-kt and D0 Run II-cone inclusive jet data in the NNPDF2.0\nDIS+DY fit, but we now focus on comparing the results obtained in the following two\ncases:\n(a) the two new datasets are included by reweighting the prior fit in a single step with\nboth datasets;\n(b) one of the datasets is included by reweighting, an unweighted set of PDFs is constructed using the procedure detailed in Section 3, and finally the latter set is\nreweighted again with the second dataset.\nWe will carry out the successive reweighting procedure (b) twice, exchanging the order\nin which the CDF and D0 datasets are included, in order to test the commutativity of\nthe procedure. A final unweighting is performed for all the reweighted sets and the PDF\ncomparisons and computations of distances are performed using these unweighted sets.\nThe number of data points and the effective number of replicas Neff after reweighting\nwith these data of a set of Nrep = 1000 replicas are summarized in Table 1. In each\n16\n\n\fDistance between central values\n\n3.5\n\nd[q(x,Q02)]\n\n3\n2.5\n\nDistance between PDF uncertainties\n4\n\n\u03a3\ng\nT3\nV\n\n3.5\n\n\u2206 S\ns+\ns-\n\n3\nd[\u03c3q(x,Q02)]\n\n4\n\n2\n1.5\n\n2.5\n2\n\n1\n\n1\n0.5\n0.0001\n\n0.001\n\n0.01\n\n\u2206 S\ns+\ns-\n\n1.5\n\n0.5\n0\n1e-05\n\n\u03a3\ng\nT3\nV\n\n0\n1e-05\n\n0.1\n\n0.0001\n\n0.001\n\nx\n\n0.01\n\n0.1\n\nx\n\nFigure 7: Distances between central values (left) and uncertainties (right) of PDFs from\nreweighting with the combined CDF+D0 dataset and PDFs from reweighting first with\nCDF data and then with D0 data.\nDistance between central values\n\n3.5\n\nd[q(x,Q02)]\n\n3\n2.5\n\nDistance between PDF uncertainties\n4\n\n\u03a3\ng\nT3\nV\n\n3.5\n\n\u2206 S\ns+\ns-\n\n3\nd[\u03c3(x,Q02)]\n\n4\n\n2\n1.5\n\n2.5\n2\n\n1\n\n1\n0.5\n0.0001\n\n0.001\n\n0.01\n\n\u2206 S\ns+\ns-\n\n1.5\n\n0.5\n0\n1e-05\n\n\u03a3\ng\nT3\nV\n\n0\n1e-05\n\n0.1\n\nx\n\n0.0001\n\n0.001\n\n0.01\n\n0.1\n\nx\n\nFigure 8: Distances between central values (left) and uncertainties (right) of PDFs obtained by reweighting with CDF and D0 jet data included in either order.\nData points\nNeff\n\n(CDF+D0)\n186\n627.1\n\nE605\n119\n59.5\n\n(CDF+D0)+E605\n305\n63.7\n\nTable 2: As Tab. 1, but now for the E605 and inclusive jet reweighting exercise.\n\u2032 = 100 unweighted replicas. When the reweighting is\ncase, we construct a final set of Nrep\nperformed in two steps, we first construct a (redundant) set of 1000 unweighted replicas,\nwhich is then reweighted and unweighted again to obtain the final set of 100 unweighted\nreplicas.\nAs discussed in Refs. [7, 14], Tevatron jet data mostly affect the gluon at large x,\nleaving all other PDFs essentially unchanged. The impact of the inclusion of these data\nin the fit is shown in Fig. 6 where we compare the gluon for the prior set, the refitted one,\nand sets obtained reweighting the prior in the three different ways described above. As in\nthe previous Section, a more quantitative assessment can be made by computing distances\nbetween various pairs of PDF sets. In Fig. 7 we show the distance between PDFs obtained\nby reweighting with the two sets at once and those found including CDF data first and\nD0 data next, while in Fig. 8 we show distances between sets obtained by including the\nCDF and D0 data in either order. It is clear that the three reweighting procedures lead\nto completely equivalent results.\n\n17\n\n\fE605/Inclusive Jets - xg(x,Q2)\n\nE605/Inclusive Jets - xg(x,Q2), ratio to NNPDF2.1 DIS\n0\n\nxg[x,Q20]\n\n0\n\nxg[x,Q2]\n\n0\n\n1\nPrior (NNPDF 2.1 DIS)\nW(Jets+E605)\nW(Jets)W(E605)\n\n0.8\n\n3\n\nPrior (NNPDF 2.1 DIS)\nW(Jets+E605)\nW(Jets)W(E605)\n\n2.5\n\nW(E605)W(Jets)\n\nW(E605)W(Jets)\n2\n0.6\n\n1.5\n\n1\n0.4\n0.5\n0.2\n\n0\n\n-0.5\n0\n0.2\n\n0.25\n\n0.3\n\n0.35\n\n0.4\n\n0.45\n\n0.5\n\n0.55\n\n0.6\n\n0.65\n\n-1\n0.2\n\n0.7\n\n0.25\n\n0.3\n\n0.35\n\n0.4\n\n0.45\n\n0.5\n\n0.55\n\n0.6\n\n0.65\n\nx\n\nxV[x,Q20]\n\nE605/Inclusive Jets -\n\n0\n\nxV[x,Q2]\n\nE605/Inclusive Jets -\n\nPrior (NNPDF 2.1 DIS)\n1\n\nW(Jets+E605)\nW(Jets)W(E605)\n\n0.7\n\nx\n\nxV(x,Q2)\n0\n\nxV(x,Q20),\n\nratio to NNPDF2.1 DIS\n\n1.15\n\nPrior (NNPDF 2.1 DIS)\nW(Jets+E605)\nW(Jets)W(E605)\n\n1.1\n\nW(E605)W(Jets)\n\nW(E605)W(Jets)\n0.8\n1.05\n\n0.6\n1\n\n0.4\n\n0.95\n\n0.2\n\n0\n0.1\n\n0.9\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\n0.85\n0.2\n\n0.7\n\nx\n\n0.25\n\n0.3\n\n0.35\n\n0.4\n\n0.45\n\n0.5\n\n0.55\n\n0.6\n\n0.65\n\n0.7\n\nx\n\nFigure 9: Comparison of the large-x gluon and quark valence PDFs for prior set and\nreweighted sets with different successive reweighting orders, when the jet and Drell-Yan\ndata of Table 2 are included in the NNPDF2.1 NLO DIS fit. Results are shown at Q2 =\n2 GeV2 , both in absolute scale (left) and as a ratio to the prior (right).\n\n4.3\n\nJet and Drell-Yan data\n\nIn this second exercise we start from a NLO fit to DIS data, NNPDF2.1 NLO DIS [8], and\ninclude the Tevatron inclusive jet data discussed in the previous section (D0 and CDF as\na single dataset) and data from one of the Drell-Yan experiments which are included in\nthe NNPDF2.1 global analysis (the E605 fixed target experiment [17]).\nThe number of data points and the effective number of replicas Neff in this case are\n\u2032\n= 100 unweighted\nsummarized in Table 2. Also in this case, we construct a set of Nrep\n\u2032\nreplicas, with Nrep = 1000 unweighted replicas in the intermediate step if any. Note that\nthis is a much less symmetric example than the previous one: the Drell-Yan data have a\n\u2032 > N ).\nmuch greater impact than the jet data (in fact for the Drell-Yan data Nrep\neff\nAs already mentioned, the jet data affect mostly the large x gluon, while the Drell-Yan\ndata have mostly an impact on the quark flavour and antiflavour separation. The impact\nof these data on the gluon and the total quark valence distribution are shown in Fig. 9,\nwhere we show the results obtained by reweighting with the two sets included together,\nor one after another in either order. Note that in this case we do not have a refitted set.\nDistances between PDFs obtained by reweighting in the combined set, or first with jets\nthen with Drell-Yan are shown in Fig. 10. Distances between PDFs obtained reweighting\nin either order are shown in Fig. 11. The test is clearly as successful here as it was in the\nprevious case, despite being perhaps more challenging.\n\n18\n\n\fDistance between central values\n\n3.5\n\nd[q(x,Q02)]\n\n3\n2.5\n\nDistance between PDF uncertainties\n4\n\n\u03a3\ng\nT3\nV\n\n3.5\n\n\u2206 S\ns+\ns-\n\n3\nd[\u03c3(x,Q02)]\n\n4\n\n2\n1.5\n\n2.5\n2\n\n1\n\n1\n0.5\n0.0001\n\n0.001\n\n0.01\n\n\u2206 S\ns+\ns-\n\n1.5\n\n0.5\n0\n1e-05\n\n\u03a3\ng\nT3\nV\n\n0\n1e-05\n\n0.1\n\n0.0001\n\n0.001\n\nx\n\n0.01\n\n0.1\n\nx\n\nFigure 10: Distances between central values (left) and uncertainties (right) of PDFs from\nreweighting with the combined jet+Drell-Yan dataset and PDFs from reweighting first\nwith jet data and then with Drell-Yan data.\nDistance between central values\n\n3.5\n\nd[q(x,Q02)]\n\n3\n2.5\n\nDistance between PDF uncertainties\n4\n\n\u03a3\ng\nT3\nV\n\n3.5\n\n\u2206 S\ns+\ns-\n\n3\nd[\u03c3(x,Q02)]\n\n4\n\n2\n1.5\n\n2.5\n2\n\n1\n\n1\n0.5\n0.0001\n\n0.001\n\n0.01\n\n\u2206 S\ns+\ns-\n\n1.5\n\n0.5\n0\n1e-05\n\n\u03a3\ng\nT3\nV\n\n0\n1e-05\n\n0.1\n\nx\n\n0.0001\n\n0.001\n\n0.01\n\n0.1\n\nx\n\nFigure 11: Distances between central values (left) and uncertainties (right) of PDFs obtained reweighting jet data and Drell-Yan data included in either order.\n\n19\n\n\f5\n\nThe W asymmetry at the LHC\n\nIn this section we will use the reweighting technique presented here and in Ref. [14] to\nstudy the effect of including in the NNPDF2.1 NLO global fit the W lepton asymmetry\nmeasurements produced by the experimental collaborations at the LHC, and based on\ndata collected in the 2010 run.\nThe W leptonic charge asymmetry is defined in terms of the W \u00b1 \u2192 l\u00b1 \u03bdl differential\ncross-sections d\u03c3l\u00b1 /d\u03b7l , with \u03b7l being the pseudorapidity of the lepton coming from the\ndecay of the W boson, as\nAlW =\n\nd\u03c3l+ /d\u03b7l \u2212 d\u03c3l\u2212 /d\u03b7l\nd\u03c3l+ /d\u03b7l + d\u03c3l\u2212 /d\u03b7l\n\n(30)\n\nwhere the cross-sections are computed inside the acceptance cuts used to select the W \u2192\nl\u03bdl events.\nThe ATLAS Collaboration published a first measurement of the muon charge asymmetry from W boson production in the pseudorapidity range |\u03b7| < 2.4, based on 31pb\u22121\nof accumulated luminosity [22], while CMS published a measurement of the muon and the\nelectron charge asymmetries in the pseudorapidity range |\u03b7| < 2.2, based on 36pb\u22121 of\ndata [23]. The data provide a constraint for the above combination of PDFs in the region\n\u22121\n10\u22123 <\n\u223cx <\n\u223c 10 , where they are only partially constrained by the data already included\nin the NNPDF global analysis. In particular, while u is very well determined by fixed\ntarget DIS data, d and the light sea (d \u0304 \u2212 \u016b) are currently much less constrained.\nThe LHCb collaboration presented preliminary results for a measurement of the muon\ncharge asymmetry in the pseudorapidity range 2 < |\u03b7| < 4.5, covered by the LHCb\ndetector. This measurement probes PDFs in the small and large x regions, where data\nincluded so far in the global analyses provide much looser constraints. For this reason\nthey might eventually have a substantially larger impact on global fits than the ATLAS\nor CMS data. However, at the time of writing these experimental results have only been\npresented in preliminary form [24], and are therefore not included in this study.\n\n5.1\n\nInclusion of individual experiments\n\nWe begin by checking the compatibility of the individual ATLAS and CMS datasets for\nthe charge lepton asymmetry with the data included in the NNPDF2.1 global fit, and by\nstudying their impact when they are included separately in the fit using the reweighting\ntechnique presented in this paper.\nThe ATLAS muon charge asymmetry data [22] and CMS electron and muon data [23]\nare compared to the predictions obtained using three different NLO global fits, CT10 [25],\nMSTW2008 [26] and NNPDF2.1 in Fig. 5.1. The theoretical predictions including NLO\nQCD corrections are obtained using the fully differential Monte Carlo code DYNNLO [27]\nwhich allows for the implementation of arbitrary experimental cuts.\nTo give a more quantitative estimate of the level of agreement of the different predictions with the experimental data, in Table 3 we collect the \u03c72 per number of data\npoints for each individual dataset. Since no covariance matrix is provided by the LHC\nexperiments at this point, we add statistical and systematic uncertainties in quadrature\nin the computation of the \u03c72 values.\n\n20\n\n\f0.26\n\n0.26\n\n0.26\n\n0.24\n\n0.24\n\n0.24\n\n0.22\n\n0.22\n\n0.22\n\n0.2\n\n0.18\n\nA(\u03b7\u03bc)\n\n0.3\n0.28\n\nA(\u03b7e)\n\n0.3\n0.28\n\nA(\u03b7)\n\n0.3\n0.28\n\n0.2\n\n0.18\nNNPDF2.1nlo\n\n0.16\n\nCT10\nMSTW08nlo\n\n0.14\n\n-1\n\n0.1\n0\n\nMSTW08nlo\nCMS Ae(36 pb-1)\n\n0.12\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n1.2\n\u03b7\n\n1.4\n\n1.6\n\n1.8\n\n2\n\n2.2\n\n2.4\n\n0.1\n0\n\nNNPDF2.1nlo\n\n0.16\n\nCT10\n\n0.14\n\nATLAS(31 pb )\n\n0.12\n\n0.2\n\n0.18\nNNPDF2.1nlo\n\n0.16\n\nCT10\nMSTW08nlo\n\n0.14\n\nCMS A\u03bc (36 pb-1)\n\n0.12\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n1.2\n\u03b7e\n\n1.4\n\n1.6\n\n1.8\n\n2\n\n2.2\n\n2.4\n\n0.1\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\u03b7\u03bc\n\n1.2\n\n1.4\n\n1.6\n\n1.8\n\n2\n\nFigure 12: Predictions for the W lepton asymmetry at NLO, obtained with DYNNLO [27]\nusing the CT10, MSTW08 and NNPDF2.1 parton sets, compared to measurements for\nthe muon charge asymmetry from ATLAS [22] (left plot), and the electron (centre plot)\nand muon (right plot) charge asymmetries from CMS [23].\nATLAS(31pb\u22121 )\nCMS(36pb\u22121 ) electron pT > 25 GeV\nCMS(36pb\u22121 ) muon pT > 25 GeV\n\nNdat\n11\n6\n6\n\nNNPDF2.1\n0.76\n1.83\n1.24\n\nCT10\n0.77\n1.19\n0.73\n\nMSTW08\n3.32\n1.70\n0.77\n\nTable 3: Values of \u03c72 /Ndat for the ATLAS and CMS lepton charge asymmetry data\nfor different PDFs sets. Theory predictions are computed at NLO accuracy using the\nDYNNLO code. Note that in Ref. [22] a somewhat lower value is quoted for MSTW08,\ndue to the use of the MC@NLO code.\nThe ATLAS muon charge asymmetry data are already very well described by the\nNNPDF2.1 prediction before being included in the analysis. This is shown by the excellent\n\u03c72 /Ndat = 0.76 reported in Table 3 and demonstrated by the distribution of \u03c72 for the\nindividual replicas before reweighting shown in the left plot of Fig. 13, which has a sharp\npeak around one. The compatibility of a new dataset with the data already included in a\nglobal analysis can be assessed by looking at the probability density for the parameter \u03b1,\nP(\u03b1) defined in Eq. (12) of [14]. If this probability distribution peaks close to one, the new\ndata are consistent with the ones already included in the global fit. For the ATLAS data,\nthe P (\u03b1) distribution, shown in the right plot of Fig. 13, is peaked slightly below one,\nthereby showing the good compatibility of these data with those included in the global\nanalysis. Note that optimal values of \u03c72 /Ndat are to be expected because statistical and\nsystematic errors have been added in quadrature, thereby leading to an overestimation of\nuncertainties.\nAfter reweighting NNPDF2.1 with the ATLAS data the quality of their description\nremains substantially unchanged, with the value \u03c72rw /Ndat = 0.72. The number of effective\nreplicas of the reweighted sets computed according to Eq. (42) in Appendix of [14] is\nNeff = 928, out of the initial number of Nrep = 1000 replicas in the prior. The distribution\nof the \u03c72 /Ndat for the weighted replicas, shown in the center plot of Fig. 13, peaks just\nbelow one, again confirming the very good description of these data also after reweighting.\nGiven the outcome of the previous statistical analysis \u2013 a very good description of\nthe data by the prior set to start with, resulting in a large number of surviving replicas\n(Neff = 928) \u2013 it is easy to predict that the ATLAS data alone will impose only mild\n\n21\n\n\fP(\u03b1 )\nP(\u03b1 )\n\nWeighted distribution of chi2-new/Ndat\n\nDistribution of chi2-new/Ndat\n0.22\n\n0.35\n\n0.2\n\n160\n\n0.18\n\n140\n\n0.3\n\n120\n\n0.25\n\n0.16\n0.14\n\n100\n\n0.12\n0.1\n\n80\n\n0.08\n\n60\n\n0.2\n0.15\n\n0.06\n\n0.1\n\n40\n\n0.04\n\n0\n0\n\n0.05\n\n20\n\n0.02\n0.5\n\n1\n\n1.5\n2\n2.5\nChi2 distribution\n\n3\n\n3.5\n\n0\n0\n\n4\n\n0.5\n\n1\n1.5\nChi2 weigthed distribution\n\n2\n\n0\n0\n\n2.5\n\n1\n\n2\n\n3\n\n4\n\n5\n\n\u03b1\n\nFigure 13: Distribution of \u03c72 /Ndat for individual replicas prior (left) and after (middle)\nreweighting and P(\u03b1) distribution (right) for the ATLAS muon charge asymmetry data.\nIn the left plot the shaded region corresponds to the central 68% of the distribution.\nQ2 = M2W , ratio to NNPDF2.1\n\nQ2 = M2W , ratio to NNPDF2.1\n\n1.3\n1.25\n1.2\n\n1.3\nNNPDF2.1\n\n1.25\n\nNNPDF2.1 + ATLAS(pl >20GeV)\nT\n\n1.2\n\n1.1\n\n1.05\n\n1.1\n\n1\n\n1\n0.95\n\n0.9\n\n0.9\n10\n\n-4\n\n-3\n\n-2\n\n10\n\nx\n\n10\n\n10\n\n0.85 -5\n10\n\n-1\n\nQ2 = M2W , ratio to NNPDF2.1\n\n1.2\n\n1.25\n\nNNPDF2.1 + ATLAS(pl >20GeV)\nT\n\n1.2\n\nx\n\n10-2\n\n10-1\n\nNNPDF2.1\nNNPDF2.1 + ATLAS(pl >20GeV)\nT\n\n1.15\n\n1.1\n\nxubar\n\nxu\n\n-3\n\n10\n\n1.3\nNNPDF2.1\n\n1.15\n\n1.05\n\n1.1\n\n1.05\n\n1\n\n1\n\n0.95\n\n0.95\n\n0.9\n0.85 -5\n10\n\n10-4\n\nQ2 = M2W , ratio to NNPDF2.1\n\n1.3\n1.25\n\nT\n\n1.05\n\n0.95\n\n0.85 -5\n10\n\nNNPDF2.1 + ATLAS(pl >20GeV)\n\n1.15\nxdbar\n\nxd\n\n1.15\n\nNNPDF2.1\n\n0.9\n10\n\n-4\n\n-3\n\n10\n\n-2\n\nx\n\n10\n\n10\n\n0.85 -5\n10\n\n-1\n\n10-4\n\n-3\n\n10\n\nx\n\n10-2\n\n10-1\n\n2\nFigure 14: Comparison of light quark and antiquark distributions at the scale Q2 = MW\nfrom the global NNPDF2.1 NLO global fit and the same distributions obtained after\nadding ATLAS muon charge asymmetry data via reweighting. Parton densities are plotted\nnormalized to the NNPDF2.1 central value.\n\nconstraints on the underlying PDFs. This is in fact what is seen in Fig. 14 where we\n2 to the ones\ncompare the NNPDF2.1 light (anti)flavour densities at the scale Q2 = MW\nobtained after reweighting with the ATLAS data. The most noticeable effect is a reduction\nof the uncertainties on these PDFs in the medium-small x region, around x \u223c 10\u22123 , by\nup to 20%.\nWe now turn to the CMS measurements described in [23]. CMS presented data for\nboth the electron and muon charge asymmetries from W decays with two different cuts on\nthe transverse momentum of the detected lepton: p\u22a5 > 25 GeV and p\u22a5 > 30 GeV. From\nthe values for \u03c72 /Ndat obtained using the NNPDF2.1 global set reported in Table 3, and\nthe plots of the distribution of \u03c72 /Ndat for individual replicas and of the P(\u03b1) distribution\n\n22\n\n\fP(\u03b1 )\n\n0.1\n\n100\n\n0.08\n\n80\n\n0.06\n\n60\n\n0.04\n\n40\n\n0.02\n\n20\n\nP(\u03b1 )\n\nWeighted distribution of chi2-new/Ndat\n\nDistribution of chi2-new/Ndat\n\n0.16\n0.14\n0.12\n0.1\n0.08\n0.06\n0.04\n0.02\n\n0\n0\n\n1\n\n2\n\n3\n4\nChi2 distribution\n\n5\n\n6\n\n7\n\n0\n0\n\n0.5\n\n1\n1.5\nChi2 weigthed distribution\n\n2\n\n0\n0\n\n2.5\n\n1\n\n2\n\n3\n\n4\n\n5\n\n1\n\n2\n\n3\n\n4\n\n5\n\n\u03b1\n\nP(\u03b1 )\n\nWeighted distribution of chi2-new/Ndat\n\nP(\u03b1 )\n\nDistribution of chi2-new/Ndat\n\n0.22\n\n0.14\n\n0.2\n\n100\n\n0.18\n\n0.12\n\n0.16\n\n80\n0.1\n\n0.14\n\n0.08\n\n60\n\n0.12\n\n40\n\n0.08\n\n0.1\n0.06\n\n0.06\n\n0.04\n\n0.04\n\n20\n\n0.02\n\n0.02\n\n0\n0\n\n1\n\n2\n\n3\n4\nChi2 distribution\n\n5\n\n6\n\n7\n\n0\n0\n\n0.5\n\n1\n1.5\nChi2 weigthed distribution\n\n2\n\n2.5\n\n0\n0\n\n\u03b1\n\nFigure 15: Same as Fig. 13 for the CMS(pT > 25 GeV) (top) and CMS(pT > 30 GeV)\n(bottom) lepton charge asymmetry data.\nQ2 = M2W , ratio to NNPDF2.1\n\nQ2 = M2W , ratio to NNPDF2.1\n\n1.3\n\n1.3\n\nNNPDF2.1\n\n1.25\n\nNNPDF2.1 + CMS(plT >25GeV)\n\n1.2\n\nNNPDF2.1 + CMS(plT >25GeV)\n\n1.2\n\n1.15\n\n1.15\n\n1.1\n\nxubar\n\nxu\n\nNNPDF2.1\n\n1.25\n\n1.05\n\n1.1\n\n1.05\n\n1\n\n1\n\n0.95\n\n0.95\n\n0.9\n\n0.9\n\n0.85 -5\n10\n\n0.85 -5\n10\n\n2\n\nQ =\n\nM2W ,\n\n10-4\n\n-3\n\n10\n\nx\n\n10-2\n\n10-1\n\n2\n\nratio to NNPDF2.1\n\nQ =\n\n1.3\n1.25\n1.2\n\nNNPDF2.1\n\n1.25\n\nNNPDF2.1 + CMS(plT >25GeV)\n\n1.2\n\n-3\n\n10\n\nx\n\n10-2\n\n10-1\n\nratio to NNPDF2.1\nNNPDF2.1\nNNPDF2.1 + CMS(plT >25GeV)\n\n1.15\n\n1.1\n\nxdbar\n\nxd\n\n10-4\n\n1.3\n\n1.15\n\n1.05\n\n1.1\n\n1.05\n\n1\n\n1\n\n0.95\n\n0.95\n\n0.9\n0.85 -5\n10\n\nM2W ,\n\n0.9\n10-4\n\n-3\n\n10\n\nx\n\n10-2\n\n0.85 -5\n10\n\n10-1\n\n10-4\n\n-3\n\n10\n\nx\n\n10-2\n\n10-1\n\nFigure 16: Same as Fig. 14 but after adding CMS lepton charge asymmetry data.\nshown in Fig. 15, we see that both sets are equally well described by the NNPDF2.1 set\nand thus compatible with the data included in the global analysis. Since the two datasets\nare not independent we have to choose which one to use in our reweighting analysis and\nthus we only consider the dataset with the looser cut pT > 25 GeV, which proves to be\nmore constraining of the PDFs. We perform our reweighting analysis including the muon\nand electron data as a single dataset.\nThe NNPDF2.1 prediction provides a good, though not optimal, description of the\nCMS data, as shown by the \u03c72 /Ndat = 1.51 obtained combining the values for the elec23\n\n\f0.3\n\n0.3\n\n0.28\n\n0.28\n\n0.26\n\n0.26\n\n0.24\n\n0.24\n\n0.22\n\n0.22\nA(\u03b7l)\n\nA(\u03b7l)\n\ntron and muon data collected in Table 3. After reweighting, the description of these data\nimproves significantly with \u03c72rw /Ndat = 0.77. The number of effective replicas computed\nas above is roughly half the initial number of replicas, Neff = 531 out of Nrep = 1000, suggesting that these data will have have a significant impact on the PDFs. The distribution\nof the \u03c72 /Ndat of individual replicas after reweighting is centered around one, as shown in\nthe middle-upper plot of Fig. 15.\nThe impact of the CMS data on light (anti)flavour PDFs, is shown in Fig. 16 where we\nobserve a reduction of uncertainties in the medium x region smaller than that due to the\nATLAS data, but also a change in the shape of the \u016b and d \u0304 distributions at relatively large\nx \u223c 0.1, pushing up the central value a little and reducing the uncertainties by around\n10% for the down distributions and as much as 25% for the up.\nWe conclude this Section by comparing the predictions for the charge asymmetry\ncomputed with NNPDF2.1 and NNPDF2.1 after reweighting with the ATLAS and CMS\ndata respectively in Fig. 17. The effect on the prediction for the CMS data is more\nsubstantial, because the data undershoot the NNPDF2.1 NLO prediction in most of the\nhigher rapidity bins.\n\n0.2\n0.18\n\n0.2\n0.18\n\nNNPDF2.1\n\n0.16\n\nNNPDF2.1\nNNPDF2.1 rw CMS\nCMS Data (36 pb-1, pe >25GeV)\nT\n\u03bc\nCMS Data (36 pb-1, p >25GeV)\n\n0.16\n\nNNPDF2.1 rw ATLAS\n\n0.14\n\n0.14\n\n-1\n\nATLAS Data (31 pb )\n\nT\n\n0.12\n0.1\n0\n\n0.12\n0.5\n\n1\n\n1.5\n\n2\n\n0.1\n0\n\n2.5\n\n0.5\n\ny\n\n1\n\n\u03b7l\n\n1.5\n\n2\n\n2.5\n\nFigure 17: Comparison of the lepton charge asymmetry from W boson production computed with the NNPDF2.1 NLO PDF set and sets where ATLAS (left) and CMS (right)\nlepton charge asymmetry data have been included using reweighting.\n\n5.2\n\nCombination of ATLAS and CMS data\n\nWe now consider adding the ATLAS and CMS lepton charge asymmetry data as a single\ndataset to the NNPDF2.1 NLO global fit using reweighting.\nThe whole dataset is already well described by the NNPDF2.1 NLO dataset with\n2\n\u03c7 /Ndat = 1.17 and the distributions of \u03c72 /Ndat for individual replicas having a sharp peak\naround one, as shown by the left plot in Fig. 18. The compatibility of the ATLAS+CMS\ndata with the data included in the global analysis and among the two experiments is also\ngood, as can be deduced by looking at the P(\u03b1) distribution shown in the right plot in\nFig. 18, which is nicely peaked around one.\nAfter reweighting the description of the data improves, with \u03c72rw /Ndat = 0.95 with the\ndistribution of \u03c72rw /Ndat for individual replicas shown in the middle plot of Fig. 18 showing\na sharp peak around one. These results, combined with the number of effective replicas\nsurviving after reweighting, namely Neff = 619 out of the initial Nrep = 1000, show that\nthe use of the ATLAS and CMS data together in the fit is not only possible but imposes\n24\n\n\fP(\u03b1 )\nP(\u03b1 )\n\nWeighted distribution of chi2-new/Ndat\n\nDistribution of chi2-new/Ndat\n\n0.35\n\n0.22\n220\n\n0.2\n\n200\n\n0.18\n\n0.3\n\n180\n0.16\n\n0.25\n\n160\n\n0.14\n\n140\n\n0.12\n\n0.2\n\n120\n\n0.1\n\n100\n\n0.08\n\n80\n\n0.06\n\n60\n\n0.04\n\n40\n\n0.02\n\n20\n\n0\n0\n\n1\n\n2\n\n3\n4\nChi2 distribution\n\n5\n\n6\n\n0.15\n0.1\n0.05\n\n0\n0\n\n0.5\n\n1\n1.5\nChi2 weigthed distribution\n\n2\n\n0\n0\n\n2.5\n\n1\n\n2\n\n3\n\n4\n\n5\n\n\u03b1\n\nFigure 18: Same as Fig. 13 for the combined ATLAS+CMS (pT > 25 GeV) lepton charge\nasymmetry data.\nQ2 = M2W , ratio to NNPDF2.1\n\nQ2 = M2W , ratio to NNPDF2.1\n\n1.3\n\n1.3\nNNPDF2.1\n\nNNPDF2.1\n\n1.25\n\n1.25\nNNPDF2.1 + ATLAS(pl >20GeV) + CMS(pl >25GeV)\n\nNNPDF2.1 + ATLAS(pl >20GeV) + CMS(pl >25GeV)\n\nT\n\nT\n\n1.2\n\n1.15\n\n1.1\n\nxubar\n\nxu\n\n1.15\n\n1.05\n\n1.1\n\n1.05\n\n1\n\n1\n\n0.95\n\n0.95\n\n0.9\n\n0.9\n\n0.85 -5\n10\n\n0.85 -5\n10\n\n2\n\nQ =\n\nM2W ,\n\n-3\n\n10-4\n\n10\n\n10-2\n\nx\n\n10-1\n\n2\n\nratio to NNPDF2.1\n\nQ =\n\n1.3\n\nM2W ,\n\n10\n\n10-2\n\nx\n\n10-1\n\nratio to NNPDF2.1\nNNPDF2.1\n\n1.25\n\n1.25\nNNPDF2.1 + ATLAS(pl >20GeV) + CMS(pl >25GeV)\n\nNNPDF2.1 + ATLAS(pl >20GeV) + CMS(pl >25GeV)\n\nT\n\nT\n\n1.2\n\nT\n\nT\n\n1.2\n\n1.15\n\n1.15\nxdbar\n\n1.1\n\n1.05\n\n1.1\n\n1.05\n\n1\n\n1\n\n0.95\n\n0.95\n\n0.9\n0.85 -5\n10\n\n-3\n\n10-4\n\n1.3\nNNPDF2.1\n\nxd\n\nT\n\nT\n\n1.2\n\n0.9\n10-4\n\n-3\n\n10\n\nx\n\n10-2\n\n0.85 -5\n10\n\n10-1\n\n10-4\n\n-3\n\n10\n\nx\n\n10-2\n\n10-1\n\nFigure 19: Same as Fig. 14 but after adding both the ATLAS and CMS lepton charge\nasymmetry data.\na moderate constraint on PDFs. However the constraint is not quite so great as with the\nCMS data alone, suggesting a mild incompatibility particularly in the high rapidity bins.\nThe impact of the data on the light flavour and anti-flavour distributions is shown in\nFig. 19, where we compare the u and d quark and antiquark distributions at the scale\n2 from the NNPDF2.1 global fit and the ones obtained after adding the ATLAS\nQ2 = MW\nand CMS lepton charge asymmetry data using reweighting. There is around 20% reduction\nin uncertainties around x \u223c 10\u22123 , mainly due to the ATLAS data, complemented by a\nreduction of between 10% and 25% at larger x, mainly due to the CMS data.\n\n25\n\n\f6\n\nGlobal PDFs including LHC data\n\nIn this section we will check the consistency of the D0 and ATLAS+CMS datasets among\nthemselves, and use both datasets to reweight the NNPDF2.1 NLO PDFs. The unweighting method presented in Sect. 3 is then used to produce a set of 100 unweighted replicas.\nThe final product of this analysis is a new set of NNPDF parton distribution functions,\nNNPDF2.2 NLO, which includes, together with all the datasets already included in the\nNNPDF2.1 NLO global set, the D0, ATLAS and CMS lepton charge asymmetry data\ndescribed above.\n\n6.1\n\nTevatron W asymmetry data\n\nIn Ref. [14] we used the reweighting technique to study the compatibility of the D0 W\nlepton charge asymmetry data with the data included in the NNPDF2.0 NLO global fit\nand to assess their impact on the fitted parton densities. The conclusion of this study was\nthat the data that are inclusive in the p\u22a5 of the identified lepton, namely the muon charge\nasymmetry data presented in [21] and electron charge asymmetry data with p\u22a5 > 25 GeV\nreleased in [20], are consistent with each other and with all the other datasets included in\nNNPDF2.0, in particular with the CDF W asymmetry data [28] and the fixed-target DIS\ndeuteron data. When included in the fit they have a moderate impact on PDFs, providing\na reduction of the uncertainty of the valence quark distributions in the medium-high x\nregion (x \u223c 10\u22122 ).\nLess inclusive electron charge asymmetry data were also presented in [20]. They are\nbinned in p\u22a5 , divided into two sets with 25GeV < p\u22a5 < 35GeV and p\u22a5 > 35GeV respectively. We observed [14] that these data, which could have potentially more impact\non the PDFs, are inconsistent with some of the DIS data included in the global analysis\nand have problems of internal consistency. Similar conclusions have been reported by the\nMSTW [29] and CTEQ [25] collaborations, as they tried to include these datasets in the\ncontext of a PDF global analysis. We will thus not use these datasets here.\nThese results, though obtained using the NNPDF2.0 global fit, remain substantially\nunchanged if we use instead the NNPDF2.1 NLO global set as a prior fit to start the\nreweighting analysis. The muon charge asymmetry [21] and inclusive electron charge\nasymmetry data (with p\u22a5 > 25 GeV) [20] can thus provide additional information to that\nfrom the ATLAS and CMS data considered in the previous section. We thus proceed\ndirectly to a combined fit of these data together with the LHC data.\n\n6.2\n\nCombining LHC and Tevatron W asymmetry data\n\nThe description of the combined ATLAS, CMS and D0 charge asymmetry datasets obtained using the NNPDF2.1 NLO global fit, in which they were not included, is reasonably\ngood but not optimal, with \u03c72 /Ndat = 2.22: a detailed comparison is shown in Table 4.\nThe distribution of the combined \u03c72 /Ndat for individual replicas before and after reweighting, and the P (\u03b1) distribution, shown in Fig. 20, indicate however that these data are reasonably compatible with the data already included in the NNPDF2.1 analysis and would\nprovide a significant constraint on the PDFs.\nThese conclusions are indeed confirmed when the effect of the ATLAS, CMS and D0\ndata is included using the reweighting technique. After reweighting their overall description improves significantly, with a combined \u03c72rw /Ndat = 0.81. This is due to a significant\n26\n\n\fExperiment\nNMC-pd\nNMC\nSLAC\nBCDMS\nHERAI-AV\nCHORUS\nFLH108\nNTVDMN\nZEUS-H2\nZEUSF2C\nH1F2C\nDYE605\nDYE886\nCDFWASY\nCDFZRAP\nD0ZRAP\nCDFR2KT\nD0R2CON\nATLASmuASY\nCMSeASY\nCMSmuASY\nD0eASY\nD0muASY\nTotal\n\nNdat\n132\n221\n74\n581\n592\n862\n8\n79\n127\n50\n38\n119\n199\n13\n29\n28\n76\n110\n11\n6\n6\n12\n10\n\nNNPDF2.1\n0.97\n1.73\n1.33\n1.24\n1.07\n1.15\n1.37\n0.79\n1.29\n0.78\n1.51\n0.84\n1.25\n1.85\n1.66\n0.60\n0.98\n0.84\n[0.77]\n[1.83]\n[1.24]\n[4.39]\n[1.48]\n1.165\n\nNNPDF2.1 LHC\n0.95\n1.72\n1.26\n1.23\n1.07\n1.15\n1.37\n0.74\n1.28\n0.79\n1.52\n0.84\n1.23\n1.81\n1.61\n0.60\n0.98\n0.84\n0.97\n1.23\n0.63\n[3.46]\n[1.17]\n1.158\n\nNNPDF2.2\n0.97\n1.72\n1.28\n1.23\n1.07\n1.15\n1.37\n0.70\n1.28\n0.78\n1.51\n0.86\n1.27\n1.81\n1.70\n0.58\n0.96\n0.83\n1.07\n1.08\n0.56\n1.38\n0.35\n1.157\n\nTable 4: Table of \u03c72 /Ndat values for the experiments included in the NNPDF2.1 NLO fit,\nthe NNPDF2.1 LHC fit discussed in Section 5 and the NNPDF2.2 NLO fit. The numbers\nin square brackets correspond to the experiments which are not included in the fit. The\nthree fits thus have respectively Ndat = 3338, 3361 and 3383.\n\n27\n\n\fP(\u03b1 )\n\n200\n\n0.08\n\n180\n\n0.07\n\n160\n\nP(\u03b1 )\n\nWeighted distribution of chi2-new/Ndat\n\nDistribution of chi2-new/Ndat\n0.09\n\n0.2\n\n0.18\n0.16\n\n140\n\n0.06\n\n0.14\n\n120\n\n0.12\n\n0.05\n100\n0.04\n\n0.1\n\n80\n\n0.08\n\n60\n\n0.06\n\n0.02\n\n40\n\n0.04\n\n0.01\n\n20\n\n0.03\n\n0\n0\n\n1\n\n2\n\n3\n\n4\n5\n6\nChi2 distribution\n\n7\n\n8\n\n9\n\n0.02\n\n0\n0\n\n10\n\n0.5\n\n1\n1.5\n2\nChi2 weigthed distribution\n\n2.5\n\n3\n\n0\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n\u03b1\n\nFigure 20: Same as Fig. 13 for the combined D0+ATLAS+CMS pT > 25 GeV dataset.\nQ2 = M2W , Ratio to NNPDF2.1\n\nQ2 = M2W , Ratio to NNPDF2.1\n\n1.3\n\n1.3\n\n1.25\n\n1.25\n\nNNPDF2.1\n\n1.2\n\nNNPDF2.2\n\n1.15\n\n1.1\n\nxu\n\nxu\n\n1.15\n\n1.05\n\n1.1\n\n1.05\n\n1\n\n1\n\n0.95\n\n0.95\n\n0.9\n0.85 -5\n10\n\n0.9\n-4\n\n10\n\n-3\n\n10\n\nx\n\n10\n\n-2\n\n0.85 -5\n10\n\n-1\n\n10\n\nQ2 = M2W , Ratio to NNPDF2.1\n\n1.3\n\n1.25\n\n1.25\n\nNNPDF2.1\n\n1.2\n\n-3\n\n10\n\nx\n\n10-2\n\n10-1\n\n10-2\n\n10-1\n\nNNPDF2.1\n\n1.2\nNNPDF2.2\n\nNNPDF2.2\n\n1.15\n\n1.15\n\n1.1\n\nxd\n\nxd\n\n10-4\n\nQ2 = M2W , Ratio to NNPDF2.1\n\n1.3\n\n1.05\n\n1.1\n\n1.05\n\n1\n\n1\n\n0.95\n\n0.95\n\n0.9\n0.85 -5\n10\n\nNNPDF2.1\n\n1.2\nNNPDF2.2\n\n0.9\n-4\n\n10\n\n-3\n\n10\n\nx\n\n10\n\n-2\n\n0.85 -5\n10\n\n-1\n\n10\n\n10-4\n\n-3\n\n10\n\nx\n\nFigure 21: Comparison of light quark and antiquark distributions at the scale Q2 =\n2 from the global NNPDF2.1 and NNPDF2.2 global fits. Parton densities are plotted\nMW\nnormalized to the NNPDF2.1 central value.\nimprovement in the fit to the CMS and the D0 data: the fit to the ATLAS data deteriorates a little, again showing that there is some tension. The number of effective replicas\nis now Neff = 181 out of the initial Nrep = 1000, showing that the W lepton asymmetry\ndata indeed introduce very significant constraints on the PDFs. The distribution of the\n\u03c72 /Ndat for the individual replicas after reweighting, shown in the middle plot of Fig. 20,\nis peaked around one, confirming the compatibility of these data with the other datasets\nincluded in the global analysis.\nAfter reweighting, the unweighting procedure of Sec. 3 may be used to give a 100\nreplica set of PDFs equivalent to a global fit which includes all the data already included\nin NNPDF2.1, plus the ATLAS, CMS and D0 W asymmetry data. We call this new NLO\nPDF set NNPDF2.2. The quality of the data to all the sets used in this new fit is shown\nin Tab. 4. There is no significant deterioration in the \u03c72 in any of other datasets included\nin the global fit, and the fit to the NuTeV dimuon data improves significantly. The overall\n\u03c72tot /Ndat thus also improves a little.\n28\n\n\fPercentage uncertainty reduction\n\nPercentage uncertainty reduction\n5\n\n0\n\n0\n\n-5\n\n-5\n\n-10\n\n-10\n\n\u2206 ubar/ubar (%)\n\n\u2206 u/u (%)\n\n5\n\n-15\n-20\n-25\n-30\n\nTeV + LHC\n\n-15\n-20\n-25\n-30\n\nLHC\n-35\n-40\n\nLHC\n-35\n\nCMS\n\n-40\n\nATLAS\n\n-45 -4\n10\n\n10-3\n\nx\n\n10-2\n\n-5\n\n-10\n\n-10\n\n\u2206 dbar/dbar (%)\n\n\u2206 d/d (%)\n\n0\n\n-5\n\n-15\n-20\n-25\n\nx\n\n10-2\n\n10-1\n\nTeV + LHC\n\n10-2\n\n10-1\n\n-15\n-20\n-25\n-30\n\nLHC\n\n-45 -4\n10\n\n10-3\n\n5\n\n0\n\n-40\n\nATLAS\n\nPercentage uncertainty reduction\n\n5\n\n-35\n\nCMS\n\n-45 -4\n10\n\n10-1\n\nPercentage uncertainty reduction\n\n-30\n\nTeV + LHC\n\nTeV + LHC\nLHC\n\n-35\n\nCMS\n\n-40\n\nATLAS\n10-3\n\nx\n\n10-2\n\n-45 -4\n10\n\n10-1\n\nCMS\nATLAS\n10-3\n\nx\n\nFigure 22: The percentage change in the uncertainty in the light quark and antiquark\n2 in the global NNPDF2.1 NLO global fit, after adding\ndistributions at the scale Q2 = MW\nATLAS, CMS and D0 lepton charge asymmetry data via reweighting. The four curves\nshow in each case the effect of ATLAS (red) and CMS (pink) only, together (blue), and\nthen together with the D0 data (green), i.e. NNPDF2.2.\nThe impact on light flavour and anti-flavour PDFs is shown in Fig. 21, where we\n2 from\ncompare the u and d quark and antiquark distributions at the scale Q2 = MW\nthe NNPDF2.1 NLO set to the ones obtained for the NNPDF2.2 NLO set. The most\nnoticeable effects of the inclusion of the new data are concentrated in two separate regions\nof x, namely, the x \u223c 10\u22123 region, which is mostly affected by the ATLAS data, and the\nx \u223c 10\u22122 \u2212 10\u22121 region, which is mostly affected by the CMS and D0 data. In each of\nthese regions, the W asymmetry data leads to a reduction of uncertainties on the light\nflavour and antiflavour distribution, or around 20% in the low x region, and up to 30%\nat higher x when CMS and D0 are combined (see Fig. 22). At higher x changes in the\ncentral values for these PDFs by up to one sigma are also observed: these are mainly due\nto the D0 data (compare Fig. 21 with Fig. 19).\nAs recently shown in the extensive studies carried out in the context of the PDF4LHC\nWorking Group [30], there is rather good agreement among NLO parton distributions\ndetermined from the widest global datasets, specifically by the NNPDF, MSTW and\nCTEQ groups. However, there still are some significant differences, notably in the flavour\nseparation at medium-large x. Since this is the region which is directly probed by the\nTevatron and LHC lepton charge asymmetry data studied here, these data might help in\nresolving some of these outstanding incompatibilities.\nTo this end, in Figs. 23 and 24 we compare the d/u and (d \u2212 u) combinations at the\n2 obtained in the NNPDF2.1 and MSTW08 NLO global analyses, which\nscale Q2 = MW\ndo not include any of the W asymmetry data, the CT10 analysis, which includes only\n29\n\n\fthe D0 data, and the new NNPDF2.2 fit, which also includes the ATLAS and CMS data.\nThe new data lie in a region of x where the compatibility between the results obtained by\ndifferent collaborations is at best marginal: in particular the d/u ratio given by MSTW08\nis too low at large x and too high at medium x. The reduction of uncertainty when going\nfrom NNPDF2.1 to NNPDF2.2 is quite visible: the NNPDF2.2 prediction should thus be\ntaken as the most reliable at present. Future LHC data will constrain the light quark\nPDFs in this region even more.\nQ2 = M2W\n\n1\n\n1.1\n\n0.9\n\n1\n\n0.8\n\n0.9\n\n0.7\nd/u\n\nd/u\n\n1.2\n\n0.8\n0.7\n0.6\n0.5\n\n0.6\n0.5\n\nNNPDF2.1\n\n0.4\n\nNNPDF2.2\nCT10\n\n0.3\n\nMSTW08\n\n0.4\n10-4\n\n1.2\n\nQ2 = M2W\n\n10\n\nNNPDF2.1\nNNPDF2.2\nCT10\nMSTW08\n\n-3\n\nx\n\n10-2\n\n0.2\n\n10-1\n\nQ2 = M2W , Ratio to NNPDF2.1\n\n1.1\n\n0.05\n\n0.1\n\n0.15\n\n0.2\n\n0.25\nx\n\n0.3\n\n0.35\n\n0.4\n\n0.45\n\n0.5\n\nQ2 = M2W , Ratio to NNPDF2.1\n\n1.08\n\n1.15\n\n1.06\n1.1\n1.04\n1.02\nd/u\n\nd/u\n\n1.05\n1\n\n0.9\n0.85\n0.8 -3\n10\n\n1\n\n0.98\n\n0.95\n\n0.96\n\nNNPDF2.1\nNNPDF2.2\n\n0.94\n\nCT10\n\nNNPDF2.1\nNNPDF2.2\n\n0.92\n\nMSTW08\n\n10-2\n\nx\n\n0.9\n\n10-1\n\nCT10\nMSTW08\n\n0.1\n\n0.2\n\n0.3\nx\n\n0.4\n\n0.5\n\n0.6\n\n2 in NNPDF2.1, CT10, MSTW08\nFigure 23: Comparison of the d/u ratio at Q2 = MW\nand NNPDF2.2. Upper plots show absolute values, while the lower plots show the ratio\nto NNPDF2.1\n\n30\n\n\fQ2=M2W\n\n0.05\n\n0.04\n\n0.04\n\n0.03\n\n0.03\nx(d-u)\n\nx(d-u)\n\n0.05\n\n0.02\n0.01\n\nQ2=M2W\n\n0.02\n0.01\n\n0\n\n0\n\nNNPDF2.1\n\n-0.01\n\nCT10\n\n-0.01\n\nMSTW08\n\n10-2\n\nx\n\n3\n\nMSTW08\n\n0.05\n\n10-1\n\n0.1\n\n0.15\n\n0.2\n\n0.25\nx\n\n0.3\n\n0.35\n\nQ2 = M2W , Ratio to NNPDF2.1\n\n2\n\n1\nx(d-u)\n\n-3\n\n10\n\nNNPDF2.1\nNNPDF2.2\n\nNNPDF2.2\nCT10\n\n0\n\n-1\nNNPDF2.1\n\n-2\n\nNNPDF2.2\nCT10\nMSTW08\n\n-3\n\n10-2\n\nx\n\n10-1\n\n2 .\nFigure 24: As Fig. 23, but showing (d \u2212 u) at Q2 = MW\n\n31\n\n0.4\n\n0.45\n\n0.5\n\n\f7\n\nConclusions and outlook\n\nThe reweighting method which we have reviewed, re-derived and refined in this paper is\na powerful techinque which enables one both to preform interesting studies of the statistical properties of parton distributions viewed as probability distributions in a space of\nfunctions, and to rapidly and effectively include new experimental information in parton\nsets. Coupled to the unweighting method that we have presented and tested here it allows\none to quickly upgrade existing Monte Carlo replica PDF sets to new sets which, while\nretaining the same format, include new experimental information.\nThe method has been used here to construct the NNPDF2.2 NLO PDF set - the\nfirst PDF set to include LHC data. This will doubtless be the first of many such sets:\nthe quantity, quality and diversity of LHC measurements potentially relevant for PDF\ndetermination is now growing at an impressive rate.\n\nThe NNPDF2.2 NLO LO PDF set that has been presented in Section 6 is available\nfrom the NNPDF web site,\nhttp://sophia.ecm.ub.es/nnpdf\nand will be also available through the LHAPDF interface [31]:\n\u2022 NNPDF2.2 NLO, set of Nrep = 100 replicas:\nNNPDF22 nlo 100.LHgrid\n\nAcknowledgments\nWe are especially grateful to John Collins and Jon Pumplin for detailed questions and a\ncritique of the reweighting method which largely stimulated this investigation. We thank\nGeorgios Daskalakis, Gautier Hamel de Monchenault, Michele Pioppi, Michael Schmitt\nand Ping Tan for help with the LHC W asymmetry data, and Giancarlo Ferrera for help\nwith the DYNNLO code. LDD acknowledges the warm hospitality of the theory group at\nKMI, Nagoya, during the final stages of this work. RDB would likewise like to thank the\nDiscovery Center at the NBI, Copenhagen. MU is supported by the Bundesministerium\nf\u00fcr Bildung and Forschung (BmBF) of the Federal Republic of Germany (project code\n05H09PAE). We would like to acknowledge the use of the computing resources provided\nby the Black Forest Grid Initiative in Freiburg and by the Edinburgh Compute and Data\nFacility (ECDF) (http://www.ecdf.ed.ac.uk/). The ECDF is partially supported by the\neDIKT initiative (http://www.edikt.org.uk).\n32\n\n\fReferences\n[1] S. Forte et al., JHEP 05 (2002) 062, hep-ph/0204232.\n[2] The NNPDF Collaboration, L. Del Debbio et al.,\nph/0501067.\n\nJHEP 03 (2005) 080, hep-\n\n[3] The NNPDF Collaboration, L. Del Debbio et al.,\nph/0701127.\n\nJHEP 03 (2007) 039, hep-\n\n[4] The NNPDF Collaboration, R.D. Ball et al.,\narXiv:0808.1231.\n\nNucl. Phys. B809 (2009) 1,\n\n[5] The NNPDF Collaboration, J. Rojo et al., (2008), arXiv:0811.2288.\n[6] The NNPDF Collaboration, R.D. Ball et al.,\narXiv:0906.1958.\n\nNucl. Phys. B823 (2009) 195,\n\n[7] The NNPDF Collaboration, R.D. Ball et al.,\narXiv:1002.4407.\n\nNucl. Phys. B838 (2010) 136,\n\n[8] The NNPDF Collaboration, R.D. Ball et al.,\narXiv:1101.1300.\n\nNucl. Phys. B849 (2011) 296,\n\n[9] The NNPDF Collaboration, R.D. Ball et al., (2011), arXiv:1107.2652.\n[10] W.T. Giele, S.A. Keller and D.A. Kosower, (2001), hep-ph/0104052.\n[11] The NNPDF Collaboration, R.D. Ball et al., \"Parton distributions: determining\nprobabilities in a space of functions\", to be published in the proceedings of PHYSTAT\n2011; CERN Yellow Report, 2011, arXiv:1110.1863.\n[12] S. Forte, Acta Phys. Polon. B41 (2010) 2859, arXiv:1011.5247.\n[13] W.T. Giele and S. Keller, Phys. Rev. D58 (1998) 094023, hep-ph/9803393.\n[14] The NNPDF Collaboration, R.D. Ball et al.,\narXiv:1012.0836.\n\nNucl.Phys. B849 (2011) 112,\n\n[15] CDF - Run II, A. Abulencia et al., Phys. Rev. D75 (2007) 092006, hep-ex/0701051.\n[16] D0, V.M. Abazov et al., Phys. Rev. Lett. 101 (2008) 062001, arXiv:0802.2400.\n[17] G. Moreno et al., Phys. Rev. D43 (1991) 2815.\n[18] E. Jaynes, Probability Theory: The Logic of Science (Cambridge University Press,\n2003).\n[19] CDF, T. Aaltonen et al., Phys. Rev. D78 (2008) 052006, arXiv:0807.2204.\n[20] D0, V.M. Abazov et al., Phys. Rev. Lett. 101 (2008) 211801, arXiv:0807.3367.\n[21] D0, V.M. Abazov et al., Phys. Rev. D77 (2008) 011106, arXiv:0709.4254.\n[22] ATLAS, G. Aad et al., (2011), arXiv:1103.2929.\n33\n\n\f[23] CMS, S. Chatrchyan et al., JHEP 04 (2011) 050, arXiv:1103.3470.\n[24] LHCb, T. Shears, PoS EPS-HEP2009 (2009) 306.\n[25] H.L. Lai et al., Phys. Rev. D82 (2010) 074024, arXiv:1007.2241.\n[26] A.D. Martin et al., Eur. Phys. J. C63 (2009) 189, arXiv:0901.0002.\n[27] S. Catani et al., Phys. Rev. Lett. 103 (2009) 082001, arXiv:0903.2120.\n[28] CDF, T. Aaltonen et al., Phys. Rev. Lett. 102 (2009) 181801, arXiv:0901.2169.\n[29] R.S. Thorne et al., PoS DIS2010 (2010) 052, arXiv:1006.2753.\n[30] S. Alekhin et al., (2011), arXiv:1101.0536.\n[31] D. Bourilkov, R.C. Group and M.R. Whalley, (2006), hep-ph/0605240.\n\n34\n\n\f"}