{"id": "http://arxiv.org/abs/physics/0208101v4", "guidislink": true, "updated": "2003-03-03T16:07:56Z", "updated_parsed": [2003, 3, 3, 16, 7, 56, 0, 62, 0], "published": "2002-08-29T17:40:43Z", "published_parsed": [2002, 8, 29, 17, 40, 43, 3, 241, 0], "title": "Singular Value Decomposition and Principal Component Analysis", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=physics%2F0208064%2Cphysics%2F0208081%2Cphysics%2F0208045%2Cphysics%2F0208069%2Cphysics%2F0208065%2Cphysics%2F0208054%2Cphysics%2F0208090%2Cphysics%2F0208002%2Cphysics%2F0208070%2Cphysics%2F0208019%2Cphysics%2F0208076%2Cphysics%2F0208091%2Cphysics%2F0208042%2Cphysics%2F0208101%2Cphysics%2F0208087%2Cphysics%2F0208039%2Cphysics%2F0208021%2Cphysics%2F0208029%2Cphysics%2F0208057%2Cphysics%2F0208005%2Cphysics%2F0208096%2Cphysics%2F0208048%2Cphysics%2F0208043%2Cphysics%2F0208012%2Cphysics%2F0208052%2Cphysics%2F0208031%2Cphysics%2F0208007%2Cphysics%2F0208071%2Cphysics%2F0208061%2Cphysics%2F0208072%2Cphysics%2F0208041%2Cphysics%2F0208093%2Cphysics%2F0208035%2Cphysics%2F0208003%2Cphysics%2F0208100%2Cphysics%2F0208089%2Cphysics%2F0208049%2Cphysics%2F0208051%2Cphysics%2F0106079%2Cphysics%2F0106042%2Cphysics%2F0106083%2Cphysics%2F0106027%2Cphysics%2F0106072%2Cphysics%2F0106048%2Cphysics%2F0106039%2Cphysics%2F0106040%2Cphysics%2F0106032%2Cphysics%2F0106037%2Cphysics%2F0106080%2Cphysics%2F0106009%2Cphysics%2F0106087%2Cphysics%2F0106081%2Cphysics%2F0106036%2Cphysics%2F0106005%2Cphysics%2F0106093%2Cphysics%2F0106060%2Cphysics%2F0106029%2Cphysics%2F0106038%2Cphysics%2F0106034%2Cphysics%2F0106054%2Cphysics%2F0106049%2Cphysics%2F0106064%2Cphysics%2F0106099%2Cphysics%2F0106055%2Cphysics%2F0106028%2Cphysics%2F0106078%2Cphysics%2F0106025%2Cphysics%2F0106073%2Cphysics%2F0106007%2Cphysics%2F0106052%2Cphysics%2F0106092%2Cphysics%2F0106035%2Cphysics%2F0106063%2Cphysics%2F0106015%2Cphysics%2F0106097%2Cphysics%2F0106041%2Cphysics%2F0106044%2Cphysics%2F0106045%2Cphysics%2F0106023%2Cphysics%2F0106010%2Cphysics%2F0106061%2Cphysics%2F0106066%2Cphysics%2F0106067%2Cphysics%2F0106089%2Cphysics%2F0106022%2Cphysics%2F0106077%2Cphysics%2F0106085%2Cphysics%2F0106096%2Cphysics%2F0106046%2Cphysics%2F0106004%2Cphysics%2F0106100%2Cphysics%2F0106018%2Cphysics%2F0106101%2Cphysics%2F0106086%2Cphysics%2F0106065%2Cphysics%2F0106070%2Cphysics%2F0106008%2Cphysics%2F0106084%2Cphysics%2F0106075%2Cphysics%2F0106057%2Cphysics%2F0106094&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Singular Value Decomposition and Principal Component Analysis"}, "summary": "This chapter describes gene expression analysis by Singular Value\nDecomposition (SVD), emphasizing initial characterization of the data. We\ndescribe SVD methods for visualization of gene expression data, representation\nof the data using a smaller number of variables, and detection of patterns in\nnoisy gene expression data. In addition, we describe the precise relation\nbetween SVD analysis and Principal Component Analysis (PCA) when PCA is\ncalculated using the covariance matrix, enabling our descriptions to apply\nequally well to either method. Our aim is to provide definitions,\ninterpretations, examples, and references that will serve as resources for\nunderstanding and extending the application of SVD and PCA to gene expression\nanalysis.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=physics%2F0208064%2Cphysics%2F0208081%2Cphysics%2F0208045%2Cphysics%2F0208069%2Cphysics%2F0208065%2Cphysics%2F0208054%2Cphysics%2F0208090%2Cphysics%2F0208002%2Cphysics%2F0208070%2Cphysics%2F0208019%2Cphysics%2F0208076%2Cphysics%2F0208091%2Cphysics%2F0208042%2Cphysics%2F0208101%2Cphysics%2F0208087%2Cphysics%2F0208039%2Cphysics%2F0208021%2Cphysics%2F0208029%2Cphysics%2F0208057%2Cphysics%2F0208005%2Cphysics%2F0208096%2Cphysics%2F0208048%2Cphysics%2F0208043%2Cphysics%2F0208012%2Cphysics%2F0208052%2Cphysics%2F0208031%2Cphysics%2F0208007%2Cphysics%2F0208071%2Cphysics%2F0208061%2Cphysics%2F0208072%2Cphysics%2F0208041%2Cphysics%2F0208093%2Cphysics%2F0208035%2Cphysics%2F0208003%2Cphysics%2F0208100%2Cphysics%2F0208089%2Cphysics%2F0208049%2Cphysics%2F0208051%2Cphysics%2F0106079%2Cphysics%2F0106042%2Cphysics%2F0106083%2Cphysics%2F0106027%2Cphysics%2F0106072%2Cphysics%2F0106048%2Cphysics%2F0106039%2Cphysics%2F0106040%2Cphysics%2F0106032%2Cphysics%2F0106037%2Cphysics%2F0106080%2Cphysics%2F0106009%2Cphysics%2F0106087%2Cphysics%2F0106081%2Cphysics%2F0106036%2Cphysics%2F0106005%2Cphysics%2F0106093%2Cphysics%2F0106060%2Cphysics%2F0106029%2Cphysics%2F0106038%2Cphysics%2F0106034%2Cphysics%2F0106054%2Cphysics%2F0106049%2Cphysics%2F0106064%2Cphysics%2F0106099%2Cphysics%2F0106055%2Cphysics%2F0106028%2Cphysics%2F0106078%2Cphysics%2F0106025%2Cphysics%2F0106073%2Cphysics%2F0106007%2Cphysics%2F0106052%2Cphysics%2F0106092%2Cphysics%2F0106035%2Cphysics%2F0106063%2Cphysics%2F0106015%2Cphysics%2F0106097%2Cphysics%2F0106041%2Cphysics%2F0106044%2Cphysics%2F0106045%2Cphysics%2F0106023%2Cphysics%2F0106010%2Cphysics%2F0106061%2Cphysics%2F0106066%2Cphysics%2F0106067%2Cphysics%2F0106089%2Cphysics%2F0106022%2Cphysics%2F0106077%2Cphysics%2F0106085%2Cphysics%2F0106096%2Cphysics%2F0106046%2Cphysics%2F0106004%2Cphysics%2F0106100%2Cphysics%2F0106018%2Cphysics%2F0106101%2Cphysics%2F0106086%2Cphysics%2F0106065%2Cphysics%2F0106070%2Cphysics%2F0106008%2Cphysics%2F0106084%2Cphysics%2F0106075%2Cphysics%2F0106057%2Cphysics%2F0106094&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This chapter describes gene expression analysis by Singular Value\nDecomposition (SVD), emphasizing initial characterization of the data. We\ndescribe SVD methods for visualization of gene expression data, representation\nof the data using a smaller number of variables, and detection of patterns in\nnoisy gene expression data. In addition, we describe the precise relation\nbetween SVD analysis and Principal Component Analysis (PCA) when PCA is\ncalculated using the covariance matrix, enabling our descriptions to apply\nequally well to either method. Our aim is to provide definitions,\ninterpretations, examples, and references that will serve as resources for\nunderstanding and extending the application of SVD and PCA to gene expression\nanalysis."}, "authors": ["Michael E. Wall", "Andreas Rechtsteiner", "Luis M. Rocha"], "author_detail": {"name": "Luis M. Rocha"}, "author": "Luis M. Rocha", "arxiv_comment": "18 pages. (9/12/2002) Replaced title. (9/16/2002) Replaced book\n  title. Fixed typos. (3/3/2003) Published. P. 10: \"unit variance\" -> \"unit\n  norm\"", "links": [{"href": "http://arxiv.org/abs/physics/0208101v4", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/physics/0208101v4", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "physics.bio-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "physics.bio-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "physics.data-an", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "q-bio.QM", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/physics/0208101v4", "affiliation": "Los Alamos National Laboratory", "arxiv_url": "http://arxiv.org/abs/physics/0208101v4", "journal_reference": "Wall ME, Rechtsteiner A, Rocha LM. In: A Practical Approach to\n  Microarray Data Analysis. (Berrar DP, Dubitzky W, Granzow M, eds.), pp.\n  91-109, Kluwer: Norwell, MA (2003)", "doi": null, "fulltext": "5. Singular value decomposition and principal component analysis\n\nChapter 5\nSingular value decomposition and principal component analysis\nIn A Practical Approach to Microarray Data Analysis (D.P. Berrar, W. Dubitzky, M.\nGranzow, eds.) Kluwer: Norwell, MA, 2003. pp. 91-109. LANL LA-UR-02-4001\nMichael E. Wall1,2, Andreas Rechtsteiner1,3, Luis M. Rocha1,\n1\n\nComputer and Computational Sciences Division and 2Bioscience Division, Mail Stop B256, Los Alamos National\nLaboratory, Los Alamos, New Mexico, 87545 USA, e-mail: {mewall, rocha}@lanl.gov\n3\nSystems Science Ph.D. Program, Portland State University, Post Office Box 751, Portland, Oregon 97207 USA, e-mail:\nandreas@sysc.pdx.edu\n\nAbstract:\n\n1.\n\nThis chapter describes gene expression analysis by Singular Value Decomposition\n(SVD), emphasizing initial characterization of the data. We describe SVD methods\nfor visualization of gene expression data, representation of the data using a smaller\nnumber of variables, and detection of patterns in noisy gene expression data. In\naddition, we describe the precise relation between SVD analysis and Principal\nComponent Analysis (PCA) when PCA is calculated using the covariance matrix,\nenabling our descriptions to apply equally well to either method. Our aim is to\nprovide definitions, interpretations, examples, and references that will serve as\nresources for understanding and extending the application of SVD and PCA to gene\nexpression analysis.\n\nINTRODUCTION\n\nOne of the challenges of bioinformatics is to develop effective ways to analyze global gene\nexpression data. A rigorous approach to gene expression analysis must involve an up-front\ncharacterization of the structure of the data. In addition to a broader utility in analysis methods,\nsingular value decomposition (SVD) and principal component analysis (PCA) can be valuable\ntools in obtaining such a characterization. SVD and PCA are common techniques for analysis of\nmultivariate data, and gene expression data are well suited to analysis using SVD/PCA. A single\nmicroarray1 experiment can generate measurements for thousands, or even tens of thousands of\ngenes. Present experiments typically consist of less than ten assays, but can consist of hundreds\n(Hughes et al., 2000). Gene expression data are currently rather noisy, and SVD can detect and\nextract small signals from noisy data.\nThe goal of this chapter is to provide precise explanations of the use of SVD and PCA for\ngene expression analysis, illustrating methods using simple examples. We describe SVD methods\nfor visualization of gene expression data, representation of the data using a smaller number of\nvariables, and detection of patterns in noisy gene expression data. In addition, we describe the\n1\n\n1\n\n\f2\n\nChapter 5\n\nmathematical relation between SVD analysis and Principal Component Analysis (PCA) when\nPCA is calculated using the covariance matrix, enabling our descriptions to apply equally well to\neither method. Our aims are 1) to provide descriptions and examples of the application of SVD\nmethods and interpretation of their results; 2) to establish a foundation for understanding previous\napplications of SVD to gene expression analysis; and 3) to provide interpretations and references\nto related work that may inspire new advances.\nIn section 1, the SVD is defined, with associations to other methods described. A summary of\nprevious applications is presented in order to suggest directions for SVD analysis of gene\nexpression data. In section 2 we discuss applications of SVD to gene expression analysis,\nincluding specific methods for SVD-based visualization of gene expression data, and use of SVD\nin detection of weak expression patterns. Some examples are given of previous applications of\nSVD to analysis of gene expression data. Our discussion in section 3 gives some general advice\non the use of SVD analysis on gene expression data, and includes references to specific published\nSVD-based methods for gene expression analysis. Finally, in section 4, we provide information\non some available resources and further reading.\n\n1.1\n\nMathematical definition of the SVD2\n\nLet X denote an m \u00d7 n matrix of real-valued data and rank3 r, where without loss of generality\nm \u2265 n, and therefore r \u2264 n. In the case of microarray data, xij is the expression level of the ith gene\nin the jth assay. The elements of the ith row of X form the n-dimensional vector gi, which we refer\nto as the transcriptional response of the ith gene. Alternatively, the elements of the jth column of X\nform the m-dimensional vector aj, which we refer to as the expression profile of the jth assay.\nThe equation for singular value decomposition of X is the following:\n\nX = USV T ,\n\n(5.1)\n\nwhere U is an m \u00d7 n matrix, S is an n \u00d7 n diagonal matrix, and VT is also an n \u00d7 n matrix. The\ncolumns of U are called the left singular vectors, {uk}, and form an orthonormal basis for the\nassay expression profiles, so that ui*uj = 1 for i = j, and ui*uj = 0 otherwise. The rows of VT\ncontain the elements of the right singular vectors, {vk}, and form an orthonormal basis for the\ngene transcriptional responses. The elements of S are only nonzero on the diagonal, and are called\nthe singular values. Thus, S = diag(s1,...,sn). Furthermore, sk > 0 for 1 \u2264 k \u2264 r, and si = 0 for\n(r+1) \u2264 k \u2264 n. By convention, the ordering of the singular vectors is determined by high-to-low\nsorting of singular values, with the highest singular value in the upper left index of the S matrix.\nNote that for a square, symmetric matrix X, singular value decomposition is equivalent to\ndiagonalization, or solution of the eigenvalue problem.\nOne important result of the SVD of X is that\n\nX (l ) =\n\nl\n\n\u2211u s v\nk k\n\nT\nk\n\n(5.2)\n\nk =1\n\nis the closest rank-l matrix to X. The term \"closest\" means that X(l) minimizes the sum of the\nsquares of the difference of the elements of X and X(l), \u2211ij|xij \u2013 x(l)ij|2.\nOne way to calculate the SVD is to first calculate VT and S by diagonalizing XTX:\n\n\f5. Singular value decomposition and principal component analysis\n\nX T X = VS 2V T ,\n\n(5.3)\n\nand then to calculate U as follows:\n\nU = XVS \u22121 ,\n\n(5.4)\n\nwhere the (r+1),...,n columns of V for which sk = 0 are ignored in the matrix multiplication of\nEquation 5.4. Choices for the remaining n-r singular vectors in V or U may be calculated using\nthe Gram-Schmidt orthogonalization process or some other extension method. In practice there\nare several methods for calculating the SVD that are of higher accuracy and speed. Section 4 lists\nsome references on the mathematics and computation of SVD.\nRelation to principal component analysis. There is a direct relation between PCA and SVD in\nthe case where principal components are calculated from the covariance matrix4. If one\nconditions the data matrix X by centering5 each column, then XTX = \u03a3igigiT is proportional to the\ncovariance matrix of the variables of gi (i.e., the covariance matrix of the assays6). By\nEquation 5.3, diagonalization of XTX yields VT, which also yields the principal components of\n{gi}. So, the right singular vectors {vk} are the same as the principal components of {gi}. The\neigenvalues of XTX are equivalent to sk2, which are proportional to the variances of the principal\ncomponents. The matrix US then contains the principal component scores, which are the\ncoordinates of the genes in the space of principal components.\nIf instead each row of X is centered, XXT = \u03a3jajajT is proportional to the covariance matrix of\nthe variables of aj (i.e. the covariance matrix of the genes7). In this case, the left singular vectors\n{uk} are the same as the principal components of {aj}. The sk2 are again proportional to the\nvariances of the principal components. The matrix SVT again contains the principal component\nscores, which are the coordinates of the assays in the space of principal components.\nRelation to Fourier analysis. Application of SVD in data analysis has similarities to Fourier\nanalysis. As is the case with SVD, Fourier analysis involves expansion of the original data in an\northogonal basis:\n\nxij =\n\n\u2211c\n\nik e\n\ni 2\u03c0jk / m\n\n(5.5)\n\nk\n\nThe connection with SVD can be explicitly illustrated by normalizing8 the vector {ei2\u03c0jk/m} and\nby naming it v'k:\n\nxij =\n\n\u2211 b v'\nik\n\nk\n\njk\n\n=\n\n\u2211 u'\n\nik\n\ns 'k v ' jk\n\n(5.6)\n\nk\n\nwhich generates the matrix equation X = U'S'V'T, similar to Equation 5.1. Unlike the SVD,\nhowever, even though the {v'k} are an orthonormal basis, the {u'k} are not in general orthogonal.\nNevertheless this demonstrates how the SVD is similar to a Fourier transform, where the vectors\n{vk} are determined in a very specific way from the data using Equation 5.1, rather than being\ngiven at the outset as for the Fourier transform. Similar to low-pass filtering in Fourier analysis,\nlater we will describe how SVD analysis permits filtering by concentrating on those singular\nvectors that have the highest singular values.\n\n3\n\n3\n\n\fChapter 5\n\n4\n\n1.2\n\nIllustrative applications\n\nSVD and PCA have found wide-ranging applications. Here we describe several that may\nsuggest potential ways that we can think about applications in gene expression analysis.\nImage processing and compression. The property of SVD to provide the closest rank-l\napproximation for a matrix X (Equation 5.2) can be used in image processing for compression and\nnoise reduction, a very common application of SVD. By setting the small singular values to zero,\nwe can obtain matrix approximations whose rank equals the number of remaining singular values\n(see Equation 5.2). Each term ukskvkT is called a principal image. Very good approximations can\noften be obtained using only a small number of terms (Richards, 1993). SVD is applied in similar\nways to signal processing problems (Deprettere, 1988).\nImmunology. One way to capture global prototypical immune response patterns is to use PCA\non data obtained from measuring antigen-specific IgM (dominant antibody in primary immune\nresponses) and IgC (dominant antibody in secondary immune responses) immunoglobulins using\nELISA assays. Fesel and Coutinho (Fesel and Coutinho, 1998) measured IgM and IgC responses\nin Lewis and Fischer rats before and at three time points after immunization with myelin basic\nprotein (MBP) in complete Freud's adjuvant (CFA), which is known to provoke experimental\nallergic encephalomeyelitis (EAE). They discovered distinct and mutually independent\ncomponents of IgM reaction repertoires, and identified a small number of strain-specific\nprototypical regulatory responses.\nMolecular dynamics. PCA and SVD analysis methods have been developed for characterizing\nprotein molecular dynamics trajectories (Garcia, 1992; Romo et al., 1995). In a study of\nmyoglobin, Romo et al. used molecular dynamics methods to obtain atomic positions of all atoms\nsampled during the course of a simulation. The higher principal components of the dynamics\nwere found to correspond to large-scale motions of the protein. Visualization of the first three\nprincipal components revealed an interesting type of trajectory that was described as resembling\nbeads on a string, and revealed a visibly sparse sampling of the configuration space.\nSmall-angle scattering. SVD has been used to detect and characterize structural intermediates\nin biomolecular small-angle scattering experiments (Chen et al., 1996). This study provides a\ngood illustration of how SVD can be used to extract biologically meaningful signals from the\ndata. Small-angle scattering data were obtained from partially unfolded solutions of lysozyme,\neach consisting of a different mix of folded, collapsed and unfolded states. The data for each\nsample was in the form of intensity values sampled at on the order of 100 different scattering\nangles. UV spectroscopy was used to determine the relative amounts of folded, collapsed and\nunfolded lysozyme in each sample. SVD was used in combination with the spectroscopic data to\nextract a scattering curve for the collapsed state of the lysozyme, a structural intermediate that\nwas not observed in isolation.\nInformation Retrieval. SVD became very useful in Information Retrieval (IR) to deal with\nlinguistic ambiguity issues. IR works by producing the documents most associated with a set of\nkeywords in a query. Keywords, however, necessarily contain much synonymy (several keywords\nrefer to the same concept) and polysemy (the same keyword can refer to several concepts). For\ninstance, if the query keyword is \"feline\", traditional IR methods will not retrieve documents\nusing the word \"cat\" \u2013 a problem of synonymy. Likewise, if the query keyword is \"java\",\ndocuments on the topic of Java as a computer language, Java as an Island in Indonesia, and Java\nas a coffee bean will all be retrieved \u2013 a problem of polysemy. A technique known Latent\nSemantic Indexing (LSI) (Berry et al., 1995) addresses these problems by calculating the best\nrank-l approximation of the keyword-document matrix using its SVD. This produces a lower\n\n\f5. Singular value decomposition and principal component analysis\ndimensional space of singular vectors that are called eigen-keywords and eigen-documents. Each\neigen-keyword can be associated with several keywords as well as particular senses of keywords.\nIn the synonymy example above, \"cat\" and \"feline\" would therefore be strongly correlated with\nthe same eigen-keyterm. Similarly, documents using \"Java\" as a computer language tend to use\nmany of the same keywords, but not many of the keywords used by documents describing \"Java\"\nas coffee or Indonesia. Thus, in the space of singular vectors, each of these senses of \"java\" is\nassociated with distinct eigen-keywords.\n\n2.\n\nSVD ANALYSIS OF GENE EXPRESSION DATA\n\nAs we mention in the introduction, gene expression data are well suited to analysis using\nSVD/PCA. In this section we provide examples of SVD-based analysis methods as applied to\ngene expression analysis. Before illustrating specific techniques, we will discuss ways of\ninterpreting the SVD in the context of gene expression data. This interpretation and the\naccompanying nomenclature will serve as a foundation for understanding the methods described\nlater.\nA natural question for a biologist to ask is: \"What is the biological significance of the SVD?\"\nThere is, of course, no general answer to this question, as it depends on the specific application.\nWe can, however, consider classes of experiments and provide them as a guide for individual\ncases. For this purpose we define two broad classes of applications under which most studies will\nfall: systems biology applications, and diagnostic applications (see below). In both cases, the n\ncolumns of the gene expression data matrix X correspond to assays, and the m rows correspond to\nthe genes. The SVD of X produces two orthonormal bases, one defined by right singular vectors\nand the other by left singular vectors. Referring to the definitions in section 1.1, the right singular\nvectors span the space of the gene transcriptional responses {gi} and the left singular vectors span\nthe space of the assay expression profiles {aj}. Following the convention of (Alter et al., 2000),\nwe refer to the left singular vectors {uk} as eigenassays and to the right singular vectors {vk} as\neigengenes9. We sometimes refer to an eigengene or eigenassay generically as a singular vector,\nor, by analogy with PCA, as a component. Eigengenes, eigenassays and other definitions and\nnomenclature in this section are depicted in Figure 5.1.\nIn systems biology applications, we generally wish to understand relations among genes. The\nsignal of interest in this case is the gene transcriptional response gi. By Equation 5.1, the SVD\nequation for gi is\nr\n\ng i = \u2211 uik sk v k , i : 1,..., m\n\n(5.7)\n\nk =1\n\nwhich is a linear combination of the eigengenes {vk}. The ith row of U, g'i (see Figure 5.1),\ncontains the coordinates of the ith gene in the coordinate system (basis) of the scaled eigengenes,\nskvk. If r < n, the transcriptional responses of the genes may be captured with fewer variables\nusing g'i rather than gi. This property of the SVD is sometimes referred to as dimensionality\nreduction. In order to reconstruct the original data, however, we still need access to the\neigengenes, which are n-dimensional vectors. Note that due to the presence of noise in the\nmeasurements, r = n in any real gene expression analysis application, though the last singular\nvalues in S may be very close to zero and thus irrelevant.\n\n5\n\n5\n\n\fChapter 5\n\n6\n\nIn diagnostic applications, we may wish to classify tissue samples from individuals with and\nwithout a disease. Referring to the definitions in section 1.1, the signal of interest in this case is\nthe assay expression profile aj. By Equation 5.1, the SVD equation for aj is\nr\n\na j = \u2211 v jk sk u k ,\n\nj : 1,..., n\n\n(5.8)\n\nk =1\n\nwhich is a linear combination of the eigenassays {uk}. The jth column of VT, a'j (see Figure 5.1),\ncontains the coordinates of the jth assay in the coordinate system (basis) of the scaled eigenassays,\nskuk. By using the vector a'j, the expression profiles of the assays may be captured by r \u2264 n\nvariables, which is always fewer than the m variables in the vector aj. So, in contrast to gene\ntranscriptional responses, SVD can generally reduce the number of variables used to represent the\nassay expression profiles. Similar to the case for genes, however, in order to reconstruct the\noriginal data, we need access to the eigenassays, which are m-dimensional vectors.\n\nFigure 5.1. Graphical depiction of SVD of a matrix X, annotated with notations adopted in this chapter.\n\nIndeed, analysis of the spectrum formed by the singular values sk can lead to the determination\nthat fewer than n components capture the essential features in the data, a topic discussed below in\nsection 2.1.1. In the literature the number of components that results from such an analysis is\nsometimes associated with the number of underlying biological processes that give rise to the\npatterns in the data. It is then of interest to ascribe biological meaning to the significant\neigenassays (in the case of diagnostic applications), or eigengenes (in the case of systems biology\napplications). Even though each component on its own may not necessarily be biologically\nmeaningful, SVD can aid in the search for biologically meaningful signals (see, e.g., small-angle\nscattering in section 1.2).\nIn the context of describing scatter plots in section 2.1.2, we discuss the application of SVD to\nthe problem of grouping genes by transcriptional response, and grouping assays by expression\nprofile. This discussion will also touch on the topic of searching for biologically meaningful\nsignals. When the data are noisy, it may not be possible to resolve gene groups, but it still may be\n\n\f5. Singular value decomposition and principal component analysis\nof interest to detect underlying gene expression patterns; this is a case where the utility of the\nSVD distinguishes itself with respect to other gene expression analysis methods (section 2.2).\nFinally we discuss some published examples of gene expression analysis using SVD, and a\ncouple of SVD-based gene grouping methods (section 2.3).\n\n2.1\n\nVisualization of the SVD\n\nVisualization is central to understanding the results of application of SVD to gene expression\ndata. For example, Figure 5.2 illustrates plots that are derived from applying SVD to Cho et al.'s\nbudding yeast cell-cycle data set (Cho et al., 1998). In the experiment, roughly 6,200 yeast genes\nwere monitored for 17 time points taken at ten-minute intervals. To perform the SVD, we have\npre-processed the data by replacing each measurement with its logarithm, and normalizing each\ngene's transcriptional response to have zero mean and unit standard deviation. In addition, a serial\ncorrelation test (Kanji, 1993) was applied to filter out ~3,200 genes that showed primarily random\nfluctuations. The plots reveal interesting patterns in the data that we may wish to investigate\nfurther: a levelling off of the relative variance after the first five components (Figure 5.2a); a\npattern in the first eigengene primarily resembling a steady decrease, or decay (Figure 5.2b); and\npatterns with cyclic structure in the second and third eigengenes (Figure 5.2c,d).\n\nFigure 5.2. Visualization of the SVD of cell cycle data. Plots of relative variance (a); and the first (b), second (c) and\nthird (d) eigengenes are shown. The methods of visualization employed in each panel are described in section 2.1.\nThese data inspired our choice of the sine and exponential patterns for the synthetic data of section 2.1.\n\nTo aid our discussion of visualization, we use a synthetic time series data set with 14\nsequential expression level assays (columns of X) of 2,000 genes (rows of X). Use of a synthetic\n7\n\n7\n\n\fChapter 5\n\n8\n\ndata set enables us to provide simple illustrations that can serve as a foundation for understanding\nthe more complex patterns that arise in real gene expression data. Genes in our data set have one\nof three kinds of transcriptional response, inspired by experimentally observed patterns in the Cho\net al. cell-cycle data: 1) noise (1,600 genes); 2) noisy sine pattern (200 genes); or 3) noisy\nexponential pattern (200 genes). Noise for all three groups of genes was modelled by sampling\nfrom a normal distribution with zero mean and standard deviation 0.5. The sine pattern has the\nfunctional form asin(2\u03c0t/140), and the exponential pattern the form be-t/100, where a is sampled\nuniformly over the interval (1.5,3), b is sampled uniformly over (4,8), t is the time (in minutes)\nassociated with each assay, and time points are sampled every ten minutes beginning at t = 0.\nEach gene's transcriptional response was centered to have a mean of zero. Figure 5.3 depicts\ngenes of type 2) and 3).\n\nFigure 5.3. Gene transcriptional responses from the synthetic data set. Overlays of a) five noisy sine wave genes and b)\nfive noisy exponential genes.\n\n2.1.1\n\nVisualization of the matrices S, V T and U\n\nSingular value spectrum. The diagonal values of S (i.e., sk) make up the singular value\nspectrum, which is easily visualized in a one-dimensional plot. The height of any one singular\nvalue is indicative of its importance in explaining the data. More specifically, the square of each\nsingular value is proportional to the variance explained by each singular vector. The relative\nvariances sk2(\u2211isi2)-1 are often plotted (Figure 5.4a; see also Figure 5.2). Cattell has referred to\nthese kinds of plots as scree plots (Cattell, 1966) and proposed to use them as a graphical method\nto decide on the significant components. If the original variables are linear combinations of a\nsmaller number of underlying variables, combined with some low-level noise, the plot will tend\nto drop sharply for the singular values associated with the underlying variables and then much\nmore slowly for the remaining singular values. Singular vectors (in our case eigenassays and\neigengenes) whose singular values plot to the right of such an \"elbow\" are ignored because they\nare assumed to be mainly due to noise. For our synthetic data set, the spectrum begins with a\nsharp decrease, and levels off after the second component, which is indicative of the two\nunderlying signals in the data (Figure 5.4a). Other heuristic approaches for deciding on the\nsignificant components have been proposed. One approach is to ignore components beyond\n\n\f5. Singular value decomposition and principal component analysis\nwhere the cumulative relative variance or singular value becomes larger than a certain threshold,\nusually defined upon the dimensionality of the data. For our example data set, the first two\nsingular vectors explain about 64% of the total variance in the data (Figure 5.4a). Everitt and\nDunn propose an alternate approach based on comparing the relative variance of each component\nto 0.7/n (Everitt and Dunn, 2001). For our example data set this threshold is (0.7/14) = 0.05,\nwhich selects the first two singular vectors as significant. Notice that if we re-construct the matrix\nX by using only the first two singular vectors, we would obtain X(2) (the best rank-2\napproximation of X), which would account for 64% of the variance in the data.\nEigengenes. When assays correspond to samplings of an ordinal or continuous variable (e.g.,\ntime; radiation dose; toxin concentration), a plot of the elements of the eigengenes {vk} may\nreveal recognizable patterns. In our example, the first two eigengenes show an obvious cyclic\nstructure (Figure 5.4b,c; see also Figure 5.2). Neither eigengene is exactly like the underlying sine\nor exponential pattern; each such pattern, however, is closely approximated by a linear\ncombination of the eigengenes. Sine wave and exponential patterns cannot simultaneously be\nright singular vectors, as they are not orthogonal. This illustrates the point that, although the most\nsignificant eigengenes may not be biologically meaningful in and of themselves, they may be\nlinearly combined to form biologically meaningful signals.\n\nFigure 5.4. Visualization of the SVD of the synthetic data matrix. a) Singular value spectrum in a relative variance plot.\nThe first two singular values account for 64% of the variance. The first (b), second (c), and third (d) eigengenes are\nplotted vs. time (assays) in the remaining panels. The third eigengene lacks the obvious cyclic structure of the first and\nsecond.\n\nWhen assays correspond to discrete experimental conditions (e.g., mutational varieties; tissue\ntypes; distinct individuals), visualization schemes are similar to those described below for\n9\n\n9\n\n\fChapter 5\n\n10\n\neigenassays. When the jth element of eigengene k is of large-magnitude, the jth assay is understood\nto contribute relatively strongly to the variance of eigenassay k, a property that may be used for\nassociating a group of assays.\nEigenassays. Alter et al. have visualized eigenassays {uk} resulting from SVD analysis of\ncell-cycle data (Alter et al., 2000) by adapting a previously developed color-coding scheme for\nvisualization of gene expression data matrices (Eisen et al., 1998). Individual elements of U are\ndisplayed as rectangular pixels in an image, and color-coded using green for negative values, and\nred for positive values, the intensity being correlated with the magnitude. The rows of matrix U\ncan be sorted using correlation to the eigengenes. In Alter et al.'s study, this scheme sorted the\ngenes by the phase of their periodic pattern. The information communicated in such visualization\nbears some similarity to visualization using scatter plots, with the advantage that the table-like\ndisplay enables gene labels to be displayed along with the eigenassays, and the disadvantage that\ndifferences among the genes can only be visualized in one dimension.\n2.1.2\n\nScatter plots\n\nVisualization of structure in high-dimensional data requires display of the data in a one-, two-,\nor three-dimensional subspace. SVD identifies subspaces that capture most of the variance in the\ndata. Even though our discussion here is about visualization in subspaces obtained by SVD, the\nillustrated visualization techniques are general and can in most cases be applied for visualization\nin other subspaces (see section 4 for techniques that use other criteria for subspace selection).\nFor gene expression analysis applications, we may want to classify samples in a diagnostic\nstudy, or classify genes in a systems biology study. Projection of data into SVD subspaces and\nvisualization with scatter plots can reveal structures in the data that may be used for classification.\nHere we discuss the visualization of features that may help to distinguish gene groups by\ntranscriptional response. Analogous methods are used to distinguish groups of assays by\nexpression profile. We discuss two different sources of gene \"coordinates\" for scatter plots:\nprojections of the transcriptional response onto eigengenes, and correlations of the transcriptional\nresponse with eigengenes.\nProjection and correlation scatter plots. Projection scatter plot coordinates qik for\ntranscriptional response gi projected on eigengene vk are calculated as qik = gi*vk. The SVD of X\nreadily allows computation of these coordinates using the equation XV = US, so that qik = (US)ik.\nThe projection of gene transcriptional responses from our example data onto the first two\neigengenes reveals the a priori structure in the data (Figure 5.5a). The groups of the 200 sine\nwave genes (bottom right cluster), and the 200 exponential decay genes (top right cluster) are\nclearly separated from each other and from the 1,600 pure noise genes, which cluster about the\norigin.\nCorrelation scatter plots may be obtained by calculating the Pearson correlation coefficient of\neach gene's transcriptional response with the eigengenes:\nrik = \u03b4g i \u22c5 \u03b4v k \u03b4g i\n\n\u22121\n\n\u03b4v k\n\n\u22121\n\n(5.9)\n\nwhere rik denotes the correlation coefficient of the transcriptional response gi with eigengene vk;\n\u03b4gi is the mean-centered gi, the elements of which are {xij - <xij>j}i, and \u03b4vk is the mean-centered\nvk, the elements of which are {vjk - <vjk>j}k. The normalization leads to \u20131 \u2264 rik \u2264 1. Note that if\neach gi is pre-processed to have zero mean and unit norm, it follows that the correlation scatter\nplot is equivalent to the projection scatter plot (gi = \u03b4gi implies vk = \u03b4vk; and |\u03b4gi|-1 = |\u03b4vk|-1 = 1).\n\n\f5. Singular value decomposition and principal component analysis\nIn the projection scatter plot, genes with a relatively high-magnitude coordinate on the k-axis\ncontribute relatively strongly to the variance of the kth eigengene in the data set. The farther a\ngene lies away from the origin, the stronger the contribution of that gene is to the variance\naccounted for by the subspace. In the correlation scatter plot, genes with a relatively highmagnitude coordinate on the k-axis have transcriptional responses that are relatively highly\ncorrelated with the kth eigengene.\nDue to the normalization in correlation scatter plots, genes with similar patterns in their\ntranscriptional responses, but with different amplitudes, can appear to cluster more tightly in a\ncorrelation scatter plot than in a projection scatter plot. Genes that correlate well with the\neigengenes lie near the perimeter, a property that can be used in algorithms that seek to identify\ninteresting genes. At the same time, low-amplitude noise genes can appear to be magnified in a\ncorrelation scatter plot. For our example data, the sine wave and exponential gene clusters are\nrelatively tightened, the scatter of the noise genes appears to be increased, and the separation\nbetween signal and noise genes is decreased for the correlation vs. the projection scatter plot\n(Figure 5.5).\n\nFigure 5.5. SVD scatter plots. Genes from our synthetic example data set are displayed in a) a projection scatter plot;\nand b) a correlation scatter plot. The bottom right cluster corresponds to sine wave genes, and the top right cluster\ncorresponds to exponential decay genes. The cluster of genes around the origin corresponds to the noise-only genes.\n\nThe projection scatter plot (Figure 5.5a) illustrates how SVD may be used to aid in detection\nof biologically meaningful signals. In this case, the position (q1, q2) of any cluster center10 may be\nused to construct the cluster's transcriptional response g from the right singular vectors:\n\ng = q1v1 + q2 v 2\n\n(5.10)\n\nIf the first and second singular vectors are biologically meaningful in and of themselves, the\ncluster centers will lie directly on the axes of the plot. For our synthetic data, the first and second\nsingular vectors are combined to approximately generate the sine wave and exponential patterns.\n11\n\n11\n\n\fChapter 5\n\n12\n\nSVD and related methods are particularly valuable analysis methods when the distribution of\ngenes is more complicated than the simple distributions in our example data: for instance, SVD\nhas been used to characterize ring-like distributions of genes such as are observed in scatter plots\nof cell-cycle gene expression data (Alter et al., 2000; Holter et al., 2000) (see section 2.3).\nScatter plots of assays. Assays can be visualized in scatter plots using methods analogous to\nthose used for genes. Coordinates for projection scatter plots are obtained by taking the dot\nproducts aj*uk of expression profiles on eigenassays, and coordinates for correlation scatter plots\nare obtained by calculating the Pearson correlation coefficient \u03b4aj*\u03b4uk|\u03b4aj|-1|\u03b4uk|-1. Such plots are\nuseful for visualizing diagnostic data, e.g., distinguishing groups of individuals according to\nexpression profiles. Alter et al. used such a technique to visualize cell-cycle assays (Alter et al.,\n2000), and were able to associate individual assays with different phases of the cell cycle.\n\n2.2\n\nDetection of weak expression patterns\n\nAs noise levels in the data increase, it is increasingly difficult to obtain separation of gene\ngroups in scatter plots. In such cases SVD may still be able to detect weak patterns in the data that\nmay be associated with biological effects. In this respect SVD and related methods provide\ninformation that is unique among commonly used analysis methods.\n\nFigure 5.6. SVD-based detection of weak signals. a) A plot of the first eigengene shows the structure of the weak sine\nwave signal that contributes to the transcriptional response for half of the genes. b) The second eigengene resembles\nnoise. c) A relative variance plot for the first six singular values shows an elbow after the first singular value. d) The\nsignal and noise genes are not separated in an eigengene scatter plot of 150 of the signal genes, and 150 of the noiseonly genes.\n\n\f5. Singular value decomposition and principal component analysis\nHere we will use an example to illustrate the ability of SVD to detect patterns in gene\ntranscriptional response even though the individual genes may not clearly separate in a scatter\nplot. A data matrix was generated using two kinds of transcriptional response: 1,000 genes\nexhibiting a sine pattern, sin(2\u03c0t/140), with added noise sampled from a normal distribution of\nzero mean and standard deviation 1.5; and 1,000 genes with just noise sampled from the same\ndistribution. Upon application of SVD, we find that the first eigengene shows a coherent sine\npattern (Figure 5.6a). The second eigengene is dominated by high-frequency components that can\nonly come from the noise (Figure 5.6b), and the singular value spectrum has an elbow after the\nfirst singular value (Figure 5.6c), suggesting (as we know a priori) that there is only one\ninteresting signal in the data. Even though the SVD detected the cyclic pattern in the first\neigengene (Figure 5.6a), the sine wave and noise-only genes are not clearly separated in the SVD\neigengene projection scatter plot (Figure 5.6d).\n\n2.3\n\nExamples from the literature\n\nCell-cycle gene expression data display strikingly simple patterns when analyzed using SVD.\nHere we discuss two different studies that, despite having used different pre-processing methods,\nhave produced similar results (Alter et al., 2000; Holter et al., 2000). Both studies found cyclic\npatterns for the first two eigengenes, and, in two-dimensional correlation scatter plots, previously\nidentified cell cycle genes tended to plot towards the perimeter of a disc. Alter et al. used\ninformation in SVD correlation scatter plots to obtain a result that 641 of the 784 cell-cycle genes\nidentified in (Spellman et al., 1998) are associated with the first two eigengenes. Holter et al.\ndisplayed previously identified cell-cycle gene clusters in scatter plots, revealing that cell-cycle\ngenes were relatively uniformly distributed in a ring-like feature around the perimeter, leading\nHolter et al. to suggest that cell-cycle gene regulation may be a more continuous process than had\nbeen implied by the previous application of clustering algorithms.\nRaychaudhuri et al.'s study of yeast sporulation time series data (Raychaudhuri et al., 2000) is\nan early example of application of PCA to microarray analysis. In this study, over 90% of the\nvariance in the data was explained by the first two components of the PCA. The first principal\ncomponent contained a strong steady-state signal. Projection scatter plots were used in an attempt\nto visualize previously identified gene groups, and to look for structures in the data that would\nindicate separation of genes into groups. No clear structures were visible that indicated any\nseparation of genes in scatter plots. Holter et al.'s more recent SVD analysis of yeast sporulation\ndata (Holter et al., 2000) made use of a different pre-processing scheme from that of\nRaychaudhuri et al. The crucial difference is that the rows and columns of X in Holter et al.'s\nstudy were iteratively centered and normalized. In Holter et al.'s analysis, the first two\neigengenes were found to account for over 60% of the variance for yeast sporulation data. The\nfirst two eigengenes were significantly different from those of Raychaudhuri et al., with no\nsteady-state signal, and, most notably, structure indicating separation of gene groups was visible\nin the data. Below we discuss the discrepancy between these analyses of yeast sporulation data.\n\n3.\n\nDISCUSSION\n\nSelection of an appropriate pre-processing method is critical, and comparisons of results using\ndifferent methods must always take the pre-processing into account. By inspecting the SVD of\ndata, one can potentially evaluate different pre-processing choices by gaining insight into, e.g.,\n13\n\n13\n\n\f14\n\nChapter 5\n\nseparability in scatter plots. The utility of SVD itself, however, depends on the choice of preprocessing, as the apparent discrepancy between the sporulation analyses described in section 2.3\nillustrates. While structure was revealed in yeast sporulation data using the SVD on centered,\nnormalized data (Holter et al., 2000), structure was not visible using SVD on the original data\n(Raychaudhuri et al., 2000), where the first component accounted for the steady-state gene\nexpression levels. There are no hard rules to be applied, but in general the decision of how to preprocess the data should be made based on the statistics of the data, what questions are being\nasked, and what methods are being used to reveal information about those questions. As an\nexample, performing a centering of gene transcriptional responses for time series data is often\nsensible because we are typically more interested in how a gene's transcriptional response varies\nover time than we are in its steady-state expression level.\nAn important capability distinguishing SVD and related methods from other analysis methods\nis the ability to detect weak signals in the data. Even when the structure of the data does not allow\nseparation of data points, causing clustering algorithms to fail, it may be possible to detect\nbiologically meaningful patterns. In section 2.2 we have given an example of this phenomenon\nusing synthetic data. As an example of practical use of this kind of SVD-based analysis, it may be\npossible to detect whether the expression profile of a tissue culture changes in response to\nradiation dose, even when it is not possible to detect which specific genes change their expression\nin response to radiation dose.\nSVD allows us to obtain the true dimensionality of our data, which is the rank r of matrix X.\nAs the number of genes m is generally (at least presently) greater than the number of assays n, the\nmatrix VT generally yields a representation of the assay expression profiles using a reduced\nnumber of variables. When r < n, the matrix U yields a representation of the gene transcriptional\nresponses using a reduced number of variables. Although this property of the SVD is commonly\nreferred to as dimensionality reduction, we note that any reconstruction of the original data\nrequires generation of an m \u00d7 n matrix, and thus requires a mapping that involves all of the\noriginal dimensions. Given the noise present in real data, in practice the rank of matrix X will\nalways be n, leading to no dimensionality reduction for the gene transcriptional responses. It may\nbe possible to detect the \"true\" rank r by ignoring selected components, thereby reducing the\nnumber of variables required to represent the gene transcriptional responses. As discussed above,\nexisting SVD-based methods for pre-processing based on this kind of feature selection must be\nused with caution.\nCurrent thoughts about use of SVD/PCA for gene expression analysis often include\napplication of SVD as pre-processing for clustering. Clustering algorithms can be applied using,\ne.g., the coordinates calculated for scatter plots instead of the original data points. Yeung and\nRuzzo have characterized the effectiveness of gene clustering both with and without preprocessing using PCA (Yeung and Ruzzo, 2001). The pre-processing consisted of using PCA to\nselect only the highest-variance principal components, thereby choosing a reduced number of\nvariables for each gene's transcriptional response. The reduced variable sets were used as inputs\nto clustering algorithms. Better performance was observed without pre-processing for the tested\nalgorithms and the data used, and the authors generally recommend against using PCA as a preprocessing step for clustering. The sole focus on gene clustering, however, in addition to the\nnarrow scope of the tested algorithms and data, limit the implications of the results of this study.\nFor example, when grouping assays is of interest, using {Sa'j} instead of {aj} (see section 2;\nFigure 5.1) enables use of a significantly reduced number of variables (r vs. m) that account for\nall of the structure in the distribution of assays. Use of the reduced variable set for clustering must\n\n\f5. Singular value decomposition and principal component analysis\ntherefore result in not only decreased compute time, but also clusters of equal or higher quality.\nThus the results in (Yeung and Ruzzo, 2001) for gene clustering do not apply to assay clustering.\nIn section 2.3 we discuss how, rather than separating into well-defined groups, cell-cycle\ngenes tend to be more continuously distributed in SVD projections. For instance, when plotting\nthe correlations of genes with the first two right singular vectors, cell-cycle genes appear to be\nrelatively uniformly distributed about a ring. This structure suggests that, rather than using a\nclassification method that groups genes according to their co-location in the neighborhood of a\npoint (e.g., k-means clustering), one should choose a classification method appropriate for dealing\nwith ring-like distributions. Previous cell-cycle analyses therefore illustrate the fact that one\nimportant use of SVD is to aid in selection of appropriate classification methods by investigation\nof the dimensionality of the data.\nIn this chapter we have concentrated on conveying a general understanding of the application\nof SVD analysis to gene expression data. Here we briefly mention several specific SVD-based\nmethods that have been published for use in gene expression analysis. For gene grouping, the\ngene shaving algorithm (Hastie et al., 2000) and SVDMAN (Wall et al., 2001) are available. An\nimportant feature to note about both gene shaving and SVDMAN is that each gene may be a\nmember of more than one group. For evaluation of data, SVDMAN uses SVD-based interpolation\nof deleted data to detect sampling problems when the assays correspond to a sampling of an\nordinal or continuous variable (e.g., time series data). A program called SVDimpute\n(Troyanskaya et al., 2001) implements an SVD-based algorithm for imputing missing values in\ngene expression data. Holter et al. have developed an SVD-based method for analysis of time\nseries expression data (Holter et al., 2001). The algorithm estimates a time translation matrix that\ndescribes evolution of the expression data in a linear model. Yeung et al. have also made use of\nSVD in a method for reverse engineering linearly coupled models of gene networks (Yeung et al.,\n2002).\nIt is important to note that application of SVD and PCA to gene expression analysis is\nrelatively recent, and that methods are currently evolving. Presently, gene expression analysis in\ngeneral tends to consist of iterative applications of interactively performed analysis methods. The\ndetailed path of any given analysis depends on what specific scientific questions are being\naddressed. As new inventions emerge, and further techniques and insights are obtained from other\ndisciplines, we mark progress towards the goal of an integrated, theoretically sound approach to\ngene expression analysis.\n\n4.\n\nFURTHER READING AND RESOURCES\n\nThe book (Jolliffe, 1986) is a fairly comprehensive reference on PCA (a new edition is meant\nto appear in summer of 2002); it gives interpretations of PCA and provides many example\napplications, with connections to and distinctions from other techniques such as correspondence\nanalysis and factor analysis. For more details on the mathematics and computation of SVD, good\nreferences are (Golub and Van Loan, 1996), (Strang, 1998), (Berry, 1992), and (Jessup and\nSorensen, 1994). SVDPACKC has been developed to compute the SVD algorithm (Berry et al.,\n1993). Some web resources on SVD are found at the following URL's:\nhttp://www.cs.ut.ee/~toomas_l/linalg/; http://www.lapeth.ethz.ch/~david/diss/node10.html; and\nhttp://www.stanford.edu/class/cs205/notes/book/book.html. SVD is used in the solution of\nunconstrained linear least squares problems, matrix rank estimation, and canonical correlation\nanalysis (Berry, 1992).\n15\n\n15\n\n\f16\n\nChapter 5\n\nApplications of PCA and/or SVD to gene expression data have been published in (Alter et al.,\n2000; Holter et al., 2000; Holter et al., 2001; Raychaudhuri et al., 2000; Troyanskaya et al., 2001;\nYeung and Ruzzo, 2001; Yeung et al., 2002). In addition, SVDMAN (Wall et al., 2001) and gene\nshaving (Hastie et al., 2000) are published SVD-based grouping algorithms; SVDMAN is free\nsoftware available at http://home.lanl.gov/svdman. Knudsen illustrates some of the uses of PCA\nfor visualization of gene expression data (Knudsen, 2002).\nEveritt, Landau and Leese (Everitt et al., 2001) present PCA as a special case of Projection\nPursuit (Friedman and Tukey, 1974). Projection Pursuit, which in general attempts to find an\n\"interesting projection\" for the data, is also related to Independent Component Analysis (ICA)\n(Hyv\u00e4rinen, 1999). ICA attempts to find a linear transformation (non-linear generalizations are\npossible) of the data so that the derived components are as statistically independent from each\nother as possible. Hyv\u00e4rinen discusses ICA and how it relates to PCA and Projection Pursuit\n(Hyv\u00e4rinen, 1999). Liebermeister has applied ICA to gene expression data (Liebermeister, 2002).\nOther techniques that are related to PCA and SVD for visualization of data are\nMultidimensional Scaling (Borg and Groenen, 1997) and Self-Organizing Maps (SOM)\n(Kohonen, 2001). Both of these techniques use non-linear mappings of the data to find lowerdimensional representations. SOM's have been applied to gene expression data in (Tamayo et al.,\n1999). There are also non-linear generalizations of PCA (Jolliffe, 1986; Scholkopf et al., 1996).\n\nACKNOWLEDGMENTS\nWe gratefully acknowledge Raphael Gottardo and Kevin Vixie for critically reading the\nmanuscript. The writing of this chapter was performed within the auspices of the Department of\nEnergy (DOE) under contract to the University of California, and was supported by LaboratoryDirected Research and Development at Los Alamos National Laboratory.\n1\n\nFor simplicity, we use the term microarray to refer to all varieties of global gene expression technologies.\nComplete understanding of the material in this chapter requires a basic understanding of linear algebra. We find\nmathematical definitions to be the only antidote to the many confusions that can arise in discussion of SVD and\nPCA.\n3\nThe rank of a matrix is the number of linearly independent rows or columns.\n4\nThe covariance between variables x and y is C(x,y) = (N-1)-1\u03a3i(xi-<x>)(yi-<y>), where N is the # of observations, and\ni=1,...,N. Elements of the covariance matrix for a set of variables {z(k)} are given by cij = C(z(i),z(j)).\n5\nA centered vector is one with zero mean value for the elements.\n6\nNote that (XTX)ij = ai*aj\n7\nNote that (XXT)ij = gi*gj\n8\nA normalized vector is one with unit length.\n9\nThis notation is similar to that used in (Alter et al., 2000), save that we use the term eigenassay instead of eigenarray.\n10\nA cluster center is the average position of the points in a cluster.\n2\n\nREFERENCES\nAlter O., Brown P.O., Botstein D. Singular value decomposition for genome-wide expression data processing and\nmodeling. Proc Natl Acad Sci USA 2000; 97:10101-06.\nBerry M.W. Large-scale sparse singular value computations. International Journal of Supercomputer Applications\n1992; 6:13-49.\nBerry M.W., Do T., Obrien G.W., Krishna V., Varadhan S., SVDPACKC: Version 1.0 User's Guide. Knoxville:\nUniversity of Tennessee, 1993.\n\n\f5. Singular value decomposition and principal component analysis\n\nBerry M.W., Dumais S.T., Obrien G.W. Using linear algebra for intelligent information-retrieval. Siam Review 1995;\n37:573-95.\nBorg I., Groenen P., Modern Multidimensional Scaling: Theory and Applications. New York: Springer Verlag, 1997.\nCattell R.B. The scree test for the number of factors. Multivariate Behavioral Research 1966; 1:245-76.\nChen L., Hodgson K.O., Doniach S. A lysozyme folding intermediate revealed by solution X-ray scattering. J Mol Biol\n1996; 261:658-71.\nCho R.J., Campbell M.J., Winzeler E.A., Steinmetz L., Conway A., Wodicka L., Wolfsberg T.G., Gabrielian A.E.,\nLandsman D., Lockhart D.J., Davis R.W. A genome-wide transcriptional analysis of the mitotic cell cycle. Mol Cell\n1998; 2:65-73.\nDeprettere F., SVD and Signal Processing: Algorithms, Analysis and Applications. Amsterdam: Elsevier Science\nPublishers, 1988.\nEisen M.B., Spellman P.T., Brown P.O., Botstein D. Cluster analysis and display of genome-wide expression patterns.\nProc Natl Acad Sci USA 1998; 95:14863-68.\nEveritt B.S., Dunn G., Applied Multivariate Data Analysis. London: Arnold, 2001.\nEveritt S.E., Landau S., Leese M., Cluster Analysis. London: Arnold, 2001.\nFesel C., Coutinho A. Dynamics of serum IgM autoreactive repertoires following immunization: strain specificity,\ninheritance and association with autoimmune disease susceptibility. Eur J Immunol 1998; 28:3616-29.\nFriedman J.H., Tukey J.W. A projection pursuit algorithm for exploratory data analysis. IEEE Transactions on\nComputers 1974; 23:881-89.\nGarcia A.E. Large-Amplitude Nonlinear Motions in Proteins. Phys Rev Lett 1992; 68:2696-99.\nGolub G., Van Loan C., Matrix Computations. Baltimore: Johns Hopkins Univ Press, 1996.\nHastie T., Tibshirani R., Eisen M.B., Alizadeh A., Levy R., Staudt L., Chan W.C., Botstein D., Brown P. 'Gene\nshaving' as a method for identifying distinct sets of genes with similar expression patterns. Genome Biol 2000;\n1:research0003.1-03.21.\nHolter N.S., Mitra M., Maritan A., Cieplak M., Banavar J.R., Fedoroff N.V. Fundamental patterns underlying gene\nexpression profiles: simplicity from complexity. Proc Natl Acad Sci USA 2000; 97:8409-14.\nHolter N.S., Maritan A., Cieplak M., Fedoroff N.V., Banavar J.R. Dynamic modeling of gene expression data. Proc\nNatl Acad Sci USA 2001; 98:1693-98.\nHughes T.R., Marton M.J., Jones A.R., Roberts C.J., Stoughton R., Armour C.D., Bennett H.A., Coffey E., Dai H., He\nY.D., Kidd M.J., King A.M., Meyer M.R., Slade D., Lum P.Y., Stepaniants S.B., Shoemaker D.D., Gachotte D.,\nChakraburtty K., Simon J., Bard M., Friend S.H. Functional discovery via a compendium of expression profiles.\nCell 2000; 102:109-26.\nHyv\u00e4rinen A. Survey on Independent Component Analysis. Neural Computing Surveys 1999; 2:94-128.\nJessup E.R., Sorensen D.C. A parallel algorithm for computing the singular-value decomposition of a matrix. Siam\nJournal on Matrix Analysis and Applications 1994; 15:530-48.\nJolliffe I.T., Principal Component Analysis. New York: Springer, 1986.\nKanji G.K., 100 Statistical Tests. New Delhi: Sage, 1993.\nKnudsen S., A Biologist's Guide to Analysis of DNA Microarray Data. New York: John Wiley & Sons, 2002.\nKohonen T., Self-Organizing Maps. Berlin: Springer-Verlag, 2001.\nLiebermeister W. Linear modes of gene expression determined by independent component analysis. Bioinformatics\n2002; 18:51-60.\nRaychaudhuri S., Stuart J.M., Altman R.B. Principal components analysis to summarize microarray experiments:\napplication to sporulation time series. Pac Symp Biocomput 2000:455-66.\nRichards J.A., Remote Sensing Digital Image Analysis. New York: Springer-Verlag, 1993.\nRomo T.D., Clarage J.B., Sorensen D.C., Phillips G.N., Jr. Automatic identification of discrete substates in proteins:\nsingular value decomposition analysis of time-averaged crystallographic refinements. Proteins 1995; 22:311-21.\nScholkopf B., Smola A.J., Muller K.-R., \"Nonlinear component analysis as a kernel eigenvalue problem,\" technical\nreport. Tuebingen: Max-Planck-Institut fur biologische Kybernetik, 1996.\nSpellman P.T., Sherlock G., Zhang M.Q., Iyer V.R., Anders K., Eisen M.B., Brown P.O., Botstein D., Futcher B.\nComprehensive identification of cell cycle-regulated genes of the yeast Saccharomyces cerevisiae by microarray\nhybridization. Mol Biol Cell 1998; 9:3273-97.\nStrang G., Introduction to Linear Algebra. Wellesley, MA: Wellesley Cambridge Press, 1998.\nTamayo P., Slonim D., Mesirov J., Zhu Q., Kitareewan S., Dmitrovsky E., Lander E.S., Golub T.R. Interpreting\npatterns of gene expression with self-organizing maps: methods and application to hematopoietic differentiation.\nProc Natl Acad Sci USA 1999; 96:2907-12.\n\n17\n\n17\n\n\f18\n\nChapter 5\n\nTroyanskaya O., Cantor M., Sherlock G., Brown P., Hastie T., Tibshirani R., Botstein D., Altman R.B. Missing value\nestimation methods for DNA microarrays. Bioinformatics 2001; 17:520-25.\nWall M.E., Dyck P.A., Brettin T.S. SVDMAN -- singular value decomposition analysis of microarray data.\nBioinformatics 2001; 17:566-68.\nYeung K.Y., Ruzzo W.L. Principal component analysis for clustering gene expression data. Bioinformatics 2001;\n17:763-74.\nYeung M.K., Tegner J., Collins J.J. Reverse engineering gene networks using singular value decomposition and robust\nregression. Proc Natl Acad Sci USA 2002; 99:6163-68.\n\n\f"}