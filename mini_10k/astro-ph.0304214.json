{"id": "http://arxiv.org/abs/astro-ph/0304214v3", "guidislink": true, "updated": "2003-09-22T13:06:28Z", "updated_parsed": [2003, 9, 22, 13, 6, 28, 0, 265, 0], "published": "2003-04-11T12:33:47Z", "published_parsed": [2003, 4, 11, 12, 33, 47, 4, 101, 0], "title": "Reconstruction of the early Universe as a convex optimization problem", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=astro-ph%2F0304341%2Castro-ph%2F0304039%2Castro-ph%2F0304184%2Castro-ph%2F0304128%2Castro-ph%2F0304481%2Castro-ph%2F0304200%2Castro-ph%2F0304106%2Castro-ph%2F0304544%2Castro-ph%2F0304399%2Castro-ph%2F0304112%2Castro-ph%2F0304013%2Castro-ph%2F0304301%2Castro-ph%2F0304543%2Castro-ph%2F0304362%2Castro-ph%2F0304058%2Castro-ph%2F0304508%2Castro-ph%2F0304364%2Castro-ph%2F0304170%2Castro-ph%2F0304196%2Castro-ph%2F0304224%2Castro-ph%2F0304005%2Castro-ph%2F0304295%2Castro-ph%2F0304134%2Castro-ph%2F0304061%2Castro-ph%2F0304464%2Castro-ph%2F0304178%2Castro-ph%2F0304422%2Castro-ph%2F0304055%2Castro-ph%2F0304425%2Castro-ph%2F0304213%2Castro-ph%2F0304038%2Castro-ph%2F0304374%2Castro-ph%2F0304350%2Castro-ph%2F0304050%2Castro-ph%2F0304028%2Castro-ph%2F0304504%2Castro-ph%2F0304514%2Castro-ph%2F0304353%2Castro-ph%2F0304363%2Castro-ph%2F0304179%2Castro-ph%2F0304451%2Castro-ph%2F0304489%2Castro-ph%2F0304467%2Castro-ph%2F0304501%2Castro-ph%2F0304429%2Castro-ph%2F0304244%2Castro-ph%2F0304046%2Castro-ph%2F0304472%2Castro-ph%2F0304367%2Castro-ph%2F0304165%2Castro-ph%2F0304228%2Castro-ph%2F0304113%2Castro-ph%2F0304368%2Castro-ph%2F0304270%2Castro-ph%2F0304101%2Castro-ph%2F0304042%2Castro-ph%2F0304130%2Castro-ph%2F0304486%2Castro-ph%2F0304498%2Castro-ph%2F0304171%2Castro-ph%2F0304392%2Castro-ph%2F0304201%2Castro-ph%2F0304209%2Castro-ph%2F0304104%2Castro-ph%2F0304183%2Castro-ph%2F0304478%2Castro-ph%2F0304298%2Castro-ph%2F0304188%2Castro-ph%2F0304221%2Castro-ph%2F0304010%2Castro-ph%2F0304424%2Castro-ph%2F0304369%2Castro-ph%2F0304527%2Castro-ph%2F0304532%2Castro-ph%2F0304143%2Castro-ph%2F0304245%2Castro-ph%2F0304403%2Castro-ph%2F0304095%2Castro-ph%2F0304292%2Castro-ph%2F0304091%2Castro-ph%2F0304105%2Castro-ph%2F0304181%2Castro-ph%2F0304550%2Castro-ph%2F0304372%2Castro-ph%2F0304319%2Castro-ph%2F0304197%2Castro-ph%2F0304032%2Castro-ph%2F0304361%2Castro-ph%2F0304273%2Castro-ph%2F0304146%2Castro-ph%2F0304217%2Castro-ph%2F0304268%2Castro-ph%2F0304528%2Castro-ph%2F0304360%2Castro-ph%2F0304142%2Castro-ph%2F0304214%2Castro-ph%2F0304423%2Castro-ph%2F0304432%2Castro-ph%2F0304412%2Castro-ph%2F0304308%2Castro-ph%2F0304156&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Reconstruction of the early Universe as a convex optimization problem"}, "summary": "We show that the deterministic past history of the Universe can be uniquely\nreconstructed from the knowledge of the present mass density field, the latter\nbeing inferred from the 3D distribution of luminous matter, assumed to be\ntracing the distribution of dark matter up to a known bias. Reconstruction\nceases to be unique below those scales -- a few Mpc -- where multi-streaming\nbecomes significant. Above 6 Mpc/h we propose and implement an effective\nMonge-Ampere-Kantorovich method of unique reconstruction. At such scales the\nZel'dovich approximation is well satisfied and reconstruction becomes an\ninstance of optimal mass transportation, a problem which goes back to Monge\n(1781). After discretization into N point masses one obtains an assignment\nproblem that can be handled by effective algorithms with not more than cubic\ntime complexity in N and reasonable CPU time requirements. Testing against\nN-body cosmological simulations gives over 60% of exactly reconstructed points.\n  We apply several interrelated tools from optimization theory that were not\nused in cosmological reconstruction before, such as the Monge-Ampere equation,\nits relation to the mass transportation problem, the Kantorovich duality and\nthe auction algorithm for optimal assignment. Self-contained discussion of\nrelevant notions and techniques is provided.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=astro-ph%2F0304341%2Castro-ph%2F0304039%2Castro-ph%2F0304184%2Castro-ph%2F0304128%2Castro-ph%2F0304481%2Castro-ph%2F0304200%2Castro-ph%2F0304106%2Castro-ph%2F0304544%2Castro-ph%2F0304399%2Castro-ph%2F0304112%2Castro-ph%2F0304013%2Castro-ph%2F0304301%2Castro-ph%2F0304543%2Castro-ph%2F0304362%2Castro-ph%2F0304058%2Castro-ph%2F0304508%2Castro-ph%2F0304364%2Castro-ph%2F0304170%2Castro-ph%2F0304196%2Castro-ph%2F0304224%2Castro-ph%2F0304005%2Castro-ph%2F0304295%2Castro-ph%2F0304134%2Castro-ph%2F0304061%2Castro-ph%2F0304464%2Castro-ph%2F0304178%2Castro-ph%2F0304422%2Castro-ph%2F0304055%2Castro-ph%2F0304425%2Castro-ph%2F0304213%2Castro-ph%2F0304038%2Castro-ph%2F0304374%2Castro-ph%2F0304350%2Castro-ph%2F0304050%2Castro-ph%2F0304028%2Castro-ph%2F0304504%2Castro-ph%2F0304514%2Castro-ph%2F0304353%2Castro-ph%2F0304363%2Castro-ph%2F0304179%2Castro-ph%2F0304451%2Castro-ph%2F0304489%2Castro-ph%2F0304467%2Castro-ph%2F0304501%2Castro-ph%2F0304429%2Castro-ph%2F0304244%2Castro-ph%2F0304046%2Castro-ph%2F0304472%2Castro-ph%2F0304367%2Castro-ph%2F0304165%2Castro-ph%2F0304228%2Castro-ph%2F0304113%2Castro-ph%2F0304368%2Castro-ph%2F0304270%2Castro-ph%2F0304101%2Castro-ph%2F0304042%2Castro-ph%2F0304130%2Castro-ph%2F0304486%2Castro-ph%2F0304498%2Castro-ph%2F0304171%2Castro-ph%2F0304392%2Castro-ph%2F0304201%2Castro-ph%2F0304209%2Castro-ph%2F0304104%2Castro-ph%2F0304183%2Castro-ph%2F0304478%2Castro-ph%2F0304298%2Castro-ph%2F0304188%2Castro-ph%2F0304221%2Castro-ph%2F0304010%2Castro-ph%2F0304424%2Castro-ph%2F0304369%2Castro-ph%2F0304527%2Castro-ph%2F0304532%2Castro-ph%2F0304143%2Castro-ph%2F0304245%2Castro-ph%2F0304403%2Castro-ph%2F0304095%2Castro-ph%2F0304292%2Castro-ph%2F0304091%2Castro-ph%2F0304105%2Castro-ph%2F0304181%2Castro-ph%2F0304550%2Castro-ph%2F0304372%2Castro-ph%2F0304319%2Castro-ph%2F0304197%2Castro-ph%2F0304032%2Castro-ph%2F0304361%2Castro-ph%2F0304273%2Castro-ph%2F0304146%2Castro-ph%2F0304217%2Castro-ph%2F0304268%2Castro-ph%2F0304528%2Castro-ph%2F0304360%2Castro-ph%2F0304142%2Castro-ph%2F0304214%2Castro-ph%2F0304423%2Castro-ph%2F0304432%2Castro-ph%2F0304412%2Castro-ph%2F0304308%2Castro-ph%2F0304156&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We show that the deterministic past history of the Universe can be uniquely\nreconstructed from the knowledge of the present mass density field, the latter\nbeing inferred from the 3D distribution of luminous matter, assumed to be\ntracing the distribution of dark matter up to a known bias. Reconstruction\nceases to be unique below those scales -- a few Mpc -- where multi-streaming\nbecomes significant. Above 6 Mpc/h we propose and implement an effective\nMonge-Ampere-Kantorovich method of unique reconstruction. At such scales the\nZel'dovich approximation is well satisfied and reconstruction becomes an\ninstance of optimal mass transportation, a problem which goes back to Monge\n(1781). After discretization into N point masses one obtains an assignment\nproblem that can be handled by effective algorithms with not more than cubic\ntime complexity in N and reasonable CPU time requirements. Testing against\nN-body cosmological simulations gives over 60% of exactly reconstructed points.\n  We apply several interrelated tools from optimization theory that were not\nused in cosmological reconstruction before, such as the Monge-Ampere equation,\nits relation to the mass transportation problem, the Kantorovich duality and\nthe auction algorithm for optimal assignment. Self-contained discussion of\nrelevant notions and techniques is provided."}, "authors": ["Y. Brenier", "U. Frisch", "M. Henon", "G. Loeper", "S. Matarrese", "R. Mohayaee", "A. Sobolevskii"], "author_detail": {"name": "A. Sobolevskii"}, "author": "A. Sobolevskii", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1046/j.1365-2966.2003.07106.x", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/astro-ph/0304214v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/astro-ph/0304214v3", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "26 pages, 14 figures; accepted to MNRAS. Version 2: numerous minour\n  clarifications in the text, additional material on the history of the\n  Monge-Ampere equation, improved description of the auction algorithm, updated\n  bibliography. Version 3: several misprints corrected", "arxiv_primary_category": {"term": "astro-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "astro-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cond-mat", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.MP", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.OC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "nlin.PS", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/astro-ph/0304214v3", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/astro-ph/0304214v3", "journal_reference": "Mon.Not.Roy.Astron.Soc. 346 (2003) 501-524", "doi": "10.1046/j.1365-2966.2003.07106.x", "fulltext": "Mon. Not. R. Astron. Soc. 000, 000\u2013000 (0000)\n\nPrinted 30 October 2018\n\n(MN LATEX style file v2.2)\n\nReconstruction of the early Universe as a convex\noptimization problem\nY. Brenier,1 U. Frisch,2,3\u22c6 M. H\u00e9non,2 G. Loeper,1 S. Matarrese,4\nR. Mohayaee,2 A. Sobolevski\u0131\u03062,5\n1\n2\n\narXiv:astro-ph/0304214v3 22 Sep 2003\n\n3\n4\n5\n\nCNRS, UMR 6621, Universit\u00e9 de Nice-Sophia-Antipolis, Parc Valrose, 06108 Nice Cedex 02, France\nCNRS, UMR 6529, Observatoire de la C\u00f4te d'Azur, BP 4229, 06304 Nice Cedex 4, France\nInstitute for Advanced Study, Einstein Drive, Princeton, NJ 08540, USA\nDipartimento di Fisica 'G. Galilei' and INFN, Sezione di Padova, via Marzolo 8, 35131-Padova, Italy\nDepartment of Physics, M. V. Lomonossov Moscow University, Leninskie Gory, 119992 Moscow, Russia\n\n30 October 2018\n\nABSTRACT\n\nWe show that the deterministic past history of the Universe can be uniquely reconstructed from the knowledge of the present mass density field, the latter being inferred\nfrom the 3D distribution of luminous matter, assumed to be tracing the distribution\nof dark matter up to a known bias. Reconstruction ceases to be unique below those\nscales \u2013 a few Mpc \u2013 where multi-streaming becomes significant. Above 6 h\u22121 Mpc we\npropose and implement an effective Monge\u2013Amp\u00e8re\u2013Kantorovich method of unique\nreconstruction. At such scales the Zel'dovich approximation is well satisfied and reconstruction becomes an instance of optimal mass transportation, a problem which\ngoes back to Monge (1781). After discretization into N point masses one obtains an\nassignment problem that can be handled by effective algorithms with not more than\nO(N 3 ) time complexity and reasonable CPU time requirements. Testing against N body cosmological simulations gives over 60% of exactly reconstructed points.\nWe apply several interrelated tools from optimization theory that were not used\nin cosmological reconstruction before, such as the Monge\u2013Amp\u00e8re equation, its relation to the mass transportation problem, the Kantorovich duality and the auction\nalgorithm for optimal assignment. Self-contained discussion of relevant notions and\ntechniques is provided.\nKey words: cosmology: theory \u2013 large-scale structure of the Universe \u2013 hydrodynamics\n\n1\n\nINTRODUCTION\n\nCan one follow back in time to initial locations the highly\nstructured present distribution of mass in the Universe, as\nmapped by redshift catalogues of galaxies? At first this\nseems an ill-posed problem since little is known about the\npeculiar velocities of galaxies, so that equations governing\nthe dynamics cannot just be integrated back in time. In fact,\nit is precisely one of the goals of reconstruction to determine\nthe peculiar velocities. Since the pioneering work of Peebles\n(1989), a number of reconstruction techniques have been\nproposed, which frequently provided non-unique answers.1\nCosmological reconstruction should however take ad-\n\n\u22c6\n\nE-mail: uriel@obs-nice.fr\nWe put the present work in context of several important existing techniques in Section 7.\n\n1\n\nc 0000 RAS\n\nvantage of our knowledge that the initial mass distribution was quasi-uniform at baryon-photon decoupling, about\n14 billion years ago (see, e.g., Susperregi & Binney 1994).\nIn a recent Letter to Nature (Frisch et al. 2002), four of us\nhave shown that, with suitable assumptions, this a priori\nknowledge of the initial density field makes reconstruction\na well-posed instance of what is called the optimal mass\ntransportation problem.\nA well-known fact is that, in an expanding universe with\nself-gravitating matter, the initial velocity field is 'slaved' to\nthe initial gravitational field, which is potential; both fields\nthus depend on a single scalar function. Hence the number\nof unknowns matches the number of constraints, namely the\nsingle density function characterising the present distribution of mass.\nThis observation alone, of course, does not ensure\nuniqueness of the reconstruction. For this, two restrictions\n\n\f2\n\nY. Brenier et al.\n\nd\u00e9blais\n\nremblais\n\nFigure 1. A sketch of Monge's mass transportation problem in\nwhich one searches the optimal way of transporting earth from\ncuts (d\u00e9blais) to fills (remblais), each of prescribed shape; the\ncost of transporting a molecule of earth is a given function of the\ndistance. The MAK method of reconstructing the early Universe\ndescribed in this paper corresponds to a quadratic cost.\n\nwill turn out to be crucial. First, from standard redshift\ncatalogues it is impossible to resolve individual streams of\nmatter with different velocities if they occupy the same space\nvolume. This 'multi-streaming' is typically confined to relatively small scales of a few megaparsecs (Mpc), below which\nreconstruction is hardly feasible. Second, to reconstruct a\ngiven finite patch of the present Universe, we need to know\nits initial shape at least approximately.\nIt is our purpose in the present paper to clarify the physical nature of the factors permitting a unique reconstruction\nand of obstacles limiting it, and to give a detailed account\nof the way some recent developments in the optimal mass\ntransportation theory are applicable. (Fig. 1 may give the\nreader some feeling of what mass transportation is about.)\nThe paper is organized as follows. In Section 2 we formulate the reconstruction problem in an expanding universe\nand state the main result about uniqueness of the solution.\nIn the next three sections we devise and test a reconstruction technique called MAK (for Monge\u2013Amp\u00e8re\u2013\nKantorovich) within a restricted framework where the Lagrangian map from initial to present mass locations is taken\npotential. In Section 3 we discuss the validity of the potentiality assumption and its relation to various approximations\nused in cosmology; then we derive the Monge\u2013Amp\u00e8re equation, a simple consequence of mass conservation, introduce\nits modern reformulation as a Monge\u2013Kantorovich problem\nof optimal mass transportation and finally discuss different\nlimitations on uniqueness of the reconstruction. In Section 4\nwe show how discretization turns optimization into an instance of the standard assignment problem; we then present\neffective algorithms for its solution, foremost the 'auction'\nalgorithm of D. Bertsekas. Section 5 is devoted to testing\nthe MAK reconstruction against N -body cosmological simulations.\nIn Section 6, we show how the general case, without the\npotentiality assumption, can also be recast as an optimization problem with a unique solution and indicate a possible\nnumerical strategy for such reconstruction. In Section 7 we\ncompare our reconstruction method with other approaches\nin the literature. In Section 8 we discuss perspectives and\nopen problems.\nA number of topics are left for appendices. In Appendix A we derive the Eulerian and Lagrangian equations in the form used throughout the paper (and provide\nsome background for non-cosmologists). Appendix B is devoted to the history of optimal mass transportation the-\n\nory, a subject more than two centuries old (Monge 1781),\nwhich has undergone significant progress within the last two\ndecades. Appendix C is a brief elementary introduction to\nthe technique of duality in optimization, which we use several times throughout the paper. Appendix D gives details\nof the uniqueness proof that is only outlined in Section 6.\nFinally, a word about notation (see also Appendix A).\nWe are using comoving coordinates denoted by x in a frame\nfollowing expansion of the Universe. Our time variable is not\nthe cosmic time but the so-called linear growth factor, here\ndenoted by \u03c4 , whose use gives to certain equations the same\nform as for compressible fluid dynamics in a non-expanding\nmedium. The subscript 0 refers to the present time (redshift\nz = 0), while the quantities evaluated at the initial epoch\ntake the subscript or superscript 'in.' Following cosmological\nusage, the Lagrangian coordinate is denoted q.\n\n2\n\nRECONSTRUCTION IN AN EXPANDING\nUNIVERSE\n\nThe most widely accepted explanation of the large-scale\nstructure seen in galaxy surveys is that it results from small\nprimordial fluctuations that grew under gravitational selfinteraction of collisionless cold dark matter (CDM) particles\nin an expanding universe (see, e.g., Bernardeau et al. (2002)\nand references therein). The relevant equations of motion,\nderived in Appendix A, are the Euler\u2013Poisson equations2\nwritten here for a flat, matter-dominated Einstein\u2013de Sitter universe (for more general case see, e.g., Catelan et al.\n1995):\n3\n(v + \u2207x \u03c6g ),\n2\u03c4\n\n\u2202\u03c4 v + (v * \u2207x )v\n\n=\n\n\u2212\n\n\u2202\u03c4 \u03c1 + \u2207x * (\u03c1v)\n\n=\n\n\u22072x \u03c6g\n\n=\n\n0,\n\u03c1\u22121\n.\n\u03c4\n\n(1)\n(2)\n(3)\n\nHere v denotes the velocity, \u03c1 denotes the density (normalized by the background density \u033a \u0304) and \u03c6g is a rescaled gravitational potential. All quantities are expressed in comoving\nspatial coordinates x and linear growth factor \u03c4 , which is\nused as the time variable; in particular, v is the Lagrangian\n\u03c4 -time derivative of the comoving coordinate of a fluid element.\n\n2.1\n\nSlaving in early-time dynamics and its fossils\n\nThe right-hand sides of the momentum and Poisson equations (1) and (3) contain denominators proportional to \u03c4 .\nHence, a necessary condition for the problem not to be singular as \u03c4 \u2192 0 is\nv in (x) + \u2207x \u03c6in\ng = 0,\n\n\u03c1in (x) = 1.\n\n(4)\n\nIn other words, (i) the initial velocity must be equal to (minus) the gradient of the initial gravitational potential and\n(ii) the initial normalized mass distribution is uniform. We\nshall refer to these conditions as slaving. Note that the density contrast \u03c1\u22121 vanishes initially, but the rescaled gravitational potential and the velocity, as defined here, stay finite\n2\n\nAlso often called the Euler equations.\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n\fReconstruction of the early Universe as a convex optimization problem\nthanks to our choice of the linear growth factor as time variable. Therefore we refer to the initial mass distribution as\n'quasi-uniform.'\nIn the sequel, when we mention the Euler\u2013Poisson\ninitial-value problem, it is always understood that we start at\n\u03c4 = 0 and assume slaving. Hence we are extending the Newtonian matter-dominated post-decoupling description back\nto \u03c4 = 0. By examination of the Lagrangian equations for\nx(q, \u03c4 ) near \u03c4 = 0, which can be linearized because the\ndisplacement x \u2212 q is small, it is easily shown that slaving\nimplies the absence of the 'decaying mode,' which behaves as\n\u03c4 \u22123/2 in an Einstein\u2013de Sitter universe and is thus singular\nat \u03c4 = 0 (for details see Appendix A).\nSlaving is also a sufficient condition for the initial problem to be well posed. It is indeed easily shown recursively\nthat (1)\u2013(3) admit a solution in the form of a formal Taylor series in \u03c4 (a related expansion involving only potentials\nmay be found in Catelan et al. 1995):\nv(x, \u03c4 )\n\n=\n\n\u03c6g (x, \u03c4 )\n\n=\n\n\u03c1(x, \u03c4 )\n\n=\n\nv (0) (x) + \u03c4 v (1) (x) + \u03c4 2 v (2) (x) + * * * ,\n\n(5)\n\n1 + \u03c4 \u03c1(1) (x) + \u03c4 2 \u03c1(2) (x) + * * * .\n\n(7)\n\n\u03c6(0)\ng (x)\n\n+\n\n\u03c4 \u03c6(1)\ng (x)\n\n+\u03c4\n\n2\n\n\u03c6(2)\ng (x)\n\n+***,\n\n(6)\n\n3\n\nterms of a single-speed solution to the Euler\u2013Poisson equations. In N -body simulations, multi-stream regions are usually found to be of relatively small extension in one or several\nspace directions, typically not more than a few Mpc, and\nhence have a small volume, although they contain a significant fraction of the total mass (see, e.g. Weinberg & Gunn\n1990).\nIn order not to have to deal with tiny multi-stream regions, we replace the true mass distribution by a 'macroscopic' one which has a regular part and a singular (collapsed) part, the latter concentrated on objects of dimension\nless than three, such as points or lines.\nThe general problem of reconstruction is to find as much\ninformation as possible on the history of the evolution that\ncarries the initial uniform density into the present macroscopic mass distribution, including the evolution of the velocities. In principle we would like to find a solution of the\nEuler\u2013Poisson initial-value problem leading to the present\ndensity field \u03c10 (x).\nA more restricted problem, which we call the 'displacement reconstruction,' is to find the Lagrangian map\nq 7\u2192 x(q) and its inverse x 7\u2192 q(x), or in other words to\nanswer the question: where does a given 'Monge molecule'5\nof matter originate from? Of course, the inverse Lagrangian\nmap will not be single-valued on mass concentrations. Furthermore, for practical cosmological applications, we define\na 'full reconstruction problem' as (i) displacement reconstruction and (ii) obtaining the initial and present peculiar\nvelocity fields, v in (q) and v 0 (x).\nWe shall show in this paper that the displacement reconstruction problem is uniquely solvable and that the full\nreconstruction problem has a unique solution outside of mass\nconcentrations; as to the latter, they are traced back to collapsed regions in the Lagrangian space whose shape and positions are well defined but the inner structure of density\nand velocity fluctuations is irretrievably lost.\n\nFurthermore, v (n) (x) is easily shown to be curl-free for\nany n.\nSeveral important consequences of slaving extend to\nlater times as 'fossils' of the earliest dynamics. First, as already stressed in the Introduction, the whole dynamics is\ndetermined by only one scalar field (e.g., the initial gravitational potential) which we can hope to determine from the\nknowledge of the present density field.\nSecond, slaving trivially rules out multi-streaming up\nto the time of formation of caustics. Since we are working\nwith collisionless matter, the dynamics should in principle\nbe governed by the Vlassov\u2013Poisson3 kinetic equation which\nallows at each (x, \u03c4 ) point a non-trivial distribution function\nf (x, v, \u03c4 ). Slaving selects a particular class of solutions for\nwhich the distribution function is concentrated on a singlespeed manifold, thereby justifying the use of the Euler\u2013\nPoisson equation without having to invoke any hydrodynamical limit (see, e.g., Vergassola et al. 1994; Catelan et al.\n1995).\nThird, it is easily checked from (1) that the initial slaved\nvelocity, which is obviously curl-free, remains so for all later\ntimes (up to formation of caustics). Note that this vanishing\nof the curl holds in Eulerian coordinates. A similar property\nin Lagrangian coordinates can only hold approximately but\nwill play an important role in the sequel (Section 3).\n\nand furthermore that the potential \u03a6(q) is convex, which is,\nas we shall see, related to the absence of multi-streaming.\n\n2.2\n\n3.1\n\nFormulation of the reconstruction problem\n\nThe present Universe is replete with high-density structures:\nclusters (point-like objects), filaments (line-like objects) and\nperhaps sheets or walls.4\nThe internal structure of such mass concentrations certainly displays multi-streaming and cannot be described in\n\n3\n\nIn this and the next two sections we shall assume that the\nLagrangian map from initial positions to present ones is potential\nx = \u2207q \u03a6(q),\n\nActually written for the first time by Jeans (1919).\n4 Whether the Great Wall and the Sculptor Wall are sheet-like\nor filament-like is a moot point (Sathyaprakash et al. 1998).\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n(8)\n\nApproximations leading to maps with convex\npotentials\n\nThe motivation for the potential assumption, first used by\nBertschinger & Dekel (1989),6 comes from the Zel'dovich\napproximation (Zel'dovich 1970), denoted here by ZA, and\nits refinements. To recall how the ZA comes about, let us\n5\n\n3\n\nPOTENTIAL LAGRANGIAN MAPS: THE\nMAK RECONSTRUCTION\n\nFor Monge and his contemporaries, the word 'molecule' meant\na Leibniz infinitesimal element of mass; see Appendix B.\n6 In connection with what was called later the Lagrangian POTENT method (Dekel, Bertschinger & Faber 1990).\n\n\f4\n\nY. Brenier et al.\n\nstart from the equations for the Lagrangian map x(q, \u03c4 ),\nwritten in the Lagrangian coordinate q (Appendix A)\nD\u03c42 x\n\u22072x \u03c6g\n\n=\n\n\u2212\n\n3\n(D\u03c4 x + \u2207x \u03c6g ),\n2\u03c4\n\n\u0003\n1\u0002\n(det \u2207q x)\u22121 \u2212 1 ,\n\u03c4\n\n=\n\n(9)\n(10)\n\nwhere D\u03c4 is the Lagrangian time derivative and \u2207xi \u2261\n(\u2202qj /\u2202xi )\u2207qj is the Eulerian gradient rewritten in Lagrangian coordinates. As shown in Appendix A, in one space\ndimension the Hubble drag term D\u03c4 x and the gravitational\nacceleration term \u2207x \u03c6g cancel exactly. Slaving, discussed\nin Section 2.1, means that the same cancellation holds to\nleading order in any dimension for small \u03c4 . The ZA extends\nthis as an approximation without the restriction of small \u03c4 .\nWithin the ZA, the acceleration D\u03c42 x vanishes. Hence the\nLagrangian map has the form\nx(q, \u03c4 )\n\n=\n=\n\nq + \u03c4 (D\u03c4 x)in (q) = q \u2212 \u03c4 \u2207q \u03c6in\ng (q)\n\n(11)\n\n\u2207q \u03a6(q, \u03c4 )\n\nwith the potential\n\u03a6(q, \u03c4 ) \u2261\n\n|q|2\n\u2212 \u03c4 \u03c6in\ng (q).\n2\n\n(12)\n\nFurthermore, taking the time derivative of (11), we see that\nthe velocity D\u03c4 x(q, \u03c4 ) is curl-free with respect to the Lagrangian coordinate q.\nPotentiality of the Lagrangian map (and consequently\nthe Lagrangian potentiality of the velocity) is perhaps the\nmost important feature of the ZA. Unlike the vanishing of\nthe acceleration, it does not depend on the choice of the\nlinear growth factor as the time variable. However, unaccelerated but vortical flow would fail to exhibit the cancellation necessary for the ZA to hold. It is noteworthy\nthat the potentiality is not limited to the ZA: indeed, the\nlatter can be formulated as the first order of a systematic Lagrangian perturbation theory in which, up to second order, the Lagrangian map is still potential under slaving (Moutarde et al. 1991; Buchert 1992; Buchert & Ehlers\n1993; Munshi, Sahni & Starobinsky 1994; Catelan 1995).\nIt is well known that the ZA map defined by (11) ceases\nin general to be invertible due to the formation of multistream regions bounded by caustics. Since particles move\nalong straight lines in the ZA, the formation of caustics\nproceeds just as in ordinary optics in a uniform medium\nin which light rays are also straight.7 One of the problems with the ZA is that caustics, which start as localized\nobjects, quickly grow in size and give unrealistically large\nmulti-stream regions.\nA modification of the ZA that has no multi-streaming\nat all, but sharp mass concentrations in the form of\nshocks and other singularities, has been introduced by\nGurbatov & Saichev (1984; see also Gurbatov et al. 1989;\nShandarin & Zel'dovich 1989). It is known as the adhesion\nmodel. In Eulerian coordinates it amounts to using a multidimensional Burgers equation (see, e.g., Frisch & Bec 2002)\n\u2202\u03c4 v + (v * \u2207x )v = \u03bd\u22072x v,\n7\n\nv = \u2212\u2207x \u03c6v ,\n\n(13)\n\nCatastrophe theory has been used to classify the different types\nof singularities thus obtained (Arnol'd, Shandarin & Zel'dovich\n1982).\n\ntaken in the limit where the viscosity \u03bd tends to zero. In\nLagrangian coordinates, the adhesion model is obtained\nfrom the ZA by replacing the velocity potential \u03a6(q, t)\ngiven by (12) by its convex hull \u03a6c (q, t) in the q variable\n(Vergassola et al. 1994).\nConvexity is a concept which plays an important role\nin this paper, and a few words on it are in order here (see\nalso Appendix C1). A body in the three-dimensional space\nis said to be convex if, whenever it contains two points, it\ncontains also the whole segment joining them. A function\nf (q) is said to be convex if the set of all points lying above\nits graph is convex. The convex hull of the function \u03a6(q)\nis defined as the largest convex function whose graph lies\nbelow that of \u03a6(q). In two dimensions it can be visualized\nby wrapping the graph of \u03a6(q) tightly from below with an\nelastic sheet.\nNote that \u03a6(q, \u03c4 ) given by (12) is obviously convex for\nsmall enough \u03c4 since it is then very close to the parabolic\nfunction |q|2 /2. After caustics form, convexity is lost in the\nZA but recovered with the adhesion model. It may then\nbe shown that those regions in the Lagrangian space where\n\u03a6(q, t) does not coincide with its convex hull will be mapped\nin the Eulerian space to sheets, lines and points, each of\nwhich contains a finite amount of mass. At these locations\nthe Lagrangian map does not have a uniquely defined Lagrangian antecedent but such points form a set of vanishing\nvolume. Everywhere else, there is a unique antecedent and\nhence no multi-streaming.\nAlthough the adhesion model has a number of\nknown shortcomings, such as non-conservation of momentum in more than one dimension, it has been found\nto be in better agreement with N -body simulations\nthan the ZA (Weinberg & Gunn 1990). Other singlespeed approximations to multi-stream flow, overcoming\ndifficulties of the adhesion model, are discussed e.g. by\nShandarin & Sathyaprakash (1996); Buchert & Dominguez\n(1998); Fanelli & Aurell (2002). In such models, multistreaming is completely suppressed by a mechanism of momentum exchange between neighbouring streams with different velocities. This is of course a common phenomenon in ordinary fluids, where it is due to viscous diffusion; dark matter is however essentially collisionless and the usual mechanism for generating viscosity does not operate, so that\na non-collisional mechanism must be invoked. A qualitative explanation using the modification of the gravitational\nforces after the formation of caustics has been proposed by\nShandarin & Zel'dovich (1989). In our opinion the mechanism limiting multi-streaming to rather narrow regions is\npoorly understood and deserves considerable further investigation.\n3.2\n\nThe Monge\u2013Amp\u00e8re equation: a consequence\nof mass conservation and potentiality\n\nWe now show that the assumption that the Lagrangian map\nis derived from a convex potential leads to a pair of nonlinear partial differential equations, one for this potential\nand another for its Legendre transform.\nLet us first assume that the present distribution of\nmass has no singular part, an assumption which we shall\nrelax later. Since in our notation the initial quasi-uniform\nmass distribution has unit density, mass conservation imc 0000 RAS, MNRAS 000, 000\u2013000\n\n\fReconstruction of the early Universe as a convex optimization problem\nplies \u03c10 (x) d3 x = d3 q, which can be rewritten in terms of\nthe Jacobian matrix \u2207q x as\ndet \u2207q x =\n\n1\n.\n\u03c10 (x(q))\n\n(14)\n\nUnder the potential assumption (8), this takes the form\ndet(\u2207qi \u2207qj \u03a6(q)) =\n\n1\n\u0001.\n\u03c10 \u2207q \u03a6(q)\n\n(15)\n\nA similar equation follows also from Eqs. (1) and (2) of\nBertschinger & Dekel (1989).\nA simpler equation, in which the unknown appears only\nin the left-hand side, viz Eq. (19) below, is obtained for the\npotential of the inverse Lagrangian map q(x). Key is the\nobservation that the inverse of a map with a convex potential has also a convex potential, and that the two potentials\nare Legendre transforms of each other.8 A purely local proof\nof this statement is to observe that potentiality of q(x) is\nequivalent to the symmetry of the inverse Jacobian matrix\n\u2207x q which follows because it is the inverse of the symmetrical matrix \u2207q x; convexity is equivalent to the positivedefiniteness of these matrices. Obviously the function\n\u0398(x) \u2261 x * q(x) \u2212 \u03a6(q(x)),\n\n(16)\n\nwhich is the Legendre transform of \u03a6(q), is the potential\nfor the inverse Lagrangian map. The modern definition of\nthe Legendre transformation (see Appendix C1), needed for\ngeneralization to non-smooth mass distributions, is\n\u0398(x)\n\n=\n\nmax x * q \u2212 \u03a6(q),\n\n(17)\n\n\u03a6(q)\n\n=\n\nmax x * q \u2212 \u0398(x).\n\n(18)\n\nq\n\nx\n\nIn terms of the potential \u0398, mass conservation is immediately written as\ndet(\u2207xi \u2207xj \u0398(x)) = \u03c10 (x).\n\n(19)\n\nThis equation, which has the determinant of the second\nderivatives of the unknown in the left-hand side and a prescribed (positive) function in the right-hand side, is called\nthe (elliptic) Monge\u2013Amp\u00e8re equation (see Appendix B for\na historical perspective).\nNotice that our Monge\u2013Amp\u00e8re equation may be\nviewed as a non-linear generalization of the Poisson equation (used for reconstruction by Nusser & Dekel (1992); see\nalso Section 7.1), to which it reduces if particles have moved\nvery little from their initial positions.\nIn actual reconstructions we have to deal with mass concentration in the present distribution of matter. Thus the\ndensity in the right-hand side of (19) has a singular component (a Dirac distribution concentrated on sets carrying\nthe concentrated mass) and the potential \u0398 ceases to be\nsmooth. As we now show, a generalized meaning can nevertheless be given to the Monge\u2013Amp\u00e8re equation by using the\n8\n\nBesides our problem, this fact prominently appears in two\nother fields of physics: in classical mechanics, the Lagrangian and\nHamiltonian functions are Legendre transforms of each other \u2013\ntheir gradients relate the generalized velocity and momentum \u2013\nand so are, in thermodynamics, the internal energy and the Gibbs\npotential, implying the same relation between extensive and intensive parameters of state.\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n5\n\nkey ingredient in its derivation, namely mass conservation,\nin integrated form.\nFor a nonsmooth convex potential \u0398, taking the gradient \u2207x \u0398(x) still makes sense if one allows it to be multivalued at points where the potential is not differentiable.\nThe gradient at such a point x is then the set of all possible slopes of planes touching the graph of \u0398 at (x, \u0398(x))\n(this idea is given a precise mathematical formulation in Appendix C1). As x varies over an arbitrary domain DE in the\nEulerian space, its image q(x) sweeps a domain q(DE ) in\nthe Lagrangian space, and mass conservation requires that\n\nZ\n\n\u03c10 (x) d3 x =\n\nDE\n\nZ\n\nd3 q,\n\n(20)\n\n\u2207x \u0398(DE )\n\nwhere we take into account that q(x) = \u2207x \u0398(x). Eq. (20)\nmust hold for any Eulerian domain DE ; this requirement\nis known as the weak formulation of the Monge\u2013Amp\u00e8re\nequation (19). A symmetric formulation may be written for\n(15) in terms of x(q) = \u2207q \u03a6(q). For further material on the\nweak formulation see, e.g., Pogorelov (1978).\nConsiderable literature has been devoted to the Monge\u2013\nAmp\u00e8re equation in recent years (see, e.g., Caffarelli 1999;\nCaffarelli & Milman 1999). We mention now a few results\nwhich are of direct relevance for the reconstruction problem.\nIn a nutshell, one can prove that when the domains occupied by the mass initially and at present are bounded and\nconvex, the Monge\u2013Amp\u00e8re equation \u2013 in its weak formulation \u2013 is guaranteed to have a unique solution, which is\nsmooth unless one or both of the mass distributions is nonsmooth. The actual construction of this solution can be done\nby a variational method discussed in the next section.\nA similar result holds also when the present density field\nis periodic and the same periodicity is assumed for the map.\nAlso relevant, as we shall see in Section 3.4, is a recent\nresult of Caffarelli & Li (2001): if the Monge\u2013Amp\u00e8re equation is considered in the whole space, but the present density\ncontrast \u03b4 = \u03c1 \u2212 1 vanishes outside of a bounded set, then\nthe solution \u0398(x) is determined uniquely up to prescription\nof its asymptotic behaviour at infinity, which is specified by\na quadratic function of the form\n\u03b8(x) \u2261 hx, Axi + hb, xi + c,\n\n(21)\n\nfor some positive definite symmetric matrix A with unit determinant, vector b and constant c.\n3.3\n\nOptimal mass transportation\n\nAs we are going to see now, the Monge\u2013Amp\u00e8re equation\n(19) is equivalent to an instance of what is called the 'optimal mass transportation problem.' Suppose we are given two\ndistributions \u03c1in (q) and \u03c10 (x) of the same amount of mass\nin two three-dimensional convex bounded domains Din and\nD0 . The optimal mass transportation problem is then to find\nthe most cost-effective way of rearranging by a suitable map\none distribution into the other, the cost of transporting a\nunit of mass from a position q \u2208 Din to x \u2208 D0 being a\nprescribed function c(q, x).\nDenoting the map by x(q) and its inverse q(x), we can\nwrite the problem as the requirement that the cost\nI\u2261\n\nZ\n\nc(q, x(q))\u03c1in (q) d3 q =\n\nDin\n\nZ\n\nc(q(x), x)\u03c10 (x) d3 x (22)\n\nD0\n\n\f6\n\nY. Brenier et al.\n\nbe minimum, with the constraints of prescribed 'terminal'\ndensities \u03c1in and \u03c10 and of mass conservation \u03c1in (q) d3 q =\n\u03c10 (x) d3 x.9\nThis problem goes back to Monge (1781) who considered the case of a linear cost function c(q, x) = |x \u2212 q| (see\nAppendix B and Fig. 1).\nFor our purposes, the central result is that the problem\nof finding a potential Lagrangian map with presecribed initial\nand present mass density fields is equivalent to a mass transportation problem with quadratic cost. Indeed, it is known\n(Brenier 1987, 1991) that, when the cost is a quadratic function of the distance, so that\nI=\n\nZ\n\n|x(q) \u2212 q|2\n\u03c1in (q) d3 q =\n2\n\nDin\n\nZ\n\n|x \u2212 q(x)|2\n\u03c10 (x) d3 x, (23)\n2\nD0\n\nthe solution q(x) to the optimal mass transportation problem is the gradient of a convex function, which then must\nsatisfy the Monge\u2013Amp\u00e8re equation (19) by mass conservation.\nA particularly simple variational proof can be given for\nthe smooth case, when the two mutually inverse maps x(q)\nand q(x) are both well defined.\nPerforming a variation of the map x(q), we cause a\nmass element in the Eulerian space that was located at\nx(q) to move to x(q) + \u03b4x(q). This variation is constrained\nnot to change the density field \u03c10 . To express this constraint it is convenient to rewrite the displacement in Eulerian coordinate \u03b4xE (x) \u2261 \u03b4x(q(x)). Noting that the point\nx gets displaced into y = x + \u03b4x, we thus require that\n\u03c10 (x) d3 x = \u03c10 (y) d3 y or\n\n\u0001\n\n\u03c10 (x) = \u03c10 (x + \u03b4xE (x)) det \u2207x (x + \u03b4xE (x)) .\n\n(24)\n\nExpanding this equation, we find that, to the leading order,\n\u2207x * (\u03c10 (x) \u03b4xE (x)) = 0,\n\n(25)\n\nan equation which just expresses the physically obvious fact\nthat the mass flux \u03c10 (x) \u03b4xE (x) should have zero divergence.\nPerforming the variation on the functional I given by (23),\nwe get\n\u03b4I\n\n=\n\nZ\n\nDin\n\n=\n\nZ\n\nD0\n\n(x(q) \u2212 q) * \u03b4x(q) \u03c1in (q) d3 q\n\n\u0001\n\n(x \u2212 q(x)) * \u03c10 (x) \u03b4xE (x) d3 x = 0,\n\n(26)\n\n(27)\n\nIndeed, should this inequality be violated for some x1 , x2 ,\nthe continuity of q(x) would imply that for all x1 , x2 close\nenough to x1 , x2\n9\n\n> |q(x2 ) \u2212 x1 |2 + |q(x1 ) \u2212 x2 |2 .\n\nNote that x(q) = q does not solve the above problem as it violates the latter constraint unless the terminal densities are identical.\n\n(28)\n\nThis in turn means that if we interchange the destinations\nof small patches around x1 and x2 , sending them not to\nthe corresponding patches around q(x1 ) and q(x2 ) but vice\nversa, then the value of the functional I will decrease by\na small yet positive quantity, and therefore it cannot be\nminimum for the original map.10\nTo complete the argument, observe that convexity of\na smooth function \u0398(x) follows if the matrix of its second\nderivatives \u2207xi \u2207xj \u0398(x) is positive definite for all x. Substituting q(x) = \u2207x \u0398(x) into (27), assuming that x2 is close\nto x1 and Taylor expanding, we find that\n(x2 \u2212 x1 ) * (\u2207xi \u2207xj \u0398(x1 ) (x2 \u2212 x1 )) > 0.\n\n(29)\n\nAs x2 is arbitrary, this proves the desired positive definiteness and thus establishes the equivalence of the Monge\u2013\nAmp\u00e8re equation (19) and of the mass transportation problem with quadratic cost.\nThis equivalence is actually proved under much weaker\nconditions, not requiring any smoothness (Brenier 1987,\n1991). The proof makes use of the 'relaxed' reformulation of\nthe mass transportation problem due to Kantorovich (1942).\nInstead of solving the highly non-linear problem of finding\na map q(x) minimizing the cost (22) with prescribed terminal densities, Kantorovich considered the linear programming problem of minimizing\nI \u0303 \u2261\n\nZ\n\nZ\n\nc(q, x) \u03c1(q, x) d3 q d3 x,\n\n(30)\n\nDin D0\n\nunder the constraint that the joint distribution \u03c1(q, x) is\nnonnegative and has marginals \u03c1in (q) and \u03c10 (x), the latter\nbeing equivalent to\n\nZ\n\nD0\n\n\u03c1(q, x) d3 x = \u03c1in (q),\n\nZ\n\n\u03c1(q, x) d3 q = \u03c10 (x).\n\n(31)\n\nDin\n\nNote that if we assume any of the two following forms for\nthe joint distribution\n\u03c1(q, x) = \u03c10 (x) \u03b4 q \u2212 q(x)\n\nwhich has to hold under the constraint (25). In other words,\nthe displacement x \u2212 q(x) has to be orthogonal (in the\nL2 functional sense) to all divergence-less vector fields and,\nthus, must be a gradient. Since x is obviously a gradient, it\nfollows that q(x) = \u2207x \u0398(x) for a suitable potential \u0398.\nIt remains to prove the convexity of \u0398. First we prove\nthat the map x 7\u2192 q(x) = \u2207x \u0398(x) is monotone, i.e., by\ndefinition, that for any x1 and x2\n(x2 \u2212 x1 ) * (q(x2 ) \u2212 q(x1 )) > 0.\n\n|q(x1 ) \u2212 x1 |2 + |q(x2 ) \u2212 x2 |2\n\n\u0001\n\n\u0001\n\n\u03c1(q, x) = \u03c1in (q) \u03b4 x \u2212 x(q) ,\n\n(32)\n\nwe find that I \u0303 reduces to the cost I as defined in (22). This\nrelaxed formulation allowed Kantorovich to establish the existence of a mimimizing joint distribution.\nThe relaxed formulation can be used to show that the\nminimizing solution actually defines a map, which need not\nbe smooth if one or both of the terminal distribution have a\nsingular component (in our case, when mass concentrations\nare present). The derivation (Brenier 1987, 1991) makes use\nof the technique of duality (Appendix C2), which will also\nappear in discussing algorithms (Section 4.2) and reconstruction beyond the potential hypothesis (Section 6).\nWe have thus shown that the Monge\u2013Kantorovich optimal mass transportation problem can be applied to solving\nthe Monge\u2013Amp\u00e8re equation. The actual implementation\n10\n\nAs we shall see in Section 4.1, the converse is not true: monotonicity alone does not imply that the integral I is a minimum;\nthe minimizing map must also be potential.\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n\fReconstruction of the early Universe as a convex optimization problem\n\u03c1\n\nx\n\nq2\n\nq1\n\nq\n\n7\n\nq\n\nx\n\n111 v\n000\n000\n111\n000\n111\n000\n111\n000\n111\n00000\n00011111\n111\n00000\n11111\n00000\n11111\nq\n00000\n11111\n00000\n11111\n00000\n11111\nin\n\nx\n\nq1\n\nFigure 2. A one-dimensional example of non-unique reconstruction of the Lagrangian map in the presence of multi-streaming.\nThe density distribution (upper graph) is generated by a multistreaming Lagrangian map (thick line of lower graph) but may\nalso be generated by a spurious single-stream Lagrangian map\n(dashed line).\n\n(Section 4), done for a suitable discretization, will be henceforth called Monge\u2013Amp\u00e8re\u2013Kantorovich (MAK).\n\n3.4\n\nSources of uncertainty in reconstruction\n\nIn this section we discuss various sources of non-uniqueness\nof the MAK reconstruction: multi-streaming, collapsed regions, reconstruction from a finite patch of the Universe.\nWe have stated before that our uniqueness result applies\nonly in so far as we can treat present-epoch high-density\nmulti-stream regions as if they were truly collapsed, ignoring their width. We now give a simple one-dimensional example of non-uniqueness in which a thick region of multistreaming is present. Fig. 2 shows a multi-stream Lagrangian\nmap x(q) and the associated density distribution; the inverse\nmap q(x) is clearly multi-valued. The same density distribution may however be generated by a spurious single-stream\nLagrangian map shown on the same figure. There is no way\nto distinguish between the two inverse Lagrangian maps if\nthe various streams cannot be disentangled.\nSuppose now that the present density has a singular\npart, i.e. there are mass concentrations present which have\nvanishing (Eulerian) volumes but possess finite masses. Obviously any such object originates from a domain in the\nLagrangian space which occupies a finite volume. A onedimensional example is again helpful. Fig. 3 shows a Lagrangian map in which a whole Lagrangian shock interval\n[q1 , q2 ] has collapsed into a single point of the x axis. Outside of this point the Lagrangian map is uniquely invertible\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n2\n\nq\n\nFigure 3. Two initial velocity profiles vin (q) (bottom, solid and\ndashed lines) leading to the same Lagrangian map x = q +\u03c4 vin (q)\n(top, solid line) in the adhesion approximation. The Zel'dovich\napproximation would give multistreaming (top, dashed line).\nHatched areas (bottom) are equal in the adhesion dynamics.\n\nbut the point itself has many antecedents. Note that the\ngraph of the Lagrangian map may be inverted by just interchanging the q and x axes, but its inverse contains a piece\nof vertical line. The position of the Lagrangian shock interval which has collapsed by the present epoch is uniquely\ndefined by the present mass field but the initial velocity fluctuations in this interval cannot be uniquely reconstructed.\nIn particular there is no way to know if collapse has started\nbefore the present epoch. We can of course arbitrarily assume that collapse has just happened at the present epoch;\nif we also suppose that particles have travelled with a constant speed, i.e. use the Zel'dovich/adhesion approximation,\nthen the initial velocity profile within the Lagrangian shock\ninterval will be linear (Fig. 3). Any other smooth velocity\nprofile joining the same end points would have points where\nits slope (velocity gradient) is more negative than that of the\nlinear profile (Fig. 3) and thus would have started collapse\nbefore the present epoch (in one dimension caustics appear\nat the time which is minus the inverse of the most negative\ninitial velocity gradient).\nAll this carries over to more than one dimension. The\nMAK reconstruction gives a unique antecedent for any\nEulerian position outside mass concentrations. Each mass\nconcentration in the Eulerian space, taken globally, has a\nuniquely defined Lagrangian antecedent region but the initial velocity field inside the latter is unknown. In other\nwords, displacement reconstruction is well defined but full\nreconstruction, based on the Zel'dovich/adhesion approximation for velocities, is possible only outside of mass concentrations (note however that velocities in the Eulerian space\n\n\f8\n\nY. Brenier et al.\n\nare still reconstructed at almost all points). We call the corresponding initial Lagrangian domains collapsed regions.\nFinally, we consider a uniqueness problem arising from\nknowing the present mass distribution only truncated over\na finite Eulerian domain D0 , as is necessarily the case when\nworking with a real catalogue. If we also know the corresponding Lagrangian domain Din and both domains are\nbounded and convex, then uniqueness is guaranteed (see Section 3.2). What we know for sure about Din is its volume,\nwhich (in our units) is equal to the total mass contained\nin D0 . Its shape and position may however be constrained\nby further information. For example, if we know that the\ntypical displacement of mass elements since decoupling is\nabout ten Mpc in comoving coordinates (see Section 5) and\nour data extend over a patch of typical size one hundred\nMpc, then there is not more than a ten percent uncertainty\non the shape of Din . Additional information about peculiar\nvelocities may also be used to constrain Din .\nNote also that a finite-size patch D0 with unknown antecedent Din will give rise to a unique reconstruction (up to\na translation) if we assume that it is surrounded by a uniform background extending to infinity. This is a consequence\nof the result of Caffarelli & Li mentioned at the end of Section 3.2. The arbitrary linear term in (21) corresponds to\na translation; as to the quadratic term, it is constrained by\nthe cosmological principle of isotropy to be exactly |q|2 /2.\n4\n\nTHE MAK METHOD: DISCRETIZATION\nAND ALGORITHMICS\n\nIn this section we show how to compute the solution to the\nMonge\u2013Amp\u00e8re\u2013Kantorovich (MAK) problem the known\npresent density field. First the problem is discretized into\nan assignment problem (Section 4.1), then we present some\ngeneral tools which make the assignment problem computationally tractable (Section 4.2) and finally we present, to the\nbest of our knowledge, the most effective method for solving\nour particular assignment problem, based on the auction\nalgorithm of D. Bertsekas (Section 4.3), and details of its\nimplementation for the MAK reconstruction (Section 4.4).\n4.1\n\nPerhaps the most natural way of discretizing a spatial mass\ndistribution is to approximate it by a finite system of identical Dirac point masses, with possibly more than one mass at\na given location. This is compatible both with N -body simulations and with the intrinsically discrete nature of observed\nluminous matter. Assuming that we have N unit masses\nboth in the Lagrangian and the Eulerian space, we may write\nN\nX\ni=1\n\n\u03b4(x \u2212 xi ),\n\n\u03c1in (q) =\n\nN\nX\nj=1\n\n\u03b4(q \u2212 q j ).\n\nN\nX\n|xi \u2212 q j(i) |2\ni=1\n\n2\n\n.\n\n(33)\n\nFor discrete densities of this form, the mass conservation\nconstraint in the optimal mass transportation problem (Section 3.3) requires that the map q(x) induce a one-to-one\npairing between positions of the unit masses in the x and q\nspaces, which may be written as a permutation of indices\nthat sends xi to q j(i) . Substituting this into the quadratic\ncost functional (23), we get\n\n(34)\n\nWe thus reduced the problem to the purely combinatorial\none of finding a permutation j(i) (or its inverse i(j)) that\nminimizes the quadratic cost function (34).\nThis problem is an instance of the general assignment\nproblem in combinatorial optimization: for a cost matrix cij ,\nfind a permutation j(i) that minimizes the cost function\nI=\n\nN\nX\n\nci j(i) .\n\n(35)\n\ni=1\n\nAs we shall see in the next sections, there exist effective\nalgorithms for finding minimizing permutations.\nBefore proceeding with the assignment problem, we\nshould mention an alternative approach in which discretization is performed only in the Eulerian space and the initial mass distribution is kept continuous and uniform. Minimization of the quadratic cost function will then give rise\nto a tesselation of the Lagrangian space into polyhedric regions which end up collapsed into the discrete Eulerian Dirac\nmasses. Basically, the reason why these regions are polyhedra is that the convex potential \u03a6(q) of the Lagrangian\nmap has a gradient which takes only finitely many values.\nThis problem, which has been studied by Aleksandrov and\nPogorelov (see, e.g., Pogorelov 1978), is closely related to\nMinkowski's (1897) famous problem of constructing a convex polyhedron with prescribed areas and orientations of\nits faces (in our setting, areas and orientations correspond\nto masses and values of the gradient). Uniqueness in the\nMinkowski problem is guaranteed up to a translation. Starting with Minkowski's own very elegant solution, various\nmethods of constructing solutions to such geometrical questions have been devised. So far, we have not been able to\nmake use of such ideas in a way truly competitive with discretization in both spaces and solving then the assignment\nproblem.\nThe solution to our assignment problem (with quadratic\ncost) has the important property that it is monotone: for\nany two Lagrangian positions q 1 and q 2 , the corresponding\nEulerian positions x1 and x2 are such that\n(x1 \u2212 x2 ) * (q 1 \u2212 q 2 ) > 0.\n\nReduction to an assignment problem\n\n\u03c10 (x) =\n\nI=\n\n(36)\n\nThis is of course the discrete counterpart of (27). In one dimension, when all the Dirac masses are on the same line,\nmonotonicity implies that the leftmost Lagrangian position\ngoes to the leftmost Eulerian position, the second leftmost\nLagrangian position to the second leftmost Eulerian position, etc. It is easily checked that this correspondence minimizes the cost (34).\nIn more than one dimension, a correspondence between\nLagrangian and Eulerian positions that is just monotone\nwill usually not minimize the cost (a simple two-dimensional\ncounterexample is given in Fig. 4).11 Actually, a much\nstronger condition, called cyclic monotonicity, is needed in\norder to minimize the cost. It requires k-monotonicity for\n\n11\n\nNote that in one dimension, in the continuous case, any map\nis a gradient and we have already observed in Section 3.3 that if a\ngradient map is monotone it is the gradient of a convex function.\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n\f9\n\nReconstruction of the early Universe as a convex optimization problem\na\n\nD\n\nA\n\na\n\nD\n\nA\n\nb\n\nb\n\n(a)\n\nA4\n\nA1\n\nA2\n\nA3\n\nz\nrows\n\n(b)\n\nd\n\nd\nc\n\nC\n\nB\n\nC\n\nc\n\nB\n\nFigure 4. Two monotone assignments sending white points to\nblack ones: (a) an assignment that is vastly non-optimal in terms\nof quadratic cost but cannot be improved by any pair interchange;\n(b) the optimal assignment, shown for comparison.\n\nany k between 2 and N ; the latter is defined by taking any\nk Eulerian positions with their corresponding Lagrangian\nantecedents and requiring that the cost (34) should not decrease under an arbitrary reassignment of the Lagrangian\npositions within the set of Eulerian positions taken. Note\nthat the usual monotonicity corresponds to 2-monotonicity\n(stability with respect to pair exchanges).\nA strategy called PIZA (Path Interchange Zel'dovich\nApproximation) for constructing monotone correspondences\nbetween Lagrangian and Eulerian positions has been proposed by Croft & Gazta\u00f1aga (1997). In PIZA, a randomly\nchosen tentative correspondence between initial and final\npositions is successively improved by swapping randomly\nselected pairs of initial particles whenever (36) is not satisfied. After the cost (34) ceases to decrease between iterations, an approximation to a monotone correspondence is\nestablished, which is generally neither unique, as already\nobserved by Valentine, Saunders & Taylor (2000) in testing\nPIZA reconstruction, nor optimal. We shall come back to\nthis in Sections 5 and 7.3.\n\n4.2\n\nNuts and bolts of solving the assignment\nproblem\n\nFor a general set of N unit masses, the assignment problem with the cost function (34) has a single solution which\ncan obviously be found by examining all N ! permutations.\nHowever, unlike computationally hard problems, such as the\ntravelling salesman's, the assignment problem can be handled in 'polynomial time' \u2013 actually in not more than O(N 3 )\noperations. All methods achieving this use a so-called dual\nformulation of the problem, based on a relaxation similar to\nthat applied by Kantorovich to the optimal mass transportation (Section 3.3; a brief introduction to duality is given in\nAppendix C2). In this section we explain the basics of this\ntechnique, using a variant of a simple mechanical model introduced in a more general setting by H\u00e9non (1995, 2002).\nConsider the general assignment problem of minimizing\nthe cost (35) over all permutations j(i). We replace it by a\n'relaxed,' linear programming problem of minimizing\nI \u0303 =\n\nN\nX\n\ncij fij ,\n\ni,j=1\n\nwhere auxiliary variables fij satisfy\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n(37)\n\nx\n\ny\nB1\nB2\nB3\n\ncolumns\nB4\n\nFigure 5. An analogue computer solving the assignment problem\nfor N = 4.\n\nfij > 0,\n\nN\nX\n\nfkj =\n\nk=1\n\nN\nX\n\nfik = 1\n\n(38)\n\nk=1\n\nfor all i, j, an obvious discrete analogue of (31). We show\nnow that it is possible to build a simple mechanical device\n(Fig. 5) which solves this relaxed problem and that the solution will in fact determine a minimizing permutation in the\noriginal assignment problem (i.e., for any i or j fixed, only\none fij will be unit and all other zero). The device acts as\nan analogue computer : the numbers involved in the problem\nare represented by physical quantities, and the equations are\nreplaced by physical laws.\nDefine coordinate axes x, y, z in space, with the z axis\nvertical. We take two systems of N horizontal rods, parallel\nto the x and y axes respectively, and call them columns and\nrows, referring to columns and rows of the cost matrix. Each\nrod is constrained to move in a corresponding vertical plane\nwhile preserving the horizontal orientation in space. For a\nrow rod Ai , we denote the z coordinate of its bottom face\nby \u03b1i and for a column rod Bj , we denote the z coordinate\nof its top face \u03b2j . Row rods are placed above column rods,\ntherefore \u03b1i > \u03b2j for all i, j (see Fig. 5).\nUpper (row) rods are assumed to have unit weight,\nand lower (column) rods to have negative unit weight, or\nunit 'buoyancy.' Therefore both groups of rods are subject\nto gravitational forces pulling them together. However, this\nmovement is obstructed by N 2 small vertical studs of negligible weight put on column rods just below row rods. A stud\nplaced at projected intersection of column Bj and row Ai\nhas length C \u2212 cij with a suitably large positive constant C\nand thus constrains the quantities \u03b1i and \u03b2j to satisfy the\nstronger inequality\n\u03b1i \u2212 \u03b2j > C \u2212 cij .\n\n(39)\n\nThe potential energy of the system is, up to a constant,\n\n\f10\nU=\n\nY. Brenier et al.\nN\nX\ni=1\n\n\u03b1i \u2212\n\nN\nX\n\n\u03b2j .\n\n(40)\n\nj=1\n\nIn linear programming, the problem of minimizing (40) under the set of constraints given by (39) is called the dual\nproblem to the 'relaxed' one (37)\u2013(38) (see Appendix C2);\nthe \u03b1 and \u03b2 variables are called the dual variables.\nThe analogue computer does in fact solve the dual problem. Indeed, first hold the two groups of rods separated from\neach other and then release them, so that the system starts\nto evolve. Rows will go down, columns will come up, and\ncontacts will be made with the studs. Aggregates of rows\nand columns will be progressively formed and modified as\nnew contacts are made, giving rise to a complex evolution.\nEventually the system reaches an equilibrium, in which its\npotential energy (40) is minimum and all constraints (39)\nare satisfied (H\u00e9non 2002). Moreover, it may be shown that\nthe solution to the original problem (37)\u2013(38) is expressible\nin terms of the forces exerted by the rods on each other\nat equilibrium and is typically a one-to-one correspondence\nbetween the Ai s and the Bj s (for details, see Appendix C3).\nThe common feature of many existing algorithms for\nsolving the assignment problem, which makes them more\neffective computationally than the simple enumeration of\nall N ! permutations, is the use of the intrinsically continuous, geometric formulation in terms of the pair of linear\nprogramming problems (37)\u2013(38) and (40)\u2013(39). The mechanical device provides a concrete model for this formulation; in fact, assignment algorithms can be regarded as descriptions of specific procedures to make the machine reach\nits equilibrium state.12 An introduction into algorithmic aspects of solving the assignment problem, including a proof of\nthe O(N 3 ) theoretical bound on the number of operations,\nbased on the Hungarian method of Kuhn (1955), may be\nfound in Papadimitriou & Steiglitz (1982).\nIn spite of the general O(N 3 ) theoretical bound, various\nalgorithms may show very different performance when applied to a specific optimization problem. During the preparation of the earlier publication (Frisch et al. 2002) the dual\nsimplex method of Balinski (1986) was used, with some modifications inspired by algorithm B of H\u00e9non (2002). Several\nother algorithms were tried subsequently, including an adaptation of algorithm A of the latter reference and the algorithm of Burkard & Derigs (1980), itself based on the earlier\nwork of Tomizawa (1971). For the time being, the fastest\nrunning code by far is based on the auction algorithm of\nBertsekas (1992, 2001), arguably the most effective of existing ones, which is discussed in the next section. Needless\nto say, all these algorithms arrive at the same solution to\nthe assignment problem with given data but can differ by\nseveral orders of magnitude in the time it takes to complete\nthe computation.\n\n4.3\n\nThe auction algorithm\n\nWe explain here the essense of the auction algorithm in\nterms of our mechanical device.13 Note that the original presentation of this algorithm (Bertsekas 1981, 1992, 2001) is\nbased on a different perspective, that of an auction, in which\nthe optimal assignment appears as an economic rather than\na mechanical equilibrium; the interested reader will benefit\nmuch from reading these papers.\nPut initially the column rods at zero height and all row\nrods well above them, so that no contacts are made and constraints (39) are satisfied. To decrease the potential energy,\nlet now the row rods descend while keeping the column rods\nfixed. Eventually all row rods will meet studs placed on column rods and stop. Some column rods may then come in\ncontact with multiple row rods. Such rods are overloaded: if\nthey were not prevented from moving they would descend.\nNote that at this stage any column rod Ai has established a contact with a row rod Bj for which the stud\nlength C \u2212 cij is the maximum and the cost cij the minimum among other Bs; for cij = |xi \u2212q j |2 /2, this means that\nany Eulerian position xi is coupled to its nearest Lagrangian\nneighbour q j . This coupling is a reasonable guess for the optimal assignment; should it happen to be one-to-one, then\nthe equilibrium, and with it the optimal assignment, would\nbe reached. It is usually not, so there are overloaded B rods\nand the following procedure is applied to find a compromise\nbetween minimization of the total cost and the requirement\nof one-to-one correspondence.\nTake any overloaded rod Bj and let it descend while\nkeeping other column rods fixed. As Bj descends, row rods\ntouching it will follow its motion until they meet studs of\nother column rods and stay behind. The downward motion\nof Bj is stopped only when the last row rod touching Bj is\nabout to lose its contact. We then turn to any other overloaded column rod and repeat the procedure as often as\nneeded.\nThis general step can be viewed as an auction in which\nrow rods bid for the descending column rod, offering prices\nequal to decreases in their potential energy as they follow\nits way down. As the column rod descends, thereby increasing its price, the auction is won by the row rod able to\noffer the largest bidding increment, i.e., to decrease its potential energy by the largest amount while not violating the\nconstraints posed by studs of the rest of column rods. For\ncomputational purposes it suffices to compute bidding increments for all competing row rods from the dual \u03b1 and \u03b2\nvariables and assign the descending column rod Bj to the\nhighest bidder Ai , decreasing their heights \u03b2j and \u03b1i correspondingly.\nObserve that, at each step, the total potential energy U\ndefined by (40) decreases by the largest amount that can be\nachieved by moving the descending column rod without violating the constraints.14 Since (40) is obviously nonnegative,\n\n13\n\n12\n\nThis applies to algorithms that never violate constraints (39)\nrepresented by studs; all practical assignment algorithms known\nto us fall within this category.\n\nA movie illustrating the subsequent discussion may be found\nat http://www.obs-nice.fr/etc7/movie.html (requires fast Internet access).\n14 This idea of moving a rod, or adjusting a dual variable, up to\nthe last point compatible with all the constraints, may be actually implemented in a number of ways, giving rise to several possible flavours of the auction algorithm. For example, the above\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n\fReconstruction of the early Universe as a convex optimization problem\n\n11\n\nthe descent cannot proceed indefinitely, and the process may\nbe expected to converge quite fast to a one-to-one pairing\nthat solves the assignment problem.\nHowever, as observed by Bertsekas (1981, 1992, 2001),\nthis 'naive' auction algorithm may end up in an infinite cycle if several row rods bid for a few equally favourable column rods, having thus zero bidding increments. To break\nsuch cycles and also to accelerate convergence, a perturbation mechanism is introduced in the algorithm. Namely, the\nconstraints (39) are replaced by weaker ones\n(41)\n\nfor a small positive quantity \u01eb, and in each auction the descending column rod is pushed down by \u01eb in addition to\ndecreasing its height by the bidding increment. It can be\nshown that this reformulated process terminates in a finite\nnumber or rounds; moreover, if all stud lengths are integer\nand \u01eb is smaller than 1/N , then the algorithm terminates at\nan assignment that is optimal in the unperturbed problem\n(Bertsekas 1992).\nThe third ingredient in the Bertsekas algorithm is the\nidea of \u01eb-scaling. When the values of dual variables are already close to the solution of the dual problem, it usually\ntakes relatively few rounds of auction to converge to a solution. Thus one can start with large \u01eb to compute a rough approximation for dual variables fast, without worrying about\nthe quality of the assignment, and then proceed reducing \u01eb\nin geometric progression until it passes the 1/N threshold,\nassuring that the assignment thus achieved solves the initial\nproblem.\nBertsekas' algorithm is especially fast for sparse assignment problems, in which rods Ai and Bj can be matched\nonly if the pair (i, j) belongs to a given subset A of the set\nof N 2 possible pairs. We call such pairs valid and define the\nfilling factor to be the proportion of valid pairs f = |A|/N 2 .\nWhen this factor is small, computation can be considerably\nfaster: to find the bidding increment for a rod Ai , we need\nonly to run over the list of rods Bj such that (i, j) is a valid\npair.\nNote also that the decentralized structure of the algorithm facilitates its parallelization (see references in\nBertsekas 1992, 2001).\n\n4.4\n\nThe auction algorithm for the MAK\nreconstruction\n\nWe now describe the adaptation of the auction algorithm\nto the MAK reconstruction. Experiments with various\nprograms contained in Bertsekas' publicly available package\n(http://web.mit.edu/dimitrib/www/auction.txt)\nshowed\nthat the most effective for our problem is auction_flp. It\nassumes integer costs cij , which in our case requires proper\nscaling of the cost matrix. To achieve this, the unit of length\nis adjusted so that the size of the reconstruction patch\nequals 100, and then the square of the distance between an\n\nprocedure in its most effective implementation requires a parallel\ncomputer so that groups of several rods can be tracked simultaneously. On sequential computers another, less intuitive procedure,\nin which upper rods are dropped once at a time, proves more\neffective (Bertsekas 1992).\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n1\n\n\u03b1i \u2212 \u03b2j > C \u2212 cij \u2212 \u01eb\n\n10 3\n\nFigure 6. Computing time for different algorithms as a function\nof the number N of points (divided by N 3 for normalization).\nAsterisks, the Burkard & Derigs (1980) algorithm (BD); crosses\nand points, the dense and sparse versions of the auction algorithm\n(described in the text).\n\ninitial and a final position is rounded off to an integer. In\nour application, row and column rods correspond to Eulerian and Lagrangian positions, respectively. As the MAK\nreconstruction is planned for application to catalogues of\n105 and more galaxies, we do not store the cost matrix,\nwhich would require an O(N 2 ) storage space, but rather\ncompute its elements on demand from the coordinates,\nwhich requires only O(N ) space.\nOur problem is naturally adapted for a sparse description if galaxies travel only a short distance compared to the\ndimensions of the reconstruction patch. For instance, in the\nsimulation discussed in Section 5, the r.m.s. distance traveled is only about 10 h\u22121 Mpc, or 5% of the size of the simulation box, and the largest distance traveled is about 15%\nof this size. So we may assume that in the optimal assignment distances between paired positions will be limited. We\ndefine then a critical distance dcrit and specify that a final\nposition xi and an initial position q j form a valid pair only\nif they are within less than dcrit from each other. This critical distance must be adjusted carefully: if it is too small,\nwe risk excluding the optimal assignment; if it is taken too\nlarge, the benefit of the sparse description is lost.\nHowever, the saving in computing time achieved by\nsparse description has to be paid for in storage space: to\nstore the set A of valid pairs, storage of size |A| = f N 2 is\nneeded, which takes us back to the O(N 2 ) storage requirement. We have explored two solutions to this problem.\n1. Use a dense description nevertheless, i.e. the one\nwhere all pairs (i, j) are valid and there is no need to store\n\n\f12\n\nY. Brenier et al.\n\nthe set A. The auction program is easily adapted to this\ncase (in fact this simplifies the code). However, we forfeit\nthe saving in time provided by the sparse structure.\n2. The sparse description can be preserved if the set\nof valid pairs is computed on demand rather than stored.\nThis is easy if initial positions fill a uniform cubic grid, the\nsimplest discrete approximation to the initial quasi-uniform\ndistribution of matter in the reconstruction problem. Thus,\nfor a given final position xi , the valid pairs correspond to\npoints of the cubic lattice that lie inside a sphere of radius\ndcrit centered at xi , so their list can be generated at run\ntime.\nFig. 6 gives the computing time as a function of the\nnumber of points N used in the assignment problem. Shown\nare the dense and sparse versions of the auction algorithm\n(in the latter, the critical distance squared was taken equal\nto 200) and the Burkard & Derigs (1980) algorithm, which\nranked the next fastest in our experiments. The N initial and\nfinal positions are chosen from the file generated by an N body simulation described in Section 5; the choice is random\nexcept for the sparse algorithm, in which the initial positions\nare required to fill a cubic lattice. Hence, the performance\nof the sparse auction algorithm shown in the figure is not\ncompletely comparable to that of the two other algorithms.\nIt is evident that the difference in computing time between the dense auction and the Burkard & Derigs algorithms steadily increases. In the vicinity of N = 105 , the\ndense auction algorithm is about 10 times faster than the\nother one. For the sparse version, the decrease in computing\ntime is spectacular: as could be expected, the ratio of computing times for the two versions of the auction algorithm\nis of the order of f . For large N , the O(N 3 ) asymptotic of\nthe computing time is quite clear for the sparse auction algorithm. For two other algorithms, similar asymptotic was\nfound for larger N in other experiments (not shown).\nIn all three cases shown, the initial positions fill a constant volume while N is varied. This is what we call constantvolume computations. In the sparse case, this results in a\nconstant filling factor, equal to the ratio of the volume of\nthe sphere with radius dcrit to the volume occupied by the\ninitial positions. Here this filling factor is about f = 0.019.\nAnother choice, not shown in the figure, is that of constantdensity computations, when the initial positions are taken\nfrom a volume whose size increases with N . In this case the\ntime dependence of algorithms for large N is of the order\nof N 1.5 .\nWe finally observe that the sparse auction algorithm applied to the MAK reconstruction requires 5 hours of singleprocessor CPU time on a 667 MHz COMPAQ/DEC Alpha\nmachine for 216,000 points.\n\n5\n\nTESTING THE MAK RECONSTRUCTION\n\nIn this section we present results of our testing the MAK\nreconstruction against data of cosmological N -body simulations. In a typical simulation of this kind, the dark matter distribution is approximated by N particles of identical\nmass. Initially the particles are put on a uniform cubic grid\nand given velocities that form a realization of the primordial velocity field whose statistics is prescribed by a certain cosmological model. Trajectories of particles are then\n\nFigure 7. N -body simulation output in the Eulerian space used\nfor testing our reconstruction method (shown is a projection\nonto the x-y plane of a 10% slice of the simulation box of size\n200h\u22121 Mpc). Points are highlighted in yellow when reconstruction fails by more than 6.25 h\u22121 Mpc, which happens mostly in\nhigh-density regions.\n\ncomputed according to the Newtonian dynamics in a comoving frame, using periodic boundary conditions. The reconstruction problem is therefore to recover the pairing between the initial (Lagrangian) positions of the particles and\ntheir present (Eulerian) positions in the N -body simulation,\nknowing only the set of computed Eulerian positions in the\nphysical space.\nWe test our reconstruction against a simulation of\n1283 particles in a box of 200 h\u22121 Mpc size (where h\nis the Hubble parameter in units of 100 km s\u22121 Mpc\u22121 )\nperformed using the adaptive P3 M code HYDRA\n(Couchman, Thomas & Pearce 1995).15 A \u039bCDM cosmological model is used with parameters \u03a9m = 0.3, \u03a9\u039b = 0.7,\nh = 0.65, \u03c38 = 0.9.16 The value of these parameters within\nthe model are determined by fitting the observed cosmic microwave background (CMB) spectrum.17 The output of the\nN -body simulation is illustrated in Fig. 7 by a projection\nonto the x-y plane of a 10% slice of the simulation box.\nSince the simulation assumes periodic boundary conditions, some Eulerian positions situated near boundaries may\nhave their Lagrangian antecedents at the opposite side of the\n\n15\n\nIn a flavour of N -body codes called particle-mesh (PM) codes,\nNewtonian forces acting on particles are interpolated from the\ngravitational field computed on a uniform mesh. In very dense\nregions, precision is increased by adaptively refining the mesh and\nby direct calculation of local particle-particle (PP) interactions;\ncodes of this type are correspondingly called adaptive P3M.\n16 The use of a \u039bCDM model instead of the model without a\ncosmological constant (Appendix A) leads to some modifications\nin basic equations but does not change formulas used for the MAK\nreconstruction.\n17 Data of the first year Wilkinson Microwave Anisotropy Probe\n(Spergel et al. 2003; see also Bridle et al. 2003) suggest a value\n\u03c38 = 0.84 \u00b1 0.04, marginally smaller than the one used here. This\nmay slightly extend the range of scales favourable for the MAK\nreconstruction.\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n\fReconstruction of the early Universe as a convex optimization problem\n\nof the vector q, which ensures a one-to-one correspondence\nbetween q\u0303-values and points on the regular Lagrangian grid.\nThe insets are histograms (by percentage) of distances, in\nreconstruction mesh units, between the reconstructed and\nsimulation Lagrangian positions; the first darker bin, slightly\nless than one mesh in width, corresponds to perfect reconstruction (thereby allowing a good determination of the peculiar velocities of galaxies).\nWith the mesh size \u2206x, Lagrangian positions of 62% of\nthe sample of 17,178 points are reconstructed perfectly and\nabout 75% are placed within not more than one mesh. With\nthe \u2206x/2 grid, we still have 35% of exact reconstruction out\nof 19,187 points, but only 14% for the \u2206x/4 grid with 23,111\npoints.\nWe also performed a reconstruction on a random sample\nof 100,000 Eulerian positions taken with their periodicitycorrected Lagrangian antecedents out of the whole set of\n1283 particles, without any restrictions. This reconstruction,\nwith the effective mesh size (average distance between neighbouring points) of 4.35h\u22121 Mpc, gives 51% of perfect reconstruction (Fig. 11).\nWe compared these results with those of the\nPIZA reconstruction method (see Section 4.1 and\nCroft & Gazta\u00f1aga 1997), which gives a 2-monotone but not\nnecessarily optimal pairing between Lagrangian and Eulerian positions. We applied the PIZA method on the \u2206x grid\nand obtained typically 30\u201340% exactly reconstructed positions, but severe non-uniqueness: for two different seeds of\nthe random generator used to set up the initial tentative assignment, only about half of the exactly reconstructed positions were the same (see figs. 3 and 7 of Mohayaee et al.\n(2003) for an illustration). We also implemented a modification of the PIZA method establishing 3-monotonicity\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n0.8\n\n60\n50\n40\n30\n\n0.7\n\nreconstruction coordinate\n\n20\n10\n0.6\n1\n\n2\n3\n4\ndistances\n\n0.5\n\n0.4\n\n0.3\n\n0.2\n0.2\n\n0.3\n\n0.4\n0.5\n0.6\nsimulation coordinate\n\n0.7\n\n0.8\n\nFigure 8. Test of the MAK reconstruction for a sample of\nN \u2032 = 17, 178 points initially situated on a cubic grid with mesh\n\u2206x = 6.25 h\u22121 Mpc. The scatter diagram plots true versus reconstructed initial positions using a quasi-periodic projection which\nensures one-to-one correspondence with points on the cubic grid.\nThe histogram inset gives the distribution (in percentages) of distances between true and reconstructed initial positions; the horizontal unit is the sample mesh. The width of the first bin is less\nthan unity to ensure that only exactly reconstructed points fall\nin it. Note that more than sixty percent of the points are exactly\nreconstructed.\n\n0.6\n40\n30\n20\n0.5\n10\n\nreconstruction coordinate\n\nsimulation box. Suppressing the resulting spurious large displacements is crucial for successful reconstruction. Indeed,\nfor a typical particle displacement of 1/20 the box size, spurious box-wide leaps of 1% of the particles will generate a\ncontribution to the quadratic cost (34) four times larger than\nthat of the rest. To suppress such leaps, for each Eulerian\nposition that has its antecedent Lagrangian position at the\nother side of the simulation box, we add or subtract the box\nsize from coordinates of the latter (in other words, we are\nconsidering the distance on a torus). In what follows we refer\nto this procedure as the periodicity correction.\nWe first present reconstructions for three samples of\nparticles initially situated on Lagrangian subgrids with\nmeshes given by \u2206x = 6.25 h\u22121 Mpc, \u2206x/2 and \u2206x/4. To\nfurther reduce possible effects of the unphysical periodic\nboundary condition, we truncate the data by discarding\nthose points whose Eulerian positions are not within the\nsphere of radius 16\u2206x placed at the centre of the simulation\nbox (for the largest \u2206x its diameter coincides with the box\nsize). The problem is then confined to finding the pairing between the remaining Eulerian positions and the set of their\nperiodicity-corrected Lagrangian antecedents in the N -body\nsimulation.\nThe results are shown in Figs. 8\u201311. The main plots\nshow the scatter of reconstructed vs. simulation Lagrangian\npositions for the same Eulerian positions. For these diagrams\nwe introduce a 'quasi-periodic projection'\n\u221a\n\u221a\n\u221a\n\u221a\nq\u0303 \u2261 (q1 + 2q2 + 3q3 )/(1 + 2 + 3)\n(42)\n\n13\n\n1 2 3 4 5 6 7\ndistances\n0.4\n\n0.3\n\n0.2\n0.2\n\n0.3\n\n0.4\nsimulation coordinate\n\n0.5\n\n0.6\n\nFigure 9. Same as Fig. 8 but with N \u2032 = 19, 187 and a sample\nmesh of \u2206x/2 = 3.125 h\u22121 Mpc. Exact reconstruction is down to\n35%.\n\n(monotonicity with respect to interchanges of 3 points instead of pairs) and checked that it does not give a significant\nimprovement over the original PIZA.\nIn comoving coordinates, the typical displacement of\na mass element is about 1/20 the box size, that is about\n10 h\u22121 Mpc. This is not much larger than the coarsest grid\nof 6.25 h\u22121 Mpc used in testing MAK which gave 62% of\nexact reconstruction. Nevertheless there are 18 other grid\npoints within 10 h\u22121 Mpc of any given grid point, so that\nthis high percentage cannot be trivially explained by the\n\n\f14\n\nY. Brenier et al.\n20\n\n10\n\nreconstruction coordinate\n\n0.55\n\n1 3 5 4 9 11\ndistances\n0.50\n\n0.45\n\n0.40\n0.40\n\n0.45\n0.50\nsimulation coordinate\n\n0.55\n\nFigure 10. Same as Fig. 8 but with N \u2032 = 23, 111 and a sample\nmesh of \u2206x/4 = 1.56 h\u22121 Mpc. Exact reconstruction is down to\n14%.\n\nMonaco & Efstathiou 1999), we use the Zel'dovich approximation (ZA) to render our MAK quadratric cost\nfunction in the s variable. As follows from (11), in this\napproximation the peculiar velocity is given by\n\n1.0\n0.9\n0.8\n\nv=\n\nreconstruction coordinate\n\n0.7\n0.6\n\ndistances\n0.4\n\n1\n\n2 3 4 5 6\n\n(s \u2212 q) * x\u0302\n\n50\n0.3\n\n2\n\n|s \u2212 q|\n\n40\n30\n\n0.2\n\n10\n0.1\n\n0.2\n\n0.3 0.4 0.5 0.6\nsimulation coordinate\n\n0.7\n\n0.8\n\n0.9\n\n1.0\n\nFigure 11. Same as Fig. 8 with N \u2032 = 105 points selected at\nrandom, neighbouring points being typically 4.35 h\u22121 Mpc apart.\nExact reconstruction is in excess of 50%.\n\nsmallness of the displacement. Note that without the periodicity correction, the percentage of exact reconstruction for\nthe coarsest grid degraded significantly (from 62% to 45%)\nand the resulting cost was far from the true minimum.\nFor real catalogues, reconstruction has to be performed\nfor galaxies whose positions are specified in the redshift\nspace, where they appear to be displaced radially (along the\nline of sight) by an amount proportional to the radial component of the peculiar velocity. Thus, at the present epoch,\nthe redshift position s of a mass element situated at the\npoint x in the physical space is given by\ns = x + x\u0302\u03b2 (v * x\u0302) ,\n\n(44)\n\n=\n=\n\n(1 + \u03b2)(x \u2212 q) * x\u0302,\n2\n\n\u00012\n\n|x \u2212 q| + \u03b2(\u03b2 + 2) (x \u2212 q) * x\u0302 .\n\n(45)\n(46)\n\nCombining now these two equations and using the fact that,\nby (43), the vectors x and s are collinear and therefore x\u0302 =\n\u00b1\u015d, we may write the quadratic cost function as\n\n20\n0.1\n\n1\n(x \u2212 q).\n\u03c4\n\nAt the present time, since \u03c40 = 1, this together with (43)\ngives\n\n0.5\n\n0.0\n0.0\n\nFigure 12. Test of the redshift-space variant of the MAK reconstruction based on the same data as Fig. 8. The circular redshift\nmap (violet points) corresponds to the same physical-space slice\nas displayed in Fig. 7 (the observer is taken at the center of the\nsimulation box). Points are highlighted in red when reconstruction fails by more than one mesh.\n\n(43)\n\nwhere v is the peculiar velocity in the comoving coordinates x and the linear growth factor time \u03c4 , x\u0302 denotes the\nunit normal in the direction of x, and the parameter \u03b2 equals\n0.486 in our \u039bCDM model.\nFollowing\nValentine et al.\n(2000;\nsee\nalso\n\n\u00012\n1\n1\n\u03b2(\u03b2 + 2)\n(s \u2212 q) * \u015d .\n|x \u2212 q|2 = |s \u2212 q|2 \u2212\n2\n2\n2(\u03b2 + 1)2\n\n(47)\n\nThe redshift-space reconstruction is then in principle reduced to the physical-space reconstruction. Note however\nthat the redshift transformation of Eulerian positions may\nfail to be one-to-one if the peculiar component of velocity\nfield in the proper space coordinates exceeds the Hubble expansion component. This undermines the simple reduction\noutlined above for catalogues confined to small distances.\nWe have performed a MAK reconstruction with the\nredshift-modified cost function (47). The redshift positions\nwere computed for the simulation data with peculiar velocities smoothed over a sphere with radius of 1/100 the box\nsize (2 h\u22121 Mpc). This reconstruction led to 43% of exactly\nreconstructed positions and 60% which are within not more\nthan one \u2206x mesh from their correct positions (see Fig. 12;\na scatter diagram is omitted because it is quite similar to\nthat in Fig. 8). A comparison of the redshift-space MAK\nreconstruction with the physical-space MAK reconstruction\nshows that almost 50% of exactly reconstructed positions\ncorrespond to the same points. This test shows that the\nMAK method is robust with respect to systematic errors\nintroduced by the redshift transformation.\nOur results demonstrate the essentially potential charc 0000 RAS, MNRAS 000, 000\u2013000\n\n\fReconstruction of the early Universe as a convex optimization problem\nacter of the Lagrangian map above \u223c 6 h\u22121 Mpc (within the\n\u039bCDM model) and perhaps at somewhat smaller scales.\nAlthough it is not our intention in this paper to actually\nimplement the MAK reconstruction on real catalogues, a few\nremarks are in order. The effect of the catalogue selection\nfunction can be handled by standard techniques; for instance\none can assign each galaxy a 'mass' inversely proportional\nto the catalog selection function (Nusser & Branchini 2000;\nValentine et al. 2000; Branchini et al. 2002). Biasing can be\ntaken into account in a similar manner (Nusser & Branchini\n2000). Both these modifications and the natural scatter of\nmasses in the observational catalogues require that massive objects be represented by clusters of multiple Eulerian points of unit mass (with the correspondingly increased\nnumber of points on a finer grid in the Lagrangian space),\nwhich reduces the problem to a variant of the usual assignment. We also observe that real catalogues involve truncation, that is data available only over a finite region. As\nalready discussed in Section 3.4, this is not a serious problem provided a sufficiently large patch is available. Actually, as noted earlier in this Section, the data used in testing\nhave been truncated spherically, without significantly affecting the quality of the reconstruction.\nIn the redshift-space modification, more accurate determination of peculiar velocities can be done using secondorder Lagrangian perturbation theory. Note also that, for\nthe observational catalogues, the motion of the local group\nitself should also be accounted for (Taylor & Valentine\n1999).\n\n6\n\nRECONSTRUCTION OF THE FULL\nSELF-GRAVITATING DYNAMICS\n\nThe MAK reconstruction discussed in Sections 3 and 4 was\nperformed under the assumption of a potential Lagrangian\nmap and of the absence of multi-streaming. The tests done\nin Section 5 indicate that potentiality works well at scales\nabove 6 h\u22121 Mpc, whereas multi-streaming is mostly believed to be unimportant above a few megaparsecs. There\ncould thus remain a substantial range of scales over which\nthe quality of the reconstruction can be improved by relaxing the potentiality assumption and using the full selfgravitating dynamics. Here we show that, as long as the dynamics can be described by a solution to the Euler\u2013Poisson\nequations, the prescription of the present density field still\ndetermines a unique solution to the full reconstruction problem. We give only the main ideas, technical details being\nleft for Appendix D (a mathematically rigorous proof may\nbe found in Loeper (2003)). In order to make the exposition\nself-contained, we also give in Appendix C an elementary introduction to convexity and duality which are used for the\nderivation (and also elsewhere in this paper).\nWe shall start from an Eulerian variational formulation\nof the Euler\u2013Poisson equations in an Einstein\u2013de Sitter universe, which is an adaptation of a variational principle given\nby Giavalisco et al. (1993). We minimize the action\n1\nI=\n2\n\nZ\n\n0\n\n\u03c40\n\nd\u03c4\n\nZ\n\n\u0010\n\nd3 x \u03c4 3/2 \u03c1|v|2 +\n\n\u0011\n\n3\n|\u2207x \u03c6g |2 ,\n2\n\nconditions that the density field be unity at \u03c4 = 0 and prescribed at the present time \u03c4 = \u03c40 . The constraints can\nbe handled by the standard method of Lagrange multipliers (here functions of space and time), which allows to vary\nindependently the fields \u03c1, \u03c6g and v. The vanishing of the\nvariation in v gives v = \u03c4 \u22123/2 \u2207x \u03b8, where \u03b8(x, \u03c4 ) is the\nLagrange multiplier for the mass conservation constraint.\nHence, the velocity is curl-free. The vanishing of the variation in \u03c1 gives then\n\u2202\u03c4 \u03b8 +\n\n1\n3\n\u03c8 = 0.\n|\u2207x \u03b8|2 +\n2\u03c4\n2\u03c4 3/2\n\n(49)\n\nBy taking the gradient, this equation goes over into the momentum equation (1), repeated here for convenience:\n\u2202\u03c4 v + (v * \u2207x )v = \u2212\n\n3\n(v + \u2207x \u03c6g ).\n2\u03c4\n\n(50)\n\nIt is noteworthy that, if in the action we replace 3/2\nboth in the exponent of \u03c4 and in the gravitational energy\nterm by 3\u03b1/2, we obtain (50) but also with a 3\u03b1/(2\u03c4 ) factor\nin the right-hand side. The Zel'dovich approximation and\nthe associated MAK reconstruction amount clearly to setting \u03b1 = 0, so as to recover the 'free-streaming action'\n1\nI=\n2\n\nZ\n\n0\n\n\u03c40\n\nd\u03c4\n\nZ\n\nd3 x \u03c1|v|2 ,\n\n(51)\n\nwhose minimization is easily shown to be equivalent to that\nof the quadratic cost function (23).\nAssuming the action (48) to be finite, existence of a minimum is mostly a consequence of the action being manifestedly non-negative. Here it is interesting to observe that the\nLagrangian, which is the difference between the kinetic energy and the potential energy, is positive whereas the Hamiltonian which is their sum does not have a definite sign. As\na consequence, our two-point boundary problem is, as we\nshall see, well posed but the initial-value problem for the\nEuler\u2013Poisson system is not well posed since formation of\ncaustics after a finite time cannot be ruled out.18\nDoes the variational formulation imply uniqueness of\nthe solution? This would be the case if the action were a\nstrictly convex functional (see Appendix C1), which is guaranteed to have one and only one minimum. The action as\nwritten in (48) is not convex in the \u03c1 and v variables, but\ncan be rendered so by introducing the mass flux J = \u03c1 v;\nthe kinetic energy term becomes then |J |2 /(2\u03c1), which is\nconvex in the J and \u03c1 variables.\nStrict convexity is particularly cumbersome to establish, but there is an alternative way, known as duality: by\na Legendre-like transformation the variational problem is\ncarried into a dual problem written in terms of dual variables; the minimum value for the original problem is the\nmaximum for the dual problem. It turns out that the difference of these equal values can be rewritten as a sum of\nnon-negative terms, each of which must thus vanish. This is\nthen used to prove (i) that the difference between any two\nsolutions to the variational problem vanishes and (ii) that\nany curl-free solution to the Euler\u2013Poisson equations with\nthe prescribed boundary conditions for the density also min-\n\n(48)\n\nunder the following four constraints: the Poisson equation\n(3), the mass conservation equation (2) and the boundary\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n15\n\n18 If we had considered electrostatic repulsive interactions the\nconclusions would be reversed.\n\n\f16\n\nY. Brenier et al.\n\nimizes the action. All this together establishes uniqueness.\nFor details see Appendix D.\nSeveral of the issues raised in connection with the\nMAK reconstruction appear in almost the same form for the\nEuler\u2013Poisson reconstruction. First, we are faced again with\nthe problem that, when reconstructing from a finite patch of\nthe present universe, we need either to know the shape of the\ninitial domain or to make some hypothesis as to the present\ndistribution of matter outside this patch. Second, just as for\nthe MAK reconstruction, the proof of uniqueness still holds\nwhen the present density \u03c10 (x) has a singular part, that is,\nwhen some matter is concentrated. Again, we shall have full\ninformation on the initial shape of collapsed regions but not\non the initial fluctuations inside them. The particular solution obtained from the variational formulation is the only\nsolution which stays smooth for all times prior to \u03c40 .\nWe also note that, at this moment and probably for\nquite some time, 3D catalogues sufficiently dense to allow\nreconstruction will be limited to fairly small redshifts. Eventually, it will however become of interest to perform reconstruction 'along our past light-cone' with data not all at\n\u03c40 . The variational approach can in principle be adapted to\nhandle such reconstruction.\nIn previous sections we have seen how to implement reconstruction using MAK, which is equivalent to using the\nsimplified action (51). Implementation using the full Euler\u2013\nPoisson action (48) is mostly beyond the scope of this paper,\nbut we shall indicate some possible directions. In principle\nit should be possible to adapt to the Euler\u2013Poisson reconstruction the method of the augmented Lagrangian which\nhas been applied to the two-dimensional Monge\u2013Amp\u00e8re\nequation (Benamou & Brenier 2000). An alternative strategy, which allows reduction to MAK-type problems, uses the\nidea of 'kicked burgulence' (Bec, Frisch & Khanin 2000) in\nwhich, in order to solve the one or multi-dimensional Burgers equation\n\nties for a small number of Local Group galaxies, situated\nwithin a few Mpc. The focus of reconstruction work has\nnow moved to tackling the rapidly growing large 3D surveys (see, e.g. Frieman & Szalay 2000). It is not our intention here to review all the work on reconstruction;19 rather\nwe shall discuss how some of the previously used methods can be reinterpreted in the light of the optimization\napproach to reconstruction. For convenience we shall divide methods into perturbative (Section 7.1), probabilistic\n(Section 7.2), and variational (Section 7.3). Methods such\nas POTENT (Dekel et al. 1990), whose purpose is to obtain the full peculiar velocity field from its radial components using the (Eulerian) curl-free property, are not directly\nwithin our scope. Note that in its original Lagrangian form\n(Bertschinger & Dekel 1989; Dekel et al. 1990) POTENT\nwas assuming a curl-free velocity in Lagrangian coordinates,\nan assumption closely related to the potential assumption\nmade for MAK, as already pointed out in Section 3.1. Even\ncloser is the relation between MAK and the PIZA method of\nCroft & Gazta\u00f1aga (1997), discussed in Section 7.3, which\nis also based on minimization of quadratic action.\n7.1\n\nPerturbative methods\n\none approximates the force by a sum of delta-functions in\ntime:\n\nNusser & Dekel (1992) have proposed using the Zel'dovich\napproximation backwards in time to obtain the initial velocity fluctuations and thus (by slaving) the density fluctuations. Schematically, their procedure involves two steps:\n(i) obtaining the present potential velocity field and (ii) integrating the Zel'dovich\u2013Bernouilli equation back in time.\nUsing the equality (in our notation) of the velocity and gravitational potentials, they point out that the velocity potential can be computed from the present density fluctuation\nfield by solving the Poisson equation. This is a perturbative approximation to reconstruction in so far as it replaces\nthe Monge\u2013Amp\u00e8re equation (19) by a linearized form. Indeed, when using the Zel'dovich approximation we have\nq = x \u2212 \u03c4 v = x + \u03c4 \u2207x \u03c6v (x). We know that q = \u2207x \u0398(x)\nwith \u0398 satisfying the Monge\u2013Amp\u00e8re equation. The latter\ncan thus be rewritten as\n\nf (x, \u03c4 ) \u2248\n\ndet \u03b4ij + \u03c4 \u2207xi \u2207xj \u03c6v (x) = \u03c1(x),\n\n\u2202\u03c4 v + (v * \u2207x )v = f (x, \u03c4 ),\n\nX\ni\n\nv = \u2212\u2207x \u03c6v ,\n\n\u03b4(\u03c4 \u2212 \u03c4i )g i (x).\n\n(52)\n\n(53)\n\nIn the present case, the g i (x) are proportional to the righthand side of (50) evaluated at the kicking times \u03c4i . The action becomes then a sum of free-streaming Zel'dovich-type\nactions plus discrete gravitational contributions stemming\nfrom the kicking times. Between kicks one can use our MAK\nsolution. At kicking times the velocity undergoes a discontinuous change which is related to the gravitational potential (and thus to the density) at those times. The densities\nat kicking times can be determined by an iterative procedure. The kicking strategy also allows to do redshift-space\nreconstruction by applying the redshift-space modified cost\n(Section 5) at the last kick.\n\n7\n\nCOMPARISON WITH OTHER\nRECONSTRUCTION METHODS\n\nReconstruction started with Peebles' (1989) work, in which\nhe compared reconstructed and measured peculiar veloci-\n\n\u0001\n\n(54)\n\nwhere \u03b4ij denotes the identityP\nmatrix. If we now use the\nrelation det(\u03b4ij + \u01ebAij ) = 1 + \u01eb i Aii + O(\u01eb2 ) and truncate\nthe expansion at order \u01eb, we obtain the Poisson equation\n\u03c4 \u22072x \u03c6v (x) = \u03c1(x) \u2212 1 = \u03b4(x).\n\n(55)\n\nOf course, in one dimension no approximation is needed.\nFrom a physical point of view, equating the velocity and\ngravitational potentials at the present epoch amounts to using the Zel'dovich approximation in reverse and is actually\ninconsistent with the forward Zel'dovich approximation: the\nslaving which makes the two potentials equal initially does\nnot hold in this approximation at later epochs. Replacing\nthe Monge\u2013Amp\u00e8re equation by the Poisson equation is not\nconsistent with a uniform initial distribution of matter and\nwill in general lead to spurious multi-streaming in the initial distribution. Of course, if the present-epoch velocity field\n19\n\nFor a comparison of\nNarayanan & Croft (1999).\n\nsix\n\ndifferent\n\ntechniques,\n\nsee\n\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n\fReconstruction of the early Universe as a convex optimization problem\nhappens to be known one can try applying the Zel'dovich\napproximation in reverse. Nusser and Dekel observe that calculating the inverse Lagrangian map by q = x \u2212\u03c4 v does not\nwork well (spurious multi-streaming appears) and instead\nintegrate back in time the Zel'dovich\u2013Bernouilli equation20\n\u2202t \u03c6v =\n\n1\n(\u2207x \u03c6v )2 ,\n2\n\n(56)\n\nwhich is obviously equivalent to the Burgers equation (13)\nwith the viscosity \u03bd = 0. One way of performing this reverse integration, which guarantees the absence of multistreaming, is to use the Legendre transformation (18) to\ncalculate \u03a6(q) from \u0398(x) = |x|2 /2 \u2212 \u03c4 \u03c6v (x) and then obtain the reconstructed initial velocity field as\nv in (q) = v 0 (\u2207q \u03a6(q)) .\n\n(57)\n\nThis procedure can however lead to spurious shocks in the\nreconstructed initial conditions, due to inaccuracies in the\npresent-epoch velocity data, unless the data are suitably\nsmoothed. Finally, the improved reconstruction method of\nGramann (1993) can be viewed as an approximation to\nthe Monge\u2013Amp\u00e8re equation beyond the Poisson equation\nwhich captures part of the nonlinearity.\n7.2\n\n17\n\nfollowing properties: (i) p1 and p2 are the marginals, i.e.\nwhen p12 is integrated over m2 (respectively, m1 ) one recovers p1 (respectively, p2 ), (ii) the correlation hm1 m2 i is\nmaximum? Since hm21 i and hm22 i are obviously prescribed\nby the constraint that we know p1 and p2 , maximizing the\ncorrelation is the same as minimizing the quadratic distance\nh(m1 \u2212m2 )2 i. This is precisely an instance of the mass transportation problem with quadratic cost, as we defined it in\nSection 3.3. As we know, the optimal solution is obtained\nby a map from the space of m1 values to that of m2 values which is the gradient of a convex function. If m1 and\nm2 are scalar variables, the map is just monotone, as in the\nGaussianization method (in the discrete setting this was already observed in Section 4.1). Hence Weinberg's method\nmay be viewed as requiring maximum correlation (or minimum quadratic distance in the above sense) between initial\nand present distributions of density fluctuations.\nIn principle the Gaussianization method can be extended to multipoint distributions, leading to a difficult multidimensional mass transportation problem which can be\ndiscretized into an assignment problem just as in Section 4.1.\nThe contact of the maximum correlation assumption to the\ntrue dynamics is probably too flimsy to justify using such\nheavy machinery.\n\nProbabilistic methods\n\nWeinberg (1992) presents an original approach to reconstruction, which turns out to have hidden connections to\noptimal mass transportation. The key observations in his\n'Gaussianization' technique are the following: (i) the initial\ndensity fluctuations are assumed to be Gaussian, (ii) the\nrank order of density values is hardly changed between initial\nand present states, (iii) the bulk displacement of large-scale\nfeatures during dynamical evolution can be neglected. Assumption (i) is part of the standard cosmological paradigm.\nAssumption (iii) can of course be tested in N -body simulations. As we have seen in Section 5, a displacement of\n10 h\u22121 Mpc is typical and can indeed be considered small\ncompared to the size of the simulation boxes (64 h\u22121 Mpc in\nWeinberg's simulations and 200 h\u22121 Mpc in ours). Assumption (ii) means that the correspondence between initial and\npresent values of the density \u03c1 (or of the contrast \u03b4 = \u03c1 \u2212 1)\nis monotone. This map, which can be determined from the\nempirical present data, can then be applied to all the data to\nproduce a reconstructed initial density field. Finally, by running an N -body simulation initialized on the reconstructed\nfield one can test the validity of the procedure, which turns\nout to be quite good and can be improved further by hybrid methods (Narayanan & Weinberg 1998; Kolatt et al.\n1996) combining Gaussianization with the perturbative approaches of Nusser & Dekel (1992) or Gramann (1993).\nThis technique is actually connected with mass transportation: starting with the work of Fr\u00e9chet (1957a; 1957b;\nsee also Rachev 1984), probabilists have been asking the\nfollowing question: given two random variables m1 and m2\nwith two laws, say PDFs p1 and p2 , can one find a joint\ndistribution of (m1 , m2 ) with PDF p12 (m1 , m2 ) having the\n20\n\nIn the non-cosmological literature this equation is usually\ncalled Hamilton\u2013Jacobi in the context of analytical mechanics\n(Landau & Lifshitz 1960) and Kardar\u2013Parisi\u2013Zhang (1986) in\ncondensed matter physics.\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n7.3\n\nVariational methods\n\nAll variational approaches to reconstruction, starting with\nthat of Peebles (1989), have common features: one uses a\nsuitable Lagrangian and poses a two-point variational problem with boundary conditions prescribed at the present\nepoch by the observed density field, and at early times by\nrequiring a quasi-uniform distribution of matter (more precisely, as we have seen in Section 2.1, by requiring that the\nsolutions not be singular as \u03c4 \u2192 0).\nThe Path Interchange Zel'dovich Approximation\n(PIZA) method of Croft & Gazta\u00f1aga (1997) and our MAK\nreconstruction techniques use a free-streaming Lagrangian\nin linear growth rate time. As we have seen in Section 3.1, this amounts to assuming adhesion dynamics.\nOnce discretized for numerical purposes, the variational\nproblem becomes an instance of the assignment problem.\nCroft & Gazta\u00f1aga (1997) have proposed a restricted procedure for solving it, which does not account for the Lagrangian potentiality and yields non-unique approximate\nsolutions. As we have seen in Sections 4 and 5, the exact\nand unique solution can be found with reasonable CPU resources.\nTurning now to the Peebles least action method, let\nus first describe it schematically, using our notation. In its\noriginal formulation it is applied to a discrete set of galaxies\n(assumed of course to trace mass) in an Einstein\u2013de Sitter\nuniverse. The action, in our notation, can be written as\nI\n\n=\n\nZ\n\n0\n\n\u03c40\n\nd\u03c4\n\n3\n2\u03c4 1/2\n\nX mi \u03c4 2 dxi\ni\n\n3\n\n2\n\nd\u03c4\n\nX\n3G X mi mj\n+\nmi |xi |2\n+ \u03c0G \u0304\n\u033a0\n2\n|xi \u2212 xj |\ni6=j\n\ni\n\n!\n\n,\n\n(58)\n\nwhere mi is the mass and xi the comoving coordinate of ith\ngalaxy (see also Nusser & Branchini 2000). This is supple-\n\n\f18\n\nY. Brenier et al.\n\nFigure 13. A schematic demonstration of Peebles' reconstruction of the trajectories of the members of the local neighbourhood\nusing a variational approach based on the minimization of Euler\u2013\nLagrange action. The arrows go back in time, starting from the\npresent and pointing towards the initial positions of the sources.\nIn most cases there is more than one allowed trajectory due to\norbit crossing (closely related to the multi-streaming of the underlying dark matter fluid). The pink (darker) orbits correspond to\ntaking the minimum of the action whereas the yellow (brighter)\norbits were obtained by taking the saddle-point solution. Of particular interest is the orbit of N6822 which in the former solution\nis on its first approach towards us and in the second solution is in\nits passing orbit. A better agreement between the evaluated and\nobserved velocities was shown to correspond to the saddle-point\nsolution.\n\nmented by the boundary condition that the present positions\nof the galaxies are known and that the early-time velocities\nsatisfy21\n\u03c4 3/2\n\ndxi\n\u21920\nd\u03c4\n\nfor \u03c4 \u2192 0.\n\n(59)\n\nThis particle approach was extended by Giavalisco et al.\n(1993) to a continuous distribution in Eulerian coordinates\nand leads then to the action analogous to (48) which we have\nused in Section 6. The procedure also involves a 'Galerkin\ntruncation' of the particle trajectories to finite sums of trial\nfunctions of the form\nN\u22121\n\nx\u03bci (\u03c4 )\n\n=\n\nx\u03bci (\u03c40 ) +\n\nX\n\n\u03bc\nCi,n\nfn (\u03c4 ),\n\n(60)\n\nn = 0, 1, . . . , N \u2212 1.\n\n(61)\n\nn=0\n\nfn (\u03c4 )\n\n=\n\n\u03c4 n (\u03c40 \u2212 \u03c4 ),\n\nThe reconstructed peculiar velocities for the Local Group\nwere used by Peebles to calibrate the Hubble and density parameters, which turned out to differ from the previously assumed values. However the peculiar velocity of one\ndwarf galaxy, N6822, failed to match the observed value (see\nFig. 13). This led Peebles (1990) to partially relax the assumption of minimum action, allowing also for saddle points\n\n21\n\nThis condition, which is written a2 dxi /dt \u2192 0 in Peebles'\nnotation, ensures the vanishing of the corresponding boundary\nterm after an integration by parts in the time variable.\n\nin the action. Somewhat better agreement with observations\nis then obtained, but at the expense of lack of uniqueness.\nIn the context of the present approach, various remarks\ncan be made. The boundary condition (59) is trivially satisfied if the velocities dx/d\u03c4 remain bounded. Actually, we\nhave seen in Section 2.1 that, as a consequence of slaving,\nthe velocity has a regular expansion in powers of \u03c4 , which\nimplies its boundedness as \u03c4 \u2192 0. The important point is\nthat the function fn (\u03c4 ) appearing in (60) should be expandable in powers of \u03c4 , as is the case with the ansatz (61).\nIn Section 6 we have established uniqueness of the reconstruction with a prescribed present density and under the\nassumption of absence of multi-streaming (but we allow for\nmass concentrations). This restriction is meaningful only in\nthe continuous case: in the discrete case, unless the particles\nare rather closely packed, the concept of multi-streaming is\nnot clear but there have been attempts to relate uniqueness\nto absence of 'orbit crossing' (see, e.g., Giavalisco et al. 1993;\nWhiting 2000). Of course, at the level of the underlying dark\nmatter, multi-streaming is certainly not ruled out at sufficiently small scales; at such scales unique reconstruction is\nnot possible.\nIn the truly discrete case, e.g. when considering a dwarf\ngalaxy, there is no reason to prefer the true minimum action\nsolution over any other stationary action solution.\n\n8\n\nCONCLUSION\n\nThe main theoretical result of this paper is that reconstruction of the past dynamical history of the Universe, knowing only the present spatial distribution of mass, is a wellposed problem with a unique solution. More precisely, reconstruction is uniquely defined down to those scales, a\nfew megaparsecs, where multi-streaming becomes important. The presence of concentrated mass in the form of\nclusters, filaments, etc is not an obstacle to a unique displacement reconstruction; the mass within each such structure originates from a collapsed region of known shape but\nwith unknown initial density and velocity fluctuations inside. There are of course practical limitations to reconstruction stemming from the knowledge of the present mass distribution over only a limited patch of the Universe; these\nwere discussed in Section 3.4.\nIn this paper we have also presented in detail and tested\na reconstruction method called MAK which reduces reconstruction to an assignment problem with quadratic cost, for\nwhich effective algorithms are available. MAK, which is exact for dynamics governed by the adhesion model, works\nvery well above 6 h\u22121 Mpc and can in principle be adapted\nto full Euler\u2013Poisson reconstruction.\nWe note that a very common method for testing ideas\nabout the early Universe is to take some model of early density fluctuations and then run an N -body simulations with\nassumed cosmological parameters until the present epoch.\nConfrontation with the observed statistical properties of the\npresent Universe helps then in selecting plausible models and\nin narrowing the choice of cosmological parameters. This forward method is conceptually very different from reconstruction; the latter not only works backward but, more importantly, it is a deterministic method which gives us a detailed\nmap of the early Universe and how it relates to the present\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n\f19\n\nReconstruction of the early Universe as a convex optimization problem\none. Reconstruction thus allows us to obtain the peculiar\nvelocities of galaxies and is probably the only method which\ncan hope to do this for a large number of galaxies. In those\ninstances were we have partial information on peculiar velocities (from independent distance measurements), e.g. for the\nNearBy Galaxies (NBG) catalogue of Tully (1988), such information can be used to calibrate cosmological parameters\nor to provide additional constraints, which are in principle\nredundant but can improve the quality.\nThe detailed reconstruction of early density fluctuations, which will become possible using large 3D surveys\nsuch as 2dF and SDSS (see, e.g., Frieman & Szalay 2000),\nwill allow us to test such assumptions as the Gaussianity of\ndensity fluctuations at decoupling. Note however that such\nreconstruction gives us full access only to the complement of\ncollapsed regions; any statistical information thus obtained\nwill be biased, roughly by overemphasizing underdense regions.\nFinally we have no reason to hide the pleasure we experience in seeing this heavenly problem bring together and\nindeed depend crucially on so many different areas of mathematics and physics, from fluid dynamics to Monge\u2013Amp\u00e8re\nequations, mass transportation, convex geometry and combinatorial optimization. Probably this is the first time that\none tackles the three-dimensional Monge\u2013Amp\u00e8re equation\nnumerically for practical purposes. As usual, we can expect that the techniques, here applied to cosmic reconstruction, will find many applications, for example to the optimal\nmatching of two holographic or tomographic images or to the\ncorrection of images in multi-dimensional colour space.\n\nACKNOWLEDGMENTS\nSpecial thanks are due to E. Branchini (observational and\nconceptual aspects) and to D. Bertsekas (algorithmic aspects). We also thank J. S. Bagla, J. Bec, E. Bertschinger,\nT. Buchert, A. Dom\u0131\u0301nguez, H. Frisch, J. Gaite, C. l'Hostis,\nL. Moscardini, A. Noullez, M. Rees, V. Sahni, S. Shandarin, A. Shnirelman, E. Slezak, E. Spiegel, A. Starobinsky,\nP. Thomas and B. Villone for comments and useful information.\nThis work was supported by the European Union under contract HPRN-CT-2000-00162, by the BQR program\nof Observatoire de la C\u00f4te d'Azur, by the TMR program of\nthe European Union (UF), by MIUR (SM), by the French\nMinistry of Education, the McDonnel Foundation, and the\nRussian Foundation for Basic Research under grant RFBR\n02-01-1062 (AS). RM was supported by a Marie Curie Fellowship HPMF-CT-2002-01532.\n\nAPPENDIX A: EQUATIONS OF MOTION IN\nAN EXPANDING UNIVERSE\nOn distances covered by present and forthcoming redshift galaxy catalogues, the Newtonian description constitutes a realistic approximation to the dynamics of selfgravitating cold dark matter filling the Universe (Peebles\n1980; Coles & Lucchin 2002). This description gives, in\nproper space coordinates denoted here by r and cosmic\ntime t, the familiar Euler\u2013Poisson system for the density \u033a(r, t), velocity U (r, t) and the gravitational potential \u03c6(r, t):\n\u2202t U + (U * \u2207r )U\n\n=\n\n\u22072r \u03c6g\n\n=\n\n\u2202t \u033a + \u2207r * (\u033aU )\n\n=\n\n\u2212\u2207r \u03c6g ,\n\n(A.1)\n\n0,\n\n(A.2)\n\n4\u03c0G\u033a,\n\n(A.3)\n\nwhere G is the gravitation constant.\nIn a homogeneous isotropic universe, the density and\nvelocity fields take the form\n\u033a(r, t) = \u033a \u0304(t),\n\nU (r, t) = H(t)r =\n\n\u0227(t)\nr.\na(t)\n\n(A.4)\n\nHere the coefficient H(t) is the Hubble parameter, and a(t) is\nthe expansion scale factor defined so that integration of the\nvelocity field \u1e59 = U (r, t) = H(t)r yields r = a(t)x, where\nx is called the comoving coordinate.\nThe background density \u033a \u0304(t) gives rise to the background gravitational potential \u03c6\u0304g , which by (A.1) and (A.4)\nsatisfies\n\u00e4\n\u2212 \u2207r \u03c6\u0304g = r.\n(A.5)\na\nFor the background density, mass conservation (A.2) gives\nthen\n\u033a \u0304a3 = \u033a \u03040 ,\n\n(A.6)\n\nwhere \u033a \u03040 = \u033a \u0304(t0 ) with t0 the present epoch and a(t0 ) is\nnormalized to unity. Eqs. (A.5), (A.6), and (A.3) imply the\nFriedmann equation for a(t):\n1\n4\n\u033a0 2\n\u00e4 = \u2212 \u03c0G \u0304\n3\na\nwith conditions posed at t = t0 :\na(t0 ) = 1,\n\n\u0227(t0 ) = H0 > 0,\n\n(A.7)\n\n(A.8)\n\nwhere H0 is the present value of the Hubble parameter, positive for an expanding universe.\nFor simplicity we restrict ourselves to the case of the\ncritical density, corresponding to the flat, matter-dominated\nEinstein-de Sitter universe (without a cosmological constant):\n3H02\n(A.9)\n8\u03c0G\nand adjust the origin of the time axis such that the solution\ntakes the form of a power law\n\n\u033a \u03040 =\n\na(t) =\n\n\u0010 \u00112/3\nt\nt0\n\n(A.10)\n\nwith H0 = 2/(3t0 ) and \u033a \u03040 = 1/(6\u03c0Gt20 ).\nThe observed Hubble expansion of the Universe suggests that the density, velocity and gravitational fields may\nbe decomposed into a sum of terms describing the uniform\nexpansion and fluctuations against the background:\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n\f20\n\nY. Brenier et al.\n\n\u033a = \u033a \u0304(t) \u03c1,\n\nU =\n\n\u0227(t)\nr + a(t)u,\na(t)\n\n\u03c6g = \u03c6\u0304g + \u03c6\neg .\n\n(A.11)\n\nThe term a(t)u is called the peculiar velocity. In cosmology,\none also often employs the density contrast defined as \u03b4 =\n\u03c1 \u2212 1, which gives the fluctuation against the normalized\nbackground density. Taking \u03c1, u, and \u03c6\neg as functions of the\ncomoving coordinate x = r/a(t) and using (A.5), (A.6) and\n(A.7), we rewrite the Euler\u2013Poisson system in the form\n\u2202t u + (u * \u2207x )u\n\n=\n\n\u2202t \u03c1 + \u2207x * (\u03c1u)\n\n=\n\n\u22072x \u03c6g\n\n=\n\ne\n\n1\n\u0227\neg ,\n\u22122 u \u2212 \u2207x \u03c6\na\na\n0,\n4\u03c0G \u0304\n\u033a0\n(\u03c1 \u2212 1).\na\n\n(A.12)\n(A.13)\n(A.14)\n\nNote the Hubble drag term \u22122(\u0227/a)u in the right-hand side\nof (A.12) representing the relative slowdown of peculiar velocities due to the uniform expansion.\nFormally linearizing (A.12)\u2013(A.14) around the trivial\nzero solution, one obtains the following ODE for the linear\ngrowth factor \u03c4 (t) of density fluctuations:\nd 2\n\u03c4\n(a \u03c4\u0307 ) = 4\u03c0G \u0304\n\u033a0 .\ndt\na\n\n(A.15)\n\nThe only solution of this equation that stays bounded (indeed, vanishes) at small times is usually referred to as the\ngrowing mode. As we shall shortly see, it is convenient to\nchoose the amplitude factor \u03c4 of the growing mode to be\na new 'time variable,' which in an Einstein\u2013de Sitter universe is proportional to t2/3 . It is normalized such that\n\u03c40 = \u03c4 (t0 ) = 1. Rescaling the peculiar velocity and the gravitational potential according to\n4\u03c0G \u0304\n\u033a0 \u03c4\n\u03c6g\n(A.16)\na\nand using the fact that in an Einstein\u2013de Sitter universe\nd ln(a2 \u03c4\u0307 )/d\u03c4 = 3/(2\u03c4 ), we arrive at the following form of the\nEuler\u2013Poisson system, which we use throughout this paper:\n\u03c6\neg =\n\nu = \u03c4\u0307 v,\n\n\u2202\u03c4 v + (v * \u2207x )v\n\n=\n\n\u2202\u03c4 \u03c1 + \u2207x * (\u03c1v)\n\n=\n\n\u2212\n\n3\n(v + \u2207x \u03c6g ),\n2\u03c4\n\n(A.17)\n\n0,\n(A.18)\n\u03c1\u22121\n.\n(A.19)\n=\n\u03c4\nSuppose initially, i.e. at \u03c4 = 0, a mass element is located\nat a point with the comoving coordinate q. Transported by\nthe peculiar velocity field in the comoving coordinates, this\nelement describes a trajectory x(q, \u03c4 ). Using the Lagrangian\ncoordinate q to parametrize the whole continuum of mass\nelements, we recast (A.17) and (A.19) in the form\n\u22072x \u03c6g\n\nD\u03c42 x\n\n=\n\n\u2212\n\n3\n(D\u03c4 x + \u2207x \u03c6g ) ,\n2\u03c4\n\n(A.20)\n\n\u0003\n1\u0002\n=\n(det \u2207q x)\u22121 \u2212 1 .\n(A.21)\n\u03c4\nThe density and peculiar velocity in Lagrangian variables\nare given by\n\u22072x \u03c6g\n\n\u03c1(x(q, \u03c4 ), \u03c4 ) = (det \u2207q x)\u22121 ,\n\nv(x(q, \u03c4 ), \u03c4 ) = D\u03c4 x(q, \u03c4 ),\n\n(A.22)\n\nwhich automatically satisfy the mass conservation\nlaw (A.18). Here D\u03c4 is the operator of Lagrangian\ntime derivative, which in Lagrangian variables is the usual\npartial time derivative at constant q and in Eulerian\n\nvariables coincides with the material derivative \u2202\u03c4 + v * \u2207x .\nThe notation \u2207x in Lagrangian variables stands for the\nx(q, \u03c4 )-dependent differential operator with components\n\u2207xi \u2261 (\u2202qj /\u2202xi )\u2207qj , which expresses the Eulerian gradient\nrewritten in Lagrangian coordinates, using the inverse\nJacobian matrix. Note that \u2207x and D\u03c4 do not commute\nand that terms with \u2207x in the Lagrangian equations are\nimplicitly non-linear.\nIn one dimension, (A.21) has an interesting consequence:\n\u2207x \u03c6g = \u2212\n\nx\u2212q\n.\n\u03c4\n\n(A.23)\n\nIndeed, in one dimension (A.21) takes the form\n\n\u0003\n1\u0002\n(\u2207q x)\u22121 \u2212 1 .\n\u03c4\n\n\u22072x \u03c6g =\n\n(A.24)\n\nMultiplying this equation by \u2207q x and expressing the first\nof the two x-derivatives acting on \u03c6g as a q-derivative, we\nobtain\n\u2207q (\u2207x \u03c6g ) = \u2207q\n\nq\u2212x\n.\n\u03c4\n\n(A.25)\n\nEq. (A.23) is obtained from (A.25) by integrating in q. The\nabsence of an arbitrary \u03c4 -dependent constant is established\neither by assuming vanishing at large distances of both \u03c6g\nand of the displacement x \u2212 q or, in the space-periodic case,\nby assuming the vanishing of period averages.\nUsing (A.23) to eliminate the \u03c6g term in (A.20) and\nintroducing the notation \u03be for the displacement x \u2212 q, we\nobtain\nD\u03c42 \u03be = \u2212\n\n3\n2\u03c4\n\n\u0010\n\nD\u03c4 \u03be \u2212\n\n\u03be\n\u03c4\n\n\u0011\n\n.\n\n(A.26)\n\nThe only solution to this equation that remains well-behaved\nfor \u03c4 \u2192 0 is the linear one \u03be \u221d \u03c4 . This solution has the two\nterms on the right-hand side of the one-dimensional version\nof (A.20) cancelling each other and hence gives a vanishing\n'acceleration' D\u03c42 x.\nAn approximate vanishing of acceleration takes place in\nhigher dimensions as well. For early times, the Lagrangian\nmap x(q, \u03c4 ) stays close to the identity, with displacements\n\u03be(q, \u03c4 ) = x(q, \u03c4 ) \u2212 q small. Linearizing (A.20) and (A.21)\naround zero displacement, we get the system\nD\u03c42 \u03be\n\n=\n\n\u22072q \u03c6g\n\n=\n\n3\n(D\u03c4 \u03be + \u2207q \u03c6g ),\n2\u03c4\n1\n\u2212 \u2207q * \u03be.\n\u03c4\n\n\u2212\n\n(A.27)\n(A.28)\n\nHere we use the fact that \u2207x \u2243 \u2207q and det \u2207q x \u2243\n1 + \u2207q * \u03be. Using (A.28) to eliminate \u03c6g in (A.27), we get\nfor \u03b8 \u2261 \u2207q * \u03be an equation that coincides with (A.26) up\nto the change of variable \u03be 7\u2192 \u03b8. Choosing the well-behaved\nlinear solution for \u03b8, solving for \u03be and using the above argument to eliminate a \u03c4 -dependent constant, we see that,\nin the linearized equations, terms in the right-hand side of\n(A.27) cancel each other and the acceleration vanishes. This\nsimplification justifies using the linear growth factor \u03c4 as a\ntime variable.\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n\fReconstruction of the early Universe as a convex optimization problem\nAPPENDIX B: HISTORY OF MASS\nTRANSPORTATION\nThe subject of mass transportation was started by Gaspard\nMonge (1781) in a paper22 entitled Th\u00e9orie des d\u00e9blais et\ndes remblais (Theory of cuts and fills) whose preamble is\nworth quoting entirely (our translation):\nWhen earth is to be moved from one place to another, the\nusage is to call cuts the volumes of earth to be transported and\nfills the space to be occupied after transportation.\nThe cost of transporting one molecule being, all things otherwise equal, proportional to its weight and to the distance [espace]\ntravelled and consequently the total cost being proportional to\nthe sum of products of molecules each multiplied by the distance\ntravelled, it follows that for given shapes and positions of the cuts\nand fills, it is not indifferent that any given molecule of the cuts\nbe transported to this or that place in the fills, but there ought\nto be a certain distribution of molecules of the former into the\nlatter, according to which the sum of these products will be the\nleast possible, and the cost of transportation will be a minimum.\n\nAlthough clearly posed, the 'mass transportation problem' was not solved, in more than one dimension, until\nLeonid Kantorovich (1942) formulated a 'relaxed' version,\nnow called the Monge\u2013Kantorovich problem: instead of a\n'distribution of molecules of the former into the latter,' he\nallowed a distribution in the product space where more than\none position in the fills could be associated with a position\nin the cuts and where the initial and final distributions are\nprescribed marginals (see Section 3.3). In cosmospeak, he\nallowed multi-streaming with given initial and final mass\ndistributions. Using the techniques of duality and of linear programming that he had invented (see Appendix C2),\nKantorovich was then able to solve the mass transportation problem in this relaxed formulation. The techniques\ndeveloped by Kantorovich found many applications, notably\nin economics, which in fact was his original motivation (he\nwas awarded, together with T.C. Koopmans, the 1975 Nobel\nprize in this field).\nBefore turning to more recent developments we must\nsay a few words about the history of the Monge\u2013Amp\u00e8re\nequation. It was considered for the first time by Amp\u00e8re\n(1820) for an unknown function z(x, y) of two scalar variables. The equation is to be found on p. 65 of Amp\u00e8re's huge\n(188 pages) mathematical memoir in the form\nHr + 2Ks + Lt + M + N (rt \u2212 s2 ) = 0,\n\n(B.1)\n\nwhere in modern notation r = \u2202 2 z/\u2202x2 , s = \u2202 2 z/(\u2202x\u2202y),\nt = \u2202 2 z/\u2202y 2 , and H, K, L, M, N are functions of x, y, z and\nthe two first-order derivatives p = \u2202z/\u2202x and q = \u2202z/\u2202y.\nThis extends the earlier work by Monge (1784, see p. 126)\nconcerning the equation without the Hessian term (N = 0).\nBoth Amp\u00e8re and Monge were interested in methods of explicit integration of these equations. Amp\u00e8re also pointed\nout the way the equation changes under Legendre transformations but there is no physical interpretation in terms of\nLagrangian coordinates.23 There is evidence that until the\n22\n\nThe author's name appears in this paper as 'M. Monge,' where\nthe 'M.' stands for 'Monsieur.'\n23 According to the biography of Amp\u00e8re by L. Pearce Williams\nin the Dictionary of Scientific Biography, Amp\u00e8re's paper was\nwritten \u2013 after he had switched from mathematics to chemistry\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n21\n\nbeginning of the 20th century the scientific community attributed the equation with the Hessian solely to Amp\u00e8re\n(Bour (1862, p. 186) and Weber (1900, p. 367)). But the\njoint attribution of (B.1) to 'Monge and Amp\u00e8re' is already\nfound in (Goursat 1896).\nThe subjects of mass transportation and of the Monge\u2013\nAmp\u00e8re equation came together when one of us (YB) showed\nthe equivalence of the elliptic Monge\u2013Amp\u00e8re equation and\nof the mass transportation problem with quadratic cost:\nwhen initial and final distributions are non-singular, the\noptimal solution is actually one-to-one, so that nothing\nis lost by the Kantorovich relaxation trick (Brenier 1987,\n1991). For an extension of this result to general costs see\nGangbo & McCann (1996); a review of the many recent papers on the subject is given by Ambrosio (2003).\n\nAPPENDIX C: BASICS OF CONVEXITY AND\nDUALITY\nC1\n\nConvexity and the Legendre transformation\n\nA convex body may be defined by the condition that it coincides with the intersection of all half-spaces containing it.\nObviously, it is sufficient to take only those half-spaces limited by planes that touch the body; such planes are called\nsupporting.\nTake now a convex function f (q), so that the set of\npoints in the (3 + 1)-dimensional (q, f ) space lying above its\ngraph is convex. It follows that we can write\nf (q) = max x * q \u2212 f \u2217 (x),\nx\n\n(C.1)\n\nwhere the expression x * q \u2212 f \u2217 (x) specifies a supporting\nplane with the slope x for the set of points lying above the\ngraph of f (see Fig. C1 for the one-dimensional case). The\nfunction f \u2217 (x), which specifies how high one should place a\nsupporting plane to touch the graph, is called the Legendre\ntransform of f (q).24\nFrom Eq. (C.1) follows the inequality (known as the\nYoung inequality)\nf (q) + f \u2217 (x) > x * q for all x, q,\n\n(C.2)\n\nwhere both sides coincide if and only if the supporting plane\nwith the slope x touches the graph of f at q. This fact, together with the obvious symmetry of this inequality, implies\nthat\nf \u2217 (x) = max x * q \u2212 f (q).\nq\n\n(C.3)\n\nThus, the Legendre transform of a convex function is itself\nconvex and the Legendre transform of the Legendre transform recovers the initial convex function.\nIf however we apply (C.1) to a nonconvex function f , we\nobtain a convex function f \u2217 , whose own Legendre transform\nwill give the convex hull of f , the largest convex function\nwhose graph lies below that of f .\nand physics \u2013 with the purpose of facilitating his election to the\nParis Academy of Science; one can then speculate that his mention of the Legendre transformation was influenced by Legendre's\npresence in this academy.\n24 It was introduced in the one-dimensional case by Mandelbrojt\n(1939) and then generalized by Fenchel (1949).\n\n\f22\n\nY. Brenier et al.\ninf sup y * q \u2212 \u03a6\u2217 (y) \u2212 x * (Aq \u2212 b)\n\nf(q)\n\nq\n\nx,y\n\n= inf sup (y \u2212 AT x) * q \u2212 \u03a6\u2217 (y) + x * b,\nq\n\n(C.5)\n\nx,y\n\nwhere \u03a6\u2217 (y) is the Legendre transform of \u03a6(q) and AT is\nthe transpose of A. Taking inf in q first, we see that the\nexpression in the right-hand side will be infinite unless y =\nAT x. We then obtain the optimization problem of finding\nsup x * b \u2212 \u03a6\u2217 (AT x),\n\n(C.6)\n\nx\n\nwhich is called dual to the original one. Note that there are\nno constraints on the dual variable x: any value is admissible.\nDenoting solutions of problems (C.4) and (C.6) by q \u2217\nand x\u2217 , we see that\n\nsubgradient\n\nf *(x)\n\nq\nx\n\nFigure C1. A convex function f (q) and the geometrical construction of its Legendre transform f \u2217 (x). Also illustrated is the\nsubgradient of f (q) at a non-smooth point.\n\nWhen f is both convex and differentiable, (C.2) becomes an equality for x = \u2207q f (q). If f \u2217 is also differentiable, then one also has q = \u2207x f \u2217 (x). This is actually\nLegendre's original definition of the transformation, which\nis thus limited to smooth functions. Furthermore, if the original function is not convex and thus has the same gradient at\nseparated locations, Legendre's purely local definition will\ngive a multivalued Legendre transform. (In the context of\nthe present paper this corresponds to multi-streaming.)\nNot all convex functions are differentiable (e.g. f (q) =\n|q|). But the Young inequality can be employed to define\na useful generalization of the gradient: the subgradient of f\nat q is the set of all x for which the equality in (C.2) holds\n(see Fig. C1). If f is smooth at q, then \u2207q f (q) will be the\nonly such point; otherwise, there will be a (convex) set of\nthem.\nIf a convex function has the same subgradient at more\nthan one point, the function is said to lack strict convexity.\nIn fact, strict convexity and smoothness are complementary:\nlack of one in a convex function implies lack of the other in\nthe Legendre transform.\nFor further background on convex analysis and geometry, see Rockafellar (1970).\nC2\n\ninf \u03a6(q) = inf sup \u03a6(q) \u2212 x * (Aq \u2212 b).\nq\n\n(C.7)\n\nbecause the optimal values of both problems are given\nby (C.5) and thus coincide. Furthermore, for any admissible q and x\n\u03a6(q) + \u03a6\u2217 (AT x) \u2212 x * b > 0,\n\n(C.8)\n\nbecause the right-hand sides of (C.4) and (C.6) cannot pass\nbeyond their optimal values.\nMoreover, let equality (C.7) be satisfied for some admissible q \u2217 and x\u2217 ; then such q \u2217 and x\u2217 must solve the problems\n(C.4) and (C.6). Indeed, taking e.g. x\u2217 for x in (C.8) and\nusing (C.7), we see that for any other admissible q\n\u03a6(q \u2217 ) 6 \u03a6(q),\n\n(C.9)\n\n\u2217\n\ni.e., that q solves the original optimization problem (C.4).\nConvex optimization problems with linear constraints\nconsidered in this section are called convex programs. Their\nclose relatives are linear programs, namely optimization\nproblems of the form\ninf\n\nAq=b, q>0\n\nc * q = inf sup c * q \u2212 x * (Aq \u2212 b),\nq>0\n\n(C.10)\n\nx\n\nwhere notation q > 0 means that all components of the\nvector q are nonnegative. Proceeding essentially as above\nwith c * q instead of \u03a6(q), we observe that in order not\nto obtain infinity when minimizing in q in (C.5), we have\nnow to require that AT x 6 c (i.e. c \u2212 AT x > 0). The dual\nproblem thus takes the form\nsup x * b\n\nDuality in optimization\n\n(C.11)\n\nAT x6c\n\nSuppose we want to minimize a convex function \u03a6(q) subject\nto a set of linear constraints that may be written in matrix\nnotation as Aq = b (vectors q satisfying this constraint are\ncalled admissible in optimization parlance). We now observe\nthat\nAq=b\n\n\u03a6(q \u2217 ) + \u03a6\u2217 (AT x\u2217 ) \u2212 x\u2217 * b = 0,\n\n(C.4)\n\nx\n\nIndeed, should Aq not equal b, the sup operation in x will\ngive infinity, so such q will not contribute to minimization.\nHere we use the inf/sup notation instead of min/max because the extremal values may not be reached, e.g., when\nthey are infinite.\nUsing (C.1), we rewrite this in the form\n\nwith an admissibility constraint on x. Instead of (C.7)\nand (C.8) we obtain\nx\u2217 * b = c * q \u2217\n\nor\n\n(AT x\u2217 \u2212 c) * q \u2217 = 0\n\n(C.12)\n\nand\nx*b 6 c*q\n\nor\n\n(AT x \u2212 c) * q 6 0,\n\n(C.13)\n\nthe latter inequality being automatically satisfied for any\nadmissible x, q. Note that for linear programs, the fact that\n(C.12) holds for some admissible q \u2217 , x\u2217 also implies that q \u2217\nand x\u2217 solve their respective optimization problems.\nFor further background on optimization and duality,\nsee, e.g., Papadimitriou & Steiglitz (1982).\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n\fReconstruction of the early Universe as a convex optimization problem\nC3\n\nWhy the analogue computer of Section 4.2\nsolves the assignment problem\n\nWe suppose that the analogue computer described in Section 4.2 has settled into equilibrium, which minimizes its\npotential energy\nU=\n\nN\nX\ni=1\n\n\u03b1i \u2212\n\nN\nX\n\n\u03b2j ,\n\n(C.14)\n\nj=1\n\nunder the set of constraints\n\u03b1i \u2212 \u03b2j > C \u2212 cij ,\n\n(C.15)\n\nfor all i, j. Our goal is here is to show that the set of equilibrium forces fij , acting on studs between row and column\nrods, solves the original linear programming problem of minimizing\nI \u0303 =\n\nN\nX\n\n23\n\nObserve that pushing a column rod down by some distance \u2206 and simultaneously increasing by \u2206 the length of\nall studs attached to this rod will have no effect on positions\nand constraints of all other rods, hence on the equilibrium\nnetwork of contacts. Moreover, due to constraints (C.17),\nthe corresponding change in coefficients cij will not change\nthe cost function (C.16) in any essential way, except of just\nsubtracting \u2206.\nWe can use this observation to put all column rods at\nthe same level, say at z = 0, adjusting cij to some new\nvalues c\u2032ij . Thus, for every i, the row rod Ai rests on the stud\nwith the largest height C \u2212 c\u2032ij , so the equilibrium pairing\nmaximizes the sum\nN\nX\n\n(C \u2212 c\u2032ij )fij\n\n(C.18)\n\ni,j=1\n\nand thus minimizes (C.16).25\ncij fij\n\n(C.16)\n\ni,j=1\n\nunder constraints\nfij > 0,\n\nN\nX\nk=1\n\nfkj =\n\nN\nX\n\nfik = 1,\n\n(C.17)\n\nk=1\n\nfor all i, j and that in fact forces fij take only zero and\nunit values, thus providing the solution to the assignment\nproblem.\nNote first that if a row rod Ai and a column rod Bj\nare not in contact at equilibrium, then the corresponding\nforce vanishes (fij = 0); if they are, then fij > 0. Take\nnow a particular pair of rods Ai and Bj that are in contact.\nAt equilibrium, the force fij must equal forces exerted on\nthe corresponding stud by Ai and Bj . We claim that both\nthese forces must be integer. To see this, let us compute\nthe force exerted by Ai . This rod contributes its weight,\n+1, possibly decreased by the force that it feels from other\ncolumn rods that are in contact with Ai . Each of these takes\n\u22121 (its 'buoyancy') out of the total force, but we may have\nto add the force it feels in turn from other row rods with\nwhich it might be in contact. Proceeding this way from one\nrod to another, we see that all contributions, positive or\nnegative, are unity, so their sum fij must be integer. The\nsame argument applies to rod Bj .\nDoes this process indeed finish or, at some stage, do we\ncome back at an already visited stud and thus end up in an\ninfinite cycle? In fact, for general set of stud lengths C \u2212 cij ,\nthe latter cannot happen, because otherwise an alternating\nsum of some subset of stud lengths would give exactly zero \u2013\na zero probability event for a set of arbitrary real numbers.\nConsider now a row rod Ai . It is in contact with one\nor more column rods, whose combined upward push must\nequilibrate the unit weight of Ai . Since any of the latter rods\nexerts a nonnegative integer force, it follows that exactly one\nof these forces is unity, and all the other ones are zero. A\nsimilar argument holds for any column rod Bj .\nWe have thus shown that all fij in the equilibrium equal\n1 or 0. One can of course ignore the vanishing forces. Then\neach row rod Ai is supported by exactly one column rod Bj ,\nand each Bj supports exactly one Ai . This defines a oneto-one pairing, and we are only left with a check that this\npairing minimizes (C.16).\nc 0000 RAS, MNRAS 000, 000\u2013000\n\nAPPENDIX D: DETAILS OF THE\nVARIATIONAL TECHNIQUE FOR THE\nEULER\u2013POISSON SYSTEM\nIn this appendix, we explain details of the variational procedure outlined in Section 6, which proves that prescription\nof the density fields at terminal epochs \u03c4 = 0 and \u03c4 = \u03c40\nuniquely determines a regular and thus curl-free solution to\nthe Euler\u2013Poisson system (A.17)\u2013(A.19).\nThe variational problem is posed for the functional\nI=\n\n1\n2\n\nZ\n\n\u03c40\n\nd\u03c4\n\n0\n\nZ\n\n\u0010\n\nd3 x \u03c4 3/2 \u03c1|v|2 +\n\n3\n|\u2207x \u03c6g |2\n2\n\n\u0011\n\n(D.1)\n\nwith four constraints: the Poisson equation (A.19), which we\nrepeat here for convenience,\n\u22072x \u03c6g =\n\n\u03c1\u22121\n,\n\u03c4\n\n(D.2)\n\nthe mass conservation (A.18), also repeated here,\n\u2202\u03c4 \u03c1 + \u2207x * (\u03c1v) = 0,\n\n(D.3)\n\nand the two boundary conditions\n\u03c1(x, 0) = 1\n\nand\n\n\u03c1(x, \u03c40 ) = \u03c10 (x).\n\nRR\n\n(D.4)\n\nIn the sequel, we shall always denote by\nthe double integration over 0 6 \u03c4 6 \u03c40 and over the whole space domain\nin x provided that the integrand vanishes at infinity sufficiently fast, or over the periodicity box in theR case of periodic\nboundary conditions. A single integral sign will always denote the integration over the relevant space domain in x.\nFirst, we make this problem convex by rewriting the\nfunctional and constraints in a new set of variables with the\nmass flux J (x, t) = \u03c1(x, t) v(x, t) instead of the velocity v.\nThe mass conservation constraint, which was the only nonlinear one in the old variables, becomes now linear:\n25 Those readers familiar with linear programming will recognize\nthat the proof just presented is based on two ideas: (i) the total\nunimodularity of the matrix of constraints in terms of which the\nequalities in (C.17) can be written and (ii) the complementary\nslackness (see, e.g., Papadimitriou & Steiglitz 1982, sections 3.2\nand 13.2).\n\n\f24\n\nY. Brenier et al.\n\n\u2202\u03c4 \u03c1 + \u2207x * J = 0,\n\n(D.5)\n\nand one can check that the density of kinetic energy takes\nthe form\n1\n1\n\u03c1|v|2 =\n|J |2 =\nmax\n(\u03c1c + J * m)\n2\n2\u03c1\nc, m: c+|m|2 /260\n\ninf\n\nsup\nc,m,\u03b8,\u03c8:\n\n\u03c1,J ,\u03c6\n\nc+|m|2 /260\n\n\u2212\n\nwhere\nF (c, m) =\n\nn\n\n0\n+\u221e\n\nif c + |m| /2 6 0\notherwise.\n\n(D.7)\n\nNote that in (D.6) the variables c, m, as well as \u03c1, J , are\nfunctions of (x, \u03c4 ). The action functional may now be written as\nI=\n\n1\n2\n\nZZ \u0012\n\n1 2 3\n|J | + |\u2207x \u03c6|2\n\u03c1\n2\n\n\u0013\n\n\u03c4 3/2 d3 x d\u03c4,\n\n(D.8)\n\nand turns out to be convex.\nTo see this, first note that the operation of integration\nis linear and thus preserves convexity of the integrand. The\nintegrand is a positive quadratic function of \u2207x \u03c6 and therefore is convex in \u03c6; furthermore, (D.6) implies that it is also\nconvex in (\u03c1, J ), since the kinetic energy density |J |2 /2\u03c1 is\nthe Legendre transform of the function F (c, m), which itself\nis convex.\nNote also that by representing the kinetic energy density in the form (D.6), we may safely allow \u03c1 to take negative\nvalues: the right-hand side being in that case +\u221e, it will not\ncontribute to minimizing (D.1).\nWe now derive the dual optimization problem. We introduce the scalar Lagrange multipliers \u03c8(x, t), \u03b8in (x), \u03b80 (x)\nand \u03b8(x, t) for the Poisson equation (D.2), the boundary\nconditions (D.4), and the constraints of mass conservation\n(D.5), respectively, and observe that the variational problem\nmay now be written in the form\ninf\n\nsup\n\n\u03c1,J ,\u03c6 c,m,\u03b8,\u03c8,\u03b80 ,\u03b8T :\nc+|m|2 /260\n\nZZ\n\nd3 x d\u03c4\n\nh\n\n\u0010\n\n3\n\u03c1\u22121\n\u03c8 \u22072x \u03c6 \u2212\n2\n\u03c4\n\n\u0010\n\n+\u03b8(\u2202\u03c4 \u03c1 + \u2207x * J ) + \u03c4 3/2 \u03c1c + J * m +\n+\n\u2212\n\nZ\n\nZ\n\n3\n\n\u03b8in (x)(\u03c1(x, 0) \u2212 1) d x\n\n\u2212\n\n(D.6)\n\n2\n\n\u0011\n\n3\n|\u2207x \u03c6|2\n4\n\n\u0011i\n\n(D.9)\n\n3\n\n\u03b80 (x)(\u03c1(x, \u03c40 ) \u2212 \u03c10 (x)) d x.\n\nTo see that (D.9) is indeed equivalent to minimizing (D.1)\nunder the constraints (D.3) or (D.5), (D.2), and (D.4), observe that for those \u03c1, J , \u03c6 that do not satisfy the constraints, the sup operation over \u03b8, \u03c8, \u03b8in , \u03b80 will give positive infinity; the sup will be finite (and thus contribute to\nthe subsequent minimization) only if all constraints are satisfied. (This argument is the functional version of what is\nexplained in Appendix C2 for the finite-dimensional case.)\nPerforming an integration by parts in the \u03c4 variable in\n(D.9) and using the boundary conditions on the mass density\n(D.4), we find that \u03b8in (x) = \u03b8(x, 0) and \u03b80 (x) = \u03b8(x, \u03c40 ).\nIntegrating further by parts in the x variable, assuming that\nboundary terms at infinity vanish (or that we have periodic\nboundary conditions in space) and rearranging terms, we get\n\n\u0010\n\nd3 x d\u03c4 \u03c1 (c\u03c4 3/2 \u2212 \u2202\u03c4 \u03b8 \u2212\n\n+J * (m\u03c4 3/2 \u2212 \u2207x \u03b8) +\n\nor\n|J |2\n= max (\u03c1c + J * m \u2212 F (c, m)),\nc, m\n2\u03c1\n\nZZ\n\n3\n3\n\u03c8\n|\u2207x \u03c8|2 +\n2\u03c4\n4\u03c4 3/2\n\nZ\n\nZ\n\n\u03b8(x, 0) d3 x +\n\n3\n\u03c8)\n2\u03c4\n\n3\n|\u2207x \u03c8 \u2212 \u03c4 3/2 \u2207x \u03c6g |2\n(D.10)\n4\u03c4 3/2\n\n\u0011\n\n\u03b8(x, \u03c40 ) \u03c10 (x) d3 x.\n\nPerforming minimization with respect to \u03c1, J , \u03c6 first, as in\n(C.5) of Appendix C2, we see that the following two equalities must hold (remember that \u03c1 need not be positive at this\nstage):\nc=\n\n1\n\u03c4 3/2\n\n\u0010\n\n\u2202\u03c4 \u03b8 +\n\n3\u03c8\n2\u03c4\n\n\u0011\n\n,\n\nm=\n\n1\n\u2207x \u03b8,\n\u03c4 3/2\n\n(D.11)\n\nso that terms linear in \u03c1 and J vanish in (D.10). It follows\nthat c and m are determined by \u03b8 and \u03c8 and that the constraint c + |m|2 /2 6 0 can be written\n\u2202\u03c4 \u03b8 +\n\n3\n1\n|\u2207x \u03b8|2 +\n\u03c8 6 0.\n2\u03c4\n2\u03c4 3/2\n\n(D.12)\n\nAlso, the inf with respect to \u03c6 is straightforward and gives\n\u03c4 3/2 \u2207x \u03c6g = \u2207x \u03c8.\n\n(D.13)\n\nUsing (D.11) and (D.13) in (D.10), we arrive at the optimization problem of maximizing\nJ=\n+\n\nZZ \u0010\n\nZ\n\n3\n3\n\u03c8 \u2212 3/2 |\u2207x \u03c8|2\n2\u03c4\n4\u03c4\n3\n\n\u03b8(x, \u03c40 ) \u03c10 (x) d x \u2212\n\nZ\n\n\u0011\n\nd3 x d\u03c4\n(D.14)\n3\n\n\u03b8(x, 0) d x\n\nunder constraint (D.12). Eqs. (D.14) and (D.12) constitute\na variational problem dual to the original one.\nAs both the original and the dual variational problems\nhave the same saddle-point formulation (D.9) or (D.10), the\noptimal values of the two functionals (D.1) and (D.14) are\nequal. Let (\u03c1, J , \u03c6g ) be a solution to the original variational\nproblem and \u03b8, \u03c8 be a solution to the dual one. Subtracting\nthe (equal) optimal values from each other, we may now\nwrite, similarly to (C.7),\n\nZZ \u0012\n\n\u03c4 3/2 2 3\u03c4 3/2\n|J | +\n|\u2207x \u03c6g |2\n2\u03c1\n4\n\n3\n3\n+ 3/2 |\u2207x \u03c8|2 \u2212\n\u03c8\n2\u03c4\n4\u03c4\n+\n\nZ\n\n\u03b8(x, 0) d3 x \u2212\n\nZ\n\n\u0013\n\nd3 x d\u03c4\n\n(D.15)\n\n\u03b8(x, \u03c40 ) \u03c10 (x) d3 x = 0.\n\nWe are going to show that the left-hand side of (D.15) may\nbe given the form of a sum of three nonnegative terms, each\nof which will therefore have to vanish. First, we rewrite the\nlast two integrals, using the mass conservation constraint\n(D.5) and integrations by parts, in the form\n\u2212\n\nZZ\n\n\u2202\u03c4 (\u03b8\u03c1) d3 x d\u03c4 = \u2212\n\nZZ\n\n(\u2202\u03c4 \u03b8 \u03c1 + \u2207x \u03b8 * J ) d3 x d\u03c4.\n\nSecond, we note that\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n\fReconstruction of the early Universe as a convex optimization problem\nZZ \u0012\n=\n\n3\n3\u03c4 3/2\n|\u2207x \u03c6g |2 + 3/2 |\u2207x \u03c8|2\n4\n4\u03c4\n\nZZ \u0010\n\n\u0013\n\nd3 x d\u03c4\n\n3\n3\n\u03c8(\u03c1 \u2212 1)\n|\u03c4 3/2 \u2207x \u03c6g \u2212 \u2207x \u03c8)|2 \u2212\n2\u03c4\n4\u03c4 3/2\n\n\u0011\n\nd3 x d\u03c4,\n\nwhich follows from the Poisson constraint (D.2). Taking all\nthis into account in (D.15), we get, after a rearrangement of\nterms,\n\nZZ\n\n\u03c1\n\u03c4 3/2\nJ \u2212 \u2207x \u03b8\n3/2\n\u03c1\n2\u03c4\n\n+\n\n+\n\nZZ\n\nZZ\n\n\u0010\n\n\u2212\u03c1 \u2202\u03c4 \u03b8 +\n\n2\n\nd3 x d\u03c4\n\n1\n3\n\u03c8\n|\u2207x \u03b8|2 +\n2\u03c4\n2\u03c4 3/2\n\n\u0011\n\nd3 x d\u03c4\n\n(D.16)\n\n3\n|\u03c4 3/2 \u2207x \u03c6g \u2212 \u2207x \u03c8)|2 d3 x d\u03c4 = 0.\n4\u03c4 3/2\n\nThe left-hand side is a sum of three nonnegative terms (the\nsecond is so by (D.12)), all of which must thus vanish. This\ngives\nv=\n\n1\n1\nJ = 3/2 \u2207x \u03b8,\n\u03c1\n\u03c4\n\n\u2207x \u03c6g =\n\n1\n\u2207x \u03c8\n\u03c4 3/2\n\n(D.17)\n\nand\n\u2202\u03c4 \u03b8 +\n\n3\n1\n\u03c8 = 0,\n|\u2207x \u03b8|2 +\n2\u03c4\n2\u03c4 3/2\n\n(D.18)\n\nwherever \u03c1 is non-vanishing (otherwise the left-hand-side is\nnon-positive by (D.12)). The last equality turns into the\nEuler equation\n\u2202\u03c4 v + (v * \u2207x )v = \u2212\n\n3\n(v + \u2207x \u03c6g )\n2\u03c4\n\n(D.19)\n\nby taking the gradient and using (D.17).\nBy (D.17) and (D.18), any two hypothetically different\nminimizing solutions for either variational problem give rise\nto the same velocity potential and to the same gravitational\npotential (up to insignificant constants) and thus define the\nsame solution (\u03c1, v, \u03c6g ) to the Euler\u2013Poisson equations with\nthe boundary conditions (D.4) and the condition of curl-free\nvelocity.\nMoreover, for any such solution (\u03c1, v, \u03c6g ), one can\nuse (D.17) to define \u03b8 and \u03c8 that satisfy (D.18) and\nthus (D.12). By (D.16), the values of functionals I and I \u0304\nevaluated at these functions will coincide; together with convexity this implies, by an argument similar to that given\nin Appendix C2 concerning (C.9), that such (\u03c1, v, \u03c6g ) and\n(\u03b8, \u03c8) in fact minimize both functionals under the corresponding constraints.\nThis means that a (curl-free) velocity field, a gravitational field and a density fields (v, \u03c6g , \u03c1) will satisfy the\nEuler\u2013Poisson equations (A.17)\u2013(A.19) (repeated as (D.19),\n(D.3), and (D.2) in this Appendix) and the boundary conditions (D.4) if and only if they minimize (D.1) under the\ncorresponding constraints. This establishes uniqueness.\n\nREFERENCES\nAmbrosio L., 2003, in Proceedings of the ICM Beijing 2002,\nVol. 3, pp 131\u2013140 and arXiv.org/abs/math.AP/0304389\nAmp\u00e8re A.-M., 1820, J. de L'\u00c9cole Royale Polytechnique,\n11, 1\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n25\n\nArnol'd V. I., Shandarin S. F., Zel'dovich Y. B., 1982, Geophys. Astrophys. Fluid Dynamics, 20, 111\nBalinski M. L., 1986, Math. Programming, 34, 125\nBec J., Frisch U., Khanin K., 2000, J. Fluid Mech., 416,\n239\nBenamou J.-D., Brenier Y., 2000, Numer. Math., 84, 375\nBernardeau F., Colombi S., Gazta\u00f1aga E., Scoccimarro R.,\n2002, Phys. Rep., 367, 1\nBertschinger E., Dekel A., 1989, ApJ, 336, L5\nBertsekas D. P., 1981, Math. Programming, 21, 152\nBertsekas D. P., 1992, Comput. Optim. Appl., 1, 7\nBertsekas D., 2001, in Encyclopedia of optimization, Vol. I.\nKluwer Academic Publishers, Dordrecht\nBour \u00c9., 1862, Journal de l'\u00c9cole polytechnique, 22,\ncah. 39, 149\nBranchini E., Eldar A., Nusser A., 2002, MNRAS, 335, 53\nBrenier Y., 1987, C. R. Acad. Sci. Paris S\u00e9r. I Math., 305,\n805\nBrenier Y., 1991, Comm. Pure Appl. Math., 44, 375\nBridle S. L., Lahav O., Ostriker J. P., Steinhardt P. J.,\n2003, Sci, 299, 1532\nBuchert T., 1992, MNRAS, 254, 729\nBuchert T., Dominguez A., 1998, A&A, 335, 395\nBuchert T., Ehlers J., 1993, MNRAS, 264, 375\nBurkard R. E., Derigs U., 1980, Assignment and matching\nproblems: solution methods with FORTRAN programs.\nVol. 184 of Lecture Notes in Economics and Mathematical\nSystems, Springer-Verlag, Berlin\nCaffarelli L., Li Y. Y., 2001, An extension to a theorem of J\u00f6rgens, Calabi, and Pogorelov, preprint\n(www.math.utexas.edu/users/combs/Caffarelli/extension.pdf)\nCaffarelli L. A., 1999, in Christ M., Kenig C. E., Sadosky\nC., eds, Chicago Lectures in Math., Harmonic analysis\nand partial differential equations. Univ. Chicago Press,\nChicago, IL, pp 117\u2013126\nCaffarelli L. A., Milman M., eds, 1999, Monge Amp\u00e8re\nequation: applications to geometry and optimization.\nVol. 226 of Contemporary Mathematics, American Mathematical Society, Providence, RI\nCatelan P., 1995, MNRAS, 276, 115\nCatelan P., Lucchin F., Matarrese S., Moscardini L., 1995,\nMNRAS, 276, 39\nColes P., Lucchin F., 2002, Cosmology: The Origin and\nEvolution of Cosmic Structure. John Wiley & Sons,\nChichester et al.\nCouchman H. M. P., Thomas P. A., Pearce F. R., 1995,\nApJ, 452, 797\nCroft R. A. C., Gazta\u00f1aga E., 1997, MNRAS, 285, 793\nDekel A., Bertschinger E., Faber S. M., 1990, ApJ, 364, 349\nFanelli D., Aurell E., 2002, A&A, 395, 399\nFenchel W., 1949, Canadian J. Math., 1, 73\nFr\u00e9chet M., 1957a, C. R. Acad. Sci. Paris S\u00e9r. I Math., 244,\n689\nFr\u00e9chet M., 1957b, Publ. Inst. Statist. Univ. Paris, 6, 183\nFrieman J. A., Szalay A. S., 2000, Phys. Rep., 333, 215\nFrisch U., Bec J., 2002, in Lesieur M., Yaglom A., David\nF., eds, \u00c9cole de physique des Houches, session LXXIV,\nNew trends in turbulence. EDP Sciences and Springer, pp\n341\u2013384\nFrisch U., Matarrese S., Mohayaee R., Sobolevski A., 2002,\nNat, 417, 260\nGangbo W., McCann R. J., 1996, Acta Math., 177, 113\n\n\f26\n\nY. Brenier et al.\n\nGiavalisco M., Mancinelli B., Mancinelli P. J., Yahil A.,\n1993, ApJ, 411, 9\nGoursat \u00c9., 1896, Le\u00e7ons sur l'int\u00e9gration des \u00e9quations\naux d\u00e9riv\u00e9es partielles du second ordre. Vol. I, Paris\nGramann M., 1993, ApJ, 405, 449\nGurbatov S. N., Saichev A. I., 1984, Izv. Vys\u0161. U\u010debn.\nZaved. Radiofizika, 27, 456\nGurbatov S. N., Saichev A. I., Shandarin S. F., 1989, MNRAS, 236, 385\nH\u00e9non M., 1995, C. R. Acad. Sci. Paris S\u00e9r. I Math., 321,\n741\nH\u00e9non M., 2002, A mechanical model for the transportation\nproblem, preprint (arXiv:math.OC/0209047)\nJeans J. H., 1919, Problems of Cosmogony and Stellar Dynamics. Cambridge University Press, Cambridge\nKantorovich L. V., 1942, C. R. (Doklady) Acad. Sci. USSR,\n321, 199\nKardar M., Parisi G., Zhang Y., 1986, Phys. Rev. Lett.,\n56, 889\nKolatt T., Dekel A., Ganon G., Willick J. A., 1996, ApJ,\n458, 419\nKuhn H. W., 1955, Naval Res. Logist. Quart., 2, 83\nLandau L. D., Lifshitz E. M., 1960, Mechanics. Vol. 1 of\nCourse of Theoretical Physics, Pergamon Press, Oxford\nLoeper G., 2003, The inverse problem for the Euler\u2013Poisson\nsystem in cosmology, preprint (math.AP/0306430)\nMandelbrojt S., 1939, C. R. Acad. Sci. Paris, 209, 977\nMinkowski H., 1897, Nachr. Ges. Wiss. G\u00f6ttingen (Math.\nPhys. Klasse), pp 198\u2013219\nMohayaee R., Frisch U., Matarrese S., Sobolevski\u0131\u0306 A., 2003,\nA&A, 406, 393\u2013401\nMonaco P., Efstathiou G., 1999, MNRAS, 308, 763\nMonge G., 1781, Histoire de l'Acad\u00e9mie Royale des Sciences, pp 666\u2013704\nMonge G., 1784, Histoire de l'Acad\u00e9mie Royale des Sciences, pp 118\u2013192\nMoutarde F., Alimi J.-M., Bouchet F. R., Pellat R., Ramani A., 1991, ApJ, 382, 377\nMunshi D., Sahni V., Starobinsky A. A., 1994, ApJ, 436,\n517\nNarayanan V. K., Croft R. A. C., 1999, ApJ, 515, 471\nNarayanan V. K., Weinberg D. H., 1998, ApJ, 508, 440\nNusser A., Branchini E., 2000, MNRAS, 313, 587\nNusser A., Dekel A., 1992, ApJ, 391, 443\nPapadimitriou C. H., Steiglitz K., 1982, Combinatorial optimization: algorithms and complexity. Prentice-Hall Inc.,\nEnglewood Cliffs, NJ\nPeebles P. J. E., 1980, The large-scale structure of the universe. Princeton University Press, Princeton, NJ\nPeebles P. J. E., 1989, ApJ, 344, L53\nPeebles P. J. E., 1990, ApJ, 362, 1\nPogorelov A. V., 1978, The Minkowski multidimensional\nproblem. V. H. Winston & Sons, Washington, D.C.\nRachev S. T., 1984, Teor. Veroyatnost. i Primenen., 29, 625\nRockafellar R. T., 1970, Convex Analysis. Princeton Univ.\nPress, Princeton, NJ\nSathyaprakash B. S., Sahni V., Shandarin S., Fisher K. B.,\n1998, ApJ, 507, L109\nShandarin S. F., Sathyaprakash B. S., 1996, ASTRJ2, 467,\nL25\nShandarin S. F., Zel'dovich Y. B., 1989, Rev. Modern\nPhys., 61, 185\n\nSpergel D. N., Verde L., Peiris H. V., Komatsu E., Nolta\nM. R., Bennett C. L., Halpern M., Hinshaw G., Jarosik N.,\nKogut A., Limon M., Meyer S. S., Page L., Tucker G. S.,\nWeiland J. L., Wollack E., Wright E. L., 2003, First year\nWilkinson microwave anisotropy probe (WMAP) observations: determination of cosmological parameters, preprint\n(astro-ph/0302209)\nSusperregi M., Binney J., 1994, MNRAS, 271, 719\nTaylor A., Valentine H., 1999, MNRAS, 306, 491\nTomizawa N., 1971, Networks, 1, 173\nTully R. B., 1988, Nearby galaxies catalog. Cambridge University Press, Cambridge and New York\nValentine H., Saunders W., Taylor A., 2000, MNRAS, 319,\nL13\nVergassola M., Dubrulle B., Frisch U., Noullez A., 1994,\nA&A, 289, 325\nWeber E. v., 1900, in Burkhardt H., ed., Encyklop\u00e4die\nder Mathematischen Wissenschaften, Vol. 2, Analysis.\nB.G. Teubner, Leipzig, p. 294\nWeinberg D. H., 1992, MNRAS, 254, 315\nWeinberg D. H., Gunn J. E., 1990, MNRAS, 247, 260\nWhiting A. B., 2000, ApJ, 533, 50\nZel'dovich Y. B., 1970, A&A, 5, 84\n\nc 0000 RAS, MNRAS 000, 000\u2013000\n\n\f"}