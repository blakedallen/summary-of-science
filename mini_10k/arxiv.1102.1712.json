{"id": "http://arxiv.org/abs/1102.1712v1", "guidislink": true, "updated": "2011-02-08T20:33:00Z", "updated_parsed": [2011, 2, 8, 20, 33, 0, 1, 39, 0], "published": "2011-02-08T20:33:00Z", "published_parsed": [2011, 2, 8, 20, 33, 0, 1, 39, 0], "title": "3D tumor localization through real-time volumetric x-ray imaging for\n  lung cancer radiotherapy", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1102.3695%2C1102.3615%2C1102.2703%2C1102.2006%2C1102.4086%2C1102.3477%2C1102.3488%2C1102.4778%2C1102.5006%2C1102.4178%2C1102.1303%2C1102.3605%2C1102.1095%2C1102.2143%2C1102.4798%2C1102.4456%2C1102.0957%2C1102.5367%2C1102.0867%2C1102.3515%2C1102.1952%2C1102.3040%2C1102.4088%2C1102.0953%2C1102.2037%2C1102.2428%2C1102.0543%2C1102.2301%2C1102.4997%2C1102.2148%2C1102.5720%2C1102.2208%2C1102.1198%2C1102.1769%2C1102.0521%2C1102.2321%2C1102.1533%2C1102.2716%2C1102.1668%2C1102.0383%2C1102.4336%2C1102.3668%2C1102.2132%2C1102.4359%2C1102.1712%2C1102.2494%2C1102.1232%2C1102.0195%2C1102.2346%2C1102.3250%2C1102.5190%2C1102.5372%2C1102.1357%2C1102.5386%2C1102.4216%2C1102.0304%2C1102.0400%2C1102.4892%2C1102.4619%2C1102.4424%2C1102.1392%2C1102.5732%2C1102.5391%2C1102.0858%2C1102.2247%2C1102.5308%2C1102.1944%2C1102.4383%2C1102.0103%2C1102.1199%2C1102.3707%2C1102.2984%2C1102.2019%2C1102.2593%2C1102.3945%2C1102.3609%2C1102.4380%2C1102.3775%2C1102.4614%2C1102.0410%2C1102.0757%2C1102.5303%2C1102.2229%2C1102.2731%2C1102.4131%2C1102.0582%2C1102.1244%2C1102.0523%2C1102.2099%2C1102.0975%2C1102.0450%2C1102.1236%2C1102.1052%2C1102.5566%2C1102.2498%2C1102.1583%2C1102.2154%2C1102.4213%2C1102.2226%2C1102.3302%2C1102.2403&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "3D tumor localization through real-time volumetric x-ray imaging for\n  lung cancer radiotherapy"}, "summary": "Recently we have developed an algorithm for reconstructing volumetric images\nand extracting 3D tumor motion information from a single x-ray projection. We\nhave demonstrated its feasibility using a digital respiratory phantom with\nregular breathing patterns. In this work, we present a detailed description and\na comprehensive evaluation of the improved algorithm. The algorithm was\nimproved by incorporating respiratory motion prediction. The accuracy and\nefficiency were then evaluated on 1) a digital respiratory phantom, 2) a\nphysical respiratory phantom, and 3) five lung cancer patients. These\nevaluation cases include both regular and irregular breathing patterns that are\ndifferent from the training dataset. For the digital respiratory phantom with\nregular and irregular breathing, the average 3D tumor localization error is\nless than 1 mm. On an NVIDIA Tesla C1060 GPU card, the average computation time\nfor 3D tumor localization from each projection ranges between 0.19 and 0.26\nseconds, for both regular and irregular breathing, which is about a 10%\nimprovement over previously reported results. For the physical respiratory\nphantom, an average tumor localization error below 1 mm was achieved with an\naverage computation time of 0.13 and 0.16 seconds on the same GPU card, for\nregular and irregular breathing, respectively. For the five lung cancer\npatients, the average tumor localization error is below 2 mm in both the axial\nand tangential directions. The average computation time on the same GPU card\nranges between 0.26 and 0.34 seconds.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1102.3695%2C1102.3615%2C1102.2703%2C1102.2006%2C1102.4086%2C1102.3477%2C1102.3488%2C1102.4778%2C1102.5006%2C1102.4178%2C1102.1303%2C1102.3605%2C1102.1095%2C1102.2143%2C1102.4798%2C1102.4456%2C1102.0957%2C1102.5367%2C1102.0867%2C1102.3515%2C1102.1952%2C1102.3040%2C1102.4088%2C1102.0953%2C1102.2037%2C1102.2428%2C1102.0543%2C1102.2301%2C1102.4997%2C1102.2148%2C1102.5720%2C1102.2208%2C1102.1198%2C1102.1769%2C1102.0521%2C1102.2321%2C1102.1533%2C1102.2716%2C1102.1668%2C1102.0383%2C1102.4336%2C1102.3668%2C1102.2132%2C1102.4359%2C1102.1712%2C1102.2494%2C1102.1232%2C1102.0195%2C1102.2346%2C1102.3250%2C1102.5190%2C1102.5372%2C1102.1357%2C1102.5386%2C1102.4216%2C1102.0304%2C1102.0400%2C1102.4892%2C1102.4619%2C1102.4424%2C1102.1392%2C1102.5732%2C1102.5391%2C1102.0858%2C1102.2247%2C1102.5308%2C1102.1944%2C1102.4383%2C1102.0103%2C1102.1199%2C1102.3707%2C1102.2984%2C1102.2019%2C1102.2593%2C1102.3945%2C1102.3609%2C1102.4380%2C1102.3775%2C1102.4614%2C1102.0410%2C1102.0757%2C1102.5303%2C1102.2229%2C1102.2731%2C1102.4131%2C1102.0582%2C1102.1244%2C1102.0523%2C1102.2099%2C1102.0975%2C1102.0450%2C1102.1236%2C1102.1052%2C1102.5566%2C1102.2498%2C1102.1583%2C1102.2154%2C1102.4213%2C1102.2226%2C1102.3302%2C1102.2403&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Recently we have developed an algorithm for reconstructing volumetric images\nand extracting 3D tumor motion information from a single x-ray projection. We\nhave demonstrated its feasibility using a digital respiratory phantom with\nregular breathing patterns. In this work, we present a detailed description and\na comprehensive evaluation of the improved algorithm. The algorithm was\nimproved by incorporating respiratory motion prediction. The accuracy and\nefficiency were then evaluated on 1) a digital respiratory phantom, 2) a\nphysical respiratory phantom, and 3) five lung cancer patients. These\nevaluation cases include both regular and irregular breathing patterns that are\ndifferent from the training dataset. For the digital respiratory phantom with\nregular and irregular breathing, the average 3D tumor localization error is\nless than 1 mm. On an NVIDIA Tesla C1060 GPU card, the average computation time\nfor 3D tumor localization from each projection ranges between 0.19 and 0.26\nseconds, for both regular and irregular breathing, which is about a 10%\nimprovement over previously reported results. For the physical respiratory\nphantom, an average tumor localization error below 1 mm was achieved with an\naverage computation time of 0.13 and 0.16 seconds on the same GPU card, for\nregular and irregular breathing, respectively. For the five lung cancer\npatients, the average tumor localization error is below 2 mm in both the axial\nand tangential directions. The average computation time on the same GPU card\nranges between 0.26 and 0.34 seconds."}, "authors": ["Ruijiang Li", "John H. Lewis", "Xun Jia", "Xuejun Gu", "Michael Folkerts", "Chunhua Men", "William Y. Song", "Steve B. Jiang"], "author_detail": {"name": "Steve B. Jiang"}, "author": "Steve B. Jiang", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1118/1.3582693", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1102.1712v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1102.1712v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "physics.med-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "physics.med-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1102.1712v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1102.1712v1", "arxiv_comment": null, "journal_reference": null, "doi": "10.1118/1.3582693", "fulltext": "1\n2\n\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n\n3D tumor localization through real-time volumetric x-ray\nimaging for lung cancer radiotherapy\nRuijiang Li, John H. Lewis, Xun Jia, Xuejun Gu, Michael Folkerts, Chunhua Men,\nWilliam Y. Song, and Steve B. Jianga\nCenter for Advanced Radiotherapy Technologies and Department of Radiation Oncology,\nUniversity of California San Diego, La Jolla, CA 92037\n\nAbstract\nPurpose: To evaluate an algorithm for real-time 3D tumor localization from a single xray projection image for lung cancer radiotherapy.\nMethods: Recently we have developed an algorithm for reconstructing volumetric\nimages and extracting 3D tumor motion information from a single x-ray projection (Li et\nal 2010 Med Phys 37 2822-6). We have demonstrated its feasibility using a digital\nrespiratory phantom with regular breathing patterns. In this work, we present a detailed\ndescription and a comprehensive evaluation of the improved algorithm. The algorithm\nwas improved by incorporating respiratory motion prediction. The accuracy and\nefficiency of using this algorithm for 3D tumor localization were then evaluated on 1) a\ndigital respiratory phantom, 2) a physical respiratory phantom, and 3) five lung cancer\npatients. These evaluation cases include both regular and irregular breathing patterns that\nare different from the training dataset.\nResults: For the digital respiratory phantom with regular and irregular breathing, the\naverage 3D tumor localization error is less than 1 mm which does not seem to be affected\nby amplitude change, period change, or baseline shift. On an NVIDIA Tesla C1060 GPU\ncard, the average computation time for 3D tumor localization from each projection ranges\nbetween 0.19 and 0.26 seconds, for both regular and irregular breathing, which is about a\n10% improvement over previously reported results. For the physical respiratory phantom,\nan average tumor localization error below 1 mm was achieved with an average\ncomputation time of 0.13 and 0.16 seconds on the same GPU card, for regular and\nirregular breathing, respectively. For the five lung cancer patients, the average tumor\nlocalization error is below 2 mm in both the axial and tangential directions. The average\ncomputation time on the same GPU card ranges between 0.26 and 0.34 seconds.\nConclusions: Through a comprehensive evaluation of our algorithm, we have established\nits accuracy in 3D tumor localization to be on the order of 1 mm on average and 2 mm at\n95 percentile for both digital and physical phantoms, and within 2 mm on average and 4\nmm at 95 percentile for lung cancer patients. The results also indicate that the accuracy is\nnot affected by the breathing pattern, be it regular or irregular. High computational\nefficiency can be achieved on GPU, requiring 0.1 - 0.3 s for each x-ray projection.\nKey words: image reconstruction, tumor localization, GPU, lung cancer radiotherapy\n\n1\n\n\f46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n\nI. INTRODUCTION\nIn modern lung cancer radiotherapy, it is important to have a precise knowledge of real-time lung\ntumor position during the treatment delivery1. Lung tumor localization methods can be broadly\ncategorized as direct tumor localization, localization via breathing surrogates, and localization of\nimplanted markers. Localization based on implanted markers has been shown to be highly\naccurate2. The major drawback is the invasive procedure of marker implantation and the\nassociated risk of pneumothorax3. Surrogate-based localization sometimes involves no additional\nradiation dose to the patient (e.g., optical localization) but suffers from the varying relationship\nbetween tumor motion and surrogates both intra- and inter- fractionally4, 5. Current radiotherapy\ntreatment machines are usually equipped with an on-board imaging system, which consists of one\nkV x-ray source and one flat panel imager. Lung tumors may thus be tracked directly without\nimplanted markers in fluoroscopic images acquired by the on-board imaging system6-9.\nDrawbacks of existing direct localization techniques include: 1) they work well mainly for\nimages acquired from the anterior-posterior (AP) direction and the tumors with well-defined\nboundaries; 2) they usually require the training fluoroscopic data acquired and labeled prior to\ntreatment; 3) the third dimension of tumor motion perpendicular to the x-ray imager cannot be\nresolved.\nThese drawbacks may be overcome if a good lung motion model is used for direct tumor\nlocalization. Zeng et al. used a generic B-spline lung motion model10 to estimate 3D respiratory\nmotion from cone beam projections. However, because of the large number of parameters in the\nmodel, multiple projections (over a 180\u00b0 gantry rotation) are required to obtain a reasonable\nestimate for the model parameters. The estimation is thus retrospective and the computation\ntakes quite a long time (several hours on MATLAB). It is clearly not sufficient for use in realtime tumor localization, which has to be done on a sub-second scale. Zhang et al. developed a\nlung motion model based on principal component analysis (PCA), which can efficiently represent\nthe lung motion with only a few eigenvectors and PCA coefficients11. The PCA lung motion\nmodel has recently been shown to bear a close relationship with the physiological 5D lung motion\nmodel proposed by Low et al.12 on a theoretical basis13. It is the implicit regularization and high\nefficiency of the PCA lung motion model that allows one to derive the dynamic lung motion in a\nreasonably accurate and efficient way, given a very limited amount of information, e.g., a single\nx-ray projection.\nIn our previous work14, we have described an algorithm based on the PCA lung motion model and\ndemonstrated the feasibility of reconstructing volumetric images and extracting 3D tumor motion\ninformation in real time from a single x-ray projection using a digital respiratory phantom with\nregular breathing patterns. In this paper, we will present a detailed description of our improved\nalgorithm and extend the scope of our previous work. In particular, the new contributions of this\nwork relative to our previous work14 are: 1) a comprehensive evaluation of the algorithm for 3D\ntumor localization using digital and physical respiratory phantoms as well as lung cancer patients\nwith both regular and irregular breathing patterns, which are different from those in the training\ndataset; 2) improved efficiency obtained from better initialization of the PCA coefficients using\nprediction methods.\n\nII. METHODS AND MATERIALS\nFor completeness, we first briefly describe the methods for volumetric image reconstruction,\nwhich were first presented by Li et al14. We also discuss ways to further speed up the\noptimization. Then, we test our algorithm using cone beam CT (CBCT) projections in three\ndifferent scenarios, namely, a digital respiratory phantom, a physical respiratory phantom, and\nfive lung cancer patients. We reconstructed the volumetric image and derived the 3D tumor\n2\n\n\f98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n\nlocation corresponding to each CBCT projection. To quantify the accuracy of our algorithm for\ntumor localization, we used the average absolute error (denoted as \u0001\u0305 ) as well as the absolute error\nat 95 percentile (denoted as \u0001\u0003\u0004 ).\n\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n\nwhere x(t ) is the parameterized DVF as a function a space and time, x is the mean DVF with\nrespect to time; u k are the eigenvectors obtained from PCA and are functions of space; the\n\nII.A. Methods\nOur method for volumetric image reconstruction and 3D tumor localization uses 4DCT from\ntreatment simulation as a priori knowledge. Deformable image registration is performed between\na reference phase and the other phases, resulting in a set of deformation vector fields (DVFs).\nThis set of DVFs can be represented efficiently by a few eigenvectors and coefficients obtained\nfrom PCA. By changing the PCA coefficients, we can generate a new DVF. A new volumetric\nimage can be obtained when the DVF is applied on the reference image. We then optimize the\nPCA coefficients such that its computed projection image matches the measured one of the new\nvolumetric image. The 3D location of the tumor can be derived by applying the inverted DVF on\nits position in the reference image.\nIn the PCA lung motion model11, the DVF relative to a reference image as a function of space and\ntime is approximated by a linear combination of the sample mean vector and a few eigenvectors\ncorresponding to the largest eigenvalues, i.e.,\n\nx(t ) \u2248 x + \u2211 k =1 u k wk (t ) .\nK\n\n(1)\n\nscalars wk (t ) are PCA coefficients and are functions of time. It is worth mentioning that the PCA\nmotion model is so flexible that it is capable of represent tumor motion which is beyond that of\nthe training set. For instance, if the PCA coefficients are allowed to change arbitrarily, then given\ntwo eigenvectors, the tumor can move anywhere in a plane defined by the corresponding entries\nin the eigenvectors, and thus hysteresis motion can be handled; given three eigenvectors, the\ntumor can move anywhere in the space. The reason for this is that each voxel is associated with\nthree entries (corresponding to three canonical directions in space) in each and every eigenvector.\nTherefore, each eigenvector defines a vector (or a direction) in space along which each voxel\nmoves; two eigenvectors span a plane; and three eigenvectors span the entire 3D space where the\ntumor can move. This important feature enables the PCA motion model to capture a wide range\nof tumor motion trajectories. In this study, we kept the first three PCA coefficients in the PCA\nlung motion model. This is mainly motivated by the fact that three is the least number of PCA\ncoefficients that are capable of capturing a full 3D tumor motion trajectory. On the other hand,\nusing more PCA coefficients, although more flexible, could lead to the overfitting problem and is\nnot necessary.\nAfter we have obtained a parameterized PCA lung motion model, we seek a set of optimal PCA\ncoefficients such that the projection of the reconstructed volumetric image corresponding to the\nnew DVF matches with the measured x-ray projection. Denote f 0 as the reference image, f as\nthe reconstructed image, y as the measured projection image, and P as a projection matrix\nwhich computes the projection image of f . The cost function is:\n2\n\n141\n\nmin .J ( w, a, b ) = P \u22c5 f ( x, f0 ) \u2212 a \u22c5 y \u2212 b \u22c5 1 2\n\n(2)\n\ns.t. x = x + U \u22c5 w\n142\n143\n144\n\nwhere, U is a matrix whose columns are the PCA eigenvectors and w is a vector comprised of\nthe PCA coefficients to be optimized, x is the parameterized DVF, and \u2016\u2219\u2016\u0007 denotes the standard\nvector \b\u0007 -norm. Because the computed and measured projection images may have different pixel\n3\n\n\f145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n\nintensity levels, we assume there exists a linear relationship between them and introduce two\nauxiliary parameters and to account for the differences. In the Appendix we describe in detail\nthe optimization of the cost function with respect to w, a, b .\n\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n\nwhere, wk 0 (t ) is the initial guess for the kth PCA coefficients for the current\nprojection; wk \u2217 (t \u2212 l ) is the optimized k-th\nPCA coefficients for previous l-th\nprojections. Note that each PCA coefficient\nhas a prediction model associated with it\nsince they have different dynamics.\n\nSelecting good initial conditions for the parameters may help speed up the convergence of the\nalgorithm. In our previous work14, we\ninitialized the PCA coefficients to those\n1: Load data: P, y, f 0\nobtained for the last projection. A better\napproach is to consider the last few\nprojections and initialize the PCA\n2: Set step size \u03bc = \u03bc0\ncoefficients to their predicted values,\ntaking into account the respiratory\ndynamics. This might become important\n3: Initialize w according to Eq. (3)\nwhen the imaging frequency is low. There\nis a vast amount of literature on respiratory\nmotion prediction models15-17 that we can\n4: Update a, b\nuse. In this paper, we used a simple linear\n16\naccording\nto Eq. (A.1)\nprediction model which predicts the\ncurrent sample using a linear combination\nof several previous samples, i.e.,\nL\n5: Compute gradient \u2202J/\u2202w\n(3)\nwk 0 (t ) = \u2211 l =1 ckl \u22c5 wk \u2217 (t \u2212 l )\n\nIn this paper, we utilize the training set\n(i.e., 4DCT) to build the prediction model\n(alternatively, the first few breathing cycles\nduring the CBCT scan may be used to\nbuild the prediction model). Because the\nsampling rate for 4DCT and CBCT scan is\ndifferent (for instance, for a patient with a\n4-sec breathing period, the sampling rate\nfor 4DCT is 2.5 Hz if 10 phases were\nreconstructed; on the other hand, the\nsampling rate for CBCT projections is\nfaster, usually on the order of 10 Hz for a\ntypical 1-min scan with around 600\nprojections), we first interpolated the PCA\ncoefficients from the training set and resampled to have the same frequency as in\nCBCT scan. Then the model fitting process\nwas done separately for each of the PCA\ncoefficients since they are assumed to be\nindependent in the PCA motion model.\nHere, we would like to point out that the\n\n6: Apply Armijo's rule to find \u03bc\n\n7: Is \u03bc less\nthan 0.1?\n\nYes\n\nNo\n8: Update w according to Eq. (A.2)\n\n9: Update x and f\nNo\n\n10: Enough\niterations (>10)?\nYes\n11: Compute inverse DVF\n12: Output tumor position and\nreconstructed image\n\nFig. 1. The flow chart of the proposed algorithm\nfor volumetric image reconstruction and tumor\nlocalization based on a single x-ray projection. For\nthe meaning of step size and gradient as well as\nexpressions of Eq. (A.1), Eq. (A.2), refer to the\nAppendix.\n\n4\n\n\f195\n196\n197\n198\n199\n200\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n\nprimary goal of the prediction model is to obtain a \"good\" initial guess for the PCA coefficients,\nso that the efficiency of the algorithm may be improved. For this purpose, the linear model used\nhere seems sufficient.\nIn order to get the current tumor position, we note that the DVF found by Eq. (2) is a pull-back\nDVF, which is defined on the coordinate of the new image and tells how each voxel in the new\nimage moves. It cannot be used directly to calculate the tumor position in the new image unless\nthe DVF is rigid everywhere. To get the correct tumor position, we need its inverse, i.e., the pushforward DVF, which is defined on the coordinate of the reference image and tells how each voxel\nin the reference image moves. In this work, we adopted an efficient fixed-point algorithm for\ndeformation inversion, which has been shown to be about 10 times faster and yet 10 times more\naccurate than conventional gradient-based iterative algorithms18. Since we are primarily\nconcerned with the tumor motion, it is not necessary to apply the deformation inversion\nprocedure on the entire image. Instead, it is applied on only one voxel, which corresponds to the\ntumor center of volume in the reference image. Finally, we summarize our algorithm in a flow\nchart, as shown in Fig. 1.\nTo achieve real-time efficiency, we have implemented our algorithm on graphic processing units\n(GPUs). For this work, we used compute unified device architecture (CUDA) as the\nprogramming environment and an NVIDIA Tesla C1060 GPU card.\nFor evaluation purposes, we used the end of exhale (EOE) phase in 4DCT as the reference image\nand performed deformable image registration (DIR) between the EOE phase and all other phases.\nThe DIR algorithm used here is a fast demons algorithm implemented on GPU19. Then PCA was\nperformed on the nine DVFs from DIR and three PCA coefficients and eigenvectors were kept in\nthe PCA lung motion model (except for the physical phantom, where the motion is along the\nlongitudinal axis so that only one PCA coefficient is necessary). For the prediction model in Eq.\n(3), we selected L = 2 in all the cases.\nII.B. Digital respiratory phantom\nThe algorithm was first tested using a non-uniform rational B-spline (NURBS) based cardiactorso (NCAT) phantom20. In this work, we considered three fundamental breathing parameters:\nnamely amplitude, period, and baseline shift relative to the training dataset. In the case of regular\nbreathing, we first used the same breathing parameters as those in the training set and generated\ntesting volumetric images. We then systematically changed the breathing pattern such that each\ntime, only one of the three parameters was changed while the other two were kept the same as\nthose in the training set. In doing so, we can independently evaluate the effects of each of the\nthree breathing parameters. The different breathing parameters considered in this work are:\namplitude (diaphragm motion: 1 cm and 3 cm), period (3 s and 5 s), and baseline shift (1 cm\ntoward the EOE phase and EOI phase). In the case of irregular breathing, we used a scaled\nversion of the breathing signal of a real patient acquired by the Real-time Position Management\n(RPM) system (Varian Medical Systems, Palo Alto, CA, USA). The dynamic NCAT phantom\nmotion can be generated by specifying the diaphragm SI motion. In this case, the scaled RPM\nsignal was then used as a substitute for the diaphragm SI motion of the NCAT phantom. The\nbreathing signal from RPM has a varying breathing amplitude (between 1.0 and 2.5 cm), period\n(between 3.5 and 6.2 s), and a baseline shift of about 1 cm.\nAfter we obtained the dynamic NCAT phantom, we then simulated 360 cone beam projections\nusing the Siddon's algorithm21 from angles that are uniformly distributed over one full gantry\nrotation (i.e., the angular spacing between consecutive projections is 1\u00b0). For instance, the cone\nbeam projection at angle 180\u00b0 corresponds to the dynamic phantom at 30 sec, and the projection\n5\n\n\f247\n248\n249\n250\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n\nat angle 360\u00b0 corresponds to the dynamic phantom at 60 sec, and so on. Since the gantry rotation\nlasts 60 seconds, the sampling rate of the cone beam projections is 6 Hz. We did not add any\nquantum noise in the simulated x-ray projections for the digital phantom cases. However,\nintrinsic quantum noise is present in all physical phantom and patient projections and no noise\nreduction was attempted on those images. The imager has a physical size of 40\u00d730 cm2. For\nefficiency considerations, we down-sampled every measured projection image to a resolution of\n200\u00d7150 (pixel size: 2\u00d72 mm2).\nII.C. Physical respiratory phantom\nThe algorithm was also tested on a simple physical respiratory phantom. The phantom consisted\nof a cork block resting on a platform that can be programmed to undergo translational motion in\none dimension. This platform was used to simulate the SI respiratory motion of a lung tumor.\nInside the cork block were embedded several tissue-like objects including a 2.5 cm water balloon\nwhich was used as the target for localization. More detailed descriptions of the phantom can be\nfound in Lewis et al.9.\n4DCT of the physical phantom was acquired using a GE four-slice LightSpeed CT scanner (GE\nMedical Systems, Milwaukee, WI, USA) and the RPM system. During the 4DCT scan, the\nphysical phantom moved according to a sinusoidal function along the SI direction, with a peakto-peak amplitude of 1.0 cm. In order to calculate the correct projection matrix and image for the\nalgorithm, the CT image corresponding to the EOE phase in 4DCT was re-sampled in space to\nhave the same spatial resolution as CBCT and then rigidly registered to the CBCT. Since only\nrigid registration was performed at this stage, in reality, paired kV radiographs may also be used\nto achieve this task during patient setup. Cone-beam projections were acquired using Varian OnBoard Imager 1.4 in full-fan mode with 100 kVp, 80 mA and 25 ms exposure time. The x-ray\nimager has a physical size of 40\u00d730 cm2 and each projection image has a resolution of 1024\u00d7768.\nFor testing purposes, we performed two CBCT scans for the physical phantom: one with regular\nbreathing, and the other with irregular breathing. For the case of regular breathing, the phantom\nmoved according to a sinusoidal function along the SI direction, with an increased peak-to-peak\namplitude of 1.5 cm. For the case of irregular breathing, the phantom moved according to the\nsame RPM signal used for the digital phantom as described before, with the peak-to-peak\namplitude scaled to 1.5 cm. In both cases, 359 bone beam x-ray projections were acquired over an\narc of around 200\u00b0 with a frequency of about 10.7 Hz. The CBCT scans for the physical phantom\nlasted for about 36 s, so only the first 36 s of the RPM signal was used during the scan. Since the\nmotion of the physical phantom during the CBCT scan is known, it was used as the ground truth\nto evaluate the accuracy of target localization.\nThe following preprocessing was performed on each of the cone beam x-ray projections. First,\ndue to the presence of the full-fan bow-tie filter near the x-ray source, a systematic bias will be\nintroduced in the linear relations between the image intensities of the simulated and measured\nprojections. So an in-air x-ray projection with exactly the same imaging protocol was acquired in\norder to correct for the systematic bias. This was done by dividing each pixel intensity value of\nthe projection images acquired for the physical phantom by those in the in-air projection image.\nEach corrected projection image was then down-sampled by a factor of 4, resulting in a resolution\nof 256\u00d7192 (pixel size: 1.56\u00d71.56 mm2). The rationale and effect of downsampling will be\ndiscussed later in the paper.\n\n6\n\n\f299\n300\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n\nII.D. Patient data\nFinally, the algorithm was evaluated with five patient data sets. Both 4DCT and CBCT were\nacquired using the same imaging systems as for the physical phantom. The cone beam projections\nwere taken with the imaging system in half-fan mode with 110 kVp, 20 mA and 20 ms exposure\ntime. Similarly to the physical phantom, the CT at the EOE phase was re-sampled in space and\nthen rigidly registered to the CBCT according to the bones. The same preprocessing on each of\nthe raw cone beam projections of the patient was used as for the physical phantom, namely,\ncutoff, downsampling, and a logarithm transform, except for the bow-tie filter correction, which\nwas based on the half-fan mode. For patient 2, however, since the computed projections of the\n4DCT did not have sufficient longitudinal coverage compared with the cone beam projections, an\nadditional 3 cm was cut off from the raw cone beam projections in both superior and inferior\ndirections.\nFor all patients in this study, there were no implanted fiducial makers and real-time 3D location\nof the tumor was not available to evaluate our algorithm. Instead, we projected the estimated 3D\ntumor location onto the 2D imager and compared with that manually defined by a clinician. The\npatients chosen for this study had tumors that were visible to the clinician in some of the cone\nbeam projections. From the clinician-defined contour, the tumor centroid position was calculated\nfor each projection and used as the ground truth to evaluate the algorithm. We calculated the\ntumor localization error along the axial and tangential directions, both scaled back to the mean\ntumor position. The axial direction is defined to be along the axis of rotation on the imager and\nthe tangential direction is perpendicular to the axis of rotation on the imager. For a tumor located\nnear the isocenter, the tumor motion along the axial direction on the imager is roughly a scaled\nversion of its SI motion in the patient coordinate system. On the other hand, the tumor motion\nalong the tangential direction is a mixture of its AP and LR motions depending on the imaging\nangle. In some special cases, the tumor motion along the tangential direction can be roughly a\nscaled version of either the AP motion (for imaging angles near LR or RL) or LR motion (for\nimaging angles near AP or PA). Since the tumor is hard to see in some of the projections, the\nuncertainty in the definition of ground truth can be large, and may depend on the angle at which a\nprojection is taken. A rough estimate of the uncertainty in the ground truth based on comparing\ncontours drawn from two observers suggests that the error in centroid position is about 1-2 mm\non average.\nFor each patient, approximately 650 projections were acquired over a full gantry rotation with a\nfrequency of about 10.7 Hz. However, since the cone beam scans were performed in the half-fan\nmode (with the imager shifted about 14.8 cm laterally), and isocenter of the scan was not placed\nat the tumor, the tumor is only visible in a subset of these projections. For each patient, the tumor\nwas marked by the clinician in the largest continuous set of projections in which the tumor was\nvisible. For the five patients, the number of cone beam projections used for this study ranged\nbetween 70 and 281, corresponding to angles of 39o and 155o, respectively.\nII.E. Summary of testing cases\nTable 1 summarizes all the testing cases in this work, including 8 digital phantom cases, 2\nphysical phantom cases, and 5 lung cancer patient cases. The table lists the relevant breathing\nparameters that were used during the CBCT scan for tumor localization purposes. It also includes\ninformation on the tumor size, location, as well as motion characteristics as measured in 4DCT\nfor the 5 lung cancer patients.\n\n7\n\n\f349\n350\n351\n352\n\n353\n354\n355\n356\n357\n358\n359\n360\n\n361\n362\n363\n364\n365\n366\n367\n368\n369\n\nTable 1. Summary of all testing cases. For the digital phantom, the breathing parameters in the training\ndataset are: 2 cm amplitude, 4 s period, and 0 cm baseline shift; for cases 2 through 7, all breathing\nparameters are the same as in training dataset except the one indicated in the table. All parameters for lung\ncancer patients were measured in 4DCT.\nCase #\nCategory\nRelevant Parameters\n1\nDigital phantom 1\nSame as training\n2\nDigital phantom 2\nAmplitude changed to 1 cm\n3\nDigital phantom 3\nAmplitude changed to 3 cm\n4\nDigital phantom 4\nPeriod changed to 3 s\n5\nDigital phantom 5\nPeriod changed to 5 s\n6\nDigital phantom 6\nBaseline shift changed to 1 cm toward the EOE phase\n7\nDigital phantom 7\nBaseline shift changed to 1 cm toward the EOI phase\n8\nDigital phantom 8\nBreathing changed to irregular patient breathing\n9\nPhysical phantom 1\nAmplitude changed to 1.5 cm (training: 1 cm)\n10\nPhysical phantom 2\nBreathing changed to irregular patient breathing\n11\nLung cancer patient 1\n2.7 cm3 tumor at right lower lobe; 20 mm tumor motion\n12\nLung cancer patient 2\n18.3 cm3 tumor at left lower lobe; 17 mm tumor motion\n13\nLung cancer patient 3\n8.1 cm3 tumor at left upper lobe; 5 mm tumor motion\n14\nLung cancer patient 4\n3.3 cm3 tumor at right lower lobe; 11 mm tumor motion\n15\nLung cancer patient 5\n10.2 cm3 tumor at left lower lobe; 12 mm tumor motion\n\nIII.\n\nResults\n\nTable 2. Summary of localization accuracy and computational time for all testing cases. For the description\nof each case, refer to Table 1. For Cases 1 through 10 (digital and physical phantoms), the localization\nerrors were computed in 3D; for Cases 11 through 15 (lung cancer patients), the localization errors were\ncomputed on the axial and tangential directions with respect to the imager.\nCase #\nTime (s)\n\u0001\u0305 (mm)\n\u0001\u0003\u0004 (mm)\n1\n0.8\n1.8\n0.20 \u00b1 0.05\n2\n0.7\n1.7\n0.19 \u00b1 0.05\n3\n0.8\n1.8\n0.22 \u00b1 0.06\n4\n0.8\n1.8\n0.20 \u00b1 0.05\n5\n0.8\n1.8\n0.20 \u00b1 0.05\n6\n0.8\n1.6\n0.24 \u00b1 0.05\n7\n0.8\n1.8\n0.24 \u00b1 0.05\n8\n0.8\n1.6\n0.26 \u00b1 0.06\n9\n0.8\n2.2\n0.13 \u00b1 0.04\n10\n0.8\n2.4\n0.16 \u00b1 0.05\n\u2212\nAxial\nTangential\nAxial\nTangential\n\u2212\n11\n1.5\n1.8\n3.1\n3.6\n0.29 \u00b1 0.07\n12\n1.9\n1.8\n3.7\n3.8\n0.31 \u00b1 0.12\n13\n0.4\n0.9\n1.0\n2.5\n0.26 \u00b1 0.04\n14\n0.9\n1.0\n2.1\n2.4\n0.34 \u00b1 0.09\n15\n1.1\n0.4\n2.7\n1.2\n0.33 \u00b1 0.11\n\nIII.A. Results for the digital respiratory phantom\nFigure 2 shows the SI tumor position estimated by our algorithm as well as the ground truth for\nthe digital respiratory phantom for Cases 1 through 8. The numerical results for localization\naccuracy and computational time are summarized in Table 2. The average 3D tumor localization\nerror for regular breathing with different breathing parameters is less than 1 mm, which does not\nseem to be affected by amplitude change, period change, or baseline shift. The same holds true\nfor irregular breathing.\n8\n\n\fSI tumor position (cm)\n\n15\n\nSI tumor position (cm)\n\n15\n\nSI tumor position (cm)\n\n370\n\n15\n\nCase 1\n14\n13\n12\n11\n\n0\n\n50\n\n100\n\n150\n200\nProjection angle (degree)\n\n250\n\n300\n\n350\n\n50\n\n100\n\n150\n200\nProjection angle (degree)\n\n250\n\n300\n\n350\n\n50\n\n100\n\n150\n200\nProjection angle (degree)\n\n250\n\n300\n\n350\n\n50\n\n100\n\n150\n200\nProjection angle (degree)\n\n250\n\n300\n\n350\n\n50\n\n100\n\n150\n200\nProjection angle (degree)\n\n250\n\n300\n\n350\n\n371\nCase 2\n14\n13\n12\n11\n\n0\n\n372\n14\n13\n12\nCase 3\n11\n\n0\n\nSI tumor position (cm)\n\n373\n15\n14\n13\n12\n11\n\nCase 4\n0\n\nSI tumor position (cm)\n\n374\n\n375\n\n15\n14\n13\n12\nCase 5\n11\n\n0\n\n9\n\n\fSI tumor position (cm)\n\n15\nCase 6\n14\n13\n12\n11\n\n0\n\n50\n\n100\n\n150\n200\nProjection angle (degree)\n\n250\n\n300\n\n350\n\n50\n\n100\n\n150\n200\nProjection angle (degree)\n\n250\n\n300\n\n350\n\n50\n\n100\n\n150\n200\nProjection angle (degree)\n\n250\n\n300\n\n350\n\nSI tumor position (cm)\n\n376\n15\n14\n13\n12\n11\n\nCase 7\n0\n\nSI tumor position (cm)\n\n377\n\n378\n379\n380\n381\n382\n383\n\n15\n14\n13\n12\nCase 8\n11\n\n0\n\nFig. 2. SI tumor position estimated by our algorithm (black circles) and the ground truth (solid line) for the\ndigital phantom (Cases 1 through 8).\n\nFrom the re-sampled PCA coefficients in the training set, the prediction models were estimated\nas:\n\nw1,0 (t ) = 1.90w1\u2217 (t \u2212 1) \u2212 0.98w1\u2217 (t \u2212 2)\nw2,0 (t ) = 1.51w2\u2217 (t \u22121) \u2212 0.84w2\u2217 (t \u2212 2)\n\u2217\n3\n\n(4)\n\n\u2217\n3\n\nw3,0 (t ) = 0.97 w (t \u2212 1) \u2212 0.84w (t \u2212 2)\n\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\n\nBy initializing the PCA coefficients to their predicted values using the above equations, the\naverage computation time for both regular and irregular breathing ranges between 0.19 and 0.26\nseconds using an NVIDIA Tesla C1060 GPU card. Particularly, the average computation time is\n0.22 seconds in the case of regular breathing with a breathing amplitude of 3 cm. This is about\n10% less than that previously reported14 using the PCA coefficients from the previous projection.\nIn the case of irregular breathing, the average computation time is 0.26 \u00b1 0.06 seconds. The slight\nincrease in computation time for irregular breathing was mainly due to a decreased accuracy of\nthe prediction model used for parameter initialization.\nIII.B. Results for the physical respiratory phantom\nFigure 3 shows the estimated and ground truth tumor position in the SI direction for both regular\nand irregular breathing. The numerical results for localization accuracy and computational time\nare summarized in Table 2 (Cases 9 and 10). The average 3D tumor localization error for both\nregular and irregular breathing is less than 1 mm.\n10\n\n\fWhen PCA coefficients were initialized to their predicted values, the average computation time\non GPU is 0.13 seconds and 0.16 seconds, for regular and irregular breathing, respectively. The\nreduced computation time compared with the NCAT phantom is mainly due to the less number of\nPCA coefficients used for the physical phantom.\nSI tumor position (cm)\n\n403\n404\n405\n406\n407\n408\n\nSince only one PCA coefficient was used for the physical phantom, the prediction model was\nestimated as:\nw1,0 (t ) = 1.96w1\u2217 (t \u2212 1) \u2212 0.99w1\u2217 (t \u2212 2)\n(5)\n\n1.5\n1\n0.5\n0\nCase 9\n\n-150\n\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n\nSI tumor position (cm)\n\n400\n401\n402\n\n-100\n-50\nProjection angle (degree)\n\n2\n1.5\n1\n0.5\nCase 10\n\n0\n\n0\n\n-150\n\n-100\n-50\nProjection angle (degree)\n\n0\n\nFig. 3. SI tumor position estimated by our algorithm (black circles) and the ground truth (solid line) for the\nphysical phantom (Cases 9 and 10). Left: regular breathing; Right: irregular breathing.\n\nIII.C Results for the patient data\nResults for the five lung cancer patients are shown in Fig. 4, where the tumor positions on the\naxial and tangential directions are shown separately. All five patients had somewhat irregular\nbreathing during the CBCT scans especially for patient 2 (Case 12) and the last breathing cycle of\npatient 4 (Case 14). Again, the numerical results for localization accuracy and computational time\nare summarized in Table 2 (Cases 11 through 15). For all five patients, the average 3D tumor\nlocalization error is less than 2 mm and the absolute error at 95 percentile is less than 4 mm on\nboth axial and tangential directions. When PCA coefficients were initialized to their predicted\nvalues, the average computation time on GPU is between 0.26 seconds and 0.34 seconds for the\nfive patients.\nFigure 5 shows the image reconstruction and tumor localization results for patient 1 at an EOE\nphase and an EOI phase (indicated in Figure 4, Case 11), as well as the corresponding cone beam\nx-ray projections. Although it is hard to see the tumor on the projections, it is clearly visible in the\ncoronal and sagittal slices of the reconstructed images.\n\n11\n\n\fa\n-150\n-100\nProjection angle (degree)\n\n0\n-5\n\n-150\n-100\nProjection angle (degree)\n\n-50\n\n5\n\nCase 12\n\n0\n-0.5\n\nCase 12\n\n0\n-5\n\n-10\n\n-1\n0\n\n50\n100\nProjection angle (degree)\n\n-15\n\n150\n\n0\n\n50\n100\nProjection angle (degree)\n\n150\n\nTangential\ntumor position (cm)\n\n4\nCase 13\n\n-10\n-10.2\n-10.4\n\n2\n0\n-2\nCase 13\n\n-4\n-150 -140 -130 -120 -110 -100\nProjection angle (degree)\n\n-150 -140 -130 -120 -110 -100 -90\nProjection angle (degree)\nCase 14\n\n0.5\n0\n-0.5\n-100\n\n-80\n-60\n-40\n-20\n0\nProjection angle (degree)\n\n5\n0\nCase 14\n\n-5\n-100\n\n20\n\n-7\n\n-80\n\n-60\n-40\n-20\n0\nProjection angle (degree)\n\n20\n\n-2\n\n-8\n-9\nCase 15\n\n-10\n-50\n\n-90\n\n10\n\n1\n\nTangential\ntumor position (cm)\n\nAxial tumor position (cm)\nAxial tumor position (cm)\n\nCase 11\n\n-10\n\n-50\n\n0.5\n\n434\nAxial tumor position (cm)\n\n5\n\nTangential\ntumor position (cm)\n\nAxial tumor position (cm)\n\n1\n\n432\n\n433\n\nTangential\ntumor position (cm)\n\n3\n\nTangential\ntumor position (cm)\n\nAxial tumor position (cm)\n\n4\n\n431\n\n435\n436\n437\n438\n\nb\n\nCase 11\n\n5\n\n-40\n-30\n-20\nProjection angle (degree)\n\n-4\n-6\nCase 15\n\n-8\n-50\n\n-10\n\n-40\n-30\n-20\nProjection angle (degree)\n\n-10\n\nFig. 4. Tumor positions estimated by our algorithm (black circles) and the ground truth (solid line) for five\nlung cancer patients (Cases 11 to 15). Left: axial tumor position; Right: tangential tumor position. The two\n\n12\n\n\f439\n440\n441\n\narrows (\"a\" and \"b\") in the left plot of patient 1 (Case 11) indicate the two angles where the image\nreconstructions results are shown in Fig. 5.\n\n442\n\n443\n444\n\n445\n446\n447\n448\n449\n450\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n\nFig. 5. Image reconstruction and tumor localization results for patient 1. Left column: raw cone beam\nprojection (top) and the corresponding coronal and sagittal views of the reconstructed image at angle 146.5\u00b0 at an EOE phase (arrow \"a\" in Fig. 4). Right column: same as left column, except for angle -74.5\u00b0 at\nan EOI phase (arrow \"b\" in Fig. 4). Red arrow indicates where the tumor was. The solid line represents the\nestimated tumor SI position at the current phase; the dashed line represents the estimated tumor SI position\nat the other phase.\n\nThere is a tradeoff between the localization accuracy and computational time, which is dependent\non the resolution of the projection image. Intuitively, as the image resolution is increased, the\nlocalization error would decrease; at the same time, the resulting computational time will\nnaturally increase. To investigate the effect of the projection image resolution, we took the\noriginal cone beam x-ray projection images with a resolution of 1024\u00d7768 for patient 1 (Case 11)\nand down-sample them by a factor of 1, 2, 4, 8, 16, 32 on both dimensions of the projection\nimages. The resulting images have the resolution of 1024\u00d7768, 512\u00d7384, 256\u00d7192, 128\u00d796,\n64\u00d748 and 32\u00d724, respectively. Figure 6 shows the average localization error on tangential and\naxial directions as well as computational time versus the downsampling factor. As expected, the\naverage localization error increases monotonically as the downsampling factor increases.\nHowever, downsampling the projection image by a factor of 4 does not increase the localization\n13\n\n\ferror noticeably. On the other hand, the computation time decreases monotonically as the\ndownsampling factor increases, but flattens out once it reaches 8. This supports the choice of a\nresolution of 256\u00d7192 (downsampling factor: 4) for the projection image used in this study,\nbecause it achieves a reasonable balance between the localization accuracy and computational\ntime. Whether this observation holds true in general for clinical cases deserves further\ninvestigation.\n\nAverage localization error (mm)\n\n3\nTangential\nAxial\nTime\n\n2.5\n\n0.8\n0.7\n0.6\n\n2\n0.5\n0.4\n\n1.5\n\n0.3\n1\n\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n\n0.9\n\nTime (s)\n\n464\n465\n466\n467\n468\n469\n470\n\n1\n\n2\n4\n8\n16\nDownsampling factor in one dimension\n\n0.2\n32\n\nFig. 6. The average localization error on tangential and axial directions as well as computational time\nversus downsampling factor in one dimension of the x-ray imager for patient 1 (Case 11).\n\nIV.\n\nDiscussions\n\nWe have developed an algorithm to localize 3D tumor positions in near real-time from a single xray image. The algorithm was systematically tested on digital and physical respiratory phantoms\nas well as lung cancer patients. For the digital phantom, the average 3D tumor localization error is\nbelow 1 mm in the case of digital and physical phantoms. For the five lung cancer patients, the\naverage tumor localization error is below 2 mm in both the axial and tangential directions. By\nutilizing the massive computing power of GPUs, we were able to derive 3D tumor locations from\none projection around 0.3 seconds on average. Successful applications of our algorithm in the\nclinic could lead to accurate 3D tumor tracking from a single x-ray imager. Furthermore,\nvolumetric images can be reconstructed from a single x-ray projection image. This is potentially\nuseful for many clinical applications such as dose verification in lung cancer radiotherapy.\nThe tumor localization error in this work arises from two different processes: 1), the PCA lung\nmotion model; 2), the 2D to 3D deformable registration between the projection and the reference\nimage. In order to investigate how much each process contributes to the overall tumor\nlocalization error, we utilized the ground truth of the 3D lung motion in the digital NCAT\nphantom and solved for the optimal PCA coefficients by directly minimizing the mean square\nerror between the left and right sides in Eq. (1). This procedure bypassed the 2D to 3D\nregistration process, and thus gives the tumor localization error solely due to the PCA lung\nmotion model. In Case 1, this error is about 0.28 mm over all the projections. Assuming that the\n14\n\n\f496\n497\n498\n499\n500\n\nabove two processes are statistically independent, we readily obtain the error due to the 2D to 3D\nregistration process, which is about 0.75 mm. Therefore, the overall tumor localization error of\nabout 0.8 mm is mainly attributed to the 2D to 3D registration process. In comparison, the error\nintroduced by the PCA lung motion model is insignificant.\n\n501\n\n502\n\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n\nFig. 7. Measured cone beam projections after preprocessing of the image intensities (logarithm transform\nfollowed by reversion of the sign) (top row), computed projections of the reconstructed image (middle\nrow), and scatter plots between the intensities of the above two images (bottom row) for patient 1. Left\ncolumn corresponds to the EOE phase in Fig. 4 (arrow \"a\"); right column corresponds to the EOI phase in\nFig. 4 (arrow \"b\"). A linear model between the two image intensities is able to explain 94% and 91% of the\nvariance in the left and right subplot, respectively. Both linear models are significant (p < 0.001).\n\nIn this work, we have assumed a linear relationship between the image intensities of the cone\nbeam projection and of the computed projection of the reconstructed image, in order to account\nfor the differences between the two image \"modalities\". One may wonder if such an assumption\n15\n\n\f515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n550\n551\n552\n553\n554\n555\n556\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n\nis accurate in reality. After all, the x-ray energies as well as their spectra used for 4DCT and\nCBCT scans may well be different. There are several physical processes in reality (e.g.,\nscattering) which are not simulated in our computation of simulated x-ray projection. Figure 7\nshows the scatter plots between the image intensities of the preprocessed cone beam projection\nand of the computed projection of the reconstructed image at two different projection angles for\npatient 1, corresponding to the two projections shown in Fig. 5. It seems that a linear model is\nsufficient in both cases: more than 90% of the variance can be explained by a simple linear\nmodel. However, in the right subplot, because of more apparent interference from the treatment\ncouch in the cone beam projection (which is absent in the computed projections), especially near\nthe right edge, the linear model is less accurate than in the left subplot. This effect can be\nmitigated by pre-scanning the treatment couch and adding it to the reference image so that the\ncouch will be also present in the computed projections.\nThis work has focused on x-ray projections with rotational geometry. The same principle can be\neasily applied to those with fixed-angle geometry, such as fluoroscopy. The only difference is that\nthe projection matrix will be constant for fixed-angle geometry instead of varying at each angle\nfor the rotational geometry considered in this work.\nIt is possible that during the course of the treatment patients may undergo anatomical changes on\nan inter-fractional basis, which could make the results worse if the lung motion model is built\nbased on 4DCT acquired during patient simulation. In this case, a PCA lung motion model built\nfrom 4DCBCT during patient setup may overcome this difficulty. Another potential issue is when\nthe tumor gets close to the heart. Then the tumor motion will be affected not only by breathing\nmotion, but by heart motion too, which is not represented by the PCA motion model. This is a\nfundamental limitation of 4DCT, which is usually synchronized to respiration, not to cardiac\nmotion.\nAlthough the results of five lung cancer patients confirmed the validity of our algorithm on a\npreliminary basis, a more comprehensive study on a larger patient population is warranted. It is\nworth mentioning that the accuracy of the tumor localization and image reconstruction is directly\naffected by the PCA lung motion model, which is in turn influenced by the quality of the training\ndata (4DCT or 4DCBCT). Therefore, it is important to minimize the motion artifacts in the\ntraining data, e.g., by optimizing the scanning protocol or coaching the patients to breathe\nregularly whenever possible. A reliable deformable registration algorithm, especially one which\ncan accurately model large motion (e.g., around the diaphragm), is also likely to help improve the\naccuracy the PCA lung motion model. In this work, since there were no fiducial markers\nimplanted in the lung cancer patients, clinician marked tumor positions had to be used to evaluate\nthe tumor localization results. The accuracy of the ground truth is thus limited due to noisy\nprojection images as well as relatively poor soft-tissue contrast. For validation purposes, it would\nbe beneficial to have patient data with implanted fiducial markers, from which better ground truth\ncan be derived.\n\nV.\n\nConclusions\n\nIn this work, we have presented an improved algorithm for 3D tumor localization from a single xray projection image by incorporating respiratory motion prediction. Through a comprehensive\nevaluation of our algorithm, we found the localization error to be less than 1 mm on average and\naround 2 mm at 95 percentile for both digital and physical phantoms, and within 2 mm on\naverage and 4 mm at 95 percentile for five lung cancer patients on both axial and tangential\ndirections. We also found that the localization accuracy is not affected by the breathing pattern,\nbe it regular or irregular. The 3D localization can be achieved on a sub-second scale on GPU,\nrequiring approximately 0.1 - 0.3 s for each x-ray projection.\n16\n\n\f567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n\nAcknowledgment\nThis work is supported in part by Varian Master Research Agreement. We would like to thank Dr.\nPaul Segars for providing the source code to generate NCAT phantom and NVIDIA for providing\nGPU cards for this project. We would also like to thank the anonymous reviewers who gave\nvaluable comments and suggestions and helped improve this paper.\n\nAppendix\nIn this appendix, we describe in detail the optimization of the cost function in Eq. (2) with respect\nto w, a, b . The optimization algorithm alternates between the following 2 steps:\n\u22121\n\nstep 1: ( an +1 , bn +1 )T = ( YT Y ) Y T Pf n\n\n\u2202J n\n\u2202w n\n\n\u2202J n\n\u2202w n\n\n(A.1)\n\n580\n\nstep 2: w n+1 = w n \u2212 \u03bcn \u22c5\n\n581\n\n\u2202J \u2202x \u2202f \u2202J\n\u2202f\nwhere, Y = [ y, 1] , and\n=\n\u22c5 \u22c5 = 2 \u22c5 UT \u22c5 \u22c5 PT \u22c5 ( P \u22c5 f \u2212 a \u22c5 y \u2212 b \u22c5 1) .\n\u2202w \u2202w \u2202x \u2202f\n\u2202x\n\n(A.2)\n2\n\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\n600\n\nIt is easy to see that the above alternating algorithm consisting of steps 1 and 2 is guaranteed to\nconverge. In step 1, the update for a, b is the unique minimizer of the cost function with fixed w .\nStep 2 is a gradient descent method with variable w and fixed a, b, where the step size \u03bc n is\nfound by Armijo's rule22 for line search. Therefore, the cost function always decreases at each\nstep. Note that the cost function is lower bounded by zero. The above alternating algorithm is\nguaranteed to converge for all practical purposes. The parameters selected for line search are:\ninitial step size \u03bc 0 = 2 and \u03b1 = 0.1, \u03b2 = 0.5 as defined by Armijo's rule. These values generally\nlead to fast convergence and were used for all experiments in this study. The algorithm stops\nwhenever the step size for current iteration is sufficiently small (fixed at 0.1 in this paper). The\nreason is that each PCA coefficients has been preconditioned so that their standard deviation is 10\nin the training set; thus a step size of 0.1 can be considered sufficiently small and do not alter the\nresults significantly. The algorithm is also terminated when the maximum number of iterations is\nreached (fixed at 10 in this paper). In the case of largest deformation from the reference image, it\ntakes around 8 or 9 iterations for the algorithm to 'converge', in the sense that the cost function\ndoes not change much after that. Therefore, a maximum of 10 iterations should be sufficient to\nget convergent results.\nAt each iteration, given the updated PCA coefficients in Eq. (A.2), the DVF is updated according\n\n601\n\nAccordingly, \u2202f \u2202x has to be consistent with the interpolation process in order to get the correct\n\n602\n\ngradient. Next, we derive the expression for \u2202f \u2202x . Let f0 (i, j , k ) and f (i, j, k ) be the\n\n603\n604\n\nreference image and reconstructed image at iteration n indexed by the integer set\n{(i, j , k ) |1 \u2264 i \u2264 N1 ,1 \u2264 j \u2264 N 2 ,1 \u2264 k \u2264 N 3 } within the bounding box of its volume, and\n\n605\n\nx1 (i, j, k ), x 2 (i, j, k ), x3 (i, j, k ) be the deformation vector fields corresponding to the three\n\n606\n\ncanonical directions, namely, lateral, AP, and SI, respectively. They can be equivalently\n\nto Eq. (2) and the reconstructed image fn+1 is obtained through trilinear interpolation.\n\n17\n\n\f607\n608\n609\n\nreorganized into a vector whose length is the total number of voxels in the image. Then\n\u2202f \u2202x = [ \u2202f \u2202x1 ; \u2202f \u2202x2 ; \u2202f \u2202x 3 ] .\n\n610\n\nLet's look at \u2202f \u2202x1 . First notice that:\n\n611\n\nf (i, j , k ) = f 0 ( i + x1 (i, j , k ), j + x2 (i, j , k ), k + x3 (i, j , k ) )\n\n612\n613\n\nThen we have:\n\n614\n615\n616\n617\n\n\u2202f (i1 , j1 , k1 )\n\u2202f (i1 , j1 , k1 ) .\n= \u03b4 (i1 \u2212 i2 )\u03b4 ( j1 \u2212 j2 )\u03b4 (k1 \u2212 k2 ) \u22c5\n\u2202x1 (i2 , j2 , k 2 )\n\u2202x1 (i2 , j2 , k2 )\nThis means that the Jacobian matrix \u2202f \u2202x1 is a diagonal matrix.\n\n(A.3)\n(A.4)\n\nIf the continuous patient geometry can be approximated by trilinear interpolation of the discrete\nvolumetric image, then we have:\n\nf (i, j, k ) = f0 ( l , m, n ) (1 \u2212 z1 )(1 \u2212 z2 )(1 \u2212 z3 ) + f 0 ( l + 1, m, n ) z1 (1 \u2212 z2 )(1 \u2212 z3 )\n+f 0 ( l, m + 1, n ) (1 \u2212 z1 ) z2 (1 \u2212 z3 ) + f0 ( l , m, n + 1) (1 \u2212 z1 )(1 \u2212 z2 ) z3\n\n618\n\n+f 0 ( l + 1, m + 1, n ) z1 z2 (1 \u2212 z3 ) + f0 ( l + 1, m, n + 1) z1 (1 \u2212 z2 ) z3\n\n(A.5)\n\n+f 0 ( l, m + 1, n + 1) (1 \u2212 z1 ) z2 z3 + f0 ( l + 1, m + 1, n + 1) z1 z2 z3\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n\nwhere,\n\nl = \uf8ef\uf8f0i + x1 (i, j , k ) \uf8fa\uf8fb , m = \uf8ef\uf8f0 j + x 2 (i, j , k ) \uf8fa\uf8fb , n = \uf8ef\uf8f0 k + x3 (i, j , k ) \uf8fa\uf8fb are the integer parts of the DVF\nand zq = {x q (i, j , k )} , q = 1, 2,3 are the fractional parts of the DVF.\nNotice that:\n\n\u2202l \u2202x1 = \u2202m \u2202x1 = \u2202n \u2202x1 = 0\n\n(A.6)\n\nand \u2202z1 \u2202x1 = 1, \u2202z2 \u2202x1 = \u2202z3 \u2202x1 = 0\n\n(A.7)\n\nwhere, for simplicity, we have omitted the index (i, j , k ) for x1 .\nFrom Eq. (A.5)-(A.7), we immediately get:\n\n\u2202f (i, j, k ) \u2202x1 (i, j , k ) = \uf8ee\uf8f0f0 ( l + 1, m, n ) \u2212 f0 ( l , m, n ) \uf8f9\uf8fb (1 \u2212 z2 )(1 \u2212 z3 )\n629\n\n+ \uf8ee\uf8f0f0 ( l + 1, m + 1, n ) \u2212 f0 ( l , m + 1, n ) \uf8f9\uf8fb z2 (1 \u2212 z3 )\n+ \uf8ee\uf8f0f0 ( l + 1, m, n + 1) \u2212 f0 ( l , m, n + 1) \uf8f9\uf8fb (1 \u2212 z2 ) z3\n\n(A.8)\n\n+ \uf8ee\uf8f0f0 ( l + 1, m + 1, n + 1) \u2212 f0 ( l , m + 1, n + 1) \uf8f9\uf8fb z2 z3\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n\nSimilar expressions can be derived for \u2202f \u2202x 2 and \u2202f \u2202x 3 .\nA few comments are appropriate at this point. Equation (A.8) is the exact derivative given the\ncontinuous patient geometry obtained from trilinear interpolation in Eq. (A.5). Of course, any\nreasonable kind of interpolation can be used here, e.g., tricubic interpolation. Then the Jacobian\nmatrix \u2202f \u2202x1 does not have a nice diagonal form anymore, but may be block diagonal. It is clear\nfrom Eq. (A.8) that \u2202f \u2202x is a linear combination of the spatial gradients of the reference image\nevaluated at the neighboring eight grid points, weighted by the appropriate fractional parts of the\nDVF. At this stage, \u2202f \u2202x contains only local information at the level of individual voxels. It is\n18\n\n\f640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n650\n\nthe eigenvectors that effectively combine all the local information into global information and\nlead to correct update for the PCA coefficients.\nFor trilinear interpolation, f is continuous but not differentiable at the boundaries of the voxel\ngrids, so that Eq. (A.6)-(A.7) do not hold in this situation. However, this happens with a\nprobability of 0. If it does happen, Eq. (A.8) simply computes the right-side derivative and will\nnot create numerical instability. What's more, even if it happens that the DVFs are integers at a\nfew voxels, the pooling effects of the eigenvectors will almost eliminates its influence by a vast\nmajority of other voxels.\n\n19\n\n\f651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n\nReferences\n\n1.\n\n2.\n\n3.\n\n4.\n\n5.\n\n6.\n\n7.\n\n8.\n\n9.\n\n10.\n\n11.\n\n12.\n\n13.\n\nP. J. Keall, G. S. Mageras, J. M. Balter, R. S. Emery, K. M. Forster, S. B. Jiang, J.\nM. Kapatoes, D. A. Low, M. J. Murphy, B. R. Murray, C. R. Ramsey, M. B. Van\nHerk, S. S. Vedam, J. W. Wong and E. Yorke, \"The management of respiratory\nmotion in radiation oncology report of AAPM Task Group 76,\" Med Phys 33,\n3874-3900 (2006).\nT. Harada, H. Shirato, S. Ogura, S. Oizumi, K. Yamazaki, S. Shimizu, R.\nOnimaru, K. Miyasaka, M. Nishimura and H. Dosaka-Akita, \"Real-time tumortracking radiation therapy for lung carcinoma by the aid of insertion of a gold\nmarker using bronchofiberscopy,\" Cancer 95, 1720-1727. (2002).\nF. Laurent, V. Latrabe, B. Vergier, M. Montaudon, J. M. Vernejoux and J.\nDubrez, \"CT-guided transthoracic needle biopsy of pulmonary nodules smaller\nthan 20 mm: results with an automated 20-gauge coaxial cutting needle,\" Clin\nRadiol 55, 281-287 (2000).\nJ. D. Hoisak, K. E. Sixel, R. Tirona, P. C. Cheung and J. P. Pignol, \"Correlation\nof lung tumor motion with external surrogate indicators of respiration,\" Int J\nRadiat Oncol Biol Phys 60, 1298-1306 (2004).\nY. Tsunashima, T. Sakae, Y. Shioyama, K. Kagei, T. Terunuma, A. Nohtomi and\nY. Akine, \"Correlation between the respiratory waveform measured using a\nrespiratory sensor and 3D tumor motion in gated radiotherapy,\" Int J Radiat Oncol\nBiol Phys 60, 951-958 (2004).\nY. Cui, J. G. Dy, G. C. Sharp, B. Alexander and S. B. Jiang, \"Multiple templatebased fluoroscopic tracking of lung tumor mass without implanted fiducial\nmarkers,\" Phys Med Biol 52, 6229-6242 (2007).\nQ. Xu, R. J. Hamilton, R. A. Schowengerdt, B. Alexander and S. B. Jiang, \"Lung\nTumor Tracking in Fluoroscopic Video Based on Optical Flow,\" Medical Physics\n35, 5351-5359 (2008).\nT. Lin, L. I. Cervino, X. Tang, N. Vasconcelos and S. B. Jiang, \"Fluoroscopic\ntumor tracking for image-guided lung cancer radiotherapy,\" Phys Med Biol 54,\n981-992 (2009).\nJ. H. Lewis, R. Li, W. T. Watkins, J. D. Lawson, W. P. Segars, L. I. Cervino, W.\nY. Song and S. B. Jiang, \"Markerless lung tumor tracking and trajectory\nreconstruction using rotational cone-beam projections: a feasibility study,\" Phys\nMed Biol 55, 2505-2522 (2010).\nR. Zeng, J. A. Fessler and J. M. Balter, \"Estimating 3-D respiratory motion from\norbiting views by tomographic image registration,\" IEEE Trans Med Imaging 26,\n153-163 (2007).\nQ. Zhang, A. Pevsner, A. Hertanto, Y. C. Hu, K. E. Rosenzweig, C. C. Ling and\nG. S. Mageras, \"A patient-specific respiratory model of anatomical motion for\nradiation treatment planning,\" Med Phys 34, 4772-4781 (2007).\nD. A. Low, P. J. Parikh, W. Lu, J. F. Dempsey, S. H. Wahab, J. P. Hubenschmidt,\nM. M. Nystrom, M. Handoko and J. D. Bradley, \"Novel breathing motion model\nfor radiotherapy,\" Int J Radiat Oncol Biol Phys 63, 921-929 (2005).\nR. Li, J. H. Lewis, X. Jia, T. Zhao, W. Liu, S. Wuenschel, J. Lamb, D. Yang, D.\nA. Low and S. B. Jiang, \"A PCA-based lung motion model,\" Phys Med Biol\nsubmitted (2010).\n20\n\n\f698\n699\n700\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n\n14.\n\n15.\n16.\n\n17.\n18.\n19.\n\n20.\n21.\n22.\n\na\n\nR. Li, X. Jia, J. H. Lewis, X. Gu, M. Folkerts, C. Men and S. B. Jiang, \"Real-time\nvolumetric image reconstruction and 3D tumor localization based on a single xray projection image for lung cancer radiotherapy,\" Med. Phys. 37, 2822-2826\n(2010).\nM. J. Murphy, J. Jalden and M. Isaksson, presented at the Proc. 16th Int. Conf. on\nComputer Assisted Radiology (CARS 2002), Paris, France, 2002 (unpublished).\nG. C. Sharp, S. B. Jiang, S. Shimizu and H. Shirato, \"Prediction of respiratory\ntumour motion for real-time image-guided radiotherapy,\" Phys Med Biol 49, 425440 (2004).\nD. Ruan, J. A. Fessler and J. M. Balter, \"Real-time prediction of respiratory\nmotion based on local regression methods,\" Phys Med Biol 52, 7137-7152 (2007).\nM. Chen, W. Lu, Q. Chen, K. J. Ruchala and G. H. Olivera, \"A simple fixed-point\napproach to invert a deformation field,\" Med Phys 35, 81-88 (2008).\nX. Gu, H. Pan, Y. Liang, R. Castillo, D. Yang, D. Choi, E. Castillo, A. Majumdar,\nT. Guerrero and S. B. Jiang, \"Implementation and evaluation of various demons\ndeformable image registration algorithms on a GPU,\" Phys Med Biol 55, 207-219\n(2010).\nW. P. Segars, \"Development and application of the new dynamic NURBS-based\ncardiac-torso (NCAT) phantom,\" Ph.D. Dissertation (2001).\nR. L. Siddon, \"Fast calculation of the exact radiological path for a threedimensional CT array,\" Medical Physics 12, 252-255 (1985).\nM. S. Bazaraa, H. D. Sherali and C. M. Shetty, Nonlinear Programming: Theory\nand Algorithms. (Hoboken: A John Wiley & Sons, 2006).\n\nEmail: sbjiang@ucsd.edu\n\n21\n\n\f"}