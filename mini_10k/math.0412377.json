{"id": "http://arxiv.org/abs/math/0412377v1", "guidislink": true, "updated": "2004-12-19T07:14:57Z", "updated_parsed": [2004, 12, 19, 7, 14, 57, 6, 354, 0], "published": "2004-12-19T07:14:57Z", "published_parsed": [2004, 12, 19, 7, 14, 57, 6, 354, 0], "title": "Noise Stability of Weighted Majority", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0412533%2Cmath%2F0412332%2Cmath%2F0412496%2Cmath%2F0412465%2Cmath%2F0412346%2Cmath%2F0412217%2Cmath%2F0412027%2Cmath%2F0412063%2Cmath%2F0412483%2Cmath%2F0412559%2Cmath%2F0412495%2Cmath%2F0412142%2Cmath%2F0412246%2Cmath%2F0412312%2Cmath%2F0412399%2Cmath%2F0412101%2Cmath%2F0412233%2Cmath%2F0412480%2Cmath%2F0412290%2Cmath%2F0412283%2Cmath%2F0412484%2Cmath%2F0412054%2Cmath%2F0412438%2Cmath%2F0412111%2Cmath%2F0412564%2Cmath%2F0412225%2Cmath%2F0412198%2Cmath%2F0412141%2Cmath%2F0412136%2Cmath%2F0412525%2Cmath%2F0412062%2Cmath%2F0412006%2Cmath%2F0412040%2Cmath%2F0412115%2Cmath%2F0412216%2Cmath%2F0412071%2Cmath%2F0412160%2Cmath%2F0412174%2Cmath%2F0412505%2Cmath%2F0412532%2Cmath%2F0412075%2Cmath%2F0412041%2Cmath%2F0412161%2Cmath%2F0412200%2Cmath%2F0412466%2Cmath%2F0412377%2Cmath%2F0412112%2Cmath%2F0412116%2Cmath%2F0412003%2Cmath%2F0412426%2Cmath%2F0412185%2Cmath%2F0412109%2Cmath%2F0412485%2Cmath%2F0412188%2Cmath%2F0412139%2Cmath%2F0412364%2Cmath%2F0412387%2Cmath%2F0412018%2Cmath%2F0412220%2Cmath%2F0412522%2Cmath%2F0412499%2Cmath%2F0412403%2Cmath%2F0412238%2Cmath%2F0412361%2Cmath%2F0412010%2Cmath%2F0412369%2Cmath%2F0412302%2Cmath%2F0412190%2Cmath%2F0412176%2Cmath%2F0412358%2Cmath%2F0412008%2Cmath%2F0412056%2Cmath%2F0412134%2Cmath%2F0412531%2Cmath%2F0412461%2Cmath%2F0412029%2Cmath%2F0412179%2Cmath%2F0412314%2Cmath%2F0412351%2Cmath%2F0412321%2Cmath%2F0412450%2Cmath%2F0412050%2Cmath%2F0412184%2Cmath%2F0412263%2Cmath%2F0412318%2Cmath%2F0412076%2Cmath%2F0412409%2Cmath%2F0412469%2Cmath%2F0412427%2Cmath%2F0412209%2Cmath%2F0412288%2Cmath%2F0412222%2Cmath%2F0412091%2Cmath%2F0412430%2Cmath%2F0412231%2Cmath%2F0412535%2Cmath%2F0412459%2Cmath%2F0412083%2Cmath%2F0412093%2Cmath%2F0412463%2Cmath%2F0412144&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Noise Stability of Weighted Majority"}, "summary": "Benjamini, Kalai and Schramm (2001) showed that weighted majority functions\nof $n$ independent unbiased bits are uniformly stable under noise: when each\nbit is flipped with probability $\\epsilon$, the probability $p_\\epsilon$ that\nthe weighted majority changes is at most $C\\epsilon^{1/4}$. They asked what is\nthe best possible exponent that could replace 1/4. We prove that the answer is\n1/2. The upper bound obtained for $p_\\epsilon$ is within a factor of\n$\\sqrt{\\pi/2}+o(1)$ from the known lower bound when $\\epsilon \\to 0$ and\n$n\\epsilon\\to \\infty$.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0412533%2Cmath%2F0412332%2Cmath%2F0412496%2Cmath%2F0412465%2Cmath%2F0412346%2Cmath%2F0412217%2Cmath%2F0412027%2Cmath%2F0412063%2Cmath%2F0412483%2Cmath%2F0412559%2Cmath%2F0412495%2Cmath%2F0412142%2Cmath%2F0412246%2Cmath%2F0412312%2Cmath%2F0412399%2Cmath%2F0412101%2Cmath%2F0412233%2Cmath%2F0412480%2Cmath%2F0412290%2Cmath%2F0412283%2Cmath%2F0412484%2Cmath%2F0412054%2Cmath%2F0412438%2Cmath%2F0412111%2Cmath%2F0412564%2Cmath%2F0412225%2Cmath%2F0412198%2Cmath%2F0412141%2Cmath%2F0412136%2Cmath%2F0412525%2Cmath%2F0412062%2Cmath%2F0412006%2Cmath%2F0412040%2Cmath%2F0412115%2Cmath%2F0412216%2Cmath%2F0412071%2Cmath%2F0412160%2Cmath%2F0412174%2Cmath%2F0412505%2Cmath%2F0412532%2Cmath%2F0412075%2Cmath%2F0412041%2Cmath%2F0412161%2Cmath%2F0412200%2Cmath%2F0412466%2Cmath%2F0412377%2Cmath%2F0412112%2Cmath%2F0412116%2Cmath%2F0412003%2Cmath%2F0412426%2Cmath%2F0412185%2Cmath%2F0412109%2Cmath%2F0412485%2Cmath%2F0412188%2Cmath%2F0412139%2Cmath%2F0412364%2Cmath%2F0412387%2Cmath%2F0412018%2Cmath%2F0412220%2Cmath%2F0412522%2Cmath%2F0412499%2Cmath%2F0412403%2Cmath%2F0412238%2Cmath%2F0412361%2Cmath%2F0412010%2Cmath%2F0412369%2Cmath%2F0412302%2Cmath%2F0412190%2Cmath%2F0412176%2Cmath%2F0412358%2Cmath%2F0412008%2Cmath%2F0412056%2Cmath%2F0412134%2Cmath%2F0412531%2Cmath%2F0412461%2Cmath%2F0412029%2Cmath%2F0412179%2Cmath%2F0412314%2Cmath%2F0412351%2Cmath%2F0412321%2Cmath%2F0412450%2Cmath%2F0412050%2Cmath%2F0412184%2Cmath%2F0412263%2Cmath%2F0412318%2Cmath%2F0412076%2Cmath%2F0412409%2Cmath%2F0412469%2Cmath%2F0412427%2Cmath%2F0412209%2Cmath%2F0412288%2Cmath%2F0412222%2Cmath%2F0412091%2Cmath%2F0412430%2Cmath%2F0412231%2Cmath%2F0412535%2Cmath%2F0412459%2Cmath%2F0412083%2Cmath%2F0412093%2Cmath%2F0412463%2Cmath%2F0412144&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Benjamini, Kalai and Schramm (2001) showed that weighted majority functions\nof $n$ independent unbiased bits are uniformly stable under noise: when each\nbit is flipped with probability $\\epsilon$, the probability $p_\\epsilon$ that\nthe weighted majority changes is at most $C\\epsilon^{1/4}$. They asked what is\nthe best possible exponent that could replace 1/4. We prove that the answer is\n1/2. The upper bound obtained for $p_\\epsilon$ is within a factor of\n$\\sqrt{\\pi/2}+o(1)$ from the known lower bound when $\\epsilon \\to 0$ and\n$n\\epsilon\\to \\infty$."}, "authors": ["Yuval Peres"], "author_detail": {"name": "Yuval Peres"}, "author": "Yuval Peres", "arxiv_comment": "six pages", "links": [{"href": "http://arxiv.org/abs/math/0412377v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/math/0412377v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.CO", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "60C05", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/math/0412377v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/math/0412377v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:math/0412377v1 [math.PR] 19 Dec 2004\n\nNOISE STABILITY OF WEIGHTED MAJORITY\nYUVAL PERES\nAbstract. Benjamini, Kalai and Schramm (2001) showed that weighted majority functions of n independent unbiased bits are uniformly stable under noise:\nwhen each bit is flipped with probability \u01eb, the probability p\u01eb that the weighted\nmajority changes is at most C\u01eb1/4 . They asked what is the best possible exponent that could replace 1/4. We prove that the answer is 1/2. The upper bound\np\nobtained for p\u01eb is within a factor of \u03c0/2 + o(1) from the known lower bound\nwhen \u01eb \u2192 0 and n\u01eb \u2192 \u221e.\n\n1. Introduction\nIn their study of noise sensitivity and stability of Boolean functions, Benjamini,\nKalai and Schramm [2] showed that weighted majority functions of n independent\nunbiased \u00b11-valued variables are uniformly stable under noise:\n\nwhen each variable is flipped with probability \u01eb, the weighted majority changes\n\nwith probability at most C\u01eb1/4 . They asked what is the best possible exponent\nthat could replace 1/4. In this note we prove that the answer is 1/2. Denote\nsgn(u) = u/|u| for u 6= 0 and sgn(0) = 0, and let N\u01eb : Rn \u2192 Rn be the noise\noperator that flips each variable in its input independently with probability \u01eb.\n\nFormally, given a random vector X = (X1 , . . . , Xn ), the random vector N\u01eb (X) is\ndefined as (\u03c31 X1 , . . . , \u03c3n Xn ) where the i.i.d. random variables \u03c3i are independent\nof X and take the values 1, \u22121 with probabilities 1 \u2212 \u01eb, \u01eb respectively.\nTheorem 1.1. Let X = (X1 , . . . , Xn ) be a random vector uniformly distributed\nover {\u22121, 1}n . Given nonzero weights w1 , . . . , wn \u2208 R and a threshold t \u2208 R,\nconsider the weighted majority function f : Rn \u2192 {\u22121, 0, 1} defined by\nn\n\u0011\n\u0010X\nwi xi \u2212 t\nf (x) = sgn\ni=1\n\nResearch partially supported by NSF grants #DMS-0104073 and #DMS-0244479.\n1\n\n(1.1)\n\n\f2\n\nYUVAL PERES\n\nThen for \u01eb \u2264 1/2,\n\u0010\n\u0011\np\u01eb (n, w, t) = P f (X) 6= f (N\u01eb (X)) \u2264 2\u01eb1/2 .\n\n(1.2)\n\nMoreover, p\u2217\u01eb = lim supn\u2192\u221e supw,t p\u01eb (n, w, t) satisfies\np\np\u2217\nlim sup \u221a\u01eb \u2264 2/\u03c0 .\n\u01eb\n\u01eb\u21920\n\n(1.3)\n\nIn the statement of the theorem we opted for a simple formulation: Our proof\nyields the following sharper, but more involved estimate:\n\u0012\n\u0013\nn\nm\n2\nn\n2\u2212n ,\np\u01eb (n, w, t) \u2264 E |Bm \u2212 | + [1 \u2212 (1 \u2212 \u01eb) ]\n\u230an/2\u230b\nm\n2\n\n(1.4)\n\nwhere m = \u230a\u01eb\u22121 \u230b and Bm is a Binomial(m, 1/2) variable.\nIt easy to see, and classical [9, 4], that for simple majority (when all weights are\nequal) we have\nlim P(sgn\n\nn\u2192\u221e\n\nn\nX\ni=1\n\nXi 6= sgn\n\nn\nX\n1\n2\u221a\n\u01eb + O(\u01eb3/2 ) . (1.5)\n(N\u01eb X)i ) = arccos(1 \u2212 2\u01eb) =\n\u03c0\n\u03c0\ni=1\n\nFor the reader's\nwe include\n\u0010Pconvenience\n\u0011 a brief argument:\nPn\nn\nSince Cov\ni=1 Xi ,\ni=1 (N\u01eb X)i = n(1 \u2212 2\u01eb), the central limit theorem im-\n\nplies that as n \u2192 \u221e,\n\nn\n\nn\n\ni=1\n\ni=1\n\n\u0011\nX\n1 \u0010X\n\u221a\n(N\u01eb X)i \u21d2 (Z1 , Z1\u2217 ) in law,\nXi ,\nn\nwhere Z1 , Z1\u2217 are standard normals with covariance 1 \u2212 2\u01eb. We can write Z1\u2217 =\n\nZ1 cos \u03b1 \u2212 Z2 sin \u03b1 where Z1 , Z2 are i.i.d. standard normals and \u03b1 \u2208 (0, \u03c0) satisfies\ncos \u03b1 = 1 \u2212 2\u01eb. Rotating the random vector (Z1 , Z2 ) by the angle \u03b1 yields a vector\n\nwith first coordinate Z1\u2217 . Since (Z1 , Z2 ) has a rotationally-symmetric law, the\n\nrotation changes the sign of the first coordinate with probability \u03b1/\u03c0. This verifies\nthe left-hand side of (1.5); the right-hand side follows from Taylor expansion of\ncosine.\nThus the estimate (1.2) is sharp (up to the value of the constant). Moreover, the\nratio between the upper bound in (1.3) and the value for simple majority in (1.5)\np\ntends to \u03c0/2 < 1.26 as \u01eb \u2192 0. We remark that the stability result in theorem\nP\n1.1 is stronger than an assertion about stability of half-spaces, {x :\ni wi xi > \u03b8},\n\nbecause we consider the weighted majority as taking three values, rather than two.\n\n\fSTABILITY OF WEIGHTED MAJORITY\n\n3\n\n2. Proof of Theorem 1.1\nUsing symmetry of Xi , we may assume that wi > 0 for i = 1, . . . , n. Let\nP\nhw, Xi = ni=1 wi Xi . We first consider the threshold t = 0. Later, we will extend\nthe argument to thresholds t 6= 0.\n\nWe will need the following well-known fact from [3]:\n\u0010\n\u0011 \u0012 n \u0013\nP hw, Xi = 0 \u2264\n2\u2212n .\n\u230an/2\u230b\n\nIndeed, the collection D(w) of sets D \u2282 {1, . . . n} such that\n\n(2.1)\nP\n\ni\u2208D\n\nwi =\n\nP\n\nk \u2208D\n/\n\nwk\n\nforms an anti-chain with respect to inclusion, so Sperner's theorem (see [1], Ch. 11)\nn \u0001\n. Finally, observe that a vector\nimplies that the cardinality of D(w) is at most \u230an/2\u230b\n\nx \u2208 {\u22121, 1}n satisfies hw, xi = 0 iff {i : xi = 1} is in D(w).\n\nLet m = \u230a\u01eb\u22121 \u230b and let \u03c4 be a random variable taking the values 0, 1, . . . , m,\n\nwith P(\u03c4 = j) = \u01eb for j = 1, . . . , m and P(\u03c4 = 0) = 1 \u2212 m\u01eb. We use a sequence\n\n\u03c41 , \u03c42 , . . . , \u03c4n of i.i.d. random variables with the same law as \u03c4 , to partition [n] =\n{1, . . . , n} into m + 1 random sets\nn\no\nAj = i \u2208 [n] : \u03c4i = j\nfor 0 \u2264 j \u2264 m.\nDenote Sj =\n\nP\n\ni\u2208Aj\n\nwi Xi and let Y1 =\n\nP\n\ni\u2208A\n/ j\n\n(2.2)\n\nwi Xi = hw, Xi \u2212 S1 . Observe that\n\nY1 \u2212 S1 has the same law, given X, as hw, N\u01eb (X)i. Therefore,\n\u0010\n\u0011\np\u01eb (n, w, 0) = P sgnhw, Xi 6= sgnhw, N\u01eb (X)i\n\n(2.3)\n\n\u0010\n\u0011\n= P sgn(Y1 + S1 ) 6= sgn(Y1 \u2212 S1 ) .\nDenote \u03bej = sgn(Sj ). A key step in the proof is the pointwise identity\n1{sgn(Y + S ) 6= sgn(Y \u2212 S )}\n1\n1\n1\n1\n\u0011\n\u00101\n\u2212 1{sgn(S + Y ) = \u2212\u03be } Y1 , |S1 | .\n= 2 * 1{S 6= 0} E\n1\n1\n1\n1\n2\n\n(2.4)\n\nTo verify this, we consider three cases:\n(i) Clearly both sides vanish if S1 = 0.\n(ii) Suppose that 0 < |S1 | < |Y1 | and therefore sgn(Y1 + S1 ) = sgn(Y1 ). The\n\nconditional distribution of S1 given Y1 and |S1 | is uniform over {\u2212|S1 |, |S1 |}, whence\nthe conditional probability that sgn(S1 + Y1 ) = \u2212\u03be1 is 1/2. Thus both sides of (2.4)\nalso vanish in this case.\n\n\f4\n\nYUVAL PERES\n\n(iii) Finally, suppose that S1 6= 0 and |S1 | \u2265 |Y1 |. In this case sgn(S1 + Y1 ) 6= \u2212\u03be1 ,\nso both sides of (2.4) equal 1.\n\nTaking expectations in (2.4) and using (2.3), we deduce that\n\u0011i\n\u00101\nh\n\u2212 1{sgnhw, Xi = \u2212\u03be }\np\u01eb (n, w, 0) = 2 E 1{S 6= 0}\n1\n1\n2\n\u0011\n\u0010\n2 X 1\n=\nE\n\u2212 1{sgnhw, Xi = \u2212\u03be } ,\nj\nm\n2\n\n(2.5)\n\nj\u2208\u039b\n\nwhere \u039b = {j \u2208 [1, m] : Sj 6= 0}.\n\nThe random variable B\u039b = #{j \u2208 \u039b : \u03bej = 1} has a Binomial(#\u039b, 12 ) distribu-\n\ntion given \u039b, and satisfies the pointwise inequality\n\nm\n\u0011\nX\n#\u039b\n1\n1{A 6= \u2205} .\n\u2212 1{sgnhw, Xi = \u2212\u03be } \u2264 B\u039b \u2212\n+ 1{hw, Xi = 0}\nj\nj\n2\n2\n2\n\nX\u0010 1\nj\u2208\u039b\n\nj=1\n\nTo see this, consider the three possibilities for sgnhw, Xi. Taking expectations and\nusing (2.5), we get\np\u01eb (n, w, 0) \u2264\n\n2\n#\u039b\nE B\u039b \u2212\n+ P(A1 6= \u2205)P(hw, Xi = 0).\nm\n2\n\n(2.6)\n\nLet Bl denote a Binomial(l, 21 ) random variable. Since for any martingale {Ml }l\u22651\n\nthe absolute values |Ml | form a submartingale, the expression E |Bl \u2212 2l | is increasing in l. By averaging over \u039b, we see that E |B\u039b \u2212\nconjunction with (2.6) and (2.1), this implies\n\n#\u039b\n2 |\n\n\u2264 E |Bm \u2212\n\nm\n2 |.\n\n\u0012\n\u0013\nn\nm\n2\nn\n2\u2212n .\np\u01eb (n, w, 0) \u2264 E |Bm \u2212 | + [1 \u2212 (1 \u2212 \u01eb) ]\n\u230an/2\u230b\nm\n2\nNext, suppose that f (x) = sgn\n\n\u0010P\nn\n\ni=1 wi xi\n\nIn\n\n(2.7)\n\n\u0011\n\u2212 t , where t 6= 0 is a given thresh-\n\nold. Let Xn+1 be a \u00b11 valued symmetric random variable, independent of X =\n(X1 , . . . , Xn ), and define wn+1 = t. Then\n\u0010\n\u0011\np\u01eb (n, w, t) = P f (X) 6= f (N\u01eb (X))\n\n(2.8)\n\nn\nn+1\n\u0010\nX\n\u0002X\n\u0003\u0011\nwi (N\u01eb X)i + wn+1 XN +1 ,\nwi Xi 6= sgn\n= P sgn\ni=1\n\ni=1\n\nand the argument used above to establish the bound (2.7) for p\u01eb (n, w, 0), yields the\nsame bound for p\u01eb (n, w, t). This proves (1.4).\n\n\fSTABILITY OF WEIGHTED MAJORITY\n\n5\n\nTo derive (1.2), we may assume that \u01eb \u2264 1/4. Use Cauchy-Schwarz to write\np\np\nVar(Bm ) = m/4 and apply the elementary inequalities\nE |Bm \u2212 m\n2|\u2264\n\u0012\n\u0013\np\nn\n2\u2212n \u2264 3/4 n\u22121/2 ,\n\u230an/2\u230b\n\u221a\n(see, e.g., [8], Section 2.3) and [1 \u2212 (1 \u2212 \u01eb)n ] \u2264 min{n\u01eb, 1} \u2264 n\u01eb, to obtain\np\n\u221a\np\u01eb (n, w, t) \u2264 m\u22121/2 + n\u01eb * 3/4 n\u22121/2 .\n(2.9)\nSince m = \u230a\u01eb\u22121 \u230b \u2265 4/(5\u01eb) for \u01eb \u2264 1/4, we conclude that\n\u0010p\np \u0011\n5/4 + 3/4 \u01eb1/2 < 2\u01eb1/2 ,\np\u01eb (n, w, t) \u2264\n\nand this proves (1.2).\n\nFinally, the central limit theorem implies that\nZ \u221e\np\n2\n1\nE |2Bm \u2212 m|\n\u221a\n|u|e\u2212u /2 du = 2/\u03c0 .\n=\u221a\nlim\nm\u2192\u221e\nm\n2\u03c0 \u2212\u221e\nThis proves (1.3).\n\n\u0003\n\nRemarks.\n1. Our proof of Theorem 1.1 was found in 1999, and was mentioned in [2]. We\npresent it here, with more attention to the constants, in view of the recent interest\nin related \"converse\" inequalities, see [5]. The randomization idea which is crucial\nto the proof was inspired by an argument of Matthews [7] to bound cover times for\nMarkov chains. See also [10] for related random walk estimates.\n2. After I described the proof of Theorem 1.1 to R. O'Donnell, he found (jointly\nwith A. Klivans and R. Servedio) some extensions and applications of the argument\nto learning theory, see [6] for this and many other results.\n3. The proof of Theorem 1.1 extends verbatim to the case where Xi are independent\nsymmetric real-valued random variables with P(Xi = 0) = 0 for all i. However,\nthis extension reduces to Theorem 1.1 by conditioning on |Xi |. A more interesting\n\nextension would be to replace the symmetry assumption on Xi by the assumption\nE Xi =0.\n4. Is simple majority the most noise sensitive of the weighted majority functions\n(asymptotically when \u01eb \u2192 0 and n\u01eb \u2192 \u221e) ?\n\nIn particular, is it possible to replace the right-hand side of (1.3) by 2/\u03c0?\nAcknowledgement. I am grateful to I. Benjamini, G. Kalai and O. Schramm for\nsuggesting the problem, and to E. Mossel, R. Peled, O. Schramm, R. SiegmundSchultze and H. V. Weizs\u00e4cker for useful discussions.\n\n\f6\n\nYUVAL PERES\n\nReferences\n1. N. Alon and J. Spencer (1992), The Probabilistic Method, Wiley, New York.\n2. I. Benjamini, G. Kalai and O. Schramm (2001), Noise sensitivity of Boolean functions and\napplications to percolation. Inst. Hautes \u00c9tudes Sci. Publ. Math., 90, 5\u201343.\n3. P. Erd\u0151s, (1945), On a lemma of Littlewood and Offord, Bull. Amer. Math. Soc., 51, 898\u2013902.\n4. G. Guilbaud (1966), Theories of the general interest, and the logical problem of aggregation.\nIn Readings in Mathematical Social Science, edited by P. F. Lazarsfeld and N. W. Henry, MIT\nPress, 262\u2013307.\n5. S. Khot, E. Mossel, and R. O'Donnell (2004), Optimal inapproximability results for MAXCUT and other 2-variable CSPs? Preprint.\n6. A. Klivans, R. O'Donnell and R. Servedio (2004), Learning intersections and thresholds of\nhalfspaces. J. Computer Syst. Sci. 68, 808\u2013840.\n7. P. Matthews (1988), Covering problems for Brownian motion on spheres. Ann. Probab. 16\n189\u2013199.\n8. J. Pitman (1993), Probability. Springer.\n9. W. Sheppard (1899). On the application of the theory of error to cases of normal distribution\nand normal correlations, Phil. Trans. Royal Soc. London, 192, 101\u2013168.\n10. R. Siegmund-Schultze and H. von Weizs\u00e4cker (2004), Level Crossing Probabilities I: Onedimensional Random Walks and Symmetrization. Preprint.\nYuval Peres, Department of Statistics, University of California, Berkeley.\nperes@stat.berkeley.edu\n\n\f"}