{"id": "http://arxiv.org/abs/1007.3381v3", "guidislink": true, "updated": "2011-08-08T12:38:49Z", "updated_parsed": [2011, 8, 8, 12, 38, 49, 0, 220, 0], "published": "2010-07-20T09:51:27Z", "published_parsed": [2010, 7, 20, 9, 51, 27, 1, 201, 0], "title": "Efficient wavefunction propagation by minimizing accumulated action", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1007.2271%2C1007.0673%2C1007.2265%2C1007.0989%2C1007.4600%2C1007.2502%2C1007.3032%2C1007.1022%2C1007.0519%2C1007.4144%2C1007.4394%2C1007.0151%2C1007.3682%2C1007.2685%2C1007.1539%2C1007.0986%2C1007.0014%2C1007.4171%2C1007.5198%2C1007.1066%2C1007.0366%2C1007.3137%2C1007.3456%2C1007.4792%2C1007.0400%2C1007.0140%2C1007.2931%2C1007.0813%2C1007.3056%2C1007.1914%2C1007.3381%2C1007.5330%2C1007.3654%2C1007.5389%2C1007.2039%2C1007.2738%2C1007.3651%2C1007.4614%2C1007.4344%2C1007.0480%2C1007.0893%2C1007.1077%2C1007.2889%2C1007.1515%2C1007.4951%2C1007.3807%2C1007.0328%2C1007.0118%2C1007.5378%2C1007.3677%2C1007.0752%2C1007.3169%2C1007.3506%2C1007.2692%2C1007.1138%2C1007.1274%2C1007.0597%2C1007.0294%2C1007.4783%2C1007.3798%2C1007.1023%2C1007.0477%2C1007.1751%2C1007.4884%2C1007.4912%2C1007.3607%2C1007.0723%2C1007.5066%2C1007.0618%2C1007.1064%2C1007.0090%2C1007.2543%2C1007.2150%2C1007.2221%2C1007.0727%2C1007.4329%2C1007.5451%2C1007.3996%2C1007.3889%2C1007.5087%2C1007.3711%2C1007.3308%2C1007.2608%2C1007.4155%2C1007.4719%2C1007.1634%2C1007.0530%2C1007.3438%2C1007.1376%2C1007.1244%2C1007.1883%2C1007.0168%2C1007.3953%2C1007.4017%2C1007.0252%2C1007.1912%2C1007.1146%2C1007.5505%2C1007.0317%2C1007.3843%2C1007.5356&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Efficient wavefunction propagation by minimizing accumulated action"}, "summary": "This paper presents a new technique to calculate the evolution of a quantum\nwavefunction in a chosen spatial basis by minimizing the accumulated action.\nIntroduction of a finite temporal basis reduces the problem to a set of linear\nequations, while an appropriate choice of temporal basis set offers improved\nconvergence relative to methods based on matrix exponentiation for a class of\nphysically relevant problems.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1007.2271%2C1007.0673%2C1007.2265%2C1007.0989%2C1007.4600%2C1007.2502%2C1007.3032%2C1007.1022%2C1007.0519%2C1007.4144%2C1007.4394%2C1007.0151%2C1007.3682%2C1007.2685%2C1007.1539%2C1007.0986%2C1007.0014%2C1007.4171%2C1007.5198%2C1007.1066%2C1007.0366%2C1007.3137%2C1007.3456%2C1007.4792%2C1007.0400%2C1007.0140%2C1007.2931%2C1007.0813%2C1007.3056%2C1007.1914%2C1007.3381%2C1007.5330%2C1007.3654%2C1007.5389%2C1007.2039%2C1007.2738%2C1007.3651%2C1007.4614%2C1007.4344%2C1007.0480%2C1007.0893%2C1007.1077%2C1007.2889%2C1007.1515%2C1007.4951%2C1007.3807%2C1007.0328%2C1007.0118%2C1007.5378%2C1007.3677%2C1007.0752%2C1007.3169%2C1007.3506%2C1007.2692%2C1007.1138%2C1007.1274%2C1007.0597%2C1007.0294%2C1007.4783%2C1007.3798%2C1007.1023%2C1007.0477%2C1007.1751%2C1007.4884%2C1007.4912%2C1007.3607%2C1007.0723%2C1007.5066%2C1007.0618%2C1007.1064%2C1007.0090%2C1007.2543%2C1007.2150%2C1007.2221%2C1007.0727%2C1007.4329%2C1007.5451%2C1007.3996%2C1007.3889%2C1007.5087%2C1007.3711%2C1007.3308%2C1007.2608%2C1007.4155%2C1007.4719%2C1007.1634%2C1007.0530%2C1007.3438%2C1007.1376%2C1007.1244%2C1007.1883%2C1007.0168%2C1007.3953%2C1007.4017%2C1007.0252%2C1007.1912%2C1007.1146%2C1007.5505%2C1007.0317%2C1007.3843%2C1007.5356&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This paper presents a new technique to calculate the evolution of a quantum\nwavefunction in a chosen spatial basis by minimizing the accumulated action.\nIntroduction of a finite temporal basis reduces the problem to a set of linear\nequations, while an appropriate choice of temporal basis set offers improved\nconvergence relative to methods based on matrix exponentiation for a class of\nphysically relevant problems."}, "authors": ["Zachary B. Walters"], "author_detail": {"name": "Zachary B. Walters"}, "author": "Zachary B. Walters", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/j.cpc.2010.12.030", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1007.3381v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1007.3381v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "physics.comp-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "physics.comp-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.MP", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "physics.atom-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "quant-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1007.3381v3", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1007.3381v3", "arxiv_comment": null, "journal_reference": "Computer Physics Communications Volume 182, Issue 4, April 2011,\n  Pages 935-939", "doi": "10.1016/j.cpc.2010.12.030", "fulltext": "Efficient wavefunction propagation by minimizing accumulated action\nZachary B. Walters1\n\narXiv:1007.3381v3 [physics.comp-ph] 8 Aug 2011\n\n1\n\nMax Born Institute, Bereich B, Max Born Strasse 2a, 12489 Berlin Adlershof, Berlin Germany\n(Dated: August 28, 2018)\n\nThis paper presents a new technique to calculate the evolution of a quantum wavefunction in a\nchosen spatial basis by minimizing the accumulated action. Introduction of a finite temporal basis\nreduces the problem to a set of linear equations, while an appropriate choice of temporal basis\nset offers improved convergence relative to methods based on matrix exponentiation for a class of\nphysically relevant problems.\n\nCalculating the time evolution of a quantum wavefunction is a longstanding problem in computational physics.\nThe fundamental nature of the problem makes it resistant\nto simplification. Problems of physical interest, such as\nthe interaction of a molecule with a strong laser field, may\nlack symmetry or involve time dependent, nonperturbative fields. Problems involving multiple dimensions or\nmultiple interacting particles may quickly grow so large\nas to be unmanageable with all but the largest computational resources [1\u20133], a problem which is not easily\noutstripped by increases in computational power. An\nideal propagator, then, must serve two masters \u2013 it must\ntreat the physical side of the problem accurately, and the\ncomputational side of the problem efficiently.\nThe most common approach to the problem does not\ntreat the evolving wavefunction directly. Instead, the\nwavefunction\nP \u03c8(x, t) is expanded in some chosen basis set\n\u03c6(x, t) = i ci (t)\u03c7i (x), where ci (t0 ) = h\u03c7i |\u03c8(t0 )i. Here\n\u03c8(x, t) is the true wavefunction and \u03c6(x, t) is its representation in the chosen basis. After this expansion has\nbeen made, the propagation scheme may operate only on\nthe wavefunction's representation, rather than the wavefunction itself. Within this general framework, there\nhas been a great profusion of methods for calculating\nthe evolution of the coefficients ci (t). Popular methods\ninclude Crank-Nicholson[4], second order differencing[5],\nsplit operator[6], short iterative Lanczos[7], and Chebyshev propagation[8], as well as many others[9].\nAs may be inferred from the large number of competing methods, the practical question of which method\nworks best is very difficult to answer, and usually requires\nproblem-specific information. Ironically, the time dependent Schr\u00f6dinger equation (TDSE), while challenging to\nsolve, is not difficult to satisfy at a particular time. All\nof the above methods satisfy the TDSE exactly or approximately at the initial time in the propagation interval. Indeed, entire families of propagators may satisfy\nthe TDSE at the initial point: for the class of propagators \u03c8(x, t)(1 \u2212 iH\u03b1\u2206t) = \u03c8(x, t + \u2206t)(1 + iH(1 \u2212 \u03b1)\u2206t),\n0 \u2264 \u2206t, the TDSE at time t is satisfied to first order\nfor any value of \u03b1. \u03b1 = 1 yields the forwards Euler\nmethod, \u03b1 = 0 the backwards Euler, \u03b1 = 1/2 the CrankNicholson. Although such methods may show sharp differences in suitability to particular problems, the TDSE\n\nalone gives little guidance. A full diagonalization of the\nHamiltonian matrix would satisfy the TDSE at all times;\nhowever, such a diagonalization would be prohibitively\nexpensive for a large problem, and would not exist for a\nproblem with a time dependent Hamiltonian. Comparison of different propagators has often involved numerical\ntesting on simple problems[10, 11] or algorithmic scaling\narguments[12].\nThis paper addresses the problem of wavefunction\npropagation from the physical perspective of minimizing the action accumulated over the chosen time interval.\nMinimizing this action is shown to be equivalent to minimizing the time integrated error of propagation. Because\nthe action is calculated over the entire time step rather\nthan at a single point, the constraint that it be minimized\nis more strict than the TDSE, allowing the construction\nof a unique, variationally optimum propagator for a particular order in time.\nERRORS OF PROPAGATION AND\nREPRESENTATION\n\nA central difficulty of any numerical propagation\nscheme is that, although the propagator seeks to model\nthe evolution of an ideal wavefunction \u03c8(x, t), it has access only to the representation of the wavefunction in\nsome chosen basis, \u03c6(x, t). The error of the representation is given by \u03b4(x, t) = \u03c8(x, t) \u2212 \u03c6(x, t).\nAs an alternative to direct exponentiation of the\nHamiltonian, a propagator may be constructed by minimizing the integral of the error over the time step\nZ t+\u2206t\nGlobal error =\ndt\u2032 h\u03b4(x, t\u2032 )|\u03b4(x, t\u2032 )i .\n(1)\nt\n\nWriting the error as a two term Taylor series,\nZ t+\u2206t\nGlobal error =\ndt\u2032 h\u03b4(x, t)|\u03b4(x, t)i +\nZ\n\nt\n\nt\n\nt+\u2206t\n\ndt\n\n\u2032\u2032\n\nZ\n\nt\n\nt\u2032\n\nd\nh\u03b4(x, t\u2032 )|\u03b4(x, t\u2032 )i ,\ndt\u2032\n\nd\n\u03c8(x, t)\ni dt\n\n(2)\n\n= H\u03c8(x, t) for the true\nand recalling that\nwavefunction, the second term in equation 2 can be writ-\n\n\f2\nten as\n\nQnm =\n\nd\nd\nh\u03b4(x, t)|\u03b4(x, t)i = 2i h\u03c6(x, t)| (i \u2212 H) |\u03c6(x, t)i +\ndt\ndt\n2i h\u03b4(x, t)| H |\u03b4(x, t)i .\n(3)\nFrom equations 2 and 3, it is apparent that the global\nerror may arise either from imperfectly representing the\nwavefunction in a particular basis (terms containing\n\u03b4(x, t)) or from imperfectly describing the evolution of\nthe wavefunction in that basis (terms containing \u03c6(x, t)).\nThe representation error may be minimized by an appropriate choice of basis; here the focus is on minimizing the\nerror of propagation.\nd\n\u2212 H) |\u03c6(x, t)i found in equaThe quantity h\u03c6(x, t)| (i dt\ntion 3 is the Lagrangian density, and its integral over time\ngives the action accumulated by the wavefunction in a\nparticular interval. However, unlike the true Lagrangian\ndensity, here the action is calculated with respect to the\nrepresentation of the wavefunction, rather than the wavefunction itself. The distinction is significant. For the\ntrue wavefunction, minimizing the action is equivalent\nd\nto setting i dt\n\u03c8(x, t) \u2212 H\u03c8(x, t) = 0 for all x and t. For\nthe action minimizing representation of the wavefunction,\n| h\u03c6(x, t)| (id/dt \u2212 H) |\u03c6(x, t)i | is dependent on the choice\nof spatial and temporal basis functions and is not guaranteed to be zero.\nFor a finite basis of spatial \u03c7i (x) and temporal Tn (t)\nbasis functions, a time dependent representation of the\nwavefunction can be written as\nX\nCin \u03c7i (x)Tn (t).\n(4)\n\u03c6(x, t) =\ni,n\n\nIn this basis, the global error of Eq. 3 becomes a function\nof the coefficients Cin and the matrix representations of\nthe quantum mechanical operators. Writing the Hamiltonian as the sum of time independent and time dependent\noperators\nH = H0 (x) + V (x, t)\nand defining the matrices\nZ\nHij = dx\u03c7\u2217i (x)H0 \u03c7j (x)\n\nVijnm =\n\nZ\n\nt\n\nt+\u2206t\n\ndt\u2032\n\nZ\n\n(5)\n\n(6)\n\ndx\u03c7\u2217i (x)Tn\u2217 (t)V (x, t)\u03c7j (x)Tm (t)\n(7)\n\nOij =\n\nZ\n\nUnm =\n\nZ\n\ndx\u03c7\u2217i (x)\u03c7j (x)\n\ndtTn\u2217 (t)Tm (t)\n\nZ\n\n\u2032\n\ndtTn\u2217 (t)Tm (t),\n\n(10)\n\nthe change in action resulting from Cin \u2192 Cin + \u01ebin is\ngiven by\n\u03b4S =\n\nX\n\nCin [iOij Qnm \u2212 Hij Unm \u2212 Vijnm ]\u01eb\u2217jm (11)\n\ni,j,n,m\n\nand the condition to minimize the accumulated action is\nthat either \u01eb\u2217jm = 0 (for the initial conditions) or\n\u03b4Sjm =\n\nX\n\nCin [iOij Qnm \u2212 Hij Unm \u2212 Vijnm ]\u01eb\u2217jm = 0\n\ni,n\n\n(12)\nfor all j,m. In these equations, i appearing as a subscript\nis treated as an index, while i multiplying Oij Qnm is the\nsquare root of negative one.\nEquation 12 is the main result of this paper. In order\nto construct a least action propagator, it is necessary\nonly to choose an appropriate temporal basis. While in\nprinciple this analysis applies equally well to any choice\nof basis, an obvious choice is for Tn (t) to be a set of\nlinearly independent low-order polynomials in t.\nLagrange interpolating polynomials provide a convenient set of temporal basis functions. For an evenly\nspaced grid tm = t + \u2206t \u2217 m/n for m = 0, n, the interpolating polynomials are given by\nTm (t) = \u03a0k=0,n;k6=m\n\nt \u2212 tk\n.\ntm \u2212 tk\n\n(13)\n\nThis yields a basis set of n linearly independent n-order\npolynomials in t, with the property that \u03c6(x, tn ) =\nP\ni Cin \u03c7i (x). One advantage of this choice of basis is\nthat for small propagation times, Cin will have comparable amplitudes for all n, making the associated linear\nsystem easier to solve with high accuracy.\nHaving chosen a temporal basis, coefficients Cin which\nsatisfy Equation 12 as well as the initial condition Ci0 =\nh\u03c7i |\u03c8(t0 )i can be found using Lagrange multipliers. If S\nis thePaction accumulated in the time interval, let S \u2032 =\nS + i \u03bbi fi\u2217 , where fi = Ci0 \u2212 h\u03c7i |\u03c8(t0 )i. The least\naction coefficients are found by minimizing S \u2032 with the\nconstraint that fi = 0 for all i. This yields a system of\nlinear equations\nX\n\nCin [iOij Qnm \u2212 Hij Unm \u2212 Vijnm ] + \u03bbj = 0\n\n(14)\n\ni,n\n\nfor all j, m, and\n\n(8)\n\nCi0 = h\u03c7i |\u03c8(t0 )i\n\n(15)\n\n(9)\n\nfor all i. The Lagrange multipliers \u03bbj calculated in this\nprocedure are not needed by the propagator and can be\ndiscarded after solving the linear system.\n\n\f3\nCOMPARISON WITH THE LANCZOS\nPROPAGATOR\n\nThe least action propagator derived in the previous\nsection is the unique, variationally optimum propagator\nfor a particular order in time. As such, it represents\na formal improvement over all propagators approximating the wavefunction as a low order polynomial in time\n\u2013 forward and backwards Euler, Crank Nicholson, second order differencing, etc. However, it is less clear\nhow this formal improvement translates to a practical\nbenefit, or how the least action propagator compares to\nmethods which attempt to diagonalize the Hamiltonian\nin a Krylov subspace, such as the popular short iterative\nLanczos method [7].\nThe Lanczos method works by repeatedly multiplying the initial wavefunction by the Hamiltonian matrix to create a Krylov space of limited dimension in\nwhich the matrix exponential e\u2212iHt can be calculated\nexactly. It is considered to be both efficient and quickly\nconverging[10]. Existing variational propagators have focused on the evolution of the wavefunction in the Krylov\nsubspace, yielding convergence properties similar to the\nLanczos propagator[13, 14]. The Chebyshev propagator,\nwhich also uses repeated multiplication by the Hamiltonian matrix to construct a Krylov space, converges similarly to the Lanczos method[15].\nIn the limit that the Krylov space has dimension equal\nto the full Hamiltonian, the Lanczos method is equivalent\nd\n\u03c8\u2212\nto diagonalizing the Hamiltonian, yielding L = i dt\nH\u03c8 = 0 at all times. This solution is the global minimum\naction solution, and cannot be improved upon. However,\nfor most applications, the Krylov subspace is chosen to\nhave a much smaller order \u2013 typically in the range 1-10.\nBecause the Krylov subspace is constructed through\nrepeatedly multiplying an initial wavefunction by the\nHamiltonian matrix, later Krylov basis vectors will tend\nto some overlap with those eigenvectors of H with the\nlargest eigenvalues. For problems with Coulomb singularities or fine spatial bases, it is not uncommon for these\nlargest eigenvalues to be artifacts of the choice of basis, having no counterpart in the system being described.\nHowever, they may nonetheless serve to limit the stepsize\nwhich may be taken with high accuracy.\nIf an ideal wavefunction (ie, without reference to a basis) \u03c8(x, t) can be expanded in terms of energy eigenfunctions over a short time interval\nX\n\u03c8(x, t) =\nc\u03b1 f\u03b1 (x)e\u2212iE\u03b1 (t\u2212t0 )\n(16)\n\u03b1\n\nand the evolution of the wavefunction's representation in\nthe Krylov subspace is given by\n\u03c6(x, t) =\n\nX\n\u03b2\n\nd\u03b1,\u03b2 g\u03b2 (x)e\u2212iE\u03b2 (t\u2212t0 ) ,\n\n(17)\n\nwhere d\u03b1,\u03b2 = c\u03b1 hg\u03b2 |f\u03b1 i, then the error is given by\nX\n\u03b4(x, t) =\nd\u03b1,\u03b2 g\u03b2 (x)(e\u2212iE\u03b1 (t\u2212t0 ) \u2212 e\u2212iE\u03b2 (t\u2212t0 ) ) (18)\n\u03b1,\u03b2\n\nand\nh\u03b4|\u03b4i =\n\nX\n\n|d\u03b1,\u03b2 |2 4 sin2 (\n\n\u03b1,\u03b2\n\nE\u03b1 \u2212 E\u03b2\n(t \u2212 t0 )).\n2\n\n(19)\n\nIf the Krylov subspace is now partitioned into a \"good\"\nsubspace with E\u03b2 < Ecutoff and a \"bad\" subspace with\nE\u03b2 > Ecutoff , the error can be estimated by setting E\u03b1 \u2212\nE\u03b2 = 0 in the good subspace and E\u03b2 \u2212 E\u03b1 = EH , where\nEH reflects the largest eigenvalues of H, yielding\nh\u03b4|\u03b4i \u2248\n\nX\n\n\u03b1,\u03b2,E\u03b2 >Ecutoff\n\n1\n|d\u03b1,\u03b2 |2 4 sin2 ( EH (t \u2212 t0 )). (20)\n2\n\nThe error of the Lanczos method is thus minimized either\nwhen the projection into the bad subspace is small or\nwhen EH \u2206t << 1.\nIn contrast to the Lanczos method, the error of the\nleast action propagator is bounded by the error of the\nTaylor series of the true wavefunction. Thus\nX\n\nN\nmax\nX\n\n(\u2212iE\u03b1 )n\n(t \u2212 t0 )n |2\nn!\n\u03b1\nn=0\n(21)\nand the condition for the error to remain small is simply\nthat Ecutoff \u2206t < 1. For a problem with Ecutoff << EH ,\nthe least action propagator offers the possibility of much\nlarger stepsizes at high accuracy than the Lanczos propagator.\nThe two propagators were tested numerically using a\n1 dimensional Coulomb potential 1/x for x ranging from\n0 to 10. The region was separated into 100 finite element regions, with two quadratic finite elements per\nregion. The wavefunction was restricted to have zero\nvalue at both endpoints. The largest eigenvalue of the\nresulting Hamiltonian matrix was 499 Hartree. The initial wavefunction was chosen to be a Gaussian of unit\nwidth, centered at x=2. The choice of initial wavefunction and potential were made to ensure that the wavefunction would be far from equilibrium and have a strong\ninteraction with the Coulomb potential, as for an electron\nwavepacket scattering from a positive ion.\nThe accuracy of the Lanczos- and least action propagator was calculated by propagating the initial wavefunction a single timestep and comparing the resulting wavefunction with the \"true\" wavefunction found by directly\ndiagonalizing the full Hamiltonian. yielding an error\nh\u03b4|\u03b4i \u2264\n\n|c\u03b1 |2 |e\u2212iE\u03b1 (t\u2212t0 ) \u2212\n\n|err| = h\u03b4(t + \u03b4t)|\u03b4(t + \u03b4t)i .\n\n(22)\n\nFor the least action propagator, the order of propagation\nis one less than the degree of the polynomial basis functions. For the Lanczos propagator, the order is given by\n\n\f4\n0\n\n0\n\n(log10 |norm|) / dt\n\nlog10 err\n\n-0.02\n\n-5\n\n1st order\n3rd order\n5th order\n7th order\n9th order\n\n-10\n-3\n\n-2\n\n-1\nlog10 dt\n\n0\n\n-0.04\n\n-0.06\n\n1\n\nFIG. 1. (Color online) Point error h\u03b4(x, t + \u2206t)|\u03b4(x, t + \u2206t)i\nof Crank Nicholson (dashed line), Lanczos (dotted lines) and\nleast action (solid lines) propagators, as a function of step\nsize. For large stepsizes, the least action propagator is many\ntimes more accurate than the Lanczos propagator of the same\norder.\n\nthe dimension of the Krylov subspace, starting with 0 for\nthe initial wavefunction.\nThe error as a function of order and stepsize for the\ntwo methods is shown in Figure 1. Also shown in the figure is the error vs time for the popular Crank Nicholson\nfirst order propagator [4]. As opposed to the global error\nwhich was used in the derivation of the least action propagator, these figures show the point error after a single\npropagation step.\nThese results show that the least action propagator offers the potential for large timesteps to be taken with\nhigh accuracy, with the greatest advantage coming from\npropagation at high order. At first order, the least action\npropagator gives approximately the same point error as\nthe Crank Nicholson method, while higher orders rapidly\ndecrease the error for a particular timestep, or alternatively increase the size of the timestep which can be taken\nfor a particular desired error. As the order increases, the\nerror begins to saturate as different order propagators\nconverge on the same result. That this saturation does\nnot result in zero error may result from numerical error\nin the diagonalization of the Hamiltonian or the linear\nsolver.\nFor all orders tested, the least action propagator was\nmany times more accurate than the Lanczos propagator\nfor large stepsizes. For very small stepsizes, the error of\nboth methods was comparable, with the Lanczos method\nmore accurate. Both methods became much more accurate for stepsizes of less than 10\u22122 , which is interpreted\nto mean that the initial wavefunction had some projection onto very high energy eigenstates; ie, the sample\nproblem did not have Ecutoff << EH .\nOne weakness of the least action propagators which\n\n-0.08\n-3\n\n1st order\n3rd order\n5th order\n7th order\n9th order\n\n-2\n\n-1\nlog10 dt\n\n0\n\n1\n\nFIG. 2.\n(Color online) Exponential growth rate\n(log10 |norm|)/dt vs propagation time for different orders of the least action propagator. Higher orders show a\ngrowth rate closer to zero.\n\narises from the choice of polynomial basis functions is\nthat the norm of the propagated wavefunction is not\nrequired to be a constant as a function of time. Figure 2 shows the rate of growth/decay of the norm h\u03c6|\u03c6i\nfor different orders of propagation as a function of step\nsize. Here the largest deviation from zero growth rate\nis found for the combination of low order and large stepsize. Higher order propagators show growth rates close to\nzero. For problems requiring repeated use of the propagator over many timesteps, it is thus likely that the\npropagated wavefunction will need to be renormalized\nperiodically. Because the norm is still very close to 1,\nsuch renormalization has a minimal effect on the point\nerror shown in Figure 1.\nFrom these figures, it is apparent that the least action propagator works best at high orders, which offer\nthe combination of large time steps, high accuracy and\nlow rates of growth or decay of the norm. However, high\norder also increases the size of the linear system which\nmust be solved at each step. For a basis consisting of nx\nspatial and nt temporal basis functions, the least action\npropagator requires ns = nx (nt +1) variables to be solved\nfor. While specific implementations are beyond the scope\nof this paper, the question of how best to solve this linear\nsystem will play a crucial role in applying the least action\npropagator to real world problems. To this end, a few features of the least action linear system are worth noting.\nFirst among these is the highly separable nature of the\nleast action linear system defined in equations 14 and 15.\nIn equation 14, the variation of the action is given as the\nsum of three matrices, Oij Qnm , Hij Unm , and Vijnm . Of\nthese, the first two are separated into the product of spatial and temporal matrices. Because of this, these two\nmatrices inherit the sparsity and/or banded structure of\nthe underlying spatial matrices. The case is similar for\n\n\f5\nthe nonseparable Vijnm : the integral over time and space\nis nonzero only if the integral over space is nonzero. Because of this, basis sets such as finite elements which are\nchosen for the structure of their Hamiltonian and overlap\nmatrices will retain these advantages in the least action\nequation. For a banded problem such as the 1D finite\nelement problem treated in this paper, the bandwidth of\nthe linear system increases linearly with the order of the\npropagator, giving an overall n2t scaling with the order.\nFor very large problems which lack such a simple structure, it is likely that solution of the least action linear system will require use of an iterative solver, such as those\navailable in the PETSc [16] or Trilinos [17] libraries. Such\nsolvers, require calculating a matrix vector product at\nevery iteration. Here the advantages of the least action\nequation's separable form are very apparent, particularly\nin the case of a static Hamiltonian. A single matrix vector\nproduct of the linear system defined in equations 14 and\n15 requires 1 (very expensive) matrix-vector multiplication by the unseparated matrix Vijnm , 2nt independent\n(expensive) multiplications of the form Dim = Mij Cjm ,\nwhere M = O or H, followed by 2nx (cheap) independent multiplications of the form Fin = Nnm Dim , where\nN = Q or U . Thus, although the linear system which\nmust be solved is very large, it is well suited to iterative solution. The overall scaling of one iteration with\nrespect to propagator order will be limited by the slowest of these steps, which may depend on specifics of the\ndata structure and architecture of the system used.\nThis paper has addressed the problem of propagating\na wavefunction in time by minimizing he accumulated\naction. For a particular choice of spatial and temporal basis functions, the problem is reduced to solution\nof a (potentially very large) system of linear equations.\nThis linear system inherits the sparsity and/or banded\nstructure of the spatial Hamiltonian and overlap matrices, while its separable structure makes it amenable to\nsolution by iterative solvers. The resulting propagator\nwas shown to have improved convergence relative to the\ncommonly used short iterative Lanczos propagator, giv-\n\ning the potential for larger stepsizes at high accuracy.\nThe derivation of the action as a measure of propagation error is a powerful result which offers many opportunities for the systematic improvement of propagation\nschemes. By monitoring the spacetime volumes where\nthe most action is accumulated, spatial or temporal bases\ncould be selectively refined to increase the total accuracy\nof a propagation step at minimal additional computational effort. For this reason, the full power of the action\nminimization principle may be yet to be unlocked.\n\n[1] Taylor, K. et al., Journal of Electron Spectroscopy and\nRelated Phenomena 144 (2005) 1191.\n[2] Feist, J. et al., Physical review letters 103 (2009) 63002.\n[3] Sansone, G. et al., Nature 465 763.\n[4] Crank, J. and Nicolson, P., Advances in Computational\nMathematics 6 (1996) 207.\n[5] Askar, A. and Cakmak, A., The Journal of Chemical\nPhysics 68 (1978) 2794.\n[6] Bandrauk, A. and Shen, H., Chemical Physics Letters\n176 (1991) 428.\n[7] Park, T. and Light, J., The Journal of chemical physics\n85 (1986) 5870.\n[8] Tal-Ezer, H. and Kosloff, R., The Journal of Chemical\nPhysics 81 (1984) 3967.\n[9] Moler, C. and Van Loan, C., SIAM review 45 (2003) 3.\n[10] Leforestier, C. et al., Journal of computational physics\n94 (1991) 59.\n[11] Truong, T. et al., The Journal of Chemical Physics 96\n(1992) 2077.\n[12] Kosloff, R., The Journal of Physical Chemistry 92 (1988)\n2087.\n[13] Triozon, F., Roche, S., and Mayou, D., Riken Review\n(2000) 73.\n[14] Tal-Ezer, H., Kosloff, R., and Cerjan, C., Journal of\nComputational Physics 100 (1992) 179.\n[15] Chen, R. and Guo, H., The Journal of Chemical Physics\n119 (2003) 5762.\n[16] Balay, S. et al., (2003).\n[17] Heroux, M. et al., ACM Transactions on Mathematical\nSoftware (TOMS) 31 (2005) 397.\n\n\f"}