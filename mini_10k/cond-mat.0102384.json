{"id": "http://arxiv.org/abs/cond-mat/0102384v1", "guidislink": true, "updated": "2001-02-21T17:20:42Z", "updated_parsed": [2001, 2, 21, 17, 20, 42, 2, 52, 0], "published": "2001-02-21T17:20:42Z", "published_parsed": [2001, 2, 21, 17, 20, 42, 2, 52, 0], "title": "Dynamics of the Time Horizon Minority Game", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0102266%2Ccond-mat%2F0102528%2Ccond-mat%2F0102189%2Ccond-mat%2F0102456%2Ccond-mat%2F0102164%2Ccond-mat%2F0102241%2Ccond-mat%2F0102061%2Ccond-mat%2F0102510%2Ccond-mat%2F0102362%2Ccond-mat%2F0102319%2Ccond-mat%2F0102247%2Ccond-mat%2F0102016%2Ccond-mat%2F0102391%2Ccond-mat%2F0102151%2Ccond-mat%2F0102378%2Ccond-mat%2F0102143%2Ccond-mat%2F0102493%2Ccond-mat%2F0102305%2Ccond-mat%2F0102093%2Ccond-mat%2F0102438%2Ccond-mat%2F0102269%2Ccond-mat%2F0102526%2Ccond-mat%2F0102521%2Ccond-mat%2F0102325%2Ccond-mat%2F0102066%2Ccond-mat%2F0102039%2Ccond-mat%2F0102180%2Ccond-mat%2F0102252%2Ccond-mat%2F0102357%2Ccond-mat%2F0102409%2Ccond-mat%2F0102055%2Ccond-mat%2F0102383%2Ccond-mat%2F0102120%2Ccond-mat%2F0102475%2Ccond-mat%2F0102386%2Ccond-mat%2F0102300%2Ccond-mat%2F0102103%2Ccond-mat%2F0102041%2Ccond-mat%2F0102216%2Ccond-mat%2F0102218%2Ccond-mat%2F0102483%2Ccond-mat%2F0102242%2Ccond-mat%2F0102130%2Ccond-mat%2F0102109%2Ccond-mat%2F0102294%2Ccond-mat%2F0102132%2Ccond-mat%2F0102414%2Ccond-mat%2F0102201%2Ccond-mat%2F0102487%2Ccond-mat%2F0102520%2Ccond-mat%2F0102073%2Ccond-mat%2F0102017%2Ccond-mat%2F0102146%2Ccond-mat%2F0102094%2Ccond-mat%2F0102340%2Ccond-mat%2F0102082%2Ccond-mat%2F0102506%2Ccond-mat%2F0102457%2Ccond-mat%2F0102407%2Ccond-mat%2F0102459%2Ccond-mat%2F0102001%2Ccond-mat%2F0102177%2Ccond-mat%2F0102124%2Ccond-mat%2F0102374%2Ccond-mat%2F0102274%2Ccond-mat%2F0102488%2Ccond-mat%2F0102034%2Ccond-mat%2F0102008%2Ccond-mat%2F0102205%2Ccond-mat%2F0102116%2Ccond-mat%2F0102059%2Ccond-mat%2F0102255%2Ccond-mat%2F0102190%2Ccond-mat%2F0102080%2Ccond-mat%2F0102191%2Ccond-mat%2F0102006%2Ccond-mat%2F0102046%2Ccond-mat%2F0102135%2Ccond-mat%2F0102023%2Ccond-mat%2F0102022%2Ccond-mat%2F0102434%2Ccond-mat%2F0102123%2Ccond-mat%2F0102497%2Ccond-mat%2F0102384%2Ccond-mat%2F0102112%2Ccond-mat%2F0102071%2Ccond-mat%2F0102507%2Ccond-mat%2F0102236%2Ccond-mat%2F0102203%2Ccond-mat%2F0102452%2Ccond-mat%2F0102418%2Ccond-mat%2F0102232%2Ccond-mat%2F0102403%2Ccond-mat%2F0102286%2Ccond-mat%2F0102307%2Ccond-mat%2F0102455%2Ccond-mat%2F0102376%2Ccond-mat%2F0102401%2Ccond-mat%2F0102226%2Ccond-mat%2F0102321%2Ccond-mat%2F0102524&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Dynamics of the Time Horizon Minority Game"}, "summary": "We present exact analytic results for a new version of the Minority Game (MG)\nin which strategy performance is recorded over a finite time horizon. The\ndynamics of this Time Horizon Minority Game (THMG) exhibit many distinct\nfeatures from the MG and depend strongly on whether the participants are fed\nreal, or random, history strings. The THMG equations are equivalent to a Markov\nChain, and yield exact analytic results for the volatility given a specific\nrealization for the quenched strategy disorder.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0102266%2Ccond-mat%2F0102528%2Ccond-mat%2F0102189%2Ccond-mat%2F0102456%2Ccond-mat%2F0102164%2Ccond-mat%2F0102241%2Ccond-mat%2F0102061%2Ccond-mat%2F0102510%2Ccond-mat%2F0102362%2Ccond-mat%2F0102319%2Ccond-mat%2F0102247%2Ccond-mat%2F0102016%2Ccond-mat%2F0102391%2Ccond-mat%2F0102151%2Ccond-mat%2F0102378%2Ccond-mat%2F0102143%2Ccond-mat%2F0102493%2Ccond-mat%2F0102305%2Ccond-mat%2F0102093%2Ccond-mat%2F0102438%2Ccond-mat%2F0102269%2Ccond-mat%2F0102526%2Ccond-mat%2F0102521%2Ccond-mat%2F0102325%2Ccond-mat%2F0102066%2Ccond-mat%2F0102039%2Ccond-mat%2F0102180%2Ccond-mat%2F0102252%2Ccond-mat%2F0102357%2Ccond-mat%2F0102409%2Ccond-mat%2F0102055%2Ccond-mat%2F0102383%2Ccond-mat%2F0102120%2Ccond-mat%2F0102475%2Ccond-mat%2F0102386%2Ccond-mat%2F0102300%2Ccond-mat%2F0102103%2Ccond-mat%2F0102041%2Ccond-mat%2F0102216%2Ccond-mat%2F0102218%2Ccond-mat%2F0102483%2Ccond-mat%2F0102242%2Ccond-mat%2F0102130%2Ccond-mat%2F0102109%2Ccond-mat%2F0102294%2Ccond-mat%2F0102132%2Ccond-mat%2F0102414%2Ccond-mat%2F0102201%2Ccond-mat%2F0102487%2Ccond-mat%2F0102520%2Ccond-mat%2F0102073%2Ccond-mat%2F0102017%2Ccond-mat%2F0102146%2Ccond-mat%2F0102094%2Ccond-mat%2F0102340%2Ccond-mat%2F0102082%2Ccond-mat%2F0102506%2Ccond-mat%2F0102457%2Ccond-mat%2F0102407%2Ccond-mat%2F0102459%2Ccond-mat%2F0102001%2Ccond-mat%2F0102177%2Ccond-mat%2F0102124%2Ccond-mat%2F0102374%2Ccond-mat%2F0102274%2Ccond-mat%2F0102488%2Ccond-mat%2F0102034%2Ccond-mat%2F0102008%2Ccond-mat%2F0102205%2Ccond-mat%2F0102116%2Ccond-mat%2F0102059%2Ccond-mat%2F0102255%2Ccond-mat%2F0102190%2Ccond-mat%2F0102080%2Ccond-mat%2F0102191%2Ccond-mat%2F0102006%2Ccond-mat%2F0102046%2Ccond-mat%2F0102135%2Ccond-mat%2F0102023%2Ccond-mat%2F0102022%2Ccond-mat%2F0102434%2Ccond-mat%2F0102123%2Ccond-mat%2F0102497%2Ccond-mat%2F0102384%2Ccond-mat%2F0102112%2Ccond-mat%2F0102071%2Ccond-mat%2F0102507%2Ccond-mat%2F0102236%2Ccond-mat%2F0102203%2Ccond-mat%2F0102452%2Ccond-mat%2F0102418%2Ccond-mat%2F0102232%2Ccond-mat%2F0102403%2Ccond-mat%2F0102286%2Ccond-mat%2F0102307%2Ccond-mat%2F0102455%2Ccond-mat%2F0102376%2Ccond-mat%2F0102401%2Ccond-mat%2F0102226%2Ccond-mat%2F0102321%2Ccond-mat%2F0102524&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We present exact analytic results for a new version of the Minority Game (MG)\nin which strategy performance is recorded over a finite time horizon. The\ndynamics of this Time Horizon Minority Game (THMG) exhibit many distinct\nfeatures from the MG and depend strongly on whether the participants are fed\nreal, or random, history strings. The THMG equations are equivalent to a Markov\nChain, and yield exact analytic results for the volatility given a specific\nrealization for the quenched strategy disorder."}, "authors": ["Michael L. Hart", "Paul Jefferies", "Neil F. Johnson"], "author_detail": {"name": "Neil F. Johnson"}, "author": "Neil F. Johnson", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/S0378-4371(02)00804-X", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/cond-mat/0102384v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cond-mat/0102384v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Latex file, 11 pages, 6 figures", "arxiv_primary_category": {"term": "cond-mat.dis-nn", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cond-mat.dis-nn", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "nlin.AO", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cond-mat/0102384v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cond-mat/0102384v1", "journal_reference": null, "doi": "10.1016/S0378-4371(02)00804-X", "fulltext": "arXiv:cond-mat/0102384v1 [cond-mat.dis-nn] 21 Feb 2001\n\nDynamics of the Time Horizon Minority Game\nMichael L. Hart, Paul Jefferies and Neil F. Johnson\nPhysics Department, Oxford University, Oxford OX1 3PU, U.K.\nNovember 13, 2018\nAbstract\nWe present exact analytic results for a new version of the Minority\nGame (MG) in which strategy performance is recorded over a finite time\nhorizon. The dynamics of this Time Horizon Minority Game (THMG) exhibit many distinct features from the MG and depend strongly on whether\nthe participants are fed real, or random, history strings. The THMG equations are equivalent to a Markov Chain, and yield exact analytic results\nfor the volatility given a specific realization for the quenched strategy\ndisorder.\n\n1\n\nIntroduction\n\nAgent-based models of complex adaptive systems are attracting significant interest across many disciplines[1]. Typically each agent has access to a limited set\nof recent global outcomes of the system; she then combines this information with\nher limited strategy set chosen randomly at the start of the game (i.e. quenched\ndisorder) in order to decide an action at a given timestep. These decisions by\nthe N agents feed back to generate the fluctuations in the system's output. The\nMinority Game (MG) introduced by Challet and Zhang[2, 3] offers possibly the\nsimplest paradigm for such a complex, adaptive system and has therefore been\nthe subject of intense research activity [1]-[9]. Most studies of the MG have\nfocussed on a calculation of both time and configuration (i.e. quenched disorder) averaged quantities, in particular the 'volatility' \u03c3 where \u03c3 is the standard\ndeviation of the fluctuations. Our own work has shown that the variations of\nthis averaged \u03c3 with memory size m can be quantitatively explained in terms\nof 'crowd-anticrowd' collective behavior [5, 6]. This crowd-anticrowd theory,\nwhich implicitly assumes both time-averaging and configuration-averaging, is\nsimple and intuitive yet it yields useful analytic expressions [5, 6]. In terms of\nmore detailed microscopic theories, two complementary spin-glass approaches\nhave been shown to be remarkably powerful[2, 9].\nIn this paper, we wish to focus on the dynamics of the multi-agent game for\na given realization of the quenched disorder of initially picked strategies. We\n1\n\n\fpresent exact analytic results for a finite time horizon version of the Minority\nGame, the Time Horizon Minority Game (THMG), in which strategy performance is only recorded over the previous \u03c4 timesteps. This seemingly trivial\nmodification of the basic MG yields a dynamical system with surprisingly rich\ndynamics. These dynamics depend strongly on whether the participants are fed\nreal (as opposed to random) history strings, and on the nature of the quenched\ndisorder corresponding to initial conditions. We present a set of equations describing the THMG - these equations are equivalent to a Markov Chain. This\nMarkov Chain is used to generate accurate analytic results for the resulting\nvolatility in the THMG. Throughout the paper, similarities and differences between the THMG and MG are pointed out where appropriate. Section 2 provides\na brief introduction to the MG and provides exact analytic expressions for the\nvolatility \u03c3 for a given configuration of quenched disorder. Section 3 discusses\nthe THMG and provides corresponding formulae for this game. Section 4 compares the analytic and numerical results for the THMG. Section 5 provides the\nconclusion.\n\n2\n\nThe basic Minority Game (MG)\n\nThe MG [1, 2] comprises an odd number of agents N (e.g. traders or drivers)\nchoosing repeatedly between option 0 (e.g. buy or choose route 0) and option 1\n(e.g. sell or choose route 1). The winners are those in the minority group; e.g.\nsellers win if there is an excess of buyers, drivers choosing route 0 encounter\nless traffic if most other drivers choose route 1. The outcome at each timestep\nrepresents the winning decision, 0 or 1. A common bit-string of the m most\nrecent outcomes is made available to the agents at each timestep [8]. The\nagents randomly pick s strategies at the beginning of the game, with repetitions\nallowed (quenched disorder). Each strategy is a bit-string of length 2m which\npredicts the next outcome for each of the 2m possible histories. After each turn,\nthe agent assigns one (virtual) point to each of her strategies which would have\npredicted the correct outcome, and penalizes a strategy by one (virtual) point\nif it incorrectly predicts the outcome. At each turn of the game, the agent uses\nthe most successful strategy, i.e. the one with the most virtual points, among\nher s strategies.\nThe number of agents holding a particular combination of strategies can\nbe written as a D \u00d7 D \u00d7 . . . (s terms) dimensional tensor \u03a9, where D is the\ntotal number of available strategies. For s = 2, this is simply a D \u00d7 D matrix\nwhere the entry (i, j) represents the number of agents who picked strategy i\nand then j. The strategy labels are given by the decimal representation of\nthe strategy plus unity, for example the strategy 0101 for m = 2 has strategy\nlabel 5+1=6. This quenched disorder \u03a9 is fixed at the beginning of the game\nand can be written using the full or reduced strategy spaces [2]. The value of\na\u03bcR [2] describes the prediction of strategy R given the history \u03bc, where \u03bc is\nthe decimal number corresponding to the m-bit binary history string. Hence\na\u03bcR = \u22121 denotes a prediction of choice '0' while a\u03bcR = 1 denotes a prediction\n2\n\n\fof choice '1'). The approach of our (time and configuration-averaged) crowdanticrowd theory was to partition the N agents into g groups in such a way that\nthe groups themselves were uncorrelated. This was achieved by considering the\nreduced strategy space, which produces essentially identical results to the full\nstrategy space for the volatility. Specifically, each group g contains a crowd of nC\ng\nagents using highly correlated strategies, and an anticrowd nA\ng of agents using\nstrategies which are highly anti-correlated to the crowd. This leaves an effective\nA\nsuper-agent of size ng = nC\ng \u2212 ng representing each group. Since the strong\ncorrelations have now been removed from the problem, the resulting groups are\nessentially uncorrelated and can be considered as executing random walks with\nrespect to each other in terms of their decisions. As shown in Refs. [5, 6],\nsumming the resulting variances yields excellent agreement with the numerical\nvalues for the volatility hh\u03c3ii\u03a9 , where hh. . . ii\u03a9 denotes averaging over all initial\nconfigurations of quenched disorder {\u03a9}.\nHere we are interested instead in the detailed dynamics of the game for a\ngiven choice of initial quenched disorder \u03a9, hence we follow a more microscopic\napproach. This is particularly relevant if the intended application of such games\nis to understand financial markets, since such markets should each correspond\nto just one realization of the game given an initial \u03a9. Hence we imagine that\na particular \u03a9 has already been chosen. Since the game involves a coin-toss to\nbreak ties in strategy scores, this stochasticity also means that different runs for\na given \u03a9 will also differ - we return to this point below. The number of traders\nmaking decision 1 (the 'instantaneous crowd') minus the number of traders\nmaking decision 0 (the 'instantaneous anticrowd') defines the net 'attendance'\nA[t] at a given timestep t of the game. This attendance A[t] is made up of two\ngroups of traders at any one timestep: there are AD [t] traders who act in a\n'decided' way, i.e. they do not require the toss of a coin to decide which choice\nto make - this is because they have one strategy that is better than their others,\nor because their highest-scoring strategies are tied but give the same response\nas each other to the history \u03bct at that turn of the game. In addition, there\nare AU [t] traders who act in an 'undecided' way, i.e. they require the toss of a\ncoin to decide which choice to make - this is because they have two (or more)\nhighest-scoring tied strategies and these give different responses to the history\n\u03bct at that turn of the game. Hence the outcome at timestep t is given by\nA[t] = AD [t] + AU [t] .\n\n(1)\n\nThe state of the game at the beginning of timestep t depends on the strategy\nscore vector st and a history \u03bct at that moment. Henceforth we will drop\nthe variable t from the notation, but note that it remains an implicit variable\nthrough the time-dependence of s and \u03bc. We also focus on s = 2 strategies per\nagent, although the formalism can be generalized in a straightforward way. At\ntimestep t, AD is given exactly by\nX \u03bc\n(2)\naR (1 + Sgn[sR \u2212 sR\u2032 ])\u03a8R,R\u2032\nAD (s, \u03bc) =\nR,R\u2032 =1\n\n3\n\n\fwhere the symmetrized matrix \u03a8 = 21 (\u03a9+\u03a9T ) with \u03a9 representing the quenched\ndisorder. The element \u03a9R,R\u2032 gives the number of agents picking strategy R and\nthen R\u2032 . The number of undecided traders NU is given exactly by\nX\nNU (s, \u03bc) =\n\u03b4(sR \u2212 sR\u2032 )[1 \u2212 \u03b4(a\u03bcR \u2212 a\u03bcR\u2032 )]\u03a9R,R\u2032\n(3)\nR,R\u2032 =1\n\nand hence the attendance of undecided traders AU is distributed binomially in\nthe following way:\n1\nAU (s, \u03bc) \u2261 2 Bin[NU (s, \u03bc), ] \u2212 NU (s, \u03bc)\n2\n\n(4)\n\nwhere the term 'Bin' denotes a binomial distribution with NU (s, \u03bc) trials and\nprobability 1/2.\nThe so-called 'volatility' is used in finance to describe some statistical characteristic of the fluctuations in the market. It does not have a unique definition\nin the finance literature but is typically taken as some form of 'root-meansquare' fluctuation - however this definition leaves open the question of which\nmean should be computed. In the present context, it makes sense to define the\nvolatility in terms of the time-average of a particular realization k of the random process A[t], given an initial quenched disorder \u03a9. As mentioned above,\nour crowd-anticrowd theory was limited to consideration of a time-averaged\nvolatility hh\u03c3ii\u03a9 which had also been averaged over all configurations of initial\nquenched disorder {\u03a9}. The present work goes beyond this limitation to consideration of a particular choice of quenched disorder \u03a9. Consider any stochastic\nprocess z(t) produced by a particular realization k of the game, given an initial\nquenched disorder \u03a9. This quantity z(t) could represent the attendance A[t] at\ntimestep t, or any time-dependent quantity derived from it such as the mean\nattendance at timestep t calculated over the past n timesteps, or the volatility\ndefined as the root-mean-square attendance over the past n timesteps. The\nfinite time average of the k'th realization of this process is given by\n[(k) z(t)]T \u2261\n\n1\nT\n\nZ\n\nt+T /2\n\n(k)\n\nz(t\u2032 )dt\u2032 .\n\n(5)\n\nt\u2212T /2\n\nIf T is finite, then [(k) z(t)]T is itself a random process. In real financial markets,\nthe volatility defined by such a finite-time average does indeed fluctuate producing 'volatility clustering'. Here we instead wish to focus on the time-average\nwhich is defined in the T \u2192 \u221e limit:\nZ\n1 t+T /2 (k) \u2032 \u2032\n(k) z \u2261 Lim\nz(t )dt ,\n(6)\nT\u2192\u221e\nT t\u2212T /2\nwhich no longer depends on t or T but in general does depend on the particular\nrealization k of the ensemble that we have chosen in addition to the dependence\non the initial quenched disorder \u03a9. In the absence of stochastic tie-breaks,\n4\n\n\fthe attendance A[t] would be deterministic hence producing a deterministic\nMinority Game for a given initial quenched disorder \u03a9 [10]. However in the\npresence of stochastic tie-breaks, which is the case of interest here, the game\nshould self-average in the following sense: for a given quenched disorder \u03a9,\nthe time-average of A[t] or any of its higher order correlation functions (e.g.\nvolatility) for a given realization k should be equivalent to the ensemble average\nvalue taken over all realizations k at a given time t. We stress that this discussion\nis for one particular (fixed ) quenched disorder \u03a9 - we are not averaging over\nthis quenched disorder. Henceforth we will therefore assume that this ergodic\nprinciple holds given a particular \u03a9, i.e. we assume that the time-average and\nensemble-average of both the attendance A[t] and the volatility are equivalent\nfor fixed quenched disorder \u03a9. We will denote this average attendance as A\nand the associated average volatility as \u03c3, noting that both have an implicit\ndependence on the initial quenched disorder \u03a9. Hence for a given \u03a9, the square\nof the volatility is given exactly by the expectation value of the mean-square\nattendance:\nX\n\u03c32 =\n(7)\n(A \u2212 A)2 P (A)\nA\n\nwhere P (A) is the probability that the attendance is given by A. From Eq.\n(1) the attendance A = AD (s, \u03bc) + AU (s, \u03bc, x) where we have included the\nstochastic variable x to denote the coin-toss process. Because this coin-toss\nprocess is unbiased, we have AU (s, \u03bc, x) = 0 and hence A = AD (s, \u03bc). The\nprobability P (A) is exactly equivalent to the probability of obtaining a given s,\n\u03bc and x. Since x is an independent variable, we have\nP (A) = P (\u03bc|s)P (s)P (x)\n\n(8)\n\nwith P (x) given by the binomial expression NU Cx ( 12 )NU . Here P (s) is the\nprobability that the strategy score vector is s, while P (\u03bc | s) is the probability\nthat the game is in a state where the history is \u03bc given that the strategy score\nvector is s. Hence Eq. (7) can be rewritten exactly as\n\u03c32 =\n\nNU \u0014\nX\u0014X\u0014X\n{s}\n\n{\u03bc}\n\nx=0\n\nNU\n\n\u0015\n\u0015\n\u0015\n1\nCx ( )NU (AD + 2x \u2212 NU \u2212 A)2 P (\u03bc | s) P (s) (9)\n2\n\nwith the mean attendance being given exactly by\n\u0015\n\u0015\nX\u0014X\u0014\nA=\nAD P (\u03bc | s) P (s)\n{s}\n\n(10)\n\n{\u03bc}\n\nwhere in Eqs. (9) and (10) AD = AD (s, \u03bc) and NU = NU (s, \u03bc). The difficulty\nin evaluating this expression for the volatility in the MG, for a given quenched\ndisorder \u03a9, now lies in the complexity of P (s) and P (\u03bc | s). As an example of a\nspecific realization of the initial quenched disorder, we shall take \u03a9 throughout\n5\n\n\fthis paper to be the following\nspace:\n\uf8eb\n1\n\uf8ec 0\n\uf8ec\n\uf8ec 2\n\uf8ec\n\uf8ec 2\n\u03a9=\uf8ec\n\uf8ec 1\n\uf8ec\n\uf8ec 2\n\uf8ec\n\uf8ed 0\n3\n\nrandomly-chosen matrix in the reduced strategy\n2\n0\n1\n2\n1\n3\n1\n2\n\n1\n2\n0\n0\n0\n2\n4\n2\n\n0\n2\n3\n3\n2\n0\n7\n0\n\n1\n2\n1\n3\n3\n1\n2\n2\n\n1\n0\n0\n2\n3\n5\n1\n2\n\n1\n2\n2\n2\n2\n1\n0\n2\n\n1\n0\n1\n2\n0\n1\n0\n4\n\n\uf8f6\n\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7 .\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f8\n\n(11)\n\nFigure 1 shows the resulting P (s) for N = 101, m = 2, s = 2 and \u03a9 as\nshown above. The strategy scores themselves are written out explicitly for the\ndominant score vectors. As can be seen, the probability distribution P (s) is\nuneven and has non-trivial structure.\n\n3\n\nTime Horizon Minority Game (THMG)\n\nIn the basic MG, strategy scores are kept since the beginning of the game. One\nmight ask whether this is realistic in a 'real-world' situation, given the finite\ntime-horizon under which most 'agents' (e.g. traders) tend to operate. Hence\nwe will make a small modification to this rule - we introduce the Time Horizon\nMinority Game (THMG) in which strategy scores are only kept over the last\n\u03c4 turns of the game. Hence agents (e.g. traders) are limited to assessing their\nstrategies' performance over the last \u03c4 turns of the game, in addition to the\nbasic MG rule of viewing just the last m steps of the history. We focus on the\nlow m regime because of the richer dynamics, however our formalism applies for\nall m.\nFigure 2 shows numerical results for the variation in volatility as a function\nof \u03c4 , given different realizations of the initial quenched disorder \u03a9. Results are\nshown for m = 3 using the full strategy space, and for both real and random\nhistories of the game. For real histories it can be seen that the volatility is\nessentially periodic in 2.2m . This value corresponds to the number of different\npaths in a De Bruijn graph linking all P = 2m histories. Such a graph is\nnecessarily Eulerian since all the vertex-degrees of a De Bruijn graph are even.\nGames that differ in \u03c4 by multiples of 2.2m show similar dynamics for t > \u03c4 .\nThe dynamics of the THMG for t < \u03c4 are that of the basic MG, as can be seen\nin Figs. 3a and 3b for small t.\nThe peaks in Fig. 2 which arise at \u03c4 = 2.2m \u03bb \u2212 1 for real histories, where\n\u03bb \u2265 1 and is an integer, correspond to realizations of the game that are purely\ndeterministic. If the game performs a path around the de Bruijn graph that is\nof a length \u03c4 and satisfies the condition that all edges have been visited equally\nduring the course of this path, then s and \u03bc at the start of the cycle are identical\nto s and \u03bc at the end of the cycle, i.e. \u2206scycle = 0 and \u2206\u03bccycle = 0. Note that\neven for large \u03bb this is very likely to happen due to the nature of the minority\n6\n\n\fgame in the efficient regime [10]. In the THMG it is observed to occur very\nsoon after t becomes larger than \u03c4 . Once this type of path occurs for integer\n\u03bb, the game evolves such that s\u03bc is equal to \u00b1a\u03bc at any subsequent time-step\nof the game. Note that for integer \u03bb the strategies are scored for one time-step\nless than the period of this special cycle; this fact together with \u2206scycle = 0\nand \u2206\u03bccycle = 0 imply that s\u03bc = \u00b1a\u03bc . When s\u03bc = \u00b1a\u03bc , we are left with the\nunique situation where all tied strategies that have a particular score at history\n\u03bc give the same game decision, i.e. +1 or \u22121. When this happens there are\nno longer any traders that have tied strategies telling them to make opposing\ndecisions. None of the game dynamics for this turn of the game are therefore\ndecided by the tossing of coins - this turn is hence purely deterministic. Once\nthe game has found such a deterministic state, it never leaves it and the game\nhenceforth evolves such that s\u03bc = \u00b1a\u03bc . Figure 3a shows the finite time-average\nstandard deviation (over 100 turns) of the attendance, together with the actual\nnumber of traders making a given decision as a function of time. The case shown\ncorresponds to \u03bb = 100 and hence \u03c4 = 1599. For time-steps 0 to 1599 the system\nis equivalent to that of the basic MG, whereas from t = 1600 onwards the effect\nof the time horizon on strategy scores becomes apparent. The system only takes\nabout 40 time-steps to become locked into the deterministic state described\nabove. We have observed at low m and for several randomly selected \u03a9, that\nonce t becomes larger than \u03c4 then the game rapidly finds the deterministic state\ndescribed above. The game dynamics hence become deterministic and periodic\nwith period \u03c4 + 1. It is possible to construct specially chosen \u03a9 matrices such\nthat the above special cycle is not found during a run of the corresponding game,\nhowever we are here interested in characterising the dynamics for a 'typical' (i.e.\nrandomly chosen) \u03a9. Figure 3b shows the corresponding results for \u03c4 = 1600.\nWe stress that the THMG with random histories has very different dynamics as\ncan be seen in Fig. 2.\nWe now present an analytic description of the THMG. Consider \u03c4 + 1 consecutive histories in the game and call this a \u03bc-path, denoted as \u03bcpath . We define\nG as the matrix telling us which transitions between histories are allowed in the\ngame - the matrix G is the P \u00d7 P 'adjacency' matrix of a de Bruijn graph of\norder m. The element G\u03bc,\u03bd has value 1 if history \u03bd can follow history \u03bc in the\ngame, but has value 0 if the transition is disallowed. The adjacency matrix is\nhence given by\nG\u03bc,\u03bd = \u03b4(2\u03bc%P \u2212 \u03bd) + \u03b4(2\u03bc%P + 1 \u2212 \u03bd)\n\n(12)\n\nwhere A%B is the remainder when A is divided by B. Here \u03bc and \u03bd denote the\nnodes (i.e. histories) in the de Bruijn graph where \u03bc, \u03bd = 0, 1, ... The matrix G\nquantifies which paths around history space are allowed and hence we can write\ndown a rule for determining which \u03bcpath transitions are permitted in the game.\nLet \u03bcpath (t\u22121) = \u03bct\u2212\u03c4 \u22121 \u2192 \u03bct\u2212\u03c4 \u2192 ...\u03bct\u22121 . Whether \u03bcpath (t\u22121) actually arises\nin the game, and whether the transition to \u03bcpath (t) = \u03bct\u2212\u03c4 \u2192 \u03bct\u2212\u03c4 +1 \u2192 ...\u03bct\nis allowed, depends on whether all the transitions are allowed between histories\nin \u03bcpath (t \u2212 1) and the corresponding history in \u03bcpath (t). Figure 4 shows an\n7\n\n\fexample of the allowed transitions between \u03bc-paths for m = 2, \u03c4 = 2. Let us\ndefine a scalar quantity \u0393 given by\n\u0393=\n\n\u03c4\nY\n\nG\u03bc\n\nt\u22121\u2212i ,\u03bct\u2212i\n\n.\n\n(13)\n\ni=0\n\nThe transition between \u03bcpath (t \u2212 1) and \u03bcpath (t) is allowed if \u0393 = 1, but is\ndisallowed if \u0393 = 0. The increment in score vector when passing from one\nhistory at time-step t \u2212 1 to the next history at time-step t is given by\n\u03b4s\u03bct\u22121 \u2192\u03bct = (2a\u03bct\u22121 \u2212 1)(2(\u03bct %2) \u2212 1)\n\n(14)\n\nIt follows that\ns\u03bcpath =\n\n\u03c4\n\u22121\nX\n\n\u03b4s\u03bct\u22121\u2212i \u2192\u03bct\u2212i .\n\n(15)\n\ni=0\n\nWe can evaluate the exact number of decided and undecided traders for a\ngiven \u03bcpath , and we can also identity which \u03bcpath are allowed in the game; hence\nwe can find the transition matrix giving the probability that a particular \u03bcpath\nat an arbitrary timestep evolves to the next allowed \u03bcpath with final history \u03bct .\nThis transition matrix is given as follows:\nNU \u0014\nX\n\n\u0014\n1 NU\nC\n(\n\u03b4\nSgn(AD + 2x \u2212 NU )\n)\nx\npath (t\u22121),\u03bcpath (t)\n2\nx=0\n\u0015\u0015\n+ (2(\u03bct %2) \u2212 1)\n\nT\u03bc\n\n=\n\nNU\n\n(16)\n\nwhere AD = AD (\u03bcpath (t \u2212 1)) = AD (s\u03bcpath (t\u22121) , \u03bct\u22121 ) and NU = NU (\u03bcpath (t \u2212\n1)) = NU (s\u03bcpath (t\u22121) , \u03bct\u22121 ). The size of T is given by \u03c6 = 2(m+\u03c4 ) . For the\nbasic MG \u03c6 would grow indefinitely with time t, however for the THMG it\nis of fixed size. Having obtained this transition matrix for the THMG then\nallows us to calculate various macroscopic quantities, in particular P (\u03bcpath ).\nThe vector P (\u03bcpath ) satisfies P (\u03bcpath ) = P (\u03bcpath )T which is the transpose of\nan eigenvector-eigenvalue equation. The vector P (\u03bcpath ) is also a stationary\ndistribution of the Markov Chain:\nP (\u03bcpath ) = [\u03c6\u22121 1 T \u221e ]\u03bcpath .\n\n(17)\n\nThe expression given for P (\u03bcpath ) represents an average over all games with\ndifferent \u03bc-paths defining the initial conditions of the game. This is achieved by\ntaking an average over all \u03c6 rows of the matrix T \u221e . This method assumes that,\nfor all possible states in the set {\u03bcpath }, if a state is visited then the state can be\nre-visited during a run of the game. We note that if there are closed irreducible\nsubsets in the set of \u03bc-paths {\u03bcpath } which are visited during the time evolution\nof the THMG, the game can then lock into a deterministic state. This situation\n8\n\n\fof deterministic states arises for \u03c4 = 2.2m \u03bb \u2212 1 as discussed earlier. In this\ncase, the present method for calculating P (\u03bcpath ) could be improved to account\nmore fully for the deterministic dynamics since in general the system is not\nergodic We do not consider such a calculation here, but note that the values of\n\u03c3 obtained using the present method may still be very accurate (see later Fig.\n6 for \u03c4 = 7 for example).\nFigure 5a shows the measured P (\u03bcpath ) for N = 101, m = 2, s = 2, \u03a9 as\nin Eq. (11) and \u03c4 = 2. Figure 5b shows the corresponding calculated P (\u03bcpath )\nusing Eq. (13). The agreement is excellent, demonstrating that our expression\nfor P (\u03bcpath ) is exact.\n\n4\n\nResults\n\nWe now show how to calculate the volatility of the THMG exactly using Eq.\n(9). Without loss of generality, we replace both P (s) and P (\u03bc | s) by the\nprobability P (\u03bcpath ) that the game has just passed through one particular \u03bcpath\nat a timestep t. This reduces the problem of calculating the volatility \u03c3 in the\nTHMG to that of studying a Markov Chain whose states are given by the set\n{\u03bcpath }. Note that whilst the THMG is homogeneous, the basic MG is not\nsince the size of the set {\u03bcpath } grows as t increases. Replacing both P (s) and\nP (\u03bc | s) by the probability P (\u03bcpath ) in Eq. (9), we have an equivalent exact\nexpression for \u03c3 given by :\n\u03c32 =\n\nNU \u0014\nX \u0014X\n\n{\u03bcpath }\n\nx=0\n\nNU\n\n\u0015\n\u0015\n1\nCx ( )NU (AD + 2x \u2212 NU \u2212 A)2 P (\u03bcpath ) .\n2\n\n(18)\n\nIn order to calculate AD and NU exactly for a given \u03bcpath , the score vector\nto be used is that which would be obtained if the game went through a path\nof histories corresponding to \u03bcpath as in Eq. (15); the history to be used is\nthe last history in the path \u03bcpath . Denoting this last history as \u03bc, we have\nAD = AD (\u03bcpath ) = AD (s\u03bcpath , \u03bc) and NU = NU (\u03bcpath ) = NU (s\u03bcpath , \u03bc). We\nnote that the exact analytic expression given for \u03c3 in Eq. (18) applies to the\nlimiting case where the number of realizations used to numerically determine \u03c3\ntends to infinity (i.e. ensemble average). We also note that using the formalism\ndescribed, we could alternatively have obtained a finite time-average volatility\n\u03c3 between t = t1 and t = t2 given a specific \u03bcpath at t = t1 .\nUsing Eq. (17) in Eq. (18), together with Eqs. (2), (3) and (10), we\nobtain analytic values for \u03c3 in the THMG given the initial quenched disorder\n\u03a9. Figure 6 shows a comparison between the analytic values for the volatility \u03c3\nand the numerical values taken from the game as a function of the time-horizon\n\u03c4 . Here N = 101, m = 2, s = 2, and \u03a9 is given in Eq. (11). We only show\n\u03c4 = 1 \u2192 2.2m + 1, i.e. \u03bb = 1; however similar results can also be obtained\nfor \u03bb > 1. The agreement is excellent, with the numerical and analytic lines\nessentially coincident. This demonstrates the power and accuracy of the present\nMarkov Chain formalism as developed for the THMG.\n9\n\n\f5\n\nConclusion\n\nIn summary, we have introduced and studied a finite time horizon version of\nthe Minority Game (THMG). We have presented exact analytic expressions for\nthe volatility in both the THMG and the basic MG, for a given configuration of\ninitial quenched disorder \u03a9. We have presented an analytic theory to describe\nthe dynamics of the THMG by obtaining an analytic expression for the transition matrix in terms of the set {\u03bcpath }. As an example of what can be achieved\nanalytically, we obtained excellent agreement between analytic and numerical\nvalues for the THMG volatility, given knowledge of the initial quenched disorder \u03a9. Finally we would like to stress that our theoretical approach and results\navoid having to keep track of the labels of individual agents - our results are obtained for a specific initial quenched disorder \u03a9, however this \u03a9 describes many\npossible arrangements of individual agents. In this sense, \u03a9 defines a macrostate\nfor which there are many possible microstates corresponding to different initial\nstrategy choices by the N individual agents.\nWe thank Pak Ming Hui for discussions.\n\n10\n\n\fReferences\n[1] See http://www.unifr.ch/econophysics for a detailed account of previous\nwork on agent-based games such as the Minority Game.\n[2] D. Challet and Y.C. Zhang, Physica A 246, 407 (1997); ibid. 256, 514\n(1998); ibid. 269, 30 (1999); D. Challet and M. Marsili, Phys. Rev. E 60,\nR6271 (1999); D. Challet, M. Marsili, and R. Zecchina, Phys. Rev. Lett.\n84, 1824 (2000); M Marsili, D. Challet and R. Zecchina cond-mat/9908480;\nM Marsili and D. Challet cond-mat/0102257.\n[3] R. Savit, R. Manuca and R. Riolo, Phys. Rev. Lett. 82, 2203 (1999). See\nalso Physica A 276, 234 (2000) and 265 (2000).\n[4] R. D'Hulst and G.J. Rodgers, Physica A 270, 514 (1999).\n[5] M. Hart, P. Jefferies, N.F. Johnson and P.M. Hui, cond-mat/0003486; Phys.\nRev. E 63, 017102 (2001); cond-mat/0005152; cond-mat/0008385 (to appear in Eur. J. Phys. B 2001); P. Jefferies, M. Hart, N.F. Johnson and P.M.\nHui, J. Phys. A: Math. Gen. 33 L409 (2000).\n[6] N.F. Johnson, P.M. Hui, D. Zheng and M. Hart, J. Phys. A: Math. Gen.\n32 L427 (1999); N.F. Johnson, M. Hart and P.M. Hui, Physica A 269, 1\n(1999).\n[7] A. Cavagna, J.P. Garrahan, I. Giardina and D. Sherrington, Phys. Rev.\nLett. 83, 4429 (1999); J.P. Garrahan, E. Moro and D. Sherrington, condmat/0012269; A. Cavagna, Phys. Rev. E 59, R3783 (1999).\n[8] See D. Challet and M. Marsili, cond-mat/0004196 for discussions of the\nrelevance of the actual memory in the MG, and diffusion around de Bruijn\ngraphs.\n[9] J.A.F. Heimel and A.C.C. Coolen, cond-mat/0012045.\n[10] P. Jefferies, M.L. Hart and N.F. Johnson (in preparation).\n\n11\n\n\fFIG. 1. The probability of occurrence P (s) of the strategy score vector\nobtained numerically from the Minority Game (MG). Strategy score vectors s\nare listed in an arbritary order along the x-axis. Unless otherwise stated, the\ngame parameters in Figs. 1-6 are as follows: N = 101, m = 2, s = 2 with the\ninitial quenched disorder matrix \u03a9 taken from Eq. (11).\nFIG. 2. Standard deviation (volatility) \u03c3 as a function of time horizon \u03c4\nfor the Time Horizon Minority Game (THMG) with m = 3. Results are obtained using the full strategy space. Numerical data is collected using real histories (black circles) and random histories (grey circles) with randomly selected\nquenched disorder matrices \u03a9. The lower short-dashed line shows the value of\nthe volatility for the basic MG in the high m limit. The upper long-dashed line\nshows the configuration-average volatility (i.e. average over quenched disorder\n\u03a9) for the basic MG with m = 3.\nFIG. 3. The finite time-average standard deviation (average taken over 100\nturns) of the attendance of traders (black line) together with the number of\ntraders choosing '1' (grey circles) as a function of time t. (a) \u03bb = 100, i.e.\n\u03c4 = 1599. (b) \u03c4 = 1600.\nFIG. 4. Schematic diagram showing the allowed transitions between \u03bc-paths\nin the THMG for the following example: \u03bcpath (t \u2212 1) = 2 \u2192 0 \u2192 1 and\nm = 2, \u03c4 = 2.\nFIG. 5. (a) Numerical and (b) analytic results for the probability distribution\nP (\u03bcpath ) as a function of \u03bcpath . \u03bc-path are listed in order of increasing decimal\nrepresentation along the x-axis. Game parameters are N = 101, m = 2, s = 2,\n\u03a9 as in Eq. (11), and \u03c4 = 2.\nFIG. 6. Standard deviation (volatility) \u03c3 for the THMG as a function of\ntime horizon \u03c4 , for a given initial quenched disorder \u03a9. Exact analytic values\nare grey diamonds joined by a thick grey dashed line, numerical values taken\nfrom the game simulation are black circles joined by a thick black line. These\nlines are essentially coincident thereby demonstrating the excellent agreement\nbetween the analytic theory and the numerical results. Here N = 101, m = 2,\ns = 2, and \u03a9 is from Eq. (11). Lower short-dashed line shows the value of the\nvolatility for the basic MG in the high m limit. Upper long-dashed line shows\nthe configuration-average volatility (i.e. average over quenched disorder \u03a9) for\nthe basic MG with m = 2.\n\n12\n\n\fstrategy score vector\n\n(0,0,0,0,0,0,0,0)\n(0,0,2,-2,2,-2,0,0)\n\n(1,-1,1,-1,1,-1,1,-1)\n\n(1,1,-1,-1,1,1,-1,-1)\n\n(2,0,0,-2,2,0,0,-2)\n\n(3,-1,-1,-1,1,1,1,-3)\n\n0.175\n\n0.15\n\n0.125\n\n0.1\n\n0.075\n\n0.05\n\n0.025\n\n0\n\nFig. 1\n\nprobability of occurrence\n\n\fstandard deviation\n\n\u03c3\n\n60\n\n50\n\n40\n\n30\n\n20\n\nreal history\n\n10\n\nrandom history\n0\n0\n\nFig. 2\n\n16\n\n32\n\n48\n\ntime horizon \u03c4\n\n64\n\n80\n\n\f90\n\n(a)\n\n80\n\nN1(t) and \u03c3\n\n70\n60\n50\n40\n30\n20\n10\n0\n0\n\n1000\n\n2000\n\n3000\n\n4000\n\n5000\n\n6000\n\ntime t\n80\n\n(b)\n\n70\n\nN1(t) and \u03c3\n\n60\n50\n40\n30\n20\n10\n0\n0\n\nFig. 3\n\n1000\n\n2000\n\n3000\n\ntime t\n\n4000\n\n5000\n\n6000\n\n\f\u03bcpath at time t-1\n\n\u03bcpath at time t\n\nFig. 4\n\n\f0.175\n0.15\n\n(a) numerical\n\nP(\u03bcpath)\n\n0.125\n0.1\n0.075\n0.05\n0.025\n0\n\n\u03bcpath\n\n0.175\n0.15\n\n(b) analytic\n\nP(\u03bcpath)\n\n0.125\n0.1\n0.075\n0.05\n0.025\n0\n\nFig. 5\n\n\u03bcpath\n\n\fstandard deviation of attendance \u03c3\n\n60\n\nnumerical\n50\n\nanalytic\n\n40\n\n30\n\n20\n\n10\n\n0\n0\n\nFig. 6\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\ntime horizon \u03c4\n\n7\n\n8\n\n9\n\n\f"}