{"id": "http://arxiv.org/abs/1203.1502v1", "guidislink": true, "updated": "2012-02-27T16:07:47Z", "updated_parsed": [2012, 2, 27, 16, 7, 47, 0, 58, 0], "published": "2012-02-27T16:07:47Z", "published_parsed": [2012, 2, 27, 16, 7, 47, 0, 58, 0], "title": "Performance Evaluation of Biometric Template Update", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1203.4513%2C1203.2971%2C1203.0818%2C1203.1502%2C1203.1406%2C1203.4559%2C1203.3640%2C1203.3416%2C1203.4269%2C1203.3406%2C1203.0148%2C1203.4308%2C1203.0335%2C1203.3626%2C1203.2995%2C1203.1921%2C1203.5537%2C1203.1915%2C1203.3153%2C1203.5263%2C1203.1914%2C1203.6518%2C1203.2141%2C1203.3956%2C1203.5013%2C1203.2889%2C1203.0615%2C1203.0061%2C1203.3093%2C1203.2311%2C1203.3370%2C1203.5496%2C1203.6593%2C1203.4584%2C1203.4489%2C1203.5340%2C1203.5991%2C1203.4042%2C1203.2721%2C1203.2513%2C1203.0488%2C1203.0879%2C1203.0574%2C1203.1767%2C1203.0308%2C1203.0204%2C1203.6123%2C1203.1484%2C1203.4250%2C1203.0496%2C1203.1807%2C1203.3094%2C1203.4498%2C1203.2073%2C1203.2352%2C1203.4813%2C1203.0924%2C1203.5304%2C1203.6405%2C1203.1135%2C1203.2443%2C1203.6173%2C1203.5984%2C1203.2440%2C1203.5936%2C1203.3177%2C1203.0499%2C1203.4509%2C1203.3825%2C1203.0901%2C1203.2301%2C1203.1144%2C1203.4991%2C1203.3514%2C1203.0265%2C1203.3181%2C1203.1598%2C1203.6032%2C1203.3575%2C1203.2770%2C1203.5169%2C1203.3661%2C1203.2927%2C1203.4314%2C1203.2040%2C1203.6532%2C1203.5346%2C1203.0325%2C1203.3880%2C1203.5214%2C1203.1343%2C1203.2350%2C1203.1763%2C1203.6082%2C1203.4254%2C1203.6255%2C1203.0676%2C1203.5189%2C1203.1736%2C1203.0870%2C1203.5203&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Performance Evaluation of Biometric Template Update"}, "summary": "Template update allows to modify the biometric reference of a user while he\nuses the biometric system. With such kind of mechanism we expect the biometric\nsystem uses always an up to date representation of the user, by capturing his\nintra-class (temporary or permanent) variability. Although several studies\nexist in the literature, there is no commonly adopted evaluation scheme. This\ndoes not ease the comparison of the different systems of the literature. In\nthis paper, we show that using different evaluation procedures can lead in\ndifferent, and contradictory, interpretations of the results. We use a\nkeystroke dynamics (which is a modality suffering of template ageing quickly)\ntemplate update system on a dataset consisting of height different sessions to\nillustrate this point. Even if we do not answer to this problematic, it shows\nthat it is necessary to normalize the template update evaluation procedures.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1203.4513%2C1203.2971%2C1203.0818%2C1203.1502%2C1203.1406%2C1203.4559%2C1203.3640%2C1203.3416%2C1203.4269%2C1203.3406%2C1203.0148%2C1203.4308%2C1203.0335%2C1203.3626%2C1203.2995%2C1203.1921%2C1203.5537%2C1203.1915%2C1203.3153%2C1203.5263%2C1203.1914%2C1203.6518%2C1203.2141%2C1203.3956%2C1203.5013%2C1203.2889%2C1203.0615%2C1203.0061%2C1203.3093%2C1203.2311%2C1203.3370%2C1203.5496%2C1203.6593%2C1203.4584%2C1203.4489%2C1203.5340%2C1203.5991%2C1203.4042%2C1203.2721%2C1203.2513%2C1203.0488%2C1203.0879%2C1203.0574%2C1203.1767%2C1203.0308%2C1203.0204%2C1203.6123%2C1203.1484%2C1203.4250%2C1203.0496%2C1203.1807%2C1203.3094%2C1203.4498%2C1203.2073%2C1203.2352%2C1203.4813%2C1203.0924%2C1203.5304%2C1203.6405%2C1203.1135%2C1203.2443%2C1203.6173%2C1203.5984%2C1203.2440%2C1203.5936%2C1203.3177%2C1203.0499%2C1203.4509%2C1203.3825%2C1203.0901%2C1203.2301%2C1203.1144%2C1203.4991%2C1203.3514%2C1203.0265%2C1203.3181%2C1203.1598%2C1203.6032%2C1203.3575%2C1203.2770%2C1203.5169%2C1203.3661%2C1203.2927%2C1203.4314%2C1203.2040%2C1203.6532%2C1203.5346%2C1203.0325%2C1203.3880%2C1203.5214%2C1203.1343%2C1203.2350%2C1203.1763%2C1203.6082%2C1203.4254%2C1203.6255%2C1203.0676%2C1203.5189%2C1203.1736%2C1203.0870%2C1203.5203&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Template update allows to modify the biometric reference of a user while he\nuses the biometric system. With such kind of mechanism we expect the biometric\nsystem uses always an up to date representation of the user, by capturing his\nintra-class (temporary or permanent) variability. Although several studies\nexist in the literature, there is no commonly adopted evaluation scheme. This\ndoes not ease the comparison of the different systems of the literature. In\nthis paper, we show that using different evaluation procedures can lead in\ndifferent, and contradictory, interpretations of the results. We use a\nkeystroke dynamics (which is a modality suffering of template ageing quickly)\ntemplate update system on a dataset consisting of height different sessions to\nillustrate this point. Even if we do not answer to this problematic, it shows\nthat it is necessary to normalize the template update evaluation procedures."}, "authors": ["Romain Giot", "Christophe Rosenberger", "Bernadette Dorizzi"], "author_detail": {"name": "Bernadette Dorizzi"}, "author": "Bernadette Dorizzi", "arxiv_comment": "International Biometric Performance Testing Conference 2012,\n  Gaithersburg, MD, USA : United States (2012)", "links": [{"href": "http://arxiv.org/abs/1203.1502v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1203.1502v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.OH", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.OH", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1203.1502v1", "affiliation": "SAMOVAR", "arxiv_url": "http://arxiv.org/abs/1203.1502v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:1203.1502v1 [cs.OH] 27 Feb 2012\n\nPerformance Evaluation\nof Biometric Template Update\nRomain Giot and Christophe Rosenberger\n\nBernadette Dorizzi\n\nUniversit\u00e9 de Caen, UMR 6072 GREYC\nENSICAEN, UMR 6072 GREYC\nCNRS, UMR 6072 GREYC\nEmail: romain.giot@ensicaen.fr\nEmail: christophe.rosenberger@ensicaen.fr\n\nInstitut T\u00e9l\u00e9com; T\u00e9l\u00e9com SudParis\nUMR 5157 SAMOVAR\nEmail: bernadette.dorizzi@it-sudparis.eu\n\nAbstract-Template update allows to modify the biometric\nreference of a user while he uses the biometric system. With\nsuch kind of mechanism we expect the biometric system uses\nalways an up to date representation of the user, by capturing\nhis intra-class (temporary or permanent) variability. Although\nseveral studies exist in the literature, there is no commonly\nadopted evaluation scheme. This does not ease the comparison of\nthe different systems of the literature. In this paper, we show that\nusing different evaluation procedures can lead in different, and\ncontradictory, interpretations of the results. We use a keystroke\ndynamics (which is a modality suffering of template ageing\nquickly) template update system on a dataset consisting of height\ndifferent sessions to illustrate this point. Even if we do not answer\nto this problematic, it shows that it is necessary to normalize the\ntemplate update evaluation procedures.\nIndex Terms-template update, biometric, evaluation\n\nI. I NTRODUCTION\nTemplate update is an active research field whose aim is to\nupdate the biometric reference of individuals while using the\nbiometric system. Even if the reason of using template update\nsystems are various (template ageings, noisy acquisitions, lack\nof samples during enrollment, ...), the expected result is always\nthe same: the improvement of the recognition performance.\nTemplate update mechanisms may vary depending of different factors (which are not directly subject of this work, as\nwe are interested on the evaluation of this mechanism):\n\u2022 The choice of the of update criteria (threshold, graph\nbased, ...).\n\u2022 The periodicity of the template update (online and batch,\nor offline, at various frequencies).\n\u2022 The working mode of the template update system (supervised or semi-supervised): in the first case, we guaranty\nno impostor data has been used for the template update.\n\u2022 The template update mechanism (mainly the employed\nmethod used to modify the biometric references).\nA very nice work 1 , exposes the various points of differences\nto specify in the studies [1] (they argue that these informations\nare mainly missing in studies). Nevertheless, this work does\nnot explore the performance evaluation procedure computation\n(they give information about the way of evaluating the system,\n1 although\n\nspecific to keystroke dynamics\n\nbut not on the way of computing the error rate). It is necessary\nto quantify the performance evolution using such kind of\nmechanism. We will show that different performance computing methods lead to different interpretations of the results. In\nthis work, we present the differences in the various template\nupdate (or related) evaluation schemes in the literature. We\ndo not emphasize on the template update mechanisms. We\nraise the questions that must be answered by the template\nupdate community in order to allow an easy evaluation and\ncomparison of the template update mechanisms.\nThe paper is organised as following. Section II briefly\npresents the datasets used in the literature for works on\ntemplate update. Section III presents the different ways encountered in the literature to evaluate the template updating\nschemes. Section IV illustrates the problem of not having\na common evaluation methodology in the template update\nstudies. Section V raises various open questions on template\nupdate evaluation methodology.\nII. AVAILABLE P UBLIC DATABASES\nStudies on template update require adequate datasets. Various datasets have been used in the literature. They all differ in\nnumber of subjects, number of samples per subjects, number\nof sessions, time difference between the youngest and oldest\nsample, type of variability. . . The following datasets have been\nused in the literature in template update works or in studies\nanalysing the variability of samples through time:\n\u2022 2D face recognition: there are several datasets for face\nrecognition. In this case, the variabilities are mainly due\nto pose or illumination differences, but few datasets allow\nthe study of templates ageing by capturing data on a very\nlong period while having a lot of users.\n\u2013 The Equinox Face Dataset [2] is often used but does\nnot seem to be yet freely available. The number of\nindividuals and samples varies between studies (they\ndo not use the same subset).\n\u2013 The dataset MORPH [3] has been used in several\nstudies. Once again, the number of individuals and\nsamples varies in studies.\n\u2013 The UMIST Face database contains 564 images of\n20 individuals. Most studies in the state of the art do\n\n\f\u2022\n\n\u2022\n\n\u2022\n\n\u2022\n\nnot use the whole set.\n\u2013 The AR [4] contains several color images of 120\nindividuals captured on two sessions.\n\u2013 Drygajlo et al. [5] used youtube's videos of people\nproviding their face each day during three years\nin general. The timespan is superior to the other\ndatasets, but the number of users is very low and no\nground truth is available (automatic image extraction\ncan be erroneous, nothing proves that pictures are\npresented in chronological order,. . . ).\n\u2013 VADANA [6] is the most recent dataset designed\nespecially for template update in face recognition\nsystems. 43 subjects have in average 53 pictures,\ndelta between two pictures of an individual can be\nof several years. This dataset has more intra-class\ncomparison than other long term datasets.\n3D face recognition. The Face Recognition Grand Challenge (FRGC) Experiment 3 [7] provides 3D faces linked\nto color information. Dataset is splitted in a training set\nof 270 individuals and a testing in of 410 individuals.\nFingerprint recognition. The dataset [8] comes from the\ncompetition \"Fingerprint Verification Competition\". Four\ndifferent sub-datasets are available. Each of them contains\n110 fingers with 8 samples per finger. This dataset is\nnot appropriate to study variation through time, but it is\ninteresting because of the high intra-class variability of\nusers [9].\nKeystroke Dynamics.\n\u2013 The GREYC keystroke [10] dataset has been captured\namong 5 distinct sessions with 100 individuals.\n\u2013 The DSN2009 [11] has been captured amoung 8\ndistinct sessions with 51 individuals.\nHandwritten signature. The dataset MCYT-100 [12] is a\nmultimodal biometric database (fingerprint and handwritten signature) which has been used to verify the reliably\nof extracted features through time [13].\n\nWe can see there are various datasets available for several\ndifferent biometric modalities ; they are summarised in the\ntable I. Most dataset are related to 2D face recognition which\nis a morphological modality which hold less variability than\nany behavioral biometric. The properties of these datasets are\nreally different. Few of them have been captured in a long\ntimespan. They are more useful to analyze the intra-class\nvariability due to temporary variations than template ageing.\nIn the next section, we present the existing evaluation\nschemes for template update algorithms.\nIII. E XISTING E VALUATION S CHEMES\nFew template update studies exist in the literature. In this\nsection, we present the different evaluation protocols found\nin the literature, using datasets separated in several sessions\n(also called batch in some studies), or not. We also present\nthe different ways of presenting the queries to the biometric\nreferences.\n\nTABLE I\nS UMMARY OF THE DATASETS USED IN THE LITERATURE . F IGURES ARE\nRELATED TO STUDIES USING THE DATASET AND MAY BE DIFFERENT FROM\nTHE REAL VALUE OF THE DATASET. W E CAN SEE THAN FEW OF THEM\nSEEM APPROPRIATE FOR TEMPLATE UPDATE STUDIES .\n\nDatabase\n\n# users\n\n# samples\n\n# sessions\n\n2D face\nEQUINOX\nMORPH\nUMIST\nAR\nYOUTUBE videos\nVADANA\n\n40-50\n14\n20\n120\n4\n43\n\n20-100\n> 20\n25-55\n26\n1200\n\u224853\n\n2\n1200\n-\n\n3D face\nFRGC-EXP3\n\n410+270\n\n1-22\n\n-\n\nFingerprint\nFVC2002\n\n110\n\n8\n\n1\n\nKeystroke dynamics\nGREYC2009\n100\nDSN2009\n51\n\n60\n400\n\n5\n8\n\nHandwritten signature\nMCYT-100\n100\n\n25\n\n5\n\nA. Studies With Several Sessions\nUsing dataset providing several capture sessions allows\ncomputing error rates specific to sessions. This way, we\ncan track the evolution of the template update through time.\nCuriously, it is only recently that this kind of evaluation has\nbeen encountered [14], [15]. Maybe, such kind of studies\nis not common because the data acquisition is not very\nstraightforward and too much time consuming.\nIn such kind of studies, the first session is used to compute\nthe biometric reference of each user, while the next ones are\nused to apply the template update mechanism and evaluate\nthe update procedure. We can observe two main evaluation\nprocesses:\n\u2022 An online order where the comparison score of the query\nagainst the reference is used to compute the evaluation\nmeasure (and is not only used in the template update\nmechanism).\n\u2022 An offline order where the comparison score of the query\nagainst the reference is not used to compute the evaluation\nmeasure. When the whole query set of the session is\nconsumed, the entire query set of the next session is\nused to evaluate the new biometric references. Following\nthis step, this set is then used for the template update\nprocedure.\nOur personal investigations suspect that these two evaluation\nschemes do not give fundamentally different results, and that\nthe online scheme must be favored to the offline one because:\n1) it simplifies the evaluation procedure,\n2) it avoids unnecessary computations,\n3) it produces an additional session result (as the latest session does not need an additional session to be evaluated).\nWe have also met two different ways of presenting the results:\n\u2022 One performance measure per session [14] computed\n\n\fFig. 1. Summary of all the possible variabilities in a template update evaluation. Dotted nodes represent the possible configuration values, while nodes with\na straight line represent the configuration types. Dark gray nodes represent the variant factors in Section IV, while light gray nodes represent the fixed factors\nin Section IV.\n\n\u2022\n\n\u2022\n\nwith one of the previously presented methods. This gives\nresult specific to each sample of the session.\nOne performance measure per session computed by\naveraging the performance of the current session and\nthe previous ones [15]. Authors argue this is important\nbecause the error rate depends too much on the used test.\nThis smoothing reduces the error rates in comparison to\nthe previous method.\nOne global performance computed with the whole set of\nscores [1].\n\nB. Studies Without Any Session\nMost template update studies use datasets with no session,\nbut samples captured in a more or less long period. We can\nobserve two main evaluation procedures:\n\u2022 Separation of the dataset in two (or three) sub-datasets,\nwhich act as if they were two sessions dependant datasets.\nIn this case, the applied procedures are similar to the\npreviously presented ones [16]. In this case, we have only\none performance measure for the template update system\non the entire dataset.\n\u2022 Computation of the biometric performance at any time,\nby modeling its behavior [17]. Note that this method\nhas been illustrated in order to observe the behaviour\nof a biometric system using no template update system.\nBut, we think it can be used in order to evaluate the\nperformance of an online template update system.\nC. Query Presentation Order\nAnother factor, in the template studies, is the query samples\npresentation order. We think this information belongs to the\n\nevaluation procedure and not directly the template update\nsystem, because performance is dependent of them.\nIn [1], authors make the distinction between global and local\norders.\n1) Global order: The differences can be:\n\u2022 The proportion of impostor samples: this is a very important information, as this factor highly impacts the performance: many impostor samples increases the probability\nof including impostor samples in the biometric references\nand decreases the performance. This information may\nbe unavailable, fixed at one specific value (50% for\nexample), or several ratios can be specified [14].\n\u2022 The presentation order of the different types (genuine or\nimpostor) of samples. This is also an important information, as this factor can also impact the performance by\ndriving the probability of doing wrong template updates.\nWe mainly meet three different behaviors. Depending on\nthe studies, one [14], [15] or all [18] of them can be\npresent. The behaviors are:\n\u2013 Presenting the genuine samples first. All the genuine\nsamples are presented before the impostor samples.\nBefore presenting the first impostor query, the biometric reference might already be highly specialised\nto efficiently recognize genuine queries and reject\nimpostor queries. We expect really good recognition\nrates and few impostor samples inclusion in the\nbiometric reference.\n\u2013 Presenting the impostor samples first. All the impostor samples are presented before the genuine\nsamples. Before presenting the first genuine query,\nthe biometric reference migh already be highly un-\n\n\fspecialised and performs poor results (by having\nincluded too many impostor samples and no genuine\nones to counterbalance that). We expect quite poor\nrecognition rates and a lot of impostor samples\ninclusion in the biometric reference.\n\u2013 Random order presentation. No specific order is\npreferred. The presentation order is totally random\n(although controlled by the impostor ratio). A good\ntemplate update system should include a lot of genuine samples and few impostor samples, while a bad\ntemplate system includes a lot of impostor samples\nand few genuine samples. Performances are averaged\nbut probably more realistic than in the first two cases.\nOf course, this must be done for different impostor\nratios.\n\u2013 Rules based order. The order is directed by a set\nof rules to follow. Such kind of order is problem\nspecific.\n2) Local Order: The local order pays attention to the order\nof presenting impostors samples.\n\u2022\n\u2022\n\u2022\n\n\u2022\n\nTotally random. A random sample from a random impostor is selected.\nClosest. The closest sample (among all the samples of all\nthe impostors) from the biometric reference is chosen.\nRandom impostor. An impostor is chosen randomly. His\nsamples are used, in a chronological order for behavioral\nbiometrics, until another impostor is selected.\nClosest impostor. The impostor closer to the biometric\nreference is selected. His samples are used, in a chronological order for behavioral biometrics, until another\nimpostor is selected.\n\nD. Query Chronology\nThe last important information, regarding the evaluation, is\nthe respect, or not, to the chronology information. When this\ninformation is presented, we met two kinds of papers:\n\u2022\n\nNo chronology respect. In these papers, samples chronology is not respected. It means that a query B tested\nagainst a biometric reference after a query A can be\nyounger than A. In average:\nP(age(A) < age(B)) = P(age(B) < age(A))\n\n\u2022\n\n(1)\n\nwith P(e) the probability of the event e and age(s)\nthe age of the sample s. This procedure is the most\ncommon in the literature whereas it can only be efficient\nif we assume that the template variability is not related\nto ageing but other factors. This is of course false for\nthe behavioral modalities and not always true for the\nmorphological ones.\nRespect of the chronology. The assumption is that biometric sample variability is also related to ageing of the\nbiometric data (whatever the reason). Genuine samples\nare always presented by chronological order, but not\n\nnecessary impostor samples:\nP(age(A) < age(B)) = 1\n\n(2)\n\nP(age(A) \u2265 age(B)) = 0\n\n(3)\n\nFrom this review of the literature, we observe that all studies\nuse different protocols, and, that up to now, no standard\nevaluation procedure exits. Figure 1 summarised the various\npoints subject of variations. It could not be a problem if all\nthese points are indicated in studies [1], because they can be\nrepresentative of different but useful scenarios. However, when\nthe performance evaluation procedure differs, it can hold to no\nsimilar results.\nWe will illustrate the problem that such a situation can\nprovide in Section IV.\nIV. I LLUSTRATION\nThe previous section presents the various differences in\nthe evaluation procedure of a template update system. The\nvariation of one factor holds to another testing scenario. We\nhave not discussed about the evaluation of these scenarios.\nIn this example, we are interested in the evaluation of a\ntemplate update mechanism [14] for a keystroke dynamics [19]\nsystem using the Equal Error Rate (EER) as the evaluation\nmetric. We are not interested in the characteristics of the template update system. This system, which is presented in [14]\naims at applying a semi-supervised update based on an update\nthreshold. We have selected two different configurations of the\ntemplate update system:\n\u2022 System 1: a scenario where the update threshold (distances can be negative) is \u22120.2.\n\u2022 System 2: a scenario where the update threshold is \u22120.3.\nThe following fixed parameters are used for the evaluation:\n\u2022 The dataset [11] provides 8 sessions. The ways of\ncomputing the performance measure are presented later.\nThe first session serves to compute the initial biometric\nreference. The other sessions serve to update the reference\nand compute the performance of the updating system.\n\u2022 We compute the scores for each session in an online way.\n\u2022 The impostor ratio is 30%.\n\u2022 As it is a behavioral modality, we respect the chronology.\n\u2022 The global order of presentation of genuine or impostor\nsamples is random.\n\u2022 The local order of presentation of impostor samples is\nrandom too.\nThis configuration allows us to compute the comparison\nscores while the system is updating. In addition of these fixed\nparameters, we have chosen to select three different ways\nof computing the performance value from these comparison\nscores. Three different evaluation procedures are applied (the\nselected performance indice is the EER):\n\u2022 Performance evaluation A. As done in our previous\nwork [14] where the scores of the current session are\nused to compute its performance.\nAi = EER (scoresi ) ,\n\n\u2200i, 2 \u2264 i \u2264 S\n\n(4)\n\n\f22\n\n26\n\nA\nB\nC\n\n21\n\nA\nB\nC\n\n24\n\n20\nEER (%)\n\nEER (%)\n\n22\n19\n\n20\n18\n\n18\n\n17\n\n16\n\n2\n\n3\n\n4\n\n5\nSession\n\n6\n\n7\n\n16\n\n8\n\n(a) Template update system 1\nFig. 2.\n\n5\nSession\n\n6\n\n7\n\n8\n\n(5)\n\nPerformance evaluation B. As done in [15] where performance of current session is computed by the mean of all\nthe previous session performance (including the current\none).\n\nFigure 1 presents in light gray this fixed configurations and\nin dark gray the varying configurations. Figure 2 presents the\nperformance, on exactly the same set of scores, of the three\nevaluation schemes A, B and C. Although globally, the three\ndifferent evaluations show that system 1 is better than system\n2 (better update involving lower EER), we can propose totally\ndifferent interpretations of the updating system, depending on\nthe chosen evaluation scheme:\n\u2022\n\ni\n\n1 X\nEER (scoresj ) ,\ni \u2212 1 j=2\n\n\u2200i, 2 \u2264 i \u2264 S\n\n(6)\n\n\u2022\n\nWe also have one EER per session.\nB = [B2 , . . . , BS ]\n\u2022\n\n4\n\nPerformances depending on the evaluation method on the same score set. (for the definition of A, B, C see Section IV).\n\nA = [A2 , . . . , AS ]\n\nBi =\n\n3\n\n(b) Template update system 2\n\nwith S the number of sessions, EER(*) the EER computing function and scoresi the scores computed at session\ni (intra and inter comparisons). We have one EER per\nsession.\n\n\u2022\n\n2\n\n(7)\n\nPerformance evaluation C. As done in [1] where only\none measure is computed. In the present case, we merge\nall the scores of all the sessions in one global set and\ncompute the performance measure on this set.\n!\nS\n[\nC = EER\nscoresi\n(8)\ni=2\n\nWe have one EER for the whole interval. To compare\nit easily with the two other methods we duplicate it the\nnumber of test sessions times.\nC = [ C, . . . , C ]\n| {z }\nS\u22121 values\n\n(9)\n\nThis evaluation procedure is repeated ten times and the results\nare averaged (as the process is stochastic due to the impostor\nchoices and order).\n\n\u2022\n\nPerformance evaluation A. Performance of system A\ndecreases fast with time, the template update system\ndoes not perform well. The template update system must\nbe improved, or the biometric modality has a very low\npermanence.\nPerformance evaluation B. Performance of system B\ndecreases with time, but the amount of decreases is\nnot really important, the template update system is not\ntoo bad. The template update is not perfect (there is a\nperformance decrease) but it takes quite well the ageing\ninto account.\nPerformance evaluation C. Performance of system C is\naveraged, but we cannot know if it is because of template\nageing, because of a bad algorithm or because of a bad\ndataset.\n\nAs no performance measure of a system without template\nupdate is presented, we cannot compare the template update systems against the baseline classifier. By the way, the\nperformance evaluation of a system without template update\nwould hold the same performance evaluation problem. The\nperformance evaluation C brings less information than the two\nother ones. So it must be avoided, because we lack the temporal information which is the most important one. However\nperformance evaluation A and performance evaluation B track\ntemporal evaluation, but give different interpretations. Which\none is the most interresting or accurate? In the next section,\nwe raise the questions it would be interesting to answer in\norder to normalize template update evaluation.\n\n\fV. O PEN Q UESTIONS\nAll along this paper, we have analyzed the differences in\nthe evaluation protocols, one can encounter in the various\nbiometric template update studies. The variability found in all\nthe protocols raise many open questions:\n\u2022 What are the characteristics of an interesting dataset\nfor such kind of studies? We have seen that there are\nseveral datasets available for the different modalities; they\nare different in their sample distribution. Few of them\nseem really interesting to be used in template update\nscenarios. It is important to know what are the interesting\ncharacteristics to respect in order to create new useful\ndatasets.\n\u2022 What is the best evaluation procedure in order to easily\ncompare the systems without doing each time all the\nprevious experiments from scratch ? The update evaluation procedure is not yet standardized and procedures are\nreally different between studies. Maybe, it is interesting\nto create new metrics specific for such kind of problem.\nSome studies present the ratio of impostors included in\nthe updated biometric reference, but other metrics could\nbe interesting too.\n\u2022 Is it more informative to work with datasets separated\nin several sessions, or with datasets captured in a longer\nperiod without more information ? We can suspect that:\n\u2013 In the first case, we have datasets with a small\nintra-class variability within sessions and a bigger\nvariability between sessions.\n\u2013 In the second case, we have datasets with in an intraclass variability homogeneously spread other time.\nWithout answering these questions, it will be hard to homogenize and compare the different studies on template update\nmechanisms.\nVI. C ONCLUSION\nWe have presented the different template update evaluation\nschemes encountered in the literature. We can observe that\nthere exist lots of different and incompatible ways to do\nit. This hardly allows the comparison of template update\nmechanisms and their understanding. This asserts the request\nfor the researchers of being very accurate while explaining the\nexperimental protocol in order to ease the reproducibility of\nthe experiment.\nR EFERENCES\n[1] M. M. Seeger and P. Bours, \"How to comprehensively describe a\nbiometric update mechanisms for keystroke authentication,\" in 3rd International Workshop on Security and Communication Networks. IWSCN,\n2011, pp. 1\u20137.\n\n[2] \"Equinox corporation.\" [Online]. Available: http://www.equinoxsensors.\ncom/products/HID.html\n[3] K. Ricanek and T. Tesafaye, \"Morph: A longitudinal image database\nof normal adult age-progression,\" in 7th International Conference on\nAutomatic Face and Gesture Recognition. FGR., 2006, pp. 341\u2013345.\n[4] A. Martinez and R. Benavente, \"The ar face database,\" CVC Technical\nreport, Tech. Rep., 1998.\n[5] A. Drygajlo, W. Li, and K. Zhu, \"Q-stack aging model for face\nverification,\" in Proc. 17th European Signal Processing Conference.\nEUSIPCO, 2009.\n[6] R. Gowri Somanath and C. Kambhamettu, \"Vadana: A dense dataset\nfor facial image analysis,\" in BeFIT 2011 \u2013 First IEEE International\nWorkshop on Benchmarking Facial Image Analysis Technologies, 2011.\n[7] P. Phillips, P. Flynn, T. Scruggs, K. Bowyer, J. Chang, K. Hoffman,\nJ. Marques, J. Min, and W. Worek, \"Overview of the face recognition\ngrand challenge,\" in IEEE Computer Society Conference on Computer\nVision and Pattern Recognition. CVPR., vol. 1, 2005, pp. 947\u2013954.\n[8] \"Fvc2002,\" 2002. [Online]. Available: http://bias.csr.unibo.it/fvc2002/\n[9] B. Freni, G. Marcialis, and F. Roli, \"Replacement algorithms for fingerprint template update,\" in International Conference on Image Analysis\nand Recognition. ICIAR. Springer, 2008, pp. 884\u2013893.\n[10] R. Giot, M. El-Abed, and C. Rosenberger, \"Greyc keystroke: a\nbenchmark for keystroke dynamics biometric systems,\" in IEEE\nInternational Conference on Biometrics: Theory, Applications and\nSystems. BTAS, Sep. 2009, pp. 1\u20136. [Online]. Available: http:\n//hal.archives-ouvertes.fr/hal-00432768/en/\n[11] K. Killourhy and R. Maxion, \"Comparing anomaly-detection algorithms\nfor keystroke dynamics,\" in IEEE/IFIP International Conference on\nDependable Systems & Networks. DSN, 2009, pp. 125\u2013134.\n[12] J. Ortega-Garcia, J. Fierrez-Aguilar, D. Simon, J. Gonzalez, M. FaundezZanuy, V. Espinosa, A. Satue, I. Hernaez, J. Igarza, C. Vivaracho et al.,\n\"Mcyt baseline corpus: a bimodal biometric database,\" in Vision, Image\nand Signal Processing, vol. 150, no. 6, 2004, pp. 395\u2013401.\n[13] N. Houmani, S. Garcia-Salicetti, and B. Dorizzi, \"On assessing the\nrobustness of pen coordinates, pen pressure and pen inclination to time\nvariability with personal entropy,\" in IEEE International Conference on\nBiometrics: Theory, Applications, and Systems. BTAS, 2009.\n[14] R. Giot, B. Dorizzi, and C. Rosenberger, \"Analysis of template update\nstrategies for keystroke dynamics,\" in Workshop on Computational\nIntelligence in Biometrics and Identity Management (CIBIM).\nSpecial Session on Adaptive Classification Systems for Biometric\nRecognition. IEEE Symposium Series in Computational Intelligence.\nSSCI., Paris, France, Apr. 2011, pp. 21\u201328. [Online]. Available:\nhttp://hal.archives-ouvertes.fr/hal-00587106/\n[15] A. Rattani, G. L. Marcialis, and F. Roli, \"Self adaptive systems: An\nexperimental analysis of the performance over time,\" in Workshop\non Computational Intelligence in Biometrics and Identity Management\n(CIBIM). Special Session on Adaptive Classification Systems for Biometric Recognition. IEEE Symposium Series in Computational Intelligence.\nSSCI, 2011.\n[16] F. Roli, L. Didaci, and G. L. Marcialis, Advances in Biometrics.\nSpringerLink, 2008, ch. Adaptive Biometric Systems That Can Improve\nwith Use, pp. 447\u2013471.\n[17] N. Poh, J. Kittler, R. Smith, and J. Tena, \"A method for estimating\nauthentication performance over time, with applications to face biometrics,\" in 12th Iberoamerican Congress on Pattern Recognition. CIARP,\n2007.\n[18] C. Ryu, H. Kim, and A. K. Jain, \"Template adaptation based fingerprint\nverification,\" in 18th International Conference on Pattern Recognition,\n2006. ICPR., 2006.\n[19] R. Giot, M. El-Abed, and C. Rosenberger, \"Keystroke dynamics\noverview,\" in Biometrics / Book 1, D. J. Yang, Ed. InTech,\nJul. 2011, vol. 1, ch. 8, pp. 157\u2013182. [Online]. Available: http:\n//www.intechopen.com/articles/show/title/keystroke-dynamics-overview\n\n\f"}