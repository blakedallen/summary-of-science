{"id": "http://arxiv.org/abs/0708.0522v2", "guidislink": true, "updated": "2007-08-08T08:32:44Z", "updated_parsed": [2007, 8, 8, 8, 32, 44, 2, 220, 0], "published": "2007-08-03T14:19:21Z", "published_parsed": [2007, 8, 3, 14, 19, 21, 4, 215, 0], "title": "Quasi-stationary distributions as centrality measures of reducible\n  graphs", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0708.2260%2C0708.3272%2C0708.3836%2C0708.3034%2C0708.0301%2C0708.1492%2C0708.4054%2C0708.3410%2C0708.2294%2C0708.2709%2C0708.1666%2C0708.1572%2C0708.3048%2C0708.1761%2C0708.0751%2C0708.2388%2C0708.3280%2C0708.0651%2C0708.0943%2C0708.0512%2C0708.2620%2C0708.2397%2C0708.3257%2C0708.0544%2C0708.1746%2C0708.3739%2C0708.0342%2C0708.2166%2C0708.4286%2C0708.2624%2C0708.1716%2C0708.0522%2C0708.1382%2C0708.1883%2C0708.1010%2C0708.0505%2C0708.4071%2C0708.2858%2C0708.3555%2C0708.2630%2C0708.0987%2C0708.3957%2C0708.1887%2C0708.2877%2C0708.1380%2C0708.3030%2C0708.0305%2C0708.1591%2C0708.0106%2C0708.1252%2C0708.0910%2C0708.4233%2C0708.3832%2C0708.2514%2C0708.0803%2C0708.1357%2C0708.0451%2C0708.1097%2C0708.0485%2C0708.3534%2C0708.1838%2C0708.2419%2C0708.2978%2C0708.2615%2C0708.1771%2C0708.0572%2C0708.4238%2C0708.1951%2C0708.3333%2C0708.1317%2C0708.3466%2C0708.3213%2C0708.1143%2C0708.3673%2C0708.0920%2C0708.1648%2C0708.1681%2C0708.0205%2C0708.2344%2C0708.2049%2C0708.1186%2C0708.4262%2C0708.2711%2C0708.1237%2C0708.0773%2C0708.3337%2C0708.1504%2C0708.0672%2C0708.4407%2C0708.3283%2C0708.3773%2C0708.3914%2C0708.1975%2C0708.3783%2C0708.1668%2C0708.3727%2C0708.0874%2C0708.3643%2C0708.0218%2C0708.0127%2C0708.1409&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Quasi-stationary distributions as centrality measures of reducible\n  graphs"}, "summary": "Random walk can be used as a centrality measure of a directed graph. However,\nif the graph is reducible the random walk will be absorbed in some subset of\nnodes and will never visit the rest of the graph. In Google PageRank the\nproblem was solved by introduction of uniform random jumps with some\nprobability. Up to the present, there is no clear criterion for the choice this\nparameter. We propose to use parameter-free centrality measure which is based\non the notion of quasi-stationary distribution. Specifically we suggest four\nquasi-stationary based centrality measures, analyze them and conclude that they\nproduce approximately the same ranking. The new centrality measures can be\napplied in spam detection to detect ``link farms'' and in image search to find\nphoto albums.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0708.2260%2C0708.3272%2C0708.3836%2C0708.3034%2C0708.0301%2C0708.1492%2C0708.4054%2C0708.3410%2C0708.2294%2C0708.2709%2C0708.1666%2C0708.1572%2C0708.3048%2C0708.1761%2C0708.0751%2C0708.2388%2C0708.3280%2C0708.0651%2C0708.0943%2C0708.0512%2C0708.2620%2C0708.2397%2C0708.3257%2C0708.0544%2C0708.1746%2C0708.3739%2C0708.0342%2C0708.2166%2C0708.4286%2C0708.2624%2C0708.1716%2C0708.0522%2C0708.1382%2C0708.1883%2C0708.1010%2C0708.0505%2C0708.4071%2C0708.2858%2C0708.3555%2C0708.2630%2C0708.0987%2C0708.3957%2C0708.1887%2C0708.2877%2C0708.1380%2C0708.3030%2C0708.0305%2C0708.1591%2C0708.0106%2C0708.1252%2C0708.0910%2C0708.4233%2C0708.3832%2C0708.2514%2C0708.0803%2C0708.1357%2C0708.0451%2C0708.1097%2C0708.0485%2C0708.3534%2C0708.1838%2C0708.2419%2C0708.2978%2C0708.2615%2C0708.1771%2C0708.0572%2C0708.4238%2C0708.1951%2C0708.3333%2C0708.1317%2C0708.3466%2C0708.3213%2C0708.1143%2C0708.3673%2C0708.0920%2C0708.1648%2C0708.1681%2C0708.0205%2C0708.2344%2C0708.2049%2C0708.1186%2C0708.4262%2C0708.2711%2C0708.1237%2C0708.0773%2C0708.3337%2C0708.1504%2C0708.0672%2C0708.4407%2C0708.3283%2C0708.3773%2C0708.3914%2C0708.1975%2C0708.3783%2C0708.1668%2C0708.3727%2C0708.0874%2C0708.3643%2C0708.0218%2C0708.0127%2C0708.1409&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Random walk can be used as a centrality measure of a directed graph. However,\nif the graph is reducible the random walk will be absorbed in some subset of\nnodes and will never visit the rest of the graph. In Google PageRank the\nproblem was solved by introduction of uniform random jumps with some\nprobability. Up to the present, there is no clear criterion for the choice this\nparameter. We propose to use parameter-free centrality measure which is based\non the notion of quasi-stationary distribution. Specifically we suggest four\nquasi-stationary based centrality measures, analyze them and conclude that they\nproduce approximately the same ranking. The new centrality measures can be\napplied in spam detection to detect ``link farms'' and in image search to find\nphoto albums."}, "authors": ["Konstantin Avrachenkov", "Vivek Borkar", "Danil Nemirovsky"], "author_detail": {"name": "Danil Nemirovsky"}, "author": "Danil Nemirovsky", "links": [{"href": "http://arxiv.org/abs/0708.0522v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0708.0522v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.NI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.NI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0708.0522v2", "affiliation": "INRIA Sophia Antipolis", "arxiv_url": "http://arxiv.org/abs/0708.0522v2", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "INSTITUT NATIONAL DE RECHERCHE EN INFORMATIQUE ET EN AUTOMATIQUE\n\nKonstantin Avrachenkov - Vivek Borkar - Danil Nemirovsky\n\nN\u00b0 6263\nAugust 2007\n\napport\nde recherche\n\nISRN INRIA/RR--6263--FR+ENG\n\nTh\u00e8me COM\n\nISSN 0249-6399\n\narXiv:0708.0522v2 [cs.NI] 8 Aug 2007\n\nQuasi-stationary distributions\nas centrality measures of reducible graphs\n\n\f\fQuasi-stationary distributions\nas\n\nentrality measures of redu ible graphs\n\u2217\n\nKonstantin Avra henkov\n\n, Vivek Borkar\n\nTh\u00e8me COM \u0016 Syst\u00e8mes\n\n\u2020\n\n\u2021\n\n, Danil Nemirovsky\n\nommuni ants\n\nProjets MAESTRO\nRapport de re her he n\u00b0 6263 \u0016 August 2007 \u0016 19 pages\n\nAbstra t:\n\nRandom walk\n\nan be used as a\n\nentrality measure of a dire ted graph. However, if\n\nthe graph is redu ible the random walk will be absorbed in some subset of nodes and will never\nvisit the rest of the graph. In Google PageRank the problem was solved by introdu tion of uniform\nrandom jumps with some probability. Up to the present, there is no\nthis parameter. We propose to use parameter-free\nof quasi-stationary distribution.\nmeasures, analyze them and\nnew\n\nentrality measures\n\nlear\n\nriterion for the\n\nhoi e\n\nentrality measure whi h is based on the notion\n\nSpe i\u001c ally we suggest four quasi-stationary based\n\nentrality\n\non lude that they produ e approximately the same ranking. The\n\nan be applied in spam dete tion to dete t \u0010link farms\u0011 and in image\n\nsear h to \u001cnd photo albums.\n\nKey-words:\n\nentrality measure, dire ted graph, quasi-stationary distribution, PageRank, Web\n\ngraph, link farm\n\nThis resear h was supported by RIAM INRIA-Canon grant, European resear h proje t Bionets, and by CEFIPRA grant no-2900-IT.\n\n\u2217 INRIA Sophia Antipolis, K.Avra henkov\bsophia.inria.fr\n\u2020 Tata Institute of Fundamental Resear h, India, E-mail: borkar\btifr.res.in\n\u2021\n\nINRIA\n\nSophia\n\nAntipolis,\n\nFran e\n\nand\n\nSt.\n\nPetersburg\n\nState\n\nUniversity,\n\ndanil.nemirovsky\bsophia.inria.fr\n\nUnit\u00e9 de recherche INRIA Sophia Antipolis\n2004, route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex (France)\nT\u00e9l\u00e9phone : +33 4 92 38 77 77 - T\u00e9l\u00e9copie : +33 4 92 38 77 65\n\nRussia,\n\nE-mail:\n\n\fDistributions quasi-stationnaires\nomme les mesures de\nR\u00e9sum\u00e9 :\n\nentralit\u00e9 pour des graphes r\u00e9du tible\n\nUne mar he au hasard peut \u00eatre utilis\u00e9e\n\nomme mesure de\n\nentralit\u00e9 d'un graphe\n\norient\u00e9. Cependant, si le graphe est r\u00e9du tible la mar he au hasard sera absorb\u00e9e dans un quelque\nsous-ensemble de noeuds et ne visitera jamais le reste du graphe.\n\nDans Google PageRank, le\n\nprobl\u00e8me a \u00e9t\u00e9 r\u00e9solu par l'introdu tion des sauts al\u00e9atoires uniformes ave\nlit\u00e9. Jusqu'\u00e0 pr\u00e9sent, il n'y a au un\nd'utiliser la mesure de\n\nrit\u00e8re\n\nlair pour le\n\nhoix de\n\nertaine probabi-\n\nentralit\u00e9 sans param\u00e8tre qui est bas\u00e9e sur la notion de la distribution\n\nquasi-stationnaire. Nous analysons les quatre mesures et\nm\u00eame\n\nune\n\ne param\u00e8tre. Nous proposons\n\nlassement de noeuds. Les nouvelles mesures de\n\non luons qu'elles produisent presque le\n\nentralit\u00e9 peuvent \u00eatre appliqu\u00e9es dans le\n\nontext de la d\u00e9te tion de spam pour d\u00e9te ter les \u0010link farms\u0011 et dans le\n\nontext de la re her he\n\nd'image pour trouver des albums photo.\n\nMots- l\u00e9s :\n\nmesure de entralit\u00e9, mar he au hasard, graphe orient\u00e9, distribution quasi-stationnaire,\n\nPageRank, graphe du Web, link farm\n\n\fQuasi-stationary distributions as entrality measures\n1\n\n3\n\nIntrodu tion\n\nRandom walk\nwalk based\n\nan be used as a\n\nentrality measure of a dire ted graph. An example of random\n\nentrality measures is PageRank [21\u2104 used by sear h engine Google. PageRank is used\n\nby Google to sort the relevant answers to user's query. We shall follow the formal de\u001cnition of\nPageRank from [18\u2104. Denote by\nhyperlink matrix\n\nfor\n\ni, j = 1, ..., n,\n\nlinks is\n\nP\n\nn\n\nthe total number of pages on the Web and de\u001cne the\n\nn\u00d7n\n\nsu h that\n\nwhere\n\ndi\n\n\uf8f1\n\uf8f2 1/di ,\npij =\n1/n,\n\uf8f3\n0,\n\nif page\nif page\n\ni\ni\n\nis dangling,\n\n(1)\n\notherwise,\n\nis the number of outgoing links from page\n\nalled dangling. We note that a\n\ni.\n\nA page with no outgoing\n\nording to (1) there exist arti\u001c ial links to all pages from\n\na dangling node. In order to make the hyperlink graph\nwith some probability\n\nj,\n\nlinks to\n\nonne ted, it is assumed that at ea h step,\n\nc, a random surfer goes to an arbitrary Web page sampled from the uniform\n\ndistribution. Thus, the PageRank is de\u001cned as a stationary distribution of a Markov\n\nhain whose\n\nstate spa e is the set of all Web pages, and the transition matrix is\n\nG = cP + (1 \u2212 c)(1/n)E,\nwhere\n\nE\n\nis a matrix whose all entries are equal to one, and\n\na hyperlink. The\n\nonstant\n\nc\n\nc \u2208 (0, 1)\n\nis a probability of following\n\nis often referred to as a damping fa tor. The Google matrix\n\nsto hasti , aperiodi , and irredu ible, so the PageRank ve tor\n\n\u03c0\n\nG\n\nis\n\nis the unique solution of the\n\nsystem\n\n\u03c0G = \u03c0,\nwhere\n\n1\n\nis a\n\n\u03c01 = 1,\n\nolumn ve tor of ones.\n\nEven though in a number of re ent works, see e.g., [5, 6, 8\u2104, the\n\nc\n\nhas been dis ussed, there is still no\n\nlear\n\npresent work is to explore parameter-free\n\nriterion for the\n\nhoi e of the damping fa tor\n\nhoi e of its value. The goal of the\n\nentrality measures.\n\nIn [5, 7, 15\u2104 the authors have studied the graph stru ture of the Web. In parti ular, in [7, 15\u2104\nit was shown that the Web Graph\n\nan be divided into three prin iple\n\nStrongly Conne ted Component, to whi h we simply refer as SCC\nand the OUT\n\nomponent. The SCC\n\nomponent is the largest strongly\n\nWeb Graph. In fa t, it is larger than the se ond largest strongly\norders of magnitude.\n\nFollowing hyperlinks one\n\nan\n\nonne ted\n\nonne ted\n\nome from the IN\n\nomponent but it is not possible to return ba k. Then, from the SCC\nthe OUT\n\nomponents: the Giant\n\nomponent, the IN\n\nomponent\n\nomponent in the\n\nomponent by several\n\nomponent to the SCC\n\nomponent one\n\nomponent and it is not possible to return to SCC from the OUT\n\nan\n\nome to\n\nomponent. In [7, 15\u2104\n\nthe analysis of the stru ture of the Web was made assuming that dangling nodes have no outgoing\nlinks. However, a\nnode. This\n\nording to (1) there is a probability to jump from a dangling node to an arbitrary\n\nan be viewed as a link between the nodes and we\n\nAs was shown in [5\u2104, these arti\u001c ial links signi\u001c antly\n\nparti ular, the arti\u001c ial links of dangling nodes in the OUT\nOUT\n\nomponent with IN and SCC\n\nall su h a link the arti\u001c ial link.\n\nhange the graph stru ture of the Web. In\nomponent\n\nonne t some parts of the\n\nomponents. Thus, the size of the Giant Strongly Conne ted\n\nComponent in reases further. If the arti\u001c ial links from dangling nodes are taken into a\nis shown in [5\u2104 that the Web Graph\n\nan be divided in two disjoint\n\nConne ted Component (ESCC) and Pure OUT (POUT)\nsmall in size but if the damping fa tor\n\nc\n\nis\n\nount, it\n\nomponents: Extended Strongly\n\nomponent. The POUT\n\nomponent is\n\nhosen equal to one, the random walk absorbs with\n\nprobability one into POUT. We note that nearly all important pages are in ESCC. We also note\nthat even if the damping fa tor is\n\nhosen\n\nlose to one, the random walk\n\nan spend a signi\u001c ant\n\namount of time in ESCC before the absorption. Therefore, for ranking Web pages from ESCC we\nsuggest to use the quasi-stationary distributions [9, 22\u2104.\nIt turns out that there are several versions of quasi-stationary distribution. Here we study four\nversions of the quasi-stationary distribution. Our main\n\nRR\n\nn\u00b0 6263\n\non lusion is that the rankings provided\n\n\fAvra henkov, Borkar & Nemirovsky\n\n4\n\nby them are very similar. Therefore, one\neasier for\n\nan\n\nhose a version of stationary distribution whi h is\n\nomputation.\n\nThe paper is organized as follows: In the next Se tion 2 we dis uss di\u001berent notions of quasistationarity, the relation among them, and the relation between the quasi-stationary distribution\nand PageRank. Then, in Se tion 3 we present the results of numeri al experiments on Web Graph\nwhi h\n\non\u001crm our theoreti al \u001cndings and suggest the appli ation of quasi-stationarity based\n\nentrality measures to link spam dete tion and image sear h. Some te hni al results we pla e in\nthe Appendix.\n\n2\n\nQuasi-stationary distributions as\n\nentrality measures\n\nAs noted in [5\u2104, by renumbering the nodes the transition matrix\n\nP\n\nan be transformed to the\n\nfollowing form\n\nP =\nT\n\nwhere the blo k\n\n\u0014\n\nQ\nR\n\n0\nT\n\n\u0015\n\n,\n\norresponds to the ESCC, the blo k\n\nQ\n\norresponds to the part of the OUT\n\nomponent without dangling nodes and their prede essors, and the blo k\ntransitions from ESCC to the nodes in blo k\nPOUT\n\nQ.\n\nR\n\norresponds to the\n\nWe refer to the set of nodes in the blo k\n\nQ\n\nas\n\nomponent.\n\nThe POUT\n\nomponent is small in size but if the damping fa tor\n\nc\n\nis\n\nhosen equal to one, the\n\nrandom walk absorbs with probability one into POUT. We are mostly interested in the nodes\nin the ESCC\nPOUT\n\nomponent.\n\nDenote by\n\nomponent and denote by\n\n\u03c0T\n\n\u03c0Q\n\na part of the PageRank ve tor\n\na part of the PageRank ve tor\n\norresponding to the\n\norresponding to the ESCC\n\nomponent. Using the following formula [20\u2104\n\n1\u2212c T\n1 [I \u2212 cP ]\u22121 ,\nn\n\n\u03c0(c) =\nwe\n\non lude that\n\n\u03c0T (c) =\nwhere\n\n1\n\n1\u2212c T\n1 [I \u2212 cT ]\u22121 ,\nn\n\nis a ve tor of ones of appropriate dimension.\n\nLet us de\u001cne\n\n\u03c0\u0302T (c) =\nSin e the matrix\n\nProposition 1\n\nT\n\n\u03c0T (c)\n.\n||\u03c0T (c)||1\n\nis substo hasti , we have the next result.\n\nThe following limit exists\n\u03c0T (c)\n1T [I \u2212 T ]\u22121\n= T\n,\nc\u21921 ||\u03c0T (c)||1\n1 [I \u2212 T ]\u22121 1\n\n\u03c0\u0302T (1) = lim\n\nand the ranking of pages in ESCC provided by the PageRank ve tor onverges to the ranking\nprovided by \u03c0\u0302T (1) as the damping fa tor goes to one. Moreover, these two rankings oin ide for\nall values of c above some value c\u2217 .\n\u03c0\u0302T (1) simply by \u03c0\u0302T . Following [9, 12\u2104 we shall all the ve tor \u03c0\u0302T pseudo-stationary\nith omponent of \u03c0\u0302T an be interpreted as a fra tion of time the random walk\nc = 1) spends in node i prior to absorption. We re all that the random walk as de\u001cned in\n\nNext we denote\n\ndistribution. The\n(with\n\nIntrodu tion starts from the uniform distribution. If the random walk were initiated from another\ndistribution, the pseudo-stationary distribution would\nDenote by\n\nT\u0304\n\nhange.\n\nthe hyperlink matrix asso iated with ESCC when the links leading outside of\n\nESCC are negle ted. Clearly, we have\n\nT\u0304ij =\n\nTij\n,\n[T 1]i\n\nINRIA\n\n\fQuasi-stationary distributions as entrality measures\n\n5\n\n[T 1]i denotes the ith omponent of ve tor T 1. In other words, [T 1]i is the sum of elements\nin row i of matrix T . The T\u0304ij entry of the matrix T\u0304 an be onsidered as a onditional probability\nto jump from the node i to the node j under the ondition that random walk does not leave ESCC\nat the jump. Let \u03c0\u0304T be a stationary distribution of T\u0304 .\nLet us now onsider the substo hasti matrix T as a perturbation of sto hasti matrix T\u0304 . We\n\nwhere\n\nintrodu e the perturbation term\n\n\u03b5D = T\u0304 \u2212 T,\n\u03b5\n\nwhere the parameter\n\nis the perturbation parameter, whi h is typi ally small.\n\nThe following\n\nresult holds.\n\nProposition 2\n\nThe ve tor \u03c0\u0302T is lose to \u03c0\u0304T . Namely,\n\u03c0\u0302T = \u03c0\u0304T \u2212 \u03c0\u0304T\n\n1\n1\n(\u03c0\u0304T \u03b5D1)1T X0 1 + 1T X0\n(\u03c0\u0304T \u03b5D1) + o(\u03b5),\nnT\nnT\n\n(2)\n\nwhere nT is the number of nodes in ESCC and X0 is given in Lemma 1 from the Appendix.\nProof: We substitute\n\nT = T\u0304 \u2212 \u03b5D\n\ninto\n\n[I \u2212 T ]\u22121\n\n[I \u2212 T ]\u22121 =\nUsing the above expression, we\n\n\u03c0\u0302T =\n\n1T [I \u2212 T ]\u22121\n=\n1T [I \u2212 T ]\u22121 1\n=\n\n\u0012\n\n\u03c0\u0304T +\n\nand use Lemma 1, to get\n\n1\n1\u03c0\u0304 + X0 + O(\u03b5).\n\u03c0\u0304\u03b5D1\n\nan write\n\n1\nT\n\u03c0\u0304T \u03b5D1 nT \u03c0\u0304T + 1 X0 + O(\u03b5)\n1\nT\n\u03c0\u0304T \u03b5D1 nT + 1 X0 1 + O(\u03b5)\n\n=\n\n1\nT\nnT (\u03c0\u0304T \u03b5D1)1 X0 + o(\u03b5)\n1\nT\nnT (\u03c0\u0304T \u03b5D1)1 X0 1 + o(\u03b5)\n\n\u03c0\u0304T +\n1+\n\n\u0013\u0012\n\u0013\n1\n1\n(\u03c0\u0304T \u03b5D1)1T X0 + o(\u03b5)\n1\u2212\n(\u03c0\u0304T \u03b5D1)1T X0 1 + o(\u03b5)\nnT\nnT\n\n= \u03c0\u0304T \u2212 \u03c0\u0304T\n\n1\n1\n(\u03c0\u0304T \u03b5D1)1T X0 1 + 1T X0\n(\u03c0\u0304T \u03b5D1) + o(\u03b5).\nnT\nnT\n\u2737\n\nSin e\nhas a\n\nR1 + T 1 = 1\n\nlear probabilisti\n\n\u03c0\u0304T .\n\u03c0\u0304T R1\n\nthe distribution\nthat not only\n\nand\n\nT\u0304 1 = 1,\n\nin lieu of\n\n\u03c0\u0304T \u03b5D1\n\nwe\n\nan write\n\n\u03c0\u0304T R1.\n\nThe latter expression\n\ninterpretation. It is a probability to exit ESCC in one step starting from\n\nLater we shall demonstrate that this probability is indeed small. We note\nis small but also the fa tor\n\n1/nT\n\nis small, as the number of states in ESCC\n\nis large.\nIn the next Proposition 3 we provide alternative expression for the \u001crst order terms of\n\nProposition 3\n\n\u03c0\u0302T = \u03c0\u0304T \u2212 \u03b5\u03c0\u0304T DH + \u03b51T\nProof: Let us onsider\n\n\u03c0\u0302T\n\n1\n(\u03c0\u0304T D1)H + o(\u03b5).\nnT\n\nas power series:\n\n(0)\n\n(1)\n\n(2)\n\n\u03c0\u0302T = \u03c0\u0302T + \u03b5\u03c0\u0302T + \u03b52 \u03c0\u0302T + . . . .\nFrom (2) we obtain\n\n\u03c0\u0302T\n\nRR\n\nn\u00b0 6263\n\n1\n1\n(\u03c0\u0304T \u03b5D1)1T X0 1 + 1T X0\n(\u03c0\u0304T \u03b5D1) + o(\u03b5) =\n= \u03c0\u0304T \u2212 \u03c0\u0304T\nn\nnT\n\u0013\n\u0012 T\n1\n1\nT\nT\n(\u03c0\u0304T D1) \u2212 \u03c0\u0304T\n(\u03c0\u0304T D1)1 X0 1 + o(\u03b5),\n= \u03c0\u0304T + \u03b5 1 X0\nnT\nnT\n\n\u03c0\u0302T .\n\n\fAvra henkov, Borkar & Nemirovsky\n\n6\n\nand hen e\n\n(1)\n\n\u03c0\u0302T = 1T X0\nwhere\n\nX0\n\n(3)\n\nis given by (30). Before substituting (30) into (3) let us make transformations\n\nX0\n\nwhere\n\n1\n1\n(\u03c0\u0304T D1) \u2212 \u03c0\u0304T\n(\u03c0\u0304T D1)1T X0 1,\nnT\nnT\n\nX\u22121\n\n=\n=\n\n(I \u2212 X\u22121 D)H(I \u2212 DX\u22121 ) =\nH \u2212 HDX\u22121 \u2212 X\u22121 DH + X\u22121 DHDX\u22121 ,\n\nis de\u001cned by (29). Pre-multiplying\n\n1T X0\n\nPost-multiplying\n\nX0\n\nX0\n\nby\n\n1T ,\n\nwe obtain\n\n=\n\n1T H \u2212 \u03c0\u0304T (1T HD1)(\u03c0\u0304T D1)\u22121 \u2212 nT \u03c0\u0304T (\u03c0\u0304T D1)\u22121 DH +\n\n+\n\nnT \u03c0\u0304T DHD1\u03c0\u0304T (\u03c0\u0304T D1)\u22122 .\n\nby\n\n1,\n\n(4)\n\nwe obtain\n\nX0 1 =\n\nX\u22121 DHDX\u22121 1 \u2212 HDX\u22121 1\n\nand hen e\n\n1T X0 1\n\n= nT \u03c0\u0304T DHD1(\u03c0\u0304T D1)\u22122 \u2212 1T HD1(\u03c0\u0304T D1)\u22121 .\n\n(5)\n\nSubstituting (5) and (4) into (3), we get\n\n(1)\n\n\u03c0\u0302T\n\n=\n=\n\n1\n1\n(\u03c0\u0304T D1) \u2212 \u03c0\u0304T\n(\u03c0\u0304T D1)1T X0 1 =\nnT\nnT\n1\n1\n(\u03c0\u0304T D1) \u2212\n\u03c0\u0304T 1T HD1 \u2212 \u03c0\u0304T DH +\n1T H\nnT\nnT\n1T X0\n\n+\n\n\u03c0\u0304T (\u03c0\u0304T DHD1)(\u03c0\u0304T D1)\u22121 \u2212 \u03c0\u0304T (\u03c0\u0304T DHD1)(\u03c0\u0304T D1)\u22121 +\n\n=\n\n1T H\n\n1\n\u03c0\u0304T 1T HD1 =\nnT\n\n1\n(\u03c0\u0304T D1) \u2212 \u03c0\u0304T DH.\nnT\n\nThus, we have\n\n(1)\n\n\u03c0\u0302T\n\n=\n\n1T H\n\n1\n(\u03c0\u0304T D1) \u2212 \u03c0\u0303T .\nnT\n\u2737\n\nNext, we\n\nonsider a quasi-stationary distribution [9, 22\u2104 de\u001cned by equation\n\nand the normalization\n\nwhere\n\n\u03bb1\n\n\u03c0\u0303T T = \u03bb1 \u03c0\u0303T ,\n\n(6)\n\n\u03c0\u0303T 1 = 1,\n\n(7)\n\nondition\n\nis the Perron-Frobenius eigenvalue of matrix\n\nT.\n\nThe quasi-stationary distribution\n\nan\n\nbe interpreted as a proper initial distribution on the non-absorbing states (states in ESCC) whi h\nis su h that the distribution of the random walk,\n\nt,\n\nis independent of\n\nmatrix\n\nT\n\nt\n\nonditioned on the non-absorption prior time\n\n[11\u2104. As in the analysis of the pseudo-stationary distribution, we take the\n\nin the form of perturbation\n\nT = T\u0304 \u2212 \u03b5D.\n\nINRIA\n\n\fQuasi-stationary distributions as entrality measures\n\nProposition 4\n\n7\n\nThe ve tor \u03c0\u0303T is lose to the ve tor \u03c0\u0304T . Namely,\n\u03c0\u0303T = \u03c0\u0304T \u2212 \u03b5\u03c0\u0304T DH + o(\u03b5).\n\nProof: We look for the quasi-stationary distribution and the Perron-Frobenius eigenvalue in the\nform of power series\n\n(0)\n\n(1)\n\n(2)\n\n\u03c0\u0303T = \u03c0\u0303T + \u03b5\u03c0\u0303T + \u03b52 \u03c0\u0303T + . . . ,\n(1)\n\n(8)\n\n(2)\n\n\u03bb1 = 1 + \u03b5\u03bb1 + \u03b52 \u03bb1 + . . . .\nSubstituting\nof\n\n\u03b5,\n\nT = T\u0304 \u2212 \u03b5D\n\nand the above series into (6), and equating terms with the same powers\n\nwe obtain\n\n(0)\n\n(0)\n\n\u03c0\u0303T T\u0304 = \u03c0\u0303T ,\n(1)\n\n(0)\n\n(1)\n\n(9)\n\n(1) (0)\n\n\u03c0\u0303T T\u0304 \u2212 \u03c0\u0303T D = 1\u03c0\u0303T + \u03bb1 \u03c0\u0303T ,\nSubstituting (8) into the normalization\n\n(10)\n\nondition (7), we get\n\n(0)\n\n\u03c0\u0303T 1 = 1,\n\n(11)\n\n(1)\n\n\u03c0\u0303T 1 = 0.\nFrom (9) and (11) we\n\non lude that\n\n(0)\n\n\u03c0\u0303T = \u03c0\u0304T .\n\n(12)\n\nThus, the equation (10) takes the form\n\n(1)\n\n(1)\n\n(1)\n\n\u03c0\u0303T T\u0304 \u2212 \u03c0\u0304T D = 1\u03c0\u0303T + \u03bb1 \u03c0\u0304T .\n1,\n\nPost-multiplying this equation by\n\nwe get\n\n(1)\n\n(1)\n\n(1)\n\n\u03c0\u0303T T\u0304 1 \u2212 \u03c0\u0304T D1 = 1\u03c0\u0303T 1 + \u03bb1 \u03c0\u0304T 1.\nNow using\n\nT\u0304 1 = 1,\n\n(11) and (12), we\n\non lude that\n\n(1)\n\n\u03bb1 = \u2212\u03c0\u0304T D1,\nand,\n\nonsequently,\n\n\u03bb1 = 1 \u2212 \u03b5\u03c0\u0304T D1 + o(\u03b5).\nNow the equation (10)\n\n(13)\n\nan be rewritten as follows:\n\n(1)\n\n\u03c0\u0303T [I \u2212 T\u0304 ] = \u03c0\u0304T [(\u03c0\u0304T D1)I \u2212 D].\nIts general solution is given by\n\n(1)\n\n\u03c0\u0303T = \u03bd \u03c0\u0304T + \u03c0\u0304T [(\u03c0\u0304T D1)I \u2212 D]H,\n\u03bd\n\nwhere\n\nis some\n\nonstant.\n\nTo \u001cnd\n\nonstant\n\n\u03bd,\n\nwe substitute the above general solution into\n\nondition (12).\n\n(1)\n\n\u03c0\u0303T 1 = \u03bd \u03c0\u0304T 1 + \u03c0\u0304T [(\u03c0\u0304T D1)I \u2212 D]H1 = 0.\nSin e\n\n\u03c0\u0304T 1 = 1\n\nand\n\nH1 = 0,\n\nwe get\n\n\u03bd = 0.\n\nConsequently, we have\n\n(1)\n\n\u03c0\u0303T = \u03c0\u0304T [(\u03c0\u0304T D1)I \u2212 D]H = (\u03c0\u0304T D1)\u03c0\u0304T H \u2212 \u03c0\u0304T DH = \u2212\u03c0\u0304T DH.\nIn the above, we have used the fa t that\n\n\u03c0\u0304T H = 0.\n\nThis\n\nompletes the proof.\n\n\u2737\n\u03bb1 is very\n\u03c0\u0304T R1 is typi\n\nSin e\nindeed\n\nlose to one, we\n\non lude from (13) and the equality\n\nally very small.\n\nThere is also a simple relation between\n\nRR\n\nn\u00b0 6263\n\n\u03bb1\n\nand\n\n\u03c0\u0303T .\n\n\u03b5\u03c0\u0304T D1 = \u03c0\u0304T R1\n\nthat\n\n\fAvra henkov, Borkar & Nemirovsky\n\n8\n\nProposition 5\n\nThe Perron-Frobenius eigenvalue \u03bb1 of matrix T is given by\n\u03bb1 = 1 \u2212 \u03c0\u0303T R1.\n\nProof: Post-multiplying the equation (6) by\n\n1,\n\n(14)\n\nwe obtain\n\n\u03bb1 = \u03c0\u0303T T 1.\nThen, using the fa t that\n\nT 1 = 1 \u2212 R1\n\nwe derive the formula (14).\n\n\u2737\n\u03bb1 is lose to one then \u03c0\u0303T R1 is small.\nAs we mentioned above the T\u0304ij entry of the matrix T\u0304\nan be onsidered as a onditional\nprobability to jump from the node i to the node j under the ondition that random walk does not\nProposition 5 indi ates that if\n\nleave ESCC at the jump.\nLet us\n\nonsider the situation when the random walk stays inside ESCC after some \u001cnite number\n\nof jumps. The probability of su h an event\n\nP\n\nan be expressed as follows:\n\nX1 = j|X0 = i \u2227\n\nN\n^\n\nXm \u2208 S\n\nm=1\nwhere ESCC is denoted by\n\nS\n\n!\n\n,\nN\n\nfor the sake of shortening notation and\n\nis the number of jumps\n\nduring whi h the random walk stays in ESCC.\n(N )\nN\nth power of T) and by\nLet us denote by Tij\nthe element of T\n(the N\nN\nmatrix T . Then\n(N )\n= (T N )i = (T T N \u22121 )i = Ti T N \u22121 .\nTi\n\n(N )\n\nTi\n\nthe\n\nith\n\nrow of the\n\nProposition 6\n\nP\n\nN\n^\n\nX1 = j|X0 = i \u2227\n\nXm \u2208 S\n\nm=1\n\n!\n\n(N \u22121)\n\n=\n\nTij Tj\n\n(N )\nTi 1\n\n1\n\n.\n\n(15)\n\nProof: see Appendix.\nThen, if we denote\n\n(N )\n\u0164ij\n\n=P\n\nX1 = j|X0 = i \u2227\n\nN\n^\n\nXm \u2208 S\n\nm=1\n\nLet us now\nBefore we\n\nonsider the limiting\n\nontinue let us analyze\n\n,\n\n(N )\n\n\u0164ij , whi h an be viewed as generalization\nase, when N goes to in\u001cnity.\nthe prin iple right eigenve tor u of the matrix T :\n\nwe will be able to \u001cnd stationary distributions of\n\n\u03c0\u0304T .\n\n!\n\nT u = \u03bb1 u,\nwhere\n\n\u03bb1\n\nof\n\n(16)\n\nis as in the previous se tion, the Perron-Frobenius eigenvalue.\n\nThe ve tor\n\nu\n\nan be normalized in di\u001berent ways. Let us de\u001cne the main normalization for\n\nu\n\nas\n\n1 T u = nT .\nLet us also de\u001cne\n\n\u016b\n\nas\n\n\u016b =\nand\n\n\u0169 =\n\nu\n\u03c0\u0304T u\n\n, so that\n\nu\n,\n\u03c0\u0303T u\n\nso that\n\n\u03c0\u0304T \u016b = 1,\n\n(17)\n\n\u03c0\u0303T \u0169 = 1.\n\n(18)\n\nINRIA\n\n\fQuasi-stationary distributions as entrality measures\n\nProposition 7\n\n9\n\nThe ve tor \u016b is lose to the ve tor 1. Namely,\n\u016b = 1 \u2212 \u03b5HD1 + o(\u03b5).\n\nProof: We look for the right eigenve tor and the Perron-Frobenius eigenvalue in the form of power\nseries\n\n\u016b = \u016b(0) + \u03b5\u016b(1) + \u03b52 \u016b(2) + . . . .\n(1)\n\n(19)\n\n(2)\n\n\u03bb1 = 1 + \u03b5\u03bb1 + \u03b52 \u03bb1 + . . . .\nSubstituting\nof\n\n\u03b5,\n\nT = T\u0304 \u2212 \u03b5D\n\nand the above series into (16), and equating terms with the same powers\n\nwe obtain\n\nT\u0304 \u016b(0) = \u016b(0) ,\n\n(20)\n\n(1)\n\nT\u0304 \u016b(1) \u2212 D\u016b(0) = \u016b(1) + \u03bb1 \u016b(0) .\nSubstituting (19) into the normalization\n\nFrom (20) and (22) we\n\non lude that\n\n(21)\n\nondition (17), we obtain\n\n\u03c0\u0304T \u016b(0) = 1,\n\n(22)\n\n\u03c0\u0304T \u016b(1) = 0.\n\n(23)\n\n\u016b(0) = 1.\n\nThus, the equation (21) takes the form\n\n(1)\n\nT\u0304 \u016b(1) \u2212 D1 = \u016b(1) + \u03bb1 1.\nPre-multiplying this equation by\n\n\u03c0\u0304T ,\n\nwe get\n\n(1)\n\n\u03c0\u0304T \u016b(1) \u2212 \u03c0\u0304T D1 = \u03c0\u0304T \u016b(1) + \u03c0\u0304T \u03bb1 1.\nNow using\n\nT\u0304 1 = 1,\n\n(22) and (23), we\n\non lude that\n\n(1)\n\n\u03bb1 = \u2212\u03c0\u0304T D1,\nand,\n\nonsequently,\n\n\u03bb1 = 1 \u2212 \u03b5\u03c0\u0304T D1 + o(\u03b5).\nNow the equation (21)\n\nan be rewritten as follows:\n\nIts general solution is given by\n\n\u0002\n\n\u0003\nI \u2212 T\u0304 \u016b(1) = [(\u03c0\u0304T D1) I \u2212 D] 1.\n\n\u016b(1) = \u03bd1 + H [(\u03c0\u0304T D1) I \u2212 D] 1,\nwhere\n\n\u03bd\n\nis some\n\nonstant.\n\nTo \u001cnd\n\nonstant\n\n\u03bd,\n\nwe substitute the above general solution into\n\nondition (23).\n\n\u03c0\u0304T \u016b(1) = \u03bd \u03c0\u0304T 1 + \u03c0\u0304T H [(\u03c0\u0304T D1) I \u2212 D] 1.\nSin e\n\n\u03c0\u0304T 1 = 1\n\nand\n\n\u03c0\u0304T H = 0,\n\nwe get\n\n\u03bd = 0.\n\nConsequently, we have\n\n\u016b(1) = \u2212HD1.\nIn the above, we have used the fa t that\n\nH1 = 0.\n\nThis\n\nompletes the proof.\n\n\u2737\nWe note that the elements of the ve tor\n\nRR\n\nn\u00b0 6263\n\n\u0169\n\nan be\n\nal ulated by the power iteration method.\n\n\fAvra henkov, Borkar & Nemirovsky\n\n10\n\nProposition 8\n\nThe following onvergen e takes pla e\nTi T n\u22121 e\n,\nn\u2192\u221e\n\u03bbn1\n\n\u0169i = lim\n\n(24)\n\nwhere Ti is the ith row of the matrix T .\nProof:\n(1)\n\n=\n\n(2)\n\n=\n\n(3)\n\n=\n\n\u0169i\n\n\u0169i\n\u0169i\n\nTi e\nTi e\n,\n=\n\u03c0\u0303T T e\n\u03bb1\nTi T\u03bb1e\nTi \u0169(1)\nTi T e\n=\n,\n=\n(1)\n\u03bb1\n\u03bb21\n\u03c0\u0303T T \u0169\nTi T 2 e\nTi \u0169(2)\n,\n=\n(2)\n\u03bb31\n\u03c0\u0303T T \u0169\n\n.\n.\n.\n\n\u2737\nLet us\n\n\u0164\n\nonsider the twisted kernel\n\nde\u001cned by\n\nTij uj\n.\n\u03bb1 ui\n\n\u0164ij =\nAs one\n\nan see the twisted kernel does not depend on the normalization of\n\nu.\n\nHen e, we\n\nan take\n\nany normalization.\n\nProposition 9\n\nThe twisted kernel is a limit of\n\nas N goes to in\u001cnity, that is\n\n(15)\n\n(N \u22121)\n\nTij Tj\n\n\u0164ij = lim\n\n(N )\nTi 1\n\nN \u2192\u221e\n\n1\n\n.\n\nProof:\n(N \u22121)\n\nTij Tj\n\n(N )\n\nTi\n\n(N \u22121)\n\nlim\n\nN \u2192\u221e\n\nUsing (24), we\n\nTij Tj\n\n(N )\n\nTi\n\n1\n\n1\n\n1\n\n1\n\nTij\nTj T N \u22122 1\n=\n= Tij\nTi T N \u22121 1\n\u03bb1\n\nTij\nlim\n=\n\u03bb1 N \u2192\u221e\n\nTj T N \u22122 1\n\u22121\n\u03bbN\n1\nN\nTi T \u22121 1\n\u03bbN\n1\n\nTj T N \u22122 1\n\u22121\n\u03bbN\n1\nTi T N \u22121 1\n\u03bbN\n1\n\n.\n\nTij limN \u2192\u221e\n=\n\u03bb1 limN \u2192\u221e\n\nTj T N \u22122 1\n\u22121\n\u03bbN\n1\nN\nTi T \u22121 1\n\u03bbN\n1\n\n.\n\nan write\n\n(N \u22121)\n\nlim\n\nN \u2192\u221e\n\nTij Tj\n\n1\n\n(N )\nTi 1\n\n=\n\nTij \u0169j\n.\n\u03bb1 \u0169i\n\n=\n\nTij uj\n.\n\u03bb1 ui\n\nAfter renormalization, we obtain\n\n(N \u22121)\n\nlim\n\nN \u2192\u221e\n\nTij Tj\n\n(N )\nTi 1\n\n1\n\n\u2737\nThe twisted kernel plays an important role in multipli ative ergodi\nfor Markov\n\nhains, see, e.g., [14\u2104.\n\nThe matrix\n\n\u0164\n\nis\n\ntheory and large deviations\n\nlearly a transition probability kernel, i.e.,\n\nINRIA\n\n\fQuasi-stationary distributions as entrality measures\n\nP\n\u0164ij \u2265 0 \u2200i, j, and j \u0164ij = 1 \u2200i.\ni, j , whi h we assume to be the\n\u03c0\u030cT asso iated with it:\n\nAlso, it is irredu ible if there exists an path\n\nESCC. Thus,\n\ni\n\n\u03c0\u030cT\n\nProposition 10\n\nto\n\nj\n\ni\u2192j\n\nunder\n\nT\n\nfor all\n\nase. In parti ular, it will have a unique stationary distribution\n\nIf we assume aperiodi ity in addition,\ntransition from\n\n11\n\n\u03c0\u030cT = \u03c0\u030cT \u0164 ,\n\n(25)\n\n\u03c0\u030cT 1 = 1.\n\n(26)\n\n\u0164ij\n\nan be given the interpretation of the probability of\n\nin the ESCC for the\n\nhain,\n\nonditioned on the fa t that it never leaves the\n\nquali\u001ces as an alternative de\u001cnition of a quasi-stationary distribution.\n\nThe following expression for \u03c0\u030cT holds:\n\u03c0\u030cT = \u03c0\u0303T i \u0169i .\n\n(27)\n\nProof: The normalization ondition (26) is satis\u001ced due to (18). Let us show that (25) holds as\nwell, i.e.\n\nnT\nX\n\n\u03c0\u030cT j =\n\n\u03c0\u030cT i \u0164ij ,\n\ni=1\n\nwhere\n\nnT\n\nis the dimension of\n\nnT\nX\n\n\u03c0\u030cT .\n\n\u03c0\u0303T i \u0169i \u0164ij =\n\nAnd for the right hand side of (27) we have\n\nnT\nX\n\nn\n\n\u03c0\u0303T i \u0169i\n\ni=1\n\ni=1\n\nT\nX\nTij \u0169j\nTij \u0169j\n\u0169j\n\u03c0\u0303T i \u0169i\n=\n=\n\u03bb1 \u03c0\u0303T j = \u03c0\u0303T j \u0169j .\n\u03bb1 \u0169i\n\u03bb\n\u0169\n\u03bb\n1\ni\n1\ni=1\n\n\u2737\nThis suggests that\n\n\u03c0\u030cT i ,\n\nor equivalently\n\nmeasure. Sin e the substo hasti matrix\nConsequently, the ve tor\nthe matrix\n\nT\n\nis\n\n\u03c0\u030cT\n\nwill be\n\nPageRank ranking\n\nis\n\nlose to\n\nlose to the sto hasti\n\ndistribution are quite\n\nT\n\n\u03c0\u0303T i \u0169i ,\n\nmay be used as another alternative\n\nlose to sto hasti , the ve tor\n\n\u03c0\u0303T\n\nand to\n\n\u03c0\u0304\n\nu will be very\n\nas well. This shows that in the\n\nentrality\nlose to\n\n1.\n\nase when\n\nmatrix all the alternative de\u001cnitions of quasi-stationary\n\nlose to ea h other. And then, from Proposition 1, we\n\non lude that the\n\nonverges to the quasi-stationarity based ranking as the damping fa tor goes\n\nto one.\n\n3\n\nNumeri al experiments and Appli ations\n\nFor our numeri al experiments we have used the Web site of INRIA (http://www.inria.fr).\n\nIt\n\nis a typi al Web site with about 300 000 Web pages and 2 200 000 hyperlinks. Sin e the Web\nhas a fra tal stru ture [10\u2104, we expe t that our dataset is su\u001e iently representative. A\n\nordingly,\n\ndatasets of similar or even smaller sizes have been extensively used in experimental studies of novel\nalgorithms for PageRank\nown Web\n\nomputation [1, 16, 17\u2104. To\n\nolle t the Web graph data, we\n\nrawler whi h works with the Ora le database. The\n\nrawler\n\nonstru t our\n\nonsists of two parts: the\n\n\u001crst part is realized in Java and is responsible for downloading pages from the Internet, parsing the\npages, and inserting their hyperlinks into the database; the se ond part is written in PL/SQL and\nis responsible for the data management. For detailed des ription of the\n\nrawler reader is referred\n\nto [3\u2104.\nAs was shown in [7, 15\u2104, a Web graph has three major distin t\nSCC. However, if one takes into a\nhas two major distin t\n\nomponents: IN, OUT and\n\nount the arti\u001c ial links from the dangling nodes, a Web graph\n\nomponents: POUT and ESCC [5\u2104. In our experiments we\n\narti\u001c ial links from the dangling nodes and\n\nompute\n\n\u03c0\u0304T , \u03c0\u0303T , \u03c0\u0302T ,\n\nand\n\n\u03c0\u030cT\n\nonsider the\n\nwith 5 digits pre ision.\n\nWe provide the statisti s for the INRIA Web site in Table 1.\nFor ea h pair of these ve tors we\nmetri\n\nRR\n\nal ulated Kendall Tau metri\n\n(see Table 2). The Kendall Tau\n\nshows how two rankings are di\u001berent in terms of the number of swaps whi h are needed to\n\nn\u00b0 6263\n\n\fAvra henkov, Borkar & Nemirovsky\n\n12\n\nIN RIA\nTotal size\n\n318585\n\nNumber of nodes in SCC\n\n154142\n\nNumber of nodes in IN\n\n0\n\nNumber of nodes in OUT\n\n164443\n\nNumber of nodes in ESCC\n\n300682\n\nNumber of nodes in POUT\n\n17903\n\nNumber of SCCs in OUT\n\n1148\n\nNumber of SCCs in POUT\n\n631\n\nTable 1: Component sizes in INRIA dataset\n\n\u03c0\u0304T\n\u03c0\u0303T\n\u03c0\u0302T\n\u03c0\u030cT\n\n\u03c0\u0304T\n1.0\n\n\u03c0\u0303T\n0.99390\n1.0\n\n\u03c0\u0302T\n0.99498\n0.99770\n1.0\n\nTable 2: Kendall Tau\n\n\u03c0\u030cT\n0.98228\n0.98786\n0.98597\n1.0\n\nomparison\n\ntransform one ranking to the other. The Kendall Tau metri\n\nhas the value of one if two rankings\n\nare identi al and minus one if one ranking is the inverse of the other.\nIn our\n\nase, the Kendall Tau metri s for all the pairs is very\n\nthat all four quasi-stationarity based\n\nlose to one. Thus, we\n\nan\n\non lude\n\nentrality measures produ e very similar rankings.\n\nWe have also analyzed the Kendall Tau metri\nfun tion of damping fa tor (see Figure 1).\n\nAs\n\nc\n\nbetween\n\n\u03c0\u0303T\n\nand PageRank of ESCC as a\n\ngoes to one, the Kendall Tau approa hes one.\n\nThis is in agreement with Proposition 1.\nFinally, we would like to note that in the\nthe \u001crst ranking pla es were o\n\nase of quasi-stationarity based\n\nentrality measures\n\nupied by the sites with the internal stru ture depi ted in Figure 2.\n\nTherefore, we suggest to use the quasi-stationarity based\n\nentrality measures to dete t \u0010link farms\u0011\n\nand to dis over photo albums. It turns out that the quasi-stationarity based\n\nentrality measures\n\nhighlights the sites with stru ture as in Figure 2 but at the same time the relative ranking of the\nother sites provided by the standard PageRank with\n\nc = 0.85\n\nwe give in Table 3 rankings of some sites under di\u001berent\nabsolute value of ranking is\n\nis preserved. To illustrate this fa t,\n\nentrality measures. Even though the\n\nhanging, the relative ranking among these sites is the same for all\n\nentrality measures. This indi ates that the quasi-stationarity based\n\nentrality measures help to\n\ndis over \u0010link farms\u0011 and photo albums and at the same time the ranking of sites of the other type\nstays\n\nonsistent with the standard PageRank ranking.\n\nhttp://www.inria.fr/\nhttp://www.loria.fr/\nhttp://www.irisa.fr/\nhttp://www-sop.inria.fr/\nhttp://www-ro q.inria.fr/\nhttp://www-futurs.inria.fr/\n\n\u03c0T (0.85)\n1\n13\n16\n30\n74\n102\n\n\u03c0\u0304T\n31\n310\n432\n508\n1333\n2201\n\n\u03c0\u0303T\n189\n1605\n1696\n1825\n2099\n2360\n\n\u03c0\u0302T\n105\n356\n460\n532\n1408\n2206\n\n\u03c0\u030cT\n200\n1633\n757\n1819\n2158\n2404\n\nTable 3: Examples of sites' rankings\n\nINRIA\n\n\fQuasi-stationary distributions as entrality measures\n\n13\n\n1\n\n0.9\n\nkendall tau\n\n0.8728\n\n0.8\n\n0.7\n\n0.6\n\n0.5\n\nFigure 1:\n\n0.05\n\n0.15\n\n0.25\n\nThe Kendall Tau metri\n\n0.35\n\n0.45\n0.55\n0.65\ndamping factor\n\nbetween\n\n\u03c0\u0303T\n\n0.75\n\nFigure 2: The album like Web site stru ture\n\nn\u00b0 6263\n\n0.95\n\n1.05\n\nand PageRank of ESCC as a fun tion of the\n\ndamping fa tor.\n\nRR\n\n0.85\n\n\fAvra henkov, Borkar & Nemirovsky\n\n14\n\n4\n\nCon lusion\n\nIn the paper we have proposed\n\nentrality measures whi h\n\nan be applied to a redu ible graph to\n\navoid the absorbtion problem. In Google PageRank the problem was solved by introdu tion of\nuniform random jumps with some probability. Up to the present, there is no\n\nlear\n\nriterion for the\n\nhoi e this parameter. In the paper we have suggested four quasi-stationarity based parameterfree\n\nentrality measures, analyzed them and\n\non luded that they produ e approximately the same\n\nranking. Therefore, in pra ti e it is su\u001e ient to\n\nompute only one quasi-stationarity based\n\nentral-\n\nity measure. All our theoreti al results are\n\non\u001crmed by numeri al experiments. The numeri al\n\nexperiments have also showed that the new\n\nentrality measures\n\nan be applied in spam dete tion\n\nto dete t \u0010link farms\u0011 and in image sear h to \u001cnd photo albums.\n\nReferen es\n[1\u2104 S. Abiteboul, M. Preda, and G. Cobena, \u0010Adaptive on-line page importan e\n\nomputation\u0011, in\n\nPro eedings of the 12 International World Wide Web Conferen e, Budapest, 2003.\n\n[2\u2104 K. Avra henkov,\n\nAnalyti Perturbation Theory and its Appli ations,\n\nPhD thesis, University\n\nof South Australia, 1999.\n[3\u2104 K. Avra henkov, D. Nemirovsky, and N. Osipova. \u0010Web Graph Analyzer Tool\u0011.\n\nof the IEEE ValueTools onferen e, 2006.\n\n[4\u2104 K. Avra henkov, M. Haviv and P.G. Howlett, \u0010Inversion of analyti\nare singular at the origin\u0011,\n\nIn Pro eedings\n\nmatrix fun tions that\n\nSIAM Journal on Matrix Analysis and Appli ations,\n\nv. 22(4),\n\npp.1175-1189, 2001.\n[5\u2104 K. Avra henkov, N. Litvak and K.S. Pham, \u0010A singular perturbation approa h for\nPageRank damping fa tor\u0011, preprint, available at\n\nhoosing\n\nhttp://arxiv.org/abs/math.PR/0612079,\n\n2006.\n[6\u2104 P. Boldi, M. Santini, and S. Vigna, \u0010PageRank as a fun tion of the damping fa tor\u0011, in\n\nPro eedings of the 14 World Wide Web Conferen e, New York, 2005.\n\n[7\u2104 A. Broder, R. Kumar, F. Maghoul, P. Raghavan, S. Rajagopalan, R. Stata, A. Tomkins and\nJ. Wiener, \u0010Graph stru ture in the Web\u0011,\n\nComputer Networks, v. 33, pp.309-320, 2000.\n\n[8\u2104 P. Chen, H. Xie, S. Maslov, and S. Redner, \u0010Finding s ienti\u001c\nalgorithm\u0011,\n\nJournal of Informetri s, v.1, pp.8\u001515, 2007.\n\ngems with Google's PageRank\n\n[9\u2104 J. N. Darro h and E. Seneta, \u0010On Quasi-Stationary Distributions in Absorbing Dis rete-Time\nFinite Markov Chains\u0011,\n\nJournal of Applied Probability,\n\nv. 2(1), pp.88-100, 1965.\n\n[10\u2104 S. Dill, R. Kumar, K. M Curley, S. Rajagopalan, D. Sivakumar, and A. Tomkins, \u0010Selfsimilarity in the Web\u0011,\n\nACM Trans. Internet Te hnol.,\n\n[11\u2104 E.A. van Doorn, \u0010Quasi-stationary distributions and\nbirth-death pro esses\u0011,\n\n2 (2002), pp. 205\u0015223.\n\nAdvan es in Applied Probability,\n\nonvergen e to quasi-stationarity of\nv. 23(4), pp. 683-700, 1991.\n\n[12\u2104 W.J. Ewens, \u0010The di\u001busion equation and pseudo-distribution in geneti s\u0011,\n\nB, v. 25, pp. 405-412, 1963.\n\n[13\u2104 J. Kleinberg, \u0010Authoritative sour es in a hyperlinked environment\u0011,\n\nJ.R. Statist. So .\n\nJournal of ACM,\n\nv. 46,\n\npp.604-632, 1999.\n[14\u2104 I. Kontoyiannis, and S. P. Meyn, \u0010Spe tral theory and limit theorems for geometri ally ergodi\nMarkov pro esses\u0011,\n\nAnn. Appl. Probab.,\n\nv. 13, no. 1, pp. 304362, 2003.\n\nINRIA\n\n\fQuasi-stationary distributions as entrality measures\n\n15\n\n[15\u2104 R. Kumar, P. Raghavan, S. Rajagopalan, D. Sivakumar, A. Tompkins and E. Upfal, \u0010The\n\nWeb as a graph\u0011, PODS'00: Pro eedings of the nineteenth ACM SIGMOD-SIGACT-SIGART\nSymposium on Prin iples of Database Systems, pp. 1-10, 2000.\n\n[16\u2104 A. N. Langville and C. D. Meyer, \u0010Deeper Inside PageRank\u0011,\n\nInternet Math.,\n\n1 (2004), pp.\n\n335\u0015400; also available online at http://www4.n su.edu/\u223canlangvi/.\n[17\u2104 A. N. Langville and C. D. Meyer, \u0010Updating PageRank with iterative aggregation\u0011, in\n\needings of the 13th World Wide Web Conferen e,\n\nPro-\n\nNew York, 2004.\n\n[18\u2104 A.N. Langville and C.D. Meyer, \u0010Google's PageRank and Beyond: The S ien e of Sear h\nEngine Rankings\u0011,\n\nPrin eton University Press, 2006.\n\n[19\u2104 R. Lempel and S. Moran, \u0010The sto hasti\nthe TKC e\u001be t\u0011,\n\napproa h for link-stru ture analysis (SALSA) and\n\nComputer Networks, v. 33, pp. 387-401, 2000.\n\n[20\u2104 C.D. Moler and K.A. Moler, \u0010Numeri al Computing with MATLAB\u0011,\n[21\u2104 L. Page, S. Brin, R. Motwani and T. Winograd, \u0010The pagerank\n\nSIAM\n\n, 2003.\n\nitation ranking: Bringing\n\norder to the web\u0011, Stanford Te hni al Report, 1998.\n[22\u2104 E. Seneta, \u0010Non-negative matri es and Markov\n\nhains\u0011,\n\nSpringer, 1973.\n\nAppendix\nHere we present a\n\nouple of important auxiliary results.\n\nLet T\u0304 be an irredu ible sto hasti matrix. And let T (\u03b5) = T\u0304 \u2212 \u03b5D be a perturbation\nof T\u0304 su h that T (\u03b5) is substo hasti matrix. Then, for su\u001e iently small \u03b5 the following Laurent\nseries expansion holds\n\nLemma 1\n\n[I \u2212 T (\u03b5)]\u22121 =\n\nwith\n\n1\nX\u22121 + X0 + \u03b5X1 + . . . ,\n\u03b5\n\nX\u22121 =\n\n(28)\n\n1\n1\u03c0\u0304,\n\u03c0\u0304D1\n\n(29)\n\nX0 = (I \u2212 X\u22121 D)H(I \u2212 DX\u22121 ),\n\n(30)\n\nwhere \u03c0\u0304 is the stationary distribution of T\u0304 and H = (I \u2212 T\u0304 + 1\u03c0\u0304)\n\n\u22121\n\n\u2212 1\u03c0\u0304 is the deviation matrix.\n\nProof: The proof of this result is based on the approa h developed in [2, 4\u2104. The existen e of the\nLaurent series (28) is a parti ular\n\nase of more general results of [4\u2104. To\n\nLaurent series, let us equate the terms with the same powers of\n\n\u03b5\n\nal ulate the terms of the\n\nin the following identity\n\n1\n(I \u2212 T\u0304 + \u03b5D)( X\u22121 + X0 + \u03b5X1 + . . .) = I,\n\u03b5\nwhi h results in\n\nFrom equation (31) we\n\nwhere\n\n\u03bc\u22121\n\n(I \u2212 T\u0304 )X\u22121 = 0,\n\n(31)\n\n(I \u2212 T\u0304 )X0 + DX\u22121 = I,\n\n(32)\n\n(I \u2212 T\u0304 )X1 + DX0 = 0.\n\n(33)\n\nX\u22121 = 1\u03bc\u22121 ,\n\n(34)\n\non lude that\n\nis some ve tor. We \u001cnd this ve tor from the\n\nondition that the equation (32) has a\n\nsolution. In parti ular, equation (32) has a solution if and only if\n\n\u03c0\u0304(I \u2212 DX\u22121 ) = 0.\n\nRR\n\nn\u00b0 6263\n\n\fAvra henkov, Borkar & Nemirovsky\n\n16\n\nBy substituting into the above equation the expression (34), we obtain\n\n\u03c0\u0304 \u2212 \u03c0\u0304D1\u03bc\u22121 = 0,\nand,\n\nonsequently,\n\n\u03bc\u22121 =\n\n1\n\u03c0\u0304,\n\u03c0\u0304D1\n\nwhi h together with (34) gives (29).\nSin e the deviation matrix\n\nH\n\nis a Moore-Penrose generalized inverse of\n\nsolution of equation (32) with respe t to\n\nX0\n\nX0 = H(I \u2212 DX\u22121 ) + 1\u03bc0 ,\nwhere\n\n\u03bc0\n\nis some ve tor. The ve tor\n\n\u03bc0\n\nI \u2212 T\u0304 ,\n\nthe general\n\nis given by\n(35)\n\nan be found from the\n\nondition that the equation (33)\n\nhas a solution. In parti ular, equation (33) has a solution if and only if\n\n\u03c0\u0304DX0 = 0.\nBy substituting into the above equation the expression for the general solution (35), we obtain\n\n\u03c0\u0304DH(I \u2212 DX\u22121 ) + \u03c0\u0304D1\u03bc0 = 0.\nConsequently, we have\n\n\u03bc0 = \u2212\n\n1\n\u03c0\u0304DH(I \u2212 DX\u22121 )\n\u03c0\u0304D1\n\nand we obtain (30).\n\n\u2737\nProposition 11\n\nP\n\nX1 = j|X0 = i \u2227\n\nN\n^\n\nXm \u2208 S\n\nm=1\n\n!\n\n(N \u22121)\n\n=\n\nTij Tj\n\n(N )\n\nTi\n\n1\n\n1\n\nProof:\n\nP\n\nX1 = j|X0 = i \u2227\n\nN\n^\n\nm=1\n\n=\n\nDenominator:\n\nXm \u2208 S\n\n!\n\n=\n\n\u0010\n\u0011\nVN\nP X0 = i \u2227 X1 = j \u2227 m=2 Xm \u2208 S\n\u0010\n\u0011\nVN\nP X0 = i \u2227 m=1 Xm \u2208 S\n\nINRIA\n\n\fQuasi-stationary distributions as entrality measures\n\nP\n\nX0 = i \u2227\n\nN\n^\n\nXm \u2208 S\n\nm=1\n\n= P\n\nX0 = i \u2227\n\nN\n^\n_\n\n!\n\n=\n\nXm = km\n\nm=1 km \u2208S\n\n= P\n\nX0 = i \u2227\n\n_\n\nX1 = k1 \u2227\n\n=\n\nN\n^\n_\n\nXm = km\n\nN\n^\n_\n\nX\n\nP\n\nX\n\nP (X1 = k1 |X0 = i) P\n\nX1 = k1 \u2227\n\nXm = km\nN\n^\n_\n\n= P (X0 = i)\n\nP (X1 = k1 |X0 = i) P\n\nk1 \u2208S\n\n= P (X0 = i)\n\nX\n\nX\n\n!\n\n=\n\nXm = km |X1 = k1\n\n_\n\nX2 = k2 \u2227\n\nP (X1 = k1 |X0 = i)\n\nX\n\nP\n\nX2 = k2 \u2227\n\nN\n^\n_\n\n!\n\n=\n\nXm = km |X1 = k1\n\n!\n\n=\n\nXm = km |X1 = k1\n\n!\n\n=\n\nm=3 km \u2208S\n\nk2 \u2208S\n\nk1 \u2208S\n\n= P (X0 = i)\n\n=\n\nm=2 km \u2208S\n\nk1 \u2208S\n\nX\n\n!\n\nm=2 km \u2208S\n\nk1 \u2208S\n\n= P (X0 = i)\n\n!\n\nm=2 km \u2208S\n\nk1 \u2208S\n\n= P (X0 = i)\n\n17\n\nN\n^\n_\n\nm=3 km \u2208S\n\nk2 \u2208S\n\nP (X1 = k1 |X0 = i)\n\nk1 \u2208S\n\nX\n\nP\n\nN\n^\n_\n\nXm = km |X2 = k2 \u2227 X1 = k1\n\nm=3 km \u2208S\n\nk2 \u2208S\n\n= P (X0 = i)\n\nX\n\n!\n\nP (X2 = k2 |X1 = k1 ) =\n\nP (X1 = k1 |X0 = i)\n\nk1 \u2208S\n\nX\n\nP\n\nN\n^\n_\n\nXm = km |X2 = k2\n\nm=3 km \u2208S\n\nk2 \u2208S\n\n= P (X0 = i)\n\nX\n\n!\n\nP (X2 = k2 |X1 = k1 ) =\n\n!\n\nP (X2 = k2 |X1 = k1 ) =\n\nP (X1 = k1 |X0 = i)\n\nk1 \u2208S\n\nX\n\nk2 \u2208S\n\nP\n\nN\n^\n_\n\nXm = km |X2 = k2\n\nm=3 km \u2208S\n\n= P (X0 = i)\n\nX\n\nP\n\nXm = km |X2 = k2\n\nm=3 km \u2208S\n\nk2 \u2208S\n\nX\n\nN\n^\n_\n\n!\n\nP (X2 = k2 |X1 = k1 ) P (X1 = k1 |X0 = i) =\n\nk1 \u2208S\n\n= P (X0 = i)\n\nX\n\nP\n\n= P (X0 = i)\n\nP\n\nk2 \u2208S\n\n= P (X0 = i)\n\nX X\n\nn\u00b0 6263\n\n_\n\nX3 = k3 \u2227\n\nP\n\nX3 = k3 \u2227\n\nN\n^\n_\n\n!\n\nP (X2 = k2 |X0 = i) =\n\nXm = km |X2 = k2\n\n!\n\nP (X2 = k2 |X0 = i) =\n\nXm = km |X2 = k2\n\n!\n\nP (X2 = k2 |X0 = i) =\n\nm=4 km \u2208S\n\nk3 \u2208S\n\nk2 \u2208S k3 \u2208S\n\nRR\n\nXm = km |X2 = k2\n\nm=3 km \u2208S\n\nk2 \u2208S\n\nX\n\nN\n_\n^\n\nN\n^\n_\n\nm=4 km \u2208S\n\n\fAvra henkov, Borkar & Nemirovsky\n\n18\n\n= P (X0 = i)\n\nX X\n\nN\n^\n_\n\nP\n\nXm = km |X3 = k3 \u2227 X2 = k2\n\nm=4 km \u2208S\n\nk3 \u2208S k2 \u2208S\n\n!\n\nP (X3 = k3 |X2 = k2 ) P (X2 = k2 |X0 = i) =\n= P (X0 = i)\n\nX X\n\nN\n^\n_\n\nP\n\nXm = km |X3 = k3\n\nm=4 km \u2208S\n\nk3 \u2208S k2 \u2208S\n\n!\n\nP (X3 = k3 |X2 = k2 ) P (X2 = k2 |X0 = i) =\n= P (X0 = i)\n\nX\n\nP\n\nXm = km |X3 = k3\n\nm=4 km \u2208S\n\nk3 \u2208S\n\nX\n\nN\n^\n_\n\n!\n\nP (X3 = k3 |X2 = k2 ) P (X2 = k2 |X0 = i) =\n\nk2 \u2208S\n\n= P (X0 = i)\n\nX\n\nP\n\nX\n\nN\n^\n\nP\n\nkN \u22122 \u2208S\n\n= P (X0 = i)\n\nXm = km |X3 = k3\n\nm=4 km \u2208S\n\nk3 \u2208S\n\n. . . = P (X0 = i)\n\nN\n^\n_\n\nX\n\nkN \u22122 \u2208S\n\n_\n\n!\n\nP (X3 = k3 |X0 = i) = . . .\n\nXm = km |XN \u22122 = kN \u22122\n\nm=N \u22121 km \u2208S\n\n\uf8eb\n\nP\uf8ed\n\n_\n\nXN \u22121 = kN \u22121 \u2227\n\nkN \u22121 \u2208S\n\n_\n\nkN \u2208S\n\n!\n\nP (XN \u22122 = kN \u22122 |X0 = i) =\n\uf8f6\n\nXN = kN |XN \u22122 = kN \u22122 \uf8f8\n\nP (XN \u22122 = kN \u22122 |X0 = i) =\n!\nX\nX\n_\n= P (X0 = i)\nP XN \u22121 = kN \u22121 \u2227\nXN = kN |XN \u22122 = kN \u22122\nkN \u22122 \u2208S kN \u22121 \u2208S\n\nkN \u2208S\n\nP (XN \u22122 = kN \u22122 |X0 = i) =\nX\nX\n= P (X0 = i)\nP\nkN \u22122 \u2208S kN \u22121 \u2208S\n\n_\n\nXN = kN |XN \u22121 = kN \u22121 \u2227 XN \u22122 = kN \u22122\n\nkN \u2208S\n\n!\n\nP (XN \u22121 = kN \u22121 |XN \u22122 = kN \u22122 ) P (XN \u22122 = kN \u22122 |X0 = i) =\n!\nX\nX\n_\n= P (X0 = i)\nP\nXN = kN |XN \u22121 = kN \u22121\nkN \u22122 \u2208S kN \u22121 \u2208S\n\nkN \u2208S\n\nP (XN \u22121 = kN \u22121 |XN \u22122 = kN \u22122 ) P (XN \u22122 = kN \u22122 |X0 = i) =\n!\nX\n_\n= P (X0 = i)\nP\nXN = kN |XN \u22121 = kN \u22121\nkN \u22121 \u2208S\n\nX\n\nkN \u2208S\n\nP (XN \u22121 = kN \u22121 |XN \u22122 = kN \u22122 ) P (XN \u22122 = kN \u22122 |X0 = i) =\n\nkN \u22122 \u2208S\n\n= P (X0 = i)\n\nX\n\nP\n\nkN \u22121 \u2208S\n\n= P (X0 = i)\n\nX\n\n_\n\nXN = kN |XN \u22121 = kN \u22121\n\nkN \u2208S\n\nX\n\n!\n\nP (XN \u22121 = kN \u22121 |X0 = i) =\n\nP (XN = kN |XN \u22121 = kN \u22121 ) P (XN \u22121 = kN \u22121 |X0 = i) =\n\nkN \u22121 \u2208S kN \u2208S\n\n= P (X0 = i)\n\nX\n\nX\n\nP (XN = kN |XN \u22121 = kN \u22121 ) P (XN \u22121 = kN \u22121 |X0 = i) =\n\nkN \u2208S kN \u22121 \u2208S\n\n= P (X0 = i)\n\nX\n\nP (XN = kN |X0 = i) =\n\nkN \u2208S\n\nINRIA\n\n\fQuasi-stationary distributions as entrality measures\n\n=\n\nnT\nX\n\n19\n\n(N )\n\nTikN P (X0 = i) =\n\nkN =1\n(N )\n\n= Ti\n\n1P (X0 = i) =\n\nP\n\nX0 = i \u2227\n\nN\n^\n\nXm \u2208 S\n\nm=1\n\n!\n\n(N )\n\n= Ti\n\n1P (X0 = i)\n\nNumerator:\n\nP\n\nX0 = i \u2227 X1 = j \u2227\n\nN\n^\n\nXm \u2208 S\n\nm=2\n\n= P\n\nN\n^\n_\n\nXm = km\n\nm=2 km \u2208S\n(N \u22121)\n\n= Tij Tj\nP\n\n!\n\n!\n\n=\n\nP (X1 = j|X0 = i) P (X0 = i) =\n\n1P (X0 = i) =\n\nX0 = i \u2227 X1 = j \u2227\n\nN\n^\n\nXm \u2208 S\n\nm=2\n\n!\n\n(N \u22121)\n\n= Tij Tj\n\n1P (X0 = i)\n\u2737\n\nContents\n1\n\nIntrodu tion\n\n2\n\nQuasi-stationary distributions as\n\n3\n\nNumeri al experiments and Appli ations\n\n11\n\n4\n\nCon lusion\n\n14\n\nRR\n\nn\u00b0 6263\n\n3\nentrality measures\n\n4\n\n\fUnit\u00e9 de recherche INRIA Sophia Antipolis\n2004, route des Lucioles - BP 93 - 06902 Sophia Antipolis Cedex (France)\nUnit\u00e9 de recherche INRIA Futurs : Parc Club Orsay Universit\u00e9 - ZAC des Vignes\n4, rue Jacques Monod - 91893 ORSAY Cedex (France)\nUnit\u00e9 de recherche INRIA Lorraine : LORIA, Technop\u00f4le de Nancy-Brabois - Campus scientifique\n615, rue du Jardin Botanique - BP 101 - 54602 Villers-l\u00e8s-Nancy Cedex (France)\nUnit\u00e9 de recherche INRIA Rennes : IRISA, Campus universitaire de Beaulieu - 35042 Rennes Cedex (France)\nUnit\u00e9 de recherche INRIA Rh\u00f4ne-Alpes : 655, avenue de l'Europe - 38334 Montbonnot Saint-Ismier (France)\nUnit\u00e9 de recherche INRIA Rocquencourt : Domaine de Voluceau - Rocquencourt - BP 105 - 78153 Le Chesnay Cedex (France)\n\n\u00c9diteur\nINRIA - Domaine de Voluceau - Rocquencourt, BP 105 - 78153 Le Chesnay Cedex (France)\nhttp://www.inria.fr\n\nISSN 0249-6399\n\n\f"}