{"id": "http://arxiv.org/abs/1007.0728v2", "guidislink": true, "updated": "2010-09-05T21:06:55Z", "updated_parsed": [2010, 9, 5, 21, 6, 55, 6, 248, 0], "published": "2010-07-05T17:22:06Z", "published_parsed": [2010, 7, 5, 17, 22, 6, 0, 186, 0], "title": "Artificial Learning in Artificial Memories", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1007.1247%2C1007.2527%2C1007.3288%2C1007.2771%2C1007.0482%2C1007.4817%2C1007.2784%2C1007.0323%2C1007.5017%2C1007.0561%2C1007.5408%2C1007.5196%2C1007.2413%2C1007.3966%2C1007.2858%2C1007.0836%2C1007.1534%2C1007.0835%2C1007.4436%2C1007.2721%2C1007.2220%2C1007.3731%2C1007.2709%2C1007.3035%2C1007.2891%2C1007.4946%2C1007.3259%2C1007.1671%2C1007.4526%2C1007.4418%2C1007.4909%2C1007.3354%2C1007.2086%2C1007.3484%2C1007.2785%2C1007.3007%2C1007.3182%2C1007.3968%2C1007.4090%2C1007.2939%2C1007.1207%2C1007.0956%2C1007.1806%2C1007.2898%2C1007.4277%2C1007.1125%2C1007.2849%2C1007.3129%2C1007.3954%2C1007.1708%2C1007.1451%2C1007.1218%2C1007.3574%2C1007.1509%2C1007.5346%2C1007.3652%2C1007.4182%2C1007.0325%2C1007.0955%2C1007.5258%2C1007.3301%2C1007.1698%2C1007.4082%2C1007.3760%2C1007.5382%2C1007.3791%2C1007.1464%2C1007.1362%2C1007.0728%2C1007.2411%2C1007.4379%2C1007.3116%2C1007.4796%2C1007.1484%2C1007.2443%2C1007.1731%2C1007.4249%2C1007.1752%2C1007.4195%2C1007.2078%2C1007.1757%2C1007.3698%2C1007.4359%2C1007.2069%2C1007.1627%2C1007.3076%2C1007.2596%2C1007.2295%2C1007.2539%2C1007.2068%2C1007.0424%2C1007.2242%2C1007.0796%2C1007.5129%2C1007.3932%2C1007.0005%2C1007.5242%2C1007.4152%2C1007.4151%2C1007.3368%2C1007.1035&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Artificial Learning in Artificial Memories"}, "summary": "Memory refinements are designed below to detect those sequences of actions\nthat have been repeated a given number n. Subsequently such sequences are\npermitted to run without CPU involvement. This mimics human learning. Actions\nare rehearsed and once learned, they are performed automatically without\nconscious involvement.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1007.1247%2C1007.2527%2C1007.3288%2C1007.2771%2C1007.0482%2C1007.4817%2C1007.2784%2C1007.0323%2C1007.5017%2C1007.0561%2C1007.5408%2C1007.5196%2C1007.2413%2C1007.3966%2C1007.2858%2C1007.0836%2C1007.1534%2C1007.0835%2C1007.4436%2C1007.2721%2C1007.2220%2C1007.3731%2C1007.2709%2C1007.3035%2C1007.2891%2C1007.4946%2C1007.3259%2C1007.1671%2C1007.4526%2C1007.4418%2C1007.4909%2C1007.3354%2C1007.2086%2C1007.3484%2C1007.2785%2C1007.3007%2C1007.3182%2C1007.3968%2C1007.4090%2C1007.2939%2C1007.1207%2C1007.0956%2C1007.1806%2C1007.2898%2C1007.4277%2C1007.1125%2C1007.2849%2C1007.3129%2C1007.3954%2C1007.1708%2C1007.1451%2C1007.1218%2C1007.3574%2C1007.1509%2C1007.5346%2C1007.3652%2C1007.4182%2C1007.0325%2C1007.0955%2C1007.5258%2C1007.3301%2C1007.1698%2C1007.4082%2C1007.3760%2C1007.5382%2C1007.3791%2C1007.1464%2C1007.1362%2C1007.0728%2C1007.2411%2C1007.4379%2C1007.3116%2C1007.4796%2C1007.1484%2C1007.2443%2C1007.1731%2C1007.4249%2C1007.1752%2C1007.4195%2C1007.2078%2C1007.1757%2C1007.3698%2C1007.4359%2C1007.2069%2C1007.1627%2C1007.3076%2C1007.2596%2C1007.2295%2C1007.2539%2C1007.2068%2C1007.0424%2C1007.2242%2C1007.0796%2C1007.5129%2C1007.3932%2C1007.0005%2C1007.5242%2C1007.4152%2C1007.4151%2C1007.3368%2C1007.1035&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Memory refinements are designed below to detect those sequences of actions\nthat have been repeated a given number n. Subsequently such sequences are\npermitted to run without CPU involvement. This mimics human learning. Actions\nare rehearsed and once learned, they are performed automatically without\nconscious involvement."}, "authors": ["John Robert Burger"], "author_detail": {"name": "John Robert Burger"}, "author": "John Robert Burger", "arxiv_comment": "7 pages, 4 figures", "links": [{"href": "http://arxiv.org/abs/1007.0728v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1007.0728v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "q-bio.NC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.2.0; I.2.2; I.2.6", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1007.0728v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1007.0728v2", "journal_reference": null, "doi": null, "fulltext": "Artificial Learning in Artificial Memories\nJohn Robert Burger\nProfessor Emeritus\nDepartment of Electrical and Computer Engineering\n25686 Dahlin Road\nVeneta, OR 97487\n(jrburger1@gmail.com)\nAbstract \u2013 Memory refinements are designed below to detect those sequences of actions that\nhave been repeated a given number n. Subsequently such sequences are permitted to run\nwithout CPU involvement. This mimics human learning. Actions are rehearsed and once\nlearned, they are performed automatically without conscious involvement.\nIntroduction\nThis paper is written from the perspective of designing artificial brains that are modeled after\nhuman brains. This architectural work pays attention to human psychology including the\ninterplay between short and long term memory, the realization of which is assumed\nconstrained by circuit and system theory. This paper is a humble attempt, but at least it has an\noriginal aspect. My fellow engineering stereotypes tend to ignore human psychology; worse\nyet, scientists in life sciences, seem unaware of the constraints imposed by working circuits and\nsystems. Although their products such as long term potentiation are impressive at first sight\nand sometimes work in cyberspace, they are most unpromising for practical humanoid\nrealizations.\nLearning is much more than random or mathematical optimization leading to a successful\nsequence of actions, although no doubt successful actions need to be discovered. The\ndiscovery of successful actions ought to be termed searching or investigating, anything but\nlearning. Learning is a specific attribute beyond mere memory that implies a long term physical\nmodification of underlying circuitry such that, in the big picture, human efficacy increases.\nComputers today obviously cannot be modified in any fundamental way by their own\nprogramming. Consequently, the envisioned learning, as below, is unrelated to the field of\nmachine learning. Machine learning is traditionally limited to the programming of structured,\nfundamentally unalterable computers (Sun & Giles, 2001; Alpaydin 2010).\nThere are times when we might benefit from artificial learning in everyday life. For example, a\nperson might perform certain keystrokes over and over; one opens a mail server, the inbox is\nopened, email is selected in chronological order and it is properly filed, each action hundreds of\ntimes per year. Yet today's best personal computers will not learn even this!\nThis paper is not about the programming of artificial neural networks (Haykin 1994). The\ntraining of artificial neural networks using, for example, gradient descent, has been construed\nas learning, but properly this is not learning at all. It is an exercise in mathematical optimization\nwithout biological underpinning.\n1\n\n\fLearning Modeled After Biology\nLearning may be viewed in the biological sense as an internalization process that detects,\nremembers and reproduces successful sequences. Learning results in performing an action, or\npossibly several actions concurrently without cognitive effort or thinking, meaning without\nconscious involvement.\nMemory hardware is designed below to learn repeated actions, analogous to rehearsal when\nhumans learn. Much of what we learn is a sequence of actions, for examples, proper\ncomponents of walking, reciting a poem or reproducing a musical tune. Such things are\nmemory-mapped actions and may be performed without CPU effort (analogous to thinking)\nonce they have been learned, and this is a key point. Properties of artificial learning for\nmemory-mapped sequences are summarized in Table 1.\nTable 1 Artificial Learning\n1 A result of rehearsal\n2 Occurs within long term memory\n3 Enables long term modification of underlying circuitry\n4 Permits action without CPU effort\n5 Permits action without CPU delays\n6 Permits action without CPU memory usage\n7 Independent sequences may run concurrently\nOverview of a Memory System\nArtificial human memory has been modeled as employing cues in a routine to find matches\nwithin associative memory (Burger 2009). One may envision an anthropomorphic system of\ndynamic (short term) working memory as in Fig. 1. Working memory has been modeled as\norchestrating long term memory (Burger Aug 30, 2010). Long term memory in humans is\nanalogous to PROM (programmable read only memory that may be programmed exactly once).\nIn humans, the contents of working memory are known (via consciousness) but all else,\nincluding editing processes are hidden.\nAn important albeit neglected attribute of any memory system is its ability to \"learn.\" Learning\nis definitely not memorization. Learning here means an ability to run a sequence of memory\nwords without controls from working memory (or CPU). This ability occurs only if the sequence\nis sufficiently rehearsed and only if a word of the sequence has been addressed by working\nmemory. This type of learning has been termed \"state machine\" learning.\nArtificial Leaning for Artificial Memories\nA word of long term memory is assumed to hold components for images or actions. Each word\nin a practical system can be diagramed as in Fig. 2. The signals and commands held by the word\nare released by activating the enable. Once the signals and commands have all been\ndischarged, there is a done signal.\n2\n\n\fTo learn something that is being practiced, a timing filter is required to detect a repeated\nsequence. For example the filter must detect whenever a certain word is enabled immediately\nafter another given word is done. A suitable digital filter to detect a sequence exploits the\ndelay between active words, specified to be Delay 1 as in Fig. 3. Part (a) of the figure indicates\nthat a done signal from Word 1 is held for a time Delay 1. Implementation of Delay 1 is not\nshown but is straightforward using elements of short term memory. When a second done\nsignal arrives in a timely way from some other word, say from Word 2, the AND gate is\nactivated to make X1 true.\nX1 results in the generation of a single spike. The spike operates a shift register of set-only Dlatches identified as D1, D2 . . . Dn-1, Dn. All D-latches initially are set to Boolean zero (cleared).\nEach time the 1-2 sequence occurs, a true signal shifts to the left one place in the shift register.\nLatch details appear in part (b) of the Fig. 3. Note that the D-latches can be set true only once\nin this plan, since learning, once it occurs, is assumed long term. The spike generator in part (c)\nof the figure uses a standard XOR (exclusive OR) to produce a brief spike on the leading edge of\nsignal X1. Spike width is determined by DELAY 2. Spike width is just enough to move the\nBoolean signal X1 only one step along the shift register. AND, OR and XOR gates are readily\navailable both in brain neurons and in hardware (Burger Apr 2010).\nThe design in Fig. 4 supports possible state transitions from any given word to any other given\nword in a block of n words within long term memory. The maximum number of possible\nsequences is n! Fig. 4 shows only three words, although many more can be used. In an attempt\nto gain focus, consider the sequence 1-3-2 that has been used, say, ten times so that it is well\nlearned. Then, whenever Word 1 is addressed (associatively) by short term memory a minor\nmiracle occurs. After a time equal to Delay 1, Word 3 is addressed directly by Word 1. Then\nafter another time equal to Delay 1, Word 2 is addressed directly by Word 3. This will\naccomplish a three-step procedure without CPU involvement.\nNote that switches Sij (1 \u2264 i \u2264 K, 1 \u2264 j \u2264 K, i \u2260 j) enable the state machine. For example, a switch\nS13 applies the done signal from Word 1 to the delayed enable of Word 3. Switches are viewed\nby neuroscientists as synaptic connections promoted by interneurons, but computer engineers\ncreate contacts artificially with a FET (Field Effect Transistor).\nIn general for K words and an arbitrary sequence that may go forward or backward, K (K-1)\ntiming filters are needed. This implies a like number of bus lines for the filter outputs and a like\nnumber of switches Sij (1 \u2264 i \u2264 K, 1 \u2264 j \u2264 K, i \u2260 j). Also there must be K lines for memory word\noutputs and K lines for memory word inputs. The overhead is reasonable for systems with\ncomplexity such as humanoid memory.\nLimitations of Artificial Learning\nA pitfall is that once a learned action is activated, it executes asynchronously. In practical\nmemory, as in human memory, it is always possible to override learning. In this case, one\n3\n\n\fsimply opens the Sij circuit using another series switch (not shown). This returns control to\nworking memory same as it does in humans.\nLearning cannot be erased easily, so if the learning is wrong, a correct version must be relearned. This is also true of human learning.\nA limitation of any state machine is that states (words) must be distinguishable. This means\nthat a learned sequence cannot repeat a given word in a sequence. For example, one cannot\nlearn the sequence 1-3-1-2 because state 1 is repeated. However, different versions of a\nrepeated word are readily possible, permitting for example, 1a-2-1b-3. Looping is not\nautomatic since it would involve repeating a word, for example, 1-2-3-1-2-3.... In this system a\ngiven sequence may be repeated by only a call from working memory.\nConclusions\nLearning is largely important both to humans and to intelligent robots. Survival matters, which\nhinges on reflexive actions concurrent with quick thinking, especially when there is no time to\nponder the pros and cons of a response. From another view, learning enables multitasking in\nthe sense that while learned actions are being performed one may think about something else.\nOne may read music and also play the violin, for instance.\nLearning as above depends on timing filters that anyone can build and verify. These filters\ndetect and remember a sequence that is rehearsed a given number of times (n). Learned\nsequences, once called, run automatically within long term memory. CPU effort is not required.\nObviously, this frees central processing for more important work while a sequence is running.\nMore importantly, long term memory is freed from the constraints of CPU control.\nConsequently artificial learning creates the possibility of parallel processing since many learned\nsequences may run simultaneously assuming they involve independent memory words.\n\n4\n\n\fFig. 1 Short term (working) memory (consciousness) provides cues that are edited\nsubliminally while recalls from associative long term memory are tested unconsciously before\nrefreshing working memory\n\n(done)\n(enable))\n\nWord\n\nFig. 2 Symbol for a word of long term memory with controls\n\n5\n\n\fLearning (Digital) Filter\n\nQ\n\nDn\n\nDn-1\n\nDelay1\n\nD2 D1\n\nX1\n\nWord1(done)\n\nWord 2 (done)\n\n(a)\n\nCk Bus\nX2\n(b)\n\nExample Data Latch D1\nCk\n\n(c)\n\nX1\n\nX1\nCk\n\nDelay2 < Delay1\n\nFig. 3 Learning filter showing how rehearsal technically results in permanent learning\n\n6\n\n\f321\n3-2\n\n3-1\n\n2-3\n\n2-1\n\n1-3\n\n321\n\nDIG FLTS\n\n1-2\nQ12 1-2 Flt\n\nS12\n1-3 Flt\n2-1 Flt\n2-3 Flt\n\n(done)\n(enable))\n\nWd 1\n\n(done)\n(enable))\n\nWd 2\n\n(done)\n(enable))\n\nWd 3\n\nS13\n\nD\nD=Delay1\n\nS21\n\nD\n\nS23\n\n3-1 Flt\nS31\n\nD\n\n.\n.\n.\n\n3-2 Flt\nS32\n(done)\n(enable))\n\nWd K\n\nFig. 4 Embedded state machine to learn an arbitrary sequence of words\n\nReferences\nAlpaydin E, Introduction to Machine Learning, second edition, MIT Press 2010\nBurger J R, Human Memory Modeled with Standard Analog and Digital Circuits \u2013 Inspiration for\nMan-made Computers, Wiley, 2009\nBurger J R, XOR at a Single Vertex -- Artificial Dendrites, arXiv:1004.2280v1 [cs.NE], Apr 2010;\n[Online]: Available: http://arxiv.org/abs/1004.2280\nBurger J R, Artificial Brain Based on Credible Neural Circuits in a Human Brain,\narXiv:1008.5161v1 [cs.AI], Aug 30, 2010; [Online}: Available: http://arxiv.org/abs/1008.5161\nHaykin S, Neural Networks: A Comprehensive Foundation, Macmillan, 1994.\nSun R, Giles CL, Sequence Learning: From Recognition and Prediction to Sequential Decision\nMaking, July/August 2001 (vol. 16 no. 4) pp. 67-70; [Online]: Available:\nhttp://scholar.google.com/scholar?q=Sequence+Learning:+From+Recognition+and+Predicti\non+to+Sequential+Decision+Making&hl=en&as_sdt=0&as_vis=1&oi=scholar\n\n7\n\n\f"}