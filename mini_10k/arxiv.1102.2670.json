{"id": "http://arxiv.org/abs/1102.2670v1", "guidislink": true, "updated": "2011-02-14T04:06:31Z", "updated_parsed": [2011, 2, 14, 4, 6, 31, 0, 45, 0], "published": "2011-02-14T04:06:31Z", "published_parsed": [2011, 2, 14, 4, 6, 31, 0, 45, 0], "title": "Online Least Squares Estimation with Self-Normalized Processes: An\n  Application to Bandit Problems", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1102.0467%2C1102.0053%2C1102.0361%2C1102.0535%2C1102.0204%2C1102.4992%2C1102.1275%2C1102.3321%2C1102.5395%2C1102.4882%2C1102.3984%2C1102.4734%2C1102.0652%2C1102.3791%2C1102.0635%2C1102.4707%2C1102.3646%2C1102.2917%2C1102.2708%2C1102.5252%2C1102.5012%2C1102.4266%2C1102.5443%2C1102.4230%2C1102.3703%2C1102.5715%2C1102.3048%2C1102.2972%2C1102.1775%2C1102.0265%2C1102.2670%2C1102.3134%2C1102.2691%2C1102.4162%2C1102.0263%2C1102.2574%2C1102.0363%2C1102.2345%2C1102.2201%2C1102.5107%2C1102.3133%2C1102.4483%2C1102.1409%2C1102.5344%2C1102.4467%2C1102.2701%2C1102.2178%2C1102.5164%2C1102.3195%2C1102.4685%2C1102.2974%2C1102.1766%2C1102.2961%2C1102.4272%2C1102.4800%2C1102.4190%2C1102.0348%2C1102.3813%2C1102.1794%2C1102.2764%2C1102.3621%2C1102.2128%2C1102.1229%2C1102.4039%2C1102.3387%2C1102.2149%2C1102.1744%2C1102.0033%2C1102.3632%2C1102.4791%2C1102.0767%2C1102.1720%2C1102.2818%2C1102.5004%2C1102.5649%2C1102.4078%2C1102.3340%2C1102.5155%2C1102.5598%2C1102.4887%2C1102.5498%2C1102.0457%2C1102.3926%2C1102.4543%2C1102.4811%2C1102.4775%2C1102.1501%2C1102.5147%2C1102.0246%2C1102.0083%2C1102.1290%2C1102.0692%2C1102.0031%2C1102.2945%2C1102.4413%2C1102.2814%2C1102.1680%2C1102.1779%2C1102.3737%2C1102.0766%2C1102.3711&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Online Least Squares Estimation with Self-Normalized Processes: An\n  Application to Bandit Problems"}, "summary": "The analysis of online least squares estimation is at the heart of many\nstochastic sequential decision making problems. We employ tools from the\nself-normalized processes to provide a simple and self-contained proof of a\ntail bound of a vector-valued martingale. We use the bound to construct a new\ntighter confidence sets for the least squares estimate.\n  We apply the confidence sets to several online decision problems, such as the\nmulti-armed and the linearly parametrized bandit problems. The confidence sets\nare potentially applicable to other problems such as sleeping bandits,\ngeneralized linear bandits, and other linear control problems.\n  We improve the regret bound of the Upper Confidence Bound (UCB) algorithm of\nAuer et al. (2002) and show that its regret is with high-probability a problem\ndependent constant. In the case of linear bandits (Dani et al., 2008), we\nimprove the problem dependent bound in the dimension and number of time steps.\nFurthermore, as opposed to the previous result, we prove that our bound holds\nfor small sample sizes, and at the same time the worst case bound is improved\nby a logarithmic factor and the constant is improved.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1102.0467%2C1102.0053%2C1102.0361%2C1102.0535%2C1102.0204%2C1102.4992%2C1102.1275%2C1102.3321%2C1102.5395%2C1102.4882%2C1102.3984%2C1102.4734%2C1102.0652%2C1102.3791%2C1102.0635%2C1102.4707%2C1102.3646%2C1102.2917%2C1102.2708%2C1102.5252%2C1102.5012%2C1102.4266%2C1102.5443%2C1102.4230%2C1102.3703%2C1102.5715%2C1102.3048%2C1102.2972%2C1102.1775%2C1102.0265%2C1102.2670%2C1102.3134%2C1102.2691%2C1102.4162%2C1102.0263%2C1102.2574%2C1102.0363%2C1102.2345%2C1102.2201%2C1102.5107%2C1102.3133%2C1102.4483%2C1102.1409%2C1102.5344%2C1102.4467%2C1102.2701%2C1102.2178%2C1102.5164%2C1102.3195%2C1102.4685%2C1102.2974%2C1102.1766%2C1102.2961%2C1102.4272%2C1102.4800%2C1102.4190%2C1102.0348%2C1102.3813%2C1102.1794%2C1102.2764%2C1102.3621%2C1102.2128%2C1102.1229%2C1102.4039%2C1102.3387%2C1102.2149%2C1102.1744%2C1102.0033%2C1102.3632%2C1102.4791%2C1102.0767%2C1102.1720%2C1102.2818%2C1102.5004%2C1102.5649%2C1102.4078%2C1102.3340%2C1102.5155%2C1102.5598%2C1102.4887%2C1102.5498%2C1102.0457%2C1102.3926%2C1102.4543%2C1102.4811%2C1102.4775%2C1102.1501%2C1102.5147%2C1102.0246%2C1102.0083%2C1102.1290%2C1102.0692%2C1102.0031%2C1102.2945%2C1102.4413%2C1102.2814%2C1102.1680%2C1102.1779%2C1102.3737%2C1102.0766%2C1102.3711&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The analysis of online least squares estimation is at the heart of many\nstochastic sequential decision making problems. We employ tools from the\nself-normalized processes to provide a simple and self-contained proof of a\ntail bound of a vector-valued martingale. We use the bound to construct a new\ntighter confidence sets for the least squares estimate.\n  We apply the confidence sets to several online decision problems, such as the\nmulti-armed and the linearly parametrized bandit problems. The confidence sets\nare potentially applicable to other problems such as sleeping bandits,\ngeneralized linear bandits, and other linear control problems.\n  We improve the regret bound of the Upper Confidence Bound (UCB) algorithm of\nAuer et al. (2002) and show that its regret is with high-probability a problem\ndependent constant. In the case of linear bandits (Dani et al., 2008), we\nimprove the problem dependent bound in the dimension and number of time steps.\nFurthermore, as opposed to the previous result, we prove that our bound holds\nfor small sample sizes, and at the same time the worst case bound is improved\nby a logarithmic factor and the constant is improved."}, "authors": ["Yasin Abbasi-Yadkori", "David Pal", "Csaba Szepesvari"], "author_detail": {"name": "Csaba Szepesvari"}, "author": "Csaba Szepesvari", "arxiv_comment": "Submitted to the 24th Annual Conference on Learning Theory (COLT\n  2011)", "links": [{"href": "http://arxiv.org/abs/1102.2670v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1102.2670v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1102.2670v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1102.2670v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:1102.2670v1 [cs.AI] 14 Feb 2011\n\nOnline Least Squares Estimation with Self-Normalized\nProcesses: An Application to Bandit Problems\u2217\n\nYasin Abbasi-Yadkori\n\nD\u00e1vid P\u00e1l\n\nCsaba Szepesv\u00e1ri\n\nabbasiya@cs.ualberta.ca\n\ndpal@cs.ualberta.ca\n\nszepesva@cs.ualberta.ca\n\nDept. of Computing Science\nUniversity of Alberta\n\nDept. of Computing Science\nUniversity of Alberta\n\nDept. of Computing Science\nUniversity of Alberta\n\nAbstract\nThe analysis of online least squares estimation is at the heart of many stochastic sequential\ndecision-making problems. We employ tools from the self-normalized processes to provide\na simple and self-contained proof of a tail bound of a vector-valued martingale. We use the\nbound to construct new tighter confidence sets for the least squares estimate.\nWe apply the confidence sets to several online decision problems, such as the multi-armed\nand the linearly parametrized bandit problems. The confidence sets are potentially applicable to other problems such as sleeping bandits, generalized linear bandits, and other\nlinear control problems.\nWe improve the regret bound of the Upper Confidence Bound (UCB) algorithm of Auer et al.\n(2002) and show that its regret is with high-probability a problem dependent constant. In\nthe case of linear bandits (Dani et al., 2008), we improve the problem dependent bound in\nthe dimension and number of time steps. Furthermore, as opposed to the previous result,\nwe prove that our bound holds for small sample sizes, and at the same time the worst case\nbound is improved by a logarithmic factor and the constant is improved.\n\n1\n\nIntroduction\n\nThe least squares method forms a cornerstone of statistics and machine learning. It is used as\nthe main component of many stochastic sequential decision problems, such as multi-armed bandit, linear bandits, and other linear control problems. However, the analysis of least squares in\nthese online settings is non-trivial because of the correlations between data points. Fortunately,\nthere is a connection between online least squares estimation and the area of self-normalized processes. Study of self-normalized processes has a long history that goes back to Student and is\ntreated in detail in recent book by de la Pe\u00f1a et al. (2009). Using these tools we provide a proof\nof a bound on the deviation for vector-valued martingales. A less general version of the bound\ncan be found already in de la Pe\u00f1a et al. (2004, 2009). Additionally our proof, based on the\nmethod of mixtures, is new, simpler and self-contained. The bound improves the previous bound\nof Rusmevichientong and Tsitsiklis (2010) and it is applicable to virtually any online least squares\nproblem.\nThe bound that we derive, gives immediately rise to tight confidence sets for the online least\nsquares estimate that can replace the confidence sets in existing algorithms. In particular, the\nconfidence sets can be used in the UCB algorithm for the multi-armed bandit problem, the ConfidenceBall algorithm of Dani et al. (2008) for the linear bandit problem, and LinRel algorithm\nof Auer (2003) for the associative reinforcement learning problem. We show that this leads to improved performance of these algorithms. Our hope is that the new confidence sets can be used to\nimprove the performance of other similar linear decision problems.\nThe multi-armed bandit problem, introduced by Robbins (1952), is a game between the learner\nand the environment. At each time step, the learner chooses one of K actions and receives a reward\nwhich is generated independently at random from a fixed distribution associated with the chosen\narm. The objective of the learner is to maximize his total reward. The performance of the learner\nis evaluated by the regret, which is defined as the difference between his total reward and the total\n\u2217\n\nSubmitted to the 24th Annual Conference on Learning Theory (COLT 2011)\n\n\fP\nreward of the best action. Lai and Robbins (1985) prove a ( i6=i\u2217 1/D(pj , pi\u2217 ) \u2212 o(1)) log T lower\nbound on the expected regret of any algorithm, where T is the number of time steps, pi\u2217 and pi are\nthe reward distributions of the optimal arm and arm i respectively, and D is the KL-divergence.\nAuer et al. (2002) designed the UCB algorithm and proved a finite-time logarithmic bound\non its regret. He used Hoeffding's inequality to construct confidence intervals and obtained a\nO((K log T )/\u2206) bound on the expected regret, where \u2206 is the difference between the expected\nrewards of the best and the second best action. We modify UCB so that it uses our new confidence\nsets and we show a stronger result. Namely, we show that with probability 1 \u2212 \u03b4, the regret of\nthe modified algorithm is O(K log(1/\u03b4)/\u2206). Seemingly, this result contradicts the lower bound of\nLai and Robbins (1985), however our algorithm depends on \u03b4 which it receives as an input. The\nexpected regret of the modified algorithm with \u03b4 = 1/T matches the regret of the original algorithm.\nIn the linear bandit problem, the learner chooses repeatedly actions from a fixed subset of Rd and\nreceives a random reward, expectation of which is a linear function of the action. Dani et p\nal. (2008)\nproposed the ConfidenceBall algorithm and showed that its regret is at most O(d log(T ) T log(T /\u03b4))\nwith probability at most 1 \u2212 \u03b4. We modify their algorithm\nso\np that it uses our new confidence\n\u221a\nsets and we show that its regret is at most O(d log(T ) T + dT log(T /\u03b4)). Additionally, constants in our bound are smaller, and our bound holds for all T \u2265 1, as opposed the previous one\nwhich holds only for sufficiently large T . Dani et al. (2008) prove also a problem dependent regret\n2\nbound. Namely, they show that the regret of their algorithm is O( d\u2206 log2 T log(T /\u03b4)) where \u2206\nis the \"gap\" as defined in (Dani et al., 2008). For our modified algorithm we prove an improved\n(log T + d log log T )2 ) bound.\nO( log(1/\u03b4)\n\u2206\n1.1 Notation\nWe use k * k to denote the 2-norm. For a positive definite matrix A \u2208 Rd\u00d7d , the weighted 2-norm\nis defined by kxk2A = x\u22a4 Ax, where x \u2208 Rd . The inner product is denoted by h*, *i and the weighted\ninner-product x\u22a4 Ay = hx, yiA . We use \u03bbmin (A) to denote the minimum eigenvalue of the positive\ndefinite matrix A. We use A \u227b 0 to denote that A is positive definite, while we use A \u0017 0 to denote\nthat it is positive semidefinite. The same notation is used to denote the Loewner partial order of\nmatrices. We shall use ei to denote the ith unit vector, i.e., for all j 6= i, eij = 0 and eii = 1.\n\n2\n\nVector-Valued Martingale Tail Inequalities\n\nLet (Fk ; k \u2265 0) be a filtration, (mk ; k \u2265 0) be an Rd -valued stochastic process adapted to (Fk ),\n(\u03b7k ; k \u2265 1) be a real-valued martingale difference process adapted to (Fk ). Assume that \u03b7k is\nconditionally sub-Gaussian in the sense that there exists some R > 0 such that for any \u03b3 \u2208 R, k \u2265 1,\n\u0012 2 2\u0013\n\u03b3 R\nE[exp(\u03b3\u03b7k ) | Fk\u22121 ] \u2264 exp\na.s.\n(1)\n2\nConsider the martingale\nSt =\n\nt\nX\n\n\u03b7k mk\u22121\n\n(2)\n\nk=1\n\nand the matrix-valued processes\nVt =\n\nt\nX\n\nmk\u22121 m\u22a4\nk\u22121 ,\n\nV t = V + Vt ,\n\nk=1\n\nt \u2265 0,\n\n(3)\n\nwhere V is an F0 -measurable, positive definite matrix. In particular, assume that with probability\none, the eigenvalues of V are larger than \u03bb0 > 0 and that kmk k \u2264 L holds a.s. for any k \u2265 0.\nThe following standard inequality plays a crucial role in the following developments:\nLemma 1. Consider (\u03b7t ), (mt ) as defined above and let \u03c4 be a stopping time with respect to the\nfiltration (Ft ). Let \u03bb \u2208 Rd be arbitrary and consider\n\u0014\n\u0015!\nt\nX\n\u03b7k h\u03bb, mk\u22121 i 1\n\u03bb\n2\nPt = exp\n.\n\u2212 h\u03bb, mk\u22121 i\nR\n2\nk=1\n\nThen P\u03c4 is almost surely well-defined and\n\u0002 \u0003\nE P\u03c4\u03bb \u2264 1.\n2\n\n\fProof. The proof is standard (and is given only for the sake of completeness). We claim that Pt = Pt\u03bb\nis a supermartingale. Let\n\u0012\n\u0013\n\u03b7k h\u03bb, mk\u22121 i 1\nDk = exp\n\u2212 h\u03bb, mk\u22121 i2 .\nR\n2\nObserve that by (1), we have E [Dk |Fk\u22121 ] \u2264 1. Clearly, Dk is Fk -adapted, as is Pk . Further,\nE [Pt |Ft\u22121 ] = E [D1 * * * Dt\u22121 Dt |Ft\u22121 ] = D1 * * * Dt\u22121 E [Dt |Ft\u22121 ] \u2264 Pt\u22121 ,\nshowing that (Pt ) is indeed a supermartingale.\nNow, this immediately leads to the desired result when \u03c4 = t for some deterministic time t.\nThis is based on the fact that the mean of any supermartingale can be bounded by the mean of its\nfirst element. In the case of (Pt ), for example, we have E [Pt ] = E [E [Pt |Ft\u22121 ]] \u2264 E [Pt\u22121 ] \u2264 . . . \u2264\nE [P0 ] = E [D0 ] = 1.\nNow, in order to consider the general case, let St = P\u03c4 \u2227t .1 It is well known that (St ) is still\na supermartingale with E [St ] \u2264 E [S0 ] = E [P0 ] = 1. Further, since Pt was nonnegative, so is\nSt . Hence, by the convergence theorem for nonnegative supermartingales, almost surely, limt\u2192\u221e St\nexists, i.e., P\u03c4 is almost surely well-defined. Further, E [P\u03c4 ] = E [lim inf t\u2192\u221e St ] \u2264 lim inf t\u2192\u221e E [St ] \u2264\n1 by Fatou's Lemma.\nBefore stating our main results, we give some recent results, which can essentially be extracted\nfrom the paper by Rusmevichientong and Tsitsiklis (2010).\nTheorem 2. Consider the processes (St ), (V t ) as defined above and let\np\n\u03ba = 3 + 2 log((L2 + trace(V ))/\u03bb0 ).\n\nThen, for any 0 < \u03b4 < 1, t \u2265 2, with probability at least 1 \u2212 \u03b4,\np\np\nkSt kV \u22121 \u2264 2 \u03ba2 R log t d log(t) + log(1/\u03b4) .\nt\n\n(4)\n\n(5)\n\nWe now show how to strengthen the previous result using the method of mixtures, originally used\nby Robbins and Siegmund (1970) to evaluate boundary crossing probabilities for Brownian motion.\nTheorem 3 (Self-normalized bound for vector-valued martingales). Let (\u03b7t ), (mt ), (St ), (V t ), and\n(Ft ) be as before and let \u03c4 be a stopping time with respect to the filtration (Ft ). Assume that V is\ndeterministic. Then, for any 0 < \u03b4 < 1, with probability 1 \u2212 \u03b4,\n\u0013\n\u0012\n1\n\u22121\ndet(V \u03c4 ) /2 det(V ) /2\n2\n2\nkS\u03c4 kV \u22121 \u2264 2R log\n.\n(6)\n\u03c4\n\u03b4\nProof. Without loss of generality, assume that R = 1 (by appropriately scaling St , this can always\nbe achieved). Let\n\u0011\n\u0010\nMt (\u03bb) = exp h\u03bb, St i \u2212 21 k\u03bbk2Vt .\n\nNotice that by Lemma 1, the mean of M\u03c4 (\u03bb) is not larger than one.\nLet \u039b be a Gaussian random variable which is independent of all the other random variables and\nwhose covariance is V \u22121 . Define\nMt = E [Mt (\u039b)|F\u221e ] .\nClearly, we still have E [M\u03c4 ] = E [ E [ M\u03c4 (\u039b) | \u039b ] ] \u2264 1.\nLet p\nus calculate Mt : Let\nthe density of \u039b and for a positive definite matrix P let\nR f denote\n1 \u22a4\nd\nc(P ) = (2\u03c0) / det(P ) = exp(\u2212 2 x P x)dx. Then,\nZ\n\u0011\n\u0010\n2\nMt =\nexp h\u03bb, St i \u2212 12 k\u03bbkVt f (\u03bb) d\u03bb\nd\nZR\n\u0010\n\u0011\n2\n2\n=\nexp \u2212 21 \u03bb \u2212 Vt\u22121 St Vt + 12 kSt kV \u22121 f (\u03bb) d\u03bb\nt\nRd\n\u0010\n\u0011Z\nn\no\u0011\n\u0010\n1\n2\nexp 12 kSt k2V \u22121\nd\u03bb.\n\u03bb \u2212 Vt\u22121 St V + k\u03bbk2V\nexp \u2212 21\n=\nt\nt\nc(V )\nRd\n1\n\n\u03c4 \u2227 t is a shorthand notation for min(\u03c4, t).\n\n3\n\n\fElementary calculation shows that if P \u0017 0, Q \u227b 0,\nkx \u2212 ak2P + kxk2Q = x \u2212 (P + Q)\u22121 P a\n\n2\nP +Q\n\n+ kak2P \u2212 kP ak2(P +Q)\u22121 .\n\nTherefore,\n\u03bb \u2212 Vt\u22121 St\n\n2\nVt\n\n2\n\n+ k\u03bbkV\n\n2\nV +Vt\n2\n\u22121\nVt ) St V +Vt\n\n=\n\n\u03bb \u2212 (V + Vt )\u22121 St\n\n=\n\n\u03bb \u2212 (V +\n\n+ Vt\u22121 St\n\n2\nVt\n\n2\n\n\u2212 kSt k(V +Vt )\u22121\n\n+ kSt k2V \u22121 \u2212 kSt k2(V +Vt )\u22121 ,\nt\n\nwhich gives\n\u0010\n\u0011\n\u0011Z\n\u0010\n1\n2\nexp 12 kSt k2(V +Vt )\u22121\nexp \u2212 12 \u03bb \u2212 (V + Vt )\u22121 St V +V d\u03bb\nt\nc(V )\nRd\n\u00131/2\n\u0012\n\u0010\n\u0010\n\u0011\n\u0011\nc(V + Vt )\ndet(V )\n2\n2\nexp 21 kSt k(V +Vt )\u22121 .\nexp 21 kSt k(V +Vt )\u22121 =\n=\nc(V )\ndet(V + Vt )\n\nMt =\n\nNow, from E [M\u03c4 ] \u2264 1, we obtain\n\n\uf8eb\n\u0012\n\u0013\u0013\n\u0012\n1/2\n\uf8ec\ndet(V + V\u03c4 )\n1\n2\nP kS\u03c4 k(V +V\u03c4 )\u22121 > 2 log\n= P\uf8ec\n1/2\n\uf8ed\n\u03b4\ndet(V )\n\uf8ee\n\n\uf8ef\n\u2264 E\uf8ef\n\uf8f0\n\nexp\n\n\u0010\n\n1\n2\n\n\u0010\n\n1\n2\n\nkS\u03c4 k2(V +V\u03c4 )\u22121\n\n\u0011\n\n\u0010\n.\n\u03b4 \u22121 det(V + V\u03c4 ) det(V )\nexp\n\n\u03b4 \u22121\n\n\u0010\n\n2\nkS\u03c4 k(V +V\u03c4 )\u22121\n\n\u0011\n\n\u00111\n2\n\n\uf8f6\n\n\uf8f7\n> 1\uf8f7\n\uf8f8\n\n\uf8f9\n\n\uf8fa\n\uf8fa\n.\n\u00111 \uf8fb\n2\ndet(V + V\u03c4 )\ndet(V )\n\n= E [M\u03c4 ] \u03b4 \u2264 \u03b4,\nthus finishing the proof.\n\nCorollary 1 (Uniform Bound). Under the same assumptions as in the previous theorem, for any\n0 < \u03b4 < 1, with probability 1 \u2212 \u03b4,\n\u0012\n\u0013\n1\n\u22121\ndet(V t ) /2 det(V ) /2\n2\n\u2200t \u2265 0,\nkSt kV \u22121 \u2264 2R2 log\n.\n(7)\nt\n\u03b4\nProof. We will use a stopping time construction, which goes back at least to Freedman (1975).\nDefine the bad event\n\u001a\n\u0012\n\u0013\u001b\ndet(V\u0304t )1/2 det(V )\u22121/2\nBt (\u03b4) = \u03c9 \u2208 \u03a9 : kSt k2V\u0304 \u22121 > 2R2 log\n(8)\nt\n\u03b4\nS\nWe are interested in bounding the probability that t\u22650 Bt (\u03b4) happens. Define \u03c4 (\u03c9) = min{t \u2265\n0 : \u03c9 \u2208 Bt (\u03b4)}, with the convention that min \u2205 = \u221e. Then, \u03c4 is a stopping time. Further,\n[\nBt (\u03b4) = {\u03c9 : \u03c4 (\u03c9) < \u221e}.\nt\u22650\n\nThus, by Theorem 3\n\uf8eb\n\uf8f6\n[\nP \uf8ed Bt (\u03b4)\uf8f8 = P (\u03c4 < \u221e)\nt\u22650\n\n\u0013\n\u0013\n\u0012\n\u0012\ndet(V\u0304\u03c4 )1/2 det(V )\u22121/2\n2\n2\n,\u03c4 <\u221e\n= P kS\u03c4 kV\u0304\u03c4\u22121 > 2R log\n\u03b4\n\u0012\n\u0012\n\u0013\u0013\ndet(V\u0304\u03c4 )1/2 det(V )\u22121/2\n\u2264 P kS\u03c4 k2V\u0304\u03c4\u22121 > 2R2 log\n\u03b4\n\u2264\u03b4.\n\n4\n\n\fLet us now turn our attention to understanding the determinant term on the right-hand side\nof (6).\nLemma 4. We have that\n\nt\n\nlog\n\ndet(V t ) X\n2\n\u2264\nkmk\u22121 kV \u22121 .\nk\u22121\ndet V\nk=1\n\nFurther, we have that\n\nt \u0010\n\u0011\nX\n2\nkmk\u22121 kV \u22121 \u2227 1 \u2264 2(log det(V t ) \u2212 log det V ) \u2264 2(d log((trace(V ) + tL2 )/d) \u2212 log det V ).\nk\u22121\n\nk=1\n\nFinally, if \u03bb0 \u2265 max(1, L2 ) then\nt\nX\n\nk=1\n\nkmk\u22121 k2V \u22121 \u2264 2 log\nk\u22121\n\ndet(V t )\n.\ndet(V )\n\nProof. Elementary algebra gives\n\u22121/2\n\n\u22121/2\n\n\u22a4\ndet(V t ) = det(V t\u22121 + mt\u22121 m\u22a4\nt\u22121 ) = det(V t\u22121 ) det(I + V t\u22121 mt\u22121 (V t\u22121 mt\u22121 ) )\nt \u0010\n\u0011\nY\n2\n2\n1 + kmk\u22121 kV \u22121 ,\n= det(V t\u22121 ) (1 + kmt\u22121 kV \u22121 ) = det(V )\nt\u22121\n\n(9)\n\nk\u22121\n\nk=1\n\nwhere we used that all the eigenvalues of a matrix of the form I + xx\u22a4 are one except one eigenvalue,\nwhich is 1 + kxk2 and which corresponds to the eigenvector x. Using log(1 + t) \u2264 t, we can bound\nlog det(V t ) by\nt\nX\n2\nlog det(V t ) \u2264 log det V +\nkmk\u22121 kV \u22121 .\nk\u22121\n\nk=1\n\nCombining x \u2264 2 log(1 + x), which holds when x \u2208 [0, 1], and (9), we get\nt \u0010\nX\nk=1\n\nt\n\u0011\n\u0010\n\u0011\nX\n2\n2\nlog 1 + kmk\u22121 kV \u22121 = 2(log det(V t ) \u2212 log det V ).\nkmk\u22121 kV \u22121 \u2227 1 \u2264 2\nk\u22121\n\nk\u22121\n\nk=1\n\nThe trace of V t is bounded by trace(V ) + tL2 , assuming kmk k \u2264 L. Hence, det(V t ) =\n\u0010\n\u0011d\ntrace(V )+tL2\nand therefore,\nd\n\nQd\n\ni=1\n\n\u03bbi \u2264\n\nlog det(V t ) \u2264 d log((trace(V ) + tL2 )/d),\nP\nfinishing the proof of the second inequality. The sum tk=1 kmk\u22121 k2V \u22121 can itself be upper bounded\nk\u22121\n\n2\n\n2\n\nas a function of log det(V t ) provided that \u03bb0 is large enough. Notice kmk\u22121 kV \u22121 \u2264 \u03bb\u22121\nmin (V k\u22121 ) kmk\u22121 k \u2264\nk\u22121\n\nL2 /\u03bb0 . Hence, we get that if \u03bb0 \u2265 max(1, L2 ),\nt\n\ndet(V t ) X\ndet(V t )\nlog\nkmk\u22121 kV2 \u22121 \u2264 2 log\n\u2264\n.\nk\u22121\ndet V\ndet(V )\nk=1\n\nMost of this argument can be extracted from the paper of Dani et al. (2008). However, the\nidea goes back at least to Lai et al. (1979), Lai and Wei (1982) (a similar argument is used around\nTheorem 11.7 in the book by Cesa-Bianchi and Lugosi (2006)). Note that Lemmas B.9\u2013B.11 of\nPt\n2\nRusmevichientong and Tsitsiklis (2010) also give a bound on k=1 kmk\u22121 kV \u22121 , with an essentially\nk\u22121\n\nidentical argument. Alternatively, one can use the bounding technique of Auer (2003) (see the proof\nPt\n2\nof Lemma 13 there on pages 412\u2013413) to derive a bound like k=1 kmk\u22121 kV \u22121 \u2264 Cd log t for a\nk\u22121\nsuitable chosen constant C > 0.\n5\n\n\fRemark 5. By combining Corollary 1 and Lemma 4, we get a simple worst case bound that holds\nwith probability 1 \u2212 \u03b4:\n\u0013\n\u0012\ntrace(V ) + tL2\n2\n2\n\u2200t \u2265 0, kSt kV \u22121 \u2264 d R log\n.\n(10)\nt\nd\u03b4\n\nStill, the new bound is considerably better than the previous one given by Theorem 2. Note that the\nlog(t) factor cannot be removed, as shown by Problem 3, page 203 in the book by de la Pe\u00f1a et al.\n(2009).\n\n3\n\nOptional Skipping\n\nConsider the case when d = 1, mk = \u03b5k \u2208 {0, 1}, i.e., the case of an optional skipping process. Then,\nPt\ndef\nusing again V = I = 1, V t = 1 + k=1 \u03b5k\u22121 = 1 + Nt and thus the expression studied becomes\nPt\n| k=1 \u03b5k\u22121 \u03b7k |\n\u221a\n.\nkSt kV \u22121 =\nt\n1 + Nt\nWe also have\n\nlog det(V t ) =\n\nt\nX\n\nk=1\n\n\u0012\n\n\u03b5k\u22121\nlog 1 +\n1 + Nk\n\n\u0013\n\nThus, we get, with probability 1 \u2212 \u03b4\n\u2200s \u2265 0,\n\ns\nX\n\nk=1\n\nZ Nt +1\nt\nN\nt +1\nX\nX\n\u03b5k\u22121\n1\n\u2264\n=\n\u2264 1+\nx\u22121 dx = 1 + log(1 + Nt ).\n1 + Nk\nk\n1\nk=1\n\n\u03b5k\u22121 \u03b7k \u2264\n\nk=1\n\ns\n\n(1 + Ns )\n\n\u0013\u0013\n\u0012\n\u0012\n(1 + Ns )1/2\n.\n1 + 2 log\n\u03b4\n\n(11)\n\nIf we apply Doob's optional skipping and Hoeffding-Azuma, with a union bound (see, e.g., the paper\nof Bubeck et al. (2008)), we would get, for any 0 < \u03b4 < 1, t \u2265 2, with probability 1 \u2212 \u03b4,\ns\n\u0012 \u0013\ns\nX\n2t\n\u2200s \u2208 {0, . . . , t},\n\u03b5k\u22121 \u03b7k \u2264 2Ns log\n.\n(12)\n\u03b4\nk=1\n\nThe major difference between these bounds is that (12) depends explicitly on t, while (11) does\nnot. This has the positive effect that one need not recompute the bound if Nt does not grow, which\nhelps e.g. in the paper of Bubeck et al. (2008) to improve the computational complexity of the HOO\nalgorithm. Also, the coefficient of the leading term in (11) under the square root is 1, whereas in (12)\nit is 2.\nInstead of a union bound, it is possible to use a \"peeling device\" to replace the conservative\nlog t factor in the above bound by essentially log log t. This is done e.g. in Garivier and Moulines\n(2008) in their Theorem 22.2 From their derivations, the following one sided, uniform bound can be\nextracted (see Remark 24, page 19): For any 0 < \u03b4 < 1, t \u2265 2, with probability 1 \u2212 \u03b4,\ns\n\u0013\n\u0012\ns\nX\n6 log t\n4 Ns\n\u2200s \u2208 {0, . . . , t},\n\u03b5k\u22121 \u03b7k \u2264\n.\n(13)\nlog\n1.99\n\u03b4\nk=1\n\nAs noted by Garivier and Moulines (2008), due to the law of iterated logarithm, the scaling of the\nright-hand side as a function of t cannot be improved in the worst-case. However, this leaves open\nthe possibility of deriving a maximal inequality which depends on t only through Nt .\n\n4\n\nThe Multi-Armed Bandit Problem\n\nNow we turn our attention to the multi-armed bandit problem. Let \u03bci denote the expected reward\nof action i and \u2206i = \u03bc\u2217 \u2212 \u03bci , where \u03bc\u2217 is the expected reward of the optimal action. We assume\nthat if we choose action It in round t, we obtain reward \u03bcIt + \u03b7t . Let Ni,t denote the number of\ntimes that we have played action i up to time t, and X\u0304i,t denote the average of the rewards received\nby action i up to time t. From (11) with \u03b4/K instead of \u03b4 and a union bound over the actions, we\nhave the following confidence intervals that hold with probability at least 1 \u2212 \u03b4:\n\u2200i \u2208 {1, . . . , K}, \u2200s \u2208 {1, 2, . . . },\n\n2\n\nX\u0304i,s \u2212 \u03bci \u2264 ci,s ,\n\n(14)\n\nThey give their theorem as ratios, which they should not, since their inequality then fails to hold for\nNt = 0. However, this is easy to remedy by reformulating their result as we do it here.\n\n6\n\n\fwhere\nci,s =\n\ns\n\n1 + Ni,s\n2\nNi,s\n\n\u0013\u0013\n\u0012\n\u0012\nK(1 + Ni,s )1/2\n.\n1 + 2 log\n\u03b4\n\nModify the UCB Algorithm of Auer et al. (2002) to use the confidence intervals (14) and change the\naction selection rule accordingly. Hence, at time t, we choose the action\nIt = argmax X\u0304i,t + ci,t .\n\n(15)\n\ni\n\nWe call this algorithm UCB(\u03b4).\nTheorem 6. With probability at least 1 \u2212 \u03b4, the total regret of the UCB(\u03b4) algorithm with the action\nselection rule (15) is constant and is bounded by\n\u0013\nX \u0012\n16\n2K\nR(T ) \u2264\n3\u2206i +\n.\nlog\n\u2206i\n\u2206i \u03b4\ni:\u2206i >0\n\nwhere i\u2217 is the index of the optimal action.\nProof. Suppose the confidence intervals do not fail. If we play action i, the upper estimate of the\naction is above \u03bc\u2217 . Hence,\n\u2206i\n.\nci,s \u2265\n2\nSubstituting ci,s and squaring gives\n\u0013\n\u0012\n2\n2\nNi,s\nNi,s\n\u22121\nK(1 + Ni,s )1/2\n4\n.\n\u2264\n\u2264 2 1 + 2 log\nNi,s + 1\nNi,s + 1\n\u2206i\n\u03b4\nBy using Lemma 8 of Antos et al. (2010), we get that\nNi,s \u2264 3 +\nThus, using R(T ) =\nbounded by\n\nP\n\ni6=i\u2217\n\n16\n2K\nlog\n.\n2\n\u2206i\n\u2206i \u03b4\n\n\u2206i Ni,T , we get that with probability at least 1 \u2212 \u03b4, the total regret is\nR(T ) \u2264\n\n\u0013\nX \u0012\n2K\n16\n.\nlog\n3\u2206i +\n\u2206i\n\u2206i \u03b4\n\ni:\u2206i >0\n\nRemark 7. Lai and Robbins (1985) prove that for any suboptimal arm j,\nE [Ni,t ] \u2265\n\nlog t\n,\nD(pj , p\u2217 )\n\nwhere, p\u2217 and pj are the reward density of the optimal arm and arm j respectively, and D is the\nKD-divergence. This lower bound does not contradict Theorem 6, as Theorem 6 only states a high\nprobability upper bound for the regret. Note that UCB(\u03b4) takes delta as its input. Because with\nprobability \u03b4, the regret in time t can be t, on expectation, the algorithm might have a regret of t\u03b4.\nNow if we select \u03b4 = 1/t, then we get O(log t) upper bound on the expected regret.\n\n5\n\nApplication to Least Squares Estimation and Linear Bandit Problem\n\nIn this section we first apply Theorem 3 to derive confidence intervals for least-squares estimation,\nwhere the covariate process is an arbitrary process and then use these confidence intervals to improve\nthe regret bound of Dani et al. (2008) for the linear bandit problem. In particular, our assumption\non the data is as follows:\nAssumption A1 Let (Fi ) be a filtration, (x1 , y1 ), . . ., (xt , yt ) be a sequence of random variables\nover Rd \u00d7 R such that xi is Fi -measurable, and yi is Fi+1 -measurable (i = 1, 2, . . .). Assume that\n\u22a4\nthere exists \u03b8\u2217 \u2208 Rd such that E [yi |Fi ] = x\u22a4\ni \u03b8\u2217 , i.e., \u03b5i = yi \u2212 xi \u03b8\u2217 is a martingale difference\nsequence (E [\u03b5i |Fi ] = 0, i = 1, 2, . . .) and that \u03b5i is sub-Gaussian: There exists R > 0 such that for\nany \u03b3 \u2208 R,\nE [exp(\u03b3\u03b5i )|Fi\u22121 ] \u2264 exp(\u03b3 2 R2 /2).\n7\n\n\fWe shall call the random variables xi covariates and the random variables yi the responses. Note\nthat the assumption allows any sequential generation of the covariates.\nLet \u03b8\u0302t be the l2 -regularized least-squares estimate of \u03b8\u2217 with regularization parameter \u03bb > 0:\n\u03b8\u0302t = (X \u22a4 X + \u03bbI)\u22121 X \u22a4 Y,\n\n\u03b8\u03020 = 0,\n\n(16)\n\n\u22a4\nx\u22a4\n1 , . . . , xt\u22121\n\n\u22a4\n\nwhere X is the matrix whose rows are\nand Y = (y1 , . . . , yt\u22121 ) . We further let \u03b5 =\n\u22a4\n(\u03b51 , . . . , \u03b5t\u22121 ) .\nWe are interested in deriving a confidence bound on the error of predicting the mean response\nx\u22a4 \u03b8\u2217 at an arbitrarily chosen random covariate x using the least-squares predictor x\u22a4 \u03b8\u0302t . Using\n\u03b8\u0302t\n\n=\n\n(X \u22a4 X + \u03bbI)\u22121 X \u22a4 (X\u03b8\u2217 + \u03b5)\n\n=\n\n(X \u22a4 X + \u03bbI)\u22121 X \u22a4 \u03b5 + (X \u22a4 X + \u03bbI)\u22121 (X \u22a4 X + \u03bbI)\u03b8\u2217 \u2212 \u03bb(X \u22a4 X + \u03bbI)\u22121 \u03b8\u2217\n\n=\n\n(X \u22a4 X + \u03bbI)\u22121 X \u22a4 \u03b5 + \u03b8\u2217 \u2212 \u03bb(X \u22a4 X + \u03bbI)\u22121 \u03b8\u2217 ,\n\nwe get\nx\u22a4 \u03b8\u0302t \u2212 x\u22a4 \u03b8\u2217 = x\u22a4 (X \u22a4 X + \u03bbI)\u22121 X \u22a4 \u03b5 \u2212 \u03bbx\u22a4 (X \u22a4 X + \u03bbI)\u22121 \u03b8\u2217\n= hx, X \u22a4 \u03b5iV \u22121 \u2212 \u03bbhx, \u03b8\u2217 iV \u22121 ,\nt\n\nt\n\nwhere Vt = X X + \u03bbI. Note that Vt is positive definite (thanks to \u03bb > 0) and hence so is Vt\u22121 , so\nthe above inner product is well-defined. Using the Cauchy-Schwartz inequality, we get\n\u0010\n\u0011\n|x\u22a4 \u03b8\u0302t \u2212 x\u22a4 \u03b8\u2217 | \u2264 kxkV \u22121 X \u22a4 \u03b5 V \u22121 + \u03bb k\u03b8\u2217 kV \u22121\nt\nt\nt\n\u0010\n\u0011\n\u2264 kxkV \u22121 X \u22a4 \u03b5 V \u22121 + \u03bb1/2 k\u03b8\u2217 k ,\n\u22a4\n\nt\n\n2\nk\u03b8\u2217 kV \u22121\nt\n\nt\n\n2\n\n2\n\nwhere we used that\n\u2264 1/\u03bbmin(Vt ) k\u03b8\u2217 k \u2264 1/\u03bb k\u03b8\u2217 k . Fix any 0 < \u03b4 < 1. By Corollary 1,\nwith probability at least 1 \u2212 \u03b4,\ns\n\u0013\n\u0012\ndet(Vt )1/2 det(\u03bbI)\u22121/2\n\u22a4\n.\n\u2200t \u2265 1,\nX \u03b5 V \u22121 \u2264 R 2 log\nt\n\u03b4\n\nTherefore, on the event where this inequality holds, one also has\ns\n!\n\u0012\n\u0013\ndet(Vt )1/2 det(\u03bbI)\u22121/2\n\u22a4\n\u22a4\n1/2\n|x \u03b8\u0302t \u2212 x \u03b8\u2217 | \u2264 kxkV \u22121 R 2 log\n+\u03bb\nk\u03b8\u2217 k .\nt\n\u03b4\nSimilarly, we can derive a worst-case bound. The result is summarized in the following statement:\nTheorem 8. Let (x1 , y1 ), . . . , (xt\u22121 , yt\u22121 ), xi \u2208 Rd , yi \u2208 R satisfy the linear model Assumption A1\nwith some R > 0, \u03b8\u2217 \u2208 Rd and let (Ft ) be the associated filtration. Assume that w.p.1 the covariates\nsatisfy kxi k \u2264 L, i = 1, . . . , n and k\u03b8\u2217 k \u2264 S. Consider the l2 -regularized least-squares parameter\nestimate \u03b8\u0302n with regularization coefficient \u03bb > 0 (cf. (16)). Let x be an arbitary, Rd -valued random\nP\n\u22a4\nvariable. Let Vt = \u03bbI + t\u22121\ni=1 xi xi be the regularized design matrix underlying the covariates. Then,\nfor any 0 < \u03b4 < 1, with probability at least 1 \u2212 \u03b4,\ns\n!\n\u0012\n\u0013\ndet(Vt )1/2 det(\u03bbI)\u22121/2\n\u22a4\n\u22a4\n1/2\n\u2200t \u2265 1, |x \u03b8\u0302t \u2212 x \u03b8\u2217 | \u2264 kxkV \u22121 R 2 log\n+\u03bb S .\n(17)\nt\n\u03b4\nSimilarly, with probability 1 \u2212 \u03b4,\n\u2200t \u2265 1,\n\n\uf8eb v\nu\nu\n\u22a4\n\u22a4\n\uf8ed\n|x \u03b8\u0302t \u2212 x \u03b8\u2217 | \u2264 kxkV \u22121 Rtd log\nt\n\n1 + tL\n\u03bb\n\u03b4\n\n!\n\n\uf8f6\n\n+ \u03bb1/2 S \uf8f8 .\n\n(18)\n\nRemark 9. We see that \u03bb \u2192 \u221e increases the second term (the \"bias term\") in the parenthesis of\nthe estimate. In fact, \u03bb \u2192 \u221e for n fixed gives \u03bb1/2 kxkV \u22121 \u2192 const (as it should be). Decreasing \u03bb,\nt\n\non the other hand increases kxkV \u22121 and the log term, while it decreases the bias term \u03bb1/2 S.\nt\n\nFrom the above result, we immediately obtain confidence bounds for \u03b8\u2217 :\n8\n\n\fCorollary 10. Under the condition of Theorem 8, with probability at least 1 \u2212 \u03b4,\ns\n\u0012\n\u0013\ndet(Vt )1/2 det(\u03bbI)\u22121/2\n\u2200t \u2265 1,\n\u03b8\u0302t \u2212 \u03b8\u2217\n\u2264 R 2 log\n+ \u03bb1/2 S.\n\u03b4\nVt\nAlso, with probability at least 1 \u2212 \u03b4,\n\u2200t \u2265 1,\n\n\u03b8\u0302t \u2212 \u03b8\u2217\n\nVt\n\nv\nu\nu\n\u2264 Rtd log\n\n1 + tL\n\u03bb\n\u03b4\n\n!\n\n+ \u03bb1/2 S.\n\nProof. Plugging in x = Vt (\u03b8\u0302t \u2212 \u03b8\u2217 ) into (17), we get\ns\n!\n\u0013\n\u0012\n2\ndet(Vt )1/2 det(\u03bbI)\u22121/2\n\u2264 Vt (\u03b8\u0302t \u2212 \u03b8\u2217 ) \u22121 R 2 log\n\u03b8\u0302t \u2212 \u03b8\u2217\n+ \u03bb1/2 S .\n\u03b4\nVt\nVt\nNow, Vt (\u03b8\u0302t \u2212 \u03b8\u2217 )\n\n2\nVt\u22121\n\n= \u03b8\u0302t \u2212 \u03b8\u2217\n\n2\nVt\n\nand therefore either \u03b8\u0302t \u2212 \u03b8\u2217\n\nclusion holds, or we can divide both sides of (19) by \u03b8\u0302t \u2212 \u03b8\u2217\n\nVt\n\nVt\n\n(19)\n\n= 0, in which case the con-\n\nto obtain the desired result.\n\nRemark 11. In fact, the theorem and the corollary are equivalent. To see this note that x\u22a4 (\u03b8\u0302t \u2212\u03b8\u2217 ) =\n1/2 \u22121/2\n(\u03b8\u0302t \u2212 \u03b8\u2217 )\u22a4 Vt Vt\nx, thus\n|x\u22a4 (\u03b8\u0302t \u2212 \u03b8\u2217 )|\nsup\n.\n= \u03b8\u0302t \u2212 \u03b8\u2217\nkxkV \u22121\nVt\nx6=0\nt\n\nRemark 12. The above bound could be compared with a similar bound of Dani et al. (2008) whose\nbound, under identical conditions, states that (with appropriate initialization) with probability 1\u2212\u03b4,\n(s\n\u0012 2\u0013\n\u0012 2 \u0013)\nt\n8\nt\n128 d log(t) log\n, log\n, (20)\n\u2264 R max\nfor all t large enough,\n\u03b8\u0302t \u2212 \u03b8\u2217\n\u03b4\n3\n\u03b4\nVt\np\nwhere large enough means that t satisfies 0 < \u03b4 < t2 e\u22121/16 . Denote by \u03b2t (\u03b4) the right-hand side\nin the above bound. The restriction on t comes from the fact that \u03b2t (\u03b4) \u2265 2d(1 + 2 log(t)) is needed\nin the proof of the last inequality of their Theorem 5.\nOn the other hand, Theorem 2 gives rise to the following result: For any fixed t \u2265 2, for any\n0 < \u03b4 < 1, with probability at least 1 \u2212 \u03b4,\np\np\n\u2264 2 \u03ba2 R log t d log(t) + log(1/\u03b4) + \u03bb1/2 S ,\n\u03b8\u0302t \u2212 \u03b8\u2217\nVt\n\nwhere \u03ba is as in Theorem 2. To get a uniform bound one can use a union bound with \u03b4t = \u03b4/t2 .\nP\n\u03c02\nThen \u221e\nt=2 \u03b4t = \u03b4( 6 \u2212 1) \u2264 \u03b4. This thus gives that for any 0 < \u03b4 < 1, with probability at least\n1 \u2212 \u03b4,\np\np\n\u2264 2 \u03ba2 R log t d log(t) + log(t2 /\u03b4) + \u03bb1/2 S ,\nfor all t \u2265 2,\n\u03b8\u0302t \u2212 \u03b8\u2217\nVt\n\nThis looks tighter than (20), but is still lagging beyond the result of Corollary 10.\n\n5.1 The Linear Bandit Problem\nWe now turn our attention to the linear bandit problem. Assume the actions lie in D \u2282 Rd and for\n2\nany x \u2208 D, kxk \u2264 L. Assume the reward of taking action x \u2208 D has the form of\nht (x) = \u03b8\u2217\u22a4 x + \u03b7t\n\nand assume \u2200x \u2208 D, \u03b8\u2217\u22a4 x \u2208 [\u22121, 1]. Define the regret by\nR(T ) =\n\nT\nX\n(\u03b8\u2217\u22a4 x\u2217 \u2212 \u03b8\u2217\u22a4 xt ),\nt=1\n\nwhere x\u2217 is the optimal action (x\u2217 = argmaxx\u2208D \u03b8\u2217\u22a4 x). Define the confidence set\nn\no\nCt (\u03b4) = \u03b8 : (\u03b8 \u2212 \u03b8\u0302t )\u22a4 Vt (\u03b8 \u2212 \u03b8\u0302t ) \u2264 \u03b2t (\u03b4) ,\n9\n\n(21)\n\n\fInput: Confidence 0 < \u03b4 < 1.\nfor t := 1, 2, . . . do\n(\u03b8\u0303t , xt ) = argmax(\u03b8,x)\u2208Ct (\u03b4)\u00d7D \u03b8\u22a4 x.\nPlay xt and observe reward ht (xt ).\nUpdate Vt and Ct .\nend for\nTable 1: The Linear Bandit Algorithm\n\nwhere\n\u03b2t (\u03b4) =\n\ns\n\nR 2 log\n\n\u0012\n\ndet(Vt )1/2 det(\u03bbI)\u22121/2\n\u03b4\n\n\u0013\n\n1/2\n\n+\u03bb\n\nS\n\n!2\n\n.\n\nConsider the ConfidenceBall algorithm of Dani et al. (2008). We use the confidence intervals (21)\nand change the action selection rule accordingly. Hence, at time t, we define \u03b8\u0303t and xt by the following\nequation:\n(\u03b8\u0303t , xt ) = argmax \u03b8\u22a4 x.\n(22)\n(\u03b8,x)\u2208Ct (\u03b4)\u00d7D\n\nThe algorithm is shown in Table 1.\nTheorem 13. With probability at least 1 \u2212 \u03b4, the regret of the Linear Bandit Algorithm shown in\nTable 1 satisfies\n\u0010\n\u0011\np\np\n\u2200T \u2265 1, R(T ) \u2264 4 T d log(\u03bb + T L/d) \u03bb1/2 S + R 2 log 1/\u03b4 + d log(1 + T L/(\u03bbd)) .\n\nProof. Lets decompose the instantaneous regret as follows:\nrt = \u03b8\u2217\u22a4 x\u2217 \u2212 \u03b8\u2217\u22a4 xt\n\u2264 \u03b8\u0303t\u22a4 xt \u2212 \u03b8\u2217\u22a4 xt\n= (\u03b8\u0303t \u2212 \u03b8\u2217 )\u22a4 xt\n\n= (\u03b8\u0302t \u2212 \u03b8\u2217 )\u22a4 xt + (\u03b8\u0303t \u2212 \u03b8\u0302t )\u22a4 xt\np\n\u2264 \u03b2t (\u03b4) kxt kV \u22121 ,\n\n(23)\n\nt\n\nwhere the last step holds by Cauchy-Schwarz. Using (23) and the fact that rt \u2264 2, we get that\np\np\nrt \u2264 2 min( \u03b2t (\u03b4) kxt k2V \u22121 , 1) \u2264 2 \u03b2t (\u03b4) min(kxt k2V \u22121 , 1).\nt\n\nt\n\nThus, with probability at least 1 \u2212 \u03b4, \u2200T \u2265 1\nv\nv\nu\nu T\nT\nu\nu X\nX\np\nt\n2\nrt \u2264 t8\u03b2T T\nmin(wt2 , 1) \u2264 4 \u03b2T T log(det(VT ))\nR(T ) \u2264 T\nt=1\n\nt=1\n\n\u0010\n\u0011\np\np\n\u2264 4 T d log(\u03bb + tL/d) \u03bb1/2 S + R 2 log 1/\u03b4 + d log(1 + tL/(\u03bbd)) .\n\nwhere the last two steps follow from Lemma 4.\n\n5.2 Saving Computation\nThe action selection rule (22) is NP-hard in general (Dani et al., 2008). In this section, we show\nthat we essentially need to solve this problem only O(log t) times up to time t and hence saving\ncomputations. Algorithm 2 achieves this objective by changing its policy only when the volume of\nthe confidence set is halved and still enjoyes almost the same regret bound as for Algorithm 1.\nTheorem 14. With probability at least 1 \u2212 \u03b4, \u2200T \u2265 1, the regret of the Linear Bandit Algorithm\nshown in Table 2 satisfies\n\u0010\n\u0011\np\np\np\nR(T ) \u2264 4 2T d log(\u03bb + T L/d) \u03bb1/2 S + R 2 log 1/\u03b4 + d log(1 + T L/(\u03bbd)) + 4 d log(T /d).\n10\n\n\fInput: Confidence 0 < \u03b4 < 1.\n\u03c4 = 1 {This is the last timestep that we changed the action}\nfor t := 1, 2, . . . do\nif det(Vt ) > 2 det(V\u03c4 ) then\n(\u03b8\u0303t , xt ) = argmax(\u03b8,x)\u2208Ct (\u03b4)\u00d7D \u03b8\u22a4 x.\n\u03c4 = t.\nend if\nxt = x\u03c4 .\nPlay xt and observe reward ht (xt ).\nend for\nTable 2: The Linear Bandit Algorithm\nFirst, we prove the following lemma:\nLemma 15. Let A, B and C be positive semi-definite matrices such that A = B + C. Then, we\nhave that\ndet(A)\nx\u22a4 Ax\n\u2264\n.\nsup \u22a4\ndet(B)\nx6=0 x Bx\nProof. We consider first a simple case. Let A = B + mm\u22a4 , B positive definite. Let x 6= 0 be an\narbitrary vector. Using the Cauchy-Schwartz inequality, we get\n(x\u22a4 m)2 = (x\u22a4 B 1/2 B \u22121/2 m)2 \u2264 B 1/2 x\n\n2\n\nB \u22121/2 m\n\n2\n\n2\n\n2\n\n= kxkB kmkB \u22121 .\n\nThus,\nx\u22a4 (B + mm\u22a4 )x \u2264 x\u22a4 Bx + kxk2B kmk2B \u22121 = (1 + kmk2B \u22121 ) kxk2B\nand so\nx\u22a4 Ax\n2\n\u2264 1 + kmkB \u22121 .\nx\u22a4 Bx\nWe also have that\n2\n\ndet(A) = det(B + mm\u22a4 ) = det(B) det(I + B \u22121/2 m(B \u22121/2 m)\u22a4 ) = det(B)(1 + kmkB \u22121 ),\nthus finishing the proof of this case.\n\u22a4\n\u22a4\n\u22a4\nIf A = B + m1 m\u22a4\n1 + * * * + mt\u22121 mt\u22121 , then define Vs = B + m1 m1 + * * * + ms\u22121 ms\u22121 and use\nx\u22a4 Ax\nx\u22a4 Vt x x\u22a4 Vt\u22121 x\nx\u22a4 V2 x\n=\n.\n.\n.\n.\nx\u22a4 Bx\nx\u22a4 Vt\u22121 x x\u22a4 Vt\u22122 x\nx\u22a4 Bx\nBy the above argument, since all the terms are positive, we get\nx\u22a4 Ax\ndet(Vt ) det(Vt\u22121 )\ndet(V2 )\ndet(Vt )\ndet(A)\n\u2264\n...\n=\n=\n.\nx\u22a4 Bx\ndet(Vt\u22121 ) det(Vt\u22122 )\ndet(B)\ndet(B)\ndet(B)\nThis finishes the proof of this case.\nNow, if C is a positive definite matrix, then the eigendecomposition of C gives C = U \u22a4 \u039bU ,\nwhere U is orthonormal and \u039b is positive diagonal matrix. This, in fact gives that C can be written\nas the sum of at most d rank-one matrices, finishing the proof for the general case.\n\nProof of Theorem 14. Let \u03c4t be the smallest timestep \u2264 t such that xt = x\u03c4t . By an argument\nsimilar to the one used in Theorem 13, we have\nrt \u2264 (\u03b8\u0302\u03c4t \u2212 \u03b8\u2217 )\u22a4 xt + (\u03b8\u0303\u03c4t \u2212 \u03b8\u0302\u03c4t )\u22a4 xt .\n11\n\n\fWe also have that for all \u03b8 \u2208 C\u03c4t and x,\n\nq\nx\u22a4 Vt\u22121 x\ns\nq\ndet(Vt )\n1/2\nx\u22a4 Vt\u22121 x\n\u2264 V\u03c4t (\u03b8 \u2212 \u03b8\u0302\u03c4t )\ndet(V\u03c4t )\nq\n\u221a\n\u2264 2 V\u03c41/2\n(\u03b8\n\u2212\n\u03b8\u0302\n)\nx\u22a4 Vt\u22121 x\n\u03c4\nt\nq\np\n\u2264 2\u03b2\u03c4t x\u22a4 Vt\u22121 x,\n1/2\n\n(\u03b8 \u2212 \u03b8\u0302\u03c4t )\u22a4 x \u2264 Vt\n\n(\u03b8 \u2212 \u03b8\u0302\u03c4 )\n\nwhere the second step follows from Lemma 15, and the third step follows from the fact that at time\nt we have det(Vt ) < 2 det(V\u03c4t ). The rest of the argument is identical to that of Theorem 13. We\nconclude that with probability at least 1 \u2212 \u03b4, \u2200T \u2265 1,\n\u0010\n\u0011\np\np\nR(T ) \u2264 4 2T d log(\u03bb + tL/d) \u03bb1/2 S + R 2 log 1/\u03b4 + d log(1 + tL/(\u03bbd)) .\n5.3 Problem Dependent Bound (\u2206 > 0)\nLet \u2206 be as defined in (Dani et al., 2008). In this section we assume that \u2206 > 0. This includes the case when the action set is a polytope. First we state a matrix perturbation theorem\nfrom Stewart and Sun (1990) that will be used later.\nTheorem 16 (Stewart and Sun (1990), Corollary 4.9). Let A be a symmetric matrix with eigenvalues \u03bd1 \u2265 \u03bd2 \u2265 . . . \u2265 \u03bdd , E be a symmetric matrix with eigenvalues e1 \u2265 e2 \u2265 . . . \u2265 ed , and V = A+E\ndenote a symmetric perturbation of A such that the eigenvalues of V are \u03bd\u03031 \u2265 \u03bd\u03032 \u2265 . . . \u2265 \u03bd\u0303d . Then,\nfor i = 1, . . . , d,\n\u03bd\u0303i \u2208 [\u03bdi + ed , \u03bdi + e1 ].\nTheorem 17. Assume that \u2206 > 0 for the gap \u2206 defined in (Dani et al., 2008). Further assume\nthat \u03bb \u2265 1 and S \u2265 1. With probability at least 1 \u2212 \u03b4, \u2200T \u2265 1, the regret of the algorithm shown in\nTable 1 satisfies\n\u0012\n\u0012\n\u0013\n\u00132\n16R2 \u03bbS 2\n64R2 \u03bbS 2 L\nd\u03bb + T L2\nR(T ) =\nlog(LT ) + (d \u2212 1) log\n+\n2(d\n\u2212\n1)\nlog\nd\nlog\n+\n2\nlog(1/\u03b4)\n+\n2\nlog(1/\u03b4)\n.\n\u2206\n\u22062\nd\nProof. First we bound the regret in terms of log det(VT ). We have that\nR(T ) =\n\nT\nX\nt=1\n\nrt \u2264\n\nT\nX\nr2\nt\n\nt=1\n\n\u2206\n\n\u2264\n\n16\u03b2T\nlog(det(VT )),\n\u2206\n\n(24)\n\nwhere the first inequality follows from the fact that either rt = 0 or \u2206 < rt , and the second inequality\ncan be extracted from the proof of Theorem 13. Let bt be the number of times we have played a suboptimal action (an action xs for which \u03b8\u2217\u22a4 x\u2217 \u2212 \u03b8\u2217\u22a4 xs \u2265 \u2206) up to time t. Next we bound log det(Vt )\nin terms of bt .P\nWe bound the eigenvalues of Vt by using Theorem 16.\nt\n\u22a4\nLet Et = s:xs 6=x\u2217 xs x\u22a4\ns and At = Vt \u2212 Et = (t \u2212 bt )x\u2217 x\u2217 . The only non-zero eigenvalue of\n\u2217\n\u2217\n\u22a4\n(t \u2212 bt )x\u2217 x\u22a4\n\u2217 is (t \u2212 bt )L , where L = x\u2217 x\u2217 \u2264 L. Let the eigenvalues of Vt and Et be \u03bb1 \u2265 * * * \u2265 \u03bbd\nand e1 \u2265 * * * \u2265 ed respectively. By Theorem 16, we have that\nThus,\n\n\u03bb1 \u2208 [(t \u2212 bt )L\u2217 + ed , (t \u2212 bt )L\u2217 + e1 ] and \u2200i \u2208 {2, . . . , d}, \u03bbi \u2208 [ed , e1 ].\ndet(Vt ) =\n\nd\nY\ni\n\nTherefore,\nBecause trace(E) =\n\nPt\n\n\u03bbi \u2264 ((t \u2212 bt )L\u2217 + e1 )ed\u22121\n\u2264 ((t \u2212 bt )L + e1 )ed\u22121\n.\n1\n1\n\nlog det(Vt ) \u2264 log((t \u2212 bt )L + e1 ) + (d \u2212 1) log e1 .\n\ns:xs 6=x\u2217\n\ntrace(xs x\u22a4\ns ) \u2264 Lbt , we conclude that e1 \u2264 Lbt . Thus,\n\nlog det(Vt ) \u2264 log((t \u2212 bt )L + Lbt ) + (d \u2212 1) log(Lbt )\n= log(Lt) + (d \u2212 1) log(Lbt ).\n12\n\n(25)\n\n\fWith some calculations, we can show that\n\u0012\n\u00132\nd\u03bb + tL2\n1\n\u03b2t log det Vt \u2264 4R2 \u03bbS 2 (2 log(1/\u03b4) + log det Vt )2 \u2264 4R2 \u03bbS 2 d log\n+ 2 log\n,\n(26)\nd\n\u03b4\nwhere the second inequality follows from Lemma 4. Hence,\n\u00132\n\u0012\nd\u03bb + tL2\n64R2 \u03bbS 2\n1\n16\u03b2t\nd\nlog\nlog(det(V\n))\n\u2264\n+\n2\nlog\n,\n(27)\nbt \u2264\nt\n\u22062\n\u22062\nd\n\u03b4\nwhere the first inequality follows from R(t) \u2265 bt \u2206. Thus, with probability 1 \u2212 \u03b4, \u2200T \u2265 1,\n16\u03b2T\nlog(det(VT ))\nR(T ) \u2264\n\u2206\n2\n64R \u03bbS 2\n\u2264\n(log(det(VT )) + 2 log(1/\u03b4))2\n\u2206\n16R2 \u03bbS 2\n(log(LT ) + (d \u2212 1) log(LbT ) + 2 log(1/\u03b4))2\n\u2264\n\u2206\n\u0012\n\u0012\n\u0013\n\u00132\n16R2 \u03bbS 2\n64R2 \u03bbS 2 L\nd\u03bb + T L2\n\u2264\nlog(LT ) + (d \u2212 1) log\n+\n2(d\n\u2212\n1)\nlog\nd\nlog\n+\n2\nlog(1/\u03b4)\n+\n2\nlog(1/\u03b4)\n,\n\u2206\n\u22062\nd\nwhere the first step follows from (24), the second step follows from the first inequality in (26), the\nthird step follows from (25), and the last step follows from the second inequality in (27).\n2\n\nRemark 18. The problem dependent regret of (Dani et al., 2008) scales like O( d\u2206 log3 T ), while our\n1\nbound scales like O( \u2206\n(log2 T + d log T + d2 log log T )).\n\nReferences\nA. Antos, V. Grover, and Cs. Szepesv\u00e1ri. Active learning in heteroscedastic noise. Theoretical\nComputer Science, 411(29-30):2712\u20132728, 2010.\nP. Auer, N. Cesa-Bianchi, and P. Fischer. Finite time analysis of the multiarmed bandit problem.\nMachine Learning, 47(2-3):235\u2013256, 2002.\nPeter Auer. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine\nLearning Research, 3:397\u2013422, 2003. ISSN 1533-7928.\nS. Bubeck, R. Munos, G. Stoltz, and Cs. Szepesv\u00e1ri. Online optimization in X-armed bandits.\nIn D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, NIPS-21, pages 201\u2013208. MIT\nPress, 2008.\nN. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press,\nNew York, NY, USA, 2006.\nV. Dani, T.P. Hayes, and S.M. Kakade. Stochastic linear optimization under bandit feedback.\nCOLT-2008, pages 355\u2013366, 2008.\nV.H. de la Pe\u00f1a, M.J. Klass, and T.L. Lai. Self-normalized processes: exponential inequalities,\nmoment bounds and iterated logarithm laws. Annals of Probability, 32(3):1902\u20131933, 2004.\nV.H. de la Pe\u00f1a, T.L. Lai, and Q.-M. Shao. Self-normalized processes: Limit theory and Statistical Applications. Springer, 2009.\nD.A. Freedman. On tail probabilities for martingales. The Annals of Probability, 3(1):100\u2013118,\n1975.\nA Garivier and E Moulines. On upper-confidence bound policies for non-stationary bandit\nproblems. Technical report, LTCI, Dec 2008. URL http://arxiv.org/pdf/0805.3415.\nT. L. Lai and H. Robbins. Asymptotically efficient adaptive allocation rules. Advances in\nApplied Mathematics, 6:4\u201322, 1985.\nT.L. Lai and C.Z. Wei. Least squares estimates in stochastic regression models with applications\nto identification and control of dynamic systems. The Annals of Statistics, 10(1):154\u2013166, 1982.\nT.L. Lai, H. Robbins, and C.Z. Wei. Strong consistency of least squares estimates in multiple\nregression. Proceedings of the National Academy of Sciences, 75(7):3034\u20133036, 1979.\nH. Robbins. Some aspects of the sequential design of experiments. Bulletin of the American\nMathematical Society, 58:527\u2013535, 1952.\nH. Robbins and D. Siegmund. Boundary crossing probabilities for the Wiener process and\nsample sums. Annals of Math. Statistics, 41:1410\u20131429, 1970.\nP. Rusmevichientong and J.N. Tsitsiklis. Linearly parameterized bandits. Mathematics of\nOperations Research, 35(2):395\u2013411, 2010.\nG.W. Stewart and Ji-guang Sun. Matrix Perturbation Theory. Academic Press, 1990.\n13\n\n\f"}