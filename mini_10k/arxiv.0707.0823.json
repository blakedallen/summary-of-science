{"id": "http://arxiv.org/abs/0707.0823v1", "guidislink": true, "updated": "2007-07-05T16:12:32Z", "updated_parsed": [2007, 7, 5, 16, 12, 32, 3, 186, 0], "published": "2007-07-05T16:12:32Z", "published_parsed": [2007, 7, 5, 16, 12, 32, 3, 186, 0], "title": "A Statistical Theory for the Analysis of Uncertain Systems", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0707.4068%2C0707.4601%2C0707.3868%2C0707.4329%2C0707.0161%2C0707.1788%2C0707.2789%2C0707.4140%2C0707.1362%2C0707.0941%2C0707.1212%2C0707.1527%2C0707.3799%2C0707.2958%2C0707.3146%2C0707.2221%2C0707.4625%2C0707.4132%2C0707.4319%2C0707.1391%2C0707.3013%2C0707.1306%2C0707.0823%2C0707.3282%2C0707.2049%2C0707.2084%2C0707.4462%2C0707.1822%2C0707.2720%2C0707.3592%2C0707.1038%2C0707.0129%2C0707.0995%2C0707.0930%2C0707.3244%2C0707.1367%2C0707.3139%2C0707.2892%2C0707.0322%2C0707.3278%2C0707.4468%2C0707.0833%2C0707.3622%2C0707.4074%2C0707.2405%2C0707.0550%2C0707.2685%2C0707.3903%2C0707.0388%2C0707.1474%2C0707.2092%2C0707.3340%2C0707.4257%2C0707.1312%2C0707.0839%2C0707.2358%2C0707.0452%2C0707.2845%2C0707.4316%2C0707.0286%2C0707.0291%2C0707.3827%2C0707.1071%2C0707.0960%2C0707.3725%2C0707.3483%2C0707.0238%2C0707.0362%2C0707.0993%2C0707.0747%2C0707.3385%2C0707.0714%2C0707.0389%2C0707.0799%2C0707.1342%2C0707.4046%2C0707.0174%2C0707.0138%2C0707.2672%2C0707.1295%2C0707.4460%2C0707.0521%2C0707.0657%2C0707.2569%2C0707.0587%2C0707.0505%2C0707.1827%2C0707.3288%2C0707.0999%2C0707.0311%2C0707.3157%2C0707.0540%2C0707.4088%2C0707.1734%2C0707.3421%2C0707.1729%2C0707.2409%2C0707.0280%2C0707.2397%2C0707.0861%2C0707.2215&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A Statistical Theory for the Analysis of Uncertain Systems"}, "summary": "This paper addresses the issues of conservativeness and computational\ncomplexity of probabilistic robustness analysis. We solve both issues by\ndefining a new sampling strategy and robustness measure. The new measure is\nshown to be much less conservative than the existing one. The new sampling\nstrategy enables the definition of efficient hierarchical sample reuse\nalgorithms that reduce significantly the computational complexity and make it\nindependent of the dimension of the uncertainty space. Moreover, we show that\nthere exists a one to one correspondence between the new and the existing\nrobustness measures and provide a computationally simple algorithm to derive\none from the other.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0707.4068%2C0707.4601%2C0707.3868%2C0707.4329%2C0707.0161%2C0707.1788%2C0707.2789%2C0707.4140%2C0707.1362%2C0707.0941%2C0707.1212%2C0707.1527%2C0707.3799%2C0707.2958%2C0707.3146%2C0707.2221%2C0707.4625%2C0707.4132%2C0707.4319%2C0707.1391%2C0707.3013%2C0707.1306%2C0707.0823%2C0707.3282%2C0707.2049%2C0707.2084%2C0707.4462%2C0707.1822%2C0707.2720%2C0707.3592%2C0707.1038%2C0707.0129%2C0707.0995%2C0707.0930%2C0707.3244%2C0707.1367%2C0707.3139%2C0707.2892%2C0707.0322%2C0707.3278%2C0707.4468%2C0707.0833%2C0707.3622%2C0707.4074%2C0707.2405%2C0707.0550%2C0707.2685%2C0707.3903%2C0707.0388%2C0707.1474%2C0707.2092%2C0707.3340%2C0707.4257%2C0707.1312%2C0707.0839%2C0707.2358%2C0707.0452%2C0707.2845%2C0707.4316%2C0707.0286%2C0707.0291%2C0707.3827%2C0707.1071%2C0707.0960%2C0707.3725%2C0707.3483%2C0707.0238%2C0707.0362%2C0707.0993%2C0707.0747%2C0707.3385%2C0707.0714%2C0707.0389%2C0707.0799%2C0707.1342%2C0707.4046%2C0707.0174%2C0707.0138%2C0707.2672%2C0707.1295%2C0707.4460%2C0707.0521%2C0707.0657%2C0707.2569%2C0707.0587%2C0707.0505%2C0707.1827%2C0707.3288%2C0707.0999%2C0707.0311%2C0707.3157%2C0707.0540%2C0707.4088%2C0707.1734%2C0707.3421%2C0707.1729%2C0707.2409%2C0707.0280%2C0707.2397%2C0707.0861%2C0707.2215&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This paper addresses the issues of conservativeness and computational\ncomplexity of probabilistic robustness analysis. We solve both issues by\ndefining a new sampling strategy and robustness measure. The new measure is\nshown to be much less conservative than the existing one. The new sampling\nstrategy enables the definition of efficient hierarchical sample reuse\nalgorithms that reduce significantly the computational complexity and make it\nindependent of the dimension of the uncertainty space. Moreover, we show that\nthere exists a one to one correspondence between the new and the existing\nrobustness measures and provide a computationally simple algorithm to derive\none from the other."}, "authors": ["Xinjia Chen", "Kemin Zhou", "Jorge L. Aravena"], "author_detail": {"name": "Jorge L. Aravena"}, "author": "Jorge L. Aravena", "arxiv_comment": "32 pages, 15 figures", "links": [{"href": "http://arxiv.org/abs/0707.0823v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0707.0823v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "stat.AP", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "stat.AP", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.DS", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0707.0823v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0707.0823v1", "journal_reference": "Proceeding of Joint Meeting of Statistics, pp. 1656--1663, Salt\n  Lake City, 2007", "doi": null, "fulltext": "A STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\narXiv:0707.0823v1 [stat.AP] 5 Jul 2007\n\nAbstract. This paper addresses the issues of conservativeness and computational complexity of probabilistic robustness analysis. We solve both issues by defining a new sampling strategy and robustness\nmeasure. The new measure is shown to be much less conservative than the existing one. The new sampling\nstrategy enables the definition of efficient hierarchical sample reuse algorithms that reduce significantly\nthe computational complexity and make it independent of the dimension of the uncertainty space. Moreover, we show that there exists a one to one correspondence between the new and the existing robustness\nmeasures and provide a computationally simple algorithm to derive one from the other.\n\n1. Introduction\nRobustness analysis is used to predict if a system will perform satisfactorily in the presence of uncertainties. It is generally accepted as an essential step in the design of high-performance control systems.\nIn practice, the analysis has to be very efficient because it has to use models as realistic as possible and,\nusually, it takes many cycles of analysis-design to come up with a satisfactory controller. The outcome of\nthe robustness analysis should allow the designer not only to evaluate the robust performance of a controller, but also to compare various controllers in order to obtain the best control strategy. Needless to\nsay, unnecessary conservativeness prevents a realistic analysis.\nAimed at overcoming the computational complexity and conservatism of the classical deterministic worstcast approach, there are growing interests in developing probabilistic methods and randomized algorithms\n(see, [1]-[6], [11]-[15] and the references therein). Specially, a probabilistic robustness measure, referred to\nas the confidence degradation function or robustness function is proposed in [3]. Such robustness measure\nhas been demonstrated to be much superior than the classical deterministic robustness margin in terms of\nconservatism, computational complexity and generality of application.\nThe computation of the robustness function using Monte Carlo simulations requires uniform sampling\nfrom bounding sets in the uncertainty space, which can reach high dimensions very quickly; for example if\nthe uncertainty is modelled by a 5 \u00d7 5 complex-valued matrix then the dimension of the uncertainty space\nis 50. We will show here that such sampling suffers from what we term surface effect and may introduce\nundue conservativeness in the evaluation of system robustness. We address this conservativeness with a\nnew sampling technique and a new probabilistic robustness measure that is significantly less conservative.\nMoreover, with a suitable computing structure it can be evaluated for arbitrarily dense gridding of uncertainty radius with a computational complexity that is very low and is independent of the dimension of\nuncertainty.\nWe shall use the following notation throughout this paper. The uncertainty is denoted as boldface \u2206 and\nits realization is denoted as \u2206. The probability density function of \u2206 is denoted as f\u2206 . We measure the\nDate: March 2007.\nKey words and phrases. Robustness analysis, risk analysis, randomized algorithms, uncertain system, computational\ncomplexity.\nThis research was supported in part by grants from NASA (NCC5-573), LEQSF (NASA /LEQSF(2001-04)-01), the NNSFC\nYoung Investigator Award for Overseas Collaborative Research (60328304) and a NNSFC grant (10377004).\n1\n\n\f2\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\nsize of uncertainty by a function ||.|| which has the scalable property that ||\u03c1\u2206|| = \u03c1||\u2206|| for any uncertainty\ninstance \u2206 and any \u03c1 > 0. Obviously, the most frequently used H\u221e or lp norm of uncertainty possesses\nsuch scalable property. The uncertainty bounding set of radius r is denoted as Br = {\u2206 : ||\u2206|| \u2264 r}. We\nuse \u2202Br to denote {\u2206 : ||\u2206|| = r}. Specially, B denotes {\u2206 : ||\u2206|| \u2264 1} and \u2202B denotes {\u2206 : ||\u2206|| = 1}.\nFor a subset Sr of \u2202Br , its \"area\" is defined as\nR\ndq\nq\u2208{ r\u03c1 \u2206: r\u2212\u03b51 \u2264\u03c1\u2264r+\u03b52 , \u2206\u2208Sr }\n(1.1)\narea(Sr ) = lim\n\u03b51 \u21930\n\u03b51 + \u03b52\n\u03b52 \u21930\nR\nwhere \" \" denotes the multivariate Lebesgue integration and the down arrow \"\u2193\" means \"decreases to\".\nThe indicator function I(.) means that I(\u2206) = 1 if the robustness requirement is guaranteed for \u2206 and\nI(\u2206) = 0 otherwise. The probability of an event is denoted as Pr{.}. The conditional probability is denoted\nas Pr{. | .}. The set of complex number is denoted as C. The set of real matrices of size m \u00d7 p is denoted\nas Rm\u00d7p . The set of complex matrices of size m \u00d7 p is denoted as Cm\u00d7p . The real and complex parts of\na number is denoted as R(.) and I(.) respectively. The largest and the second largest singular values of\na matrix are denoted as \u03c3(.) and \u03c32 (.) respectively. The ceiling function is denoted as \u2308.\u2309 and the floor\nfunction is denoted as \u230a.\u230b.\n1.1. The Surface Effect of Uniform Sampling. In order to illustrate the surface effect, consider a\nuniform sampling extracting samples from the uncertainty set Br . Let E\u03c1 denote the event that a sample\nchosen uniformly from Br lies outside the bounding set B\u03c1 of radius \u03c1 < r. Under the assumption of\n\u0001d\nuniform distribution it is easy to see that such event will have the probability Pr{E\u03c1 } = 1 \u2212 \u03c1r where\nd is the dimension of uncertainty. As d increases this probability approaches one for all \u03c1 < r. For\nexample when \u03c1r = 0.9 and d = 50 then Pr{E\u03c1 } = 0.9948. Hence out of 1000 samples extracted\nuniformly from the bounding set of radius r one would expect that about 995 will be outside\nthe bounding set with radius \u03c1 = 0.9r. If the uncertainty is well modeled one can reasonably assume\nthat large uncertainties are less likely than small ones and we are faced with the fact that the uniform\nsampling selects cases that are not indicative of the actual situation but present a very unfavorable picture.\nIn Section 2 we discuss in detail the modeling of uncertainties and show that uniform sampling can give a\nvery conservative evaluation of system robustness. In Section 3 we introduce a new sampling technique and\na new robustness measure which overcomes the conservativeness issue. Section 4 establishes a one to one\nmapping between our measure and the existing one and considers other capabilities of the new robustness\nfunction. The detail algorithms are presented in Section 5. Section 6 addresses the issue of computational\ncomplexity for the evaluation of robustness function. In particular we show that by using a special type of\nhierarchial data structure it is possible to design computational algorithms that have a complexity that is\nindependent of the dimension of the uncertainty. The proofs of theorems are given in the Appendix.\n2. Modeling Uncertainty\nIn this section, we shall discuss the characteristics of uncertainty from the perspective of modelling\npractices.\nConsider an uncertain system shown in Figure 1. In control engineering, one usually takes into account\nall possible directional information about the uncertainty by introducing weighting matrices and absorbing\nit into the generalized plant P . Therefore, it is reasonable to assume that the uncertainty \u2206 is radially\nsymmetrical in distribution in the sense that, for any r > 0 and any Sr \u2286 {\u2206 : ||\u2206|| = r},\nPr{\u2206 \u2208 Sr | ||\u2206|| = r} =\n\narea(Sr )\narea(\u2202Br )\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n\n10\n\n3\n\n\u2206\nP\n\n5\n\nK\n0\n0\n\n5\n\n10\n\nFigure 1. Uncertain System\nif f||\u2206|| (.) is continuous at r, where the conditional probability in the left hand side is defined as\nlim\n\n\u03b51 \u21930\n\u03b52 \u21930\n\nPr {\u2206 \u2208 {\u2206 \u2208 S\u03c1 : r \u2212 \u03b51 \u2264 \u03c1 \u2264 r + \u03b52 }}\n.\nPr{r \u2212 \u03b51 \u2264 ||\u2206|| \u2264 r + \u03b52 }\n\nOn the other hand, one usually attempts to make the magnitude of modelling error, measured by ||\u2206||,\nas small as possible. Due to the effort to minimize ||\u2206|| in modelling, it is reasonable to assume that\nsmall modelling error is more likely than large modelling error. This gives rise to the rationale of treating\n||\u2206|| as a random variable such that its density, f||\u2206|| (r) = d[Pr{||\u2206||\u2264r}]\n, is non-increasing with respect to\ndr\nr. In the sequel, we shall use F to denote the family of radially symmetrical and non-increasing density\nfunction f\u2206 . It should be noted that a wider class of probability density functions, denoted by G , has been\nproposed in [3] to model uncertainty. Such family G consists of radially symmetrical density function f\u2206\nthat is non-increasing in the sense that f\u2206 (\u22061 ) \u2264 f\u2206 (\u22062 ) if ||\u22061 || \u2265 ||\u22062 ||. It can be shown that G is a\nsuperset of F , i.e., G \u2287 F (see Lemma 2 in Appendix A).\n2.1. Existing Robustness Function. The existing robustness function, proposed in [3], is given by\ndef\n\nP(r) =\n\ninf P(\u03c1)\n\n\u03c1\u2208(0,r]\n\nwith\nP(r) = Pr{I(\u2206u ) = 1}\nwhere \u2206u is uniformly distributed over Br . It has been shown in [3] that P(r) is a lower bound of the\nprobability of guaranteeing the robustness requirement if the density of uncertainty belongs to G and the\nuncertainty is bounded in Br .\nAn attracting feature of the existing robustness function is that it relies on very mild assumptions about\nuncertainty. However, as can be seen from Theorem 6.1 (in page 856) of [3], the associated computational\ncomplexity can be very high for large uncertainty dimension. Another issue of the existing measure is that\nit can be very conservative from the perspective of modelling practices. For illustration of this point, we\nconsider a conceptual example as follows.\nSuppose it is known that the norm of uncertainty \u2206 cannot exceed \u03b3. Without loss of generality, assume\n\u03b3 = 1. That is, all instances of \u2206 are included in the bounding set B = {\u2206 : ||\u2206|| < 1}. We partition\nl\n, l = 0, 1, * * * , m. From the\nB as m layers Sl = {\u2206 : rl\u22121 \u2264 ||\u2206|| < rl }, l = 1, 2, * * * , m by radii rl = m\nconsideration of modelling practices, it is reasonable to assume that the density of uncertainty \u2206 belongs\nto F . Hence, for sufficiently large m, we have Pr{\u2206 \u2208 Sl } \u2265 Pr{\u2206 \u2208 Sl+1 }, l = 1, 2, * * * , m \u2212 1. In\nreality, it is not impossible that not only the outer layers are \"bad\" and some inner layer is also \"bad\".\nSuch scenario is described as follows:\nThe robustness requirement is violated for \u2206 \u2208 Si and for \u2206 \u2208 Sl , l = j, j + 1, * * * , m where i and j are\nintegers such that 2 \u2264 i+1 < j < m. See Figure 2 for an illustration. Let d be the dimension of uncertainty\n\n\f4\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\n1\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0\n\n\u22120.2\n\n\u22120.4\n\n\u22120.6\n\n\u22120.8\n\n\u22121\n\u22121\n\n\u22120.8\n\n\u22120.6\n\n\u22120.4\n\n\u22120.2\n\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\nFigure 2. Conceptual Example (The robustness requirement is violated for red layers\nand is satisfied for green layers. Existing robustness measure tends to completely ignore\nuncertainty instances in the inner layers as d increases. Based on the existing robustness\nmeasure, a very thin bad layer may lead to an unrealistic judgement that the system has\nvery poor robustness. However, the instances in the inner layers are more probably to\noccur in reality. Hence, they should have at least equal impact on the evaluation of system\nrobustness as compared to the instances in the outer layer.)\nspace. By direct computation, we obtain the existing robustness function as P(r) = inf \u03c1\u2208[0,r] P(\u03c1) where\n\nP(\u03c1) =\n\n8\n>\n1,\n>\n>\n>\n>\n< (i\u22121)d ,\n(m\u03c1)d\n\n(m\u03c1)d \u2212id +(i\u22121)d\n>\n>\n,\n>\n(m\u03c1)d\n>\n>\n: (j\u22121)d \u2212id +(i\u22121)d\n,\n(m\u03c1)d\n\nfor \u03c1 < ri\u22121 ;\nfor ri\u22121 \u2264 \u03c1 < ri ;\nfor ri \u2264 \u03c1 < rj\u22121 ;\nfor rj\u22121 \u2264 \u03c1 < 1.\n\nClearly, limd\u2192\u221e P(r) = 1 for r < ri\u22121 and limd\u2192\u221e P(r) = 0 for ri\u22121 \u2264 r < 1. This indicates that the\nexisting robustness function tends to be a discontinuous function as d increases. An undesirable feature\nof existing measure resulted from such discontinuity is that a very small variation in the knowledge of the\nuncertainty bound, \u03b3, may lead to an opposite evaluation of the system robustness.\nFor practical systems, large uncertainty instance is less probably while the robustness requirement is more\nlikely to be violated for larger uncertainty instance. Consequently, unduly conservatism may be introduced\nif the uncertainty instances near the surface of uncertainty bounding sets assume a dominant role. This is\nindeed the case for the existing probabilistic robustness measure. This can be illustrated as follows. Suppose\nPr{||\u2206|| < \u03b3} = 1. For the existing measure, the corresponding density of ||\u2206|| of the sampling distribution\n\"\n\n\"d\u22121\n\nwhere \u03c1\u2217 = max{\u03c1 : P(\u03c1) = P(\u03b3)}. For\n\u0010 \u0011d\n\u03c1 \u2248 \u03c1\u2217 , the probability that a sample falls into {\u2206 : \u03c1 < ||\u2206|| \u2264 \u03c1\u2217 } is 1 \u2212 \u03c1\u03c1\u2217\nwhich is very close to\n1 when the dimension d is high. This shows that the uncertainty instances near the surface of B\u03c1\u2217 are\ndominating in the evaluation of system robustness.\n\nthat determines P(\u03b3) is often times close to f||\u2206|| (r) = d\n\nr\n\u03c1\u2217\n\n3. New Sampling Technique and Robustness Function\nWe have shown before that uniform sampling in high dimensional sets suffers from a surface effect.\nIn the following we introduce a new sampling technique that offsets such effect and we use the modified\nsampling technique to define the new robustness measure.\n3.0.1. A New Sampling Technique. To offset the surface effect for uncertainties with radial symmetry we\ndefine two independent random variables. One, U is uniformly distributed in the surface of the unit\nbounding set, {\u2206 : ||\u2206|| = 1}, in the uncertainty space. The second random variable is R which is a scalar\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n\n5\n\nvariable uniformly distributed over [0, r]. Clearly, for a given value of the scalar random variable R, the\nuncertainties lay on the surface of a ball and since R is scalar the surface effect is reduced.\n3.0.2. A New Robustness Function. Now that have established the sampling technique to be used, we define\nthe robustness measure for the radius r as\nP(r) =\n\ninf\n\n\u03c1\u2208(0, r]\n\nP(\u03c1) with P(r) = Pr{I(U R) = 1}\n\nwhere U is a sample from U and R a sample from R. The probabilistic implication of such robustness\nmeasure can be seen from the following theorem.\nTheorem 1. For any robustness requirement,\ninf Pr{I(\u2206) = 1 | ||\u2206|| \u2264 \u03b3} = P(\u03b3) \u2265 P(\u03b3).\n\nf\u2206 \u2208F\n\nSee Appendix A for a proof. The intuition behind Theorem 1 is that, in the worst-case, the uncertainty\ninstances in the inner layers should assume equal importance as that of uncertainty instances in the outer\nlayers in the evaluation of system robustness. It should be noted that the density f||\u2206|| (.) can be unbounded\nand has infinitely many and arbitrarily distributed discontinuities. An example of unbounded density is\nf||\u2206|| (\u03c1) = k\u22121\n, k > 1.\n\u03c1k\nNow we revisit the conceptual example discussed in Section 2.1. Our robustness function is P(r) =\ninf \u03c1\u2208[0,r] P(\u03c1) where\n\uf8f1\n\uf8f4\n1,\nfor \u03c1 < ri\u22121 ;\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2 i\u22121 ,\nfor ri\u22121 \u2264 \u03c1 < ri ;\nP(\u03c1) = m\u03c1\nm\u03c1\u22121\n\uf8f4\n\uf8f4\n\uf8f4\nm\u03c1 , for ri \u2264 \u03c1 < rj\u22121 ;\n\uf8f4\n\uf8f4\n\uf8f3 j\u22122\nfor rj\u22121 \u2264 \u03c1 < 1.\nm\u03c1 ,\nAs can be seen from Figure 3, our robustness measure is significantly less conservative than the existing\none.\n4. Mapping of Robustness Functions\nIn this section, we shall demonstrate that there exists a fundamental relationship between our robustness\nmeasure and the existing probabilistic robustness measure. This relationship can be exploited, for example,\nto reduce the computational complexity of existing probabilistic robustness measure.\n4.1. Integral Transforms. The following theorem shows that there exists an integral transform between\nour proposed robustness function and existing robustness function.\nTheorem 2. Define \u03c6(r) = Pr{I(rU ) = 1} where U is a random variable uniformly distributed over\n{\u2206 : ||\u2206|| = 1}. Suppose that the distribution of uncertainty \u2206 is radially symmetrical and that both\nf||\u2206|| (.) and \u03c6(.) are piece-wise continuous. Then, for any r > 0,\nZ\nP(r) n \u2212 1 1\nP(r) =\n+\nP(r\u03c1) d\u03c1,\nn\nn\n0\nZ 1\nP(r) = n P(r) \u2212 n(n \u2212 1)\nP(r\u03c1) \u03c1n\u22121 d\u03c1\n0\n\nwhere n is the dimension of uncertainty space.\n\nSee Appendix B for a proof. Theorem 2 shows that once one of P(.) and P(.) is available from Monte\nCarlo simulation, the other can be obtained without simulation.\n\n\f6\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\n1\n0.9\n\nInfimum of Probability\n\n0.8\n\nExisting Measure\nOur Measure\n\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\n\n0\n\n0.2\n\n0.4\n0.6\nUncertainty radius\n\n0.8\n\n1\n\nFigure 3. Comparison of Robustness Functions (m = 20, i = 11 and j = 19. The\ndimension of uncertainty space is d = 50, which is equivalent to a complex block of size\n5 \u00d7 5.)\n4.2. Recursive Computation. For a transform to be useful, we shall develop efficient method for its\ncomputation. The efficiency can be achieved by recursive computation. We first discuss the computation\nof transform from P(.) to P(.).\nIt can be seen that the expression of P(.) in terms of P(.) is not amenable for recursive computation. By a\nRr\nn\u22121\nchange of variable, we rewrite the second equation of Theorem 2 as P(r) = n P(r)\u2212 n(n\u22121)\nd\u03c1.\nrn\n0 P(\u03c1) \u03c1\nRr\nn\u22121\nClearly, the major computation is on the integration I(r) = 0 P(\u03c1) \u03c1 d\u03c1, which can be computed\nR\nrecursively because of the relationship I(r + h) = I(r) + rr+h P(\u03c1) \u03c1n\u22121 d\u03c1. Unfortunately, there will be a\nnumerical problem for computing the product n(n\u22121)\n\u00d7 I(r) in the situation that n is large and r < 1. For\nrn\ncan\nbe\na\nhuge\nnumber\nand\ncause\nintolerable\nnumerical error when n = 36 and r = 0.5. To\nexample, n(n\u22121)\nn\nr\novercome this problem, we derive the following recursive relationship\nP(r + h)\n\n=\n\nnP(r + h) \u2212\n\n\u201e\n\nr\nr+h\n\n\u00abn\n\n[nP(r) \u2212 P(r)] \u2212\n\nn(n \u2212 1)\n(r + h)n\n\nZ\n\nr+h\n\nP(\u03c1) \u03c1n\u22121 d\u03c1.\n\nr\n\nr+h\nP(\u03c1) \u03c1n\u22121 d\u03c1 as a\nSince P(.) can be approximated by a simple function, we can decompose n(n\u22121)\n(r+h)n r\nn(n\u22121) R \u03b2\nsummation of integrations of the form (r+h)n \u03b1 P(\u03c1) \u03c1n\u22121 d\u03c1 with P(\u03c1) = c, \u2200\u03c1 \u2208 [\u03b1, \u03b2]. Clearly, we have\n\nR\n\n\"\n\n\"n h`  \u0301n\n\ni\n\n\u03b2\n\u03b2\n\u03b1\nP(\u03c1)\u03c1n\u22121 d\u03c1 = (n \u2212 1)c r+h\n\u22121 .\nthe explicit formula n(n\u22121)\n(r+h)n \u03b1\n\u03b1\nIn a similar manner, P(.) can be computed recursively by relationship\n\u0014\n\u0015\nZ r+h\nP(r)\nn\u22121 1\nr\nP(r + h)\nP(r) \u2212\n+\n+\nP(r + h) =\nP(\u03c1)d\u03c1.\nn\nr+h\nn\nn r+h r\n\nR\n\n5. Computational Algorithms and Hierarchial Sample Reuse\n\u0003\n\u0002\nIn this section we shall discuss the evaluation of P(.) for uncertainty radius \u03bba , a with sample size N\nand m grid points \u03bba = r1 < * * * < rm = a. First, we shall introduce basic subroutines. Second, we present\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n\n7\n\nsample reuse algorithm based on sequential data merging method. Third, we shall demonstrate that the\nsequential sample reuse algorithm is impractical and propose hierarchy sample reuse algorithms.\nThe basic idea of our algorithms is as follows. Let U k , k = 1, * * * , N P\nbe N i.i.d. samples uniformly\nN\nI(\u2206k,i )\nwith \u2206k,i = U k Rk,i\ngenerated from {\u2206 : ||\u2206|| = 1}. For i = 1, * * * , m, we can estimate P(ri ) as k=1N\nwhere Rk,i is uniformly distributed over [0, ri ] and is independent of U k for k = 1, * * * , N . It should be\nnoted that Rk,i , i = 1, * * * , m are not necessarily mutually independent to ensure that \u2206k,i , k = 1, * * * , N\nare i.i.d samples. Due to the uniform distribution of Rk,i , sample reuse techniques can be employed to save\na substantial amount of computation for the generation of Rk,i , \u2206k,i and the evaluation of I(\u2206k,i ) in the\nfollowing manner. Let k be fixed. Let R be a sample uniformly generated from interval [0, rp ]. Then, for\nany index j such that rj \u2208 [R, rp ], we can use R as Rk,j , U k R as \u2206k,j , and I(U k R) as I(\u2206k,j ). It can be\nshown that the minimum index j can be computed by explicit formula (5.1) as\n\uf8f1\nk\u0011\n\u0010 j\n\uf8f2 1 + max 0, (\u03bbR\u2212a)(m\u22121)\nfor uniform gridding;\na(\u03bb\u22121)\n\u0010 j\n\u0010\n\u0011k\u0011\n(5.1)\nj=\nR\n\uf8f3 1 + max 0, (m \u2212 1) 1 + ln a\nfor geometric gridding\nln \u03bb\n\nwhere \"uniform gridding\" means that ri \u2212 ri\u22121 is the same for i = 2, * * * , m and \"geometric gridding\"\nri\nis the same for i = 2, * * * , m.\nmeans that ri\u22121\nFor a specific k, the sample U k is referred to as a directional sample and the simulation with sample\nreuse techniques to obtain I(\u2206k,i ), i = 1, * * * , m is referred to as \"Radial Sampling\". Clearly, I(\u2206k,i ), i =\n1, * * * , m can be expressed as a matrix D of 3 columns and random number of rows such that its i-th row\n[Di1 , Di2 , Di3 ] means that\n\uf8f1\n\uf8f21 if D = 1;\ni3\nI(\u2206k,j ) =\n\uf8f30 if Di3 = 0\nfor Di1 \u2264 j \u2264 Di2 . The algorithm of \"Radial Sampling\" is formally described in Section 5.1.\nPN\nThe process of obtaining the summation k=1 I(\u2206k,j ), i = 1, * * * , m is accomplished by the subroutine\n\"Merging\", which is described in Section 5.2.\n\n5.1. Radial Sampling. For a directional sample U , the goal of radial sampling is to create a matrix\nD. The input of the subroutine \"Radial Sampling\" is U, \u03bb, a, m and the corresponding output is D =\nRS(U, \u03bb, a, m). The algorithm is presented as follows.\n\u2022 Let p \u2190 m and do the following.\n\u2013 Generate a sample R uniformly from [0, rp ].\n\u2013 Let \u2206 \u2190 U R and evaluate I(\u2206).\n\u2013 Determine the smallest index j such that rj \u2265 R by (5.1).\n\u2013 Let D \u2190 [j, p, I(\u2206)] and s \u2190 I(\u2206).\n\u2013 Let p \u2190 j \u2212 1.\n\u2022 While p > 0 do the following.\n\u2013 Generate a sample R uniformly from [0, rp ].\n\u2013 Let \u2206 \u2190 U R and evaluate I(\u2206).\n\u2013 Determine the smallest index j such that rj \u2265 R by (5.1).\n\u2013 If I(\u2206) 6= s, add [j, p, I(\u2206)] to D as the first row and let s \u2190 I(\u2206). Otherwise, update the\nfirst element of the first row of D as j.\n\u2013 Let p \u2190 j \u2212 1.\n\u2022 Return D as the outcome of radial sampling.\n\n\f8\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\n5.2. Merging. The operation of merging involves two matrices D and H. Matrix D defines a segmented\nfunction fD (.) over domain {1, * * * , m} in the sense that, for the j-th row of D, fD (i) = Dj3 for any i such\nthat Dj1 \u2264 i \u2264 Dj2 . Similarly, matrix H defines a segmented function fH (.) over domain {1, * * * , m} in\nthe sense that, for the j-th row of H, fH (i) = Hj3 for any i such that Hj1 \u2264 i \u2264 Hj2 . For input matrices\nD and H, the merging operation finds M = Merge(D, H) such that\nfM (i) = fD (i) + fH (i),\n\ni = 1, * * * , m\n\nwhere fM (.) is a segmented function fM (.) over domain {1, * * * , m} in the sense that, for the j-th row of\nM , fM (i) = Mj3 for any i such that Mj1 \u2264 i \u2264 Mj2 .\n5.3. Sequential Sample Reuse Algorithm (SSRA). The sequential algorithm derives its name from\nthe sequential nature of the data merging process. The input variable is N, \u03bb, a, m and the output is a\nmatrix H of random number of rows and 3 columns. The main algorithm is presented as follows.\n\u2022 Let k \u2190 1 and do the following.\n\u2013 Generate a directional sample U .\n\u2013 Perform radial sampling and let D \u2190 RS(U, \u03bb, a, m).\n\u2013 Let H \u2190 D.\n\u2022 While k < N do the following.\n\u2013 Generate a directional sample U .\n\u2013 Perform radial sampling and let D \u2190 RS(U, \u03bb, a, m).\n\u2013 Perform merging and let H \u2190 Merge(D, H).\n\u2013 Let k \u2190 k + 1.\n\u2022 Return H.\n\nOnce we have H from the execution of SSRA, we can estimate P(ri ) as\n1, * * * , m.\n\nPN\n\nI(\u2206k,i )\nN\n\nk=1\n\n=\n\nfH (i)\nN ,\n\ni =\n\n5.4. Hierarchy Sample Reuse Algorithm (HSRA). A major problem with the sequential algorithm\nis that the computational effort devoted to merging becomes an enormous burden as the sample size N\nbecomes large.\nThe merging time for N = 1000, 5, 000, 10, 000 and 50, 000 are respectively 4, 120, 722 and 92119\nseconds, which is obtained by simulation on a PC of 1024M RAM and 3.2G CPU. As can be seen from\nFigure 4, the merging time required for N = 105 , 106 and N = 5 \u00d7 106 is predicted respectively as, 12\ndays, 366 years, and 9 \u00d7 105 years, by fitting the simulation data into a quadratic function (in log scale)\nbased on regression techniques. For a better understanding of the complexity issue, a theoretical analysis\nof the computational complexity of data merging is as follows.\nFrom the merging process, it can be seen that the computational complexity of merging two matrices can\nbe quantified by the sum of the numbers of the rows of the two input matrices. Thus, it suffices to study\nhow the number of rows is growing when matrices Dk = RS(U k , \u03bb, a, m), k = 1, * * * , N are sequentially\nmerged.\nNote that the average numbers of rows for all Dk are identical. Let this average be L. To merge D1\nwith D2 , the required computation is 2L. The computation to merge the outcome with D3 is 3L. The\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n\n9\n\n16\n\n10\n\n14\n\n10\n\nRegression\nSimulation\n\nMerging Time (in seconds)\n\n12\n\n10\n\n10\n\n10\n\n8\n\n10\n\n6\n\n10\n\n4\n\n10\n\n2\n\n10\n\n0\n\n10\n\n3\n\n4\n\n10\n\n5\n\n10\n\n6\n\n10\nSample Size\n\n7\n\n10\n\n10\n\nFigure 4. Merging Time\n\n1\n\n1\n\n1\n\n2\n\n1\n\n1\n\n2\n\n1\n\n1\n\n2\n\n4\n\n1\n\n2\n\n4\n\n8\n\nN= 8\nFigure 5. Illustration of Successive Binary Merging with N = 8.\n\ncomputation for all steps of merging forms a series, 2L, 3L, * * * , N L, of constant increment L. Hence, the\n. This can be a huge number because N is usually large.\ntotal number of computation is L(N+2)(N\u22121)\n2\nTo overcome the difficulty of sequential algorithm, we propose a merging method of hierarchy structure.\nWe first introduce a subroutine called successive binary merging for N = 2p data matrices as follows.\nDivide these N matrices D1 , * * * , DN into N2 groups so that each group has two matrices. After merging\neach group, we have N2 matrices. Repeating the operations of dividing and merging, we obtain a matrix\nin the final stage. This process can be associated with a binary tree as illustrated by Figure 5.\nFor the general case that N is not a power of 2, we decompose N as a summation of numbers which\nare powers of 2. For example, for N = 1000, we have N = 512 + 256 + 128 + 64 + 32 + 8. Such\n\n\f10\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\n512\n\n256\n\n128\n\n64\n\n32\n\n8\n\n40\n\nN=\n1000\n\n104\n\n232\n\n488\n\n1000\n\nFigure 6. Merging with N = 1000.\n\ndecomposition corresponds to the decimal-to-binary conversion. In general, for N =\nand N1 < N2 < * * * < N\u03c4 , the merging can be performed as follows.\n\nP\u03c4\n\nl=1\n\nNl with Nl = 2pl\n\n\u2022 Let l \u2190 1. Applying successive binary merging to N1 to create data matrix M1 . Let H \u2190 M1 .\n\u2022 While l < \u03c4 do the following.\n\u2013 Applying successive binary merging to Nl to create data matrix Ml .\n\u2013 Let H \u2190 Merge(H, Ml ).\n\u2013 Let l \u2190 l + 1.\nThe merging for N = 1000 is shown by Figure 6.\nThe complexity of such hierarchy can be analyzed as follows. For successive binary merging with N = 2p ,\nP\u03c4\nP\u03c4\nthe computation is p \u00d7 N L. For N = l=1 Nl , the computation is bounded by L l=1 Nl log2 (Nl ) +\nP\u03c4\nL l=1 (\u03c4 \u2212l+1)Nl \u2212LN1 . Therefore, the computation is reduced from the sequential algorithm by a factor\n(N +2)(N \u22121)\n(N+2)(N\u22121)\nP\n. Specially, for N = 2p , we have \u03a5 = 2 log (N ) > 2 logN (N ) ,\nof \u03a5 = 2 P\u03c4 N log (N\n)+ \u03c4 (\u03c4 \u2212l+1)N \u2212N\n[\n\nl=1\n\nl\n\n2\n\nl\n\nl=1\n\nl\n\n1\n\n]\n\n2\n\n2\n\nwhich is usually a very large number.\n\n6. Computational Complexity\nIn this section, we discuss the computational complexity for the evaluation of P(.) over uncertainty\nradius interval ( \u03bba , a]. For practical designs, the robustness requirement is guaranteed for the nominal\nmodel. Hence, P(\u03c1) = 1 for small \u03c1, and we have inf \u03c1\u2208(0,a] P(\u03c1) = inf \u03c1\u2208( \u03bba ,\u03b3] P(\u03c1) for a sufficiently\nlarge \u03bb. A direct Monte Carlo simulation method is to partition the interval ( \u03bba , a] by m grid points\na\n\u03bb = r1 < * * * < rm = a and estimate P(ri ) by N i.i.d. Monte Carlo simulations. The estimate of\ninf \u03c1\u2208( \u03bba ,a] P(\u03c1) is obtained by taking the minimum of the results for the m grid points. Such direct method\nrequires mN simulations. As m gets large, the computing time and the memory complexity becomes a\nchallenging problem. Fortunately, by employing our hierarchy sample reuse algorithms, the computational\ncomplexity is absolutely bounded and very low for arbitrarily dense griding and arbitrarily large dimension\nof uncertainty.\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n\n11\n\nFor quantifying the computational complexity, we define the equivalent number of grid points, meq as\nthe ratio\nAverage total number of simulations\n.\nmeq =\nN\nWe shall interpolate the value of P(r) for r \u2208 [ri , ri+1 ] as\nP \u2217 (r) =\n\n(r \u2212 ri ) P(ri+1 ) + (ri+1 \u2212 r) P(ri )\n.\nri+1 \u2212 ri\n\nFor a uniform gridding, we have\nTheorem 3. Let \u01eb \u2208 (0, 1) and m = 2 +\n\nj\n\n2(\u03bb\u22121)\n\u01eb\n\nk\n\n. Let ri =\n\n|P(r) \u2212 P \u2217 (r)| < \u01eb,\n\u201e\nP\n1\u2212\nfor i = 1, * * * , m \u2212 1. Moreover, meq (\u01eb) = m \u2212 m\u22121\ni=1\n\na\n\u03bb\n\n+\n\na\n(i\u22121)(a\u2212 \u03bb\n)\nm\u22121\n\nfor i = 1, * * * , m. Then,\n\n\u2200r \u2208 [ri , ri+1 ]\n1\nm\u22121\n+i\n\u03bb\u22121\n\n\u00ab\n\n< 1 + ln \u03bb for any \u01eb \u2208 (0, 1).\n\nSee Appendix C for a proof. For a geometric gridding, we have\nTheorem 4. Let \u01eb \u2208 (0, 1) and m = 2 +\n\n-\n\nln \u03bb\n\u01eb\nln(1+ 2\n)\n\n\u0017\n\n. Let ri = a\n\n|P(r) \u2212 P \u2217 (r)| < \u01eb,\n\n1\n\u03bb\n\nm\u2212i\n\u0001 m\u22121\n\nfor i = 1, * * * , m. Then,\n\n\u2200r \u2208 [ri , ri+1 ]\n\nh\n`  \u0301 1 i\nfor i = 1, * * * , m \u2212 1. Moreover, meq (\u01eb) = 1 + (m \u2212 1) 1 \u2212 \u03bb1 m\u22121 < 1 + ln \u03bb for any \u01eb \u2208 (0, 1).\n\nSee Appendix C for a proof. For completeness, we note that, for arbitrarily large m, the memory\ncomplexity is also absolutely bounded and independent of uncertainty dimension.\nTo compare the computational complexity of our probabilistic measure with that of [3], we recall Theorem 6.1 of [3], which states that if\n(6.1)\n\nm\u22651+\n\n2(\u03bb \u2212 1)d\n\u01eb\n\nthen |P(r) \u2212 P(ri )| < \u01eb \u2200r \u2208 [ri , ri+1 ] for i = 1, * * * , m \u2212 1. This bound shows that, for fixed error \u01eb,\nthe complexity is polynomial. From another perspective, it also shows that the number of grid points and\ncomputational complexity tend to infinity as the tolerance tends to zero. The computational complexity\ncan be reduced by the sample reuse techniques of [5]. It is recently shown in [7] that the equivalent number\nof grid points is bounded by 1 + d ln \u03bb (see Appendix C for a proof). In applications, d can be very large.\nFor example, the dimension d is 2n2 for a complex block of size n \u00d7 n. Since the complexity of computing\nP(.) is independent of dimension d, the integral transform can be applied to obtain P(.) from P(.) and\nthus significantly reduced the computational complexity.\n7. Examples\nIn this section, we shall demonstrate the power of our techniques by examples. By the definition of the\nindicator function I(.), for N i.i.d. samples \u22061 , * * * , \u2206N generated from Br ,\n\uf8f1\n\uf8f21 if the robustness requirement is satisfied for \u2206 ;\ni\nI(\u2206i ) =\n\uf8f30 otherwise.\n\n\f12\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\nSpecially, for the robustness stability problem in the M \u2212 \u2206 setup with M (s) = C(sI \u2212 A)\u22121 B,\n\uf8f1\n\uf8f21 if A + B\u2206 C is stable;\ni\nI(\u2206i ) =\n\uf8f30 otherwise.\n\nOf course, the N samples\nare obtained by the HSRA. A minimum variance unbiased estimator of P(r) is\nPN\ni=1 I(\u2206i )\nc\n. Since I(\u2206i ), i = 1, * * * , N are i.i.d. Bernoulli random\nvariables with ao success\ntaken as P(r) =\nN\nn\nc\nprobability P(r), the Chernoff bound [8] asserts that, for any \u03b5, \u03b4 \u2208 (0, 1), Pr P(r) \u2212 P(r) < \u03b5 > 1\u2212\u03b4\nln\n\n2\n\nif the sample size N > 2\u03b52\u03b4 .\nIn all examples, we first apply our previous method in [6] to obtain an estimate of the probabilistic\nmargin with a risk probability \u03b1 = 0.05 (Roughly speaking, we are only interested in the curve of robustness\nfunction above 1\u2212\u03b1 = 0.95). Then, we evaluate the robustness function P(r) for r \u2208 [ ae , a] by our hierarchy\nsample reuse algorithms. The existing robustness measure is computed from our measure by the integral\ntransform. The algorithms are implemented in MATLAB and all programs are executed on a PC of 1024M\nRAM and 3.2G CPU.\nWe first consider the case that the uncertainty is of a single block. A typical robustness problem is to\ndetermine the robustness margin which is specified as the maximum size of uncertainty under the condition\nthat all poles of the closed-loop system are restricted in a certain domain Cg . For single blocked uncertainty,\nthere exists formulas for computation of the robustness margin in a M \u2212\u2206 setup with M (s) = C(sI \u2212A)\u22121 B\n(see, e.g., [16] for illustration). For complex uncertainty, the robustness margin is\nrC\n\n= inf{\u03c3(\u2206) : \u2206 \u2208 Cm\u00d7p and all eigenvalues of A + B\u2206C are in Cg } =\n\n1\nsups\u2208\u2202Cg \u03c3[C(sI \u2212 A)\u22121 B]\n\nwhere \u2202Cg denotes the boundary of domain Cg . This formula was essentially obtained by Doyle and Stein\n[9]. For real uncertainty, the robustness margin is\nrR\n\n=\n=\n\ninf{\u03c3(\u2206) : \u2206 \u2208 Rm\u00d7p and all eigenvalues of A + B\u2206C are in Cg }\n1\n\"\n#!\nR(M )\n\u2212\u03b3 I(M )\nsups\u2208\u2202Cg inf \u03b3\u2208(0,1] \u03c32\n\u03b3 \u22121 I(M )\nR(M )\n\nwhere the function to be minimized is a unimodal function on (0, 1]. This formula was established by Qiu\nand his coworkers [13].\nTo compare the power of our randomized algorithms with that of these formulas, we revisit two examples\nof [13]. In example 2 of [13], the domain Cg is defined as Cg = {s \u2208 C : R(s) < 0}. The data of matrices\nA, B, C can be found in page 889 and is thus omitted here. The robustness margins for the complex and\nreal uncertainty are obtained, respectively, as rC = 0.3914 and rR = 0.5141. The robustness functions are\nshown in Figures 7 and 8 for the cases of complex and real uncertainty respectively. It can be seen that our\nrandomized algorithms can provide useful information for the system robustness beyond the deterministic\nrobustness margin. Specially, the deterministic robustness margin can be estimated from both types of\nrobustness functions. Moreover, it can be seen that our robustness measure is significantly less conservative\nthan the existing robustness measure.\nIn example 3 of [13], the domain Cg is defined as Cg = {s \u2208 C : |s| < 1} and the data of matrices\nA, B, C are given in page 889. The robustness margins for the complex and real uncertainty are obtained\nas rC = 0.7472 and rR = 1.0374 respectively. The robustness functions are shown in Figures 9 and 10 for\nthe cases of complex and real uncertainty respectively.\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n\n1\n\nInfimum of Probability\n\n0.95\n\n0.9\n\n0.85\n\n0.8\nExisting measure from transform\nOur measure\n0.75\n0.3\n\n0.4\n\n0.5\n\n0.6\n0.7\nUncertainty Radius\n\n0.8\n\n0.9\n\nFigure 7. Robustness Functions (Sample Size N = 26482). The vertical line marks the\ndeterministic robustness margin.\n1\n0.98\n\nInfimum of Probability\n\n0.96\n0.94\n0.92\n0.9\n0.88\n0.86\n0.84\nExisting measure from transform\nOur measure\n\n0.82\n0.8\n0.4\n\n0.5\n\n0.6\n\n0.7\n0.8\nUncertainty Radius\n\n0.9\n\n1\n\nFigure 8. Robustness Functions (Sample Size N = 26482). The vertical line marks the\ndeterministic robustness margin.\n\n13\n\n\f14\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\n1\n\nInfimum of Probability\n\n0.95\n\n0.9\n\n0.85\n\n0.8\nExisting measure from transform\nOur measure\n0.75\n0.6\n\n0.8\n\n1\n\n1.2\n1.4\nUncertainty Radius\n\n1.6\n\n1.8\n\nFigure 9. Robustness Functions (Sample Size N = 26482). The vertical line marks the\ndeterministic robustness margin.\n1\n0.98\n\nInfimum of Probability\n\n0.96\n0.94\n0.92\n0.9\n0.88\n0.86\n0.84\n\nExisting measure from transform\nOur measure\n\n0.82\n0.8\n0.8\n\n1\n\n1.2\n\n1.4\n1.6\nUncertainty Radius\n\n1.8\n\n2\n\nFigure 10. Robustness Functions (Sample Size N = 26482). The vertical line marks the\ndeterministic robustness margin.\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n\n15\n\nWe now consider the stability margin problem where the uncertainty consists of multiple blocks. A particularly important special case is that the uncertainty is real parameters. When the number of uncertainty\nblocks is more than one, the formulas of [9] and [13] are not applicable and the branch and techniques\nare needed. We explore the application of our HSRA for the stability margin problem studied in [10] by\na deterministic approach. The system considered in [10] is represented by Figure 11. The compensator is\n800(1+0.1\u03b41 )\ns+2\nwith parametric uncertainty \u2206 = [\u03b41 , \u03b42 , \u03b43 ].\nC(s) = s+10\nand the plant is P (s) = s(s+4+0.2\u03b4\n2 )(s+6+0.3\u03b43 )\nr\n\n+\n\ne\n\nc\n\nC(s)\n\nP(s)\n\n_\n\nFigure 11. Uncertain System\nThe deterministic robustness margin is found to be 3.44 by a branch and bound technique (see, page\n163 of [10]). The robustness functions are shown in Figure 12, which provides more insight for the system\nrobustness than the deterministic robustness margin.\n\n1\n\n0.98\n\nInfimum of Probability\n\n0.96\n\n0.94\n\n0.92\n\n0.9\nExisting measure from transform\nOur measure\n0.88\n\n0.86\n\n3\n\n4\n\n5\n\n6\n7\nUncertainty Radius\n\n8\n\n9\n\nFigure 12. Robustness Functions (Sample size N = 119, 830.)\nWe now consider the robustness problem involving time-domain specifications for the same system shown\nby Figure 11. The robustness requirement is that the rise time and settling time should be no more than\n0.25 and 3.5 seconds respectively and the overshoot should be no more than 70% under the condition that\nthe closed-loop system is stable. It is well-known that this type of problems are, in general, intractable by\n\n\f16\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\nthe deterministic approach. However, our HSRA can readily provided insightful solution. The robustness\nfunctions are shown in Figure 13.\n\n1\n\nInfimum of Probability\n\n0.98\n\n0.96\n\n0.94\nExisting measure from transform\nOur measure\n0.92\n\n0.9\n\n0.88\n0.08\n\n0.1\n\n0.12\n\n0.14\n\n0.16\n0.18\n0.2\nUncertainty Radius\n\n0.22\n\n0.24\n\n0.26\n\nFigure 13. Robustness Functions (Sample size N = 26482.)\nNow we present more extensive numerical experiments for testing the efficiency of our hierarchy sample\nreuse algorithms. We consider the robust stability of a system of transfer function H(s) = C(sI\u2212A)\u22121 B+D\n\u221a\nP\nwith uncertain matrix A = \u221210 Ik\u00d7k + dl=1 ql l W where Ik\u00d7k is a k by k identity matrix, d = k 2\nis the dimension of uncertainty and W is a matrix with all elements equal to 1. This is a special case of\nmultiple blocks of real uncertainty. Although this may not be a realistic system, it can be representative\nfor realistic systems in the respect of computational complexity.\nWhen the size of matrix A increases from 2 to 10, the dimension of uncertainty increases from 4 to 100.\nThe robustness functions for the case that A is of size 10 \u00d7 10 is shown in Figure 14. The computing time\nm\nl 2 is\nln\nshown in Figure 15 for various problem sizes. The sample size is chosen by the Chernoff bound N = 2\u03b52\u03b4\nas 738, 26482, 119830, 3800452 corresponding to \u03b5 = \u03b4 = 0.05, 0.01, 0.005, 0.001 respectively.\nTraditionally, it is widely believed that the classical deterministic robustness analysis are usually more\nefficient than randomized algorithms. However, as can be seen from Figure 15, our numerical experiments\nindicates that, if one is willing to accept our probabilistic robustness measure, the robustness analysis via\nhierarchy sample reuse algorithms can be generally far more efficient.\n8. Conclusion\nIn this paper, we develop a new statistical approach for robustness analysis which requires an extremely\nlow complexity that is independent of the dimension of uncertainty space. Our proposed robustness measure is less conservative as compared to the existing probabilistic robustness measure. The fundamental\nconnection between our measure and the existing one is also established.\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n\n1\n\nInfimum of Probability\n\n0.95\n\n0.9\n\n0.85\nExisting measure from transform\nOur measure\n0.8\n\n0.75\n0.06\n\n0.08\n\n0.1\n\n0.12\n0.14\nUncertainty Radius\n\n0.16\n\n0.18\n\nFigure 14. Robustness Functions (Dimension d = 100. Sample size N = 119, 830.)\n4\n\n10\n\nSimulation Time (in seconds)\n\n3\n\n10\n\n2\n\n10\n\nN = 738\nN = 26,482\nN = 119,830\nN = 3,800,452\n\n1\n\n10\n\n0\n\n10\n\n1\n\n10\nDimension of Uncertainty\n\nFigure 15. Simulation Time\n\n2\n\n10\n\n17\n\n\f18\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\nReferences\n[1] E. W. BAI, R. TEMPO, AND M. FU, \"Worst-case properties of the uniform distribution and randomized algorithms\nfor robustness analysis,\" Mathematics of Control, Signals and Systems, vol. 11, pp. 183-196, 1998.\n[2] B. R. BARMISH AND C. M. LAGOA, \"The uniform distribution: a rigorous justification for its use in robustness\nanalysis,\" Mathematics of Control, Signals and Systems, vol. 10 (1997), pp. 203-222.\n[3] B. R. BARMISH, C. M. LAGOA, AND R. TEMPO, \"Radially truncated uniform distributions for probabilistic robustness\nof control systems,\" Proc. of American Control Conference, pp. 853-857, Albuquerque, New Mexico, June 1997.\n[4] B. R. BARMISH AND P. S. SHCHERBAKOV, \"On avoiding vertexization of robustness problems: The approximate\nfeasibility concept,\" IEEE Transactions on Automatic Control, vol. 42, pp. 819-824, 2002.\n[5] X. CHEN, K. ZHOU, AND J. ARAVENA, \"Fast construction of robustness degradation function,\" SIAM Journal on\nControl and Optimization, vol. 42, pp. 1960-1971, 2004.\n[6] X. CHEN, K. ZHOU, AND J. ARAVENA, \"Fast universal algorithms for robustness analysis,\" Proceedings of IEEE\nConference on Decision and Control, pp. 1926-1931, Maui, Hawaii, December 2003.\n[7] X. CHEN, K. ZHOU, AND J. ARAVENA, \"Probabilistic robustness analysis - Risks, complexity and algorithms,\"\nsubmitted for publication.\n[8] H. CHERNOFF, \"A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations,\" Annals\nof Mathematical Statistics, vol. 23, pp. 493-507, 1952.\n[9] J. C. DOYLE AND G. STEIN, \"Multivariable feedback design: concepts for a classical/modern synthesis,\" IEEE Trans.\nAutom. Control, vol. 26, pp. 4-16, 1981.\n[10] R. R DE GASTON AND M. G. SAFONOV, \"Exact calculation of the multiloop stability margin,\" IEEE Trans. Autom.\nControl, vol. 33, pp. 156-171, 1988.\n[11] S. KANEV, B. De SCHUTTER, AND M. VERHAEGEN, \"An ellipsoid algorithm for probabilistic robust controller\ndesign,\" Systems and Control Letters, vol. 49, pp. 365-375, 2003.\n[12] V. KOLTCHINSKII, C.T. ABDALLAH, M. ARIOLA, P. DORATO, AND D. PANCHENKO, \"Improved sample complexity estimates for statistical learning control of uncertain systems,\" IEEE Transactions on Automatic Control, vol.\n46, pp. 2383-2388, 2000.\n[13] L. QIU, B. BERNHARDSSON, A. RANTZER, E. J. DAVISON, P. M. YOUNG, AND J. C. DOYLE, \"A formula for\ncomputation of the real stability radius,\" vol. 31, pp. 879-890, 1995.\n[14] R. F. STENGEL AND L. R. RAY, \"Stochastic robustness of linear time-invariant systems,\" IEEE Transaction on\nAutomatic Control, vol. 36, pp. 82-87, 1991.\n[15] Q. WANG AND R. F. STENGEL, \"Robust control of nonlinear systems with parametric uncertainty,\" Automatica, vol.\n38, pp. 1591-1599, 2002.\n[16] K. ZHOU, J. C. DOYLE, AND K. GLOVER, Robust and Optimal Control, Prentice Hall, Upper Saddle River, NJ, 1996.\n\nAppendix A. Proof of Theorem 1\nThe following Lemma 1 is due to [3].\nLemma 1. For any robustness requirement, inf f\u2206 \u2208G Pr{I(\u2206) = 1 | ||\u2206|| \u2264 \u03b3} = P(\u03b3).\nLemma 2. G is a superset of F , i.e., G \u2287 F .\nProof. Let f\u2206 \u2208 F . We need to show f\u2206 \u2208 G . Let 0 < r1 < r2 be two numbers such that, for any\n\u22061 , \u22062 satisfying ||\u22061 || = r1 , ||\u22062 || = r2 , both f\u2206 (\u22061 ) and f\u2206 (\u22062 ) exist. By the radial symmetry of the\ndistribution of \u2206, we can write f\u2206 (\u2206i ) as g(ri ) for i = 1, 2. Clearly, the existence implies that g(.) is\nR\ncontinuous at r = ri , i = 1, 2. Let c = v\u2208B1 dv. By the radial symmetry of the distribution of \u2206 and the\nR ri +\u03b5\n1\nn\u22121\nd\u03c1 for i = 1, 2, where\nscaling property of the function ||.||, we have f||\u2206|| (ri ) = lim\u03b5\u21920 2\u03b5\nri \u2212\u03b5 g(\u03c1) nc\u03c1\nn is the dimension of \u2206. Hence, f||\u2206|| (r) is continuous at r = ri , i = 1, 2. Recall that f\u2206 \u2208 F , we have\nf||\u2206|| (r1 ) \u2265 f||\u2206|| (r2 ). On the other hand, by the radial symmetry of the distribution of \u2206 and the scaling\nproperty of the function ||.||, we have g(ri ) = lim\u03b5\u21930\n\nR ri +\u03b5\n\nri \u2212\u03b5 f||\u2206|| (\u03c1) d\u03c1\nc(ri +\u03b5)n \u2212c(ri \u2212\u03b5)n\n\nfor i = 1, 2. By the continuity of\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n(r )\n\nf\n\ni\nfor i = 1, 2. It follows that\nf||\u2206|| (r) at ri , we have g(ri ) = n||\u2206||\nc rin\u22121\n1, implying that f\u2206 \u2208 G . Hence, G \u2287 F .\n\ng(r1 )\ng(r2 )\n\n=\n\n\u0010\n\nr2\nr1\n\n\u0011n\u22121\n\n19\n\nf||\u2206|| (r1 )\nf||\u2206|| (r2 )\n\n\u2265\n\n\u0010\n\nr2\nr1\n\n\u0011n\u22121\n\n\u2265\n\u2737\n\nLemma 3. For any S \u2286 \u2202B, area(Sr ) = rn\u22121 area(S) where Sr = {r\u2206 : \u2206 \u2208 S} and n is the dimension\nof B.\nProof. By the scalable property of ||.||,\nn\u03c1\nr\n\n\u2206 : r \u2212 \u03b5 1 < \u03c1 < r + \u03b5 2 , \u2206 \u2208 Sr\n\no\n\n=\n\n{\u03c1\u2206 : r \u2212 \u03b51 < \u03c1 < r + \u03b52 , \u2206 \u2208 S} =\n\nHence, by invoking the definition (1.1), area(Sr ) = lim \u03b51 \u21930\n\nR\n\nof variable q = rq yields\narea(Sr )\n\nn\n\n= r lim\n\n\u03b51 \u21930\n\u03b52 \u21930\n\n= r\n\n= r\n\nn\u22121\n\nR\n\nlim\n\n\u03b51 \u21930\n\u03b52 \u21930\n\nn\u22121\n\n{\u2206: r\u2212\u03b51 <\u03c1<r+\u03b52 ,\n\nlim\n\n\u03b51 \u21930\n\u03b52 \u21930\n\nr\u2206\n\u03c1 \u2208S\n\n\u03b51 + \u03b52\n\nq\u2032 \u2208{ r\u03c1 \u2206: \u2212\n\nR\n\n\u2206 \u2208S\n\u03c1\n\n\u03b51 +\u03b52\n\nq\u2032 \u2208{\u2206: r\u2212\u03b51 <\u03c1<r+\u03b52 ,\n\nR\n\n\u2206 : r \u2212 \u03b51 < \u03c1 < r + \u03b52 ,\n\nq\u2208\n\n\u03b52 \u21930\n\n\u2032\n\n\uf6be\n\n\u03b51\nr\n\n\u2264\u03c1\nr \u22121\u2264\n\n\u03b52\nr\n\n(\u03b51 + \u03b52 )/r\n\n} dq\n\n. Making a change\n\n\u2032\n\n, \u2206\u2208S }\n\nq\u2032 \u2208{\u03c1\u2206: \u2212\u03b51 \u2264\u03c1\u22121\u2264\u03b52 , \u2206\u2208S}\n\n} dq\n\nff\n\u2206\n\u2208S .\n\u03c1\n\ndq \u2032\n\ndq \u2032\n\n\u03b51 + \u03b52\n\n= rn\u22121 area(S).\n\u2737\nLemma 4.\nn Suppose the distribution\no of \u2206 is radially symmetrical. Let S be a subset of \u2202B = {\u2206 : ||\u2206|| = 1}.\nThen, Pr\n\n\u2206\n||\u2206||\n\n\u2208S\n\n||\u2206|| = \u03c1 =\n\narea(S)\narea(\u2202B)\n\nfor any \u03c1 > 0 such that f||\u2206|| (\u03c1) is continuous.\n\nProof. By the definition of the conditional probability,\nn\no\n\u2206\n\u001b\n\u001a\nPr\n\u2208\nS,\n\u03c1\n\u2212\n\u03b5\n\u2264\n||\u2206||\n\u2264\n\u03c1\n+\n\u03b5\n1\n2\n||\u2206||\n\u2206\n\u2208 S ||\u2206|| = \u03c1 = lim\n.\nPr\n\u03b51 \u21930\n||\u2206||\nPr {\u03c1 \u2212 \u03b51 \u2264 ||\u2206|| \u2264 \u03c1 + \u03b52 }\n\u03b52 \u21930\no\nn\n\u2206\nWe claim that ||\u2206||\n\u2208 S, \u03c1 \u2212 \u03b51 \u2264 ||\u2206|| \u2264 \u03c1 + \u03b52 = {\u2206 \u2208 S\u03c1,\u03b51 ,\u03b52 } where S\u03c1,\u03b51 ,\u03b52 = {\u2206 : \u03c1\u2206\u2032 \u2208 S, \u03c1\u2212\u03b51 \u2264\nn\no\n\u2206\n\u03c1\u2032 \u2264 \u03c1+\u03b52 }. To show this claim, it suffices to show that \u2206 : ||\u2206||\n\u2208 S, \u03c1 \u2212 \u03b51 \u2264 ||\u2206|| \u2264 \u03c1 + \u03b52 = S\u03c1,\u03b51 ,\u03b52 .\nLet \u2206 \u2208 S\u03c1,\u03b51 ,\u03b52 . By definition, there exists \u03c1\u2032 \u2208 [\u03c1 \u2212 \u03b51 , \u03c1 + \u03b52 ] such that\n\u03c1\u2032 \u03c1\u2206\u2032\n\n\u2032\n\n\u2206\n\u03c1\u2032\n\n\u2206\n\u03c1\u2032\n\n\u2208 S. Therefore, by the\n\n\u2032\n\n= \u03c1\n= \u03c1 \u2208 [\u03c1 \u2212 \u03b51 , \u03c1 + \u03b52 ] and\nscalable property of the function ||.||, we have ||\u2206|| =\no\nn\n\u2206\n\u2206\n\u2032\n\u03c1\u2032\n\u2206\n\u2206\n=  \u0328 \u0328 \u0328 \u0328 \u03c1\u2206  \u0328 \u0328 \u0328 \u0328 = \u03c1\u2206\u2032 \u2208 S. This implies that \u2206 \u2208 \u2206 : ||\u2206||\n\u2208 S, \u03c1 \u2212 \u03b51 \u2264 ||\u2206|| \u2264 \u03c1 + \u03b52 .\n||\u2206|| = ||\u2206||\n \u0328 \u0328 \u03c1\u2032  \u0328 \u0328\n\u03c1\u2032\no\nn\n\u2206\n\u2208 S, \u03c1 \u2212 \u03b51 \u2264 ||\u2206|| \u2264 \u03c1 + \u03b52 and \u03c1\u2032 = ||\u2206||. By definition, \u03c1 \u2212 \u03b51 \u2264 \u03c1\u2032 \u2264\nNow let \u2206 \u2208 \u2206 : ||\u2206||\n\u03c1 + \u03b52 ,\n\n\u2206\n\u03c1\u2032\n\n\u2208 S. Hence, \u2206 \u2208 S\u03c1,\u03b51 ,\u03b52 . The claim is thus proved and we have\n\u001b\n\u001a\n\u2206\nPr\n\u2208 S, \u03c1 \u2212 \u03b51 \u2264 ||\u2206|| \u2264 \u03c1 + \u03b52 = Pr{\u2206 \u2208 S\u03c1,\u03b51 ,\u03b52 }.\n||\u2206||\n\nLet S\u03c1\u2032 = {\u03c1\u2032 \u2206 : \u2206 \u2208 S}. Then, S\u03c1\u2032 \u2286 \u2202B\u03c1\u2032 and S\u03c1,\u03b51 ,\u03b52 = {\u2206 : \u2206 \u2208 S\u03c1\u2032 , \u03c1 \u2212 \u03b51 \u2264 \u03c1\u2032 \u2264 \u03c1 + \u03b52 }. By\nthe notion of the radially symmetrical distribution of \u2206 and the property of the area function shown in\n\n\f20\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\nLemma 3, we have Pr{\u2206 \u2208 S\u03c1\u2032 | ||\u2206|| = \u03c1\u2032 } =\nthe definition of the conditional probability,\n\narea(S\u03c1\u2032 )\narea(\u2202B\u03c1\u2032 )\n\nPr{\u2206 \u2208 S\u03c1\u2032 | ||\u2206|| = \u03c1\u2032 } = lim\nIt follows that Pr\n\nn\n\n\u03b51 \u21930\n\u03b52 \u21930\n\n\u2206\n||\u2206||\n\n\u2208S\n\no\n||\u2206|| = \u03c1 = lim \u03b51 \u21930\n\n\u03b52 \u21930\n\n=\n\n\u03c1\u2032 n\u22121 area(S)\n\u03c1\u2032 n\u22121 area(\u2202B)\n\n=\n\narea(S)\narea(\u2202B) .\n\nOn the other hand, by\n\nPr{\u2206 \u2208 S\u03c1,\u03b51 ,\u03b52 }\n.\nPr {\u03c1 \u2212 \u03b51 \u2264 ||\u2206|| \u2264 \u03c1 + \u03b52 }\n\nPr{\u2206\u2208S\u03c1,\u03b51 ,\u03b52 }\nPr{\u03c1\u2212\u03b51 \u2264||\u2206||\u2264\u03c1+\u03b52 }\n\nLemma 5. Suppose f||\u2206|| (.) is continuous in (a, b). Then, Pr\n\n=\n\narea(S)\narea(\u2202B) .\n\n\u2737\nn\n\n\u2206\n||\u2206||\n\no\n\u2208 S | a < ||\u2206|| < b =\n\narea(S)\narea(\u2202B) .\n\n\u0001\narea(S)\n. By Lemma 4, for any\n. For notational simplicity, let c = area(\u2202B)\nProof. Let \u03b7 > 0 and \u03b4 \u2208 0, b\u2212a\n2\nn\no\n\u2206\n\u03c1 \u2208 [a + \u03b4, b \u2212 \u03b4], we can find \u03b5 = \u03b5(\u03c1) such that Pr ||\u2206|| \u2208 S | \u03c1 \u2212 \u03b51 \u2264 ||\u2206|| \u2264 \u03c1 + \u03b52 \u2212 c < \u03b7 for any\n\npositive \u03b51 , \u03b52 less than \u03b5(\u03c1). Hence, the union of the open intervals \u222a\u03c1\u2208[a+\u03b4,b\u2212\u03b4] (\u03c1\u2212\u03b5(\u03c1), \u03c1+\u03b5(\u03c1)) will cover\ninterval [a+\u03b4, b\u2212\u03b4]. By the finite coverage theorem, we can choose finite number of \u03c1i from [a+\u03b4, b\u2212\u03b4] such\nthat \u222aki=1 (\u03c1i \u2212\u03b5(\u03c1i ), \u03c1i +\u03b5(\u03c1i )) covers interval [a+\u03b4, b\u2212\u03b4] and that none of (\u03c1i \u2212\u03b5(\u03c1i ), \u03c1i +\u03b5(\u03c1i )) is nested in\nanother. By using the mid-points of the intersections of every twonconsecutive intervals as dividing\npoints,\no\n\u2206\n\u2208 S | ai \u2264 ||\u2206|| \u2264 bi \u2212 c < \u03b7 for\nwe can partition [a + \u03b4, b \u2212 \u03b4] as k intervals [ai , bi ] such that Pr ||\u2206||\nn\no\n\u2206\ni = 1, * * * , k. Therefore, Pr ||\u2206||\n\u2208 S, ai \u2264 ||\u2206|| \u2264 bi \u2212 c Pr {ai \u2264 ||\u2206|| \u2264 bi } < \u03b7 Pr {ai \u2264 ||\u2206|| \u2264 bi }\nfor i = 1, * * * , k and\n\u001b\n\u0015\n\u001a\nk\nk \u0014\nX\nX\n\u2206\nPr {ai \u2264 ||\u2206|| \u2264 bi } .\n\u2208 S, ai \u2264 ||\u2206|| \u2264 bi \u2212 c Pr {ai \u2264 ||\u2206|| \u2264 bi } < \u03b7\nPr\n||\u2206||\ni=1\ni=1\no\nn\n\u2206\n\u2208 S, a + \u03b4 \u2264 ||\u2206|| \u2264 b \u2212 \u03b4 \u2212 c Pr {a + \u03b4 \u2264 ||\u2206|| \u2264 b \u2212 \u03b4} < \u03b7 Pr {a + \u03b4 \u2264 ||\u2206|| \u2264 b \u2212 \u03b4}.\nThat is, Pr ||\u2206||\nn\no\n\u2206\nAs a result, Pr ||\u2206||\n\u2208 S | a + \u03b4 \u2264 ||\u2206|| \u2264 b \u2212 \u03b4 \u2212 c < \u03b7. Since \u03b7 can be arbitrarily small, we have\n\u001b\n\u001a\n\u2206\n\u2208 S, a + \u03b4 \u2264 ||\u2206|| \u2264 b \u2212 \u03b4 = c Pr {a + \u03b4 \u2264 ||\u2206|| \u2264 b \u2212 \u03b4} .\nPr\n||\u2206||\nBy the assumption that f||\u2206|| (.) is piece-wise continuous, we have Pr {\u03c1 \u2264 ||\u2206|| \u2264 \u03c1 + \u03b4} \u2192 0 as \u03b4 \u2193 0 for\nall \u03c1 \u2265 0. Hence,\n\u001a\n\u001b\n\u001a\n\u001b\n\u2206\n\u2206\nlim Pr\n\u2208 S, a + \u03b4 \u2264 ||\u2206|| \u2264 b \u2212 \u03b4 \u2212 Pr\n\u2208 S, a < ||\u2206|| < b\n\u03b4\u21930\n||\u2206||\n||\u2206||\n\u001b\n\u001a\n\u001b\u0015\n\u0014 \u001a\n\u2206\n\u2206\n\u2208 S, a < ||\u2206|| < a + \u03b4 + Pr\n\u2208 S, b \u2212 \u03b4 < ||\u2206|| < b\n= lim Pr\n\u03b4\u21930\n||\u2206||\n||\u2206||\n\u2264 lim [Pr {a < ||\u2206|| < a + \u03b4} + Pr {b \u2212 \u03b4 < ||\u2206|| < b}] = 0,\n\u03b4\u21930\n\nand so lim\u03b4\u21930 Pr\n\nn\n\n\u2206\n||\u2206||\n\no\nn\no\n\u2206\n\u2208 S, a + \u03b4 \u2264 ||\u2206|| \u2264 b \u2212 \u03b4 = Pr ||\u2206||\n\u2208 S, a < ||\u2206|| < b . Similarly,\nlim |Pr {a + \u03b4 \u2264 ||\u2206|| \u2264 b \u2212 \u03b4} \u2212 Pr {a < ||\u2206|| < b}|\n\u03b4\u21930\n\n= lim [Pr {a < ||\u2206|| < a + \u03b4} + Pr {b \u2212 \u03b4 < ||\u2206|| < b}] = 0,\n\u03b4\u21930\n\nand so lim\u03b4\u21930 Pr {a + \u03b4 \u2264 ||\u2206|| \u2264 b \u2212 \u03b4} = Pr {a < ||\u2206|| < b}. It follows that\n\u001a\n\u001b\n\u2206\nPr\n\u2208 S, a < ||\u2206|| < b = c Pr {a < ||\u2206|| < b} .\n||\u2206||\nThis completes the proof.\n\n\u2737\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n\n21\n\nLemma 6. Suppose that the distribution of \u2206 is radially symmetrical and that f||\u2206|| (.) is piece-wise\n\u2206\n\u2206\nis independent with ||\u2206||. Moreover, ||\u2206||\nis uniformly distributed\ncontinuous over (0, \u221e). Then, ||\u2206||\nover {\u2206 : ||\u2206|| = 1}.\nProof. Since f||\u2206|| (.) is piece-wise continuous over (0, \u221e), we can represent (0, \u221e) as a union of open\nintervals (ai , bi ) where f||\u2206|| (.) is continuous and the set of discrete values \u03c1j , j = 1, 2, * * * for which f||\u2206|| (.)\nis discontinuous. We can enumerate the intervals and the discrete values such that\no\nn bi \u2212 ai is non-increasing\n\u2206\nwith respect to i and that \u03c1j \u2212 \u03c1j\u22121 is non-increasing with respect to j. Then, Pr ||\u2206||\n\u2208 S, ||\u2206|| = \u03c1j =\n0, j = 1, 2, * * * and, by Lemma 5,\nPr\n\n\u001a\n\n\u2206\n\u2208S\n||\u2206||\n\n\u001b\n\n=\n\n=\n\n\u001b X \u001a\n\u001b\n\u2206\n\u2206\nPr\n\u2208 S, ai < ||\u2206|| < bi +\n\u2208 S, ||\u2206|| = \u03c1j\n||\u2206||\n||\u2206||\nj\ni\n\uf8f9\n\uf8ee\nX\narea(S)\narea(S) \uf8f0X\nPr {||\u2206|| = \u03c1j }\uf8fb =\nPr {ai < ||\u2206|| < bi } +\n.\narea(\u2202B)\narea(\u2202B)\nj\ni\n\nX\n\nPr\n\n\u001a\n\nTherefore, invoking Lemma 4, we have Pr\n\nn\n\n\u2206\n||\u2206||\n\no\nn\no\n\u2206\n\u2208 S | ||\u2206|| = \u03c1 = Pr ||\u2206||\n\u2208 S for any \u03c1 such that\n\n\u2206\nand ||\u2206||. Moreover, since the argument\nf||\u2206|| (.) is continuous. This implies the independence between ||\u2206||\n\u2206\nholds for any S \u2286 {\u2206 : ||\u2206|| = 1}, we have that ||\u2206|| is uniformly distributed over {\u2206 : ||\u2206|| = 1}. The\nproof is thus completed.\n\u2737\n\nLemma 7. Suppose that \u03c6(.) is continuous over (a, b) and that the distribution of uncertainty \u2206 is radially\nRb\nsymmetrical and continuous over (a, b). Then Pr{I(\u2206) = 1, a < ||\u2206|| < b} = a \u03c6(r)fR (r)dr.\n\n\u2206\nProof. Define U = ||\u2206||\n, R = ||\u2206|| and fR (\u03c1) = d[Pr{R\u2264\u03c1}]\n. By Lemma 6, we have that U and R are\nd\u03c1\n1\n\u00d7fR (r)\nindependent and that U is uniform over \u2202B. Hence, the probability density function of U R is area(\u2202B)\nand, by the Fubini's Theorem,\n\nPr{I(\u2206) = 1, a < ||\u2206|| < b} =\n=\n=\n=\n\nPr{I(U R) = 1, a < R < b}\nZ b Z\n\n1\nfR (r) dudr\nr=a {u: I(ru)=1, u\u2208\u2202B} area(\u2202B)\n#\nZ b \"Z\n1\ndu fR (r)dr\nr=a\n{u: I(ru)=1, u\u2208\u2202B} area(\u2202B)\nZ b\n\u03c6(r)fR (r)dr\nr=a\n\nwhere the last equality follows from the definition of \u03c6(.).\n\u2737\n\nLemma 8. Suppose that \u03c6(.) is piece-wise continuous and that f||\u2206|| (.) is piece-wise continuous and nonR\u03b3\nincreasing. Then, Pr{I(\u2206) = 1, ||\u2206|| \u2264 \u03b3} = 0 \u03c6(\u03c1) f||\u2206|| (\u03c1)d\u03c1.\n\n\f22\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\nfor \u03c1 \u2208 [\u03b5, \u03c1]. It\nProof. Let \u03b5 > 0. Since f||\u2206|| (\u03c1) is non-increasing, we have f||\u2206|| (\u03c1) \u2264 Pr{||\u2206||\u2264\u03b5}\n\u03b5\nfollows that \u03c6(\u03c1) f||\u2206|| (\u03c1) is piece-wise continuous and bounded for \u03c1 \u2208 [\u03b5, \u03c1]. Hence, the Riemann integral\nR\u03b3\nR\u03b3\nR\u03b3\nR\u03b3\n\u2264 \u03b5 f||\u2206|| (\u03c1)d\u03c1 \u2264 1 and that \u03b5 \u03c6(\u03c1) f||\u2206|| (\u03c1)d\u03c1\n\u03b5 \u03c6(\u03c1) f||\u2206|| (\u03c1)d\u03c1 exists. Note that \u03b5 \u03c6(\u03c1) f||\u2206|| (\u03c1)d\u03c1\nR\u03b3\nis non-increasing with respect to \u03b5. Thus, lim\u03b5\u21930 \u03b5 \u03c6(\u03c1) f||\u2206|| (\u03c1)d\u03c1 exists. This limit is denoted as\nR\u03b3\n0 \u03c6(\u03c1) f||\u2206|| (\u03c1)d\u03c1.\nNote that we can partition interval (0, \u03b3) as a sequence of intervals (ai , bi ), i = 1, * * * , \u221e such that\nai , bi , i = 1, 2, * * * are discontinuities of f||\u2206|| (\u03c1) and that bi \u2212 ai is non-increasing with respect to i. To\nensure that the partition is unique, we can handle the situation that some intervals have the same length\nby enforcing the following criterion: if bi \u2212 ai = bj \u2212 aj , i < j then ai < aj . Then, by the property of\nR\u03b3\nR bi\nP\nthe Riemann integral, we have 0 \u03c6(\u03c1) f||\u2206|| (\u03c1)d\u03c1 = \u221e\ni=1 ai \u03c6(\u03c1) f||\u2206|| (\u03c1)d\u03c1. On the other hand, since\nPr{||\u2206|| = ai } = Pr{||\u2206|| = bi } = 0 for i = 1, 2 * * * , \u221e, we have\nPr{I(\u2206) = 1, ||\u2206|| \u2264 \u03b3} =\n(A.1)\n\n=\n=\n\n\u221e\nX\n\nPr{I(\u2206) = 1, ai < ||\u2206|| < bi }\n\ni=1\n\u221e Z bi\nX\n\ni=1\nZ \u03b3\n\n\u03c6(\u03c1) f||\u2206|| (\u03c1)d\u03c1\n\nai\n\n\u03c6(\u03c1) f||\u2206|| (\u03c1)d\u03c1\n\n0\n\nwhere the equality (A.1) follows from Lemma 7.\n\n\u2737\nLemma 9. For any r > 0, P(r) =\n\n1\nr\n\nRr\n0\n\n\u03c6(\u03c1) d\u03c1.\n\nProof. By the definition of P(.), we have P(r) = Pr{I(U R) = 1} = Pr{I(U R) = 1, ||U R|| \u2264 r}\nwhere U and R are independent random variables such that U is uniformly distributed over \u2202B and\nR is uniformly distributed over [0, r]. Applying Lemma 8 to random variable \u2206 = U R, we have P(r) =\nRr\nRr\n\u03c6(\u03c1) fR (\u03c1) d\u03c1 = 1r 0 \u03c6(\u03c1) d\u03c1.\n0\n\u2737\nLemma 10. Let 0 < r1 < r2 . Then, |P(r2 ) \u2212 P(r1 )| <\nProof. By Lemma 9,\n|P(r2 ) \u2212 P(r1 )| =\n\u2264\n\u2264\n=\n\nR r2\n\n2(r2 \u2212r1 )\n.\nr1\n\n\u0013 Z r1\n1\n1\n+\n\u2212\n\u03c6(\u03c1) d\u03c1\nr2\nr2\nr1\n0\nR r2\n\u0013 Z r1\n\u0012\n\u03c6(\u03c1) d\u03c1\n1\n1\nr1\n+\n\u2212\n\u03c6(\u03c1) d\u03c1\nr2\nr1\nr2\n0\nr2 \u2212 r1\nr2 \u2212 r1\n+\nr1\nr2\nr1 r2\n2(r2 \u2212 r1 )\n2(r2 \u2212 r1 )\n\u2264\nr2\nr1\nr1\n\n\u03c6(\u03c1) d\u03c1\n\n\u0012\n\nwhere we have used the fact that 0 \u2264 \u03c6(\u03c1) \u2264 1.\n\nP(\u03c1) = inf 0<\u03c1\u2264\u03b3 P(\u03c1) where Q denotes the set of all rational numbers.\nLemma 11. inf 0<\u03c1\u2264\u03b3\n\u03c1\n\u03b3\n\n\u2208Q\n\n\u2737\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n\n23\n\nP(\u03c1) and b = inf 0<\u03c1\u2264\u03b3 P(\u03c1). Clearly, a \u2265 b \u2265 0. Suppose a > b. Then, there\nProof. Let a = inf 0<\u03c1\u2264\u03b3\n\u03c1\n\u03b3\n\n\u2208Q\n\nexists a real number \u03c1\u2217 \u2208 (0, \u03b3] such that P(\u03c1\u2217 ) < a+b\n2 . By the dense property of the rational numbers,\n\u2217\nfor any \u03b4 \u2208 (0, \u03c1 ), there exists a number \u03b8 such that \u03b3\u03b8 \u2208 Q and that |\u03b8 \u2212 \u03c1\u2217 | < \u03b4. Thus, by Lemma 10,\n2\u03b4\n|P(\u03b8) \u2212 P(\u03c1\u2217 )| \u2264 \u03c1\u22172\u03b4\u2212\u03b4 , leading to P(\u03b8) \u2264 P(\u03c1\u2217 ) + \u03c1\u22172\u03b4\u2212\u03b4 < a+b\n2 + \u03c1\u2217 \u2212\u03b4 . Since \u03b4 can be arbitrarily small,\na+b\na+b\nwe have P(\u03b8) \u2264 2 . Hence, a \u2264 2 , i.e., a \u2264 b, contradicting to a > b. This shows that a > b is not\ntrue. Therefore, a = b.\n\u2737\nWe are now in the position to prove Theorem 1. For every f\u2206 \u2208 F , define f||\u2206|| (\u03c1, \u03b3) =\nd Pr{||\u2206||\u2264\u03c1}\n1\nPr{||\u2206||\u2264\u03b3}\nd\u03c1\n\nd Pr{||\u2206||\u2264\u03c1 | ||\u2206||\u2264\u03b3}\nd\u03c1\n\nf||\u2206|| (\u03c1)\nPr{||\u2206||\u2264\u03b3} ,\n\n=\nand the set of all such functions constitute a\nThen, f||\u2206|| (\u03c1, \u03b3) =\nfamily of conditional density functions, denoted by F\u03b3 . Clearly, every conditional density f||\u2206|| (\u03c1, \u03b3) in F\u03b3\nis non-increasing with respect to \u03c1. For every positive integer k, we use F\u03b3,k to denote the set of conditional\nPk\ndensity functions of the form: f||\u2206|| (\u03c1, \u03b3) = i=1 \u03bei I(ri\u22121 ,ri ] (\u03c1), \u2200\u03c1 \u2208 (0, \u03b3] where ri = ik\u03b3 , i = 0, 1, * * * , k,\n\uf8f1\n\uf8f21 if x \u2208 (r , r ];\ni\u22121 i\nI(ri\u22121 ,ri ] (x) =\n\uf8f30 otherwise\nand \u03be1 \u2265 \u03be2 \u2265 * * * \u2265 \u03bek \u2265 0 with\nPr{I(\u2206) = 1 | ||\u2206|| \u2264 \u03b3} =\n\n\u03b3\nk\n\nPk\n\ni=1 \u03bei\n\n= 1. By Lemma 8,\nR\u03b3\nZ \u03b3\n\u03c6(\u03c1) f||\u2206|| (\u03c1)d\u03c1\nPr{I(\u2206) = 1, ||\u2206|| \u2264 \u03b3}\n= 0\n=\n\u03c6(\u03c1)f||\u2206|| (\u03c1, \u03b3)d\u03c1.\nPr{||\u2206|| \u2264 \u03b3}\nPr{||\u2206|| \u2264 \u03b3}\n0\n\nTherefore,\n(A.2)\n\ninf Pr{I(\u2206) = 1 | ||\u2206|| \u2264 \u03b3} =\n\nf\u2206 \u2208F\n\ninf\n\nf||\u2206|| (.,\u03b3)\u2208F\u03b3\n\nZ\n\n\u03b3\n\n\u03c6(\u03c1)f||\u2206|| (\u03c1, \u03b3)d\u03c1.\n\n0\n\nSince \u03c6(\u03c1) I(ri\u22121 ,ri ] (\u03c1) is bounded and piece-wise continuous over (0, \u03b3], it is Riemann integrable. It follows\nthat, for a conditional density f||\u2206|| (\u03c1, \u03b3) in the family F\u03b3,k ,\n#\n\" k\n\u0015\nZ \u03b3\nZ \u03b3\nk\nk \u0014Z \u03b3\nX\nX\nX\nai \u03bei\n\u03c6(\u03c1) I(ri\u22121 ,ri ] (\u03c1) d\u03c1 \u03bei =\n\u03bei I(ri\u22121 ,ri ] (\u03c1) d\u03c1 =\n\u03c6(\u03c1)f||\u2206|| (\u03c1, \u03b3)d\u03c1 =\n\u03c6(\u03c1)\n0\n\n0\n\ni=1\n\ni=1\n\n0\n\ni=1\n\nR\u03b3\n\nwhere ai = 0 \u03c6(\u03c1) I(ri\u22121 ,ri ] (\u03c1) d\u03c1 for i = 1, * * * , k. Since ai is independent of (\u03be1 , * * * , \u03bek ) for i = 1, * * * , k,\nPk\nwe have that i=1 ai \u03bei is a linear function of \u03bei , i = 1, * * * , k for any given k > 0. Therefore, the infimum\nR\u03b3\nPk\ninf f||\u2206|| (.,\u03b3)\u2208F\u03b3,k 0 \u03c6(\u03c1)f||\u2206|| (\u03c1, \u03b3)d\u03c1 equals to the minimum of i=1 ai \u03bei subject to the constraint that\nP\nk\n\u03be1 \u2265 \u03be2 \u2265 * * * \u2265 \u03bek \u2265 0 and \u03b3k i=1 \u03bei = 1. Note that the minimum of a linear program over a bounded\nset is achieved at the extreme points. By Lemma 2.2 of [2], for every extreme point of the convex set\nPk\nk\n{(\u03be1 , * * * , \u03bek ) : \u03be1 \u2265 \u03be2 \u2265 * * * \u2265 \u03bek \u2265 0, \u03b3k i=1 \u03bei = 1}, we can find an integer l such that \u03bei = \u03b3l\nfor i = 1, * * * , l and \u03bei = 0 for i = l + 1, * * * , k. For such extreme point associated with l, we have\nR\u03b3\nR kl \u03b3\n\u0001\nPk\n\u03c6(\u03c1) l1\u03b3 d\u03c1 = P kl \u03b3 , where the last equality follows from Lemma\ni=1 ai \u03bei = 0 \u03c6(\u03c1)f||\u2206|| (\u03c1, \u03b3)d\u03c1 = 0\nk\n9. Therefore,\n\u001b\n\u001a \u0012 \u0013\nZ \u03b3\nl\ninf\n\u03b3 :0\u2264l\u2264k .\n\u03c6(\u03c1)f||\u2206|| (\u03c1, \u03b3)d\u03c1 = min P\nk\nf||\u2206|| (.,\u03b3)\u2208F\u03b3,k 0\nIt follows that\ninf \u221e\n\nf||\u2206|| (.,\u03b3)\u2208\u222ak=1 F\u03b3,k\n\nZ\n\n\u03b3\n\n\u03c6(\u03c1)f||\u2206|| (\u03c1, \u03b3)d\u03c1 = inf\n0\n\nff\n\uf6be\nff\n\u201e \u00ab\n\u221e \uf6be\n[\n\u03c1\nl\n\u03b3 : 0 \u2264 l \u2264 k = inf P(\u03c1) : 0 < \u03c1 \u2264 \u03b3,\n\u2208Q .\nP\nk\n\u03b3\n\nk=1\n\n.\n\n\f24\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\nIt can be shown that\ninf \u221e\n\nf||\u2206|| (.,\u03b3)\u2208\u222ak=1 F\u03b3,k\n\nZ\n\n\u03b3\n\n\u03c6(\u03c1)f||\u2206|| (\u03c1, \u03b3)d\u03c1 =\n\n0\n\nHence, by (A.2),\ninf Pr{I(\u2206) = 1 | ||\u2206|| \u2264 \u03b3} = inf\n\nf\u2206 \u2208F\n\n\u001a\n\ninf\n\nf||\u2206|| (.,\u03b3)\u2208F\u03b3\n\nP(\u03c1) : 0 < \u03c1 \u2264 \u03b3,\n\nZ\n\n\u03b3\n\n\u03c6(\u03c1)f||\u2206|| (\u03c1, \u03b3)d\u03c1.\n\n0\n\n\u03c1\n\u2208Q\n\u03b3\n\n\u001b\n\n= inf P(\u03c1),\n0<\u03c1\u2264\u03b3\n\nwhere the last equality follows from Lemma 11. Finally, by Lemma 1 and Lemma 2, we have P(\u03b3) =\ninf f\u2206 \u2208F Pr{I(\u2206) = 1 | ||\u2206|| \u2264 \u03b3} \u2265 inf f\u2206 \u2208G Pr{I(\u2206) = 1 | ||\u2206|| \u2264 \u03b3} = P(\u03b3). The proof is thus\ncompleted.\nAppendix B. Proof of Theorem 2\nWe shall first define some terminologies that will be used in the proof.\nDefinition 1. A value of the uncertainty radius is said to be a discontinuity if \u03c6(.) is discontinuous for\nthat value.\nDefinition 2. An open interval (a, b) is said to be a continuous interval if \u03c6(r) is continuous for any\nr \u2208 (a, b).\nDefinition 3. A discontinuity, p, is said to be a cluster point if, for any \u01eb > 0, there exists another\ndiscontinuity, q, such that |p \u2212 q| < \u01eb.\nThe proof of the transform formulas is largely focused on the investigation of discontinuities, cluster\npoints and continuous intervals. By the assumption that \u03c6(.) is piece-wise continuous, we can see that the\ndistributions of discontinuities and cluster points can be arbitrary. For example, it is possible that there are\nr\nwhere i = 1, * * * , \u221e and j = 1, * * * , \u221e.\ninfinitely many discontinuities distributed over (0, r) as (i+1)(j+1)\nr\nIn this example, there are infinitely many cluster points i+1 , i = 1, * * * , \u221e.\nDespite the complexity of the distributions of discontinuities and cluster points, it suffices to prove the\ntransform formulas for the following four cases:\nCase (1): There are a finite number of discontinuities.\nCase (2): There are infinitely many discontinuities such that r = 0 is the unique cluster point.\nCase (3): There are infinitely many discontinuities such that there is a cluster point at r = 0 and\nthat there is at least one more cluster point at r > 0.\nCase (4): There are infinitely many discontinuities such that there is no cluster point at r = 0.\nBefore addressing each case in details, we need to establish some preliminary results.\nThe following lemma is on the enumeration and classification of continuous intervals.\nLemma 12. For any \u03b5 > 0, the set of all continuous intervals defined by the end points q, r or discontinuities of interval (q, r) can be divided into two classes such that i) the first class, denoted by Ic\n\u03b5 , has a finite\nnumber of intervals; ii) the second class, denoted by I\u03b5 , has infinitely many intervals and the total length\nis less than \u03b5.\nProof. Such classification can be performed as follows. Let k = 1 and ck = 21k . Find all intervals with\nlength greater than ck . Rank these intervals by the lengths and include it in set A . Include the remaining\nintervals in set B. Increment k and update ck = 21k . From B find all intervals with length greater than\nck . Add these intervals to set A and rank all intervals by the lengths. Eliminate those intervals from set\nB.\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n\n25\n\nRepeating these steps for infinitely many values of k leads to a sequence of intervals of decreasing lengths.\nP\u221e\nLet (ai , bi ), i = 1, 2, * * * denote this sequence. Let Li = bi \u2212 ai . Then, i=1 Li = r \u2212 q and Li is decreasing\nP\u221e\nwith respect to i. Thus, by Cauchy's theorem, there must be an integer K such that i=K Li < \u03b5. This\nimplies that we have the desired two classes. The first class Ic\n\u03b5 consists of intervals (ai , bi ), i = 1, * * * , K \u22121\nand the second class I\u03b5 consists of intervals (ai , bi ), i = K, * * * , \u221e.\n\u2737\nLemma 13. For any r > 0, P(r) =\n\nn\nrn\n\nRr\n0\n\n\u03c6(\u03c1) \u03c1n\u22121 d\u03c1 where n is the dimension of uncertainty space.\n\nProof. Since \u2206u is uniformly distributed over B, we can derive the density function of ||\u2206u || as f||\u2206u || (\u03c1) =\nn\u03c1n\u22121\nrn .\n\nBy definition, P(r) = Pr{I(\u2206u ) = 1} = Pr{I(\u2206u ) = 1, ||\u2206u || \u2264 r}. By Lemma 8,\nZ\nZ r\nZ r\nn r\nn\u03c1n\u22121\nu\n\u03c6(\u03c1) \u03c1n\u22121 d\u03c1.\nP(r) =\n\u03c6(\u03c1) f||\u2206 || (\u03c1) d\u03c1 =\n\u03c6(\u03c1) n d\u03c1 = n\nr\nr\n0\n0\n0\n\n\u2737\n\nThe following two lemmas establish connections between \u03c6(.), P(.) and P(.).\nLemma 14. For any continuous interval (a, b) with 0 < a < b,\nZ b\nZ\nbP(b) \u2212 aP(a) n \u2212 1 b\n\u03c6(\u03c1) d\u03c1 =\n+\nP(\u03c1) d\u03c1.\nn\nn\na\na\nRr\nProof. By Lemma 13, we have P(r) = rnn 0 \u03c6(\u03c1) \u03c1n\u22121 d\u03c1. Since \u03c6(\u03c1) is continuous over (a, b), we have\nd[\u03c1n P(\u03c1)]\nd\u03c1\nn\u03c1n\u22121\n\nthat P(r) is differentiable with respect to r and that \u03c6(\u03c1) =\nZ\n\nb\n\n\u03c6(\u03c1) d\u03c1\n\n=\n\na\n\nZ\n\na\n\n=\n\nZ\n\nn\n\nb d[\u03c1 P(\u03c1)]\nd\u03c1\nn\u03c1n\u22121\nb\n\na\n\nfor any \u03c1 \u2208 (a, b). Consequently,\n\nd\u03c1\n\n1\nd[\u03c1n P(\u03c1)]\nn\u03c1n\u22121\n\n(b \u2212 \u01eb)P(b \u2212 \u01eb) \u2212 (a + \u01eb)P(a + \u01eb) n \u2212 1\n+\n\u01eb\u21920\nn\nn\nZ b\nbP(b) \u2212 aP(a) n \u2212 1\n+\nP(\u03c1)d\u03c1\n=\nn\nn\na\n\n=\n\n(B.1)\n(B.2)\n\nlim\n\nZ\n\nb\n\nP(\u03c1)d\u03c1\n\na\n\nwhere we have used the technique of integration by part in (B.1) and the fact that P(\u03c1) is continuous for\nany \u03c1 > 0 in (B.2).\n\u2737\nLemma 15. For any continuous interval (a, b) with 0 < a < b,\nZ r\nZ\n\u03c6(\u03c1) \u03c1n\u22121 d\u03c1 = [bn P(b) \u2212 an P(a)] \u2212 (n \u2212 1)\n0\n\n1\nr\n\nb\n\nP(\u03c1) \u03c1n\u22121 d\u03c1.\n\na\n\nRr\n\n\u03c6(\u03c1) d\u03c1. Since \u03c6(\u03c1) is continuous over (a, b), we have that P(\u03c1)\nProof. By Lemma 9, we have P(\u03c1) =\n0\nP(\u03c1)]\nis differentiable with respect to \u03c1 and that \u03c6(\u03c1) = d[\u03c1 d\u03c1\nfor any \u03c1 \u2208 (a, b). Hence,\nZ b\nZ r\n\u03c1n\u22121 d[\u03c1 P(\u03c1)]\n\u03c1n\u22121 \u03c6(\u03c1) d\u03c1 =\n0\n\na\n\n=\n=\n\nn\n\nn\n\nlim [(b \u2212 \u01eb) P(b \u2212 \u01eb) \u2212 (a + \u01eb) P(a + \u01eb)] \u2212\n\n\u01eb\u21920\n\n[bn P(b) \u2212 an P(a)] \u2212 (n \u2212 1)\n\nZ\n\na\n\nb\n\nZ\n\na\n\nP(\u03c1) \u03c1n\u22121 d\u03c1\n\nb\n\n\u03c1 P(\u03c1) (n \u2212 1)\u03c1n\u22122 d\u03c1\n\n\f26\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\nwhere we have used the technique of integration by part and the fact that P(\u03c1) is continuous for any\n\u03c1 > 0.\n\u2737\n\nLemma 16. Let q \u2264 a < b \u2264 r. Then, |bP(b) \u2212 aP(a)| \u2264\n\n\u0010\n\nnr\nq\n\n\u0011\n+ 1 (b \u2212 a).\n\nProof. Note that, for q \u2264 a < b \u2264 r, we have\n|bP(b) \u2212 aP(a)| =\n\u2264\n\u2264\n\n|bP(b) \u2212 bP(a) + bP(a) \u2212 aP(a)|\nb|P(b) \u2212 P(a)| + (b \u2212 a)P(a)\n\u0012\n\u0013\nn(b \u2212 a)\nnr\nb\n+ (b \u2212 a) \u2264\n+ 1 (b \u2212 a)\na\nq\n\nwhere we have used the bound |P(b) \u2212 P(a)| \u2264\npage 856 of [3].\n\nn(b\u2212a)\n,\na\n\nwhich was derived in the proof of Theorem 6.1 in\n\u2737\n\nLemma 17. Let q \u2264 a < b \u2264 r. Then, |bn P(b) \u2212 an P(a)| <\nProof. Note that, by Lemma 10, |P(b) \u2212 P(a)| \u2264\n|bn P(b) \u2212 an P(a)| =\n\u2264\n\u2264\n<\n=\n\u2264\n\n2(b\u2212a)\n,\na\n\n\u0010\n\n2r n\nq\n\n\u0011\n+ nrn\u22121 (b \u2212 a).\n\nwe have\n\n|bn P(b) \u2212 bn P(a) + bn P(a) \u2212 an P(a)|\n\nbn |P(b) \u2212 P(a)| + (bn \u2212 an )P(a)\n2bn (b \u2212 a)\n+ (bn \u2212 an )\na\n2bn (b \u2212 a)\n+ nbn\u22121 (b \u2212 a)\na\n\u0013\n\u0012 n\n2b\n+ nbn\u22121 (b \u2212 a)\na\n\u0012 n\n\u0013\n2r\nn\u22121\n(b \u2212 a)\n+ nr\nq\n\nwhere we have used the inequality bn \u2212 an < nbn\u22121 (b \u2212 a) which can be shown by using Taylor's expansion\nformula bn = an + n\u03be n\u22121 (b \u2212 a) < an + nbn\u22121 (b \u2212 a) with some \u03be \u2208 (a, b).\n\u2737\n\nWe are now in the position to prove the transform formulas for each cases.\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n\n27\n\nCase (1): Let 0 = p0 < p1 < * * * < pk < pk+1 = r where p1 , * * * , pk are k \u2265 0 discontinuities. By\nLemma 14, we have\nZ\n\nr\n\n\u03c6(\u03c1)d\u03c1\n\n=\n\n0\n\n=\n=\n\n=\n\nlim\n\u01eb\u21930\n\nlim\n\u01eb\u21930\n\nZ\n\nr\n\n\u03c6(\u03c1)d\u03c1\n\n\u01eb\n\nZ\n\u0014\n\np1\n\n\u03c6(\u03c1) d\u03c1 +\n\n\u01eb\n\nk Z\nX\ni=1\n\npi+1\n\n\u03c6(\u03c1) d\u03c1\n\npi\n\n\u0015\nZ\np1 P(p1 ) \u2212 \u01ebP(\u01eb) n \u2212 1 p1\nP(\u03c1)d\u03c1\n+\n\u01eb\u21930\nn\nn\n\u01eb\n\u0015\n\u0014\nk\nX pi+1 P(pi+1 ) \u2212 pi P(pi ) n \u2212 1 Z pi+1\nP(\u03c1)d\u03c1\n+\n+\nn\nn\npi\ni=1\n\u0014\n\u0015\nZ p1\nZ\nrP(r) n \u2212 1 r\n\u2212\u01ebP(\u01eb) n \u2212 1\nlim\nP(\u03c1)d\u03c1 +\n+\n+\nP(\u03c1)d\u03c1.\n\u01eb\u21930\nn\nn\nn\nn\n\u01eb\np1\nlim\n\nRp\nRp\nSince 0 \u2264 P(\u03c1) \u2264 1, \u2200\u03c1 > 0, we have lim\u01eb\u21930 \u01ebP(\u01eb) = 0 and lim\u01eb\u21930 \u01eb 1 P(\u03c1)d\u03c1 = 0 1 P(\u03c1)d\u03c1. It follows\nRr\nR\nR\nR\nP(r)\nn\u22121 r\n1 r\nn\u22121 r\nthat 0 \u03c6(\u03c1)d\u03c1 = rP(r)\nn + n\n0 P(\u03c1)d\u03c1 and that P(r) = r 0 \u03c6(\u03c1)d\u03c1 = n + nr\n0 P(\u03c1)d\u03c1.\nBy Lemma 15 and similar techniques, we can show the expression for P(r) in this case.\nCase (2): In this case, the discontinuities can be represented as a monotone decreasing sequence\n{pi }\u221e\ni=1 such that r = p0 > p1 > p2 > * * * > pk > * * * and limk\u2192\u221e pk = 0. By Lemma 14, we have\nZ\n\nr\n\n\u03c6(\u03c1)d\u03c1\n\n=\n\n0\n\n=\n=\n\nlim\n\nk\u2192\u221e\n\nlim\n\nk\u2192\u221e\n\nlim\n\nk\u2192\u221e\n\nk Z\nX\ni=1\n\npi\u22121\n\n\u03c6(\u03c1) d\u03c1\n\npi\n\nk \u0014\nX\npi\u22121 P(pi\u22121 ) \u2212 pi P(pi )\n\nn\n\ni=1\n\n\u0014\n\nrP(r) \u2212 pk P(pk ) n \u2212 1\n+\nn\nn\n\n+\nZ\n\nn\u22121\nn\n\nZ\n\npi\u22121\n\nP(\u03c1)d\u03c1\n\npi\n\n\u0015\n\nr\n\n\u0015\n\nP(\u03c1)d\u03c1 .\n\npk\n\nSince 0 \u2264 P(\u03c1) \u2264 1, \u2200\u03c1 > 0 and limk\u2192\u221e pk = 0, we have limk\u2192\u221e pk P(pk ) = 0 and limk\u2192\u221e prk P(\u03c1)d\u03c1 =\nRr\nRr\nRr\nRr\nrP(r)\nP(\u03c1)d\u03c1 and P(r) = 1r 0 \u03c6(\u03c1)d\u03c1 = P(r)\nP(\u03c1)d\u03c1. It follows that 0 \u03c6(\u03c1)d\u03c1 = n + n\u22121\n0\nn\nn +\n0\nR\nn\u22121 r\nP(\u03c1)d\u03c1.\nnr\n0\nBy Lemma 15 and similar techniques, we can show the expression for P(r) in this case.\nCase (3): In this case, let r\u2217 be the smallest positive cluster point. Let q = r2\u2217 . We can write\nRr\nRq\nRr\nRq\n= 0 \u03c6(\u03c1)d\u03c1 + q \u03c6(\u03c1)d\u03c1. Applying the result of Case (2), we have 0 \u03c6(\u03c1)d\u03c1 = qP(q)\n0 \u03c6(\u03c1)d\u03c1\nn +\nR\nRr\nn\u22121 q\nP(\u03c1)d\u03c1. We consider q \u03c6(\u03c1)d\u03c1. For any \u03b5 > 0, by Lemma 12, we can write\nn\n0\nR\n\nZ\n\n(B.3)\n\nq\n\nR\n\nr\n\n\u03c6(\u03c1)d\u03c1 =\n\nX\n\nc\u03b5\n(a,b)\u2208I\n\nZ\n\n(a,b)\n\n\u03c6(\u03c1)d\u03c1 +\n\nX\n\n(a,b)\u2208I\u03b5\n\nZ\n\n\u03c6(\u03c1)d\u03c1\n\n(a,b)\n\nP\nmeans the integration over interval (a, b) and (a,b)\u2208I\nc\u03b5 means the summation over all\nP\nc\u03b5 . The notion of\nintervals of I\n(a,b)\u2208I\u03b5 is similar.\nR\nP\nc\nTo evaluate (a,b)\u2208I\nc\u03b5 (a,b) \u03c6(\u03c1)d\u03c1, we arrange the intervals in I\u03b5 as (ai , bi ), i = 1, * * * , k such\nthat a1 = q, bi < ai+1 , i = 1, * * * , k \u2212 1 (Here k is the total number of intervals). Note that, by\nwhere\n\n(a,b)\n\n\f28\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\nLemma 14,\nX\n\nc\u03b5\n(a,b)\u2208I\n\n(B.4)\n\nZ\n\n\u03c6(\u03c1)d\u03c1\n\n\"\n#\nZ\nk\nX\nbi P(bi ) \u2212 ai P(ai ) n \u2212 1 bi\nP(\u03c1)d\u03c1\n+\nn\nn\nai\ni=1\n\n=\n\n(a,b)\n\nZ\nrP(r) \u2212 qP(q) n \u2212 1 r\n+\nP(\u03c1)d\u03c1\nn\nn\nq\n\u0015\nZ\nk\u22121 \u0014\nX\nai+1 P(ai+1 ) \u2212 bi P(bi ) n \u2212 1 ai+1\n\u2212\nP(\u03c1)d\u03c1 .\n+\nn\nn\nbi\ni=1\n\u0011\n\u0010\n+\n1\n(ai+1 \u2212 bi ), i = 1, * * * , k \u2212 1 and\nBy Lemma 16, we have |ai+1 P(ai+1 ) \u2212 bi P(bi )| < nr\nq\n=\n\nk\u22121\nX\ni=1\n\nk\u22121\nX \u0014\u0012\n\n\u0013\n\u0015 \u0012\n\u0013 k\u22121\nX\nnr\nnr\n(ai+1 \u2212 bi )\n+ 1 (ai+1 \u2212 bi ) =\n+1\nq\nq\ni=1\ni=1\n\u0012\n\u0013\nnr\n=\n+ 1 \u03b5.\nq\n\nai+1 P(ai+1 ) \u2212 bi P(bi )\nn\n\n<\n\n(B.5)\nSince 0 \u2264 P(\u03c1) \u2264 1, we have\nk\u22121\nX\n\n(B.6)\n\ni=1\n\nn\u22121\nn\n\nZ\n\nk\u22121\nn\u22121\nn\u22121 X\n(ai+1 \u2212 bi ) =\n\u03b5.\nn i=1\nn\n\nai+1\n\nbi\n\nP(\u03c1)d\u03c1 \u2264\n\nBy (B.4), (B.5), and (B.6),\nk\u22121\nX\u0014\ni=1\n\nai+1 P(ai+1 ) \u2212 bi P(bi ) n \u2212 1\n+\nn\nn\n\n(B.7)\n\nai+1\n\nbi\n\nP(\u03c1)d\u03c1\n\n\u0015\n\n<\n=\n\nP\n\nR\n\n\u0012\n\n\u0013\nnr\nn\u22121\n+1 \u03b5+\n\u03b5\nq\nn\n\u0013\n\u0012\nn\u22121\nnr\n\u03b5.\n+1+\nq\nn\n\n\u03c6(\u03c1)d\u03c1. By Lemmas 14 and 16,\n\"\n#\nZ\nX\nX Z\nbP(b) \u2212 aP(a) n \u2212 1 b\n\u03c6(\u03c1)d\u03c1 =\n+\nP(\u03c1)d\u03c1\nn\nn\na\n(a,b)\u2208I\u03b5\n(a,b)\u2208I\u03b5 (a,b)\n\u0013\n\u0015\nX \u0014\u0012 nr\nn\u22121\n+ 1 (b \u2212 a) +\n(b \u2212 a)\n<\nq\nn\n(a,b)\u2208I\u03b5\n\u0012\n\u0013 X\nnr\nn\u22121\n=\n(b \u2212 a)\n+1+\nq\nn\n(a,b)\u2208I\u03b5\n\u0013\n\u0012\nn\u22121\nnr\n\u03b5.\n=\n+1+\nq\nn\n\nNow we bound\n\n(B.8)\n\nZ\n\n(a,b)\u2208I\u03b5\n\n(a,b)\n\nTherefore, by (B.3), (B.4), (B.7) and (B.8),\n\u0014\n\u0015\nZ r\nZ\nrP(r) \u2212 qP(q) n \u2212 1 r\n\u03c6(\u03c1)d\u03c1 \u2212\n+\nP(\u03c1)d\u03c1\nn\nn\nq\nq\n\u0015\nk\u22121\nX Z\nX \u0014 ai+1 P(ai+1 ) \u2212 bi P(bi ) n \u2212 1 Z ai+1\n\u03c6(\u03c1)d\u03c1\nP(\u03c1)d\u03c1 +\n+\n\u2264\nn\nn\nbi\ni=1\n(a,b)\u2208I\u03b5 (a,b)\n\u0013\n\u0012\nnr\nn\u22121\n\u03b5.\n< 2\n+1+\nq\nn\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n\n29\n\nRr\n\nSince the above argument holds for arbitrarily small \u03b5 > 0, it must be true that\nRr\nrP(r)\u2212qP(q)\n+ n\u22121\nn\nn\nq P(\u03c1)d\u03c1. It follows that\nZ\n\nZ\n\nr\n\n\u03c6(\u03c1)d\u03c1\n\n=\n\n0\n\nq\n\n\u03c6(\u03c1)d\u03c1 +\n0\n\nZ\n\n\u03c6(\u03c1)d\u03c1\n\nq\n\nZ\n\nZ\n\nrP(r) n \u2212 1\n+\nn\nn\n\n=\n\n\u03c6(\u03c1) d\u03c1 =\n\nr\n\nqP(q) n \u2212 1\n+\nn\nn\n\n=\n\nq\n\nq\n\nP(\u03c1)d\u03c1 +\n\n0\n\nrP(r) \u2212 qP(q) n \u2212 1\n+\nn\nn\n\nr\n\nZ\n\nr\n\nP(\u03c1)d\u03c1\n\nq\n\nP(\u03c1)d\u03c1,\n\n0\n\nleading to the formula for P(r).\nRr\nTo show the formula for P(r), recall that rn P(r) = n 0 \u03c6(\u03c1) \u03c1n\u22121 d\u03c1. We write\nZ\n\n(B.9)\n\nZ\n\nr\n\n\u03c6(\u03c1)\u03c1\n\nn\u22121\n\nd\u03c1 =\n\n0\n\nq\n\n\u03c6(\u03c1)\u03c1\n\nn\u22121\n\nd\u03c1 +\n\n0\n\nZ\n\nr\n\n\u03c6(\u03c1)\u03c1n\u22121 d\u03c1.\n\nq\n\nBy Lemma 12, we can write\nZ\n\n(B.10)\n\nX\n\nr\n\n\u03c6(\u03c1)\u03c1\n\nn\u22121\n\nd\u03c1 =\n\nq\n\nc\u03b5\n(a,b)\u2208I\n\nZ\n\n\u03c6(\u03c1)\u03c1\n\nn\u22121\n\nX\n\nd\u03c1 +\n\n(a,b)\n\n(a,b)\u2208I\u03b5\n\nZ\n\n\u03c6(\u03c1)\u03c1n\u22121 d\u03c1.\n\n(a,b)\n\nR\nP\nn\u22121\nc\u03b5 as (ai , bi ), i = 1, * * * , k\nTo evaluate (a,b)\u2208I\nd\u03c1, we arrange the intervals in I\nc\u03b5 (a,b) \u03c6(\u03c1)\u03c1\nsuch that a1 = q, bi < ai+1 , i = 1, * * * , k \u2212 1 (Here k is the total number of intervals). Note that,\nby Lemma 15,\nX\n\nc\u03b5\n(a,b)\u2208I\n\nZ\n\n\u03c6(\u03c1)\u03c1\n\nn\u22121\n\nd\u03c1\n\n=\n\n(a,b)\n\nk\nX\ni=1\n\n(B.11)\n\n=\n\n\"\n\nbni P(bi )\n\n\u2212\n\nani P(ai )\n\n\u2212 (n \u2212 1)\n\nrn P(r) \u2212 q n P(q) \u2212 (n \u2212 1)\n\nZ\n\nZ\n\nbi\n\nP(\u03c1)\u03c1\n\nBy Lemma 17, we have |ani+1 P(ai+1 ) \u2212 bni P(bi )| <\n\ni=1\n\nani+1 P(ai+1 )\n\n\u2212\n\n\u0003\n\nbni P(bi )\n\n(B.13)\n\n<\n=\n\n(B.12)\n\nOn the other hand, observing that\nk\u22121 Z\nX\ni=1\n\nai+1\n\nbi\n\n#\n\nr\n\nP(\u03c1)\u03c1n\u22121 d\u03c1\n\nq\nai+1\n\nP(\u03c1)\u03c1\n\nn\u22121\n\nRb\na\n\n\u0010\n\n2r n\nq\n\n\u0011\n+ nrn\u22121 (ai+1 \u2212 bi ). Hence,\n\n\u0013X\nk\u22121\n2rn\nn\u22121\n(ai+1 \u2212 bi )\n+ nr\nq\ni=1\n\u0012 n\n\u0013\n2r\nn\u22121\n\u03b5.\n+ nr\nq\n\n\u0012\n\nP(\u03c1) \u03c1n\u22121 d\u03c1 < rn\u22121 (b \u2212 a), we have\n\nP(\u03c1)\u03c1n\u22121 d\u03c1 < rn\u22121\n\nk\u22121\nX\ni=1\n\n(ai+1 \u2212 bi ) = rn\u22121 \u03b5.\n\n\u0015\n\nd\u03c1 .\n\nbi\n\ni=1\n\n\u0002\n\nd\u03c1\n\nai\n\nZ\nk\u22121 \u0014\nX\nn\nn\nai+1 P(ai+1 ) \u2212 bi P(bi ) \u2212 (n \u2212 1)\n\u2212\n\nk\u22121\nX\n\nn\u22121\n\n\f30\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\nBy (B.11), (B.12) and (B.13),\nX\n\nc\u03b5\n(a,b)\u2208I\n\n<\n=\n(B.14)\n\n\u0012\n\n(a,b)\u2208I\u03b5\n\n(a,b)\n\n\u0014\nZ\n\u03c6(\u03c1)\u03c1n\u22121 d\u03c1 \u2212 rn P(r) \u2212 q n P(q) \u2212 (n \u2212 1)\n\nr\n\nP(\u03c1)\u03c1n\u22121 d\u03c1\n\nq\n\n\u0013\n\n\u0015\n\n2rn\n+ nrn\u22121 \u03b5 \u2212 (n \u2212 1)rn\u22121 \u03b5\nq\n\u0012 n\n\u0013\n2r\n+ rn\u22121 \u03b5.\nq\nP\n\nNow we bound\nX\n\nZ\n\nZ\n\n(a,b)\u2208I\u03b5\n\n\u03c6(\u03c1)\u03c1\n\nn\u22121\n\nd\u03c1\n\nR\n\n(a,b)\n\n\u03c6(\u03c1)\u03c1n\u22121 d\u03c1. By Lemmas 15 and 17,\nX\n\n=\n\n(a,b)\n\n(a,b)\u2208I\u03b5\n\n\"\n\nn\n\nn\n\nb P(b) \u2212 a P(a) \u2212 (n \u2212 1)\n\n\u0014\u0012\n\nZ\n\nb\n\nP(\u03c1)\u03c1\n\nn\u22121\n\na\n\nd\u03c1\n\n#\n\n\u0013\n\u0015\n2rn\nn\u22121\nn\u22121\n<\n(b \u2212 a) \u2212 (n \u2212 1)r\n(b \u2212 a)\n+ nr\nq\n(a,b)\u2208I\u03b5\n\u0013 X\n\u0012 n\n2r\nn\u22121\n(b \u2212 a)\n+r\n=\nq\n(a,b)\u2208I\u03b5\n\u0013\n\u0012 n\n2r\n=\n+ rn\u22121 \u03b5.\nq\nX\n\n(B.15)\n\nTherefore, by (B.10), (B.14) and (B.15),\nZ\n\n<\n\nZ\n\n0\n\nr\n\n\u0012\n\nr\n\nq\n\n\u0014\nZ\n\u03c6(\u03c1)\u03c1n\u22121 d\u03c1 \u2212 rn P(r) \u2212 q n P(q) \u2212 (n \u2212 1)\n\nn\n\n\u0013\n\n2r\n+ rn\u22121 \u03b5 +\nq\n\n\u0012\n\nn\n\n\u0013\n\n2r\n+ rn\u22121 \u03b5 = 2\nq\n\n\u0012\n\nq\n\nr\n\nP(\u03c1)\u03c1n\u22121 d\u03c1\n\n\u0013\n2r\nn\u22121\n\u03b5.\n+r\nq\nn\n\n\u0015\n\nSince the argument applies to arbitrarily small \u03b5 > 0, it must be true that\nh\ni\nRr\nrn P(r) \u2212 q n P(q) \u2212 (n \u2212 1) q P(\u03c1)\u03c1n\u22121 d\u03c1 . Therefore,\n\u03c6(\u03c1)\u03c1n\u22121 d\u03c1\n\n=\n\nZ\n\nq\n\n\u03c6(\u03c1)\u03c1n\u22121 d\u03c1 +\n\n0\n\n= q n P(q) \u2212 (n \u2212 1)\n= rn P(r) \u2212 (n \u2212 1)\n\nZ\n\nRr\nq\n\n\u03c6(\u03c1)\u03c1n\u22121 d\u03c1 =\n\nr\n\n\u03c6(\u03c1)\u03c1n\u22121 d\u03c1\n\nq\n\nZ\n\nZ\n\nq\n\nP(\u03c1)\u03c1n\u22121 d\u03c1 + rn P(r) \u2212 q n P(q) \u2212 (n \u2212 1)\n\n0\nr\n\nZ\n\nr\n\nP(\u03c1)\u03c1n\u22121 d\u03c1\n\nq\n\nP(\u03c1)\u03c1n\u22121 d\u03c1,\n\n0\n\nfrom which we find the formula for P(r).\nCase (4): In this case, let r\u2217 be the smallest positive cluster point. Let q = r2\u2217 . We can write\nRr\nRq\nRr\nRq\nqP(q)\n0 \u03c6(\u03c1)d\u03c1 = 0 \u03c6(\u03c1)d\u03c1 + q \u03c6(\u03c1)d\u03c1. Applying the result of Case (1), we have 0 \u03c6(\u03c1)d\u03c1 =\nn +\nR\nR\nr\nrP(r)\u2212qP(q)\nn\u22121 q\n+\nn R0 P(\u03c1)d\u03c1. By a method similar to that of Case (3), we have q \u03c6(\u03c1) d\u03c1 =\nn\nn\u22121 r\nP(\u03c1) d\u03c1. Combining the two integrals gives the formula for P(r). The proof for the\nn\nq\nformula of P(r) is similar.\n\n\fA STATISTICAL THEORY FOR THE ANALYSIS OF UNCERTAIN SYSTEMS\n\n31\n\nAppendix C. Proofs of Theorem 3 and 4\nFor completeness of argument, we need to quote a general complexity result established in [7] as Theorem\n5 at below. This theorem concerns the sampling complexity of the Sample Reuse Algorithm proposed in\npage 1963 of [5].\nTheorem 5. Let d be the dimension of uncertainty parameter space. Then, for arbitrary gridding scheme,\nthe equivalent number of grid points based on the Sample Reuse Algorithm [5] is strictly bounded from above\nby 1 + d ln \u03bb, i.e., meq < 1 + d ln \u03bb.\nProof. We first establish the following inequality (C.1) that will be used to prove Theorem 5.\n1\n+ ln x > 1,\nx\n\n(C.1)\nTo prove C.1, let f (x) =\nf (x) > 1, \u2200x > 1.\n\n1\nx\n\n\u2200x > 1.\n\n+ ln x. Then f (1) = 1 and\n\nd f (x)\ndx\n\n=\n\nx\u22121\nx2\n\n> 0, \u2200x > 1. It follows that\n\n\u0011d\n\u0010 \u0011d\nQm\u22121 \u0010\n= i=1 ri+1\n, we have\nNow we are in the position to prove Theorem 5. Observing that rrm1\nri\n\u0010 \u0011d P\n\u0011d\n\u0010\nri+1\nln rrm1\n= m\u22121\n. Therefore,\ni=1 ln\nri\n\uf8ee\n\uf8f9\n\u0012\n\u0012 \u0013d\n\u0013d\nm\u22121\nm\u22121\nX \u0012 ri \u0013d\nX\nri+1 \uf8fa\n1\nrm\n\uf8ef\n+ ln\n=\n\uf8f0\u0010\n\uf8fb.\n\u0011d + ln\nr\nr\nri\nri+1\ni+1\n1\ni=1\ni=1\nri\n\nSince\n\n\u0010\n\nHence,\n\nri+1\nri\n\n\u0011d\n\n> 1, i = 1, * * * , m\u22121, it follows from (C.1) that\n\nPm\u22121 \u0010\ni=1\n\nri\nri+1\n\n\u0011d\n\n+ ln\n\n\u0010\n\nrm\nr1\n\n\u0011d\n\n\" r 1 \"d\ni+1\nri\n\n> m \u2212 1, or equivalently, m \u2212\n\n+ln\n\nPm\u22121 \u0010\ni=1\n\n\u0010\n\nri\n\nri+1\n\nri+1\nri\n\n\u0011d\n\nFinally, by Theorem 1 of [5] and the definition of meq , we have meq = m \u2212\n\nC.1. Proof of Theorem 3. By Lemma 9, |P(r) \u2212 P \u2217 (r)| \u2264\n\nto show\n\n2 (ri+1 \u2212ri )\nri\n\n< \u01eb, i.e.,\n\n2 (ri+1 \u2212ri )\n,\nri\n\n\u0011d\n\n> 1 for i = 1, * * * , m\u22121.\n\n< 1 + ln\nPm\u22121 \u0010\ni=1\n\n\u0010\n\nrm\nr1\n\nri\nri+1\n\n\u0011d\n\n\u0011d\n\n= 1 + d ln \u03bb.\n< 1 + d ln \u03bb.\n\u2737\n\n\u2200r \u2208 [ri , ri+1 ]. Thus, it suffices\n\nri+1\n\u01eb\n<1+ .\nri\n2\nBy the definition of uniform griding, for i = 1, * * * , m \u2212 1,\n\n(C.2)\n\nri+1\nri\n\n=\n\n(m\u2212i\u22121)(\u03bb\u22121)\na\n(m\u22121)\u03bb\n(m\u2212i)(\u03bb\u22121)\n\u2212 (m\u22121)\u03bb a\n\na\u2212\na\n\n=1+\n\n\u03bb\u22121\n\u03bb\u22121\n\u22641+\n.\nm \u2212 1 + (\u03bb \u2212 1)(i \u2212 1)\nm\u22121\n\n\u03bb\u22121\nBy virtue of (C.2), to guarantee that the gridding error is less than \u01eb, it suffices to ensure 1 + m\u22121\n< 1 + 2\u01eb ,\nj\nk\nri\n. Hence, it suffices to have m \u2265 2 + 2(\u03bb\u22121)\n= 1 \u2212 m\u221211 +i\n. It can be verified that ri+1\ni.e., m > 1 + 2(\u03bb\u22121)\n\u01eb\n\u01eb\n\u03bb\u22121\n\nfor i = 1, * * * , m \u2212 1.\nLet nk be the total number of simulations on the direction associated with directional sample U k , k =\n1, * * * , N . Applying Theorem 1 of [5] and Theorem 5 in this paper to a sample reuse process conditioned\nPm\u22121 ri\n<\nupon a direction with grid points r1 , * * * , rm and sample size N = 1, we have E[nk | U k ] = m\u2212 i=1 ri+1\nPm\u22121 ri\nk\nk\nk\n1 + d ln \u03bb and consequently E[n ] = E[E[n | U ]] = m \u2212 i=1 ri+1 < 1 + d ln \u03bb for k = 1, * * * , N . Finally,\nthe proof is completed by invoking the definition of equivalent number of grid points.\n\n\f32\n\nXINJIA CHEN, KEMIN ZHOU AND JORGE L. ARAVENA\n\nC.2. Proof of Theorem 4. By the definition of uniform griding, we have\n1\n\nri+1\nri\n\n1\n\n= \u03bb m\u22121 . Hence, by (C.2),\n\nit suffices to show \u03bb m\u22121 < 1 + 2\u01eb , which can be reduced to m > 1 + ln ln1+\u03bb \u01eb . This inequality is equivalent\n( 2)\n\u0016\n\u0017\nln \u03bb\nk\nto m \u2265 2 + ln 1+ \u01eb . By letting n be the total number of simulations on the direction associated with\n( 2)\ndirectional sample U k , k = 1, * * * , N and applying Theorem 1 of [5] and Theorem 5 in this paper to a\nsample reuse process conditioned upon a direction with grid points r1 , * * * , rm and sample size N = 1,\n\u0001 1\nwe have E[nk | U k ] = m \u2212 (m \u2212 1) \u03bb1 m\u22121 < 1 + d ln \u03bb and consequently E[nk ] = E[E[nk | U k ]] =\n\u0001 1\nm \u2212 (m \u2212 1) \u03bb1 m\u22121 < 1 + d ln \u03bb for k = 1, * * * , N . The proof is completed by using the definition of\nequivalent number of grid points.\nDepartment of Electrical and Computer Engineering, Louisiana State University, Baton Rouge, LA 70803\nE-mail address: chan@ece.lsu.edu, kemin@ece.lsu.edu, aravena@ece.lsu.edu\n\n\f"}