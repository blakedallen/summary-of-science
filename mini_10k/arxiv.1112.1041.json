{"id": "http://arxiv.org/abs/1112.1041v1", "guidislink": true, "updated": "2011-12-05T19:57:44Z", "updated_parsed": [2011, 12, 5, 19, 57, 44, 0, 339, 0], "published": "2011-12-05T19:57:44Z", "published_parsed": [2011, 12, 5, 19, 57, 44, 0, 339, 0], "title": "Stabilization of Branching Queueing Networks", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1112.4239%2C1112.0141%2C1112.0258%2C1112.2729%2C1112.2023%2C1112.5847%2C1112.3748%2C1112.0160%2C1112.4891%2C1112.5157%2C1112.3901%2C1112.5510%2C1112.0044%2C1112.5838%2C1112.0719%2C1112.1897%2C1112.1366%2C1112.4878%2C1112.1696%2C1112.5836%2C1112.6187%2C1112.3531%2C1112.4192%2C1112.2883%2C1112.0937%2C1112.1074%2C1112.6129%2C1112.0754%2C1112.5256%2C1112.0069%2C1112.5046%2C1112.0189%2C1112.0553%2C1112.5268%2C1112.4524%2C1112.4533%2C1112.3994%2C1112.4169%2C1112.1544%2C1112.5514%2C1112.6083%2C1112.0428%2C1112.3334%2C1112.5628%2C1112.4907%2C1112.2847%2C1112.3268%2C1112.1419%2C1112.4176%2C1112.0711%2C1112.1076%2C1112.5426%2C1112.6307%2C1112.1396%2C1112.3455%2C1112.2788%2C1112.3060%2C1112.6279%2C1112.4391%2C1112.4103%2C1112.5971%2C1112.4017%2C1112.2641%2C1112.2546%2C1112.4874%2C1112.1378%2C1112.4153%2C1112.0345%2C1112.4658%2C1112.3573%2C1112.2564%2C1112.2425%2C1112.3946%2C1112.6365%2C1112.3956%2C1112.4873%2C1112.0017%2C1112.1131%2C1112.0558%2C1112.0477%2C1112.1333%2C1112.3732%2C1112.3613%2C1112.4138%2C1112.0099%2C1112.4974%2C1112.6025%2C1112.4304%2C1112.0537%2C1112.0735%2C1112.4062%2C1112.3841%2C1112.1041%2C1112.4267%2C1112.1324%2C1112.1026%2C1112.5613%2C1112.2714%2C1112.0029%2C1112.5485%2C1112.5217&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Stabilization of Branching Queueing Networks"}, "summary": "Queueing networks are gaining attraction for the performance analysis of\nparallel computer systems. A Jackson network is a set of interconnected\nservers, where the completion of a job at server i may result in the creation\nof a new job for server j. We propose to extend Jackson networks by \"branching\"\nand by \"control\" features. Both extensions are new and substantially expand the\nmodelling power of Jackson networks. On the other hand, the extensions raise\ncomputational questions, particularly concerning the stability of the networks,\ni.e, the ergodicity of the underlying Markov chain. We show for our extended\nmodel that it is decidable in polynomial time if there exists a controller that\nachieves stability. Moreover, if such a controller exists, one can efficiently\ncompute a static randomized controller which stabilizes the network in a very\nstrong sense; in particular, all moments of the queue sizes are finite.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1112.4239%2C1112.0141%2C1112.0258%2C1112.2729%2C1112.2023%2C1112.5847%2C1112.3748%2C1112.0160%2C1112.4891%2C1112.5157%2C1112.3901%2C1112.5510%2C1112.0044%2C1112.5838%2C1112.0719%2C1112.1897%2C1112.1366%2C1112.4878%2C1112.1696%2C1112.5836%2C1112.6187%2C1112.3531%2C1112.4192%2C1112.2883%2C1112.0937%2C1112.1074%2C1112.6129%2C1112.0754%2C1112.5256%2C1112.0069%2C1112.5046%2C1112.0189%2C1112.0553%2C1112.5268%2C1112.4524%2C1112.4533%2C1112.3994%2C1112.4169%2C1112.1544%2C1112.5514%2C1112.6083%2C1112.0428%2C1112.3334%2C1112.5628%2C1112.4907%2C1112.2847%2C1112.3268%2C1112.1419%2C1112.4176%2C1112.0711%2C1112.1076%2C1112.5426%2C1112.6307%2C1112.1396%2C1112.3455%2C1112.2788%2C1112.3060%2C1112.6279%2C1112.4391%2C1112.4103%2C1112.5971%2C1112.4017%2C1112.2641%2C1112.2546%2C1112.4874%2C1112.1378%2C1112.4153%2C1112.0345%2C1112.4658%2C1112.3573%2C1112.2564%2C1112.2425%2C1112.3946%2C1112.6365%2C1112.3956%2C1112.4873%2C1112.0017%2C1112.1131%2C1112.0558%2C1112.0477%2C1112.1333%2C1112.3732%2C1112.3613%2C1112.4138%2C1112.0099%2C1112.4974%2C1112.6025%2C1112.4304%2C1112.0537%2C1112.0735%2C1112.4062%2C1112.3841%2C1112.1041%2C1112.4267%2C1112.1324%2C1112.1026%2C1112.5613%2C1112.2714%2C1112.0029%2C1112.5485%2C1112.5217&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Queueing networks are gaining attraction for the performance analysis of\nparallel computer systems. A Jackson network is a set of interconnected\nservers, where the completion of a job at server i may result in the creation\nof a new job for server j. We propose to extend Jackson networks by \"branching\"\nand by \"control\" features. Both extensions are new and substantially expand the\nmodelling power of Jackson networks. On the other hand, the extensions raise\ncomputational questions, particularly concerning the stability of the networks,\ni.e, the ergodicity of the underlying Markov chain. We show for our extended\nmodel that it is decidable in polynomial time if there exists a controller that\nachieves stability. Moreover, if such a controller exists, one can efficiently\ncompute a static randomized controller which stabilizes the network in a very\nstrong sense; in particular, all moments of the queue sizes are finite."}, "authors": ["Tom\u00e1\u0161 Br\u00e1zdil", "Stefan Kiefer"], "author_detail": {"name": "Stefan Kiefer"}, "author": "Stefan Kiefer", "arxiv_comment": "technical report for a STACS'12 paper", "links": [{"href": "http://arxiv.org/abs/1112.1041v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1112.1041v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.PF", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.PF", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1112.1041v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1112.1041v1", "journal_reference": null, "doi": null, "fulltext": "Stabilization of Branching Queueing Networks\u2217\nTom\u00e1\u0161 Br\u00e1zdil1 and Stefan Kiefer2\n1\n\nFaculty of Informatics, Masaryk University, Czech Republic\nbrazdil@fi.muni.cz\nDepartment of Computer Science, University of Oxford, United Kingdom\nstefan.kiefer@cs.ox.ac.uk\n\n2\n\narXiv:1112.1041v1 [cs.PF] 5 Dec 2011\n\nAbstract\nQueueing networks are gaining attraction for the performance analysis of parallel computer systems. A Jackson network is a set of interconnected servers, where the completion of a job at\nserver i may result in the creation of a new job for server j. We propose to extend Jackson\nnetworks by \"branching\" and by \"control\" features. Both extensions are new and substantially\nexpand the modelling power of Jackson networks. On the other hand, the extensions raise computational questions, particularly concerning the stability of the networks, i.e, the ergodicity of\nthe underlying Markov chain. We show for our extended model that it is decidable in polynomial time if there exists a controller that achieves stability. Moreover, if such a controller exists,\none can efficiently compute a static randomized controller which stabilizes the network in a very\nstrong sense; in particular, all moments of the queue sizes are finite.\n1998 ACM Subject Classification G.3 Probability and Statistics\nKeywords and phrases continuous-time Markov decision processes, infinite-state systems, performance analysis\n\n1\n\nIntroduction\n\nQueueing theory plays a central role in the performance analysis of computer systems. In\nparticular, queueing networks are gaining attraction as models of parallel systems. A queueing\nnetwork is a set of processing units (called servers), each of which performs tasks (called\njobs) of a certain type. Each server has its own queue of jobs waiting to be processed. The\nsuccessful completion of a job may trigger one (or more) new jobs (of possibly different type)\nthat need to be processed as well. In addition to this \"internal\" job creation, so-called open\nqueueing networks allow for new jobs to arrive \"externally\", i.e., from outside.\nQueueing networks are a popular model for both hardware and software systems because\nof their simplicity and generality. On the hardware side, queueing networks can, e.g., be used\nfor modeling multi-core processors, see e.g. [30] and the references in [9]. One advantage of\nqueueing-based analyses is their scalability with growing parallelism; e.g., it is said in [21]:\n\"Cycle-accurate full-system performance simulators do not scale well beyond a few tens of\nprocessor cores at best. As such, analytical models based on the theory of queueing systems,\nare a logical choice for developing a basic understanding of the fundamental tradeoffs in\nfuture, large-scale multi-core systems.\" On the software side, queueing networks are used for\nmodeling message passing. It is said in [29]: \"Two natural classes of systems can be modeled\nusing such a framework: asynchronous programs on a multi-core computer and distributed\nprograms communicating on a network.\" Of course, the realm of queueing networks stretches\nfar beyond computer science, see [5, 8].\n\n\u2217\n\nS. Kiefer is supported by a DAAD postdoctoral fellowship.\n\u00a9 Tom\u00e1\u0161 Br\u00e1zdil and Stefan Kiefer;\nlicensed under Creative Commons License NC-ND\nLeibniz International Proceedings in Informatics\nSchloss Dagstuhl \u2013 Leibniz-Zentrum f\u00fcr Informatik, Dagstuhl Publishing, Germany\n\n\f2\n\nStabilization of Branching Queueing Networks\n\nThe simplest queueing networks are so-called Jackson networks [16]: Given two servers\npij\n\ni, j \u2208 {1, . . . , n}, there is a \"rule\" of the form i ,\u2212\u2212\u2192 j which specifies the probability pij that\npi0\nthe completion of an i-job results in the creation of a j-job. There are also rules i ,\u2212\u2212\u2192 \u03b5\nP\nwhere pi0 = 1 \u2212 j pij specifies the probability that no new job is created. Each server i has\na rate \u03bci with which an i-job is processed if there is one. In addition, there is a rate \u03b1i with\nwhich i-jobs arrive from outside the network. The processing times and the external arrivals\nare exponentially distributed, so that a Jackson network describes a continuous-time Markov\nchain (CTMC). It was shown in Jackson's paper [16] that if the rate \u03bbi of internal and\nexternal arrivals at server i is less than \u03bci for all i, then the network is stable, i.e., the average\nqueue length is finite and almost surely all queues are empty infinitely often. Moreover,\nJackson networks allow a product form, i.e., the steady-state distribution of the queue lengths\ncan be expressed as a product of functions \u03c0i (k), where \u03c0i (k) is the steady-state probability\nthat queue i has length k.\nI Example 1 (network processor). In [1], Jackson networks are used to model network\nprocessors, i.e., chips that are specifically targeted at networking applications-think of a\nrouter. We describe the model from [1] (sections 4.1 and 4.2, slightly adapted). Before\npackets are processed in the \"master processor\" M , they pass through the \"data plane\" D,\nfrom which a fraction q of packets needs to be processed first in the \"control plane\" C:\n1\u2212q\n\nD ,\u2212\u2212\u2192 M\n\nq\n\nD ,\u2212\n\u2192C\n\n1\n\nC ,\u2212\n\u2192M\n\n1\n\nM ,\u2212\n\u2192\u03b5\n\nAn \"arrival manager\" A sends some packets (fraction d0 ) directly to D, but others (fractions d1 , . . . , dn with d0 + d1 + * * * + dn = 1) are sent to \"slave processors\" S1 , . . . , Sn to assist\nthe master. Some packets (fraction b) still need the attention of the master after having been\nprocessed by a slave:\nd0\n\nA ,\u2212\u2192 D\n\ndi\n\nA ,\u2212\n\u2192 Si\n\nb\n\nSi ,\u2212\n\u2192D\n\n1\u2212b\n\nSi ,\u2212\u2212\u2192 \u03b5\n\n,\n\ni \u2208 {1, . . . , n}.\n\nJackson networks and their extensions have been thoroughly studied, but they are\nrestricted in their modelling capabilities, as (i) the completion of a job may trigger at\nmost one job, and (ii) there is no nondeterminism that would allow to control the output\nprobabilities of a server. Considering (i), it seems unnatural to assume that a distributed\nprogram communicating on a network produces at most one message at the end of its\ncomputation. Considering (ii), the \"arrival manager\" A in Example 1 may want to flexibly\npass incoming packets to the master or one of the slaves, possibly depending on the current\nload. These restrictions have not been fully addressed, not even in isolation. In this paper we\nintroduce controlled branching queueing networks, which are Jackson-like networks but allow\nfor both nondeterminism (\"controlled\") and the creation of more than one job (\"branching\").\nBoth extensions directly raise computational issues. We show in Example 2 on page 5\nthat even purely stochastic branching networks do not allow a product form, which illustrates\nthe mathematical challenge1 of this extension and poses the question for an effective criterion\nthat allows to determine whether the network is stable, i.e., returns to the empty state\ninfinitely often. Moreover, due to the nondeterminism, we now deal with continuous-time\nMarkov decision processes (CTMDPs). Our main theorem (Theorem 3) states that if there\nexists any scheduler resolving the nondeterminism in such a way that the controlled branching\n\n1\n\nIt is noted in [15] that \"[. . . ] virtually all of the models that have been successfully analyzed in classical\nqueueing network theory are models having a so-called product form stationary distribution.\"\n\n\fT. Br\u00e1zdil and S. Kiefer\n\nnetwork is stable, then there exists a randomized static scheduler that achieves stability as\nwell, where by \"randomized static\" we mean that the decisions may be randomized but not\ndependent on the current state (such as the load) of the system. Moreover, the existence of\nsuch a stabilizing scheduler and the scheduler itself can be determined in polynomial time,\nand, finally, the randomized static scheduler is stabilizing in a very strong sense, in particular,\nall moments of the queue sizes are finite.\nRelated work. We use nondeterminism to describe systems whose behaviour is not\ncompletely specified. A system designer can then resolve the nondeterminism to achieve\ncertain goals, in our case stability. Although nondeterminism is a very well established\nmodelling feature of probabilistic systems (see e.g. [20]), the literature on automatic design\nof stabilizing controllers for queueing networks is sparse. Flow-controlled networks [28, 22]\nallow to control only the external arrival stream or the service rates (see also [2] and the\nreferences therein). The authors of [19, 14] consider queueing networks with fewer servers\nthan job types, so that the controller needs to assign servers to queues. As in [19, 14], we\nalso use linear programming to design a controller, but our aim is different: we allow the\ncontroller to influence the production of the individual queues, and we study the complexity\nof designing stabilizing controllers and the nature of such controllers. There has been a\nsubstantial amount of work in the last years analyzing probabilistic systems with \"branching\nfeatures\", most prominently on recursive Markov chains [13, 12] and probabilistic pushdown\nsystems [11, 6]. While these models allow for a probabilistic splitting of tasks by pushing\nnew procedures on a stack, the produced tasks are processed in a strictly sequential manner,\nwhereas the queues in a queueing network process jobs in parallel and in continuous time.\nRecently, probabilistic split-join systems were introduced [17], which allow for branching but\nnot for external arrivals, and assume unlimited parallelism. In [18, chapter 8] a queueing\nmodel with multiple classes of tasks and \"feedback\" is discussed, which is similar to our\nbranching except that there is only one server, hence there is no parallelism. Algorithmic\ntheory of queueing systems has also attracted some attention in the past. In particular, for\nclosed (i.e., without external arrivals) queueing systems, [26] shows EXP-completeness of\nminimizing a weighted throughput of the queues.\n\n2\n\nPreliminaries\n\nNumbers. We use Z, Q, R for the sets of integer, rational, real numbers, respectively, and\nN, Q\u22650 , R\u22650 for their respective subsets of nonnegative numbers.\nVectors and Matrices. Let n \u2265 1. We use boldface letters for denoting vectors x =\n(x1 , . . . , xn ) \u2208 Rn . Vectors are row vectors per default, and we use superscript T for\ntranspose, so that xT denotes a column vector. If the dimension n is clear from the context,\nwe write 0 := (0, . . . , 0), 1 := (1, . . . , 1), and e(i) = (0, . . . , 0, 1, 0, . . . , 0) for the vector with\nthe 1 at the ith component (1 \u2264 i \u2264 n). It is convenient to define e(0) := 0. For two\nvectors x, y \u2208 Rn we write x \u223c y with \u223c \u2208 {=, <, \u2264, >, \u2265} if the respective relation holds\nPn\ncomponentwise. For a vector x \u2208 Rn we denote its 1-norm by kxk := i=1 |xi |. When\nx \u2208 Nn is a vector of queue sizes, we refer to kxk as the total queue size. For a matrix\nA \u2208 Rn\u00d7n , we write Ai for its ith row, i.e., Ai = (Ai1 , . . . , Ain ).\nCTMDP. A continuous-time Markov decision process (CTMDP) consists of an at most\ncountable set S of states, an initial state s1 \u2208 S, a set of actions \u03a3 2 , and a transition rate\n2\n\nUsually, each state has its own set of available actions. As this feature is not needed for queueing\nnetworks, we stick to the simpler version in which all actions are always available.\n\n3\n\n\f4\n\nStabilization of Branching Queueing Networks\n\nq(s, \u03c3, s0 ) \u2265 0 for each pair of states s, s0 \u2208 S and each action \u03c3 \u2208 \u03a3 (here q(s, \u03c3, s0 ) = 0\nmeans that the transition from s to s0 never occurs). We define a continuous-time Markov\nchain (CTMC) to be a CTMDP whose set of actions \u03a3 is a singleton (we usually do not\nwrite the only action explicitly, so the transition rates of a CTMC are denoted by q(s, s0 ),\netc.).\nIntuitively, a run of a CTMDP starts in s1 and then evolves in so-called epochs. Assume\nthat (after the previous epoch) the system is in a state s. The next epoch consists of the\nfollowing phases: First, a scheduler chooses an action \u03c3 \u2208 \u03a3 to be executed. Second, a waiting\ntime for transition to each state s0 \u2208 S is chosen according to the exponential distribution\nwith the rate q(s, \u03c3, s0 ) (here we assume that if q(s, \u03c3, s0 ) = 0, then the waiting time is \u221e).\nThe transitions compete in a way such that the one with the least waiting time is executed\nand the state of the CTMDP is chosen accordingly (the other transitions are subsequently\ndiscarded).\nFormally, a run is an infinite sequence s1 , \u03c31 , t1 , s2 , \u03c32 , t2 , . . . \u2208 (S \u00d7 \u03a3 \u00d7 R\u22650 )\u03c9 . We\ndenote by Run the set of all runs. A scheduler is a function \u0398 which assigns to every finite\npath s1 , \u03c31 , t1 , s2 , \u03c32 , t2 , . . . sn \u2208 (S \u00d7 \u03a3 \u00d7 R\u22650 )\u2217 \u00d7 S a probability distribution \u0398(w) on\nP\nactions (i.e. \u0398(w) : \u03a3 \u2192 [0, 1] satisfies \u03c3\u2208\u03a3 \u0398(w)(\u03c3) = 1). For technical reasons, we have\nto restrict ourselves to measurable schedulers (for details see e.g. [24]).\nWe work with a measurable space of runs (Run, F) where F is the smallest \u03c3-algebra\ngenerated by basic cylinders (i.e. sets of runs with common finite prefix) in a standard\nway. Every scheduler \u0398 induces a unique probability measure Pr\u0398 on F determined by the\nprobabilities of the basic cylinders. For detailed definitions see [24]. Then each scheduler \u0398\ninduces a stochastic process (x(t) | t \u2208 R\u22650 ) on the probability space (Run, F, Pr\u0398 ) where\nx(t) is the current state of the run in time t, i.e., each x(t) is a random variable defined by\nx(t)(s1 , \u03c31 , t1 , s2 , \u03c32 , t2 , . . .) = si\n\n,\n\ni\u22121\nX\nj=1\n\nti \u2264 t and\n\ni\nX\n\nti \u2265 t .\n\nj=1\n\nA scheduler \u0398 is memoryless if for every path w = s1 , \u03c31 , t1 , s2 , \u03c32 , t2 , . . . sn+1 \u2208 (S \u00d7 \u03a3 \u00d7\nR\u22650 )\u2217 \u00d7 S we have that \u0398(w) = \u0398(sn+1 ).\nNetworks. Define R(n,K) := {r \u2208 Nn | r 1 + * * * + r n \u2264 K}. A production function for\nP\n(n, K) is a function Prob : R \u2192 Q \u2229 (0, 1] with R \u2286 R(n,K) such that r\u2208R Prob(r) = 1. A\ncontrolled branching network with n queues and branching factor K consists of an arrival\nrate \u03bc0 \u2208 Q \u2229 (0, \u221e), queue rates \u03bci \u2208 Q \u2229 (0, \u221e) for i \u2208 {1, . . . , n}, an arrival production\nfunction Prob0 : R0 \u2192 Q \u2229 (0, 1] for (n, K), and finite action sets \u03a31 , . . . , \u03a3n as follows. An\naction \u03c3i \u2208 \u03a3i assigns to queue i a production function Probi (\u03c3i ) : Ri (\u03c3i ) \u2192 Q \u2229 (0, 1] for\n(n, K). Define \u03a3 := \u03a31 \u00d7 * * * \u00d7 \u03a3n . If \u03c3 = (\u03c31 , . . . , \u03c3n ) \u2208 \u03a3, we write Ri (\u03c3), Probi (\u03c3) and\nR0 (\u03c3), Prob0 (\u03c3) to mean Ri (\u03c3i ), Probi (\u03c3i ) and R0 , Prob0 . Observe that the rates \u03bci do not\ndepend on actions. This simplification is without loss of generality.3 We assume a nonzero\narrival stream, i.e., there is r \u2208 R0 with r 6= 0. We define the size of a controlled network\nPn\nPn P\nby n + K + ( i=0 |\u03bci |) + |R0 | + |Prob0 | + i=1 \u03c3i \u2208\u03a3i |Ri (\u03c3i )| + |Probi (\u03c3i )|, where |\u03bci | etc.\nmeans the description size assuming the rationals are represented as fractions of integers in\n\n3\n\nTo show that this assumption is w.l.o.g. one can employ the standard \"uniformization\" trick. More\nprecisely, assume that the actions of a queue i have different rates. Define \u03bci to be the maximum of\nall rates of \u03a3i and compensate by \"adding self-loops\", i.e., make the actions of \u03a3i generate a new job\nfor queue i with a suitable probability. This effectively substitutes a transition with longer delay by\npossibly several transitions with delay \u03bci . As static schedulers can be easily translated between the\noriginal and the transformed system, our results remain valid.\n\n\fT. Br\u00e1zdil and S. Kiefer\n\n5\n\nbinary. A controlled branching network induces a CTMDP with state space Nn (the queue\nsizes), initial state 0, action set \u03a3, and transition rates\nX\nX\nq(x, \u03c3, y) =\n\u03bci Probi (\u03c3)(r)\nfor x, y \u2208 Nn , \u03c3 \u2208 \u03a3.\ni\u2208{0,1,...,n}:i=0\u2228xi 6=0 r\u2208Ri (\u03c3):y=x\u2212e(i) +r\n\nInterpreting this definition, there is a \"race\" between external arrivals (rate \u03bc0 ) and the\nnonempty queues (rates \u03bci ); if the external arrivals win, new jobs are added according\nto Prob0 (\u03c3); if queue i wins, one i-job is removed and new jobs are added according\nto Probi (\u03c3).\nAn purely stochastic branching network is a controlled branching network with \u03a3 = {\u03c3},\ni.e., with a unique action for each queue. Hence, the induced CTMDP is a CTMC. In the\npurely stochastic case we write only Ri for Ri (\u03c3) etc. If Probi (r) = p in the purely stochastic\np\ncase, we use in examples the notation i ,\u2212\n\u2192 r, where we often write r \u2208 R(n,K) as a multiset\np\np\np\nwithout curly brackets. For instance, if n = 2, we write 1 ,\u2212\n\u2192 1, 2 and 1 ,\u2212\n\u2192 2, 2 and 1 ,\u2212\n\u2192 \u03b5 to\nmean Prob1 (r) = p with r = (1, 1) and r = (0, 2) and r = (0, 0), respectively.\nFixing a controlled network N and a scheduler \u0398 for the CTMDP induced by N , we\nobtain a stochastic process N\u0398 = (x(t) | t \u2208 R\u22650 ), where x(0) = 0 \u2208 Nn , which evolves\naccording to the dynamics of N and the scheduler \u0398. In the purely stochastic case we drop\nthe subscript \u0398, and so we identify a network N with its induced stochastic process.\nI Example 2 (no product form). Consider the purely stochastic branching network with\n1\n\n1\n\n1\n\n0 ,\u2212\n\u2192 1, 2 and 1 ,\u2212\n\u2192 \u03b5 and 2 ,\u2212\n\u2192 \u03b5. If its stationary distribution \u03c0 (for a definition of stationary\ndistribution see before Theorem 3) had product from, the queues would be \"independent in\nsteady-state\", i.e., \u03c0(x2 \u2265 1 | x1 \u2265 1) = \u03c0(x2 \u2265 1), where by x we mean x(t) in steady state.\nHowever, if \u03bc0 is much smaller than \u03bc1 = \u03bc2 , then we have \u03c0(x2 \u2265 1 | x1 \u2265 1) > \u03c0(x2 \u2265 1),\nintuitively because x1 \u2265 1 probably means that there was an arrival recently, so that x2 \u2265 1\nis more likely than usual. More concretely, let \u03bc0 = 1 and \u03bc1 = \u03bc2 = 3 and consider the\n2-state Markov chain obtained by assuming that each arrival leads to the state (1, 1) and each\ncompletion of any job leads to the state (0, 0). By computing the stationary distribution \u03c0 0 of\nthis 2-state Markov chain in the standard way, we obtain \u03c0 0 ((0, 0)) = 6/7 and \u03c0 0 ((1, 1)) = 1/7.\nSince this 2-state Markov chain \"underapproximates\" the CTMC induced by the network,\nwe have \u03c0(x1 \u2265 1 \u2227 x2 \u2265 1) \u2265 1/7. On the other hand, by considering the two queues\nseparately, the standard formula for the M/M/1 queue gives \u03c0(x1 \u2265 1) = \u03c0(x2 \u2265 1) = 1/3.\nProduct form would imply \u03c0(x1 \u2265 1 \u2227 x2 \u2265 1) = \u03c0(x1 \u2265 1) * \u03c0(x2 \u2265 1) = 1/9, contradicting\nthe inequality above.\n\n3\n\nResults\n\nWe focus on the stability of purely stochastic and controlled branching networks. Our notion\nof stability requires that the network is completely empty infinitely many times. Given a\nstochastic process (x(t) | t \u2208 R\u22650 ), we say that the process is ergodic if the expected return\ntime to 0 is finite. More formally, define a random variable R by\nR\n\n:=\n\ninf {t | x(t) = 0, \u2203t0 < t : x(t0 ) 6= 0} .\n\nt>0\n\nThen the process is ergodic iff E [R] < \u221e. In the controlled case, we say that a scheduler \u0398\nfor N is ergodic for N if N\u0398 is ergodic. In the following we use stability and ergodicity\ninterchangeably. A scheduler \u0398 is static if it always chooses the same fixed distribution on\nactions. Note that static schedulers are memoryless. If in a stochastic process (x(t) | t \u2208 R\u22650 )\n\n\f6\n\nStabilization of Branching Queueing Networks\n\nthe limit \u03c0(x) := limt\u2192\u221e Pr(x(t) = x) exists for all x \u2208 Nn and\n\u03c0 : R\u22650 \u2192 [0, 1] is called the stationary distribution.\n\nP\n\nx\u2208Nn\n\n\u03c0(x) = 1, then\n\nI Theorem 3. Let N be a controlled branching network. It is decidable in polynomial time\nwhether there exists an (arbitrary) ergodic scheduler for N . If it exists, one can compute, in\npolynomial time, a static randomized ergodic scheduler for N with stationary distribution \u03c0\nsuch that there exists an exponential moment of the total number of waiting jobs, i.e., there\nP\nis \u03b4 > 0 such that x\u2208Nn exp(\u03b4 kxk)\u03c0(x) exists.\nTo prove Theorem 3 we generalize the concept of traffic equations (see e.g. [7]) from the\ntheory of Jackson networks. Intuitively, the traffic equations express the fact that the inflow\nof jobs to a given queue must be equal to the outflow. Remarkably, the traffic equations\ncharacterize the stability of the Jackson network. More precisely, a Jackson network is stable\nif and only if there is a solution of the traffic equations whose components are strictly smaller\nthan the rates of the corresponding queues (we call such a solution deficient).\nWe show how to extend the traffic equations so that they characterize the stability of\ncontrolled branching networks. For a smooth presentation, we start with purely stochastic\nbranching networks and add control later on. Hence, the overall plan of the proof of Theorem 3\nis as follows: Set up traffic equations for purely stochastic branching networks and show\nthat if there is a deficient solution of these equations, then the network is stable. This\nresult, presented in Section 3.1 (Proposition 4), is of independent interest and requires the\nconstruction of a suitable Lyapunov function. Then, in Section 3.2, we generalize the traffic\nequations to controlled branching networks and show that any ergodic scheduler determines\na deficient solution (Proposition 10). This solution naturally induces a static scheduler,\nwhich, when fixed, determines an purely stochastic network with deficiently solvable traffic\nequations. Propositions 4 and 10 imply Theorem 3 and provide some additional results.\n\n3.1\n\nPurely stochastic branching networks\n\nAssume that N is purely stochastic, i.e., there is a single action for each queue. In such a case\nthe CTMDP induced by the network is in fact a CTMC. We associate the following quantities\nto a network, which will turn out to be crucial for its performance. Let \u03bc := (\u03bc1 , . . . , \u03bcn ).\nP\nLet \u03b1 \u2208 Rn\u22650 be the vector with \u03b1i := \u03bc0 r\u2208R0 Prob0 (r)r i ; i.e., \u03b1i indicates the expected\nnumber of external arrivals at queue i per time unit. Note that \u03b1 6= 0, as we assume a\nP\nnonzero arrival stream. Let A \u2208 Rn\u00d7n\n\u22650 be the matrix with Aij :=\nr\u2208Ri Prob i (r)r j ; i.e., Aij\nindicates the expected production of j-jobs when queue i fires. W.l.o.g. we assume that all\nqueues are \"reachable\", i.e., for all queues i there is j \u2208 N with (\u03b1Aj )i =\n6 0. We define a set\nof traffic equations\n\u03bbj\n\n=\n\n\u03b1j +\n\nn\nX\n\n\u03bbi * Aij\n\n,\n\nj \u2208 {1, . . . , n},\n\n(1)\n\ni=1\n\nin matrix form:\n\u03bb = \u03b1 + \u03bbA .\n\n(2)\n\nWe prove the following proposition.\nI Proposition 4. Assume that \u03bb \u2208 Rn\u22650 solves the traffic equations (2) and satisfies \u03bb < \u03bc.\nThen the following conclusions hold:\n1. The process N is ergodic, i.e., the expected return time to 0 is finite.\n\n\fT. Br\u00e1zdil and S. Kiefer\n\n7\n\n2. There exists a stationary distribution \u03c0 such that there exists an exponential moment of\nP\nthe total queue size, i.e., there is \u03b4 > 0 such that x\u2208Nn exp(\u03b4 kxk)\u03c0(x) exists.\nThe key step to the proof of Proposition 4 is to construct a so-called Lyapunov function with\nrespect to which the process N exhibits a \"negative drift\". This is in fact a classical technique\nfor showing the stability of queueing systems [23]; the difficulty lies in finding a suitable\nLyapunov function. The \"drift\" of N is given by the mean velocity vector \u2206(x) \u2208 Rn\u22650\nof N , defined by \u2206(x) := limh\u21920+ E [x(t + h) \u2212 x(t) | x(t) = x] /h. The limit exists, is\nindependent of t, and we have\nX\n\u2206(x) = \u03b1 +\n\u03bci (\u2212e(i) + Ai ) .\n(3)\ni:xi 6=0\n\nThe following lemma is implicitly proved in [10, theorem 1].\nI Lemma 5. Suppose that a function Ve : Rn\u22650 \u2192 R\u22650 is two times continuously differentiable,\nVe (x) = 0 implies x = 0, and that there is \u03b3 > 0 such that we have\n\u2206(x) Ve 0 (x)\n\n\u0001T\n\n\u2264 \u2212\u03b3\n\nfor all x 6= 0,\n\nwhere Ve 0 (x) denotes the gradient of Ve at x. Then the conclusions of Proposition 4 holds.\nFollowing [10], we construct the Lyapunov function Ve in two stages: we first define a suitable\npiecewise linear function V : Nn \u2192 R\u22650 ; then V is smoothed to obtain Ve . For the definition\nof V we need the following lemma.\nP\u221e\nI Lemma 6. The matrix series A\u2217 := i=0 Ai converges (\"exists\") in Rn\u00d7n\n\u22650 and is equal to\n(I \u2212 A)\u22121 .\nDefine vectors q (1) , . . . , q (n) \u2208 Rn\u22650 by setting q (i)T := a(i)T / a(i) , where a(i)T is the ith\ncolumn of A\u2217 . Observe that we have 1q (i)T = 1 for all i. Define the function V : Rn\u22650 \u2192 R\u22650\nby V (x) := maxi {xq (i)T }. We will use the following property of V :\nI Lemma 7. If 0 6= x \u2208 Rn\u22650 and xi = 0, then xq (i)T < V (x).\nLemma 7 is not obvious; in the appendix we use Farkas' lemma for the proof. The following\nlemma describes the crucial \"negative drift\" property of V :\nI Lemma 8. There is \u03b3 > 0 such that we have\n\u0001T\n\u2206(x) V 0 (x) \u2264 \u2212\u03b3\nfor all x 6= 0\nand all subgradient vectors V 0 (x) of V at x. More precisely, one can choose\n\u03b3 := min(\u03bci \u2212 \u03bbi )/ a(i) ,\ni\n\nwhere a(i)T is the ith column of A\u2217 .\nI Example 9. Consider the network with\n1/5\n\n1\n\n0 ,\u2212\n\u21921\n\n1 ,\u2212\u2212\u2192 2, 2\n4/5\n\n1 ,\u2212\u2212\u2192 \u03b5\n\n1/6\n\n2 ,\u2212\u2212\u2192 1, 2\n5/6\n\n,\n\n2 ,\u2212\u2212\u2192 \u03b5\n\narrival rate \u03bc0 = 7/30, and \u03bc = (5/12, 7/20), so that \u03bc0 + \u03bc1 + \u03bc2 = 1. Let us write\n[0] := \u03b1 = \u03bc0 (1, 0), [1] := \u03bc1 (\u2212e(1) + A1 ), [2] := \u03bc2 (\u2212e(2) + A2 ), [01] := [0] + [1],\n\n\f8\n\nStabilization of Branching Queueing Networks\n\nx2\n3\nx2\n0.2\n2\n\n[1]\n[2]\n\n[01]\n[0]\n\nx1\n\n0.2\n\n1\n\n[012]\n[02]\n\n[012]\n[02]\n\n[2]\n\n[0]\n\n[1]\n\n[01]\n1\n\n(a)\n\n2\n\n3\n\nx1\n\n(b)\n\nFigure 1 Illustration of negative drift.\n\n[02] := [0] + [2], [012] := [0] + [1] + [2]. These vectors are shown in Figure 1 (a). The\nmean velocity vector \u2206(x) is one of the vectors [0], [01], [02], [012], depending on which\ncomponents of x are nonzero. The vector field in Figure 1 (b) shows the corresponding\nvectors for several x \u2208 N2 . The connected line segments indicate points x with the same\nvalue of V (x) = max{xq (1)T , xq (2)T } = max{ 56 x1 + 16 x2 , 27 x1 + 57 x2 } (values 0.5, 1, 1.5, . . .).\nIt can be seen from the figure that the drift is negative with respect to the gradient of V , if\nx 6= 0.\nProof of Lemma 8. Let x 6= 0. We need to show \u2206(x)q (i)T \u2264 \u2212\u03b3 for all i with xq (i)T =\nV (x). W.l.o.g. we assume that xq (1)T = V (x) and show only \u2206(x)q (1)T \u2264 \u2212\u03b3. By Lemma 7\nwe have x1 6= 0. It follows from the property (I \u2212 A)A\u2217 = I and the definition of q (1) that\nwe have\n(\u2212e(1) + A1 )q (1)T = \u22121/ a(1)\n\nand\n\n(\u2212e(i) + Ai )q (1)T = 0\n\nfor 2 \u2264 i \u2264 n. (4)\n\nHence we have:\n\uf8eb\n\u2206(x)q (1)T = \uf8ed\u03b1 +\n\n\uf8f6\nX\n\n\u03bci (\u2212e(i) + Ai )\uf8f8 q (1)T\n\nby (3)\n\ni:xi 6=0\n\n= \u03b1q (1)T \u2212 \u03bc1 / a(1)\n\nby (4) and x1 6= 0\n\n\u2264 \u2212\u03b3 + \u03b1q (1)T \u2212 \u03bb1 / a(1)\n= \u2212\u03b3 +\n\n\u03b1+\n\nn\nX\n\nby the definition of \u03b3\n!\n\n\u03bbi (\u2212e(i) + Ai ) q (1)T\n\nby (4)\n\ni=1\n\n= \u2212\u03b3 + (\u03b1 + \u03bb(\u2212I + A)) q (1)T\n= \u2212\u03b3 + 0q (1)T = \u2212\u03b3\n\nby the traffic equation.\nJ\n\n\fT. Br\u00e1zdil and S. Kiefer\n\n9\n\nUsing integration, one can obtain a two times continuously differentiable function Ve satisfying\nthe conditions in Lemma 5: the function V is smoothed by defining Ve (x), for all x, as an\n\"average\" of the values V (y) where y belongs to a small ball around x; see the appendix\nof [10] for the formal details. This concludes the proof of Proposition 4.\n\n3.2\n\nControlled branching networks\n\nIn this subsection we generalize the traffic equations (2) to deal with an arbitrary controlled\nbranching network N . To obtain a distribution on actions for a static randomized ergodic\nscheduler, we assign variables to actions instead of queues, i.e., for every action \u03be of the\nnetwork we introduce a variable \u03bb\u03be capturing the rate of firing the action \u03be. Denote by \u03a3\u0304\nSn\nthe set i=1 \u03a3i . Given \u03b6 \u2208 \u03a3\u0304 and j \u2208 {1, . . . , n}, we denote by A\u03b6j the average number of\njobs added to the queue j when the action \u03b6 fires, i.e., for \u03b6 \u2208 \u03a3i we set\nX\nA\u03b6j :=\nProbi (\u03b6)(r) * r j .\nr\u2208Ri (\u03b6)\n\nWe generalize (2) to the traffic LP presented in Figure 2, where the variable \u03b4 is intended to\nbound, for all j, the probability that queue j is busy.\n\nmin \u03b4 subject to\n\nX\n\n\u03bb\u03be\n\n=\n\n\u03b1j +\n\nn X\nX\n\n\u03bb\u03b6 * A\u03b6j\n\nj \u2208 {1, . . . , n}\n\ni=1 \u03b6\u2208\u03a3i\n\n\u03be\u2208\u03a3j\n\nP\n\u03b4\n\n\u2265\n\n\u03bb\u03be\n\n\u2265\n\n\u03be\u2208\u03a3j\n\n\u03bb\u03be\n\n\u03bcj\n0\n\nj \u2208 {1, . . . , n}\n\u03be \u2208 \u03a3\u0304\n\nFigure 2 The traffic LP.\n\nWe prove the following\nI Proposition 10.\n1. If there exists an arbitrary ergodic scheduler for N , then the traffic LP can be solved with\nmin \u03b4 < 1.\n2. If the traffic LP is solved with min \u03b4 < 1, one can compute in polynomial time a\nstatic randomized ergodic scheduler \u0398s for N . Moreover, denoting by \u03c1i the utilization limt\u2192\u221e Pr(xi (t) 6= 0) of the queue i, the scheduler \u0398s minimizes maxi \u03c1i among all\nmemoryless ergodic schedulers.\nHence one can decide in polynomial time whether an arbitrary ergodic scheduler exists; if\nyes, one can compute in polynomial time a static randomized ergodic scheduler.\nLet us first concentrate on part 1. Let \u0398 be an ergodic scheduler. Roughly speaking, we\nprove that a feasible solution of the traffic LP can be constructed using (limit) frequencies of\nfiring individual actions in N\u0398 . Formally, given a run \u03c9 of N\u0398 , t \u2208 R\u22650 and \u03be \u2208 \u03a3\u0304, we denote\nby O\u03be\u2264t (\u03c9) the number of times the action \u03be is fired up to time t on \u03c9. For memoryless \u0398 we\nhave the following result.\n\n\f10\n\nStabilization of Branching Queueing Networks\n\nI Lemma 11. Assume that \u0398 is a memoryless ergodic scheduler. For every \u03be \u2208 \u03a3\u0304 there is a\nconstant O\u03be such that for almost all runs \u03c9 of N\u0398 the limit\nlim\n\nO\u03be\u2264t (\u03c9)\nt\n\nt\u2192\u221e\n\n\u0001\nexists and is equal to O\u03be . There is \u03b4\u0304 < 1 such that \u03b4\u0304, O\u03be | \u03be \u2208 \u03a3\u0304 solves the traffic\nLP.\nP\nMoreover, for every i \u2208 {1, . . . , n} the utilization \u03c1i of the queue i in N\u0398 is equal to\n\n\u03be\u2208\u03a3i\n\nO\u03be\n\n\u03bci\n\n.\n\nWe prove Lemma 11 in Appendix A.3. If there exists an arbitrary (i.e. possibly historydependent) ergodic scheduler, then by Theorem 7.3.8 of [27] there exists also a memoryless\n(and deterministic) ergodic scheduler.4 This fact, combined with Lemma 11, implies part 1.\nof Proposition 10.\nNow let us concentrate on part 2. of Proposition 10.\n\u0001\nI Lemma 12. Any feasible solution \u03b4\u0304, \u03bb\u0304\u03be | \u03be \u2208 \u03a3\u0304 of the traffic LP with \u03b4\u0304 < 1Pinduces a\nstatic randomized ergodic scheduler whose utilization of any queue i is equal to\n\n\u03be\u2208\u03a3i\n\n\u03bci\n\n\u03bb\u0304\u03be\n\n.\n\nProof. We construct a static randomized scheduler \u0398 which chooses an action \u03be \u2208 \u03a3i for\nthe queue i with probability\nP\u03be = P\n\n\u03bb\u0304\u03be\n\n\u03b6\u2208\u03a3i\n\n,\n\n\u03bb\u0304\u03b6\n\nX\n\n\u03bb\u0304\u03b6 > 0 .\n\n(5)\n\n\u03b6\u2208\u03a3i\n\nP\nOtherwise, if \u03b6\u2208\u03a3i \u03bb\u0304\u03b6 = 0, we may control the queue i arbitrarily because no jobs ever\ncome to the queue. We further assume (w.l.o.g.) that such queues have been removed from\nP\nthe network, i.e., that P\u03be is defined using (5) for all \u03be \u2208 \u03a3\u0304. Note that \u03be\u2208\u03a3i P\u03be = 1 for every\ni \u2208 {1, . . . , n}.\nFixing the scheduler \u0398 we obtain a purely stochastic branching network whose traffic\nequations are deficiently solvable. Formally, we define a new purely stochastic branching\nnetwork N 0 with n queues with the same arrival rate, the same arrival production function\nS\nand the same queue rates as N . Further, N 0 has Ri0 = \u03be\u2208\u03a3i Ri (\u03be) and the following\nproduction functions Prob0i associated to queues:\nX\nProb0i (r) =\nP\u03be * Probi (\u03be)(r) , r \u2208 Ri0\n\u03be\u2208\u03a3i\n\n(Here we formally assume Probi (\u03be)(r) = 0 for r 6\u2208 R\u03be .) The traffic equations (1) for N 0 have\nthe following form:\n\u03bbj\n\n=\n\n\u03b1j +\n\nn\nX\n\n\u03bbi * A0ij\n\nj \u2208 {1, . . . , n}\n\n,\n\n(6)\n\ni=1\n\nwith\nA0ij :=\n\nX\n\nProb0i (r) * r j =\n\nr\u2208Ri0\n\nP\u03be\n\n\u03be\u2208\u03a3i\n\n=\n\n\u03bb\u0304\u03be\n\nX\nP\n\u03be\u2208\u03a3i\n\n4\n\nX\n\n\u03b6\u2208\u03a3i\n\nX\n\u03bb\u0304\u03b6\n\nr\u2208Ri0\n\nX\n\nProbi (\u03be)(r) * r j =\n\nr\u2208Ri0\n\nProbi (\u03be)(r) * r j =\n\n\u03bb\u0304\u03be\n\nX\nP\n\u03be\u2208\u03a3i\n\n\u03b6\u2208\u03a3i\n\n\u03bb\u0304\u03b6\n\n* A\u03bej .\n\nTo be formally correct, we apply Theorem 7.3.8 of [27] to the embedded discrete time MDP and obtain\na scheduler which returns to the state 0 in finitely many steps (on average). As there are only finitely\nmany rates in our system, this means that also the expected return time to 0 is finite.\n\n\fT. Br\u00e1zdil and S. Kiefer\n\n11\n\nP\nP\nSetting \u03bbi := \u03be\u2208\u03a3i \u03bb\u0304\u03be for every i \u2208 {1, . . . , n}, we obtain \u03bbi A0ij = \u03be\u2208\u03a3i \u03bb\u0304\u03be A\u03bej . If we put\nthis equality into the first equation of the traffic LP, we see that (\u03bb1 , . . . , \u03bbn ) solves (6). Also,\n\u03bbj < \u03bcj for all j \u2208 {1, . . . , n}. Proposition 4 then implies that the scheduler \u0398 is ergodic.\nFinally, let us concentrate on the utilization. Note that the utilization of any queue i is\nthe same in N 0 as in N\u0398 , so it suffices to concentrate on N 0 . Observe that the matrix I \u2212 A0\nis invertible by Lemma 6. This means that (\u03bb1 , . . . , \u03bbn ) is, in fact, the unique solution of (6).\nThen however,P\nby Lemma 11, the utilization \u03c1i of queue i in N 0 (and thus also in N\u0398 ) is\nequal to\n\n\u03bbi\n\u03bci\n\n=\n\n\u03be\u2208\u03a3i\n\n\u03bb\u0304\u03be\n\n\u03bci\n\n.\n\nJ\n\nTo complete the proof of Proposition 10, we consider the problem of minimizing the maximal\nutilization maxi \u03c1i . Let \u0398s be a static randomized ergodic scheduler induced by a solution\nof the traffic LP in the sense of Lemma 12 (here we consider a solution which minimizes \u03b4).\nObserve that the scheduler \u0398s minimizes maxi \u03c1i among all schedulers induced by solutions\nof the traffic LP. However, by Lemmas 11 and 12, for every memoryless scheduler \u0398 there\nexists a static randomized scheduler induced by a solution of the traffic LP which has the\nsame utilization of each queue as \u0398. Thus \u0398s minimizes maxi \u03c1i among all memoryless\nergodic schedulers.\n\n4\n\nConclusions\n\nWe have suggested and studied controlled branching networks, a queueing model which\nextends Jackson networks by nondeterministic and branching features as required to model\nparallel systems. Although much of the classical theory (such as product-form stationary\ndistributions) no longer holds for controlled branching networks, we have shown that the\ntraffic equations can be generalized. This enabled us to construct a suitable Lyapunov\nfunction which we have used to establish strong stability properties. We have shown for\nthe controlled model that static randomized schedulers are sufficient to achieve those strong\nstability properties. Linear programming can be used to efficiently compute such a scheduler,\nwhich at the same time minimizes the maximal queue utilization.\nFuture work should include the investigation of more performance measures, e.g., the\nlong-time average queue size. Can non-static schedulers help to minimize it?\nReferences\n1\n\n2\n3\n4\n5\n6\n\n7\n\nM. Ahmadi and S. Wong. A performance model for network processor architectures in\npacket processing system. In Proceedings of the 19th IASTED International Conference on\nParallel and Distributed Computing and Systems, pages 176\u2013181. ACTA Press, 2007.\nA. Azaron and S.M.T. Fatemi Ghomi. Optimal control of service rates and arrivals in\nJackson networks. European Journal of Operational Research, 147(1):17\u201331, 2003.\nA. Berman and R.J. Plemmons. Nonnegative matrices in the mathematical sciences. Academic Press, 1979.\nP. Billingsley. Probability and Measure. Wiley, 1995.\nG. Bolch, S. Greiner, H. de Meer, and K.S. Trivedi. Queueing Networks and Markov Chains.\nJohn Wiley and Sons, 2006.\nT. Br\u00e1zdil, S. Kiefer, A. Ku\u010dera, and I. Huta\u0159ov\u00e1 Va\u0159ekov\u00e1. Runtime analysis of probabilistic programs with unbounded recursion. In Proceedings of ICALP, volume 6756 of LNCS,\npages 319\u2013331, 2011.\nH. Chen and D. Yao. Fundamentals of Queueing Networks. Springer, 2001.\n\n\f12\n\nStabilization of Branching Queueing Networks\n\n8\n9\n\n10\n11\n12\n13\n14\n\n15\n\n16\n17\n\n18\n19\n\n20\n21\n\n22\n23\n24\n\n25\n26\n27\n28\n29\n30\n\nJ. Daigle. Queueing Theory with Applications to Packet Telecommunication. Springer,\n2010.\nJ.D. Deng and M.K. Purvis. Multi-core application performance optimization using a\nconstrained tandem queueing model. Journal of Network and Computer Applications, In\nPress, Corrected Proof, 2011. DOI: 10.1016/j.jnca.2011.07.004.\nD. Down and S.P. Meyn. Piecewise linear test functions for stability and instability of\nqueueing networks. Queueing Systems, 27:205\u2013226, 1997.\nJ. Esparza, A. Ku\u010dera, and R. Mayr. Model checking probabilistic pushdown automata. In\nLICS 2004, pages 12\u201321. IEEE, 2004.\nK. Etessami, D. Wojtczak, and M. Yannakakis. Recursive stochastic games with positive\nrewards. In Proceedings of ICALP 2008, pages 711\u2013723, 2008.\nK. Etessami and M. Yannakakis. Recursive Markov chains, stochastic grammars, and\nmonotone systems of nonlinear equations. Journal of the ACM, 56(1):1\u201366, 2009.\nK.D. Glazebrook and J. Ni\u00f1o-Mora. A linear programming approach to stability, optimisation and performance analysis for Markovian multiclass queueing networks. Annals of\nOperations Research, 92:1\u201318, 1999.\nJ.M. Harrison and R.J. Williams. Brownian models of feedforward queueing networks:\nQuasireversibility and product form solutions. Annals of Applied Probability, 2(2):263\u2013293,\n1992.\nJ.R. Jackson. Networks of waiting lines. Operations Research, 5(4):518\u2013521, 1957.\nS. Kiefer and D. Wojtczak. On probabilistic parallel programs with process creation and\nsynchronisation. In Proceedings of TACAS, volume 6605 of LNCS, pages 296\u2013310. Springer,\n2011.\nM.Y. Kitaev and V.V.Rykov. Controlled queueing systems. CRC Press, 1995.\nP.R. Kumar and S.P. Meyn. Duality and linear programs for stability and performance\nanalysis of queueing networks and scheduling policies. IEEE Transactions on Automatic\nControl, 42(1):4\u201317, 1996.\nM. Kwiatkowska, G. Norman, and D. Parker. Prism 4.0: Verification of probabilistic realtime systems. In Proceedings of CAV, volume 6806 of LNCS, pages 585\u2013591, 2011.\nN. Madan, A. Buyuktosunoglu, P. Bose, and M. Annavaram. A case for guarded power\ngating for multi-core processors. In High Performance Computer Architecture (HPCA),\npages 291\u2013300, 2011.\nW.A. Massey and R. Srinivasan. A heavy traffic analysis for semi-open networks. Performance Evaluation, 13(1):59\u201366, 1991.\nS.P. Meyn and R.L. Tweedie. Markov Chains and Stochastic Stability. Springer, 1993.\nM. Neuh\u00e4usser, M. Stoelinga, and J.-P. Katoen. Delayed nondeterminism in continuoustime Markov decision processes. In Proceedings of FoSSaCS 2009, volume 5504 of LNCS,\npages 364\u2013379. Springer, 2009.\nJ.R. Norris. Markov Chains. Oxford University Press, first edition, 1998.\nC.H. Papadimitriou and J.N. Tsitsiklis. The complexity of optimal queueing network control. Mathematics of Operations Research, 24:293\u2013305, 1994.\nM. L. Puterman. Markov Decision Processes: Discrete Stochastic Dynamic Programming.\nJohn Wiley and Sons, 2008.\nS. Stidham, Jr. Optimal control of admission to a queueing system. IEEE Transactions on\nAutomatic Control, 30(8):705\u2013713, 1985.\nS. La Torre, P. Madhusudan, and G. Parlato. Context-bounded analysis of concurrent\nqueue systems. In Proceedings of TACAS, volume 4963 of LNCS, pages 299\u2013314, 2008.\nH. Zisgen, I. Meents, B.R. Wheeler, and T. Hanschke. A queueing network based system\nto model capacity and cycle time for semiconductor fabrication. In Proceedings of the 40th\nConference on Winter Simulation, pages 2067\u20132074, 2008.\n\n\fT. Br\u00e1zdil and S. Kiefer\n\nA\n\n13\n\nProofs\n\nA.1\n\nProof of Lemma 6\n\nLemma 6. The matrix series A\u2217 :=\n(I \u2212 A)\u22121 .\n\nP\u221e\n\ni=0\n\nn\u00d7n\nAi converges (\"exists\") in R\u22650\nand is equal to\n\nProof. By the traffic equation \u03bb = \u03b1 + \u03bbA we have \u03bbA \u2264 \u03bb, with \u03bb > 0. By [3, Theorem 2.1.11] this implies that the spectral radius of A is at most 1 (where the spectral radius\nis the largest absolute value of the eigenvalues of A).\nTo show the statement of the lemma, it now suffices to show that I \u2212 A is invertible.\nConsider the (monotone) function f : Rn\u22650 \u2192 Rn\u22650 with f (x) := \u03b1 + xA. By the traffic\nequation, \u03bb is a fixed point of f . Assume for a contradiction that I \u2212 A is singular, i.e., there\nis y \u2208 Rn with y 6= 0 and yA = y. Then \u03bb + ry is a fixed point for all r \u2208 R. Choose r\nso that z := \u03bb + ry \u2208 Rn\u22650 , but z i = 0 for some i \u2208 {1, . . . , n}. By the monotonicity of f ,\nall points u \u2208 {0, f (0), f (f (0)), . . .} satisfy 0 \u2264 u \u2264 z = f (z). It follows that ui = 0 for\nall u. This contradicts the fact that queue i is \"reachable\" (recall that \"queue i is reachable\"\nmeans there is j \u2208 N with (\u03b1Aj )i 6= 0).\nJ\n\nA.2\n\nProof of Proposition 4\n\nIn this section we complete the proof of\nProposition 4. Assume that \u03bb \u2208 Rn\u22650 solves the traffic equations (2) and satisfies \u03bb < \u03bc.\nThen the following conclusions hold:\n1. The process N is ergodic, i.e., the expected return time to 0 is finite.\n2. There exists a stationary distribution \u03c0 such that there exists an exponential moment of\nP\nthe total queue size, i.e., there is \u03b4 > 0 such that x\u2208Nn exp(\u03b4 kxk)\u03c0(x) exists.\nP\u221e\nRecall from Lemma 6 that the matrix series A\u2217 := i=0 Ai converges (\"exists\") in Rn\u00d7n\n\u22650\nand equals (I \u2212 A)\u22121 . Observe that for any vector v T = A\u2217 wT with w \u2208 Rn , we have\nv T = Av T + wT . We prove Lemma 7:\nLemma 7. If 0 6= x \u2208 Rn\u22650 and xi = 0, then xq (i)T < V (x).\nProof. For the proof we use the following notation: For a matrix M we denote by Mi..j the\nmatrix obtained by restricting M to its rows indexed by i, . . . , j. Similarly, we denote by\nMi..j,k..` the matrix M restricted to the corresponding rows and columns.\nn\u00d7n\nLet Q \u2208 R\u22650\ndenote the matrix whose columns are q (1)T , . . . , q (n)T . Note that 1Q = 1.\n\u2217\n\u2217\nWe have Q = A D where D \u2208 Rn\u00d7n\n\u22650 is the diagonal matrix with 1/Dii = (1A )i . Further,\nn\u00d7(n\u22121)\nwe define the matrix P \u2208 {\u22121, 0, 1}\nwith\n\u22121\n\uf8ec1\n\uf8ec\n\uf8ec\nP := \uf8ec 0\n\uf8ec\n\uf8ed\n\uf8eb\n\n0\n\n\u22121\n0\n1\n\n\u22121\n0\n0\n\n***\n***\n***\n..\n.\n\n\u22121\n0\n0\n\n\uf8f6\n\u22121\n0 \uf8f7\n\uf8f7\n0 \uf8f7\n\uf8f7 .\n\uf8f7\n\uf8f8\n\n0\n\n0\n\n***\n\n0\n\n1\n\n\f14\n\nStabilization of Branching Queueing Networks\n\nW.l.o.g. let x1 = 0. With the notation above and writing x\u0304 := (x2 , . . . , xn ) \u2208 Rn\u22121\n\u22650 , the\nlemma states that\nthere is no x\u0304 \u2208 Rn\u22121\n\u22650 with x\u0304 6= 0 and x\u0304Q2..n P \u2264 0 .\n\n(7)\n\nWe use Farkas' lemma for the proof:\nI Lemma 13 (Farkas' lemma). Let M \u2208 Rm\u00d7n and b \u2208 Rm . Then exactly one of the\nfollowing is true:\n1. There exists x \u2208 Rm with xM \u2264 0 and xbT > 0.\n2. There exists y \u2208 Rn with M y T = bT and y \u2265 0.\nUsing Farkas' lemma we prove (7) by exhibiting b > 0 and y \u2265 0 such that Q2..n P y T = bT .\nWe choose\nbT := (A2..n,2..n )\u2217 1T \u2265 1T > 0T .\nWe have 1Q = 1, which implies 1Q\u22121 = 1QQ\u22121 = 1, hence P (Q\u22121 )2..n = Q\u22121 \u2212 E where\nE \u2208 {0, 1}n\u00d7n denotes the matrix with 1 in the first row and 0 in the other rows. It follows\nP (Q\u22121 )2..n P = Q\u22121 P .\n\n(8)\n\nSetting\ny T := (Q\u22121 )2..n P bT\nwe therefore have\n(8)\n\nQ2..n P y T = Q2..n P (Q\u22121 )2..n P bT = Q2..n Q\u22121 P bT = P2..n bT = bT ,\nas desired. It remains to prove y \u2265 0. As Q = A\u2217 D, we have Q\u22121 = D\u22121 (I \u2212 A) with D\u22121\nnonnegative, so it suffices to prove that (I \u2212 A)2..n P bT \u2265 0T . Indeed we have\n(I \u2212 A)2..n P bT = (I \u2212 A2..n P )bT = bT \u2212 A2..n P bT \u2265 bT \u2212 A2..n,2..n bT = 1T ,\nwhere the inequality holds as bT and the first column of A2..n are nonnegative and the first\nrow of P is negative.\nJ\nRecall the following lemma:\nLemma 8. There is \u03b3 > 0 such that we have\n\u2206(x) V 0 (x)\n\n\u0001T\n\n\u2264 \u2212\u03b3\n\nfor all x 6= 0\n\nand all subgradient vectors V 0 (x) of V at x. More precisely, one can choose\n\u03b3 := min(\u03bci \u2212 \u03bbi )/ a(i) ,\ni\n\nwhere a(i)T is the ith column of A\u2217 .\nProposition 4 follows from Lemma 8 using exactly the reasoning from theorem 1 and\nlemma 5 of [10].\n\n\fT. Br\u00e1zdil and S. Kiefer\n\nA.3\n\n15\n\nProof of Lemma 11\n\nLemma 11. Assume that \u0398 is a memoryless ergodic scheduler. For every \u03be \u2208 \u03a3\u0304 there is a\nconstant O\u03be such that for almost all runs \u03c9 of N\u0398 the limit\nlim\n\nO\u03be\u2264t (\u03c9)\nt\n\nt\u2192\u221e\n\n\u0001\nexists and is equal to O\u03be . There is \u03b4\u0304 < 1 such that \u03b4\u0304, O\u03be | \u03be \u2208 \u03a3\u0304 solves the traffic\nLP.\nP\nMoreover, for every i \u2208 {1, . . . , n} the utilization \u03c1i of the queue i in N\u0398 is equal to\n\n\u03be\u2208\u03a3i\n\n\u03bci\n\nO\u03be\n\n.\n\nWe divide our proof of Lemma 11 into four claims.\nI Claim 1. For every \u03be \u2208 \u03a3\u0304 there is a constant O\u03be such that for almost all runs \u03c9 of N\u0398 the\nlimit\nlim\n\nO\u03be\u2264t (\u03c9)\n\nt\u2192\u221e\n\nt\n\nexists and is equal to O\u03be .\nProof. Given an action \u03be \u2208 \u03a3\u0304 and i \u2265 1, denote by Mi\u03be a random variable giving the number\nof times the action \u03be is fired between the i-th and i + 1-st visit to 0 (note that the network\nstarts with all empty queues so the first visit happens at time 0). Observe that all Mi\u03be are\nidentically distributed. Also, as the expected return time to 0 is finite and there are only\nfinitely many distinct rates (i.e. the expected time between\nh two\ni state transitions is bounded\n\nfrom below by a positive constant), the expectation E M1\u03be is finite. By the strong law\n\u03be\nof large numbers\nPn (see\u03be e.g. [4]), there is a constant M such that for almost all runs \u03c9 the\nM (\u03c9)\nlimit limn\u2192\u221e i=1n i\nexists and is equal to M \u03be . For i \u2265 1 we define Ri to be a random\nvariable giving the total time between the i-th and i + 1-st visits to 0. Note that R1 is\nprecisely the variable R giving the return\nP time to 0. By the strong law of large numbers, for\nn\n\nRi (\u03c9)\n\nalmost all runs \u03c9 the limit limn\u2192\u221e i=1n\nexists and is equal to E [R1 ] = E [R] < \u221e.\nPn\u22121\nPn\nNow note that for t \u2265 0 and n \u2265 1 satisfying i=1 Ri (\u03c9) \u2264 t \u2264 i=1 Ri (\u03c9) (here for\nPn\u22121\nn = 1 we assume i=1 Ri (\u03c9) = 0) we have\nPn\u22121 \u03be\nMi (\u03c9)\nPi=1\nn\ni=1 Ri (\u03c9)\n\n\u2264\n\nO\u03be\u2264t (\u03c9)\nt\n\n\u2264\n\nPn\nMi\u03be (\u03c9)\nPi=1\nn\ni=1 Ri (\u03c9)\n\n(9)\n\nThe limit of the rightmost term of (9) exists:\nM\u03be\nE [R]\n\nPn\n=\n\nlim\n\nn\u2192\u221e\n\ni=1\n\nMi\u03be (\u03c9)\nn\n* lim Pn\nn\u2192\u221e\nn\ni=1 Ri (\u03c9)\n\n=\n\nPn\nMi\u03be (\u03c9)\nlim Pi=1\nn\nn\u2192\u221e\ni=1 Ri (\u03c9)\n\nSimilarly, the limit of the left most term of (9) exists:\n!\nPn\u22121 \u03be\nM\u03be\nn\u22121\nn\ni=1 Mi (\u03c9)\n=\nlim\n* lim\n* lim Pn\nn\u2192\u221e\nn\u2192\u221e\nn\u2192\u221e\nE [R]\nn\u22121\nn\ni=1 Ri (\u03c9)\n\n=\n\nPn\nMi\u03be (\u03c9)\nlim Pi=1\nn\nn\u2192\u221e\ni=1 Ri (\u03c9)\n\n\u2264t\n\nThus by basic properties of limits, the limit limt\u2192\u221e\n\nO\u03be (\u03c9)\nt\n\nexists and is equal to\n\nM\u03be\nE[R] .\n\nJ\n\n\f16\n\nStabilization of Branching Queueing Networks\n\nThe following two claims show that the frequencies indeed solve the traffic LP with \u03b4 < 1.\nI Claim 2. For every j \u2208 {1, . . . , n} we have\nX\n\nO\u03be =\n\nn X\nX\n\nO\u03b6 * A\u03b6j\n\n(10)\n\ni=0 \u03b6\u2208\u03a3i\n\n\u03be\u2208\u03a3j\n\nHere we assume (in order to simplify notation) that the external source is a (symbolic)\nqueue 0, with action set \u03a3 = {\u03b9} where \u03b9 has rate \u03bc0 and a production function Prob0 (thus\nO\u03b9 * A\u03b9j = \u03b1j ).\n\u2264t\nProof. Denote by O\u03b6\u2192j\n(\u03c9) the number of jobs produced for queue j by firing the action \u03b6.\nThe crucial observation is that for almost all runs \u03c9 we have\nP\nPn P\n\u2264t\n\u2264t\n\u03be\u2208\u03a3j O\u03be (\u03c9)\ni=0\n\u03b6\u2208\u03a3i O\u03b6\u2192j (\u03c9)\nlim\n=\nlim\nt\u2192\u221e\nt\u2192\u221e\nt\nt\nP\nPn P\nPn P\n\u2264t\n\u2264t\n\u2264t\nIndeed, \u03be\u2208\u03a3j O\u03be (\u03c9) \u2264 i=0 \u03b6\u2208\u03a3i O\u03b6\u2192j (\u03c9) for all t and \u03c9 because i=0 \u03b6\u2208\u03a3i O\u03b6\u2192j\n(\u03c9)\nis precisely the number of jobs that enter the queue j up to time t. On the other hand,\nP\nPn P\n\u2264t\n\u2264t\n\u03be\u2208\u03a3j O\u03be (\u03c9) for infinitely many t and almost all \u03c9 because (almost\ni=0\n\u03b6\u2208\u03a3i O\u03b6\u2192j (\u03c9) \u2264\nsurely) queue j becomes empty infinitely many times.\nWe obtain that\n\nX\n\nO\u03be\n\n=\n\n\u03be\u2208\u03a3j\n\nX\n\u03be\u2208\u03a3j\n\nlim\n\nO\u03be\u2264t (\u03c9)\nt\n\nt\u2192\u221e\n\nP\n=\n\nlim\n\n\u03be\u2208\u03a3j\n\nt\u2192\u221e\n\nPn\n=\n=\n\nlim\n\ni=0\n\nt\u2192\u221e\nn X\nX\ni=0 \u03b6\u2208\u03a3i\n\n=\n\n=\n\nn X\nX\ni=0 \u03b6\u2208\u03a3i\nn X\nX\n\nO\u03be\u2264t (\u03c9)\n\nt\nP\n\nlim\n\n\u03b6\u2208\u03a3i\n\nt\n\u2264t\nO\u03b6\u2192j\n(\u03c9)\nt\n\nt\u2192\u221e\n\nlim\n\n\u2264t\nO\u03b6\u2192j\n(\u03c9)\n\nO\u03b6\u2264t (\u03c9)\n\nt\u2192\u221e\n\nt\n\n* lim\n\nt\u2192\u221e\n\n\u2264t\nO\u03b6\u2192j\n(\u03c9)\n\nO\u03b6\u2264t (\u03c9)\n\nO\u03b6 * A\u03b6j\n\ni=0 \u03b6\u2208\u03a3i\n\u2264t\n\nHere the last equality follows from Claim 1 and the fact that limt\u2192\u221e\nnumber of jobs for queue j produced by firing \u03b6, i.e., A\u03b6j .\nI Claim 3. For every i \u2208 {1, . . . , n} we have\nP\n\u03be\u2208\u03a3i O\u03be\n<1\n\u03bci\nP\nO\u03be\n\nO\u03b6\u2192j (\u03c9)\n\u2264t\n\nO\u03b6 (\u03c9)\n\nis the average\nJ\n\n(11)\n\ni\nProof. Intuitively, we show that \u03be\u2208\u03a3\n+ \u03c0(0) is equal to the proportion of time in which\n\u03bci\neither the queue i operates a job or all queues are empty. As this proportion is at most 1\nand \u03c0(0) > 0, we obtain the desired result.\nFormally, denote by Tn the total amount of time in which the first n jobs are processed\nby queue i (by this we mean the total time from the beginning of the computation needed to\n\n\fT. Br\u00e1zdil and S. Kiefer\n\n17\n\nfinish n jobs using the \"machine\" operating queue i). Denote by Nj the total time it takes to\nprocess the j-th job from queue i (by this we mean the time the \"machine\" actively spends\nby processing the job).\nP\nn\n\nNj (\u03c9)\n\nObserve that for almost all runs \u03c9 we have that limn\u2192\u221e j=1n\nprocessing time of the queue i which is \u03bc1i , and that Tnn(\u03c9) is equal to\n\nis the average\n\n\u2264Tn (\u03c9)\n\nP\n\n\u03be\u2208\u03a3i\n\nO\u03be\n\nTn (\u03c9)\nwhich means that by Claim 1,\n\u2264Tn (\u03c9)\n\nP\n\nn\nlim\nn\u2192\u221e Tn (\u03c9)\n\n=\n\nO\u03be\n\n\u03be\u2208\u03a3i\n\nlim\n\nTn (\u03c9)\n\nn\u2192\u221e\n\nX\n\n=\n\nO\u03be\n\n\u03be\u2208\u03a3i\n\nThus\nPn\n\nj=1\n\nlim\n\nn\u2192\u221e\n\nNj (\u03c9)\n\nTn (\u03c9)\n\nPn\n=\n\nj=1\n\nlim\n\nNj (\u03c9)\n\nn\n\nn\u2192\u221e\n\nn\n* lim\nn\u2192\u221e Tn (\u03c9)\n\nP\n\n\u03be\u2208\u03a3i\n\n=\n\nO\u03be\n\n(12)\n\n\u03bci\n\nDenote by En the total amount of time the network spends in state 0 before queue i finishes\nn jobs (by this we mean the sum of all time intervals up to time Tn in which all queues are\nsimultaneously idle before n jobs are finished by the \"machine\" operating queue i). Intuitively,\nn (\u03c9)\nlimn\u2192\u221e E\nTn (\u03c9) is equal to the proportion of time spent in 0 which is equal to \u03c0(0) > 0. More\nprecisely, by the Ergodic Theorem, see Theorem 3.8.1 of [25], for almost all runs \u03c9 we have\n0\n\n<\n\n\u03c0(0)\n\n=\n\nt\n\nZ\n\n1\nt\u2192\u221e t\n\nI[x(\u03c9) = 0](s)ds\n\nlim\n\n=\n\n0\n\nEn (\u03c9)\nn\u2192\u221e Tn (\u03c9)\n\n(13)\n\nlim\n\nFinally, by (12) and (13),\nP\nP\n\u03be\u2208\u03a3i O\u03be\n\u03be\u2208\u03a3i O\u03be\n<\n+ \u03c0(0) =\n\u03bci\n\u03bci\nPn\nPn\nn\nEn (\u03c9)\nj=1 Nj (\u03c9) + En (\u03c9)\nj=1 Nj (\u03c9)\n* lim\n+ lim\n= lim\n\u2264 1\nn\u2192\u221e Tn (\u03c9)\nn\u2192\u221e Tn (\u03c9)\nn\u2192\u221e\nn\nTn (\u03c9)\nJ\nP\nI Claim 4. For every i \u2208 {1, . . . , n}, \u03c1i =\n\n\u03be\u2208\u03a3i\n\nO\u03be\n\n\u03bci\n\n.\n\nProof. By the Ergodic Theorem, see Theorem 3.8.1 of [25], and by (12), for almost all runs\n\u03c9 we have\nX\n\u03c1i =\nlim Pr(xi (t) 6= 0) =\n\u03c0(x)\nt\u2192\u221e\n\nx\u2208Nn :xi 6=0\n\n=\n\n1\nlim\nt\u2192\u221e t\n\nZ\n\nPn\n\nt\n\nI[xi (\u03c9) 6= 0](s)ds\n0\n\n=\n\nlim\n\nn\u2192\u221e\n\nj=1\n\nNj (\u03c9)\n\nTn (\u03c9)\n\nP\n=\n\n\u03be\u2208\u03a3i\n\nO\u03be\n\n\u03bci\nJ\n\nThis finishes a proof of Lemma 11.\n\n\f"}