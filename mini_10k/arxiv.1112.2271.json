{"id": "http://arxiv.org/abs/1112.2271v1", "guidislink": true, "updated": "2011-12-10T12:09:21Z", "updated_parsed": [2011, 12, 10, 12, 9, 21, 5, 344, 0], "published": "2011-12-10T12:09:21Z", "published_parsed": [2011, 12, 10, 12, 9, 21, 5, 344, 0], "title": "Anglers' fishing problem", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1112.5182%2C1112.1765%2C1112.1837%2C1112.3358%2C1112.1738%2C1112.2739%2C1112.0448%2C1112.1024%2C1112.2326%2C1112.3690%2C1112.2191%2C1112.5079%2C1112.5792%2C1112.1961%2C1112.0228%2C1112.3066%2C1112.2552%2C1112.3343%2C1112.3252%2C1112.4107%2C1112.5774%2C1112.0696%2C1112.1193%2C1112.4857%2C1112.2297%2C1112.3234%2C1112.3595%2C1112.4757%2C1112.2422%2C1112.6394%2C1112.2158%2C1112.2183%2C1112.5092%2C1112.5826%2C1112.4425%2C1112.1063%2C1112.4606%2C1112.0913%2C1112.5109%2C1112.4930%2C1112.4501%2C1112.1122%2C1112.3693%2C1112.2903%2C1112.2523%2C1112.1223%2C1112.0359%2C1112.0623%2C1112.5239%2C1112.2554%2C1112.6360%2C1112.3067%2C1112.5778%2C1112.2471%2C1112.1796%2C1112.0363%2C1112.3847%2C1112.4761%2C1112.0637%2C1112.0580%2C1112.3125%2C1112.2460%2C1112.1686%2C1112.2340%2C1112.0384%2C1112.1883%2C1112.4517%2C1112.0503%2C1112.6294%2C1112.1786%2C1112.4545%2C1112.2915%2C1112.0654%2C1112.5840%2C1112.3669%2C1112.2271%2C1112.5767%2C1112.0745%2C1112.0549%2C1112.3527%2C1112.1702%2C1112.0394%2C1112.1054%2C1112.3879%2C1112.3566%2C1112.2038%2C1112.3270%2C1112.5032%2C1112.3665%2C1112.4223%2C1112.5457%2C1112.1637%2C1112.0184%2C1112.1592%2C1112.1112%2C1112.2056%2C1112.4725%2C1112.1141%2C1112.2428%2C1112.1956%2C1112.6124&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Anglers' fishing problem"}, "summary": "The considered model will be formulated as related to \"the fishing problem\"\neven if the other applications of it are much more obvious. The angler goes\nfishing. He uses various techniques and he has at most two fishing rods. He\nbuys a fishing ticket for a fixed time. The fishes are caught with the use of\ndifferent methods according to the renewal processes. The fishes' value and the\ninter arrival times are given by the sequences of independent, identically\ndistributed (i.i.d.) random variables with the known distribution functions. It\nforms the marked renewal--reward process. The angler's measure of satisfaction\nis given by the difference between the utility function, depending on the value\nof the fishes caught, and the cost function connected with the time of fishing.\nIn this way, the angler's relative opinion about the methods of fishing is\nmodelled. The angler's aim is to have as much satisfaction as possible and\nadditionally he has to leave the lake before a fixed moment. Therefore his goal\nis to find two optimal stopping times in order to maximize his satisfaction. At\nthe first moment, he changes the technique of fishing, e.g. by excluding one\nrod and intensifying on the rest. Next, he decides when he should stop the\nexpedition. These stopping times have to be shorter than the fixed time of\nfishing. The dynamic programming methods have been used to find these two\noptimal stopping times and to specify the expected satisfaction of the angler\nat these times.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1112.5182%2C1112.1765%2C1112.1837%2C1112.3358%2C1112.1738%2C1112.2739%2C1112.0448%2C1112.1024%2C1112.2326%2C1112.3690%2C1112.2191%2C1112.5079%2C1112.5792%2C1112.1961%2C1112.0228%2C1112.3066%2C1112.2552%2C1112.3343%2C1112.3252%2C1112.4107%2C1112.5774%2C1112.0696%2C1112.1193%2C1112.4857%2C1112.2297%2C1112.3234%2C1112.3595%2C1112.4757%2C1112.2422%2C1112.6394%2C1112.2158%2C1112.2183%2C1112.5092%2C1112.5826%2C1112.4425%2C1112.1063%2C1112.4606%2C1112.0913%2C1112.5109%2C1112.4930%2C1112.4501%2C1112.1122%2C1112.3693%2C1112.2903%2C1112.2523%2C1112.1223%2C1112.0359%2C1112.0623%2C1112.5239%2C1112.2554%2C1112.6360%2C1112.3067%2C1112.5778%2C1112.2471%2C1112.1796%2C1112.0363%2C1112.3847%2C1112.4761%2C1112.0637%2C1112.0580%2C1112.3125%2C1112.2460%2C1112.1686%2C1112.2340%2C1112.0384%2C1112.1883%2C1112.4517%2C1112.0503%2C1112.6294%2C1112.1786%2C1112.4545%2C1112.2915%2C1112.0654%2C1112.5840%2C1112.3669%2C1112.2271%2C1112.5767%2C1112.0745%2C1112.0549%2C1112.3527%2C1112.1702%2C1112.0394%2C1112.1054%2C1112.3879%2C1112.3566%2C1112.2038%2C1112.3270%2C1112.5032%2C1112.3665%2C1112.4223%2C1112.5457%2C1112.1637%2C1112.0184%2C1112.1592%2C1112.1112%2C1112.2056%2C1112.4725%2C1112.1141%2C1112.2428%2C1112.1956%2C1112.6124&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The considered model will be formulated as related to \"the fishing problem\"\neven if the other applications of it are much more obvious. The angler goes\nfishing. He uses various techniques and he has at most two fishing rods. He\nbuys a fishing ticket for a fixed time. The fishes are caught with the use of\ndifferent methods according to the renewal processes. The fishes' value and the\ninter arrival times are given by the sequences of independent, identically\ndistributed (i.i.d.) random variables with the known distribution functions. It\nforms the marked renewal--reward process. The angler's measure of satisfaction\nis given by the difference between the utility function, depending on the value\nof the fishes caught, and the cost function connected with the time of fishing.\nIn this way, the angler's relative opinion about the methods of fishing is\nmodelled. The angler's aim is to have as much satisfaction as possible and\nadditionally he has to leave the lake before a fixed moment. Therefore his goal\nis to find two optimal stopping times in order to maximize his satisfaction. At\nthe first moment, he changes the technique of fishing, e.g. by excluding one\nrod and intensifying on the rest. Next, he decides when he should stop the\nexpedition. These stopping times have to be shorter than the fixed time of\nfishing. The dynamic programming methods have been used to find these two\noptimal stopping times and to specify the expected satisfaction of the angler\nat these times."}, "authors": ["Anna Karpowicz", "Krzysztof Szajowski"], "author_detail": {"name": "Krzysztof Szajowski"}, "author": "Krzysztof Szajowski", "arxiv_comment": "23 pages + index", "links": [{"href": "http://arxiv.org/abs/1112.2271v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1112.2271v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.SY", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.OC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.TH", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "60G40, 60K99, 90A46", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "G.3", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1112.2271v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1112.2271v1", "journal_reference": null, "doi": null, "fulltext": "Anglers' fishing problem\n\narXiv:1112.2271v1 [math.PR] 10 Dec 2011\n\nAnna Karpowicz and Krzysztof Szajowski\n\nAbstract The considered model will be formulated as related to \"the fishing problem\" even if the other applications of it are much more obvious. The angler goes\nfishing. He uses various techniques and he has at most two fishing rods. He buys a\nfishing ticket for a fixed time. The fishes are caught with the use of different methods\naccording to the renewal processes. The fishes' value and the inter arrival times are\ngiven by the sequences of independent, identically distributed (i.i.d.) random variables with the known distribution functions. It forms the marked renewal\u2013reward\nprocess. The angler's measure of satisfaction is given by the difference between the\nutility function, depending on the value of the fishes caught, and the cost function\nconnected with the time of fishing. In this way, the angler's relative opinion about the\nmethods of fishing is modelled. The angler's aim is to have as much satisfaction as\npossible and additionally he has to leave the lake before a fixed moment. Therefore\nhis goal is to find two optimal stopping times in order to maximize his satisfaction.\nAt the first moment, he changes the technique of fishing e.g. by excluding one rod\nand intensifying on the rest. Next, he decides when he should stop the expedition.\nThese stopping times have to be shorter than the fixed time of fishing. The dynamic\nprogramming methods have been used to find these two optimal stopping times and\nto specify the expected satisfaction of the angler at these times.\nKey words: fishing problem, optimal stopping, dynamic programming, semi-Markov\nprocess, marked renewal process, renewal\u2013reward process, infinitesimal generator\nAMS 2010 Subject Classifications:60G40, 60K99, 90A46\n\nAnna Karpowicz\nBank Zachodni WBK, Rynek 9/11, 50-950 Wroc\u0142aw, Poland\ne-mail: a.m.karpowicz@gmail.com\nKrzysztof Szajowski\nInstitute of Mathematics and Computer Sci., Wybrze\u017ce Wyspia\u0144skiego 27, 50-370 Wroc\u0142aw,\nPoland\ne-mail: Krzysztof.Szajowski@pwr.wroc.pl\n\n1\n\n\f2\n\nA. Karpowicz, K. Szajowski\n\n1 Introduction\nBefore we start the analysis of the double optimal stopping problem (cf. idea of\nmultiple stopping for stochastic sequences in Haggstrom [8], Nikolaev [16]) for\nthe marked renewal process related to the angler behavior, let us present the so\ncalled \"fishing problem\". One of the first authors who considered the basic version\nof this problem was Starr [19] and further generalizations were done by Starr and\nWoodroofe [21], Starr, Wardrop and Woodroofe [20], Kramer, Starr [14] et al. The\ndetailed review of the papers related to the \"fishing problem\" was presented by Ferguson [7]. The simple formulation of the fishing problem, where the angler changes\nthe fishing place or technique before leaving the fishing place, has been done by\nKarpowicz [12]. We extend the problem to a more advanced model by taking into\naccount the various techniques of fishing used the same time (the parallel renewal\u2013\nreward processes or the multivariate renewal\u2013reward process). It is motivated by\nthe natural, more precise models of the known, real applications of the fishing problem. The typical process of software testing consists of checking subroutines. At the\nbeginning many kinds of bugs are being searched. The consecutive stopping times\nare moments when the expert stops general testing of modules and starts checking\nthe most important, dangerous type of error. Similarly, in proof reading, it is natural\nto look for typographic and grammar errors at the same time. Next, we are looking\nfor language mistakes.\nAs various works are done by different groups of experts, it is natural that we\nwould compete with each other. If in the first period work is meant for one group\nand the second period needs other experts, then they can be players of a game between them. In this case the proposed solution is to find the Nash equilibrium where\nstrategies of players are the stopping times.\nThe applied techniques of modeling and finding the optimal solution are similar\nto those used in the formulation and solution of the optimal stopping problem for the\nrisk process. Both models are based on the methodology explicated by Boshuizen\nand Gouweleeuw [1]. The background mathematics for further reading are monographs by Br\u00e9maud [3], Davis [4] and Shiryaev [18]. The optimal stopping problems\nfor the risk process are subject of consideration in papers by Jensen [10], Ferenstein\nand Sieroci\u0144ski [6], Muciek [15]. A similar problem for the risk process having disruption (i.e. when the probability structure of the considered process is changed at\none moment \u03b8 ) has been analyzed by Ferenstein and Pasternak\u2013Winiarski [5]. The\nmodel of the last paper brings to mind the change of fishing methods considered\nhere, however it should be made by a decision maker, not the type of the environment.\nThe following two sections usher details of the model. It is proper to emphasize\nthat the slight modification of the background assumption by adopting multivariate\ntools (two rods) and the possible control of their numbers in use extort a different\nstructure of the base model (the underlining process, sets of strategies \u2013 admissible\nfiltrations and stopping times). This modified structure allows the introduction of\na new kind of knowledge selection which consequently leads to a game model of\nthe anglers' expedition problem in the section 1.2 and 2.2. After a quite general\n\n\fAnglers' fishing problem\n\n3\n\nformulation a version of the problem for a detailed solution will be chosen. However,\nthe solution is presented as the scalable procedure dependent on parameters which\ndepends on various circumstances. It is not difficult to adopt a solution to wide range\nof natural cases.\n\n1.1 Single Angler's expedition\nThe angler goes fishing. He buys a fishing ticket for a fixed time t0 which gives him\nthe right to use at most two rods. The total cost of fishing depends on real time of\neach equipment usage and the number of rods used simultaneously. He starts fishing\nwith two rods up to the moment s. The effect on each rod can be modelled by the\nrenewal processes {Ni (t),t \u2265 0}, where Ni (t) is the number of fishes caught on the\nrod i, i \u2208 A := {1, 2} during the time t. Let us combine them together to the marked\nrenewal process. The usage of the i-th rod by the time t generates cost ci : [0,t0 ] \u2192\nR (when the rod is used simultaneously with other rods it will be denoted by the\nindex dependent on the set of rods, e.g. a, cai ) and the reward represented by i.i.d.\n{i}\n{i}\nrandom variables X1 , X2 , . . . (the value of the fishes caught on the i-th rod) with\ncumulative distribution function Hi 1 . The streams of two kinds of fishes are mutually\nindependent and they are independent of the sequence of random moments when the\n\u2192\n\u2212\nfishes have been caught. The 2-vector process N (t) = (N1 (t), N2 (t)), t \u2265 0, can be\nrepresented also by a sequence of random variables Tn taking values in [0, \u221e] such\nthat\nT0 = 0,\n(1)\nTn < \u221e \u21d2 Tn < Tn+1 ,\nfor n \u2208 N, and a sequence of A-valued random variables zn for n \u2208 N \u222a {0} (see\nBr\u00e9maud [3] Ch. II, Jacobsen [9]). The random variable Tn denotes the moment of\ncatching the n-th fish (T0 = 0) of any kind and the random variable zn indicates to\nwhich kind the n-th fish belongs. The processes Ni (t) can be defined by the sequence\n{(Tn , zn )}\u221e\nn=0 as:\n\u221e\n\nNi (t) =\n\n\u2211 I{Tn \u2264t} I{zn =i} .\n\n(2)\n\nn=1\n\n\u2192\n\u2212\nBoth the 2-variate process N (t) and the double sequence {(Tn , zn )}\u221e\nn=0 are called\n2-variate renewal process. The optimal stopping problems for the compound risk\nprocess based on 2-variate renewal process was considered by Szajowski [22].\nLet us define, for i \u2208 A and k \u2208 N, the sequence\n{i}\n\nn0 = 0,\n{i}\n{i}\nnk+1 = inf{n > nk : zn = i}\n\n(3)\n\n\u2212\nThe following convention is used in all the paper: \u2192\nx = (x1 , x2 , . . ., xs ) for the ordered collection\ns\nof the elements {xi }i=1\n1\n\n\f4\n\nA. Karpowicz, K. Szajowski\n{i}\n\nand put Tk\n\n{i}\n\n{i}\n\n= T {i} . Let us define random variables Sn = Tn\nnk\n\n{i}\n\n\u2212 Tn\u22121 and as-\n\nsume that they are i.i.d. with continuous, cumulative distribution function Fi (t) =\n{i}\n{i}\n{i}\nP(Sn \u2264 t) and the conditional distribution function Fis (t) = P(Sn \u2264 t|Sn \u2265 s). In\nthe section 2.1 the alternative representation of the 2-variate renewal process will be\nproposed. There is also mild extension of the model in which the stream of events\nafter some moment changes to another stream of events.\nRemark 1. In various procedures it is needed to localize the events in a group of the\nrenewal processes. Let C be the set of indices related to such a group. The sequence\n\u221e\nC\nC\nC\n{nC\nk }k=0 such that n0 = 0, nk+1 := inf{n > nk : zn \u2208 C} has an obvious meaning.\nC\nAnalogously, n (t) := inf{n : Tn > t,zn \u2208 C}.\nLet i, j \u2208 A. The angler's satisfaction measure (the net reward) at the period\na from the rod i is the difference between the utility function gai : [0, \u221e)2 \u00d7 A \u00d7\nR+ \u2192 [0, Gai ] which can be interpreted as the reward from the i-th rod when the\nlast success was on rod j and, additionally, it is dependent on the value of the fishes\ncaught, the moment of results' evaluation, and the cost function cai : [0,t0 ] \u2192 [0,Cia ]\nreflecting the cost of duration of the angler's expedition. We assume that gai and cai\nare continuous and bounded, additionally cai are differentiable. Each fishing method\nevaluation is based on different utility functions and cost functions. In this way, the\nangler's relative opinion about them is modelled.\nThe angler can change his method of fishing at the moment s and decide to use\nonly one rod. It could be one of the rods used up to the moment s or the other one.\nEvent though the rod used after s is the one chosen from the ones used before s its\neffectiveness could be different before and after s. Following these arguments, the\nmathematical model of catching fishes, and their value after s, could (and in practice\nshould) be different from those for the rods used before s. The reason for reduction\nof the number of rods could be their better effectiveness. The value of the fishes\nwhich have been caught up to time t, if the change of the fishing technology took\nplace at the time s, is given by\nMts =\n\nNi (s\u2227t)\n\n\u2211 \u2211\n\ni\u2208A n=1\n\n{i}\n\nXn +\n\nN3 ((t\u2212s)+ )\n\n\u2211\n\nn=1\n\n{3}\n\nXn\n\nN3 ((t\u2212s)+ )\n\n= Ms\u2227t +\n\n\u2211\n\n{3}\n\nXn ,\n\nn=1\n\n\u2192\n\u2212\n{2}\n{1}\nNi (t) {i}\n{i}\n{i}\nXn , and Mt = \u22112i=1 Mt We denote M t = (Mt , Mt ). Let\nwhere Mt = \u2211n=1\nZ(s,t) denote the angler's pay-off for stopping at time t (the end of the expedition)\nif the change of the fishing method took place at time s. If the effect of extending\n2\nthe expedition after s is described by gbj : R+ \u00d7 A \u00d7 [0,t0] \u00d7 R \u00d7 [0,t0] \u2192 [0, Gbj ],\nj \u2208 B, minus the additional cost of time cbj (*), where cbj : [0,t0 ] \u2192 [0,Cbj ] (when\ncard(B) = 1 then index j will be abandoned, also cb = \u2211 j\u2208B cbj will be used, which\nwill be adequate). The payoff can be expressed as:\n\n\fAnglers' fishing problem\n\n\uf8f1\n\u2192\n\u2212\n\uf8f4\nga ( M t , zN(t) ,t) \u2212 ca (t)\nif t < s \u2264 t0 ,\n\uf8f4\n\uf8f4\n\u2192\n\uf8f2 a \u2212\na\ng ( M s , zN(s) , s) \u2212 c (s)\nZ(s,t) =\n\u2192\n\u2212\n\uf8f4\n+gb ( M s , zN(s) , s, Mts ,t) \u2212 cb(t \u2212 s) if s \u2264 t \u2264 t0 ,\n\uf8f4\n\uf8f4\n\uf8f3\n\u2212C\nif t0 < t.\n\n5\n\n(4)\n\n\u2192\nwhere the function ca (t), ga (\u2212\nm , i,t) and the constant C can be taken as follows:\n\u2192\n\u2212\n\u2192\n\u2212\n2\na\na\na\nc (t) = \u2211i=1 ci (t), g ( M s , j,t) = \u22112i=1 gai ( M t , j,t), C = C1a + C2a + Cb . After moment s the modelling process is the renewal\u2013reward one with the stream of i.i.d.\n{3}\n{3}\nrandom variables Xn at the moments Tn (i.e. appearing according to the renewal\n\u2192\n\u2212\n\u2192\n\u2192\nprocess N3 (t)). With the notation wb ( m , i, s, m,t)\ne = wa (\u2212\nm , i, s) + gb (\u2212\nm , i, s, m,t)\ne \u2212\n\u2192\n\u2212\n\u2192\n\u2212\ncb (t \u2212 s) and wa ( m , i,t) = ga ( m , i,t) \u2212 ca (t), formula (4) is reduced to:\nZ(s,t) = Z {zN(t) } (s,t)I{t<s\u2264t0 } + Z {zN(s) } (s,t)I {s\u2264t} ,\n\nwhere\n\u2212\n\u2192\n\u2192\n\u2212\nZ {i} (s,t) = I{t<s\u2264t0 } wa ( M t , i,t) + I{s\u2264t\u2264t0 } wb ( M s , i, s, Mts ,t) \u2212 I{t0 <t}C.\n\n1.2 The competitive fishing\nWhen the methods of fishing are operating by separated anglers then the stopping\nrandom field can be built based on the structure of the marked renewal\u2013reward process as a model of the competitive expedition results. One possible definition of\npay-off is based on the assumption that each player has his own account related to\nthe exploration of the fishery. The states of the accounts depend on who forces the\nfirst stop for changing technique, under which circumstances and what techniques\nthey choose. The first stopping moment, the minimum of stopping moments chosen by the players, is after the moment of the event (catching fish) Tn by the rod\nzn and the reward functions depend on the type of fishing which gives recent fish\n\u2192\n\u2192\n(i.e. j, where j = zn ). The player's pay-off wai (\u2212\nm , j,t) = gai (\u2212\nm , j,t) \u2212 cai (t) . The\npart of the pay-off which depends on the second chosen moment, which stops the\nexpedition, is different for the player who forces the change of fishing methods (the\nleader) by himself and the other the opponent. The leader is the responsible angler\nfor determining the expedition deadline.\nLets assume for a while that the i-th player, i = 1, 2, will take the rod of the\nopponent and gives his rod to him. It is not a crucial assumption anyway and the\nmethod of fishing after the change can be different from both available before the\nconsidered moment. The method of treatment of the case without this assumption\nwill be explained later (see page 9), when the behavior of the player in the second\npart of the expedition will be formulated. Define the function\n\u2192\n\u2192\n\u2192\nw\u0303bi (\u2212\nm , j, s, k, m,t)\ne = w\u0303ai (\u2212\nm , j, s) + g\u0303bi (\u2212\nm , j, s, k, m,t)\ne \u2212 cb (t \u2212 s)\n\n\f6\n\nA. Karpowicz, K. Szajowski\n\nfor j \u2208 A, k \u2208 B, where j is the rod by which the fish had been caught just before the\nmoment of the first stop and k is the technique used by i-th player after the change\n(the denotation \u2212k is used for a complimentary rod or player who has decided,\nwhich is appropriate). It describes the case when the player deciding to change the\nmethod chooses the perspective technique of fishing as the first one. Presumably he\nwill explore the best methods with improvements and the second angler will use the\nrod which is not used by the leader. The pay-off of the players, when i-th is the one\nwho forces the first stop, has the following form:\n\u2192\n\u2212\n\u2192\n\u2212\nZi ( j, s,t) = I{t\u2264s\u2264t0 } g\u0303ai ( M t , j,t) + I{s<t\u2264t0 } w\u0303bi ( M s , i, s, \u2212i, Mts ,t) \u2212 I{t0 <t}C (5)\n\u2192\n\u2212\n\u2192\n\u2212\nZ\u2212i ( j, s,t) = I{t\u2264s\u2264t0 } g\u0303a\u2212i ( M t , j,t) + I{s<t\u2264t0 } w\u0303b\u2212i ( M s , i, s, i, Mts ,t) \u2212 I{t0 <t}C.(6)\nIn the above pay\u2013offs it is assumed that the final stop can be declared at any moment.\nThe change of techniques declaration each player makes just after an event at his rod\n(the catching fish at his rod) as long as on the opponent's rod there is no event. The\ndetails of the strategy sets and the solution concept are formulated in the further\nparts of the paper.\nThe extension considered here is motivated by the natural, more precise models of the known real applications of the fishing problem. The typical process of\nsoftware testing consists of checking subroutines. Various types of bugs can be discovered. Each problem with subroutines generates the cost of a bug removal and\nincreases the value of the software. It depends on the types of the bug found. The\npreliminary testing requires various types of experts. The stable version of subroutines can be kept by less educated computer scientists. The consecutive stopping\ntimes are moments when the expert of the defined class stops testing one module\nand the another tester starts checking. Similarly as in the proof reading.\n\n2 The optimization problem and a two person game\n2.1 Filtrations and Markov moments\nLet the sequences of pairs {(Tn , zn )}\u221e\nn=0 be 2-variate renewal process (A-marked\nrenewal process) defined on (\u03a9 , F , P). According to the denotation of the previous\n{i}\nsection there are three renewal processes {Tn }\u221e\nn=0 , i = 1, 2, 3, and denoted by Tn =\n{zn }\n{i}\n{i}\nTNz (Tn +) . There are also three renewal\u2013rewarded processes {(Tn , Xn )}\u221e\nn=0 , i =\nn\n\n{z }\n\n1, 2, 3 . By convention let us denote Xn = XNz n(Tn ) . The following \u03c3 -field generated\nn\nby history of the A-marked renewal processes are defined\nFt = FtA = \u03c3 (X0 , T0 , z0 . . . , XN(t) , TN(t) , zN(t) ),\nfor t \u2265 0. This \u03c3 -field can be defined as\n\n(7)\n\n\fAnglers' fishing problem\n\n7\n\n\u2212\n\u2192\nFtA = \u03c3 {( N (s), XN(s) , zN(s) ), 0 \u2264 s \u2264 t, i \u2208 A}.\n\nDefinition 1. Let T be a set of stopping times with respect to \u03c3 -fields {Ft }, t \u2265 0,\ndefined by (7). The restricted sets of stopping times are\nTn,K = {\u03c4 \u2208 T : \u03c4 \u2265 0, Tn \u2264 \u03c4 \u2264 TK }\n\n(8)\n\nfor n \u2208 N, n < K are subsets of T . The elements of Tn,K are denoted \u03c4n,K .\nThe stopping times \u03c4 \u2208 T have nice representation which will be helpful in the solution of the optimal stopping problems for the renewal processes (see Br\u00e9maud [3]).\nThe crucial role in our subsequent considerations plays such a representation. The\nfollowing lemma is for the unrestricted stopping times.\nLemma 1. If \u03c4 \u2208 T then there exist Rn \u2208 Mes(Fn ) such that the condition \u03c4 \u2227\nTn+1 = (Tn + Rn ) \u2227 Tn+1 on {\u03c4 \u2265 Tn } a.s. is fulfilled.\nVarious restrictions in the class of admissible stopping times will change this representation. Some examples of subclasses of T are formulated here (see Lemma 1).\nOnly a few of them are used in optimization problems investigated in the paper (see\npage 9, Corollary 1).\n{3}\n{3}\n{3}\n{3}\nLet Fs,t = \u03c3 (FsA , X0 , T0 , . . . , XN ((t\u2212s))+ , TN ((t\u2212s)+ ) ) be the \u03c3 -field gener3\n3\nated by all events up to time t if the switch at time s from 2-variate renewal\nprocess to another renewal process took place. For simplicity of notation we set2\n{i}\n{i}\nFn := F {i} , Fn := FTn , Fns := F {3} . Let Mes(Fn ) (Mes(Fn )) denote the\nTn\n\ns,Tn\n\n{i}\n\nset of non-negative and Fn (Fn )-measurable random variables. From now on,\nT and T s stands for the sets of stopping times with respect to \u03c3 -fields Fs and\n{Fs,t , 0 \u2264 s \u2264 t}, respectively. Furthermore, we can define for n \u2208 N and n \u2264 K the\nsets\n{i}\n\n{i}\n\n1. Tn,K = {\u03c4 \u2208 T : \u03c4 \u2265 0, Tn\n2.\n3.\n\n{i}\nTn = {\u03c4 \u2208 T\n{i,A{\u2212i} }\nT \u0304n,K\n= {\u03c4\n\n:\u03c4 \u2265\n\n\u2264 \u03c4 \u2264 TK };\n\n{i}\nTn };\n{i}\n\n\u2208 T : \u03c4 \u2265 0, Tn\nA\u2212i\n\nwhere A{\u2212i} := A \\ {i}, Tk\n\n\u2212i\n\n:= min{ j\u2208A{\u2212i} } {T { j}\nn\n\n{i}\n\n(Tk )\n{i}\n\n\u2212i\n{i}\n{i}\nA\u2212i \u2228 T\n4. T \u0304n = {\u03c4 \u2208 T : \u03c4 \u2265 Tn , \u2200k \u03c4 \u2208\n/ [TkA , Tk+1\n{i}\n\nn\n\n{3}\n\n{i}\n\nn\n\n{ j}\n\ns = {\u03c4 \u2208 T s : 0 \u2264 s \u2264 \u03c4 , T\n5. Tn,K\nn\n\n\u2212i\n\nA \u2228T\n\u2264 \u03c4 \u2264 TK , \u2200k \u03c4 \u2208\n/ [TkA , Tk+1\n{i}\n\n\u2212i\n\n(TkA )\n\n]}\n\n};\n\n\u2212i\n\n(TkA )\n\n]};\n\n\u2264 \u03c4 \u2264 TK }.\n\nThe stopping times \u03c4 \u2208 T {i} and \u03c4 \u2208 T \u0304 {i} can also be represented in the way shown\nin Lemma 1.\n2 For the optimization problem there are two epochs: before the first stop, where there are some\npay-offs, the model of stream of events, and after the first stop, when there are other pay-offs and\ndifferent streams of events. In section 3 this will be emphasized, by adopting adequate denotations.\n\n\f8\n\nA. Karpowicz, K. Szajowski\n\nLemma 2. Let the index i \u2208 A be chosen and fixed.\n{i}\n\n{i}\n\n{i}\n\n1. For every \u03c4 \u2208 T {i} and n \u2208 N there exist Rn \u2208 Mes(Fn ) such that \u03c4 \u2227 Tn+1 =\n2.\n\n{i}\n\u2265 Tn } a.s. is fulfilled.\n{i}\n{i}\nexist Rn \u2208 Mes(Fn ) such\n{i}\n{i}\n{i}\n{i}\n(Tn + Rn ) \u2227 Tn+1 on {\u03c4 \u2265 Tn } a.s. is fulfilled.\n\n{i}\n{i}\n{i}\n(Tn + Rn ) \u2227 Tn+1 on {\u03c4 {i}\nIf \u03c4 \u2208 T \u0304 {i} and n \u2208 N there\n{i}\n\nTn+1 =\n\nthat the condition \u03c4 \u2227\n\nObviously the angler wants to have as much satisfaction as possible and he has\nto leave the lake before the fixed moment. Therefore, his goal is to find two optimal\n\u2217\n\u2217\nstopping times \u03c4 a and \u03c4 b so that the expected gain is maximized\n\u2217\n\n\u2217\n\nEZ(\u03c4 a , \u03c4 b ) = sup\n\n\u03c4 a \u2208T\n\nsup EZ(\u03c4 a , \u03c4 b ),\n\na\n\u03c4 b \u2208T \u03c4\n\n(9)\n\n\u2217\n\nwhere \u03c4 a corresponds to the moment, when he eventually should change the two\n\u2217\nrods to the more effective one and \u03c4 b , when he should stop fishing. These stopping moments should appear before the fixed time of fishing t0 . The process Z(s,t)\nis piecewise-deterministic and belongs to the class of semi-Markov processes. The\noptimal stopping of similar semi-Markov processes was studied by Boshuizen and\nGouweleeuw [1] and the multivariate point process by Boshuizen [2]. Here the\nstructure of multivariate processes is discovered and their importance for the model\nis shown. We use the dynamic programming methods to find these two optimal\nstopping times and to specify the expected satisfaction of the angler. The way of the\nsolution is similar to the methods used by Karpowicz and Szajowski [13], Karpowicz [12] and Szajowski [22]. Let us first observe that by the properties of conditional\nexpectation we have\ni\nh\n\u2217\n\u2217\n\u2217\nEZ(\u03c4 a , \u03c4 b ) = sup E{E Z(\u03c4 a , \u03c4 b )|F\u03c4 a } = sup EJ(\u03c4 a ),\n\u03c4 a \u2208T\n\nwhere\n\n\u03c4 a \u2208T\n\nh\nh\ni\ni\n\u2217\nJ(s) = E Z(s, \u03c4 b )|Fs = ess sup E Z(s, \u03c4 b )|Fs .\n\n(10)\n\n\u03c4 b \u2208T s\n\n\u2217\n\n\u2217\n\nTherefore, in order to find \u03c4 a and \u03c4 b , we have to calculate J(s) first. The process\nJ(s) corresponds to the value of the revenue function in one stopping problem if the\nobservation starts at the moment s.\n\n2.2 Anglers' games\nBased on the consideration of the section 1.2 a version of competitive fishing is\nformulated here. There are two anglers, each using one method of fishing at the\nbeginning of an expedition and an additional fishing period after a certain moment\nby another method up to the moment chosen by a certain rule. The random field\nwhich is the model of payoffs in such a case is given by (5) and (6). The final\n\n\fAnglers' fishing problem\n\n9\n\nsegment starts at the moment when one of the anglers wants it. Let \u03c4i \u2208 T \u0304 {i} , i = A,\nbe the strategies of the players to stop individual fishing period and switch to the\ntime segment which is stopped at moment \u03c3 determined by one angler (let us call\nthem a leader). The payoffs of the players are\n\n\u03c8i (\u03c41 , \u03c42 ) = Zi (zN(\u03c41 \u2227\u03c42 ) , \u03c41 \u2227 \u03c42 , \u03c3 \u03c41 \u2227\u03c42 )I{\u03c41 6=\u03c42 }\n+Zi (zN(\u03c41 \u2227\u03c42 ) \u2227 zN(\u03c41 \u2227\u03c42 ) , \u03c41 \u2227 \u03c42 , \u03c3\n\n(11)\n\n\u03c41 \u2227 \u03c42\n\n)I{\u03c41 =\u03c42 } .\n\nThe aim is to find a pair (\u03c41\u22c6 , \u03c42\u22c6 ) of stopping times such that for i \u2208 {1, 2} we have\n\u22c6\n\u22c6\nE\u03c8i (\u03c4i\u22c6 , \u03c4\u2212i\n) \u2265 E\u03c8i (\u03c4i , \u03c4\u2212i\n).\n\n(12)\n\nThe optimization problem of the angler and the game between two anglers will\ninvolve the construction of the optimal second stopping moment.\n\n3 Construction of the optimal second stopping time\nIn this section, we will find the solution of one stopping problem defined by (10).\nWe will first solve the problem for the fixed number of fishes caught, next we will\nconsider the case with the infinite stream of fishes caught. In this section we fix\ns - the moment when the change took place and m = Ms - the mass of the fishes\nat the time s. Taking into account various models of fishing after the first stop it\nis needed to admit various models of stream of events. Assume that the moments\n{3}\nof successive fishes catching after the first stop are Tn and the times between\nthe events are i.i.d. with continuous, cumulative distribution function F(t) with the\ndensity function f(t)and the fishes value represented by i.i.d. random variables with\ndistribution function H(t) (for conveniences this part of expedition is modelled by\n{3}\n{3}\nthe renewal process denoted (Tn , Xn )).\n\n3.1 Fixed number of fishes caught\n\u2217\n\nb := \u03c4 b\nIn this subsection we are looking for optimal stopping time \u03c40,K\nK\n\nh\nh\ni\ni\n\u2217\nE Z(s, \u03c4Kb )|Fs = ess sup E Z(s, \u03c4Kb )|Fs ,\n\n\u2217\n\n(13)\n\ns\n\u03c4Kb \u2208T0,K\n\nwhere s \u2265 0 is a fixed time when the position was changed and K is the maximum\nnumber of fishes which can be caught. Let us define\ni\nh\ni\nh\ns\nb\nb\u2217\n\u0393n,K\n= ess sup E Z(s, \u03c4n,K\n)|Fns = E Z(s, \u03c4n,K\n)|Fns , n = K, . . . , 1, 0 (14)\nb \u2208T s\n\u03c4n,K\nn,K\n\n\f10\n\nA. Karpowicz, K. Szajowski\n{3}\n\ns = Z(s, T\nand observe that \u0393K,K\nK ). In the subsequent considerations we will use the\nrepresentation of stopping time formulated in Lemma 1 and 2. The exact form of\nthe stopping strategies are given in the following corollary.\n{i}\n\nCorollary 1. Let i \u2208 A. If \u03c4 a \u2208 T {i} , \u03c4 b \u2208 T s , then there exist Ran \u2208 Mes(Fn ) and\n{i}\n{i}\n{i}\nRbn \u2208 Mes(Fns ) respectively, such that for conditions \u03c4 a \u2227 Tn+1 = (Tn + Ran ) \u2227 Tn+1\n{i}\n\n{3}\n\n{3}\n\non {\u03c4 a \u2265 Tn } a.s. and \u03c4 b \u2227 Tn+1 = (Tn\nvalid.\n\n{3}\n\n{3}\n\n+ Ran ) \u2227 Tn+1 on {\u03c4 a \u2265 s \u2227 Tn } a.s. are\n\ns . To\nNow we can derive the dynamic programming equations satisfied by \u0393n,K\n{1}\nbn = MT 1 , Mns = M s {3} and\nsimplify the notation we can write Mt = Mts for t \u2264 s, M\nn\n\nTn\n\nF\u0304i = 1\u2212Fi . The payoff functions are simplified here to \u011da (m) = ga (m1 , m2 , i,t)I{m1 +m2 =m} (m1 , m2 ),\n\u011db (m) = gb (m1 , m2 , i, s, m,t)I\ne\n{m\u2212m\ne\n1 \u2212m2 =m}\nLemma 3. Let s \u2265 0 be the moment of changing fishery. For n = K \u2212 1, K \u2212 2, . . . , 0\n{3}\n\ns = Z(s, T\n\u0393K,K\nK ),\n{3}\ns\n\u0393n,K = ess supRbn \u2208Mes(Fns ) \u03b8n,K (Ms , s, Mns , Tn , Rbn ) a.s.,\n\n(15)\n\nwhere\n\u001a\ne r) = I{t\u2264t0 } F\u0304(r)[I {r\u2264t0 \u2212t} \u0175b (m, s, m,t\ne + r) \u2212 CI{r>t0 \u2212t} ]\n\u03b8n,K (m, s, m,t,\n\u0014\n\u0015\u001b\ns\n+ E I {3} \u0393n+1,K\n\u2212 CI{t>t0 }\n|Fns\n{S\n\u2264r}\nn+1\n\n\u22c6\n\nand there exists Rbn \u2208 Mes(Fns ) such that\n{3}\n\n\u22c6\n\ns\n\u0393n,K\n= \u03b8n,K (Ms , s, Mns , Tn , Rbn ) a.s.,\nb\u2217\n\u03c4n,K\n\u2217\n\n=\n\n(\n\n\u2217\n\n\u2217\n\n(16)\n\n{3}\n\nb\n\u03c4n+1,K\nif Rbn \u2265 Sn+1 ,\n\u2217\n\u2217\n{3}\n{3}\nTn + Rbn if Rbn < Sn+1 ,\n\n(17)\n\n{3}\n\nb =T\nb\n\u03c4K,K\ne = \u0175a (m, s) + \u011db (m\u2212\ne m) \u2212 cb(t \u2212 s) where \u0175a (m,t) =\nK and \u0175 (m, s, m,t)\na\na\n\u011d (m) \u2212 c (t).\n\u2217\n\n\u2217\n\nRemark 2. Let {Rbn }Kn=1 , RbK = 0, be a sequence of Fns \u2013measurable random\nh vari\u22c6\n\n\u2217\n\n{3}\n\ns\n\u22c6s = K \u2227inf{i \u2265 n : Rb < S\ns\nb\nables, n = 1, 2, . . ., K, and \u03b7n,K\ni\ni+1 }. Then \u0393n,K = E Z(s, \u03c4n,K )|Fn\n\u2217\n\n\u22c6\n\nb = T \u22c6s + Rb .\nfor n \u2264 K \u2212 1, where \u03c4n,K\n\u03b7n,K\n\u03b7 \u22c6s\nn,K\n\nP ROOF\n\nOF REMARK .\n\n\u22c6\n\n2. It is a consequence of an optimal choice Rb n in (15).\n\u0004\n\ni\n\n\fAnglers' fishing problem\n\n11\n{3}\n\ns for the case T\n> t0\nP ROOF OF LEMMA . 3 First observe that the form of the \u0393n,K\nn\nis obvious from (4) and (14). Let us assume (15) and (16) for n + 1, n + 2, . . ., K. For\ns (i.e. \u03c4 \u2265 T {3} we have {\u03c4 < T {3} } = {\u03c4 \u2227T {3} < T {3} } = {T {3} +Rb <\nany \u03c4 \u2208 Tn,K\nn\nn\nn\nn+1\nn+1\nn+1\n{3}\n\nTn+1 }. It implies\n{3}\n\n{3}\n\n{3}\n\n{3}\n\n{\u03c4 < Tn+1 } = {Sn+1 > Rbn }, {\u03c4 \u2265 Tn+1 } = {Sn+1 \u2264 Rbn }.\n\n(18)\n\n{3}\n\nb\ns\n\u2208 TK\u22121,K\n. According to (18) and the\nSuppose that TK\u22121 \u2264 t0 and take any \u03c4K\u22121,K\nproperties of conditional expectation\n\u0015\n\u0014\n{3}\ns\nE [Z(s, \u03c4 )|Fns ] = E I {3} b E[Z(s, \u03c4 \u2228 Tn+1 )|Fn+1\n]|Fn\n{Sn+1 \u2264Rn }\n\u0015\n\u0014\n{3}\n+ E I {3} b Z(s, \u03c4 \u2227 Tn+1 )|Fns\n{Sn+1 >Rn }\n\n{3}\n\n= I{Rbn \u2264t0 \u2212Tn } F\u0304(Rn )\u0175b (Ms , s, Mns , Tn + Rbn )\n\u0014\n\u0015\n{3}\ns\ns\n+ E I {3} b E[Z(s, \u03c4 \u2228 Tn+1 )|Fn+1 |Fn .\n{Sn+1 \u2264Rn }\n\nb . For every \u03c4 \u2208 T we have\nLet \u03c3 \u2208 Tn+1\nn\n(\n{3}\n\u03c3\nif Rbn \u2265 Sn+1 ,\n\u03c4=\n{3}\n{3}\nTn + Rbn if Rbn < Sn+1 .\n\nWe have\n\u0014\nE[Z(s, \u03c4 )|Fns ] = E I\n\n{3}\n{Sn+1 \u2264Rb\nn}\n\ns\nE[Z(s, \u03c3 )|Fn+1\n]|Fn\n\n\u0015\n\n{3}\n\n+ I{Rbn \u2264t0 \u2212Tn } F\u0304(Rbn )\u0175b (Ms , s, Mns , Tn + Rbn )\n\u0015\n\u0014\ns\n\u0393n+1,K |Fn\n\u2264 sup {E I {3}\nR\u2208Mes(Fns )\n\n{Sn+1 \u2264R}\n\n{3}\n\n+ I{R\u2264t0 \u2212Tn } F\u0304(R)\u0175b (Ms , s, Mns , Tn\n\n\u22c6\n+ R)} = E[Z(s, \u03c4n,K\n|Fns ]\n\n\u22c6 |F s ] \u2264 sup\ns\nIt follows sup\u03c4 \u2208Tns E[Z(s, \u03c4 )|Fns ] \u2264 E[Z(s, \u03c4n,K\nn\n\u03c4 \u2208Tnb E[Z(s, \u03c4 )|Fn ] where\n\u22c6\ns\nthe last inequality is because \u03c4n,K \u2208 Tn,K . We apply the induction hypothesis, which\ncompletes the proof.\nz\n{3}\n\ns = \u03b3 s,Ms (M s , T\nLemma 4. \u0393n,K\nn n ) for n = K, . . . , 0, where the sequence of functions\nK\u2212n\ns,m\n\u03b3 j is given recursively as follows:\n\n\f12\n\nA. Karpowicz, K. Szajowski\n\n\u03b30s,m (m,t)\ne = I{t\u2264t0 } \u0175b (m, s, m,t)\ne \u2212 CI{t>t0 } ,\n\ne = I{t\u2264t0 } sup \u03ba\u03b3bs,m (m, s, m,t,\n\u03b3 s,m\ne r) \u2212 CI{t>t0 } ,\nj (m,t)\n\nwhere\n\n(19)\n\nj\u22121\n\nr\u22650\n\n\u03ba\u03b4b (m, s, m,t,\ne r) = F\u0304(r)[I {r\u2264t0 \u2212t} \u0175b (m, s, m,t\ne + r) \u2212 CI{r>t0 \u2212t} ]\n+\n\nZ r\n\ndF(z)\n\nZ \u221e\n\n\u03b4 (m\ne + x,t + z)dH(x).\n\n0\n\n0\n\nP ROOF OF LEMMA . 4. Since the case for t > t0 is obvious let us assume that\n\u2264 t0 for n \u2208 {0, . . . , K \u2212 1}. Let us notice that according to Lemma 3 we obtain\n{3}\n= \u03b30s,Ms (MKs , TK ), thus the proposition is satisfied for n = K. Let n = K \u2212 1\nthen Lemma 3 and the induction hypothesis leads to\n\u001a\n{3}\ns\nb\ns\nb\n\u0393K\u22121,K\n=\ness sup\nF\u0304(RbK\u22121 )[I b\n{3} \u0175 (Ms , s, MK\u22121 , TK\u22121 + RK\u22121 )\n{3}\nTn\ns\n\u0393K,K\n\n{RK\u22121 \u2264t0 \u2212TK\u22121 }\n\nRb\nK\u22121 \u2208Mes(Fs,K\u22121 )\n\n\u2212 CI\n\n{3}\n\n{Rb\nK\u22121 >t0 \u2212TK\u22121 }\n\n\u0014\n]+E I\n\n{3}\n\n{3}\n\ns\nwhere MKs = MK\u22121\n+ XK , TK\n{3}\n\n{3}\n\n{3}\n\n{SK \u2264Rb\nK\u22121\n\n\u03b3 s,Ms (MKs , TK )|Fs,K\u22121\n} 0\n\n{3}\n\n{3}\n\n= TK\u22121 + SK\n\n\u0015\u001b\n\na.s.,\n{3}\n\nand the random variables XK\n{3}\n\ns\nand SK are independent of Fs,K\u22121 . Moreover RbK\u22121 , MK\u22121\nand TK\u22121 are Fs,K\u22121 measurable. It follows\n\u001a\n{3}\nb\ns\nb\ns\nF\u0304(RbK\u22121 )[I b\ness sup\n\u0393K\u22121,K =\n{3} \u0175 (Ms , s, MK\u22121 , TK\u22121 + RK\u22121 )\n{RK\u22121 \u2264t0 \u2212TK\u22121 }\n\nRb\nK\u22121 \u2208Mes(Fs,K\u22121 )\n\n\u2212 CI\n=\n\n{3}\n\n{Rb\nK\u22121 >t0 \u2212TK\u22121 }\n\n]+\n\n{3}\ns\n\u03b31s,Ms (MK\u22121\n, TK\u22121 )\n\nZ Rb\nK\u22121\n\ndF(z)\n\n0\n\nZ \u221e\n0\n\n\u001b\n{3}\ns\n+ x, TK\u22121 + z)dH(x)\n\u03b30s,Ms (MK\u22121\n\na.s.\n{3}\n\ns = \u03b3 s,Ms (M s , T\nLet n \u2208 {1, . . . , K \u22121} and suppose that \u0393n,K\nn n ). Similarly like before,\nK\u2212n\nwe conclude by Lemma 3 and induction hypothesis that\n\u001a\n{3}\ns\nb\ns\nb\n\u0393n\u22121,K =\ness sup\nF\u0304(Rbn\u22121 )[I b\n{3} \u0175 (Ms , s, Mn\u22121 , Tn\u22121 + Rn\u22121 )\n{Rn\u22121 \u2264t0 \u2212Tn\u22121 }\n\ns\nRb\nn\u22121 \u2208Mes(Fn\u22121 )\n\n\u2212 CI\n\n{3}\n\n{Rb\nn\u22121 >t0 \u2212Tn\u22121 }\n\n]+\n\nZ Rb\nn\u22121\n\ndF(s)\n\nZ \u221e\n0\n\n0\n\n\u001b\n{3}\ns,Ms\ns\n\u03b3K\u2212n\n(Mn\u22121\n+ x, Tn\u22121 + s)dH(x) a.s.\n\n{3}\n\ns,Ms\ns\ns ,T\ntherefore \u0393n\u22121,K\n= \u03b3K\u2212(n\u22121)\n(Mn\u22121\nn\u22121 ).\n\nz\n\n\fAnglers' fishing problem\n\n13\n\nFrom now on we will use \u03b1i to denote the hazard\u0002rate of the distribution\n\u0003 Fi (i.e.\n\u03b1i = fi /F\u0304i ) and to shorten notation we set \u2206 * (a) = E \u011d* (a + X {i}) \u2212 \u011d*(a) , where *\ncan be a or b.\nRemark 3. The sequence of functions \u03b3 s,m\nj can be expressed as:\n\ne = I{t\u2264t0 } \u0175b (m, s, m,t)\ne \u2212 CI{t>t0 } ,\n\u03b30s,m (m,t)\n\u001a\n\u001b\nb\nb\n\u0175\n(m,\ns,\nm,t)\ne\n+\ny\n(\nm\ne\n\u2212\nm,t\n\u2212\ns,t\n\u2212\nt)\n\u2212 CI{t>t0 }\n(\nm,t)\ne\n=\nI\n\u03b3 s,m\n0\n{t\u2264t0 }\nj\nj\n\nand ybj (a, b, c) is given recursively as follows\n\nyb0 (a, b, c) = 0\nybj (a, b, c) = max \u03c6ybb (a, b, c, r),\n0\u2264r\u2264c\n\nwhere \u03c6\u03b4b (a, b, c, r) =\nz)}dz.\nP ROOF\nZ r\n0\n\nRr\n0\n\nOF REMARK .\n\ndF(s)\n\nZ \u221e\n0\n\nj\u22121\n\n\u0002\n\u0003\n\u2032\nF\u0304(z){\u03b12 (z) \u2206 b (a) + E\u03b4 (a + X {3}, b + z, c \u2212 z) \u2212 cb (b +\n3 Clearly\n\nh\ni\ns,m\n{3}\n{3}\n(\nm\ne\n+\nx,t\n+\ns)dH(x)\n=\nE\nI\n(\nm\ne\n+\nX\n,t\n+\nS\n)\n,\n\u03b3 s,m\n\u03b3\n{3}\nj\u22121\n{S \u2264r} j\u22121\n\ne r)\nwhere S{3} has c.d.f. F and X {3} has c.d.f. H. Since F is continuous and \u03ba\u03b3bs,m (m, s, m,t,\nj\u22121\n\nis bounded and continuous for t \u2208 R+ \\ {t0 }, the supremum in (19) can be changed\ninto maximum. Let r > t0 \u2212 t then\nh\ni\ne r) = E I{S{3} \u2264t0 \u2212t} \u03b3 s,m\n\u03ba\u03b3bs,m (m, s, m,t,\n(m\ne + X {3},t + S{3}) \u2212 CF\u0304(t0 \u2212 t)\nj\u22121\nj\u22121\ni\nh\n{3}\n{3}\n(\nm\ne\n+\nX\n,t\n+\nS\n)\n+ F\u0304(t0 \u2212 t)\u0175b (m, s, m,t\ne 0)\n\u2264 E I{S{3} \u2264t0 \u2212t} \u03b3 s,m\nj\u22121\ne 0 \u2212 t).\n= \u03ba\u03b3bs,m (m, s, m,t,t\nj\u22121\n\ne r) \u2212\nThe above calculations cause that \u03b3 s,m\ne = I{t\u2264t0 } max0\u2264r\u2264t0 \u2212t \u03c6 j (m, s, m,t,\nj (m,t)\nh\ni\ns,m\nb\nCI{t>t0 } , where \u03c6 j (m, s, m,t,\ne r) = F\u0304(r)\u0175 (m, s, m,t\ne +r)+E I{S{3} \u2264r} \u03b3 j\u22121 (m\ne + X {3},t + S{3}) .\nObviously for S{3} \u2264 r and r \u2264 t0 \u2212t we have S{3} \u2264 t0 therefore we can consider the\ne = \u0175b (m, s, m,t)\ne and the\ncases t \u2264 t0 and t > t0 separately. Let t \u2264 t0 then \u03b30s,m (m,t)\n(\nm,t)\ne\ngiven\nhypothesis is true for j = 0. The task is now to calculate \u03b3 s,m\n\u03b3 s,m\nj (*, *).\nj+1\nThe induction hypothesis implies that for t \u2264 t0\n\n\f14\n\nA. Karpowicz, K. Szajowski\n\nh\n\ni\ne r) = F\u0304(r)\u0175b (m, s, m,t\ne + r) + E I{S{3} \u2264r} \u03b3 s,m\ne + X {3},t + S{3})\n\u03c6 j+1 (m, s, m,t,\nj (m\nh\ni\n= \u011da (m) \u2212 ca (s) + F\u0304(r) \u011db (m\ne \u2212 m) \u2212 cb(t \u2212 s + r)\n+\n\nZ r\n0\n\nf(z){E\u011db (m\ne \u2212 m + X {3}) \u2212 cb (t \u2212 s + z)\n\n+ Eybj (m\ne \u2212 m + X {3},t \u2212 s + z,t0 \u2212 t \u2212 z)}dz.\n\nIt is clear that for any a and b\nh\ni\nF\u0304(r) \u011db (a) \u2212 cb(b + r) = \u011db (a) \u2212 cb(b)\nZ r\nh\ni\n\u2032\n\u2212 {f(z) \u011db (a) \u2212 cb(b + z) + F\u0304(z)cb (b + z)}dz,\n0\n\ntherefore\n\n\u03c6 j+1 (m, s, m,t,\ne r) = \u0175b (m, s, m,t)\ne +\n\n+ Eybj (m\ne\u2212m+X\n\nZ r\n\n0\n{3}\n\ne \u2212 m)\nF\u0304(z){\u03b12 (z)[\u2206 b (m\n\n\u2032\n\n,t \u2212 s + z,t0 \u2212 t \u2212 z)] \u2212 cb (t \u2212 s + z)}dz,\n\nwhich proves the theorem. The case for t > t0 is trivial.\n\u0004\nFollowing the methods of Ferenstein and Sieroci\u0144ski [6], we find the second optimal stopping time. Let B = B([0, \u221e) \u00d7 [0,t0 ] \u00d7 [0,t0]) be the space of all bounded,\ncontinuous functions with the norm k\u03b4 k = supa,b,c |\u03b4 (a, b, c)|. It is easy to check\nthat B with the norm supremum is complete space. The operator \u03a6 b : B \u2192 B is\ndefined by\n(20)\n(\u03a6 b \u03b4 )(a, b, c) = max \u03c6\u03b4b (a, b, c, r).\n0\u2264r\u2264c\n\nLet us observe that ybj (a, b, c) = (\u03a6 b ybj\u22121 )(a, b, c). Remark 3 now implies that there\n\u2217\n\u2217\nexists a function rb j (a, b, c) such that ybj (a, b, c) = \u03c6ybb (a, b, c, rb j (a, b, c)) and this\nj\u22121\n\ngives\n\u001a\nb\ne\n(\nm,t)\ne\n=\nI\n\u03b3 s,m\n{t\u2264t0 } \u0175 (m, s, m,t)\nj\n\n\u001b\n\u2217\n+ \u03c6ybb (m\ne \u2212 m,t \u2212 s,t0 \u2212 t, rbj (m\ne \u2212 m,t \u2212 s,t0 \u2212 t)) \u2212 CI{t>t0 } .\nj\u22121\n\nThe consequence of the foregoing considerations is the theorem, which determines\nb\u2217\noptimal stopping times \u03c4n,K\nin the following manner:\n\u2217\n\n\u2217\n\n{3}\n\nb (M s \u2212 M , T\nTheorem 1. Let Rbi = rK\u2212i\ns i\ni\n\nover\n\ns\n\u03b7n,K\n\n= K \u2227 inf{i \u2265\n\n\u2217\nn : Rbi\n\n{3}\n< Si+1 },\n\ns and \u0393 s\nis optimal in the class Tn,K\nn,K\n\n{3}\n\n\u2212 s,t0 \u2212 Ti\n\n) for i = 0, 1, . . . , K more\u2217\n\n{3}\n\n\u2217\n\nb =T\nb\nthen the stopping time \u03c4n,K\ns + R\u03b7 s\n\u03b7n,K\nn,K\ni\nh\nb\u2217 )|F s .\n= E Z(s, \u03c4n,K\nn\n\n\fAnglers' fishing problem\n\n15\n\n3.2 Infinite number of fishes caught\n\u2217\n\nThe task is now to find the function J(s) and stopping time \u03c4 b , which is optimal in\nclass T s . In order to get the solution of one stopping problem for infinite number\nof fishes caught it is necessary to put the restriction F(t0 ) < 1.\nLemma 5. If F(t0 ) < 1 then the operator \u03a6 b : B \u2192 B defined by (20) is a contraction.\nP ROOF OF LEMMA . 5. Let \u03b4i \u2208 B assuming that i \u2208 {1, 2}. There exists \u03c1i such that\n(\u03a6 b \u03b4i )(a, b, c) = \u03c6\u03b4bi (a, b, c, \u03c1i ). We thus get\n(\u03a6 b \u03b41 )(a, b, c) \u2212 (\u03a6 b \u03b42 )(a, b, c) = \u03c6\u03b4b1 (a, b, c, \u03c11 ) \u2212 \u03c6\u03b4b2 (a, b, c, \u03c12 )\n\u2264 \u03c6\u03b4b1 (a, b, c, \u03c11 ) \u2212 \u03c6\u03b4b2 (a, b, c, \u03c11 )\n=\n\nZ \u03c11\n\ndF(z)\n\n0\n\n0\n\n\u2264\n\nZ \u03c11\n\nZ \u221e\n\ndF(z)\n\nZ \u221e\n\n[\u03b41 \u2212 \u03b42 ](a + x, b + z, c \u2212 s)dH(x)\nsup |[\u03b41 \u2212 \u03b42 ](a, b, c)|dH(x)\n\n0 a,b,c\n\n0\n\n\u2264 F(c) k\u03b41 \u2212 \u03b42 k \u2264 F(t0 ) k\u03b41 \u2212 \u03b42 k \u2264 C k\u03b41 \u2212 \u03b42 k ,\nwhere 0 \u2264 C < 1. Similarly, like as before, (\u03a6 b \u03b42 )(a, b, c) \u2212 (\u03a6 b \u03b41 )(a, b, c) \u2264\nC k\u03b42 \u2212 \u03b41 k. Finally we conclude that \u03a6 b \u03b41 \u2212 \u03a6 b \u03b42 \u2264 C k\u03b41 \u2212 \u03b42 k which completes the proof.\nz\nApplying Remark 3, Lemma 5 and the fixed point theorem we conclude\nRemark 4. There exists yb \u2208 B such that yb = \u03a6 b yb and limK\u2192\u221e kybK \u2212 yb k = 0.\nAccording to the above remark, yb is the uniform limit of ybK , when K tends to\ninfinity, which implies that yb is measurable and \u03b3 s,m = limK\u2192\u221e \u03b3Ks,m is given by\nh\ni\n\u03b3 s,m (m,t)\ne + yb(m\ne \u2212 m,t \u2212 s,t0 \u2212 t) \u2212 CI{t>t0 } .\n(21)\ne = I{t\u2264t0 } \u0175b (m, s, m,t)\nWe can now calculate the optimal strategy and the expected gain after changing the\nplace.\nTheorem 2. If F(t0 ) < 1 and has the density function f, then\n\u22c6\n\n\u2217\n\n\u22c6\n\nb a.s. exists and \u03c4 b \u2264 t is an optimal\n(i) for n \u2208 N the limit \u03c4nb = limK\u2192\u221e \u03c4n,K\n0\nn\n{3}\n\nstopping rule in the set T s \u2229 {\u03c4 \u2265 Tn },\n\u0003\n\u0002\n\u22c6\n{3}\n(ii)E Z(s, \u03c4nb )|Fns = \u03b3 s,m (Mns , Tn ) a.s.\n\n\u22c6\n\ns\nP ROOF. (i) Let us first prove the existence of \u03c4nb . By definition of \u0393n,K+1\nwe have\ns\n\u0393n,K+1\n= ess sup E [Z(s, \u03c4 )|Fns ] = ess sup E [Z(s, \u03c4 )|Fns ] \u2228 ess sup E [Z(s, \u03c4 )|Fns ]\ns\n\u03c4 \u2208Tn,K+1\n\nh\n\n\u2217\n\ni\n\ns\n\u03c4 \u2208Tn,K\n\nb\n= E Z(s, \u03c4n,K\n)|Fns \u2228 E [Z(s, \u03c3 \u2217 )|Fns ]\n\ns\n\u03c4 \u2208TK,K+1\n\n\f16\n\nA. Karpowicz, K. Szajowski\nb\u2217\n\nb\u2217\n\n\u2217\n\nb \u2208 T s and \u03c3 \u2217 \u2208\nthus we observe that \u03c4n,K+1 is equal to \u03c4n,K or \u03c3 \u2217 , where \u03c4n,K\nn,K\n\u2217\n\u2217\ns\nb\nb which implies that the sequence\nTK,K+1\nrespectively. It follows that \u03c4n,K+1\n\u2265 \u03c4n,K\n\u2217\n\n\u2217\n\n{3}\n\nb is nondecreasing with respect to K. Moreover Rb \u2264 t \u2212 T\n\u03c4n,K\nfor all i \u2208\n0\ni\ni\nb\u2217 \u2264 t and therefore \u03c4 b\u22c6 \u2264 t exists.\n{0, . . . , K} thus \u03c4n,K\n0\n0\nn\nLet us now look at the process \u03be s (t) = (t, Mts ,V (t)), where s is fixed and V (t) =\n{3}\nt \u2212 TN (t) . \u03be s (t) is Markov process with the state space [s,t0 ] \u00d7 [m, \u221e) \u00d7 [0, \u221e). In a\n3\ngeneral case the infinitesimal operator for \u03be s is given by\n\n\u2202 s,m\n\u2202 s,m\np (t, m,\ne v) +\np (t, m,\ne v)\n\u2202t \u001a\n\u2202v\n\nAps,m (t, m,\ne v) =\n\nZ\n\n+ \u03b12 (v)\n\nR+\n\n\u001b\nps,m (t, x, 0)dH(x) \u2212 ps,m (t, m,\ne v) ,\n\nwhere ps,m (t, m,\ne v) : [0, \u221e) \u00d7 [0, \u221e) \u00d7 [0, \u221e) \u2192 R is continuous, bounded, measurable\nwith bounded left-hand derivatives with respect to t and v (see [1] and [17]). Let\nus notice that for t \u2265 s the process Z(s,t) can be expressed as Z(s,t) = ps,m (\u03be s (t)),\nwhere\n\u001a a\n\u011d (Ms ) \u2212 ca(s) + \u011db (Mts \u2212 Ms ) \u2212 cb(t \u2212 s) if s \u2264 t \u2264 t0 ,\ns,m s\np (\u03be (t)) =\n\u2212C\nif t0 < t.\nIt follows easily that in our case Aps,m (t, m,\ne v) = 0 for t0 < t and\n\nAps,m (t, m,\ne v) = \u03b12 (v)[E\u011db (m\ne + X {3} \u2212 m) \u2212 \u011db(m\ne \u2212 m)] \u2212 cb\u2032(t \u2212 s)\n\n(22)\n\nRt\n\nfor s \u2264 t \u2264 t0 . The process ps,m (\u03be s (t)) \u2212 ps,m (\u03be s (s)) \u2212 s (Aps,m )(\u03be s (z))dz is a martingale with respect to \u03c3 (\u03be s (z), z \u2264 t) which is the same as Fs,t . This can be found\nb\u2217 \u2264 t , applying the Dynkin's formula we obtain\nin [4]. Since \u03c4n,K\n0\nh\n\nE p\n\ns,m\n\n(\u03be\n\ns\n\nb\u2217\n))|Fns\n(\u03c4n,K\n\ni\n\n\u2212p\n\ns,m\n\n(\u03be\n\ns\n\n{3}\n(Tn ))\n\n=E\n\n\"Z\n\n\u2217\n\nb\n\u03c4n,K\n{3}\n\nTn\n\n(Ap\n\ns,m\n\n)(\u03be\n\ns\n\n(z))dz|Fns\n\n#\n\na.s.\n(23)\n\nFrom (22) we conclude that\nZ \u03c4 b\u2217\nn,K\n{3}\n\nTn\n\n(Ap\n\ns,m\n\n)(\u03be (z))dz = [E\u011d\ns\n\n\u2212\n\nb\n\n(Mns + X {3} \u2212 m) \u2212 \u011db(Mns \u2212 m)]\n\nZ \u03c4 b\u2217\nn,K\n\nMoreover let us check that\n\n{3}\nTn\n\n\u2032\n\ncb (z \u2212 s)dz.\n\nZ \u03c4 b\u2217\nn,K\n{3}\n\nTn\n\n{3}\n\n\u03b12 (z \u2212 Tn )dz\n\n\fAnglers' fishing problem\n\nZ\n\nb\u2217\n\u03c4n,K\n{3}\nTn\n\nZ \u03c4 b\u2217\nn,K\n{3}\n\nTn\n\n17\n{3}\n\n\u03b12 (z \u2212 Tn )dz \u2264\n\u2032\n\n1\nF\u0304(t0 )\n\nZ\n\nb\u2217\n\u03c4n,K\n{3}\nTn\n\n{3}\n\nf(z \u2212 Tn )dz \u2264\n\n\u2217\n\n{3}\n\nb\n\u2212 s) \u2212 cb(Tn\ncb (z \u2212 s)dz = cb (\u03c4n,K\n\n1\n< \u221e,\nF\u0304(t0 )\n\n\u2212 s) < \u221e,\n\nE\u011db (Mns + X {3} \u2212 m) \u2212 \u011db(Mns \u2212 m) < \u221e,\nwhere the two last inequalities result from the fact that the functions \u011db and cb are\nbounded. On account of the above observation we can use the dominated convergence theorem and\n\" Z b\u2217\n#\n\" Z b\u22c6\n#\nlim E\n\nK\u2192\u221e\n\n\u03c4n,K\n\n{3}\nTn\n\n(Aps,m )(\u03be s (z))dz|Fns = E\n\n\u03c4n\n\n{3}\n\nTn\n\n(Aps,m )(\u03be s (z))dz|Fns .\n\n(24)\n\n\u22c6\n\nSince \u03c4nb \u2264 t0 applying the Dynkin's formula to the left side of (24) we conclude\nthat\n#\n\" Z b\u22c6\nh\ni\n\u03c4n\n{3}\ns\ns\ns,m s b\u22c6\ns\ns,m\n\u03be\n(z))dz|F\n=\nE\np\n(\n\u03be\n(\n\u03c4\n))|F\n\u2212 ps,m (\u03be s (Tn )) a.s.\n(Ap\n)(\nE\nn\nn\nn\n{3}\nTn\n\n(25)\n\nCombining (23), (24) and (25) we can see that\nh\ni\nh\ni\n\u2217\nb\u2217\nlim E ps,m (\u03be s (\u03c4n,K\n))|Fns = E ps,m (\u03be s (\u03c4nb ))|Fns ,\n\n(26)\n\nK\u2192\u221e\n\ni\nh\n\u0003\n\u0002\n\u2217\nb\u2217\n)|Fns = E Z(s, \u03c4nb )|Fns . We next prove the optihence that limK\u2192\u221e E Z(s, \u03c4n,K\n\u2217\n\n{3}\n\n{3}\n\nmality of \u03c4nb in the class T s \u2229 {\u03c4nb \u2265 Tn }. Let \u03c4 \u2208 T s \u2229 {\u03c4nb \u2265 Tn } and it is\n{3}\ns . As \u03c4 b\u2217 is optimal in the class T s we have\nclear that \u03c4 \u2227 TK \u2208 Tn,K\nn,K\nn,K\ni\nh\ni\nh\n{3}\nb\u2217\n))|Fns \u2265 lim E ps,m (\u03be s (\u03c4 \u2227 TK ))|Fns .\nlim E ps,m (\u03be s (\u03c4n,K\n\nK\u2192\u221e\n\nK\u2192\u221e\n\n(27)\n\n\u0002\n\u0003\n\u2217\nFrom (26) and (27) we conclude that E ps,m (\u03be s (\u03c4nb ))|Fns \u2265 E [ps,m (\u03be s (\u03c4 ))|Fns ]\n{3}\n\n\u2217\n\nfor any stopping time \u03c4 \u2208 T s \u2229 {\u03c4 \u2265 Tn }, which implies that \u03c4nb is optimal in this\nclass.\ni\nh\n\u2217\n{3}\n(ii) Lemma 4 and (26) lead to E Z(s, \u03c4nb )|Fns = \u03b3 s,Ms (Mns , Tn ).\n\u0003\n\nThe remainder of this section will be devoted to the proof of the left-hand differentiability of the function \u03b3 s,m (m, s) with respect to s. This property is necessary to\nconstruct the first optimal stopping time. First, let us briefly denote \u03b4 (0, 0, c) \u2208 B by\n\u03b4\u0304 (c).\nLemma 6. Let \u03bd\u0304 (c) = \u03a6 b \u03b4\u0304 (c), \u03b4\u0304 (c) \u2208 B and \u03b4\u0304+\u2032 (c) \u2264 A1 for c \u2208 [0,t0 ) then\n\u03bd\u0304+\u2032 (c) \u2264 A2 .\n\n\f18\n\nA. Karpowicz, K. Szajowski\n\nP ROOF OF LEMMA . 6. First observe that the derivative \u03bd\u0304+\u2032 (c) exists because\n\u03bd\u0304 (c) = max0\u2264r\u2264c \u03c6\u0304 b (c, r), where \u03c6\u0304 b (c, r) is differentiable with respect to c and r.\nFix h \u2208 (0,t0 \u2212 c) and define \u03b4\u03041 (c) = \u03b4\u0304 (c + h) \u2208 B and \u03b4\u03042 (c) = \u03b4\u0304 (c) \u2208 B. Obviously,\nk\u03a6 b \u03b4\u03041 \u2212 \u03a6 b \u03b4\u03042 k \u2265 |\u03a6 b \u03b4\u03041 (c) \u2212 \u03a6 b \u03b4\u03042 (c)| = |\u03a6 b \u03b4\u0304 (c + h) \u2212 \u03a6 b\u03b4\u0304 (c)| and on the other\nside using Taylor's formula for right-hand derivatives we obtain\n\n\u03b4\u03041 \u2212 \u03b4\u03042 = sup \u03b4\u0304 (c + h) \u2212 \u03b4\u0304 (c) \u2264 h sup \u03b4\u0304+\u2032 (c) + |o(h)| .\nc\n\nc\n\nFrom the above and Remark 8 it follows that\n\u001a\n\u001b\n\u001b\n\u001a\n\u03bd\u0304 (c + h) \u2212 \u03bd\u0304 (c)\n|o(h)|\n|o(h)|\n\u2032\n\u2032\n\u2212C sup \u03b4\u0304+ (c) +\n\u2264\n\u2264 C sup \u03b4\u0304+ (c) +\nh\nh\nh\nc\nc\nand letting h \u2192 0+ gives \u03bd\u0304+\u2032 (c) \u2264 CA1 = A2 .\nz\nThe significance of Lemma 6 is such that the function \u0233(t0 \u2212 s) has bounded lefthand derivative with respect to s for s \u2208 (0,t0 ]. The important consequence of this\nfact is the following\nRemark 5. The function \u03b3 s,m can be expressed as \u03b3 s,m (m, s) = I{s\u2264t0 } u(m, s)\u2212CI{s>t0 } ,\nwhere u(m, s) = \u011da (m) \u2212 ca (s) + \u011db (0) \u2212 cb (0) + \u0233b (t0 \u2212 s) is continuous, bounded,\nmeasurable with the bounded left-hand derivatives with respect to s.\nAt the end of this section, we determine the conditional value function of the second\noptimal stopping problem. According to (10), Theorem 2 and Remark 5 we have\ni\nh\n\u2217\n(28)\nJ(s) = E Z(s, \u03c4 b )|Fs = \u03b3 s,Ms (Ms , s) a.s.\n\n4 Construction of the optimal first stopping time\nIn this section, we formulate the solution of the double stopping problem. On the\nfirst epoch of the expedition the admissible strategies (stopping times) depend on\nthe formulation of the problem. For the optimization problem the most natural are\nthe stopping times from T (see the relevant problem considered in Szajowski [22]).\nHowever, when the bilateral problem is considered the natural class of admissible\nstrategies depends on who uses the strategy. It should be T {i} for the i-th player.\nHere the optimization problem with restriction to the strategies from the T {1} at the\nfirst epoch is investigated.\nLet us first notice that the function u(m, s) has a similar properties to the function\n\u0175b (m, s, m,t)\ne and the process J(s) has similar structure to the process Z(s,t). By\nthis observation one can follow the calculations of Section 3 to get J(s). Let us\ndefine again \u0393n,K = ess sup\u03c4 a \u2208Tn,K E [J(\u03c4 a )|Fn ] , n = K, . . . , 1, 0, which fulfills the\nfollowing representation\n\n\fAnglers' fishing problem\n\n19\n\nbn{1} , Tn{1} ) for n = K, . . . , 0, where the sequence of funcLemma 7. \u0393n,K = \u03b3K\u2212n (M\ntions \u03b3 j can be expressed as:\n\n\u03b30 (m, s) = I{s\u2264t0 } u(m, s) \u2212 CI{s>t0 } ,\n\u001a\n\u001b\n\u03b3 j (m, s) = I{s\u2264t0 } u(m, s) + yaj (m, s,t0 \u2212 s) \u2212 CI{s>t0 }\n\nand yaj (a, b, c) is given recursively as follows:\nya0 (a, b, c) = 0\nyaj (a, b, c) = max \u03c6yaa (a, b, c, r)\nj\u22121\n\n0\u2264r\u2264c\n\nwhere\n\n\u03c6\u03b4a (a, b, c, r) =\n\nZ r\n\nh\nn\ni\nF\u03041 (z) \u03b11 (z) \u2206 a (a) + E\u03b4 (a + x{1}, b + z, c \u2212 z)\n0\no\n\u2212 (\u0233b\u2032\u2212 (c \u2212 z) + ca\u2032 (b + z)) dz.\n\nLemma 7 corresponds to the combination of Lemma 4 and Remark 3 from Subsection 3.1. Let the operator \u03a6 a : B \u2192 B be defined by\n(\u03a6 a \u03b4 )(a, b, c) = max \u03c6\u03b4a (a, b, c, r).\n0\u2264r\u2264c\n\n(29)\n\n\u2217\nLemma 7 implies that there exists a function r1,\nj (a, b, c) such that\n\n\u001b\n\u001a\na\n\u2217\n\u03b3 j (m, s) = I{s\u2264t0 } u(m, s) + \u03c6ya (m, s,t0 \u2212 s, r1, j (m, s,t0 \u2212 s)) \u2212 CI{s>t0 } .\nj\u22121\n\nWe can now state the analogue of Theorem 1.\n\u2217\n\n\u2217\n\n{1}\n\n{1}\na\u2217\nSi+1 }, then \u03c4n,K\n\n\u2217\n{1}\n= T\u03b7n,K +Ra\u03b7n,K\n\n{1}\n\n) and \u03b7n,K = K \u2227 inf{i h\u2265 n : Rai \u2217 <i\na\u2217 )|F .\nis optimal in the class Tn,K and \u0393n,K = E J(\u03c4n,K\nn\n\na (M , T\nTheorem 3. Let Rai = rK\u2212i\ni i\n\n,t0 \u2212 Ti\n\nThe following results may be proved in much the same way as in Section 3.\n\nLemma 8. If F1 (t0 ) < 1 then the operator \u03a6 a : B \u2192 B defined by (29) is a contraction.\nRemark 6. There exists ya \u2208 B such that ya = \u03a6 a ya and limK\u2192\u221e kyaK \u2212 ya k = 0.\nThe above remark implies that \u03b3 = limK\u2192\u221e \u03b3K is given by\n\n\u03b3 (m, s) = I{s\u2264t0 } [u(m, s) + ya (m, s,t0 \u2212 s)] \u2212 CI{s>t0 } .\nWe can now formulate our main results.\nTheorem 4. If F1 (t0 ) < 1 and has the density function f1 , then\n\n(30)\n\n\f20\n\nA. Karpowicz, K. Szajowski\na\u2217\n\na\u2217\n\na\u2217\n\n(i) for n \u2208 N the limit \u03c4n = limK\u2192\u221e \u03c4n,K a.s. exists and \u03c4n \u2264 t0 is an optimal stop{1}\n\nping rule in the set T \u2229 {\u03c4 \u2265 Tn },\n\u0003\n\u0002\n\u2217\n{1}\n(ii)E J(\u03c4na )|Fn = \u03b3 (Mn , Tn ) a.s.\n\nP ROOF. The proof follows the same method as in Theorem 2. The difference lies\nin the form of the infinitesimal operator. Define the processes \u03be (s) = (s, Ms ,V (s))\n{1}\nwhere V (s) = s \u2212 TN (s) . Like before \u03be (s) is the Markov process with the state space\n1\n[0, \u221e) \u00d7 [0, \u221e) \u00d7 [0, \u221e). Notice that J(s) = p(\u03be (s)) and p(s, m, v) : [0,t0 ] \u00d7 [0, \u221e) \u00d7\n[0, \u221e) \u2192 R continuous, bounded, measurable with the bounded left-hand derivatives\nwith respect\nseen that Ap(s, m, v) = \u03b11 (v)[E\u011da (m + x{1}) \u2212\nh to s and v. It is easily\ni\n\u2032\n\n\u011da (m)] \u2212 \u0233b\u2212 (t0 \u2212 s) + ca\u2032 (s) for s \u2264 t0 . The rest of the proof remains the same as\nin the proof of Theorem 2.\n\u0003\nSummarizing, the solution of a double stopping problem is given by\n\u2217\n\n\u2217\n\n\u2217\n\n{1}\n\nEZ(\u03c4 a , \u03c4 b ) = EJ(\u03c4 a ) = \u03b3 (M0 , T0 ) = \u03b3 (0, 0),\n\u2217\n\n\u2217\n\nwhere \u03c4 a and \u03c4 b are defined according to Theorem 2 and Theorem 4 respectively.\n\n5 Examples\nThe form of the solution results in the fact that it is difficult to calculate the solution\nin an analytic way. In this section we will present examples of the conditions for\nwhich the solution can be calculated exactly.\nRemark 7. If the process \u03b62 (t) = Aps,m (\u03be s (t)) has hdecreasing\ni paths, then the second\n\u2217\n\n{3}\n\noptimal stopping time is given by \u03c4nb = inf{t \u2208 Tn ,t0 : Aps,m (\u03be s (t)) \u2264 0} on\n\nthe other side if \u03b62 (t) has non-decreasing paths, then the second optimal stopping\ntime is equal to t0 .\nSimilarly, if the process \u03b61 (s) = Ap(\u03be (s)) has\npaths, then the first optii\nh decreasing\n\u2217\n{1}\na\nmal stopping time is given by \u03c4n = inf{s \u2208 Tn ,t0 : Ap(\u03be (s)) \u2264 0} on the other\n\nside if \u03b61 (s) has non-decreasing paths, then the first optimal stopping time is equal\nto t0 .\n\u0015\n\u0014 \u2217\n\u0002\n\u0003\nR \u03c4nb\n\u2217\n{3}\ns,m )(\u03be s (z))dz\n(Ap\nP ROOF. From (25) we obtain E Z(s, \u03c4nb )|Fns = Z(s, Tn )+E\n{3}\nTn\n\na.s. and the application results of Jensen and Hsu [11] completes the proof.\n\n\u0003\nCorollary 2. If\nhas exponential distribution with constant hazard rate \u03b12 , the\n{3}\nb\nfunction \u011d is increasing and concave, the cost function cb is convex and t2,n = Tn ,\ns\ns\nmn = Mn then\nS{3}\n\n\fAnglers' fishing problem\n\n21\nb\u2032\n\nb\u2217\n\n\u03c4n = inf{t \u2208 [t2,n ,t0 ] : \u03b12 [E\u011db (msn + x{3} \u2212 m) \u2212 \u011db(msn \u2212 m)] \u2264 c (t \u2212 s)}, (31)\nwhere s is the moment of changing the place. Moreover, if S{1} has exponential\ndistribution with constant hazard rate \u03b11 , \u011da is increasing and concave, ca is convex\n{1}\nbn{1} then\nand t1,n = Tn , mn = M\nh\ni\n\u2217\n\u03c4na = inf{s \u2208 [t1,n ,t0 ] : \u03b11 E\u011da (mn + x{1}) \u2212 \u011da (mn ) \u2264 ca \u2032 (s)}\n\u2217\n\nP ROOF. The form of \u03c4 a \u2217n and \u03c4nb is a consequence of Remark 7. Let us observe\n\u2032\nthat by our assumptions \u03b62 (t) = \u03b12 \u2206 b (Mts \u2212 m) \u2212 cb (t \u2212 s) has decreasing paths for\n{3}\n{3}\n{3}\nt \u2208 [Tn , Tn+1 ). It suffices to prove that \u03b62 (Tn ) \u2212 \u03b62 (Tn2\u2212 ) = \u03b12 [\u2206 b (Mns \u2212 m) \u2212\ns\n\u2206 b (Mn\u22121\n\u2212 m)] < 0 for all n \u2208 N.\n\u2032\n\u2217\n\u2217\nIt remains to check that \u0233b\u2212 (t0 \u2212s) = 0. We can see that \u03c4 b = \u03c4 b (s) is deterministic,\nwhich is clear from (31). Let us notice that if s \u2264 t0 then\n(25), (26) and\ni\nhR combining\n\u2217\n\u0002\n\u0003\n\u2217\n\u03c4b\ns,m\ns,m\nb\n(28) gives \u03b3 (m, s) = E Z(s, \u03c4 )|Fs = Z(s, s) + E s (Ap )(\u03be s (z))dz|Fs .\nBy Remark 5 it follows that\n# Z b\u2217\n\"Z b \u2217\ni\n\u03c4 (s)\n\u03c4 (s) h\ns\nb\ns,m\n\u03b12 \u2206 b (0) \u2212 c\u20322(z \u2212 s) dz\n\u0233 (t0 \u2212 s) = E\n(Ap )(\u03be (z))dz =\ns\n\ns\n\nand this yields\n\u2032\n\nZ \u03c4 b \u2217 (s)\n\nh\ni\n\u2217\u2032\n\u2217\nc\u2032\u20322 (z \u2212 s)dz + \u03c4 b (s) \u03b12 \u2206 b (0) \u2212 c\u20322(\u03c4 b 2 (s) \u2212 s) (32)\ns\nh\ni\n\u2212 \u03b12 \u2206 b (0) \u2212 c\u20322 (0)\nh\ni\n\u2217\n= c\u20322 (\u03c4 b (s) \u2212 s) \u2212 c\u20322(0) \u2212 \u03b12 \u2206 b (0) \u2212 c\u20322(0) = 0.\n\n\u0233b\u2212 (t0 \u2212 s) =\n\nThe rest of proof runs as before.\n\n\u0003\nCorollary 3. If for i = 1 and i = 2 the functions gi are increasing and convex, ci\nare concave and S{i} have the exponential distribution with constant hazard rate \u03b1i\n\u2217\n\u2217\nthen \u03c4na = \u03c4nb = t0 for n \u2208 N.\nP ROOF. It is also the straightforward consequence of Remark 7. It suffices to check\n\u2217\n\u2032\nthat \u0233b\u2212 (t0 \u2212 s) is non-increasing with respect to s. First observe that \u03c4 b (s) = t0 .\n\u2032\nConsidering (32) it is obvious that \u0233b\u2212 (t0 \u2212 s) = \u03b12 \u2206 b (0) \u2212 c\u20322(t0 \u2212 s) and this completes the proof.\n\u0003\n\n\f22\n\nA. Karpowicz, K. Szajowski\n\n6 Conclusions\nThis article presents the solution of the double stopping problem in the \"fishing\nmodel\" for the finite horizon. The analytical properties of the reward function in\none stopping problem played the crucial rule in our considerations and allowed us\nto get the solution for the extended problem of a double stopping. Let us notice that\nby repeating considerations from Section 4 it is easy to generalize our model and\nthe solution to the multiple stopping problem but the notation can be inconvenient.\nThe construction of the equilibrium in the two person non-zero sum problem formulated in the section 2 can be reduced to the two double optimal stopping problems\nin the case when the payoff structure is given by (5), (6) and (11). The key assumptions were related to the properties of the distribution functions. Assuming general\ndistributions and the infinite horizon one can get the extensions of the above model.\n\nReferences\n1. Boshuizen, F., Gouweleeuw, J.: General optimal stopping theorems for semi-markov processes. Adv. in Appl. Probab. 4, 825\u2013846 (1993)\n2. Boshuizen, F.A.: A general framework for optimal stopping problems associated with multivariate point processes, and applications. Sequential Anal. 13(4), 351\u2013365 (1994)\n3. Br\u00e9maud, P.: Point Processes and Queues. Martingale Dynamics. Springer-Verlag, New York\n(1981)\n4. Davis, M.H.A.: Markov Models and Optimization. Chapman and Hall, New York (1993)\n5. Ferenstein, E., Pasternak-Winiarski, A.: Optimal stopping of a risk process with disruption and\ninterest rates. In: M. Br\u00e8ton, K. Szajowski (eds.) Advances in Dynamic Games: Differential\nand Stochastic games: theory, application and numerical methods, Annals of the International\nSociety of Dynamic Games, vol. 11, p. 18pages. Birkh\u00e4user, Boston (2010)\n6. Ferenstein, E., Sieroci\u0144ski, A.: Optimal stopping of a risk process. Applicationes Mathematicae 24(3), 335\u2013342 (1997)\n7. Ferguson, T.: A Poisson Fishing Model. In Festschrift for Lucien Le Cam: Research Papers in\nProbability and Statistics (D. Pollard, E. Torgersen and G. Yang, eds.). Springer, New York\n(1997)\n8. Haggstrom, G.: Optimal sequential procedures when more then one stop is required. Ann.\nMath. Statist. 38, 1618\u20131626 (1967)\n9. Jacobsen, M.: Point process theory and applications. Marked point and picewise deterministic\nprocesses., Probability and Its Applications, vol. 7. Birkh\u00e4user, Boston (2006)\n10. Jensen, U.: An optimal stopping problem in risk theory. Scand. Actuarial J. 2, 149\u2013159 (1997)\n11. Jensen, U., Hsu, G.: Optimal stopping by means of point process observations with applications in reliability. Mathematics of Operations Research 18(3), 645\u2013657 (1993)\n12. Karpowicz, A.: Double optimal stopping in the fishing problem. J. Appl. Probab. 46(2), 415\u2013\n428 (2009). DOI 10.1239/jap/1245676097\n13. Karpowicz, A., Szajowski, K.: Double optimal stopping of a risk process. GSSR Stochastics:\nAn International Journal of Probability and Stochastic Processes 79, 155\u2013167 (2007)\n14. Kramer, M., Starr, N.: Optimal stopping in a size dependent search. Sequential Anal. 9, 59\u201380\n(1990)\n15. Muciek, B.K., Szajowski, K.: Optimal stopping of a risk process when claims are covered\nimmediately. In: Mathematical Economics, RIMS K\u00f4ky\u00fbroku, vol. 1557, pp. 132\u2013139 (2007)\n16. Nikolaev, M.: Obobshchennye posledovatel\u2032 nye procedury.\nLitovski\u012d Matematicheski\u012d\nSbornik 19, 35\u201344 (1979)\n\n\fReferences\n\n23\n\n17. Rolski, T., Schmidli, H., Schimdt, V., Teugels, J.: Stochastic Processes for Insurance and Finance. John Wiley & Sons, Chichester (1998)\n18. Shiryaev, A.: Optimal Stopping Rules. Springer-Verlag, New York, Heidelberg, Berlin (1978)\n19. Starr, N.: Optimal and adaptive stopping based on capture times. J. Appl. Prob. 11, 294 \u2013 301\n(1974)\n20. Starr, N., Wardrop, R., Woodroofe, M.: Estimating a mean from delayed observations. Z. f \u00fcr\nWahr. 35, 103\u2013113 (1976)\n21. Starr, N., Woodroofe, M.: Gone fishin': Optimal stopping based on catch times. U. Mich.\nReport., Dept. of Statistics No. 33 (1974)\n22. Szajowski, K.: Optimal stopping of a 2-vector risk process. In: Stability in Probability, Banach\nCenter Publications, vol. 90, pp. 179\u2013191. PWN, Warszawa (2010)\n\n\f\fIndex\n\nfiltrations\n{i}\nFn \u2013the short denotation of FT {i} , 7\nn\n\nFt ,FtA \u2013the filtration generated by the\nA-marked renewal\u2013rewarded process to\nthe moment t, 6\nFt \u2013the filtration generated by the A-marked\nrenewal\u2013rewarded process to the\nmoment t, 6\npay-off functions\nCbj \u2013the bounds of the costs, 4\nZi ( j, s,t)\u2013the pay\u2013off process of the anglers,\nwhen the first stop has been forced by\ni-th one, 6\n\u2192\nw\u0303ai (\u2212\nm , j, s, k, m\ne,t)\u2013the pay-off of the angler\ni-th at moment t, when his change of\nfishing method to k \u2208 B has been forced\nby the angler j at s(\u2264 t) and the state of\n\u2212\nthe renewal-reward process \u2192\nm ,6\ncbj (t)\u2013the cumulative costs of fishing after\nthe change of fishing method using\nmethod j, 4\nci , cai , ca \u2013the cumulative cost of usage the\ni-th rod at the period a, 4\n\u2192\n\u2212\nga (\u2212\nm , j,t), (gai (\u2192\nm , j,t))\u2013the utility of fishes\ngotten to the moment t (at the i-th rod)\nwhen the last catch was at the j-th rod\nand the state of the renewal-reward\n\u2192\nprocess is \u2212\nm, 5\n\u2192\ngbj (\u2212\nm , i, s, m,t)\u2013the\ne\nreward function after\nthe change of the fishing methods when\nthe state of the renewal-reward processes\n\u2212\nat s has been \u2192\nm and the final state of\nthe renewal-reward process at t(\u2265 s) has\nbeen m,\ne 4\n\u2192\nwai (\u2212\nm , j,t)\u2013the i-th player's pay-off at\nmoment t when the stop has been\n\nmade by the j-th and the state of the\n\u2212\nrenewal-reward process \u2192\nm ,5\nrenewal\u2013reward processes\n{i}\n{i}\n(Tn , Xn )\u2013the renewal\u2013rewarded\nprocesses, 6\nFi (t)\u2013the distribution function of the holding\ntimes of the i-th type, 4\n{i}\nMt \u2013the renewal-reward process at moment\nt related to the rod i-th, 4\nMt (Mts )\u2013the renewal-reward process at\nmoment t (with change of a structure at\nmoment s), 4\nNi (t)\u2013the number of fishes caught on the rod\ni to the moment t, 3\n{i}\nSn \u2013n-th holding time of the i-th type, 4\n{i}\nTk \u2013k-th jump time of the i-th type, 4\nTn \u2013n-th jump moment, 3\n{i}\nXk \u2013the value of the k-th fish cached on the\ni-th rod, 3\nF(t), f(t)\u2013the distribution and density\nfunctions of the holding times after the\nchange of fishing method, 9\nH(t)\u2013the distribution function of the rewards\nafter the change of fishing method, 9\nzn \u2013the index of n-th jump, 3\n\u2192\n\u2212\nN (t)\u2013the 2-dimensional renewal process, 3\n{i}\nnk \u2013the index of k-th jump of i-th type, 4\nstopping times\nT , Tn,K \u2013sets of stopping times with respect\nto \u03c3 -fields {Ft }, 7\n{i}\n{i}\nTn,K \u2013the stopping times bounded by Tn\nand TK , 7\n{i}\n{i}\nTn \u2013the stopping times bounded by Tn , 7\n\n25\n\n\f26\n\nIndex\nTn,K \u2013the subset of stopping times \u03c4 \u2208 T\nwith respect to the filtration {Ft } such\nthat Tn \u2264 \u03c4 \u2264 TK , 7\n\u2217\n\u03c4 a \u2013the optimal moment of the first\ndecision, 8\n\n\u2217\n\n\u03c4 b \u2013the optimal moment of the second\ndecision, 8\n\u03c4n,K \u2013the element of the set Tn,K , 7\nb \u2217 , \u03c4 b \u2217 \u2013the second optimal stopping time\n\u03c40,K\nK\nin a restricted problem, 9\n\n\f"}