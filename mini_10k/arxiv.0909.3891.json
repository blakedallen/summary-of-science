{"id": "http://arxiv.org/abs/0909.3891v1", "guidislink": true, "updated": "2009-09-22T02:11:24Z", "updated_parsed": [2009, 9, 22, 2, 11, 24, 1, 265, 0], "published": "2009-09-22T02:11:24Z", "published_parsed": [2009, 9, 22, 2, 11, 24, 1, 265, 0], "title": "Stock Market Trading Via Stochastic Network Optimization", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0909.5076%2C0909.3246%2C0909.3609%2C0909.2694%2C0909.1382%2C0909.0098%2C0909.3263%2C0909.2588%2C0909.5609%2C0909.5036%2C0909.4395%2C0909.1193%2C0909.1129%2C0909.0849%2C0909.4856%2C0909.4711%2C0909.4781%2C0909.0937%2C0909.5481%2C0909.2564%2C0909.4486%2C0909.3427%2C0909.3799%2C0909.2264%2C0909.5548%2C0909.4043%2C0909.4724%2C0909.2233%2C0909.1671%2C0909.5169%2C0909.0936%2C0909.5409%2C0909.2463%2C0909.1225%2C0909.1925%2C0909.2524%2C0909.1180%2C0909.3016%2C0909.4111%2C0909.5628%2C0909.1076%2C0909.4414%2C0909.2165%2C0909.5056%2C0909.5259%2C0909.3376%2C0909.0214%2C0909.1875%2C0909.0445%2C0909.3655%2C0909.3786%2C0909.4864%2C0909.3891%2C0909.1650%2C0909.5332%2C0909.4917%2C0909.5378%2C0909.5577%2C0909.4186%2C0909.4068%2C0909.3036%2C0909.3429%2C0909.1130%2C0909.0624%2C0909.5215%2C0909.0014%2C0909.5002%2C0909.2408%2C0909.4365%2C0909.4601%2C0909.1514%2C0909.1663%2C0909.0346%2C0909.3894%2C0909.1060%2C0909.3895%2C0909.2193%2C0909.4948%2C0909.2108%2C0909.4241%2C0909.4433%2C0909.4386%2C0909.1933%2C0909.0122%2C0909.1802%2C0909.2324%2C0909.2737%2C0909.4820%2C0909.1910%2C0909.2902%2C0909.0954%2C0909.0765%2C0909.3954%2C0909.0138%2C0909.4901%2C0909.5328%2C0909.4029%2C0909.5693%2C0909.4124%2C0909.2157%2C0909.4791&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Stock Market Trading Via Stochastic Network Optimization"}, "summary": "We consider the problem of dynamic buying and selling of shares from a\ncollection of $N$ stocks with random price fluctuations. To limit investment\nrisk, we place an upper bound on the total number of shares kept at any time.\nAssuming that prices evolve according to an ergodic process with a mild\ndecaying memory property, and assuming constraints on the total number of\nshares that can be bought and sold at any time, we develop a trading policy\nthat comes arbitrarily close to achieving the profit of an ideal policy that\nhas perfect knowledge of future events. Proximity to the optimal profit comes\nwith a corresponding tradeoff in the maximum required stock level and in the\ntimescales associated with convergence. We then consider arbitrary (possibly\nnon-ergodic) price processes, and show that the same algorithm comes close to\nthe profit of a frame based policy that can look a fixed number of slots into\nthe future. Our analysis uses techniques of Lyapunov Optimization that we\noriginally developed for stochastic network optimization problems.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0909.5076%2C0909.3246%2C0909.3609%2C0909.2694%2C0909.1382%2C0909.0098%2C0909.3263%2C0909.2588%2C0909.5609%2C0909.5036%2C0909.4395%2C0909.1193%2C0909.1129%2C0909.0849%2C0909.4856%2C0909.4711%2C0909.4781%2C0909.0937%2C0909.5481%2C0909.2564%2C0909.4486%2C0909.3427%2C0909.3799%2C0909.2264%2C0909.5548%2C0909.4043%2C0909.4724%2C0909.2233%2C0909.1671%2C0909.5169%2C0909.0936%2C0909.5409%2C0909.2463%2C0909.1225%2C0909.1925%2C0909.2524%2C0909.1180%2C0909.3016%2C0909.4111%2C0909.5628%2C0909.1076%2C0909.4414%2C0909.2165%2C0909.5056%2C0909.5259%2C0909.3376%2C0909.0214%2C0909.1875%2C0909.0445%2C0909.3655%2C0909.3786%2C0909.4864%2C0909.3891%2C0909.1650%2C0909.5332%2C0909.4917%2C0909.5378%2C0909.5577%2C0909.4186%2C0909.4068%2C0909.3036%2C0909.3429%2C0909.1130%2C0909.0624%2C0909.5215%2C0909.0014%2C0909.5002%2C0909.2408%2C0909.4365%2C0909.4601%2C0909.1514%2C0909.1663%2C0909.0346%2C0909.3894%2C0909.1060%2C0909.3895%2C0909.2193%2C0909.4948%2C0909.2108%2C0909.4241%2C0909.4433%2C0909.4386%2C0909.1933%2C0909.0122%2C0909.1802%2C0909.2324%2C0909.2737%2C0909.4820%2C0909.1910%2C0909.2902%2C0909.0954%2C0909.0765%2C0909.3954%2C0909.0138%2C0909.4901%2C0909.5328%2C0909.4029%2C0909.5693%2C0909.4124%2C0909.2157%2C0909.4791&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We consider the problem of dynamic buying and selling of shares from a\ncollection of $N$ stocks with random price fluctuations. To limit investment\nrisk, we place an upper bound on the total number of shares kept at any time.\nAssuming that prices evolve according to an ergodic process with a mild\ndecaying memory property, and assuming constraints on the total number of\nshares that can be bought and sold at any time, we develop a trading policy\nthat comes arbitrarily close to achieving the profit of an ideal policy that\nhas perfect knowledge of future events. Proximity to the optimal profit comes\nwith a corresponding tradeoff in the maximum required stock level and in the\ntimescales associated with convergence. We then consider arbitrary (possibly\nnon-ergodic) price processes, and show that the same algorithm comes close to\nthe profit of a frame based policy that can look a fixed number of slots into\nthe future. Our analysis uses techniques of Lyapunov Optimization that we\noriginally developed for stochastic network optimization problems."}, "authors": ["Michael J. Neely"], "author_detail": {"name": "Michael J. Neely"}, "author": "Michael J. Neely", "arxiv_comment": "14 pages", "links": [{"href": "http://arxiv.org/abs/0909.3891v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0909.3891v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "q-fin.PM", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "q-fin.PM", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "q-fin.CP", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0909.3891v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0909.3891v1", "journal_reference": null, "doi": null, "fulltext": "1\n\nStock Market Trading via Stochastic Network\nOptimization\n\narXiv:0909.3891v1 [q-fin.PM] 22 Sep 2009\n\nMichael J. Neely\nUniversity of Southern California\nhttp://www-rcf.usc.edu/\u223cmjneely\n\nAbstract- We consider the problem of dynamic buying and\nselling of shares from a collection of N stocks with random\nprice fluctuations. To limit investment risk, we place an upper\nbound on the total number of shares kept at any time. Assuming\nthat prices evolve according to an ergodic process with a mild\ndecaying memory property, and assuming constraints on the total\nnumber of shares that can be bought and sold at any time,\nwe develop a trading policy that comes arbitrarily close to\nachieving the profit of an ideal policy that has perfect knowledge\nof future events. Proximity to the optimal profit comes with a\ncorresponding tradeoff in the maximum required stock level\nand in the timescales associated with convergence. We then\nconsider arbitrary (possibly non-ergodic) price processes, and\nshow that the same algorithm comes close to the profit of a\nframe based policy that can look a fixed number of slots into the\nfuture. Our analysis uses techniques of Lyapunov Optimization\nthat we originally developed for stochastic network optimization\nproblems.\nIndex Terms- Queueing analysis, stochastic control, universal\nalgorithms\n\nI. I NTRODUCTION\nThis paper considers the problem of stock trading in an\neconomic market with N stocks. We treat the problem in\ndiscrete time with normalized time slots t \u2208 {0, 1, 2, . . .},\nwhere buying and selling transactions are conducted on each\nslot. Let Q(t) = (Q1 (t), . . . , QN (t)) be a vector of the current\nnumber of shares owned of each stock, called the stock queue.\nThat is, for each n \u2208 {1, . . . , N }, the value of Qn (t) is an\ninteger that represents the number of shares of stock n. Stock\nprices are given by a vector p(t) = (p1 (t), . . . , pN (t)) and\nare assumed to evolve randomly, with mild assumptions to be\nmade precise in later sections. Each buy and sell transaction\nincurs trading costs. Stocks can be sold and purchased on every\nslot. Let \u03c6(t) represent the net profit on slot t (after transaction\ncosts are paid). The goal is to design a trading policy that\nmaximizes the long term time average of \u03c6(t).\nFor this system model, we enforce the additional constraint\nthat at most \u03bcmax\nshares of each stock n can be bought and\nn\nsold on a given slot. This ensures that our trading decisions\nonly gradually change the portfolio allocation. While this\n\u03bcmax\nconstraint can significantly limit the ability to take\nn\nadvantage of desirable prices, and hence limits the maximum\npossible long term profit, we show that it can also reduce\ninvestment risk. Specifically, subject to the \u03bcmax\nconstraint,\nn\nThis material is supported in part by one or more of the following: the\nDARPA IT-MANET program grant W911NF-07-0028, the NSF Career grant\nCCF-0747525.\n\nwe develop an algorithm that achieves a time average profit\nthat is arbitrarily close to optimal, with a tradeoff in the\nmaximum number of shares Qmax\nrequired for stock n. The\nn\nQmax\nvalues can be chosen as desired to limit the losses\nn\nfrom a potential collapse of one or more of the stocks. It\nalso impacts the timescales over which profit is accumulated,\nwhere smaller Qmax\nlevels lead to faster convergence times.\nn\nIt is important to note that long term wealth typically\ngrows exponentially when the Qmax\nand \u03bcmax\nconstraints are\nn\nn\nremoved. In contrast, it can be shown that these Qmax\nand\nn\nconstraints restrict wealth to at most a linear growth.\n\u03bcmax\nn\nTherefore, using Qmax\nand \u03bcmax\nto limit investment risk\nn\nn\nunfortunately has a dramatic impact on the long term growth\ncurve. However, our ability to bound the timescales over which\nwealth is earned suggests that our strategy may be useful\nin cases when, in addition to a good long-term return, we\nalso desire noticeable and consistent short-term gains. At the\nend of this paper, we briefly describe a modified strategy\nas wealth progresses, with the\nand \u03bcmax\nthat increases Qmax\nn\nn\ngoal of achieving noticeable short-term gains while enabling\nexponential wealth increase.\nOur approach uses the Lyapunov optimization theory developed for stochastic queueing networks in our previous work\n[1][2][3]. Specifically, the work [1][2][3] develops resource\nallocation and scheduling policies for communication and\nqueueing networks with random traffic and channels. The\npolicies can maximize time average throughput-utility and\nminimize time average power expenditure, as well as optimize\nmore general time average attributes, without a-priori knowledge of the traffic and channel probabilities. The algorithms\ncontinuously adapt to emerging conditions, and are robust\nto non-ergodic changes in the probability distributions [4].\nThis suggests that similar control techniques can be used\nsuccessfully for stock trading problems. The difference is that\nthe queues associated with stock shares are controlled to have\npositive drift (pushing them towards the maximum queue size),\nrather than negative drift (which would push them in the\ndirection of the empty state).\nThe Dynamic Trading Algorithm that we develop from these\ntechniques can be intuitively viewed as a variation on a theme\nof dollar cost averaging, where price downturns are exploited\nby purchasing more stock. However, the actual amount of\nstock that we buy and sell on each slot is determined by\na constrained optimization of a max-weight functional that\nincorporates transaction costs, current prices, and current stock\nqueue levels.\n\n\f2\n\nMuch prior work on financial analysis and portfolio optimization assumes a known probability model for stock prices.\nClassical portfolio optimization techniques by Markowitz [5]\nand Sharpe [6] construct portfolio allocations over N stocks to\nmaximize profit subject to variance constraints (which model\nrisk) over one investment period (see also [7] and references\ntherein). Solutions to this problem can be calculated if the\nmean and covariance of stock returns are known. Samuelson considers multi-period problems in [8] using dynamic\nprogramming, assuming a known product form distribution\nfor investment returns. Cover in [9] develops an iterative\nprocedure that converges to the constant portfolio allocation\nthat maximizes the expected log investment return, assuming a\nknown probability distribution that is the same on each period.\nRecent work by Rudoy and Rohrs in [10] [11] considers riskaware optimization with a more complex cointegrated vector\nautorgressive assumption on stock processes, and uses Monte\nCarlo simulations over historical stock trajectories to inform\nstochastic decisions. Stochastic models of stock prices using\nL\u00e9vy processes and multi-fractal processes are considered in\n[7] [12] [13] and references therein.\nA significant departure from this work is the universal stock\ntrading paradigm, as exemplified in prior works of Cover and\nGluss [14], Larson [15], Cover [16], Merhav and Feder [17],\nand Cover and Ordentlich [18] [19], where trading algorithms\nare developed and shown to provide analytical guarantees for\nany sample path of stock prices. Specifically, the work in\n[14]-[19] seeks to find a non-anticipating trading algorithm\nthat yields the same growth exponent as the best constant\nportfolio allocation, where the constant can be optimized with\nfull knowledge of the future. The works in [14][15] develop\nalgorithms that come close to the optimal exponent, and the\nwork in [16] achieves the optimal exponent under a mild active\nstock assumption on the price sample paths. Similar results\nare derived in [17] using a general framework of sequential\ndecision theory. Related results are derived in [18] [19] without\nthe active stock assumption, where [19] also treats max-min\nperformance when stock prices are chosen by an adversary.\nOur work is similar in spirit to this universal trading\nparadigm, in that we do not base decisions on a known (or\nestimated) probability distribution. However, our context and\nsolution methodology is very different. Indeed, the works in\n[14]-[19] assume that the entire stock portfolio can be sold and\nreallocated on every time period, and allow stock holdings to\ngrow arbitrarily large. This means that the accumulated profit\nis always at risk of one or more stock failures. In our work, we\ntake a more conservative approach that restricts reallocation\nto gradual changes, and that pockets profits while holding no\nmore than Qmax\nshares of each stock n. We also explicitly\nn\naccount for trading costs and integer constraints on stock\nshares, which is not considered in the works [14]-[19]. In this\ncontext, we first design an algorithm under the assumption that\nprices are ergodic with an unknown distribution. In this case,\nwe develop a simple non-anticipating algorithm that comes\narbitrarily close to the optimal time average profit that could\nbe earned by an ideal policy with complete knowledge of\nthe future. The ideal policy used for comparison can make\ndifferent allocations at different times, and is not restricted to\n\nconstant allocations as considered in [14]-[19]. We then show\nthat the same algorithm can be used for general price sample\npaths, even non-ergodic sample paths without well defined\ntime averages. A more conservative guarantee is shown in this\ncase: The algorithm yields profit that is arbitrarily close to\nthat of a frame based policy with \"T -slot lookahead,\" where\nthe future is known up to T slots. Our approach is inspired\nby Lyapunov optimization and decision theory for stochastic\nqueueing networks [1]. However, the Lyapunov theory we use\nhere involves sample path techniques that are different from\nthose in [1]. These techniques might have broader impacts on\nqueueing problems in other areas.\nIn the next section we present the system model. In Section\nIII we develop the Dynamic Trading Algorithm and analyze\nperformance for the simple (and possibly unrealistic) case\nwhen price vectors p(t) are ergodic and i.i.d. over slots. While\nthis i.i.d. case does not accurately model actual stock prices,\nits analysis provides valuable insight. Section IV expands the\nanalysis to show the same algorithm can handle more general\nergodic processes with a mild decaying memory property.\nSection V shows the algorithm also provides performance\nguarantees for completely arbitrary price processes (possibly\nnon-ergodic). A simple enhancement that reduces startup cost\nis treated in Section VI, and Section VII briefly considers\nan extension that allows for exponential wealth increase by\ngradually scaling the \u03bcmax\nand Qmax\nparameters.\nn\nn\nII. S YSTEM M ODEL\nLet A(t) = (A1 (t), . . . , AN (t)) be a vector of decision\nvariables representing the number of new shares purchased\nfor each stock on slot t, and let \u03bc(t) = (\u03bc1 (t), . . . , \u03bcN (t))\nbe a vector representing the number of shares sold on slot\nt. The values An (t) and \u03bcn (t) are non-negative integers for\neach n \u2208 {1, . . . , N }. Each purchase of A new shares of\nstock n incurs a transaction cost bn (A) (called the buying cost\nfunction). Likewise, each sale of \u03bc shares of stock n incurs a\ntransaction cost sn (\u03bc) (called the selling cost function). The\nfunctions bn (A) and sn (\u03bc) are arbitrary, and are assumed only\nto satisfy bn (0) = sn (0) = 0, and to be non-negative, nondecreasing, and bounded by finite constants bmax\nand smax\n,\nn\nn\nso that:\n0 \u2264 bn (A) \u2264 bmax\nn\n\nfor 0 \u2264 A \u2264 \u03bcmax\nn\n\nsmax\nn\n\nfor 0 \u2264 \u03bc \u2264 \u03bcmax\nn\n\n0 \u2264 sn (\u03bc) \u2264\n\nwhere for each n \u2208 {1, . . . , N }, \u03bcmax\nis a positive integer\nn\nthat limits the amount of shares of stock n that can be bought\nand sold on slot t.\nA. Example Transaction Cost Functions\nThe functions bn (A) might be linear, representing a transaction fee that charges per share purchased. Another example\nis a fixed cost model with some fixed positive fee bn , so that:\n\u001a\nbn if A > 0\nbn (A) =\n0\nif A = 0\nSimilar models can be used for the sn (\u03bc) function. The\nsimplest model of all is the zero transaction cost model where\nthe functions bn (A) and sn (\u03bc) are identically zero.\n\n\f3\n\nB. System Dynamics\n\nC. The Maximum Profit Objective\n\nThe stock price vector p(t) is assumed to be a random\nvector process that takes values in some finite set P \u2282 RN ,\nwhere P can have an arbitrarily large number of elements.1\nFor each n, let pmax\nrepresent a bound on pn (t), so that:\nn\n0 \u2264 pn (t) \u2264 pmax\nn\n\nDefine \u03c6(t) as the net profit on slot t:\n\u03c6(t)\n\n\u25b3\n\n=\n\nN\nX\n\n[\u03bcn (t)pn (t)\nn=1\nN\nX\n\n\u2212\n\nfor all t and all n \u2208 {1, . . . , N } (1)\n\n\u2212 sn (\u03bcn (t))]\n\n[An (t)pn (t) + bn (An (t))]\n\n(8)\n\nn=1\n\nWe assume that buying and selling decisions can be made on\neach slot t based on knowledge of p(t). The selling decision\nvariables \u03bc(t) are made every slot t subject to the following\nconstraints:\n\nt\u22121\n\n1X\nE {\u03c6(\u03c4 )}\nt\u2192\u221e t\n\u03c4 =0\n\n\u25b3\n\u03c6=\nlim\n\n\u03bcn (t) \u2208 {0, 1, . . . , \u03bcmax\n}\nn\n\nfor all n \u2208 {1, . . . , N }\n\n(2)\n\n\u03bcn (t)pn (t) \u2265 sn (\u03bcn (t))\n\u03bcn (t) \u2264 Qn (t)\n\nfor all n \u2208 {1, . . . , N }\nfor all n \u2208 {1, . . . , N }\n\n(3)\n(4)\n\nConstraint (2) ensures that no more than \u03bcmax\nshares can\nn\nbe sold of any stock on a single slot. Constraint (3) restricts\nto the reasonable case when the money earned from the sale\nof a stock must be larger than the transaction fee associated\nwith the sale (violating this constraint would clearly be suboptimal).2 Constraint (4) requires the number of shares sold\nto be less than or equal to the current number owned.\nThe buying decision variables A(t) are constrained as\nfollows:\nAn (t) \u2208 {0, 1, 2, . . . , \u03bcmax\n} for all n \u2208 {1, . . . , N }\nn\nPN\nn=1 An (t)pn (t) \u2264 x\n\nDefine \u03c6 as the time average expected value of \u03c6(t) under a\ngiven trading algorithm (temporarily assumed to have a well\ndefined limit):\n\n(5)\n(6)\n\nwhere x is a positive value that bounds the total amount\nof money used for purchases on slot t. For simplicity,\nwe assume there is always at least a minimum of x and\nP\nN\nmax max\npn + bn (\u03bcmax\n)] dollars available for making\nn\nn=1 [\u03bcn\npurchasing decisions. This model can be augmented by adding\na checking account queue Q0 (t) from which we must draw\nmoney to make purchases, although we omit this aspect for\nbrevity.\nThe resulting queueing dynamics for the stock queues Qn (t)\nfor n \u2208 {1, . . . , N } are thus:\n\nThe goal is to design a trading policy that maximizes \u03c6. It is\nclear that the trivial strategy that chooses \u03bc(t) = A(t) = 0 for\nall t yields \u03c6(t) = 0 for all t, and results in \u03c6 = 0. Therefore,\nwe desire our algorithm to produce a long term profit that\nsatisfies \u03c6 > 0.\nD. Discussion of Constraints\n\u25b3 PN\nmax max\npn +bn (\u03bcmax\n)], then constraint\nIf we set x=\nn\nn=1 [\u03bcn\n(6) is redundant and can be removed. In this case, the multistock problem completely decouples into separate problems\nof optimally trading on each of the individual stocks. Trading\non just a single stock is itself an important problem that can\nbe viewed as a special case of our system model. We add the\nconstraint (6) for multi-stock problems as it can be used to\nlimit the total amount spent on new purchases on a single slot.\nThe constraint (6) can lead to a complex decision on each slot\nthat is related to the bounded knapsack problem, as discussed\nin Section III-A after the description of the Dynamic Trading\nAlgorithm. The formulation can be modified by replacing the\nconstraint (6) with the following constraint that often yields a\nsimpler implementation:\nPN\n(9)\nn=1 An (t) \u2264 Atot\nwhere Atot is an integer that bounds the total number of stocks\nthat can be bought on a single slot.\nE. The Stochastic Price Vector and p-only Policies\n\nQn (t + 1) = max[Qn (t) \u2212 \u03bcn (t) + An (t), 0]\n\n(7)\n\nStrictly speaking, the max[*, 0] operator in the above dynamic\nequation is redundant, because the constraint (4) ensures that\nthe argument inside the max[*, 0] operator is non-negative.\nHowever, the max[*, 0] shall be useful for mathematical analysis when we compare our strategy to that of a queueindependent strategy that neglects constraint (4).\n1 The\n\ncardinality of the set P does not enter into our analysis. We assume it\nis finite only for the convenience of claiming that the supremum time average\nprofit \u03c6opt is achievable by a single \"p-only\" policy, as described in Section\nII-E. Theorems 1, 2, 3 are unchanged if the set P is infinite, although the\nproofs of Theorems 1 and 2 would require an additional limiting argument\nover p-only policies that approach \u03c6opt .\n2 Constraint (3) can be augmented by allowing equality only if \u03bc (t) = 0.\nn\n\nWe first assume the stochastic process p(t) has well defined\ntime averages (this is generalized to non-ergodic models in\nSection V). Specifically, for each price vector p in the finite\nset P, we define \u03c0(p) as the time average fraction of time that\np(t) = p, so that:\nt\u22121\n\n1X\n1{p(\u03c4 ) = p} = \u03c0(p) with probability 1\nlim\nt\u2192\u221e t\n\u03c4 =0\n\n(10)\n\nwhere 1{p(\u03c4 ) = p} is an indicator function that is 1 if p(\u03c4 ) =\np, and zero otherwise.\nDefine a p-only policy as a buying and selling strategy\nthat chooses virtual decision vectors A\u2217 (t) and \u03bc\u2217 (t) as a\nstationary and possibly randomized function of p(t), constrained only by (2)-(3) and (5)-(6). That is, the virtual decision\n\n\f4\n\nvectors A\u2217 (t) and \u03bc\u2217 (t) associated with a p-only policy do\nnot necessarily satisfy the constraint (4) that is required of\nthe actual decision vectors, and hence these decisions can be\nmade independently of the current stock queue levels.\nUnder a given p-only policy, define the following time\naverage expectations d\u2217n and \u03c6\u2217 :\n\u25b3\nd\u2217n =\nlim\n\nt\u2192\u221e\n\nt\u22121\n\nt\u22121\n1X\n\nt\n\n1X\nE\n\u03c6 = lim\nt\u2192\u221e t\n\u03c4 =0\n\u2217\u25b3\n\n\u2212\n\nN\nX\n\nE {A\u2217n (\u03c4 ) \u2212 \u03bc\u2217n (\u03c4 )}\n\n(11)\n\n\u03c4 =0\n\n(\n\nN\nX\n\n[\u03bc\u2217n (\u03c4 )pn (\u03c4 ) \u2212 sn (\u03bc\u2217n (\u03c4 ))]\n\nn=1\n\n[A\u2217n (\u03c4 )pn (\u03c4 )\nn=1\n\n+\n\n)\n\nbn (A\u2217n (\u03c4 ))]\n\nthat have a mild decaying memory property (a property held\nby all processes that are modulated by finite state Markov\nchains). Section V shows the algorithm can also treat arbitrary\n(possibly non-ergodic) price models.\nF. The i.i.d. Model\nSuppose p(t) is i.i.d. over slots with P r[p(t) = p] = \u03c0(p)\nfor all p \u2208 P. Because the value \u03c6opt is achievable by a\nsingle p-only policy, and because the expected values of any\np-only policy are the same every slot under the i.i.d. model,\nwe have the following: There is a p-only policy A\u2217 (t), \u03bc\u2217 (t)\nthat yields for all t and all Q(t):\nE {A\u2217n (t) \u2212 \u03bc\u2217n (t) | Q(t)} = 0\n\n(12)\n\nIt is easy to see by (10) that these time averages are well\ndefined for any p-only policy. For each n, the value d\u2217n\nrepresents the virtual drift of stock queue Qn (t) associated\nwith the virtual decisions A\u2217 (t) and \u03bc\u2217 (t). The value \u03c6\u2217\nrepresents the virtual profit under virtual decisions A\u2217 (t) and\n\u03bc\u2217 (t). Note that the trivial p-only policy A\u2217 (t) = \u03bc\u2217 (t) = 0\nyields d\u2217n = 0 for all n, and \u03c6\u2217 = 0. Thus, we can define\n\u03c6opt as the supremum value of \u03c6\u2217 over all p-only policies\nthat yield d\u2217n \u2265 0 for all n, and we note that \u03c6opt \u2265 0. Using\nan argument similar to that given in [2], it can be shown that:\n1) \u03c6opt is achievable by a single p-only policy that satisfies\nd\u2217n = 0 for all n \u2208 {1, . . . , N }.\n2) \u03c6opt is greater than or equal to the supremum of the\nlim sup time average expectation of \u03c6(t) that can be\nachieved over the class of all actual policies that satisfy\nthe constraints (2)-(6), including ideal policies that use\nperfect information about the future. Thus, no policy can\ndo better than \u03c6opt .\nThat \u03c6opt is achievable by a single p-only policy (rather\nthan by a limit of an infinite sequence of policies) can be\nshown using the assumption that the set P of all price vectors\nis finite. That \u03c6opt bounds the time average profit of all\npolicies, including those that have perfect knowledge of the\nfuture, can be intuitively understood by noting that the optimal\nprofit is determined only by the time averages \u03c0(p). These\ntime averages are the same (with probability 1) regardless\nof whether or not we know the future. The detailed proofs\nof these results are similar to those in [2] and are provided\nin Appendix C. In the next section we develop a Dynamic\nTrading Algorithm that satisfies the constraints (2)-(6) and that\ndoes not know the future or the distribution \u03c0(p), yet yields\ntime average profit that is arbitrarily close to \u03c6opt .\nTo develop our Dynamic Trading Algorithm, we first focus\non the simple case when the vector p(t) is independent and\nidentically distributed (i.i.d.) over slots, with a general probability distribution \u03c0(p). This is an overly simplified model\nand does not reflect actual stock time series data. Indeed,\na more accurate model would be to assume the differences\nin the logarithm of prices are i.i.d. (see [7] and references\ntherein). However, we show in Section IV that the same\nalgorithm developed for the simplified i.i.d. case can also be\nused for a general class of ergodic but non-i.i.d. processes\n\n(13)\n\nand\nnP\nN\n\u2217\n\u2217\nE\nn=1 [\u03bcn (t)pn (t) \u2212 sn (\u03bcn (t))]\no\nPN\n\u2212 n=1 [A\u2217n (t)pn (t) + bn (A\u2217n (t))] | Q(t) = \u03c6opt\nIII. C ONSTRUCTING\n\nA\n\n(14)\n\nDYNAMIC T RADING A LGORITHM\n\nThe goal is to ensure that all stock queues Qn (t) are\nmaintained at reasonably high levels so that there are typically\nenough shares available to sell if an opportune price should\narise. To this end, define \u03b81 , . . . , \u03b8n as positive real numbers\nthat represent target queue sizes for the stock queues (soon to\nbe related to the maximum queue size). The particular values\n\u03b81 , . . . , \u03b8n shall be chosen later. As a scalar measure of the\ndistance each queue is away from its target value, we define\nthe following Lyapunov function L(Q(t)):\n\u25b3\nL(Q(t))=\n\nN\n1X\n(Qn (t) \u2212 \u03b8n )2\n2 n=1\n\n(15)\n\nSuppose that Q(t) evolves according to some probability law,\nand define \u2206(Q(t)) as the one-slot conditional Lyapunov\ndrift:3\n\u25b3\n\u2206(Q(t))=\nE {L(Q(t + 1)) \u2212 L(Q(t)) | Q(t)}\n\n(16)\n\nAs in the stochastic network optimization problems of\n[1][2][3], our approach is to take control actions on each slot t\nto minimize a bound on the \"drift-minus-reward\" expression:\n\u2206(Q(t)) \u2212 V E {\u03c6(t) | Q(t)}\nwhere V is a positive parameter to be chosen as desired to\naffect the proximity to the optimal time average profit \u03c6opt .\nTo this end, we first compute a bound on the Lyapunov drift.\nLemma 1: (Lyapunov drift bound) For all t and all possible\nvalues of Q(t), we have:\n\u2206(Q(t))\n\n\u2264\n\nB\u2212\n\nN\nX\n\n(Qn (t) \u2212 \u03b8n )E {\u03bcn (t) \u2212 An (t) | Q(t)}\n\nn=1\n3 Strictly speaking, proper notation is \u2206(Q(t), t), as the drift may arise\nfrom a non-stationary algorithm. However, we use the simpler notation\n\u2206(Q(t)) as a formal representation of the right hand side of (16).\n\n\f5\n\nLemma 2: For a given Q(t) on slot t, the above dynamic\ntrading algorithm satisfies:\n\nwhere B is a finite constant that satisfies:\nB\u2265\n\nN\n1X \b\nE (\u03bcn (t) \u2212 An (t))2 | Q(t)\n2 n=1\n\n(17)\nB \u2212 V \u03c6(t) \u2212\n\nSuch a finite constant B exists because of the boundedness\nassumptions on buy and sell variables \u03bcn (t) and An (t). In\nparticular, we have:\nN\n1 X max 2\n(\u03bc\n)\n(18)\n2 n=1 n\nProof: See Appendix A.\nUsing Lemma 1 with the definition of \u03c6(t) in (8), a bound\non the drift-minus-reward expression is given as follows:\n\nB\u2264\n\n\u2206(Q(t)) \u2212 V E {\u03c6(t) | Q(t)} \u2264 B\nPN\n\u2212 n=1 (Qn (t) \u2212 \u03b8n )E {\u03bcn (t) \u2212 An (t) | Q(t)}\nP\n\u2212V N\nn=1 E {\u03bcn (t)pn (t) \u2212 sn (\u03bcn (t)) | Q(t)}\nPN\n+V n=1 E {An (t)pn (t) + bn (An (t)) | Q(t)}\n\n(19)\n\nWe desire an algorithm that, every slot, observes the Q(t)\nvalues and the current prices, and makes a greedy trading\naction subject to the constraints (2)-(6) that minimizes the right\nhand side of (19).\n\nA. The Dynamic Trading Algorithm\nEvery slot t, observe Q(t) and p(t) and perform the\nfollowing actions.\n1) Selling: For each n \u2208 {1, . . . , N }, choose \u03bcn (t) to solve:\nMinimize: [\u03b8n \u2212 Qn (t) \u2212 V pn (t)]\u03bcn (t) + V sn (\u03bcn (t))\nSubject to:\n\nConstraints (2)-(4)\n\n2) Buying: Choose A(t) = (A1 (t), . . . , An (t)) to solve:\nMinimize:\nSubject to:\n\nPN\n\nn=1 [Qn (t) \u2212 \u03b8n + V pn (t)]An (t)\nPN\n+ n=1 V bn (An (t))\n\nN\nX\n\n(Qn (t) \u2212 \u03b8n )(\u03bcn (t) \u2212 An (t)) \u2264\n\nn=1\n\u2217\n\nB \u2212 V \u03c6 (t) \u2212\n\nN\nX\n\n(Qn (t) \u2212 \u03b8n )(\u03bc\u2217n (t) \u2212 A\u2217n (t))\n\n(20)\n\nn=1\n\nwhere A(t), \u03bc(t) are the actual decisions made by the\nalgorithm, which define \u03c6(t) by (8), and A\u2217 (t), \u03bc\u2217 (t) are\nany alternative (possibly randomized) decisions that can be\nmade on slot t that satisfy (2)-(6), which define \u03c6\u2217 (t) by (8).\nFurthermore, we have:\n\u2206(Q(t)) \u2212 V E {\u03c6(t) | Q(t)} \u2264 B\nPN\n\u2212 n=1 (Qn (t) \u2212 \u03b8n )E {\u03bc\u2217n (t) \u2212 A\u2217n (t) | Q(t)}\nPN\n\u2212V n=1 E {\u03bc\u2217n (t)pn (t) \u2212 sn (\u03bc\u2217n (t)) | Q(t)}\nP\n\u2217\n\u2217\n+V N\nn=1 E {An (t)pn (t) + bn (An (t)) | Q(t)}\n\n(21)\n\nwhere the expectation on the right hand side of (21) is with\nrespect to the random price vector p(t) and the possibly\nrandom actions A\u2217 (t), \u03bc\u2217 (t) in response to this price vector.\nProof: Given Q(t) on slot t, the dynamic algorithm makes\nbuying and selling decisions to minimize the left hand side of\n(20) over all alternative decisions that satisfy (2)-(6). Therefore, the inequality (20) holds for all realizations of the random\nquantities, and hence also holds when taking conditional\nexpectations of both sides. The conditional expectation of the\nleft hand side of (20) is equivalent to the right hand side of\nthe drift-minus-reward expression (19), which proves (21).\nThe main idea behind our analysis is that the Dynamic\nTrading Algorithm is simple to implement and does not require\nknowledge of the future or of the statistics of the price\nprocess p(t). However, it can be compared to alternative\npolicies A\u2217 (t) and \u03bc\u2217 (t) (such as in Lemma 2, and in other\nlemmas in Sections IV and V that consider more complex\nprice processes), and these policies possibly have knowledge\nboth of the price statistics and of the future.\n\nConstraints (5)-(6)\n\nThe buying algorithm uses the integer constraints (5)-(6),\nand is related to the well known bounded knapsack problem\n(it is exactly the bounded knapsack problem if the bn (*) functions are linear). Implementation of this integer constrained\nproblem can be complex when\nthe number of stocks N is\n\u25b3 PN\nmax max\npn + bn (\u03bcmax\n)],\nlarge. However, if we use x=\nn\nn=1 [\u03bcn\nthen constraint (6) is effectively removed. In this case, the\nstocks are decoupled and the buying algorithm reduces to\nmaking separate decisions for each stock n. Alternatively,\nthe constraint (6) can be replaced by the constraint (9). In\nthis case, it is easy to see that if buying costs are linear, so\nthat bn (A) = bn A for all n (for some positive constants bn ),\nthen the buying algorithm reduces to successively buying as\nmuch stock as possible from the queues with the smallest (and\nnegative) [Qn (t) \u2212 \u03b8n + V (pn (t) + bn )] values. An alternative\nrelaxation of the constraint (6) is discussed in Section VII-C.\n\nB. Bounding the Stock Queues\nThe next lemma shows that the above algorithm does not\nsell any shares of stock n if Qn (t) is sufficiently small.\nLemma 3: Under the above Dynamic Trading Algorithm\nand for arbitrary price processes p(t) that satisfy (1), if\nQn (t) < \u03b8n \u2212 V pmax\nfor some particular queue n and slot t,\nn\nthen \u03bcn (t) = 0. Therefore, if Qn (0) \u2265 \u03b8n \u2212 V pmax\n\u2212 \u03bcmax\n,\nn\nn\nthen:\nQn (t) \u2265 \u03b8n \u2212 V pmax\n\u2212 \u03bcmax\nfor all t\nn\nn\nProof: Suppose that Qn (t) < \u03b8n \u2212 V pmax\nfor some\nn\nparticular queue n and slot t. Then for any \u03bc \u2265 0 we have:\n[\u03b8n \u2212 Qn (t) \u2212 V pn (t)]\u03bc + V sn (\u03bc)\n\u2265 [\u03b8n \u2212 Qn (t) \u2212 V pmax\n]\u03bc + V sn (\u03bc)\nn\n\u2265\n\u2265\n\n[\u03b8n \u2212 Qn (t) \u2212 V pmax\n]\u03bc\nn\n0\n\n\f6\n\nwhere the final inequality holds with equality if and only\nif \u03bc = 0. Therefore, the Dynamic Trading Algorithm must\nchoose \u03bcn (t) = 0.\nNow suppose that Qn (t) \u2265 \u03b8n \u2212 V pmax\n\u2212 \u03bcmax\nfor some\nn\nn\ntime t. We show it also holds for t+1. If Qn (t) \u2265 \u03b8n \u2212V pmax\n,\nn\nthen it can decrease by at most \u03bcmax\non a single slot, so that\nn\nQn (t+1) \u2265 \u03b8n \u2212V pmax\n\u2212\u03bcmax\n. Conversely, if \u03b8n \u2212V pmax\n>\nn\nn\nn\nmax\nmax\nQn (t) \u2265 \u03b8n \u2212 V pn \u2212 \u03bcn , then we know \u03bcn (t) = 0 and\nso the queue cannot decrease on the next slot and we again\nhave Qn (t + 1) \u2265 \u03b8n \u2212 V pmax\n\u2212 \u03bcmax\n. It follows that this\nn\nn\ninequality is always upheld if it is satisfied at t = 0.\nWe note that the above lemma is a sample path statement\nthat holds for arbitrary (possibly non-ergodic) price processes.\nThe next lemma also deals with sample paths, and shows that\nall queues have a finite maximum size Qmax\n.\nn\nLemma 4: Under the above Dynamic Trading Algorithm\nand for arbitrary price processes p(t) that satisfy (1), if\nQn (t) > \u03b8n for some particular queue n and slot t, then\nAn (t) = 0 and so the queue cannot increase on the next slot.\nIt follows that if Qn (0) \u2264 \u03b8n + \u03bcmax\n, then:\nn\nQn (t) \u2264 \u03b8n + \u03bcmax\nfor all t\nn\nProof: Suppose that Qn (t) > \u03b8n for a particular queue\nn and slot t. Let A(t) = (A1 (t), . . . , AN (t)) be a vector of\nbuying decisions that solve the optimization associated with\nthe Buying algorithm on slot t, so that they minimize the\nexpression:\nN\nX\n\n[Qm (t) \u2212 \u03b8m + V pm (t)]Am (t) +\n\nm=1\n\nN\nX\n\nV bm (Am (t)) (22)\n\nm=1\n\nsubject to (5)-(6). Suppose that An (t) > 0 (we shall reach\na contradiction). Because the term [Qn (t) \u2212 \u03b8n + V pn (t)]\nis strictly positive, and because the bn (A) function is nondecreasing, we can strictly reduce the value of the expression\n(22) by changing An (t) to 0. This change still satisfies the\nconstraints (5)-(6) and produces a strictly smaller sum in (22),\ncontradicting the assumption that A(t) is a minimizer. Thus,\nif Qn (t) > \u03b8n , then An (t) = 0.\nBecause the queue value can increase by at most \u03bcmax\non\nn\nany slot, and cannot increase if it already exceeds \u03b8n , it follows\nthat Qn (t) \u2264 \u03b8n + \u03bcmax\nfor all t, provided that this inequality\nn\nholds at t = 0.\nC. Analyzing Time Average Profit\nTheorem 1: Fix any value V > 0, and define \u03b8n as follows:\n\u25b3\nV pmax\n+ 2\u03bcmax\n\u03b8n =\nn\nn\n\n(23)\n\nSuppose that initial stock queues satisfy:\n\u03bcmax\n\u2264 Qn (0) \u2264 V pmax\n+ 3\u03bcmax\nn\nn\nn\n\n(24)\n\nIf the Dynamic Trading Algorithm is implemented over t \u2208\n{0, 1, 2, . . .}, then:\n(a) Stock queues Qn (t) (for n \u2208 {1, . . . , N }) are deterministically bounded for all slots t as follows:\nfor all n and all t (25)\n\u03bcmax\n\u2264 Qn (t) \u2264 V pmax\n+ 3\u03bcmax\nn\nn\nn\n\n(b) If p(t) is i.i.d. over slots with general distribution\nP r[p(t) = p] = \u03c0(p) for all p \u2208 P, then for all t \u2208 {1, 2, . . .}\nwe have:\n\u03c6(t) \u2265 \u03c6opt \u2212\n\nB\nE {L(Q(0))}\n\u2212\nV\nVt\n\n(26)\n\nwhere the constant B is defined by (17) (and satisfies the\ninequality (18)), \u03c6opt is the optimal time average profit, and\n\u03c6(t) is the time average expected profit over t slots:\n\u25b3 1 Pt\u22121\n(27)\n\u03c6(t)=\n\u03c4 =0 E {\u03c6(\u03c4 )}\nt\n\nTherefore:\n\nlim inf \u03c6(t) \u2265 \u03c6opt \u2212 B/V\n(28)\nt\u2192\u221e\nTheorem 1 shows that the time average expected profit\nis within B/V of the optimal value \u03c6opt . Because the B\nconstant is independent of V , we can choose V to make\nB/V arbitrarily small. This comes with a tradeoff in the\nmaximum size required for each stock queue that is linear\nin V . Specifically, the maximum stock level Qmax\nrequired\nn\nfor stock n is given as follows:\n\u25b3\nmax\nmax\nQmax\n=V pn + 3\u03bcn\nn\n\nNow suppose that we start with initial condition Qn (0) =\n\u03bcmax\nfor all n and all t. Then for t \u2208 {1, 2, . . .} the error\nn\nterm L(Q(0))/(V t) is given by:\nPN\n(V pmax\n+ \u03bcmax\n)2\nL(Q(0))\nn\nn\n= n=1\n= O(V )/t\n(29)\nVt\n2V t\n\nThis shows that if V is chosen to be large, then the amount\nof time t required to make this error term negligible must\nalso be large. One can minimize this error term with an initial\ncondition Qn (0) that is close to \u03b8n for all n. However, this\nis an artificial savings, as it does not include the startup cost\nassociated with purchasing that many initial units of stock.\nTherefore, the timescales are more accurately described by\nthe transient given in (29).\nOne may wonder how the Dynamic Trading Algorithm is\nachieving near optimal profit without knowing the distribution\nof the price vector p(t), and without estimating this distribution. The answer is that it uses the queue values themselves\nto guide decisions. These queue values Qn (t) only deviate\nsignificantly from the target \u03b8n when inefficient decisions are\nmade. The values then act as a \"sufficient statistic\" on which\nto base future decisions. The same sufficient statistic holds for\nthe non-i.i.d. case, as shown in Section IV, so that we do not\nneed to estimate price patterns or time-correlations, provided\nthat we allow for a sufficiently large control parameter V and\ncorresponding large timescales for convergence.\nFinally, one may also wonder if the limiting time average\nexpected profit given in (28) also holds (with probability 1)\nfor the limiting time average profit (without the expectation).\nWhen p(t) evolves according to a finite state irreducible\nMarkov chain (as is the case in this i.i.d. scenario), then\nthe Dynamic Trading Algorithm in turn makes Q(t) evolve\naccording to a finite state Markov chain, and it can be shown\nthat the limiting time average expected profit is the same (with\nprobability 1) as the limiting time average profit.\n\n\f7\n\nD. Proof of Theorem 1\nProof: (Theorem 1 part (a)) By Lemma 3 we know that\nQn (t) \u2265 \u03b8n \u2212 V pmax\n\u2212 \u03bcmax\nfor all t (provided that this\nn\nn\nholds at t = 0). However, \u03b8n \u2212 V pmax\n\u2212 \u03bcmax\n= \u03bcmax\n. Thus,\nn\nn\nn\nmax\nQn (t) \u2265 \u03bcn\nfor all t, provided that this holds for t = 0.\nSimilarly, by Lemma 4 we know that Qn (t) \u2264 \u03b8n + \u03bcmax\nfor\nn\nall t (provided that this holds for t = 0), and \u03b8n + \u03bcmax\n=\nn\nQmax\n.\nn\nProof: (Theorem 1 part (b)) Fix a slot t \u2208 {0, 1, 2, . . .}. To\nprove part (b), we plug an alternative set of control choices\nA\u2217 (t) and \u03bc\u2217 (t) into the drift-minus-reward bound (21) of\nLemma 2. Because p(t) is i.i.d., we can choose A\u2217 (t) and\n\u03bc\u2217 (t) as the p-only policy that satisfies (13), (14). Note that\nwe must first ensure this p-only policy satisfies the constraint\n(4) needed to apply the bound (21). However, we know from\npart (a) of this theorem that Qn (t) \u2265 \u03bcmax\nfor all n, and so\nn\nthe constraint (4) is trivially satisfied. Therefore, we can plug\nthis policy A\u2217 (t) and \u03bc\u2217 (t) into (21) and use equalities (13)\nand (14) to yield:\n\u2206(Q(t)) \u2212 V E {\u03c6(t) | Q(t)} \u2264 B \u2212 V \u03c6opt\nTaking expectations of the above inequality over the distribution of Q(t) and using the law of iterated expectations yields:\nE {L(Q(t + 1)) \u2212 L(Q(t))} \u2212 V E {\u03c6(t)} \u2264 B \u2212 V \u03c6opt\nThe above holds for all t \u2208 {0, 1, 2, . . . , }. Summing the above\nover \u03c4 \u2208 {0, . . . , t \u2212 1} (for some positive integer t) yields:\nE {L(Q(t)) \u2212 L(Q(0))} \u2212 V\n\nt\u22121\nX\n\nE {\u03c6(\u03c4 )} \u2264 tB \u2212 tV \u03c6opt\n\n\u03c4 =0\n\nDividing by tV , rearranging terms, and using non-negativity\nof L(*) yields:\n\nthis the optimal p-only policy. Let A\u2217 (t) and \u03bc\u2217 (t) represent\nthe resulting decision variables under this policy. Because\nthese decisions react only to the current p(t), and because\nthe limiting fraction of time of being in each price state is the\nsame as the i.i.d. case, the identities (13) and (14) are now\ntrue in the limit as t \u2192 \u221e (rather than true on every slot t):\nt\u22121\n\nIV. N ON -I.I.D. P RICES\nHere we consider a general class of non-i.i.d. price processes that have a mild decaying memory property. We first\nnote that the only place a change is needed is in the proof\nof Theorem 1 part (b). Indeed, part (a) of Theorem 1 is a\nsample path statement that is true for any p(t) process. That\nis, regardless of whether or not p(t) is i.i.d. over slots, and\neven if it does not have well defined time averages as in (10),\nwe still have:\n\u03bcmax\n\u2264 Qn (t) \u2264 V pmax\n+ 3\u03bcmax\nfor all n and all t\nn\nn\nn\nprovided that this inequality is upheld at time 0, and that the\n\u03b8n values are defined as in (23).\nA. The Decaying Memory Property\nFirst consider any price vector process p(t) that satisfies\n(10), where \u03c0(p) is the time average fraction of time that\np(t) = p. Consider implementing the p-only policy that would\nachieve (13) and (14) on each slot t if the process where\ni.i.d. with the same steady state distribution \u03c0(p). We call\n\nlim\n\nt\u22121\n\nopt\n\n\u03c6\n\n1X\nlim\nE {\u03c6\u2217 (\u03c4 )}\nt\u2192\u221e t\n\u03c4 =0\n\n=\n\nwhere \u03c6\u2217 (\u03c4 ) is defined:\n\u03c6\u2217 (\u03c4 )\n\nN\nX\n\n\u25b3\n\n=\n\nE {\u03bc\u2217n (\u03c4 )pn (\u03c4 ) \u2212 sn (\u03bc\u2217n (\u03c4 ))}\n\nn=1\nN\nX\n\n\u2212\n\nE {A\u2217n (\u03c4 )pn (\u03c4 ) + bN (A\u2217n (\u03c4 ))} (30)\n\nn=1\n\nWe now further assume that the p(t) process achieves time\naverages that are close to these limits when summed over an\ninterval of T slots, regardless of the past history before the\ninterval. Specifically, let H(t) denote the history of the system\nup to slot t, defined:\n\u25b3\nH(t)=\n[Q(t), Q(t \u2212 1), . . . , Q(0); p(t \u2212 1), p(t \u2212 2), . . . , p(0)]\n\nAssume there are arbitrarily small values \u01eb > 0 for which\nthere exists a positive integer T (that may depend on \u01eb) such\nthat the optimal p-only policy yields the following: For any\nslot t0 \u2208 {0, 1, 2, . . .} and any H(t0 ), we have for all n \u2208\n{1, . . . , N }:\n1\nT\n\n\u03c6(t) \u2265 \u03c6opt \u2212 B/V \u2212 E {L(Q(0))} /V t\nwhere \u03c6(t) is defined in (27). This proves the result.\n\n1X\nE {A\u2217n (\u03c4 ) \u2212 \u03bc\u2217n (\u03c4 )} for all n\nt\u2192\u221e t\n\u03c4 =0\n\n0 =\n\nand\n\nt0 +T\nX\u22121\n\nE {A\u2217n (\u03c4 ) \u2212 \u03bc\u2217n (\u03c4 ) | H(t0 )} \u2264 \u01eb\n\n(31)\n\n\u03c4 =t0\n\n\u03c6opt \u2212\n\n1\nT\n\nt0 +T\nX\u22121\n\nE {\u03c6\u2217 (\u03c4 ) | H(t0 )} \u2264 \u01eb\n\n(32)\n\n\u03c4 =t0\n\nWe say that the stochastic process p(t) has the decaying\nmemory property if it satisfies (31) and (32). This property\nensures that time averages over any interval of T slots are\nuniformly close to their steady state values, regardless of\npast history. The simplest model that satisfies this decaying\nmemory property is the i.i.d. model, for which we can use\nT = 1 and \u01eb = 0. However, the decaying memory property\nis also satisfied by any p(t) process that evolves according\nto a finite state ergodic Markov chain, where the integer T is\nrelated to the \"mixing time\" of the chain.\nB. Performance\nTheorem 2: Suppose the Dynamic Trading Algorithm is\nimplemented, with \u03b8n values satisfying (23), and initial condition that satisfies (24). Then the queue backlog satisfies\nthe deterministic bound (25). Further, for any pair T , \u01eb that\nsatisfies (31), (32), we have for any integer M \u2208 {1, 2, 3, . . .}:\n\u03c6(M T ) \u2265 \u03c6opt \u2212 C2 \u01eb \u2212 C1 T /V \u2212\n\nE {L(Q(0))}\nV MT\n\n(33)\n\n\f8\n\nand:\nlim inf \u03c6(t) \u2265 \u03c6opt \u2212 C2 \u01eb \u2212 C1 T /V\nt\u2192\u221e\n\n(34)\n\nwhere C1 and C2 are defined:\n\u0015\n\u0014\nN\nN\nX\n\u01eb X max\n1\n1\n\u25b3\n2 3\n+\n+\n+\n\u03bc\nC1 =\n(\u03bcmax\n)\nn\n2 T\n2T 2\nT n=1 n\nn=1\nC2\n\n\u25b3\n\n=\n\n1+\n\nN\nX\n\npmax\nn\n\nn=1\n\nIf Q(0) = (\u03bcmax\n, . . . , \u03bcmax\n1\nN ), then L(Q(0))/(V M T ) has the\nform (29) with t = M T .\nProof: The theorem is proven by a Lyapunov drift argument\nover T -slot frames, and is given in Appendix B.\nNote that the same Dynamic Trading Algorithm as in the\ni.i.d. case is used here, without requiring knowledge of \u01eb or T .\nIndeed, the above performance bounds (33) and (34) hold for\nany \u01eb, T pair that satisfies (31) and (32). The bounds can thus\nbe optimized over all such \u01eb, T pairs. However, it suffices to\nnote that such pairs can be found for arbitrarily small values\nof \u01eb. Thus, choosing a large value of V makes achieved profit\narbitrarily close to the optimal value \u03c6opt . However, if the p(t)\nprocess has a long \"mixing time,\" then the value of T needed\nfor a given \u01eb will be large, and so the V parameter will also\nneed to be chosen to be large. Thus, non-i.i.d. p(t) processes\ntypically require larger queue sizes to ensure close proximity\nto the optimal profit.\nV. A RBITRARY P RICE P ROCESSES\nHere we consider the performance of the Dynamic Trading\nAlgorithm for an arbitrary price vector process p(t), possibly\na non-ergodic process without a well defined time average\nsuch as that given in (10). In this case, there may not be a well\ndefined \"optimal\" time average profit \u03c6opt . However, one can\ndefine \u03c6opt (t) as the maximum possible time average profit\nachievable over the interval {0, . . . , t \u2212 1} by an algorithm\nwith perfect knowledge of the future and that conforms to\nthe constraints (2)-(6). For the ergodic settings described in\nthe previous sections, \u03c6opt (t) has a well defined limiting\nvalue, and our algorithm comes close to its limiting value.\nIn this (possibly non-ergodic) setting, we do not claim that\nour algorithm comes close to \u03c6opt (t). Rather, we make a less\nambitious claim that our policy yields a profit that is close to\n(or greater than) the profit achievable by a frame-based policy\nthat can look only T slots into the future.\nA. The T -Slot Lookahead Performance\nLet T be a positive integer, and fix any slot t0 \u2208\n{0, 1, 2, . . .}. Define \u03c8T (t0 ) as the optimal profit achievable\nover the interval {t0 , . . . , t0 + T \u2212 1} by a policy that has\nperfect a-priori knowledge of the prices p(\u03c4 ) over this interval,\nand that ensures for each n \u2208 {1, . . . , N } that the total amount\nof stock n purchased over this interval is greater than or equal\nto the total amount sold. Specifically, \u03c8T (t0 ) is mathematically\ndefined according to the following optimization problem that\n\nhas decision variables A(\u03c4 ), \u03bc(\u03c4 ), and that treats the stock\nprices p(\u03c4 ) as deterministically known quantities:\n\u25b3 Pt0 +T \u22121 PN\nMax: \u03c8 =\nn=1 [\u03bcn (\u03c4 )pn (\u03c4 ) \u2212 sn (\u03bcn (\u03c4 ))]\n\u03c4 =t0\nPt0 +T \u22121 PN\n\u2212 \u03c4 =t0\nn=1 [An (\u03c4 )pn (\u03c4 ) + bn (An (\u03c4 ))] (35)\nP +T \u22121\nPt0 +T \u22121\n\u03bcn (\u03c4 ) \u2200n (36)\nAn (\u03c4 ) \u2265 \u03c4t0=t\nSubj. to:\n\u03c4 =t0\n0\nConstraints (2), (3), (5), (6)\n\n(37)\n\nThe value \u03c8T (t0 ) is equal to the maximizing value \u03c8 in the\nabove problem (35)-(37). Note that the constraint (36) only\nrequires the amount of type-n stock purchased to be greater\nthan or equal to the amount sold by the end of the T -slot\ninterval, and does not require this at intermediate steps of the\ninterval. This allows the T -slot Lookahead policy to sell short\nstock that is not yet owned, provided that the requisite amount\nis purchased by the end of the interval.\nNote that the trivial decisions A(\u03c4 ) = \u03bc(\u03c4 ) = 0 for \u03c4 \u2208\n{t0 , . . . , t0 +T \u22121} lead to 0 profit over the interval, and hence\n\u03a8T (t0 ) \u2265 0 for all T and all t0 . Consider now the interval\n{0, 1, . . . , M T \u2212 1} that is divided into a total of M frames of\nT -slots. We show that for any positive integer M , our Dynamic\nTrading Algorithm yields an average profit over this interval\nthat is close to the average profit of a T -slot lookahead policy\nthat is implemented on each T -slot frame of this interval.\nB. The T -Slot Sample Path Drift\nLet L(Q(t)) be the Lyapunov function of (15). For a given\nslot t and a given positive integer T , define the T -slot sample\n\u02c6 T (t) as follows:\npath drift \u2206\n\u25b3\n\u02c6 T (t)=\n\u2206\nL(Q(t + T )) \u2212 L(Q(t))\n\n(38)\n\nThis differs from the one-slot conditional Lyapunov drift in\n(16) in two respects:\n\u2022\n\u2022\n\nIt considers the difference in the Lyapunov function over\nT slots, rather than a single slot.\nIt is a random variable equal to the difference between\nthe Lyapunov function on slots t and t + T , rather than\na conditional expectation of this difference.\n\nLemma 5: Suppose the Dynamic Trading Algorithm is implemented, with \u03b8n values satisfying (23), and initial condition\nthat satisfies (24). Then for any given slot t0 and all integers\nT > 0, we have:\n\u02c6 T (t0 ) \u2212 V Pt0 +T \u22121 \u03c6(\u03c4 ) \u2264 DT 2 \u2212 V Pt0 +T \u22121 \u03c6\u2217 (\u03c4 )\n\u2206\n\u03c4 =t0\n\u03c4 =t0\nPt +T \u22121\nPN\n+ n=1 |Qn (t0 ) \u2212 \u03b8n | \u03c40=t0 [\u03bc\u2217n (\u03c4 ) \u2212 A\u2217n (\u03c4 )]\n\nwhere \u03c6(\u03c4 ) is defined in (8), and \u03c6\u2217 (\u03c4 ), \u03bc\u2217 (\u03c4 ), A\u2217 (\u03c4 )\nrepresent any alternative control actions for slot \u03c4 that satisfy\nthe constraints (2), (3), (5), (6). Further, the constant D is\ngiven by:\n\n\u0015 N\n1 X max 2\n1\n3\n+\n+\n(\u03bc\n)\n(39)\nD=\n2 2T 2 T n=1 n\nProof: This lemma is identical to Lemma 8 in Appendix\nB, and the proof is given there.\n\u25b3\n\n\u0014\n\n\f9\n\nTheorem 3: Suppose the Dynamic Trading Algorithm is\nimplemented, with \u03b8n values satisfying (23), and initial condition that satisfies (24). Then for any arbitrary price process\np(t) that satisfies (1), we have:\n(a) All queues Qn (t) are bounded according to (25).\n(b) For any positive integers M and T , the time average\nprofit over the interval {0, . . . , M T \u2212 1} satisfies the deterministic bound:\nMT \u22121\n1 X\n\u03c6(\u03c4 )\nM T \u03c4 =0\n\n\u2265\n\nM\u22121\n1 X\n\u03c8T (mT )\nM T m=0\n\n\u2212\n\nL(Q(0))\nDT\n\u2212\nV\nMT V\n\n(40)\n\nwhere the \u03c8T (mT ) values are defined according to the T slot lookahead policy that uses knowledge of the future to\nsolve (35)-(37) for each T -slot frame. The constant D is\ndefined in (39), and if Q(0) = (\u03bcmax\n, . . . , \u03bcmax\n1\nN ) then\nL(Q(0))/(M T V ) has the form (29) with t = M T .\nProof: Part (a) has already been proven in Theorem 1. To\nprove part (b), fix any slot t0 and any positive integer T . Define\nA\u2217 (\u03c4 ) and \u03bc\u2217 (\u03c4 ) as the solution of (35)-(37) over the interval\n\u03c4 \u2208 {t0 , . . . , t0 + T \u2212 1}. By (37), these decision variables\nsatisfy constraints (2), (3), (5), (6), and hence can be plugged\nin to the bound in Lemma 5. Because (35), (36) hold for these\nvariables, by Lemma 5 we have:\n\u02c6 T (t0 ) \u2212 V\n\u2206\n\nt0 +T\nX\u22121\n\n\u03c6(\u03c4 ) \u2264 DT 2 \u2212 V \u03c8T (t0 )\n\n\u03c4 =t0\n\n\u02c6 T (t0 ) given in (38) yields:\nUsing the definition of \u2206\nL(Q(t0 +T ))\u2212L(Q(t0 ))\u2212V\n\nt0 +T\nX\u22121\n\n\u03c6(\u03c4 ) \u2264 DT 2 \u2212V \u03c8T (t0 )\n\n\u03c4 =t0\n\nThe above inequality holds for all slots t0 \u2208 {0, 1, 2, . . .}.\nLetting t0 = mT and summing over m \u2208 {0, 1, . . . , M \u2212 1}\n(for some positive integer M ) yields:\nL(Q(M T )) \u2212 L(Q(0)) \u2212 V\n2\n\nM DT \u2212 V\n\nMT\n\u22121\nX\n\u03c4 =0\nM\u22121\nX\n\n\u03c6(\u03c4 ) \u2264\n\n\u03c8T (mT )\n\nm=0\n\nRearranging terms and using non-negativity of L(*) proves the\ntheorem.\nTheorem 3 is stated for general price processes, but has\nexplicit performance bounds for queue size in terms of the\nchosen V parameter, and for profit in terms of V and of the\nprofit \u03c8T (mT ) of T -slot lookahead policies. Plugging a large\nvalue of T into the bound (40) increases the first term on\nthe right hand side because it allows for a larger amount of\nlookahead. However, this comes with the cost of increasing\nthe term DT /V that is required to be small to ensure close\nproximity to the desired profit. One can use this theorem\nwith any desired model of stock prices to compute statistics\nassociated with \u03c8T (mT ) and hence understand more precisely\nthe timescales over which near-optimal profit is achieved.\n\nVI. P LACE -H OLDER S TOCK\nTheorems 1, 2, 3 require an initial stock level of at least\n\u03bcmax\nin all of the N stocks. This can be achieved by initially\nn\npurchasing these shares (say, at time t = \u22121). This creates\nan initial startup cost that, while independent of V , can still\nbe substantial. It turns out that we can achieve the same\nperformance as specified in Theorems 1, 2, 3 without paying\nthis startup cost. This can be done using the concept of placeholder backlog from [20], which becomes place-holder stock\nin our context.\nSpecifically, suppose that we use Q\u0302(t) to represent the\nactual amount of stock held on slot t, and assume that Q\u0302(0)\nsatisfies:\n0 \u2264 Q\u0302n (0) \u2264 V pmax\n+ 2\u03bcmax\nfor all n \u2208 {1, . . . , N }\nn\nn\n\u25b3\nDefine Q(t)=\nQ\u0302(t) + \u03bcmax as an augmented stock vector,\nwhere vector \u03bcmax is given by:\n\u25b3\n(\u03bcmax\n, . . . , \u03bcmax\n\u03bcmax =\n1\nN )\n\nNotice that the initial value of Q(0) satisfies (24). Let us implement the Dynamic Trading Algorithm using the augmented\nstock vector Q(t). This is equivalent to starting out the system\nwith an initial amount that includes \u03bcmax\nfake shares of stock\nn\nin all queues. We then run the algorithm on the Q(t) values,\nand any time we are asked to sell stock, we choose to sell\nreal shares whenever possible. The algorithm breaks if at any\ntime we are asked to sell at a level that is more than the\nnumber of real shares we have. However, because on every\nsample path, we have Qn (t) \u2265 \u03bcmax\n, we know that we are\nn\nnever asked to sell more real shares than we actually have.\nThus, these fake shares simply act as place holders to achieve\nthe performance that would be achieved if we started out\nwith \u03bcmax\nunits of real shares in all queues. Specifically, we\nn\nachieve performance guarantees specified in Theorems 1, 2, 3\nassociated with Q(0). If all actual queues are initially empty,\nthen we have Q(0) = \u03bcmax , and hence we also have transients\ncorresponding to L(Q(0)) = L(\u03bcmax ), without having to pay\nthe startup cost of purchasing \u03bcmax\nshares of each stock.\nn\nVII. E XTENSIONS\nA. Price Jumps and Stock Splits\nWe have assumed that prices are bounded by values pmax\nn\nfor simplicity of exposition. In practice, the pmax\nvalues can\nn\nbe chosen as price levels that we do not expect to see (perhaps\n3 or 4 times the current price). The prediction should be small\nenough to maintain reasonably small values for \u03b8n and Qmax\n,\nn\ngiven in (23) and (25).\nIn the (desirable) situation when the price of a certain stock\nn exceeds our estimated upper bound pmax\n, we can simply\nn\nadjust pmax\nto\na\nhigher\nvalue.\nWe\nmust\nthen\nalso\nappropriately\nn\nadjust \u03b8n according to (23). This can be viewed as if we are\nstarting the system off with a new initial condition at this time\n(given by the current queue state), with new parameter choices.\nBecause Theorems 1, 2, 3 are stated in terms of general initial\nconditions, the achieved performance is then also determined\nby these theorems (applied to the time interval starting at the\n\n\f10\n\ncurrent time). Intuitively, this will not \"break\" the algorithm\nbecause it continuously adapts to emerging conditions.\nSimilarly, we might have a price go so high as to affect a\nstock split. This (desirable) situation can either be modeled by\nan increase in the pmax\nvalue (maintaining the same number\nn\nof shares, but treating each share as being worth double the\nmarket price), or by doubling the number of shares of that\nstock and increasing the \u03bcmax\nand/or the V parameter to allow\nn\nfor more shares to be maintained. Again, the new situation\ncan be viewed as creating a new initial condition, and so the\nalgorithm can adapt to such events.\nB. Scaling for Exponential Growth\nSuppose we run the Dynamic Trading Algorithm over a\nfixed window of W slots, using parameters \u03bcmax\nand V , with\nn\n\u03b8nmax defined by (23). Assume we use place-holder stock so\nthat the actual stock queues are 0 at the beginning of the time\nwindow. If the achieved profit over this window is z, then\nfor any given value \u03b1 > 0, a profit (1 + \u03b1)z could have\nand V parameters\nbeen achieved if we had scaled the \u03bcmax\nn\n(and hence \u03b8nmax by (23)) by a factor (1 + \u03b1) (for simplicity,\nwe ignore integer constraints in the scaling of \u03bcmax\nfor the\nn\nhigh level discussion of this subsection). Of course, doing this\nwould require a tolerance to the extra amount of risk associated\nwith keeping that much more stock in the stock queues.\nHowever, assuming our risk tolerance grows proportionally to\nour wealth, this increased risk is tolerable on the next window\nof W slots. Specifically, choose a value T , and consider the\nT -slot lookahead policy for comparison using (40) of Theorem\n3. Fix a value \u01eb > 0, and choose \u03bcmax\n, V , and M so that\nn\nDT /V + L(\u03bcmax )/(M T V ) \u2264 \u01eb. Let W = M T . Then by\n(40) we know that time average profit over W slots is within\n\u01eb of that provided by the T -slot lookahead policy.\nNow consider consecutive windows of W slots, and define\nqw as the time average profit that would be earned over the\nwth window if we use place-holder stock with 0 initial stock\n, V , and \u03b8nmax . Let\nlevels, and if we use parameters \u03bcmax\nn\n(T )\nqw denote the time average profit of the T -slot lookahead\npolicy over this same window of time. By Theorem 3 we have\n(T )\nthat qw \u2265 qw \u2212 \u01eb for each window w \u2208 {1, 2, . . .}. Define\n\u25b3\n\u03b1w =\u03b2 max[qw , 0], where \u03b2 is some positive proportionality\nconstant. Then \u03b1w is non-negative, and if it is positive then it\nis proportional to the profit earned over window w. On each\nwindow w > 1, rather than using parameters \u03bcmax\n, V , and\nn\n\u03b8nmax , we scale these by the following factor:\n(1 + \u03b11 )(1 + \u03b12 ) * * * (1 + \u03b1w\u22121 )\nIgnoring integer constraints in this scaling for simplicity, we\nknow that time average profit earned over window w is at\nleast:\n(T )\n(qw\n\u2212 \u01eb)(1 + \u03b11 )(1 + \u03b12 ) * * * (1 + \u03b1w\u22121 )\n\nIt follows that our wealth increases exponentially as (1 +\n\u03b11 )(1 + \u03b12 )(1 + \u03b13 ) . . ., where the profit coefficients \u03b1w are\nclose to those associated with the T -slot lookahead policy. In\nparticular, the \u03b1i coefficients are all greater than a uniform\n(T )\npositive number whenever qw \u2265 2\u01eb for all w \u2208 {1, 2, . . .}.\n\nC. Relaxing the Buying Constraint (6)\nThe constraint (6) can make the buying policy of the\nDynamic Trading Algorithm difficult to implement when the\nnumber of stocks N is large, as discussed after the description of the algorithm in Section III-A. Here we consider a\nsimple and greedy modification that relaxes the constraint (6):\nAssume the buying functions bn (A) are concave and nondecreasing. The algorithm seeks to minimize the expression:\nN\nX\n\n[(Qn (t) \u2212 \u03b8n + V pn (t))An (t) + V bn (An (t))]\n\n(41)\n\nn=1\n\nsubject to An (t)P\u2208 {0, 1, . . . , \u03bcmax\n} for all n \u2208 {1, . . . , N },\nn\nN\nand subject to n=1 An (t)pn (t) \u2264 x. Consider the following sequential algorithm for adding new shares until this\nlast constraint is either met or exceeded: Initialize A =\n(A1 , . . . , AN ) = 0. On step k of the procedure, for each\nn \u2208 {1, . . . , N } such that An \u2264 \u03bcmax\n, compute the value\nn\nof:\n(Qn (t) \u2212 \u03b8n + V pn (t)) + V (bn (An + 1) \u2212 bn (An ))\npn (t)\nIf this value is non-negative for all n \u2208 {1, . . . , N }, stop and\ndesignate A(t) = A. Else, choose the n with the smallest\n(negative) such value and add one more\nPN share to the A vector\nin that entry n. If the constraint\nn=1 An (t)pn (t) \u2264 x is\neither met or exceeded, we are done and choose A(t) = A.\nElse, repeat the procedure with the new A vector.\nThe intuition behind this greedy relaxation is that we\nchoose to increment our allocation by one share in the stock\nwith the smallest (negative) ratio given by the incremental\nchange in (41) divided by the amount consumed in the total\nmoney budget x. This procedure yields a vector A(t) that\nmax\nsatisfies the constraints An (t) \u2208 {0, 1,\nP. . . , \u03bcn } for all n,\nalthough it may violate the constraint n An (t)pn (t) \u2264 x by\novershooting the required value x with purchase of one extra\nshare of a particular stock. However, it has the property:\nN\nX\n\nn=1\n\nAn (t)pn (t) \u2264 x +\n\nmax\n\nn\u2208{1,...,N }\n\npmax\nn\n\nTherefore, we spend no more than a constant amount over our\nintended constraint x on each slot. It can be shown that this\ngreedy policy yields a value of the expression (41) that is less\nthan or equal to the corresponding expression that minimizes\nthis value subject to the original constraints (5)-(6). This is\nthe key property used in Lemma 2 to prove Theorems 1, 2,\n3. Hence, it can be shown that these theorems still hold under\nthis relaxation. Specifically, our queue sizes are still bounded\naccording to (25) (which was derived using only the \u03bcmax\nn\nconstraints and not constraint (6)), and our time average profit\n(under this relaxed policy that does not necessarily satisfy\n(6)) is close to or better than the corresponding policies used\nfor comparison in Theorems 1, 2, 3, which do satisfy the\nconstraint (6).\nVIII. C ONCLUSION\nThis work uses Lyapunov optimization theory, developed\nfor stochastic optimization of queueing networks, to construct\n\n\f11\n\na dynamic policy for buying and selling stock. When prices\nare ergodic, a single non-anticipating policy was constructed\nand shown to perform close to an ideal policy with perfect\nknowledge of the future, with a tradeoff in the required amount\nof stock kept in each queue and in the timescales associated\nwith convergence. For arbitrary price sample paths, the same\nalgorithm was shown to achieve a time average profit close\nto that of a frame based T -slot lookahead policy that can\nlook T slots into the future. Our framework constrains the\nmaximum number of stock shares that can be bought and\nsold at any time. While this restricts the long term growth\ncurve to a linear growth, it also limits risk by ensuring no\nmore than a constant value Qmax\nshares of each stock n are\nn\nkept at any time. A modified policy was briefly discussed that\nachieves exponential growth by scaling Qmax\nin proportion\nn\nto increased risk tolerance as wealth increases. These results\nadd to the theory of universal stock trading, and are important\nfor understanding optimal decision making in the presence of\na complex and possibly unknown price process.\nA PPENDIX A - P ROOF OF L EMMA 1\nHere we prove Lemma 1. From the dynamics for Qn (t) in\n(7) we have:\n(Qn (t + 1) \u2212 \u03b8n )2 = (max[Qn (t) \u2212 \u03bcn (t) + An (t), 0] \u2212 \u03b8n )2\n\u2264 (Qn (t) \u2212 \u03bcn (t) + An (t) \u2212 \u03b8n )2\n\n(42)\n\nThe inequality above holds because \u03b8n \u2265 0. To see this, note\nthat the inequality holds with equality if Qn (t) \u2212 \u03bcn (t) +\nAn (t) \u2265 0. In the opposite case, the result of the max[*, 0]\noperation is 0, and we have:\n(0 \u2212 \u03b8n )2 \u2264 (z \u2212 \u03b8n )2\nwhere z is any negative number, and so:\n\n(Qn (t) \u2212 \u03b8n )2\n(\u03bcn (t) \u2212 An (t))2\n+\n2\n2\n\u2212(Qn (t) \u2212 \u03b8n )(\u03bcn (t) \u2212 An (t))\n\nSumming over n \u2208 {1, . . . , N } and taking conditional expectations proves that:\n\u2206(Q(t)) \u2264\n\nN\n1X \b\nE (\u03bcn (t) \u2212 An (t))2 | Q(t)\n2 n=1\n\n\u2212\n\nN\nX\n\n(Qn (t) \u2212 \u03b8)E {\u03bcn (t) \u2212 An (t) | Q(t)}\n\nn=1\n\nUsing the definition of B in (17) to replace the first term on\nthe right hand side above yields the result.\nA PPENDIX B - P ROOF OF T HEOREM 2\nA. T -Slot Drift Analysis\nFor the same Lyapunov function given in (15), and for\na given positive integer T , define the T -slot conditional\nLyapunov drift as follows:\n\u25b3\n\u2206T (H(t))=\nE {L(Q(t + T )) \u2212 L(Q(t)) | H(t)}\n\nLemma 6: Suppose the Dynamic Trading Algorithm is implemented, with \u03b8n values satisfying (23), and initial condition\nthat satisfies (24). Then for all t0 \u2208 {0, 1, 2, . . .}, all integers\nT > 0, and all possible values of Q(t0 ) we have:\nN\nX\n\n\u02c6 T (t0 ) \u2264 T 2 B\u0303 \u2212\n\u2206\n\n(Qn (t0 ) \u2212 \u03b8n )\n\nt0 +T\nX\u22121\n\n[\u03bcn (\u03c4 ) \u2212 An (\u03c4 )]\n\n\u03c4 =t0\n\nn=1\n\nwhere B\u0303 is defined:\nN\n(1 + 1/T 2 ) X max 2\n(\u03bcn )\n2\nn=1\nProof: First note that:\n\u25b3\nB\u0303 =\n\n(Qn (t0 + T ) \u2212 \u03b8n )2 \u2264 (\u03bcmax\n)2\nn\n\u00112\n\u0010\nPt +T \u22121\n+ Qn (t0 ) \u2212 \u03c40=t0 [\u03bcn (\u03c4 ) \u2212 An (\u03c4 )] \u2212 \u03b8n\n\n(45)\n\nThis can be seen as follows: If Qn (t0 + T ) \u2265 \u03b8n , then by (25)\nand (23) we know that |Qn (t0 + T ) \u2212 \u03b8n | \u2264 \u03bcmax\n, and so\nn\nthe square of this quantity is bounded by the first term on the\nright hand side of (45), so that (45) holds in this case. Else,\nsuppose that Qn (t0 + T ) < \u03b8n . We then have:\nt0 +T\nX\u22121\n\n[\u03bcn (\u03c4 ) \u2212 An (\u03c4 )]\n\n\u03c4 =t0\n\nFrom (42) we have:\n\u2264\n\n\u02c6 T (t) is a random variable representing\nWith this definition, \u2206\nthe difference between the Lyapunov function at time t + T\nand time t, and:\nn\no\n\u02c6 T (t) | H(t) = \u2206T (H(t))\nE \u2206\n(44)\n\n\u03b8n > Qn (t0 + T ) \u2265 Qn (t0 ) \u2212\n\n(0 \u2212 \u03b8n )2 \u2264 (Qn (t) \u2212 \u03bcn (t) + An (t) \u2212 \u03b8n )2\n(Qn (t + 1) \u2212 \u03b8n )2\n2\n\nwhere H(t) is the past history up to time t, defined as\n[Q(t), Q(t \u2212 1), . . . , Q(0); p(t \u2212 1), p(t \u2212 2), . . . , p(0)]. Also\n\u02c6 T (t) as:\ndefine the T -slot sample path drift \u2206\n\u25b3\n\u02c6 T (t)=\nL(Q(t + T )) \u2212 L(Q(t))\n\u2206\n\n(43)\n\nwhere the second inequality holds because the right hand side\nneglects the max[*, 0] in the queueing dynamics (7). It follows\nthat (45) again holds.\nFrom (45) we have:\n\u0002\n\u0003\n1\n2\n2\n\u2264 (\u03bcmax\n)2 /2\nn\n2 (Qn (t0 + T ) \u2212 \u03b8n ) \u2212 (Qn (t0 ) \u2212 \u03b8n )\n\u0010P\n\u00112\nt0 +T \u22121\n+ 21\n[\u03bcn (\u03c4 ) \u2212 An (\u03c4 )]\n\u03c4 =t0\nPt0 +T \u22121\n\u2212(Qn (t0 ) \u2212 \u03b8n ) \u03c4 =t0 [\u03bcn (\u03c4 ) \u2212 An (\u03c4 )]\n\nNote that |\u03bcn (\u03c4 ) \u2212 An (\u03c4 )| \u2264 \u03bcmax\nfor all \u03c4 . Summing the\nn\nabove over n \u2208 {1, . . . , N } yield the result.\nLemma 7: Suppose the Dynamic Trading Algorithm is implemented, with \u03b8n values satisfying (23), and initial condition\nthat satisfies (24). Then for any times \u03c4 and t0 such that\n\u03c4 \u2265 t0 , and for any given Q(\u03c4 ), Q(t0 ), we have:\n\u2212V \u03c6(\u03c4 ) \u2212\n\nN\nX\n\n(Qn (t0 ) \u2212 \u03b8n )(\u03bcn (\u03c4 ) \u2212 An (\u03c4 )) \u2264\n\nn=1\n\n2|\u03c4 \u2212 t0 |\n\nN\nX\n\n(\u03bcmax\n)2\nn\n\nn=1\n\n\u2212V \u03c6\u2217 (\u03c4 ) \u2212\n\nN\nX\n\n(Qn (t0 ) \u2212 \u03b8n )(\u03bc\u2217n (\u03c4 ) \u2212 A\u2217n (\u03c4 ))\n\nn=1\n\n\f12\n\nwhere \u03c6(\u03c4 ) is defined in (8), and \u03c6\u2217 (\u03c4 ), \u03bc\u2217 (\u03c4 ), A\u2217 (\u03c4 )\nrepresent any alternative control actions for slot \u03c4 that satisfy\nthe constraints (2), (3), (5), (6).\nProof: Because each queue can change by at most \u03bcmax\nn\nper slot, we have for each n \u2208 {1, . . . , N }:\n\u2212 Qn (t0 )(\u03bcn (\u03c4 ) \u2212 An (\u03c4 )) \u2264 \u2212Qn (\u03c4 )(\u03bcn (\u03c4 ) \u2212 An (\u03c4 ))\n+|\u03c4 \u2212 t0 |(\u03bcmax\n)2 (46)\nn\n\nwhere M(t) is the set of all n \u2208 {1, . . . P\n, N } such that\nN\n)2 .\nQn (t) > \u03b8n . The final term is bounded by 2T n=1 (\u03bcmax\nn\nThus:\nt0 +T\nN\nX\nX\u22121\n[\u03bc\u2217n (\u03c4 ) \u2212 A\u2217n (\u03c4 )]\n(Qn (t0 ) \u2212 \u03b8n )\n\u2212\n\u2264\n\nn=1\n\n\u03c4 =t0\n\nN\nX\n\nt0 +T\nX\u22121\n\n|Qn (t0 ) \u2212 \u03b8n |\n\n\u2212V \u03c6(\u03c4 ) \u2212\n\n(47)\n(48)\n\nwhere (47) holds because, from Lemma 2, we know the\nDynamic Trading Algorithm on slot \u03c4 minimizes the left\nhand side of the inequality over all alternative decisions for\nslot \u03c4 that satisfy the constraints (2), (3), (5), (6) (note that\nwe already know Qn (\u03c4 ) \u2265 \u03bcmax\nand so constraint (4) is\nn\nredundant). Inequality (48) follows by an argument similar to\n(46).\nLemma 8: Suppose the Dynamic Trading Algorithm is implemented, with \u03b8n values satisfying (23), and initial condition\nthat satisfies (24). Then for any given slot t0 , all integers\nT > 0, and all possible values of Q(t0 ) we have:\nP\nP\n\u02c6 T (t0 ) \u2212 V t0 +T \u22121 \u03c6(\u03c4 ) \u2264 DT 2 \u2212 V t0 +T \u22121 \u03c6\u2217 (\u03c4 )\n\u2206\n\u03c4 =t0\n\u03c4 =t0\nPN\nPt0 +T \u22121 \u2217\n+ n=1 |Qn (t0 ) \u2212 \u03b8n | \u03c4 =t0 [\u03bcn (\u03c4 ) \u2212 A\u2217n (\u03c4 )]\n\u2217\n\n\u2217\n\nNow note that \u2212(Qn (t)\u2212\u03b8n ) = |Qn (t0 )\u2212\u03b8n | if Qn (t0 ) \u2264 \u03b8n .\nElse, if Qn (t0 ) > \u03b8n then Qn (t0 ) \u2212 \u03b8n = |Qn (t0 ) \u2212 \u03b8n | \u2264\n(by (25) and (23)). Thus:\n\u03bcmax\nn\n\u2212\n\n(Qn (t0 ) \u2212 \u03b8n )\n\nN\nX\n\n|Qn (t0 ) \u2212 \u03b8n |\n\nn=1\n\n\u22122\n\nX\n\nn\u2208M(t)\n\n[\u03bc\u2217n (\u03c4 ) \u2212 A\u2217n (\u03c4 )]\n\n\u03c4 =t0\n\nn=1\n\n=\n\nt0 +T\nX\u22121\n\n|Qn (t0 ) \u2212 \u03b8n |\n\nPlugging the policy A\u2217 (t), \u03bc\u2217 (t) (and hence \u03c6\u2217 (t)) that yields\n(31), (32) gives:\nPt +T \u22121\n\u2206T (H(t0 )) \u2212 V \u03c40=t0 E {\u03c6(\u03c4 ) | H(t0 )} \u2264 DT 2\n\u2212V T \u03c6opt + V T \u01eb\nPN\n+ n=1 [V pmax\n+ \u03bcmax\n]T \u01eb\n(50)\nn\nn\nwhere we have used the fact that (by (25) and (23)):\n+ \u03bcmax\n|Qn (t0 ) \u2212 \u03b8n | \u2264 V pmax\nn\nn\nTaking expectations of (50) with respect to H(t0 ) yields:\nE {L(Q(t0 + T )) \u2212 L(Q(t0 ))} \u2212 V\n\nt0 +T\nX\u22121\n\nE {\u03c6(\u03c4 )} \u2264\n\n\u03c4 =t0\n\nC1 T 2 + V T C2 \u01eb \u2212 V T \u03c6opt\nwhere C1 and C2 are defined:\nC1\n\nN\n\u01eb X max\n\u03bc\n= D+\nT n=1 n\n\nC2\n\n\u25b3\n= 1+\n\n\u25b3\n\nN\nX\n\npmax\nn\n\nn=1\n\nThe above holds for all t0 . Summing over t0 \u2208\n{0, T, 2T, . . . , (M \u2212 1)T } for some positive integer M and\ndividing by V M T yields:\nMT \u22121\n1 X\nE {L(Q(M T )) \u2212 L(Q(0))}\n\u2212\nE {\u03c6(\u03c4 )} \u2264\nV MT\nM T \u03c4 =0\n\nC1 T /V + C2 \u01eb \u2212 \u03c6opt\n\nRearranging terms and using non-negativity of L(*) yields:\n\n[\u03bc\u2217n (\u03c4 ) \u2212 A\u2217n \u03c4 )]\n\nE {L(Q(0))}\nV MT\nTherefore (noting that the lim inf sampled every T slots is the\nsame as the regular lim inf because \u03c6(\u03c4 ) is bounded) yields:\n\n[\u03bc\u2217n (\u03c4 ) \u2212 A\u2217n (\u03c4 )]\n\nlim inf \u03c6(t) \u2265 \u03c6opt \u2212 C2 \u01eb \u2212 C1 T /V\n\nt0 +T\nX\u22121\n\u03c4 =t0\n\nt0 +T\nX\u22121\n\u03c4 =t0\n\n(\u03bcmax\n)2\nn\n\nB. The Time Average Profit\nIf the system satisfies the requirements specified in Lemma\n\u02c6 T (t0 ) to\n8, then we can take conditional expectations of \u2206\nyield (from (44)):\nPt +T \u22121\n\u2206T (H(t0 )) \u2212 V \u03c40=t0 E {\u03c6(\u03c4 ) | H(t0 )} \u2264 DT 2\nPt +T \u22121\n\u2212V \u03c40=t0 E {\u03c6\u2217 (\u03c4 ) | H(t0 )}\nPN\nPt +T \u22121\n+ n=1 |Qn (t0 ) \u2212 \u03b8n | \u03c40=t0 E {\u03bc\u2217n (\u03c4 ) \u2212 A\u2217n (\u03c4 ) | H(t0 )}\n\nn=1\n\nProof: Summing the result of Lemma 7 over \u03c4 \u2208\n{t0 , . . . , t0 + T \u2212 1} and using Lemma 6 yields:\nP\n\u02c6 T (t0 ) \u2212 V t0 +T \u22121 \u03c6(\u03c4 ) \u2264 T 2 B\u0303\n\u2206\n\u03c4 =t0\nP\nP +T \u22121 \u2217\nmax 2\n\u03c6 (\u03c4 )\n+ N\n(\u03bc\n) (T \u2212 1)T \u2212 V \u03c4t0=t\nn=1 n\n0\nPN\nPt0 +T \u22121 \u2217\n\u2212 n=1 (Qn (t0 ) \u2212 \u03b8n ) \u03c4 =t0 [\u03bcn (\u03c4 ) \u2212 A\u2217n (\u03c4 )] (49)\n\nN\nX\n\nn=1\n\n\u2217\n\nwhere \u03c6(\u03c4 ) is defined in (8), and \u03c6 (\u03c4 ), \u03bc (\u03c4 ), A (\u03c4 )\nrepresent any alternative control actions for slot \u03c4 that satisfy\nthe constraints (2), (3), (5), (6). Further, the constant D is\ndefined:\nN\nX\n\u25b3\nD=B\u0303 + (1 + 1/T )\n(\u03bcmax\n)2\nn\n\nN\nX\n\n+ 2T\n\nUsing this in (49) yields the result.\n\nPN\n\nn=1 (Qn (t0 ) \u2212 \u03b8n )(\u03bcn (\u03c4 ) \u2212 An (\u03c4 ))\nPN\n)2 \u2212 V \u03c6(\u03c4 )\n\u2264 |\u03c4 \u2212 t0 | n=1 (\u03bcmax\nn\nPN\n\u2212 n=1 (Qn (\u03c4 ) \u2212 \u03b8n )(\u03bcn (\u03c4 ) \u2212 An (\u03c4 ))\nPN\n\u2264 |\u03c4 \u2212 t0 | n=1 (\u03bcmax\n)2 \u2212 V \u03c6\u2217 (\u03c4 )\nn\nPN\n\u2212 n=1 (Qn (\u03c4 ) \u2212 \u03b8n )(\u03bc\u2217n (\u03c4 ) \u2212 A\u2217n (\u03c4 ))\nPN\n)2 \u2212 V \u03c6\u2217 (\u03c4 )\n\u2264 2|\u03c4 \u2212 t0 | n=1 (\u03bcmax\nn\nPN\n\u2212 n=1 (Qn (t0 ) \u2212 \u03b8n )(\u03bc\u2217n (\u03c4 ) \u2212 A\u2217n (\u03c4 ))\n\n\u2212\n\nA\u2217n \u03c4 )]\n\n\u03c4 =t0\n\nn=1\n\nTherefore:\n\n[\u03bc\u2217n (\u03c4 )\n\n\u03c6(M T ) \u2265 \u03c6opt \u2212 C2 \u01eb \u2212 C1 T /V \u2212\n\nt\u2192\u221e\n\n\f13\n\nA PPENDIX C - C HARACTERIZATION OF \u03c6opt\nLemma 9: The value \u03c6opt is achievable by a single p-only\npolicy that satisfies d\u2217n = 0 for all n \u2208 {1, . . . , N }.\nProof: For each price vector p in the finite set P, define\n\u03a9(p) as the set of all decision vectors [A; \u03bc] that satisfy\n(2), (3), (5), (6), where p(t) is replaced with p in (3) and\n(6). Note that \u03a9(p) is finite for each p \u2208 P. A p-only\npolicy is characterized by a conditional probability distribution\nq(A, \u03bc|p) that satisfies:\nX\nq(A, \u03bc|p) = 1\nfor all p \u2208 P\n(51)\n[A;\u03bc]\u2208\u03a9(p)\n\n0 \u2264 q(A, \u03bc|p) \u2264 1\n\nq(A, \u03bc|p) = 0\n\nfor all A, \u03bc, p\n\n(52)\n\nwhenever [A; \u03bc] \u2208\n/ \u03a9(p) (53)\n\nThen d\u2217n = \u03b1\u2217n \u2212 \u03b2n\u2217 , and so \u03b1\u2217n > \u03b2n\u2217 \u2265 0. Consider now\na new p-only policy \u00c3(t), \u03bc\u0303(t) defined as follows: Define\n\u25b3 \u2217\n\u03bc\u0303(t)=\n\u03bc (t) (so that selling decisions are the same). Define\n\u25b3 \u2217\n\u00c3m (t)=\nAm (t) for all m 6= n. For stock n, choose \u00c3n (t) as\nfollows:\n\u001a \u2217\nAn (t) with probability \u03b2n\u2217 /\u03b1\u2217n\n\u25b3\n\u00c3n (t)=\n0\notherwise\nNote that this new p-only policy satisfies the constraints (2),\n(3), (5), (6), as the original policy satisfies these constraints,\nand we have only changed the A\u2217 (t) decision vector by\nprobabilistically setting the nth entry to zero. Also note that\nthe drift for all stocks m 6= n is unchanged, so that d \u0303m \u2265 0\nfor all m 6= n. Further:\nd \u0303n = \u03b1\u2217n (\u03b2n\u2217 /\u03b1\u2217n ) \u2212 \u03b2n\u2217 = 0\n\nwhere q(A, \u03bc|p) is defined:\n\u25b3\nq(A, \u03bc|p)=\nP r[A(t) = A, \u03bc(t) = \u03bc | p(t) = p]\n\nThe collection of values q(A, \u03bc|p) for p \u2208 P and [A; \u03bc] \u2208\n\u03a9(p) can be viewed as a finite dimensional vector defined over\nthe compact set defined by (51)-(53). Hence, by the BolzanoWierstrass theorem, any infinite sequence of such policies must\nhave a convergent subsequence that converges to a particular\np-only policy that satisfies (51)-(53). In particular, let A(k) (t),\n\u03bc(k) (t) be an infinite sequence of p-only policies defined by\ndistributions q (k) (A, \u03bc|p) that satisfy (51)-(53), and define:\nX\nX\n\u25b3\nq (k) (A, \u03bc|p)[An \u2212 \u03bcn ]\nd(k)\n\u03c0(p)\nn =\np\u2208P\n\n\u25b3\n\u03c6(k) =\n\nX\n\n[A;\u03bc]\u2208\u03a9(p)\n\np\u2208P\n\n\u2212\n\nX\n\n\u03c0(p)\n\nX\n\nq (k) (A, \u03bc|p)\n\np\u2208P\n\nX\n\nq (k) (A, \u03bc|p)\n\n[\u03bcn pn \u2212 sn (\u03bcn )]\n\nN\nX\n\n[An pn + bn (An )]\n\n(k)\n\ndn \u2265 0 for all n \u2208 {1, . . . , N }, k \u2208 {0, 1, . . .}\n\n(54)\n\nlimk\u2192\u221e \u03c6(k) = \u03c6opt\n\n(55)\n\nConsider now any convergent subsequence of distributions\nq (km ) (A, \u03bc|p) that converge to some particular distribution\nq \u2217 (A, \u03bc|p) that satisfies (51)-(53). This defines a single p-only\npolicy. Further, by (54)-(55), this p-only policy must satisfy:\nd\u2217n \u2265 0 for all n \u2208 {1, . . . , N } , \u03c6\u2217 = \u03c6opt\nIt remains only to show that the algorithm can be modified\nto achieve \u03c6opt with d\u2217n = 0 for all n \u2208 {1, . . . , N }. Suppose\nthe current p-only policy has a stock n \u2208 {1, . . . , N } such that\nd\u2217n > 0. We shall create a new p-only policy with d\u2217n = 0,\nwithout reducing profit. Define:\nX\nX\n\u25b3\nq \u2217 (A, \u03bc|p)An\n\u03b1\u2217n =\n\u03c0(p)\n\u25b3\n\n=\n\np\u2208P\n\n[A;\u03bc]\u2208\u03a9(p)\n\nX\n\nX\n\np\u2208P\n\n\u03c0(p)\n\n[A;\u03bc]\u2208\u03a9(p)\n\n\u2217\n\nq (A, \u03bc|p)\u03bcn\n\nt\u22121\n1X\n\u03c6(\u03c4 ) \u2264 \u03c6opt with probability 1\nt \u03c4 =0\n\nand:\n\n(56)\n\nt\u22121\n\n1X\nE {\u03c6(\u03c4 )} \u2264 \u03c6opt\n(57)\nt\u2192\u221e t\n\u03c4 =0\nProof: We prove only (56) (the result (57) follows from\n(56), for example, using the Lebesgue Dominated Convergence\nwith the observation that 0 \u2264 \u03c6(\u03c4 ) \u2264\nPN Theorem\nmax max\np\n\u03bc\n).\nBecause the algorithm can never sell more\nn\nn=1 n\nstock than it has, for a given time t we have:\nlim sup\n\nIt is clear that dn and \u03c6(k) correspond to the virtual drift of\nstock n and the virtual profit under the p-only policy A(k) (t),\n\u03bc(k) (t), as defined by the time average expectations in (11),\n(12). Assume that this infinite sequence of p-only policies\nsatisfies:\n\n\u03b2n\u2217\n\nlim sup\nt\u2192\u221e\n\nn=1\n\n[A;\u03bc]\u2208\u03a9(p)\n(k)\n\nLemma 10: If the price process p(t) satisfies (10), then \u03c6opt\nis an upper bound on the lim sup time average profit of any\npolicy that satisfies (2)-(6). In particular, if A(t) and \u03bc(t)\nare decisions for any policy that satisfies (2)-(6) for all t \u2208\n{0, 1, 2, . . .}, then:\n\nn=1\n\n[A;\u03bc]\u2208\u03a9(p)\n\n\u03c0(p)\n\nN\nX\n\nThus, we have d \u0303m \u2265 0 for all m \u2208 {1, . . . , N }. Finally, it is\neasy to see that this modification has not reduced the profit\nvalue, and hence it must also achieve \u03c6\u0303 = \u03c6opt . If there are any\nremaining stocks m such that d\u2217m > 0, we can repeat the same\nmodification procedure. This proves the existence of a p-only\npolicy that achieves \u03c6opt with d\u2217n = 0 for all n \u2208 {1, . . . , N }.\n\nt\u22121\nX\n\nAn (\u03c4 ) \u2265\n\n\u03c4 =0\n\nt\u22121\nX\n\n\u03bcn (\u03c4 ) for all n \u2208 {1, . . . , N }\n\n(58)\n\n\u03c4 =0\n\nNow for each p \u2208 P, define Tp (t) as the set of slots \u03c4 \u2208\n{0, 1, . . . , t \u2212 1} for which p(\u03c4 ) = p, and define |Tp (t)| as\nthe total number of such slots. Define P(t) as the set of all\nprice vectors p \u2208 P for which |Tp (t)| > 0. We thus have:\nt\u22121\nX\nX |Tp (t)| 1\n1X\n\u03c6(\u03c4 )\n\u03c6(\u03c4 ) =\nt \u03c4 =0\nt |Tp (t)|\n\u03c4 \u2208Tp (t)\n\np\u2208P(t)\n\nHowever, for each p \u2208 P(t) we have:\nX\n1\n|Tp (t)|\n\n1\n|Tp (t)|\n\nX\n\n[A;\u03bc]\u2208\u03a9(p)\n\n\u03c6(\u03c4 ) =\n\n\u03c4 \u2208Tp (t)\n\nN (A, \u03bc, p, t)\u03c6\u0302(A, \u03bc, p)\n\n\f14\n\nwhere N (A, \u03bc, p, t) is defined as the number of times during\nthe interval {0, . . . , t\u22121} that the algorithm selects A(\u03c4 ) = A,\n\u03bc(\u03c4 ) = \u03bc when p(\u03c4 ) = p, and where \u03c6\u0302(A, \u03bc, p) is given by:\n\u25b3\n\u03c6\u0302(A, \u03bc, p)=\n\nN\nX\n\n[\u03bcn pn \u2212 sn (\u03bcn )] \u2212\n\nn=1\n\nN\nX\n\n[An pn + bn (An )]\n\nn=1\n\nThe values N (A, \u03bc, p, t) define a p-only policy, given by\ndistribution:\n(\nN (A,\u03bc,p,t)\nif |Tp (t)| > 0\n(t)\n|Tp (t)|\nq (A, \u03bc|p) =\n0\notherwise\nFurther, this distribution satisfies the constraints (51)-(53)\nrequired for p-only policies. Now let tk be an infinite subsequence over which the lim sup time average profit is achieved,\nso that:\ntk\nt\u22121\n1X\n1 X\nlim sup\n\u03c6(\u03c4 )\n\u03c6(\u03c4 ) = lim\nk\u2192\u221e tk\nt\u2192\u221e t\n\u03c4 =0\n\u03c4 =0\n\nWe thus have:\ntk\n1 X\n\u03c6(\u03c4 ) =\ntk \u03c4 =0\nX |Tp (tk )|\n\nX\n\ntk\n\np\u2208P(tk )\n\nq (tk ) (A, \u03bc|p)\u03c6\u0302(A, \u03bc, p)(59)\n\n[A;\u03bc]\u2208\u03a9(p)\n\nFurther, with this notation, from (58) we have for each n \u2208\n{1, . . . , N }:\n0\u2264\n\ntX\nk \u22121\n\n[An (\u03c4 ) \u2212 \u03bcn (\u03c4 )]\n\n\u03c4 =0\n\n=\n\nX\n\np\u2208P(tk )\n\n|Tp (tk )|\ntk\n\nX\n\nq (tk ) (A, \u03bc|p)[An \u2212 \u03bcn ] (60)\n\n[A;\u03bc]\u2208\u03a9(p)\n\nBecause P is finite and \u03a9(p) is finite for each p \u2208 P, the ponly distributions q (tk ) (A, \u03bc|p) can be viewed as an infinite\nsequence of vectors in a compact set defined by (51)-(53),\nand hence have a convergent subsequence that converges to a\ndistribution q \u2217 (A, \u03bc|p) that is in the set (51)-(53). Note by\n(10) that for each p \u2208 P we have:\n|Tp (t)|\n= \u03c0(p) with probability 1\nt\u2192\u221e\nt\nTaking limits of (59) and (60) thus yields:\nlim\n\nt\u22121\n\n1X\n\u03c6(\u03c4 ) =\nt\u2192\u221e t\n\u03c4 =0\nX\nX\nq \u2217 (A, \u03bc|p)\u03c6\u0302(A, \u03bc, p)\n\u03c0(p)\n\nlim sup\n\np\u2208P\n\n[A;\u03bc]\u2208\u03a9(p)\n\nand for all n \u2208 {1, . . . , N }:\nX\nX\n\u25b3 \u2217\nq \u2217 (A, \u03bc|p)[An \u2212 \u03bcn ]=\ndn\n0\u2264\n\u03c0(p)\np\u2208P\n\n[A;\u03bc]\u2208\u03a9(p)\n\nThis defines a p-only policy that achieves the lim sup time\naverage of \u03c6(t), while yielding d\u2217n \u2265 0 for all n. It follows\nthat the lim sup time average of \u03c6(t) must be less than or equal\nto the value \u03c6opt defined as the largest such value achievable\nover p-only policies that satisfy d\u2217n \u2265 0 for all n.\n\nR EFERENCES\n[1] L. Georgiadis, M. J. Neely, and L. Tassiulas. Resource allocation and\ncross-layer control in wireless networks. Foundations and Trends in\nNetworking, vol. 1, no. 1, pp. 1-149, 2006.\n[2] M. J. Neely. Energy optimal control for time varying wireless networks.\nIEEE Transactions on Information Theory, vol. 52, no. 7, pp. 2915-2934,\nJuly 2006.\n[3] M. J. Neely. Dynamic Power Allocation and Routing for Satellite\nand Wireless Networks with Time Varying Channels. PhD thesis,\nMassachusetts Institute of Technology, LIDS, 2003.\n[4] M. J. Neely and R. Urgaonkar. Cross layer adaptive control for wireless\nmesh networks. Ad Hoc Networks (Elsevier), vol. 5, no. 6, pp. 719-743,\nAugust 2007.\n[5] H. Markowitz. Portfolio selection. Journal of Finance, vol. 7, no. 1,\npp. 77-91, March 1952.\n[6] W. F. Sharpe. A simplified model for portfolio analysis. Management\nScience, vol. 9, no. 2, pp. 277-293, Jan. 1963.\n[7] J-P. Bouchaud and M. Potters. Theory of Financial Risk and Derivative\nPricing: From Statistical Physics to Risk Management, 2nd ed. Cambridge University Press, 2003.\n[8] P. A. Samuelson. Lifetime portfolio selection by dynamic stochastic\nprogramming. The Review of Economics and Statistics, vol. 51, no. 3,\npp. 239-246, Aug. 1969.\n[9] T. M. Cover. An algorithm for maximizing expected log investment\nreturn. IEEE Transactions on Information Theory, IT-30, pp. 369-373,\n1984.\n[10] M. B. Rudoy and C. E. Rohrs. A dynamic programming approach\nto two-stage mean-variance portfolio selection in cointegrated vector\nautoregressive systems. IEEE Conf. on Decision and Control, 2008.\n[11] M. B. Rudoy. Multistage Mean-Variance Portfolio Selection in Cointegrated Vector Autoregressive Systems. PhD thesis, Massachusetts\nInstitute of Technology, Feb. 2009.\n[12] A. Turiel and C. J. P\u00e9rez-Vicente. Multifractal geometry in stock market\ntime series. Physica A: Statistical Mechanics and its Applications, vol.\n322, pp. 629-649, May 2003.\n[13] B. Mandelbrot and H. M. Taylor. On the distribution of stock price\ndifferences. Operations Research, vol. 15, no. 6, pp. 1057-1062, 1967.\n[14] T. M. Cover and D. Gluss. Empirical bayes stock market portfolios.\nAdv. Appl. Math, vol. 7, pp. 170-181, 1986.\n[15] D. C. Larson. Growth Optimal Trading Strategies. PhD thesis, Stanford\nUniversity, 1986.\n[16] T. M. Cover. Universal portfolios. Mathematical Finance, vol. 1, no. 1,\npp. 1-29, Jan. 1991.\n[17] N. Merhav and M. Feder. Universal schemes for sequential decision from\nindividual data sequences. IEEE Transactions on Information Theory,\nvol. 39, no. 4, pp. 1280-1292, July 1993.\n[18] T. M. Cover and E. Ordentlich. Universal portfolios with side information. IEEE Transactions on Information Theory, vol. 42, no. 2, 1996.\n[19] E. Ordentlich and T. M. Cover. The cost of achieving the best portfolio\nin hindsight. Mathematics of Operations Research, vol. 23, no. 4, Nov.\n1998.\n[20] M. J. Neely and R. Urgaonkar. Opportunism, backpressure, and\nstochastic optimization with the wireless broadcast advantage. Asilomar\nConference on Signals, Systems, and Computers, Pacific Grove, CA, Oct.\n2008.\n\n\f"}