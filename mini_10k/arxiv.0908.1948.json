{"id": "http://arxiv.org/abs/0908.1948v2", "guidislink": true, "updated": "2009-08-20T17:51:00Z", "updated_parsed": [2009, 8, 20, 17, 51, 0, 3, 232, 0], "published": "2009-08-13T18:17:38Z", "published_parsed": [2009, 8, 13, 18, 17, 38, 3, 225, 0], "title": "Interference Mitigation Through Limited Receiver Cooperation: Symmetric\n  Case", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0908.1727%2C0908.2643%2C0908.4023%2C0908.3135%2C0908.1984%2C0908.4523%2C0908.1927%2C0908.2924%2C0908.1600%2C0908.3820%2C0908.2925%2C0908.2964%2C0908.2454%2C0908.1277%2C0908.1579%2C0908.1850%2C0908.0411%2C0908.2670%2C0908.2926%2C0908.1227%2C0908.3746%2C0908.4281%2C0908.4268%2C0908.4423%2C0908.3432%2C0908.3858%2C0908.2789%2C0908.1327%2C0908.3098%2C0908.3346%2C0908.4206%2C0908.1966%2C0908.3627%2C0908.0800%2C0908.2753%2C0908.2772%2C0908.1415%2C0908.1124%2C0908.4149%2C0908.2464%2C0908.3299%2C0908.3877%2C0908.1875%2C0908.2190%2C0908.3508%2C0908.2777%2C0908.1607%2C0908.3042%2C0908.4581%2C0908.0549%2C0908.4320%2C0908.2848%2C0908.3476%2C0908.0836%2C0908.1869%2C0908.0886%2C0908.0739%2C0908.0702%2C0908.2617%2C0908.2229%2C0908.3649%2C0908.0330%2C0908.0028%2C0908.3764%2C0908.2509%2C0908.1792%2C0908.0838%2C0908.3498%2C0908.1553%2C0908.1080%2C0908.1082%2C0908.2280%2C0908.1917%2C0908.2659%2C0908.2302%2C0908.0830%2C0908.0928%2C0908.2637%2C0908.2266%2C0908.2855%2C0908.0630%2C0908.4291%2C0908.2761%2C0908.3447%2C0908.3977%2C0908.4122%2C0908.3308%2C0908.1948%2C0908.4047%2C0908.0541%2C0908.0846%2C0908.2992%2C0908.1711%2C0908.0453%2C0908.0243%2C0908.1298%2C0908.0215%2C0908.3010%2C0908.2738%2C0908.4223%2C0908.0963&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Interference Mitigation Through Limited Receiver Cooperation: Symmetric\n  Case"}, "summary": "Interference is a major issue that limits the performance in wireless\nnetworks, and cooperation among receivers can help mitigate interference by\nforming distributed MIMO systems. The rate at which receivers cooperate,\nhowever, is limited in most scenarios. How much interference can one bit of\nreceiver cooperation mitigate? In this paper, we study the two-user Gaussian\ninterference channel with conferencing decoders to answer this question in a\nsimple setting. We characterize the fundamental gain from cooperation: at high\nSNR, when INR is below 50% of SNR in dB scale, one-bit cooperation per\ndirection buys roughly one-bit gain per user until full receiver cooperation\nperformance is reached, while when INR is between 67% and 200% of SNR in dB\nscale, one-bit cooperation per direction buys roughly half-bit gain per user.\nThe conclusion is drawn based on the approximate characterization of the\nsymmetric capacity in the symmetric set-up. We propose strategies achieving the\nsymmetric capacity universally to within 3 bits. The strategy consists of two\nparts: (1) the transmission scheme, where superposition encoding with a simple\npower split is employed, and (2) the cooperative protocol, where\nquantize-binning is used for relaying.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0908.1727%2C0908.2643%2C0908.4023%2C0908.3135%2C0908.1984%2C0908.4523%2C0908.1927%2C0908.2924%2C0908.1600%2C0908.3820%2C0908.2925%2C0908.2964%2C0908.2454%2C0908.1277%2C0908.1579%2C0908.1850%2C0908.0411%2C0908.2670%2C0908.2926%2C0908.1227%2C0908.3746%2C0908.4281%2C0908.4268%2C0908.4423%2C0908.3432%2C0908.3858%2C0908.2789%2C0908.1327%2C0908.3098%2C0908.3346%2C0908.4206%2C0908.1966%2C0908.3627%2C0908.0800%2C0908.2753%2C0908.2772%2C0908.1415%2C0908.1124%2C0908.4149%2C0908.2464%2C0908.3299%2C0908.3877%2C0908.1875%2C0908.2190%2C0908.3508%2C0908.2777%2C0908.1607%2C0908.3042%2C0908.4581%2C0908.0549%2C0908.4320%2C0908.2848%2C0908.3476%2C0908.0836%2C0908.1869%2C0908.0886%2C0908.0739%2C0908.0702%2C0908.2617%2C0908.2229%2C0908.3649%2C0908.0330%2C0908.0028%2C0908.3764%2C0908.2509%2C0908.1792%2C0908.0838%2C0908.3498%2C0908.1553%2C0908.1080%2C0908.1082%2C0908.2280%2C0908.1917%2C0908.2659%2C0908.2302%2C0908.0830%2C0908.0928%2C0908.2637%2C0908.2266%2C0908.2855%2C0908.0630%2C0908.4291%2C0908.2761%2C0908.3447%2C0908.3977%2C0908.4122%2C0908.3308%2C0908.1948%2C0908.4047%2C0908.0541%2C0908.0846%2C0908.2992%2C0908.1711%2C0908.0453%2C0908.0243%2C0908.1298%2C0908.0215%2C0908.3010%2C0908.2738%2C0908.4223%2C0908.0963&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Interference is a major issue that limits the performance in wireless\nnetworks, and cooperation among receivers can help mitigate interference by\nforming distributed MIMO systems. The rate at which receivers cooperate,\nhowever, is limited in most scenarios. How much interference can one bit of\nreceiver cooperation mitigate? In this paper, we study the two-user Gaussian\ninterference channel with conferencing decoders to answer this question in a\nsimple setting. We characterize the fundamental gain from cooperation: at high\nSNR, when INR is below 50% of SNR in dB scale, one-bit cooperation per\ndirection buys roughly one-bit gain per user until full receiver cooperation\nperformance is reached, while when INR is between 67% and 200% of SNR in dB\nscale, one-bit cooperation per direction buys roughly half-bit gain per user.\nThe conclusion is drawn based on the approximate characterization of the\nsymmetric capacity in the symmetric set-up. We propose strategies achieving the\nsymmetric capacity universally to within 3 bits. The strategy consists of two\nparts: (1) the transmission scheme, where superposition encoding with a simple\npower split is employed, and (2) the cooperative protocol, where\nquantize-binning is used for relaying."}, "authors": ["I-Hsiang Wang", "David N. C. Tse"], "author_detail": {"name": "David N. C. Tse"}, "author": "David N. C. Tse", "arxiv_comment": "To appear in IEEE Information Theory Workshop, Taormina, October\n  2009. Final version", "links": [{"href": "http://arxiv.org/abs/0908.1948v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0908.1948v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0908.1948v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0908.1948v2", "journal_reference": null, "doi": null, "fulltext": "Interference Mitigation Through Limited Receiver\nCooperation: Symmetric Case\nI-Hsiang Wang and David N. C. Tse\n\narXiv:0908.1948v2 [cs.IT] 20 Aug 2009\n\nWireless Foundations\nUniversity of California at Berkeley,\nBerkeley, California 94720, USA\n{ihsiang, dtse}@eecs.berkeley.edu\n\nAbstract-Interference is a major issue that limits the performance in wireless networks, and cooperation among receivers\ncan help mitigate interference by forming distributed MIMO\nsystems. The rate at which receivers cooperate, however, is\nlimited in most scenarios. How much interference can one bit of\nreceiver cooperation mitigate? In this paper, we study the twouser Gaussian interference channel with conferencing decoders\nto answer this question in a simple setting. We characterize the\nfundamental gain from cooperation: at high SNR, when INR is\nbelow 50% of SNR in dB scale, one-bit cooperation per direction\nbuys roughly one-bit gain per user until full receiver cooperation\nperformance is reached, while when INR is between 67% and\n200% of SNR in dB scale, one-bit cooperation per direction buys\nroughly half-bit gain per user. The conclusion is drawn based on\nthe approximate characterization of the symmetric capacity in the\nsymmetric set-up. We propose strategies achieving the symmetric\ncapacity universally to within 3 bits. The strategy consists of two\nparts: (1) the transmission scheme, where superposition encoding\nwith a simple power split is employed, and (2) the cooperative\nprotocol, where quantize-binning is used for relaying.\n\nI. I NTRODUCTION\nIn modern communication systems, interference is one of\nthe fundamental factors that limit performance: a receiver\nis only interested in retrieving information from its own\ntransmitter, while the information-carrying signals become interference to other users due to the broadcast and superposition\nnature of wireless channels. The simplest information theoretic\nmodel for studying this issue is the interference channel.\nCharacterizing the capacity region is a long-standing open\nproblem, except for several special cases. Recently Etkin, Tse,\nand Wang characterize the capacity region of the Gaussian\ninterference channel to within one bit [1] by using a superposition coding scheme with a simple power-split configuration\nand by providing new upper bounds.\nIn the above interference channel set-up, transmitters or\nreceivers are not allowed to communicate with one another,\nand hence each user has to combat interference on its own.\nIn various applications, however, nodes are not isolated, and\ntransmitters/receivers can exchange certain amount of information. Since the nodes are distributed due to the physical\nconstraints, the amount of information they can exchange is\nlimited. Therefore, one of the fundamental questions is, how\nThis work was supported by National Science Foundation under grant #\nCCF-0830796.\n\nmuch interference can limited transmitter/receiver cooperation\nmitigate?\nIn this paper, we consider a two-user Gaussian interference channel with conferencing decoders to answer this\nquestion regarding receiver cooperation. Conferencing among\nencoders/decoders has been studied in [2], [3], [4], [5], [6],\nand [7]. Our model is similar to those in [6] and [7] but in\nan interference channel set-up. The work in [6] characterizes\nthe capacity region of the compund MAC with unidirectional\nconferencing between decoders and provides achievable rates\nfor general set-up but is not able to establish a constant-gap result. The work in [7] considers one-sided Gaussian interference\nchannels with unidirectional conferencing between decoders\nand characterizes the capacity region in strong interference\nregimes and the asymptotic sum capacity at high SNR. For\ngeneral receiver cooperation, works including [8] and [9],\ninvestigate cooperation in interference channels with a set-up\nwhere the cooperative links are of the same band as the links\nin the interference channel. In particular, [9] characterizes the\nsum capacity of Gaussian interference channels with in-band\nreceiver cooperation to within 40 bits. Our work, on the other\nhand, is focused on the Gaussian interference channel with\northogonal receiver cooperation.\nWe propose a strategy achieving the symmetric capacity\nuniversally to within 3 bits in the symmetric set-up, regardless\nof channel parameters. The three-bit gap is the worst-case gap\nwhich can be loose in some regimes, and it is vanishingly\nsmall at high SNR when compared to the capacity.The strategy\nconsists of two parts: (1) the transmission scheme, describing\nhow transmitters encode their messages, and (2) the cooperative protocol, describing how receivers exchange information\nand decode messages. For transmission, both transmitters use\nsuperposition coding [10] with a simple power-split configuration, which is the same as that in the case without cooperation\n[1], to encode messages. For the cooperative protocol, it is\nappealing to apply the decode-forward or compress-forward\nschemes, originally proposed in [11] for the relay channel,\nlike most works dealing with more complicated networks,\nincluding [5], [6], [7], [8], [12], etc. It turns out neither\ncompress-forward nor decode-forward achieves capacity to\nwithin a constant number of bits universally for the problem\nat hand. On the other hand, [13], [14], and [15] observe\n\n\fthat the conventional compress-forward scheme [11] may be\nimproved by the destination directly decoding the sender's\nmessage instead of requiring to first decode the quantized\nsignal of the relay. We use such an improved compressforward scheme as our cooperative protocol. Each receiver\nfirst quantizes its received signal at an appropriate distortion,\nbins the quantization codeword and sends the bin index to the\nother receiver. Each receiver then decodes its own information\nbased on its own received signal and the received bin index.\nIt turns out that this simple \"one-round\" cooperative protocol\nis sufficient to achieve within a constant gap to the symmetric\ncapacity in the symmetric case. In the general asymmetric\nchannel, it turns out that this simple protocol is not sufficient\nwhile a more sophisticated \"two-round\" protocol is [16].\nII. P ROBLEM F ORMULATION\nThe Gaussian interference channel with conferencing decoders is depicted in Fig. 1.\nz1\nm1\n\nENC 1\n\nh11\n\nx1\n\n+\n\nDEC 1\n\nh21\nu12\n\nu21\n\nm\n!1\n\nh12\nm2\n\nENC 2\n\nx2\n\nh22\n\n+\n\nDEC 2\n\nz2\n\nFig. 1.\n\nm\n!2\n\nChannel Model\n\nA. Channel Model\n1) Transmitter-Receiver Links: The transmitter-receiver\nlinks are modeled as the normalized Gaussian interference\nchannel:\ny1 = h11 x1 + h12 x2 + z1\ny2 = h21 x1 + h22 x2 + z2 ,\nwhere the additive noise processes {zi [n]}, (i = 1, 2), are\nindependent CN (0, 1), i.i.d. over time. In this paper, we use\n[.] to denote time indices. Transmitter i intends to convey\nmessage mi to receiver i by encoding it into a block codeword\n{xi [n]}N\nn=1 , with transmit power constraints\nN\ni\n1 X h\n2\nE xi [n]\n\u2264 1, i = 1, 2,\nN n=1\n\nfor arbitrary block length N . Note that outcome of the encoder\ndepends solely on its own message. Messages m1 , m2 are\nindependent. Define channel parameters\nSNRi := |hii |2 , INRi := |hij |2 , i, j = 1, 2, i 6= j.\n2) Receiver-Cooperative Links: The receiver-cooperative\nlinks are noiseless with finite capacity CBij from receiver i\nto j. Encoding must satisfy causality constraints: for any\ntime index n = 1, 2, . . . , N , u21 [n] is only a function of\n{y2 [1], . . . , y2 [n \u2212 1], u12 [1], . . . , u12 [n \u2212 1]}, and u12 [n] is\nonly a function of {y1 [1], . . . , y1 [n\u22121], u21 [1], . . . , u21 [n\u22121]}.\n\nIII. ACHIEVABLE S TRATEGY AND S YMMETRIC C APACITY\nTO WITHIN 3 B ITS\nWe focus on the symmetric set-up, namely, SNR = SNR1 =\nSNR2 , INR = INR1 = INR2 , and CB = CB12 = CB21 .\nFor the symmetric set-up, a natural performance measure\nis the symmetric capacity Csym := sup {R : (R, R) \u2208 C },\nwhere C is the capacity region.\nA. Outline of the Strategy\nIn our model, note that arbitrarily large number of rounds1\nare allowed for conferencing among receivers. Remarkably,\nwith the proposed strategy, one-round2 conference is sufficient\nto achieve Csym to within constant number of bits universally.\nThe strategy proposed in this section consists of three basic\ningredients: superposition coding at transmitters, quantizebinning for relaying, and a decoder keeping track of the\ncodebook structure when figuring out quantization codewords.\nDue to space constraint, we give an outline.\nSuperposition coding:\nFor each transmitter, it splits its own message into common and private (sub-)messages. Each common message is\naimed at both receivers, while each private one is aimed at\nits own receiver. Each message is encoded into a Gaussian\nrandom codeword with certain power. As [1] points out, since\nthe private signal is undesired at the unintended receiver, a\nreasonable configuration is to make the private interference at\nor below the noise level so that it does not cause much damage\nand can still convey additional information in the direct link\nif it is stronger than the cross link. When the interference is\nstronger than the desired signal, simply set the whole message\nto be common.\nQuantize-binning:\nUpon receiving its signal from the transmitter-receiver link,\neach receiver does not decode messages immediately. Instead,\neach receiver, serving as a relay, first quantizes its signal by\na pre-generated Gaussian quantization codebook with certain\ndistortion, and then sends out a bin index determined by\na pre-generated binning function. How should we set the\ndistortion? Note that both its own private signal and the noise\nit encounters are not of interest to the other receiver. Therefore,\na natural configuration is to set the distortion level equal to\nthe maximum of noise power and private signal power level.\nDecoding:\nAfter retrieving the receiver-cooperative side information,\nthat is, the bin index, the receiver decodes the two common\nmessages and its own private message, by searching in transmitters' codebooks for a codeword triple (indexed by the two\ncommon messages and the user's own private message) that is\njointly typical with its received signal and some quantization\n1 By multiple rounds we mean that one receiver can decide what to send to\nthe other receiver after it receives the side information from the other, and so\non so forth.\n2 One-round means that each receiver decides on its own what to send to\nthe other receiver.\n\n\fpoint (codeword) in the given bin. If there is no such unique\ncodeword triple, it declares an error.\nB. Comparison with the Conventional Compress-Forward\nNote that the main difference between our cooperative\nprotocol and the conventional compress-forward with Gaussian\nvector quantization lies in the decoding procedure and the chosen distortion. In the conventional Gaussian compress-forward,\nthe decoder first searches in the bin for one quantization\ncodeword that is jointly typical with its received signal from its\nown transmitter only, assuming that the two received signals\nare jointly Gaussian. This may not be true since a single user\nmay not transmit at the capacity in its own link, which results\nin \"holes\" in signal space. As a consequence, this scheme\nmay not utilize the dependency of two received signals well\nand cause larger distortions. Our scheme, on the other hand,\nutilizes the dependency in a better way by jointly deciding the\nquantization codeword and the message triple, consequently\nallows smaller distortions, and is able to reveal the beneficial\nside information to the other receiver.\nWe give an example to illustrate the above observations. In\nthis example channel, set INR to be 2/3 of SNR in dB scale,\nthat is, log INR = 32 log SNR. Besides, set CB = 13 log SNR.\nTo better convey the key ideas, we make use of the linear\ndeterministic channel (LDC) proposed in [15]. The corresponding channel is depicted in Fig. 2. The bits (a1 , a2 , a3 )\nand (b1 , 0, b3 ) can be viewed as the binary expansions of the\ntransmitted signals. Note that in this example, one bit in the\nLDC corresponds to 31 log SNR in the Gaussian channel. As\na baseline, without cooperation the optimal sum rate is 4 bits\nin the LDC. With one-bit cooperation in each direction in the\nLDC, the optimal sum rate is 5 bits. The scheme is depicted\nin Fig. 2.(a).\nReceived\n\nExchanged\n\nReceived\n\nExchanged\n\na1\n\na1\n\na1\n\nb1\n\na2\na3\n\nb1 \u2295 a2\na3\n\nb1\n\nb1\n\nb1\n\nb1\na1\n\nb1\n\nb3 \u2295 a2 b1 \u2295 a2\n\nb3\n\nb3 \u2295 a2\n\na1\n\na1\n\na1\n\na2\na3\n\nb1 \u2295 a2\na3\n\nb1\n\nb1\na1\n\nb3\n\nb1 \u2295 a2\n\nQuantization Distortion\n\n(a) Optimal Scheme\nFig. 2.\n\nNow, suppose compress-forward assuming joint Gaussianity\nof the received signals is used for receivers to cooperate. This\nis a standard approach to evaluate achievable rates of Gaussian channels using compress-forward in the literature. The\nincorrect assumption results in larger quantization distortions,\nas depicted in Fig. 2.(b). The information sent from receiver\n1 to receiver 2, a1 , is redundant, and cannot help mitigate\ninterference a2 . Hence, the achievable sum rate is 4 bits (3\nbits for user 1 and 1 bit for user 2), which is the same as\nthat without cooperation and is one bit less than the optimal\nperformance. Recall that 1 bit in the LDC corresponds to\n1\n3 log SNR in the Gaussian channel, therefore the performance\nloss is unbounded as SNR \u2192 \u221e.\nOur scheme is very similar to extended hash-and-forward\nproposed in [14], in which it is pointed out that the scheme\nhas no advantage over the conventional compress-forward in a\nsingle-source single-relay setting. Due to the above mentioned\nissues, however, we recognize in our problem where the channel consists of two source-destination pairs and two relays, the\nscheme has an unbounded advantage over the conventional\ncompress-forward in certain regimes.\nC. Achievable Symmetric Rate\nDue to space constraint, we give the following coding\ntheorem without proof. Let Ric and Rip denote the rates for\nuser i's common message and private message respectively,\nfor i = 1, 2.\nTheorem 1. The rate tuple (R1c , R2c , R1p , R2p ) satisfying the\nfollowing constraints are achievable:\nConstraints at receiver 1:\n\u0001+\nR1p \u2264 I (x1 ; y1 |x1c , x2c ) + CB21 \u2212 \u03be1\n\u0001+\nR2c + R1p \u2264 I (x2c , x1 ; y1 |x1c ) + CB21 \u2212 \u03be1\n\u0001+\nR1c + R1p \u2264 I (x1 ; y1 |x2c ) + CB21 \u2212 \u03be1\n\u0001+\nR1c + R2c + R1p \u2264 I (x1 , x2c ; y1 ) + CB21 \u2212 \u03be1 ,\nwhere \u03be1 = I (b\ny2 ; y2 |x1c , x1 , x2c , y1 ), and xic is the common\ncodebook generating random variable for i = 1, 2.\nR1p \u2264 I (x1 ; y1 , yb2 |x1c , x2c )\nR2c + R1p \u2264 I (x2c , x1 ; y1 , yb2 |x1c )\nR1c + R1p \u2264 I (x1 ; y1 , yb2 |x2c )\n\n(b) Compress-Forward\nAn Example Channel\n\nR1c + R2c + R1p \u2264 I (x1 , x2c ; y1 , yb2 ) .\nd\n\nFrom its corresponding LDC, one can see that the two\nreceived signals of the Gaussian channel, (y1 , y2 ), are not\njointly Gaussian. The reason is that, suppose they are jointly\nGaussian, the conditional distribution of y2 given y1 should be\nmarginally Gaussian. As Fig. 2 suggests, however, conditioning on receiver 1's signal results in a hole at the second level\nof receiver 2's signal, which was occupied by a1 . Therefore,\ntransmitter 2's common codebook is not dense enough to\nmake the conditional distribution of y2 given y1 marginally\nGaussian.\n\nwhere yb2 = y2 + zb2 is the quantization codebook generating random variable, and zb2 \u223c CN (0.\u22062 ), independent of\neverything else. \u22062 is the quantization distortion at receiver\n2.\nConstraints at receiver 2: the above constraints with index\n\"1\" and \"2\" exchanged.\nIn the rest of this paper, we focus on the symmetric setup. Besides, for simplicity we assume the typical case where\nSNR > 1 and INR > 1. We defer the full treatment of general\nasymmetric set-up in a subsequent paper [16].\n\n\fLemma 1 (Achievable Symmetric Rate). When SNR \u2264 INR,\n\uf8f1\n\uf8fc\nB\n\u22121)+ ,log(1+SNR+INR)\u22121,\n\uf8f2log(1+SNR)+(C\n\uf8fd\n\u0002\n\u0003\nRsym = min 12 \u0002 log(1+SNR+INR)+(CB \u22121)+ ,\n\uf8f3 1 log 1+2SNR+2INR+|h h \u2212h h |2 \u22121\u0003\uf8fe\n(\n11 22\n12 21 )\n2\nis achievable. When SNR > INR,\nRsym =\n\uf8f1\n\uf8fc\n+\nB\n\uf8f2log\u0002 (1+ SNR\nINR +INR)+(C \u2212log 3) \u22121,log(1+SNR)\u22122, \u0003 \uf8fd\n+\nB\nmin 12 \u0002 log(1+SNR+INR)+log(2+ SNR\nINR )+(C \u2212log 3) \u22122 ,\n\u0003\n\uf8f31\n\uf8fe\n2\n2 log(1+2SNR+2INR+|h11 h22 \u2212h12 h21 | )\u22123\nis achievable.\nNext, we have outer bounds for symmetric capacity:\nLemma 2 (Outer Bounds for Symmetric Capacity). Csym \u2264\nC sym with\n\uf8f1\n\uf8fc\nINR\nlog(1+SNR)+min{CB ,log(1+ 1+SNR\n)},\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8fd\nSNR\nlog(1+INR+ 1+INR\n)+CB ,\nC sym = min 1 log(1+SNR+INR)+ 1 log 1+ SNR + 1 CB , .\n( 1+INR ) 2 \uf8f4\n\uf8f4\n2\n\uf8f3 12\n\uf8fe\n2\n2 log(1+2SNR+2INR+|h11 h22 \u2212h12 h21 | )\n\nTheorem 3 (Number of Generalized Degrees of Freedom\nPer User). We have a direct consequence from Lemma 2 and\nTheorem 2:\n\b\n\u001a\n, 0\u2264\u03b1<1\nmin \b1, max (\u03b1, 1 \u2212 \u03b1) + \u03ba, 1 \u2212 \u03b1\u2212\u03ba\n2\nd=\nmin \u03b1, 1 + \u03ba, \u03b1+\u03ba\n,\n\u03b1\u22651\n2\nNumerical plots for g.d.o.f. are given in Fig. 3. We observe\nthat at different values of \u03b1, the gain from cooperation\nvaries. By investigating the g.d.o.f., we conclude that at high\nSNR, when INR is below 50% of SNR in dB scale, one-bit\ncooperation per direction buys roughly one-bit gain per user\nuntil full receiver cooperation performance is reached, while\nwhen INR is between 67% and 200% of SNR in dB scale,\none-bit cooperation per direction buys roughly half-bit gain\nper user until saturation.\nd (\u03b1, \u03ba)\n2\n\n1.5\n\n1\n\nWith Lemma 1 and 2, we establish the following theorem:\n\n0.5\n\nTheorem 2 (Constant Gap to Symmetric Capacity). The\nstrategy can achieve the symmtric capacity to within 3 bits;\nnamely,\n\n0\n0\n\nFig. 3.\n\nRsym \u2264 Csym \u2264 C sym \u2264 Rsym + 3\nIV. G ENERALIZED D EGREES OF F REEDOM\nGeneralized degrees of freedom (g.d.o.f.) characterization,\noriginally proposed in [1], is an asymptotic capacity characterization in high SNR regime. For our problem, it is\nappealing to define a similar notion for characterizing the\nhigh-SNR asymptotic performance, in the following way: let\nlog INR\nCB\nlimSNR\u2192\u221e log\nSNR = \u03b1, limSNR\u2192\u221e log SNR = \u03ba, and define\nthe number of generalized degrees of freedom per user as\nd (\u03b1, \u03ba) :=\n\nlim\n\nfix \u03b1,\u03ba\nSNR\u2192\u221e\n\nCsym\n,\nlog SNR\n\n(IV-\u2217)\n\nif the limit exists. With fixed \u03b1 and \u03ba, however, there are\ncertain channel realizations under which (IV-\u2217) has different\nvalues and hence the limit does not exist. This happens when\n\u03b1 = 1, where the phases of the channel gains matter both in\ninner and outer bounds. In particular, its value can depend on\nwhether the system MIMO matrix is well-conditioned or not.\nInstead of claiming that the limit (IV-\u2217) exists for all channel realizations, we pose a reasonable distribution, namely,\ni.i.d. uniform distribution, on the phases, show that the limit\nexists almost surely, and define the limit to be the number of\ngeneralized degrees of freedom per user. Details are omitted\nhere due to space constraint. In particular, (IV-\u2217) is the same\nas the symmetric capacity normalized by the interference-free\ncapacity per user in the corresponding linear deterministic\nchannel (LDC) except for \u03b1 = 1.\nNow that the number of g.d.o.f. is well-defined, we can give\nthe following theorem:\n\n\u03ba = 1/2\n\u03ba = 1/3\n\u03ba = 1/6\n\u03ba=0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\n\n\u03b1\n\nGeneralized Degrees of Freedom\n\nThe fundamental behavior of the gain from receiver cooperation is explained in the rest of this section, by looking at\ntwo particular points: \u03b1 = 12 and \u03b1 = 23 . Furthermore, we use\nthe linear deterministic channel (LDC) for illustration.\nd (\u03b1, \u03ba)\n1.1\n\n\u03b1=\n\n1\n2\n\n1\n0.9\n\n3\n4\n\nSlope = 1\n\na2\na3\na4\n\na2\na3\na4 \u2295b2\n\nb2\nb3\nb4\n\nb2\nb3\nb4 \u2295a2\n\n0.8\n0.7\n0.6\n0.5\n0\n\n0.2 1\n\n0.4\n\n0.6\n\n0.8\n\n1\n\n4\n\n\u03ba\n\n(a)\nd (\u03b1, \u03ba)\n1.1\n\n\u03b1=\n\n1\n\n(b)\n2\n3\n\n0.9\n\n5\n6 0.8\n\nSlope = 1/2\n\n2 0.7\n3\n0.6\n0.5\n0\n\n0.2\n\n1 0.4\n3\n\n0.6\n\n0.8\n\n1\n\n\u03ba\n\na1\na2\na3\n\na1\na2 \u2295 b1\na3\n\nb1\n\nb1\na1\nb3 \u2295 a2\n\nb3\n\n(c)\n\n(d)\nFig. 4.\n\nGain from Cooperation\n\nAt \u03b1 = 21 , the plot of d versus \u03ba is given in Fig. 4.(a).\nThe slope is 1 until full receiver cooperation performance is\n\n\freached, implying that one-bit cooperation buys one more bit\nper user. We look at a particular point \u03ba = 41 and use its\ncorresponding LDC (Fig. 4.(b)) to provide insights. Note that\n1 bit in the LDC corresponds to 14 log SNR in the Gaussian\nchannel, and since CB \u2248 14 log SNR, in the corresponding LDC\neach receiver is able to sent one-bit information to the other.\nWithout cooperation, the optimal way is to turn on bits not\ncausing interference, that is, the private bits a3 , a4 , b3 , b4 . We\ncannot turn on more bits without cooperation since it causes\ncollisions, for example, at the fourth level of receiver 2 if we\nturn on a2 bit. Now with receiver cooperation, we want to\nsupport two more bits a2 , b2 . Note that prior to turning on\na2 , b2 , there are \"holes\" left in receiver signal spaces, and\nturning on each of these bits only causes one collision at\none receiver. Therefore, we need 1 bit in each direction to\nresolve the collision at each receiver. We can achieve 3 bits\nper user in the corresponding LDC and d = 34 in the Gaussian\nchannel. We cannot turn on more bits in the LDC since it\ncauses collisions while no cooperation capability is left.\nAt \u03b1 = 23 , the plot of d versus \u03ba is given in Fig. 4.(c).\nThe slope is 12 until full receiver cooperation performance\nis reached, implying that two-bit cooperation buys one more\nbit per user. We look at a particular point \u03ba = 31 and\nuse its corresponding LDC (Fig. 4.(d)) to provide insights.\nNote that now 1 bit in the LDC corresponds to 13 log SNR\nin the Gaussian channel, and since CB \u2248 13 log SNR, in\nthe corresponding LDC each receiver is able to sent one-bit\ninformation to the other. Without cooperation, the optimal way\nis to turn on bits a1 , a3 , b1 , b3 . We cannot turn on more bits\nwithout cooperation since it causes collisions, for example,\nat the second level of receiver 2 if we turn on a2 bit. Now\nwith receiver cooperation, we want to support one more bit\na2 . Note that prior to turning on a2 , there are no \"holes\" left\nin receiver signal spaces, and turning on a2 causes collisions\nat both receivers. Therefore, we need 2 bits in total to resolve\ncollisions at both receivers. We can achieve 5 bits in total in the\ncorresponding LDC and d = 56 in the Gaussian channel. We\ncannot turn on more bits in the LDC since it causes collision\nwhile no cooperation capability is left.\nFrom above examples and illustrations, we see that whether\none cooperation bit buys one more bit or two cooperation\nbits buy one more bit depends on whether there are \"holes\" in\nreceiver signal spaces before increasing data rates. The \"holes\"\nplay a central role not only in why the conventional compressforward is suboptimal in certain regimes, as mentioned in the\nprevious section, but also in the fundamental behavior of the\ngain from receiver cooperation. We notice that in [9], there is a\nsimilar behavior about the gain from cooperation as discussed\nin Section 3.2. of [9]. We conjecture that the behavior can be\nexplained via the concept of \"holes\" as well.\nV. G ENERAL A SYMMETRIC C ASE : A N E XAMPLE\nIn this paper, we propose a one-round scheme achieving the\nsymmetric capacity to within 3 bits. The proposed one-round\nscheme, however, is not sufficient to achieve the capacity\nregion to within a constant number of bits in general. As an\n\nexample, consider the LDC in Fig. 5. If receiver 2 quantizes at\nit private signal level, it can only forward a1 to receiver 1 and\nachieves R1 up to 2 bits. On the other hand, if receiver 2 first\ndecodes b2 , a3 and then forwards a3 to receiver 1, it achieves\nR1 = 3 bits. In [16], this problem with general asymmetric\nset-up is investigated. We implement a two-round strategy and\nshow that it can achieve the capacity region universally to\nwithin 2 bits per user.\nReceived\n\na1\n\nExchanged\n\nExchanged\n\na1\na2\na3\n\na1\n\na2\n\na2\n\na3\n\na1\n\na3\n\nb2\n\nb2 \u2295 a2\na3\n\na2\na1\n\na2\na3\n\na1\n\na2\n\na2\n\na1\n\na1\n\na1\n\nb2\n\nb2 \u2295 a2\na3\n\na2\na1\n\n(a) Suboptimal One-round Scheme\nFig. 5.\n\nReceived\n\na1\n\na1\n\n(b) Optimal Two-round Scheme\n\nA Motivating Example for the Two-Round Scheme\n\nR EFERENCES\n[1] R. Etkin, D. N. C. Tse, and H. Wang, \"Gaussian interference channel\ncapacity to within one bit,\" IEEE Transactions on Information Theory,\nvol. 54, pp. 5534\u20135562, December 2008.\n[2] F. M. J. Willems, \"The discrete memoryless mulitple access channel\nwith partially cooperating encoders,\" IEEE Transactions on Information\nTheory, vol. 29, pp. 441\u2013445, May 1983.\n[3] S. I. Bross, A. Lapidoth, and M. A. Wigger, \"The gaussian mac with\nconferencing encoders,\" Proceedings of IEEE International Symposium\non Information Theory, July 2008.\n[4] I. Mari\u0107, R. D. Yates, and G. Kramer, \"Capacity of interference channels\nwith partial transmitter cooperation,\" IEEE Transactions on Information\nTheory, vol. 53, pp. 3536\u20133548, October 2007.\n[5] R. Dabora and S. D. Servetto, \"Broadcast channels with cooperating\ndecoders,\" IEEE Transactions on Information Theory, vol. 52, pp. 5438\u2013\n5454, December 2006.\n[6] O. Simeone, D. G\u00fcnd\u00fcz, H. V. Poor, A. J. Goldsmith, and S. Shamai,\n\"Compound multiple access channels with partial cooperation,\" IEEE\nTransactions on Information Theory, vol. 55, pp. 2425\u20132441, June 2009.\n[7] W. Yu and L. Zhou, \"Gaussian z-interference channel with a relay\nlink: Achievability region and asymptotic sum capacity,\" Submitted\nto IEEE Transactions on Information Theory, September 2008, http:\n//www.comm.utoronto.ca/\u223cweiyu/z relay.pdf.\n[8] A. H\u00f8st-Madsen, \"Capacity bounds for cooperative diversity,\" IEEE\nTransactions on Information Theory, vol. 52, pp. 1522\u20131544, April 2006.\n[9] V. Prabhakaran and P. Viswanath, \"Interference channels with destination cooperation,\" Submitted to IEEE Transactions on Information\nTheory, July 2009. http://arxiv.org/abs/0907.2702.\n[10] T. S. Han and K. Kobayashi, \"A new achievable rate region for\nthe interference channel,\" IEEE Transactions on Information Theory,\nvol. 27, pp. 49\u201360, January 1981.\n[11] T. M. Cover and A. A. El Gamal, \"Capacity theorems for the relay\nchannel,\" IEEE Transactions on Information Theory, vol. 25, pp. 572\u2013\n584, September 1979.\n[12] G. Kramer, M. Gastpar, and P. Gupta, \"Cooperative strategies and capacity theorems for relay networks,\" IEEE Transactions on Information\nTheory, vol. 51, pp. 3037\u20133063, September 2005.\n[13] T. M. Cover and Y.-H. Kim, \"Capacity of a class of deterministic\nrelay channels,\" Proceedings of IEEE International Symposium on\nInformation Theory, June 2007.\n[14] Y.-H. Kim, \"Coding techniques for primitive relay channels,\" Proceedings of Allerton Conference on Communication, Control, and Computing, September 2007.\n[15] A. S. Avestimehr, S. N. Diggavi, and D. N. C. Tse, \"Wireless network information flow: A deterministic approach,\" Submitted to IEEE Transactions on Information Theory, June. http://arxiv.org/abs/0906.5394 2009.\n\n\f[16] I.-H. Wang and D. N. C. Tse, \"Interference mitigation through limited\nreceiver cooperation,\" Preprint, 2009.\n\n\f"}