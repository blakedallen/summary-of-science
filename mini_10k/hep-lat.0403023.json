{"id": "http://arxiv.org/abs/hep-lat/0403023v2", "guidislink": true, "updated": "2005-01-14T19:11:38Z", "updated_parsed": [2005, 1, 14, 19, 11, 38, 4, 14, 0], "published": "2004-03-22T23:06:36Z", "published_parsed": [2004, 3, 22, 23, 6, 36, 0, 82, 0], "title": "What can Lattice QCD theorists learn from NMR spectroscopists?", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=hep-lat%2F0409154%2Chep-lat%2F0409093%2Chep-lat%2F0409020%2Chep-lat%2F0409122%2Chep-lat%2F0409114%2Chep-lat%2F0409161%2Chep-lat%2F0409166%2Chep-lat%2F0409108%2Chep-lat%2F0409014%2Chep-lat%2F0409163%2Chep-lat%2F0409160%2Chep-lat%2F0409049%2Chep-lat%2F0409101%2Chep-lat%2F0409157%2Chep-lat%2F0409164%2Chep-lat%2F0409150%2Chep-lat%2F0409158%2Chep-lat%2F0409133%2Chep-lat%2F0409124%2Chep-lat%2F0409053%2Chep-lat%2F0409051%2Chep-lat%2F0409006%2Chep-lat%2F0409145%2Chep-lat%2F0409151%2Chep-lat%2F0409031%2Chep-lat%2F0409009%2Chep-lat%2F0409077%2Chep-lat%2F0409056%2Chep-lat%2F0409005%2Chep-lat%2F0409127%2Chep-lat%2F0409044%2Chep-lat%2F0409137%2Chep-lat%2F0409119%2Chep-lat%2F0409015%2Chep-lat%2F0409002%2Chep-lat%2F0409096%2Chep-lat%2F0409059%2Chep-lat%2F0409121%2Chep-lat%2F0403030%2Chep-lat%2F0403029%2Chep-lat%2F0403013%2Chep-lat%2F0403018%2Chep-lat%2F0403001%2Chep-lat%2F0403014%2Chep-lat%2F0403016%2Chep-lat%2F0403025%2Chep-lat%2F0403027%2Chep-lat%2F0403022%2Chep-lat%2F0403007%2Chep-lat%2F0403005%2Chep-lat%2F0403009%2Chep-lat%2F0403004%2Chep-lat%2F0403023%2Chep-lat%2F0403019%2Chep-lat%2F0403024%2Chep-lat%2F0403026%2Chep-lat%2F0403020%2Chep-lat%2F0403006%2Chep-lat%2F0403011%2Chep-lat%2F0403012%2Chep-lat%2F0403008%2Chep-lat%2F0403003%2Chep-lat%2F0403015%2Chep-lat%2F0403021%2Chep-lat%2F0403002%2Chep-lat%2F0403017%2Chep-lat%2F0403028%2Chep-lat%2F0403010%2Chep-lat%2F0506015%2Chep-lat%2F0506017%2Chep-lat%2F0506003%2Chep-lat%2F0506030%2Chep-lat%2F0506029%2Chep-lat%2F0506007%2Chep-lat%2F0506035%2Chep-lat%2F0506020%2Chep-lat%2F0506006%2Chep-lat%2F0506018%2Chep-lat%2F0506022%2Chep-lat%2F0506011%2Chep-lat%2F0506023%2Chep-lat%2F0506004%2Chep-lat%2F0506026%2Chep-lat%2F0506019%2Chep-lat%2F0506028%2Chep-lat%2F0506013%2Chep-lat%2F0506001%2Chep-lat%2F0506027%2Chep-lat%2F0506032%2Chep-lat%2F0506016%2Chep-lat%2F0506014%2Chep-lat%2F0506008%2Chep-lat%2F0506005%2Chep-lat%2F0506031%2Chep-lat%2F0506034%2Chep-lat%2F0506002%2Chep-lat%2F0506010%2Chep-lat%2F0506012%2Chep-lat%2F0506036%2Chep-lat%2F0506025%2Chep-lat%2F0506024&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "What can Lattice QCD theorists learn from NMR spectroscopists?"}, "summary": "Euclidean-time hadron correlation functions computed in Lattice QCD (LQCD)\nare modeled by a sum of decaying exponentials, reminiscent of the exponentially\ndamped sinusoid models of free induction decay (FID) in Nuclear Magnetic\nResonance (NMR) spectroscopy. We present our initial progress in studying how\ndata modeling techniques commonly used in NMR perform when applied to LQCD\ndata.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=hep-lat%2F0409154%2Chep-lat%2F0409093%2Chep-lat%2F0409020%2Chep-lat%2F0409122%2Chep-lat%2F0409114%2Chep-lat%2F0409161%2Chep-lat%2F0409166%2Chep-lat%2F0409108%2Chep-lat%2F0409014%2Chep-lat%2F0409163%2Chep-lat%2F0409160%2Chep-lat%2F0409049%2Chep-lat%2F0409101%2Chep-lat%2F0409157%2Chep-lat%2F0409164%2Chep-lat%2F0409150%2Chep-lat%2F0409158%2Chep-lat%2F0409133%2Chep-lat%2F0409124%2Chep-lat%2F0409053%2Chep-lat%2F0409051%2Chep-lat%2F0409006%2Chep-lat%2F0409145%2Chep-lat%2F0409151%2Chep-lat%2F0409031%2Chep-lat%2F0409009%2Chep-lat%2F0409077%2Chep-lat%2F0409056%2Chep-lat%2F0409005%2Chep-lat%2F0409127%2Chep-lat%2F0409044%2Chep-lat%2F0409137%2Chep-lat%2F0409119%2Chep-lat%2F0409015%2Chep-lat%2F0409002%2Chep-lat%2F0409096%2Chep-lat%2F0409059%2Chep-lat%2F0409121%2Chep-lat%2F0403030%2Chep-lat%2F0403029%2Chep-lat%2F0403013%2Chep-lat%2F0403018%2Chep-lat%2F0403001%2Chep-lat%2F0403014%2Chep-lat%2F0403016%2Chep-lat%2F0403025%2Chep-lat%2F0403027%2Chep-lat%2F0403022%2Chep-lat%2F0403007%2Chep-lat%2F0403005%2Chep-lat%2F0403009%2Chep-lat%2F0403004%2Chep-lat%2F0403023%2Chep-lat%2F0403019%2Chep-lat%2F0403024%2Chep-lat%2F0403026%2Chep-lat%2F0403020%2Chep-lat%2F0403006%2Chep-lat%2F0403011%2Chep-lat%2F0403012%2Chep-lat%2F0403008%2Chep-lat%2F0403003%2Chep-lat%2F0403015%2Chep-lat%2F0403021%2Chep-lat%2F0403002%2Chep-lat%2F0403017%2Chep-lat%2F0403028%2Chep-lat%2F0403010%2Chep-lat%2F0506015%2Chep-lat%2F0506017%2Chep-lat%2F0506003%2Chep-lat%2F0506030%2Chep-lat%2F0506029%2Chep-lat%2F0506007%2Chep-lat%2F0506035%2Chep-lat%2F0506020%2Chep-lat%2F0506006%2Chep-lat%2F0506018%2Chep-lat%2F0506022%2Chep-lat%2F0506011%2Chep-lat%2F0506023%2Chep-lat%2F0506004%2Chep-lat%2F0506026%2Chep-lat%2F0506019%2Chep-lat%2F0506028%2Chep-lat%2F0506013%2Chep-lat%2F0506001%2Chep-lat%2F0506027%2Chep-lat%2F0506032%2Chep-lat%2F0506016%2Chep-lat%2F0506014%2Chep-lat%2F0506008%2Chep-lat%2F0506005%2Chep-lat%2F0506031%2Chep-lat%2F0506034%2Chep-lat%2F0506002%2Chep-lat%2F0506010%2Chep-lat%2F0506012%2Chep-lat%2F0506036%2Chep-lat%2F0506025%2Chep-lat%2F0506024&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Euclidean-time hadron correlation functions computed in Lattice QCD (LQCD)\nare modeled by a sum of decaying exponentials, reminiscent of the exponentially\ndamped sinusoid models of free induction decay (FID) in Nuclear Magnetic\nResonance (NMR) spectroscopy. We present our initial progress in studying how\ndata modeling techniques commonly used in NMR perform when applied to LQCD\ndata."}, "authors": ["George T. Fleming"], "author_detail": {"name": "George T. Fleming"}, "author": "George T. Fleming", "arxiv_comment": "11 pages, svmult.cls. Minor changes in response to reviewers'\n  comments. To appear in the Proceedings of the Third International Workshop on\n  Numerical Analysis and Lattice QCD, Edinburgh, Scotland, 30 Jun - 04 Jul 2003", "links": [{"href": "http://arxiv.org/abs/hep-lat/0403023v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/hep-lat/0403023v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "hep-lat", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "hep-lat", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/hep-lat/0403023v2", "affiliation": "Jefferson Lab", "arxiv_url": "http://arxiv.org/abs/hep-lat/0403023v2", "journal_reference": null, "doi": null, "fulltext": "What can Lattice QCD theorists learn from\nNMR spectroscopists?\n\narXiv:hep-lat/0403023v2 14 Jan 2005\n\nGeorge T. Fleming1\nJefferson Lab, 12000 Jefferson Ave, Newport News VA 23606, USA\nflemingg@jlab.org\n\n1 Lattice QCD and NMR Spectroscopy\nThe Lattice QCD (LQCD) community has occasionally gone through periods of self-examination of its data analysis methods and compared them with\nmethods used in other disciplines [Tou90, Mic94, MM95]. This process has\nshown that the techniques widely used elsewhere may also be useful in analyzing LQCD data. It seems that we are in such a period now with many\ngroups trying what are generally called Bayesian methods such as Maximal\nEntropy (MEM) or constrained fitting [NAH99, L+ 02, ABC02, Fie02, D+ 03,\nand many others]. In these proceedings we will attempt to apply this process\nto a comparison of data modeling techniques used in LQCD and NMR Spectroscopy to see if there are methods which may also be useful when applied\nto LQCD data.\nA common problem in Lattice QCD is the estimation of hadronic energies\nEk (p) of k = 1 * * * K states from samples of the hadronic correlation function\nof a specified set of quantum numbers computed in a Monte Carlo simulation.\nA typical model function is\nC(p, tn ) =\n\nK\nX\n\nAk (p) exp [\u2212(t0 + na)Ek (p)]\n\n(1)\n\nk=1\n\nAk , Ek \u2208 R,\n\n0 \u2264 E1 \u2264 * * * \u2264 Ek \u2264 Ek+1 \u2264 * * * \u2264 EK\n\nwhere one of the quantum numbers, the spatial momentum p, is shown explicitly for illustration. The correlation function is estimated at each time tn ,\nn = 0 * * * N \u2212 1 with the N chosen such that (E2 \u2212 E1 )tN \u22121 \u226b 1. This enables\nthe ground state energy E1 to be easily determined from the large time behavior. To accurately estimate the k-th energy level requires choosing a sampling\ninterval a\u22121 \u226b Ek \u2212 E1 . Unfortunately, computational constraints typically\nforce us to choose time intervals larger (a\u22121 \u223c 2 GeV) and number of time\nsamples smaller (N \u223c 32) than is ideally preferred.\n\n\f2\n\nGeorge T. Fleming\n\nIn an idealized nuclear magnetic resonance (NMR) spectroscopy1 experiment, a sample is placed in an external magnetic field and a transient field\nfrom an RF coil is used to temporarily drive the various nuclei into a nonequilibrium distribution of magnetic spin states. Then, as the sample relaxes\nback to its equilibrium distribution, each type of excited nuclei radiates at\na characteristic frequency fk . The sum of all these microscopic signals are\npicked up by another RF coil, giving rise to the free induction decay (FID)\nsignal\nK\nX\n(2)\nyn =\nak ei\u03c6k e(\u2212dk +i2\u03c0fk )tn + en , n \u2208 [0, N \u2212 1]\nk=1\n\nak , \u03c6k , dk , fk \u2208 R;\n\ndk \u2265 0;\n\nnoise : en \u2208 C.\n\nAs the frequencies are known a priori, an experienced operator can incorporate this prior knowledge by Fourier transforming the data and matching\nLorentzian peaks against existing databases. Bayesian methods are then used\nto constrain the frequencies, enabling the estimation of the other parameters.\nOf particular interest are the amplitudes ak , which are related to the number\nof various nuclei in the sample, and the damping rates dk , which are related\nto the mobility and molecular environment of the nuclei.\nBoth Eqs. (1) and (2) can be written in the form\nyn =\n\nK\nX\n\nak \u03b1nk\n\n(3)\n\nk=1\n\nor in matrix notation y = \u03a6(\u03b1) a. In numerical analysis, this is known as\na Vandermonde system and \u03a6 is a Vandermonde matrix. Note also that all\nthe parameters \u03b1 which enter non-linearly in the model only appear in the\nVandermonde matrix and the remaining linear parameters in a. This suggests\nb were known\nthat if the best fit values of only the non-linear parameters, \u03b1,\na priori then the remaining best fit values of the linear parameters, b\na could\nbe determined using a linear least squares algorithm. Hence, linear and nonlinear parameters need not be determined simultaneously and in Sec. 2 we\nwill discuss the best known algorithm that exploits this feature.\nWe have found that all of the model functions we use to fit hadronic correlations in LQCD can be written in the Vandermonde form. For a less trivial\nexample, here is the model function for mesonic correlations with periodic\n(or anti-periodic) temporal boundary conditions and either Wilson (\u03c3=1) or\nstaggered (\u03c3=-1) fermions\nC(\u03c4n ) =\n\nK\nX\n\nk=1\n1\n\n\u03c3 kn Ak e\u2212aN Ek /2 cosh(anEk ),\n\n0 \u2264 Ek \u2264 Ek+2 .\n\n(4)\n\nIn medical applications, MRS is a preferred abbreviation, probably to avoid the\nperceived public aversion to anything nuclear.\n\n\fWhat can Lattice QCD theorists learn from NMR spectroscopists?\n\n3\n\nIn this case, if we choose \u03b1k = \u03c3 k cosh(aEk ) to be the parameters of the\nVandermonde matrix \u03a6 then we can construct the data vector y from the\ncorrelation data\n\u0013\nn\u22121 \u0012\n1 X n\u22121\nC(\u03c4n\u22122j\u22121 ).\n(5)\nyn = n\u22121\n2\nj\nj=0\n\n\u0001\nwhere nj are binomial coefficients.\nIn NMR spectroscopy and in LQCD, fitting data often requires an experienced user to interact with the fitting program, i.e. to provide initial guesses to\nthe minimizer or to choose what prior knowledge may be used to constrain the\nminimization, and this can often be a time-consuming process if the data are\nof marginal quality. In LQCD fitting programs, the effective mass technique\nis often used to provide non-interactive initial guesses to the minimizer. In\nNMR spectroscopy, more general analogues, called black box methods, have\nbeen developed for situations where an expert user is unavailable or the rate\nof data acquisition precludes interaction. In Sec. 3, we will look at the generalization of the effective mass technique, which will lead to a Hankel system\nthat must be solved.\n\n2 VARPRO: Variable Projection algorithm\nIn Sec. 1, we considered data whose model may be written as y = \u03a6a, as\nin Eq. (3), with the data vector y \u2208 RN and the linear parameter vector\na \u2208 RK and N > 2K is necessary for the problem to be over-determined.\nThe non-linear parameter vector \u03b1 is used to determine the components of\nthe non-linear parameter matrix \u03a6 \u2208 RN \u00d7K of the general form\n\uf8eb\n\uf8f6\n\u03c61 (t1 , \u03b1) * * * \u03c6K (t1 , \u03b1)\n\uf8ec\n\uf8f7\n..\n..\n..\n\u03a6=\uf8ed\n(6)\n\uf8f8.\n.\n.\n.\n\u03c61 (tN , \u03b1) * * * \u03c6K (tN , \u03b1)\n\nNon-linear least squares problems of this type form a special class known as\nseparable non-linear least squares and have been well studied in the numerical\nanalysis community for the past thirty years.\nTo see how this special structure can be exploited, recall the least squares\nfunctional to be minimized is\n2\n\nr12 (\u03b1, a) = |y \u2212 \u03a6(\u03b1)a| .\n\n(7)\n\nNow, suppose we were given a priori the value of the non-linear parameters\n\u03b1 at the minimum of Eq. (7) which we denote \u03b1\u0302. We can easily determine a\nposteriori the linear parameters \u00e2 by solving the corresponding linear least\nsquares problem. The solution is simply\n\n\f4\n\nGeorge T. Fleming\n\n\u00e2 = \u03a6+ (\u03b1\u0302)y\n\n(8)\n\nwhere \u03a6+ (\u03b1\u0302) is the Moore\u2013Penrose pseudo-inverse of \u03a6(\u03b1\u0302) [Wei04]. Substituting Eq. (8) back into Eq. (7) we get a new least squares functional that\ndepends only on \u03b1\n2\n\nr22 (\u03b1) = y \u2212 \u03a6(\u03b1)\u03a6+ (\u03b1)y .\n\n(9)\n\nP(\u03b1) \u2261 \u03a6(\u03b1)\u03a6+ (\u03b1) is the orthogonal projector onto the linear space spanned\nby the column vectors of \u03a6(\u03b1), so P\u22a5 (\u03b1) \u2261 1\u2212P(\u03b1) is the projector onto the\northogonal complement of the column space of \u03a6(\u03b1). Hence, we can rewrite\nEq. (9) more compactly as\n2\n\nr22 (\u03b1) = P\u22a5 (\u03b1)y .\n\n(10)\n\nThis form makes it easier to see why r22 (\u03b1) is commonly called the variable\nprojection (VARPRO) functional. It has been shown [GP73] that the minima\nof r2 (\u03b1) and the corresponding values of a from Eq. (8) are equivalent to the\nminima of r12 (\u03b1, a).\nOne complication of the VARPRO method is computing the gradient\n\u2202r2 /\u2202\u03b1 when the gradients \u2202\u03c6k (tn , \u03b1)/\u2202\u03b1 are known. The solution is presented in some detail in [GP73] and an excellent FORTRAN implementation\n[Bol77] is available in the Netlib Repository.\nFrom our review of the NMR spectroscopy literature, it appears that the\nVARPRO method, and in particular the Netlib implementation, is competitive\nwith the standard least squares method using either the LMDER routine of the\nMINPACK library or the NL2SOL routines of the PORT library, both also available\nin the Netlib Repository. In general, the VARPRO functional requires fewer\nminimizer iterations, but the gradient computation is more expensive. Note\nthat the Levenberg-Marquardt minimizer in [PFTV92] performs quite poorly\nrelative to these three and we cannot recommend its use in production code.\nApart from the issue of numerical speed and accuracy of the VARPRO\nmethod, we see two additional benefits of this method over the standard\nmethod. First, by reducing the dimensionality of the search space by postponing the determination of \u00e2, this also means that starting estimates for \u00e2\nare not needed. For LQCD, this is a great benefit, since good guesses for \u03b1\nare easily obtained from the black box methods of Sec. 3. Second, when the\nincorporation of Bayesian prior knowledge is desired, for LQCD it seems easier to develop reasonable priors for the energies Ek than the amplitudes Ak .\nWhen using the VARPRO method, only priors for the energies are needed. Of\ncourse, if reliable priors for the amplitudes are available, one should instead\nuse the standard method. Finally, data covariance can easily be incorporated\nin the usual way\nh\niT\nh\ni\nr22 (\u03b1) = P\u22a5 (\u03b1)y C\u22121 (y) P\u22a5 (\u03b1)y .\n(11)\n\n\fWhat can Lattice QCD theorists learn from NMR spectroscopists?\n\n5\n\n3 Black Box Methods\n3.1 Effective Masses\nThe best example of a black box method widely used in LQCD is the method\nof effective masses. Let's consider the problem of Eq. (3) for the case N =2,\nK=1\n\u0013 \u0012 n \u0013\n\u0012\nyn+1\nyn\n\u03b11\nyn\n=\n(a1 ) \u21d2 \u03b11 =\n, a1 = n\n(12)\nyn+1\n\u03b1n+1\ny\n\u03b1\nn\n1\n1\nAs expected, the problem is exactly determined, so there is an unique zero\nresidual solution. For the model function of Eq. (1) the effective mass is meff =\n\u2212 log(\u03b11 ). Note that the non-linear parameter \u03b11 is determined first from the\ndata and then the linear parameter a1 can be determined. This is an indication\nof the separability of the least squares problem discussed in Sec. 2.\nAs we are unaware of its presentation elsewhere, here is the two-state\neffective mass solution. We start from Eq. (3) for N =4, K=2\n\uf8f6\n\uf8f6 \uf8eb\n\uf8eb\n1 1\nyn\n\u0012\n\u0013\n\uf8ec yn+1 \uf8f7 \uf8ec \u03b11 \u03b12 \uf8f7 a1 \u03b1n1\n\uf8f7 = \uf8ec 2 2\uf8f7\n\uf8ec\n(13)\n\uf8ed yn+2 \uf8f8 \uf8ed \u03b11 \u03b12 \uf8f8 a2 \u03b1n2 .\n3 3\n\u03b11 \u03b12\nyn+3\n\nIf we compute three quantities from the data\n\n2\nA = yn+1\n\u2212 yn yn+2\nB = yn yn+3 \u2212 yn+1 yn+2\n2\nC = yn+2\n\u2212 yn+1 yn+3\n\n(14)\n(15)\n(16)\n\nthen the two solutions for the non-linear parameters \u03b1k come from the familiar\nquadratic equation\n\u221a\n\u2212B \u00b1 B 2 \u2212 4AC\n\u03b11,2 =\n.\n(17)\n2A\nAs before, the linear parameters a1,2 can also be determined once the nonlinear parameters are known\n\"\n#\np\n2 \u2212 4AC)[4A3 + (B 2 \u2212 4AC)y 2 ]\n(B\n1\nn\nyn \u00b1\n(18)\nak \u03b1nk =\n2\nB 2 \u2212 4AC\nwhere some care must be taken to properly match solutions.\nIn general, when N =2K there should always be such a unique zero residual solution. From inspection of Eq. (13) the N =4, K=2 problem is a set of 4\ncoupled cubic equations. Unfortunately, due to Abel's Impossibility Theorem\n[Abe26], we should expect that general algebraic solutions are only possible\nfor N \u22645. Yet, the rather surprising result of Eq.(17) is that after properly separating the non-linear parameters \u03b1k , the N =4, K=2 problem is of quadratic\norder. Thus, we suspect that it is also possible to find algebraic solutions to\nthe three-state and four-state effective mass problems when properly reduced\nto cubic and quartic equations after separation of variables.\n\n\f6\n\nGeorge T. Fleming\n\n3.2 Black Box I: Linear Prediction\nIn order to compute solutions of Eq. (3) when the system is over-determined\n(N > 2K) or when an algebraic solution is not available, we consider the first\nblack box method called linear prediction. We form a K-th order polynomial\nwith the \u03b1k as roots\np(\u03b1) =\n\nK\nY\n\n(\u03b1 \u2212 \u03b1k ) =\n\nk=1\n\nK\nX\n\npi \u03b1K\u2212i\n\n(p0 = 1).\n\n(19)\n\ni=0\n\nSince p(\u03b1k ) = 0 the following is true\n\u03b1m\nk = \u2212\n\nK\nX\n\npi \u03b1m\u2212i\n,\nk\n\ni=1\n\nm \u2265 K.\n\n(20)\n\nWhen Eq. (20) is substituted in Eq. (3) we find the following relation\nym = \u2212\n\nK\nX\n\npk ym\u2212k ,\n\nk=1\n\nm \u2265 K.\n\n(21)\n\nBecause Eq. (21) enables us to \"predict\" the data ym at larger times in terms\nof the data ym\u2212K , * * * , ym\u22121 at earlier times, the pk are commonly called\nforward linear prediction coefficients.\nUsing Eq. (21) we can construct the linear system hlp = \u2212Hlp p\n\uf8eb\n\uf8f6\n\uf8f6\n\uf8eb\n\uf8f6\uf8eb\npM\nyM\ny0\n* * * yM\u22121\n\uf8ec\n\uf8ec yM+1 \uf8f7\n\uf8f7\n\uf8ec\ny1\n* * * yM \uf8f7\n\uf8ec\n\uf8f7\n\uf8ec\n\uf8f7 \uf8ec pM\u22121 \uf8f7\n(22)\n\uf8ec\n\uf8ec .. \uf8f7 = \u2212 \uf8ec\n\uf8f7\n. \uf8f7 , N \u2265 2M.\n..\n..\n..\n\uf8ed . \uf8f8\n\uf8ed\n.\n.\n. \uf8f8 \uf8ed .. \uf8f8\nyM\u22121\n\nyN \u2212M\u22121 * * * yN \u22122\n\np1\n\nIn numerical analysis, this is known as a Hankel system and the matrix Hlp\nis a Hankel matrix. After solving Eq. (22) for p, the roots of the polynomial\nof Eq. (19) are computed to determine the parameters \u03b1k . The ak parameters\ncan subsequently be determined from Eq. (8).\nIn the presence of noisy data, the equality in Eq. (22) is only approximate,\neven for the case N = 2M , so some minimization method like least squares\nmust be used. This doesn't mean that the parameter estimates from linear\nprediction agree with the parameter estimates from the least squares methods\nof Sec. 2. Gauss proved [Gau23] that the least squares estimates of fit parameters for linear problems have the smallest possible variance. In this sense, least\nsquares estimates are considered optimal although we know of no proof that\nthis holds for non-linear problems. Since linear prediction estimates may not\nagree with least squares, they are considered sub-optimal even though there\nis no proof that the variance is larger, due to non-linearity.\n\n\fWhat can Lattice QCD theorists learn from NMR spectroscopists?\n\n7\n\nA popular method for solving Eq. (22) is the LPSVD algorithm [KT82].\nIn this method, we construct Hlp for M as large as possible, even if we are\nonly interested in estimating K < M parameters. After computing the SVD\nof Hlp , we construct a rank K approximation HlpK\n\u0013\n\u0012\n\u03a3K\n\u2020\n(VK V2 ) , HlpK = UK \u03a3K V\u2020K (23)\nHlp = U\u03a3V\u2020 = (UK U2 )\n\u03a32\n\u03a3K contains the K largest singular values. By zeroing \u03a32 to reduce the rank\nof Hlp , much of the statistical noise is eliminated from the problem. From the\nEckart\u2013Young\u2013Mirsky theorem [EY36, Mir60], this rank K approximation\nis the nearest possible under either the Frobenius norm or matrix 2-norm.\nThen, after solving hlp = \u2212HlpK p for the pm coefficients, the M roots of the\npolynomial in Eq. (19) are computed using a root-finding algorithm. Since the\nrank of Hlp was reduced to K, only K roots are valid parameter estimates.\nTypically, the K largest magnitude roots are chosen.\nOur experience with this algorithm is that the largest magnitude roots\noften have unphysical values if K is set larger than a reasonable number given\nthe statistical precision of the data. There are also several issues which may\nbe of some concern. First, we found that root-finding algorithms all come\nwith caveats about stability and susceptibility to round-off error and must be\ntreated with some care. Also, since statistical noise is present on both sides of\nEq. (22), the rank-reduced least squares solution is probably not appropriate\nand one should probably use an errors-in-variables (EIV) approach like total\nleast squares (TLS), which we will describe in Sec. 3.3. We have found that\nthe TLS variant of LPSVD, called LPTLS [TM89], gives better parameter\nestimates than LPSVD.\n3.3 Total Least Squares\nIn the standard linear least squares problem Ax \u2248 b\nminimize kAx \u2212 bk2 ,\nx\u2208RK\n\nA \u2208 RN \u00d7K , b \u2208 RN , N \u2265 K\n\n(24)\n\nan important assumption for the solution, i.e. Eq. (8), to be considered optimal is that the only errors are in the data vector b and further that those\nerrors are i.i.d. (independent and identically distributed). When errors also occur in A, as in Eq. (22), then a new approach, often called errors-in-variables\n(EIV), is required to restore optimality. Note that the errors in A that cause\nthe loss of optimality need not be purely statistical: numerical round-off errors or choosing to fit a model function which differs from the \"true\" model\nfunction are potential sources of error which could cause loss of optimality.\nTo understand the total least squares (TLS) solution to the EIV problem,\nconsider the case when a zero residual solution to Eq. (24) exists. Then, if we\nadd b as a column of A, written [Ab], it cannot have greater column rank\n\n\f8\n\nGeorge T. Fleming\n\nthan A because b \u2208 Ran(A). If we compute the SVD of [Ab] we will find\nthat the singular value \u03c3K+1 = 0. When the solution of Eq. (24) has non-zero\nresidual, we may find the singular value \u03c3K + 1 of [Ab] to be non-zero as\nwell. But, we can construct the nearest rank R \u2264 K approximation to [Ab]\n(in the sense of the Eckart\u2013Young\u2013Mirsky theorem) and this gives us the TLS\nsolution. The TLS solution was computed in [GR70, Gol73], although the\nname was not coined until [GV80]. A comprehensive review [VV92] of the\nsubject is available.\nFinally, TLS is very sensitive to the distribution of errors in [Ab]. If the\nerrors are not known to be i.i.d. then it is crucial to scale the matrix before\nusing the TLS algorithm. If the data are uncorrelated, then a method known\nas \"equilibrium\" scaling [Bau63] is sufficient. If the data are correlated, then\nCholesky factors of the covariance matrix must be used. In this case, it is\nbetter to use either the generalized TLS algorithm (GTLS) [Van90a, Van90b]\nor the restricted TLS algorithm (RTLS) [VZ91] which are more robust when\nthe covariance matrix is ill-conditioned. Implementations of various TLS algorithms are available in the Netlib Repository [Van88].\n3.4 Black Box II: State Space Methods\nThe name for these methods is derived from state-space theory in the control\nand identification literature [KAB83]. The basic approach is to compute the\nnon-linear parameters \u03b1k of Eq. (3) without needing to compute the roots of\na polynomial, as in Sec. 3.2. From Eq. (22), we start by noting that Hs =\n[Hlp hlp ] is also a Hankel matrix\n\uf8eb\n\uf8f6\ny0\n* * * yM\u22121 yM\n\uf8ec\n..\n.\n.. \uf8f7\n..\nHs = \uf8ed\nM \u2265 K, N \u2212 M > K\n(25)\n. ..\n.\n. \uf8f8\nyN \u2212M\u22121 * * * yN \u22122 yN \u22121\n\nA Vandermonde decomposition exists for this matrix\n\uf8eb\n\n\uf8ec\n\uf8ec\nSATT = \uf8ec\n\uf8ed\n\n1\n\u03b11\n..\n.\n\n***\n***\n..\n.\n\n\uf8f6\n\n1\n\u03b1K\n..\n.\n\n\u2212M\u22121\n\u2212M\u22121\n\u03b1N\n* * * \u03b1N\n1\nK\n\n\uf8eb\n\n\uf8f7\n\uf8f7\uf8ec\n\uf8f7\uf8ed\n\uf8f8\n\na1\n\n\uf8f6T\n1 *** 1\n\uf8f7\n\uf8ec\n\uf8f7 \uf8ec \u03b11 * * * \u03b1K \uf8f7\n..\n\uf8f7 (26)\n\uf8ec\n\uf8f8\n.\n.\n.\n\uf8ed .. . . . .. \uf8f8\naK\nM\n\u03b1M\n1 * * * \u03b1K\n\uf8f6\n\n\uf8eb\n\nin terms of the linear (ak ) and non-linear (\u03b1k ) parameters of Eq. (3). If we\ncould compute this decomposition directly, then the problem would be solved.\nAlas, no such algorithm is currently known.\nAn indirect method exists to compute this decomposition called Hankel\nSVD (HSVD). We will consider here a TLS variant called HTLS [VCDV94].\nFirst, we note the shift invariance property of S (and similarly for T)\nS\u2191 A = S\u2193 ,\n\nA = diag(\u03b11 , * * * , \u03b1K ).\n\n(27)\n\n\fWhat can Lattice QCD theorists learn from NMR spectroscopists?\n\n9\n\nNext, we note that if such a decomposition is possible, then S, A and T are\nall of rank K by inspection, so Hs is at least of rank K, as well. So, using\nSVD we construct the nearest rank K approximation to HsK\n\u0013\n\u0012\n\u03a3K\n(VK V2 )\u2020 = UK \u03a3K V\u2020K\n(28)\nHsK = (UK U2 )\n0\nBy comparing the decompositions of Eq. (26) and Eq. (28) we can see\nSpan(S) = Span(UK ) =\u21d2 UK = SQ =\u21d2 U\u2191K = UK\u2193 Q\u22121 AQ (29)\ni\nh\nSo, computing the TLS solution of U\u2191K UK\u2193 will give us Q\u22121 AQ, which we\ncan then diagonalize using an eigenvalue solver to get our estimates of \u03b1k .\nIn our experience with these black box methods, the HTLS algorithm\nseems to be the most robust. However, we would like to emphasize two points.\nFirst, the estimates of \u03b1k from HTLS are considered sub-optimal because\nHsK in Eq. (28) is only approximately, but not exactly, a Hankel matrix because the SVD does not enforce the Hankel structure hthroughout.\ni A similar\n\u2191\nproblem occurs while constructing the TLS solution of UK UK\u2193 . Structured\nTLS algorithms (STLS) exist which can construct HsK while preserving the\nHankel structure (see [Van99] for references) and hence restoring the optimality of the estimates. While we have not yet tried these STLS algorithms,\nwe note that all of them involve iterative procedures to restore the structure.\nThus, under the \"no free lunch\" theorem, we suspect that the price of restoring optimality is roughly equivalent to performing the (optimal) non-linear\nleast squares minimizations described in Sec. 2.\nOur second observation is that LQCD data is always correlated, so that\nha GTLS ior RTLS algorithm is needed to compute the TLS solution of\nU\u2191K UK\u2193 . But, covariance estimates of UK are not readily computed from\nthe data covariance matrix because of the required SVD. Thus, a jackknife\nor bootstrap resampling method is required to estimate cov(UK ). Since we\nexpect to use a resampling method to estimate the covariance of the \u03b1k , this\nmeans that there is an inner and outer resampling loop so the method can easily become computationally expensive if the number of data samples becomes\nlarge. In this case, blocking the data is recommended.\n\n4 Conclusions\nWe have found that reviewing the literature of other fields where data analysis\nof exponentially damped time series is also prevalent to be quite fruitful. Our\nreview has discovered several mature analysis methods which are virtually\nunknown (or unmentioned) in the Lattice QCD literature. We have performed\nseveral tests of all the methods discussed on fake data and on some actual\n\n\f10\n\nGeorge T. Fleming\n\nLQCD data are encouraged by the results. So, we are incorporating these\ntechniques into our production versions of analysis programs and expect to\nreport results soon.\nFinally, we would like to acknowledge that we have found Leentje Vanhamme's Ph.D. Thesis [Van99] an extremely useful guide to the literature of\nthe NMR spectroscopy community. We would encourage anyone interested in\nlearning more to start there. An electronic copy is currently available online.\nThis work was supported in part by DOE contract DE-AC05-84ER40150\nunder which the Southeastern Universities Research Association (SURA) operates the Thomas Jefferson National Accelerator Facility.\n\nReferences\nABC02. Chris Allton, Danielle Blythe, and Jonathan Clowser. Spectral functions,\nmaximum entropy method and unconventional methods in lattice field theory. Nucl. Phys. Proc. Suppl., 109A:192\u2013196, 2002.\nAbe26. Niels H. Abel.\nBeweis der Unm\u00f6glichkeit, algebraische\nGleichungen\nvon\nh\u00f6heren\nGraden\nals\ndem\nvierten\nallgemein aufzul\u00f6sen.\nJ. reine angew. Math., 1:65, 1826.\nSee\nhttp://mathworld.wolfram.com/AbelsImpossibilityTheorem.html\nfor more references.\nBau63. F. L. Bauer. Optimally scaled matrices. Numer. Math., 5:73\u201387, 1963.\nBol77. John\nBolstad.\nvarpro.f.\nAvailable\nat:\nhttp://www.netlib.org/opt/index.html, January 1977.\nD+ 03. T. Draper et al. An algorithm for obtaining reliable priors for constrainedcurve fits. 2003.\nEY36. Carl H. Eckart and Gale Young. The approximation of one matrix by\nanother of lower rank. Psychometrika, 1:211\u2013218, 1936.\nFie02. H. Rudolf Fiebig. Spectral density analysis of time correlation functions in\nlattice QCD using the maximum entropy method. Phys. Rev., D65:094512,\n2002.\nGau23. Karl F. Gauss. Theoria combinationis observationum erroribus minimis\nobnoxiae. Comment. Soc. Reg. Sci. Gotten. Recent., 5:33, 1823.\nGol73. Gene H. Golub. Some modified matrix eigenvalue problems. SIAM Rev.,\n15:318\u2013334, 1973.\nGP73. Gene H. Golub and Victor Pereyra. The differentiation of pseudoinverses\nand nonlinear least squares problems whose variables separate. SIAM J.\nNumer. Anal., 10:413\u2013432, 1973.\nGR70. Gene H. Golub and Christian H. Reinsch. Singular value decomposition\nand least squares solutions. Numer. Math., 14:403\u2013420, 1970.\nGV80. Gene H. Golub and Charles F. Van Loan. An analysis of the total least\nsquares problem. SIAM J. Numer. Anal., 17:883\u2013893, 1980.\nKAB83. S. Y. Kung, K. S. Arun, and D. V. Bhaskar Rao. State-space and singular value decomposition-based approximation methods for the harmonic\nretrieval problem. J. Opt. Soc. Am., 73:1799\u20131811, 1983.\n\n\fWhat can Lattice QCD theorists learn from NMR spectroscopists?\n\n11\n\nKT82. Ramdas Kumeresan and Donald W. Tufts. Estimating the parameters of\nexponentially damped sinusoids and pole-zero modeling in noise. IEEE\nTrans. Acoust. Speech Signal Proc., 30:833\u2013840, 1982.\nL+ 02. G. P. Lepage et al. Constrained curve fitting. Nucl. Phys. Proc. Suppl.,\n106:12\u201320, 2002.\nMic94. Chris Michael. Fitting correlated data. Phys. Rev., D49:2616\u20132619, 1994.\nMir60. Leon Mirsky. Symmetric gauge functions and unitarily invariant norms.\nQuart. J. Math. Oxford Ser., 11:50\u201359, 1960.\nMM95. Chris Michael and A. McKerrell. Fitting correlated hadron mass spectrum\ndata. Phys. Rev., D51:3745\u20133750, 1995.\nNAH99. Y. Nakahara, M. Asakawa, and T. Hatsuda. Hadronic spectral functions\nin lattice QCD. Phys. Rev., D60:091503, 1999.\nPFTV92. William H. Press, Brian P. Flannery, Saul A. Teukolsky, and William T.\nVetterling. Numerical Recipes: The Art of Scientific Computing. Cambridge University Press, Cambridge (UK) and New York, second edition,\n1992.\nTM89. C. F. Tirendi and J. F. Martin. Quantitative analysis of NMR spectra\nby linear prediction and total least squares. J. Magn. Reson., 85:162\u2013169,\n1989.\nTou90. D. Toussaint. In T. DeGrand and D. Toussaint, editors, From Actions to\nAnswers, page 121, Singapore, 1990. World Scientific. Proceedings of Theoretical Advanced Study Institute in Elementary Particle Physics, Boulder,\nUSA, June 5-30, 1989.\nVan88. Sabine Van Huffel. Available at: http://www.netlib.org/vanhuffel/,\n1988.\nVan90a. Sabine Van Huffel. The generalized total least squares problem: formulation, algorithm and properties. In Gene H. Golub and P. Van Dooren,\neditors, Numerical Linear Algebra, Digital Signal Processing and Parallel\nAlgorithms, volume 70 of NATO ASI Series F: Computer and Systems Sciences, pages 651\u2013660, Berlin, 1990. Springer-Verlag. Proceedings of NATO\nASI, Leuven, Belgium, August 1988.\nVan90b. Sabine Van Huffel. Reliable and efficient techniques based on total least\nsquares for computing consistent estimators in models with errors in the\nvariables. In J. G. McWhirter, editor, Mathematics in Signal Processing\nII, pages 593\u2013603, Oxford, 1990. Clarendon Press. Proceedings of IMA\nconference, December 1988.\nVan99. Leentje Vanhamme.\nAdvanced time-domain methods for nuclear magnetic resonance spectroscopy data analysis.\nPhD thesis, Katholieke Universiteit Leuven, Belgium, November 1999.\nftp://ftp.esat.kuleuven.ac.be/pub/sista/vanhamme/reports/phd.ps.gz.\nVCDV94. Sabine Van Huffel, H. Chen, C. Decanniere, and P. Van Hecke. Algorithm\nfor time-domain NMR data fitting based on total least squares. J. Magn.\nReson., Ser. A, 110:228\u2013237, 1994.\nVV92. Sabine Van Huffel and Joos Vandewalle. The Total Least Squares Problem: Computational Aspects and Analysis, volume 9 of Frontiers in Applied\nMathematics. SIAM, Philadelphia, 1992.\nVZ91. Sabine Van Huffel and H. Zha. The restricted total least squares problem: formulation, algorithm and properties. SIAM J. Matrix Anal. Appl.,\n12:292\u2013309, 1991.\n\n\f12\n\nGeorge T. Fleming\n\nWei04. Eric\nW.\nWeisstein.\nMoore-Penrose\nmatrix\ninverse.\nhttp://mathworld.wolfram.com/Moore-PenroseMatrixInverse.html,\n2004. From MathWorld \u2013 A Wolfram Web Resource.\n\n\f"}