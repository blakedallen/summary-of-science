{"id": "http://arxiv.org/abs/1202.5298v2", "guidislink": true, "updated": "2012-10-30T16:29:38Z", "updated_parsed": [2012, 10, 30, 16, 29, 38, 1, 304, 0], "published": "2012-02-23T20:53:18Z", "published_parsed": [2012, 2, 23, 20, 53, 18, 3, 54, 0], "title": "Min Max Generalization for Two-stage Deterministic Batch Mode\n  Reinforcement Learning: Relaxation Schemes", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1202.3253%2C1202.0607%2C1202.0741%2C1202.4410%2C1202.5147%2C1202.5168%2C1202.6202%2C1202.6176%2C1202.5788%2C1202.0536%2C1202.1076%2C1202.4489%2C1202.5955%2C1202.0164%2C1202.1597%2C1202.0468%2C1202.3154%2C1202.3501%2C1202.6369%2C1202.4379%2C1202.1377%2C1202.1777%2C1202.5218%2C1202.5582%2C1202.1398%2C1202.6397%2C1202.2992%2C1202.5051%2C1202.1216%2C1202.1753%2C1202.2081%2C1202.4768%2C1202.2361%2C1202.1324%2C1202.6411%2C1202.0403%2C1202.2388%2C1202.4829%2C1202.5154%2C1202.4325%2C1202.2089%2C1202.0352%2C1202.4585%2C1202.5463%2C1202.4333%2C1202.0386%2C1202.4294%2C1202.0949%2C1202.4754%2C1202.1433%2C1202.5141%2C1202.4637%2C1202.0329%2C1202.6205%2C1202.3396%2C1202.6555%2C1202.4226%2C1202.0598%2C1202.6475%2C1202.2841%2C1202.4088%2C1202.5298%2C1202.6527%2C1202.0313%2C1202.2773%2C1202.2197%2C1202.2062%2C1202.1581%2C1202.4470%2C1202.4948%2C1202.4511%2C1202.1652%2C1202.2352%2C1202.3520%2C1202.0648%2C1202.1281%2C1202.5963%2C1202.6267%2C1202.1701%2C1202.6682%2C1202.4822%2C1202.2560%2C1202.5965%2C1202.0221%2C1202.0189%2C1202.6294%2C1202.3526%2C1202.4712%2C1202.3966%2C1202.3763%2C1202.4597%2C1202.1275%2C1202.4049%2C1202.0951%2C1202.4272%2C1202.2510%2C1202.5441%2C1202.1901%2C1202.4175%2C1202.0568%2C1202.5725&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Min Max Generalization for Two-stage Deterministic Batch Mode\n  Reinforcement Learning: Relaxation Schemes"}, "summary": "We study the minmax optimization problem introduced in [22] for computing\npolicies for batch mode reinforcement learning in a deterministic setting.\nFirst, we show that this problem is NP-hard. In the two-stage case, we provide\ntwo relaxation schemes. The first relaxation scheme works by dropping some\nconstraints in order to obtain a problem that is solvable in polynomial time.\nThe second relaxation scheme, based on a Lagrangian relaxation where all\nconstraints are dualized, leads to a conic quadratic programming problem. We\nalso theoretically prove and empirically illustrate that both relaxation\nschemes provide better results than those given in [22].", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1202.3253%2C1202.0607%2C1202.0741%2C1202.4410%2C1202.5147%2C1202.5168%2C1202.6202%2C1202.6176%2C1202.5788%2C1202.0536%2C1202.1076%2C1202.4489%2C1202.5955%2C1202.0164%2C1202.1597%2C1202.0468%2C1202.3154%2C1202.3501%2C1202.6369%2C1202.4379%2C1202.1377%2C1202.1777%2C1202.5218%2C1202.5582%2C1202.1398%2C1202.6397%2C1202.2992%2C1202.5051%2C1202.1216%2C1202.1753%2C1202.2081%2C1202.4768%2C1202.2361%2C1202.1324%2C1202.6411%2C1202.0403%2C1202.2388%2C1202.4829%2C1202.5154%2C1202.4325%2C1202.2089%2C1202.0352%2C1202.4585%2C1202.5463%2C1202.4333%2C1202.0386%2C1202.4294%2C1202.0949%2C1202.4754%2C1202.1433%2C1202.5141%2C1202.4637%2C1202.0329%2C1202.6205%2C1202.3396%2C1202.6555%2C1202.4226%2C1202.0598%2C1202.6475%2C1202.2841%2C1202.4088%2C1202.5298%2C1202.6527%2C1202.0313%2C1202.2773%2C1202.2197%2C1202.2062%2C1202.1581%2C1202.4470%2C1202.4948%2C1202.4511%2C1202.1652%2C1202.2352%2C1202.3520%2C1202.0648%2C1202.1281%2C1202.5963%2C1202.6267%2C1202.1701%2C1202.6682%2C1202.4822%2C1202.2560%2C1202.5965%2C1202.0221%2C1202.0189%2C1202.6294%2C1202.3526%2C1202.4712%2C1202.3966%2C1202.3763%2C1202.4597%2C1202.1275%2C1202.4049%2C1202.0951%2C1202.4272%2C1202.2510%2C1202.5441%2C1202.1901%2C1202.4175%2C1202.0568%2C1202.5725&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We study the minmax optimization problem introduced in [22] for computing\npolicies for batch mode reinforcement learning in a deterministic setting.\nFirst, we show that this problem is NP-hard. In the two-stage case, we provide\ntwo relaxation schemes. The first relaxation scheme works by dropping some\nconstraints in order to obtain a problem that is solvable in polynomial time.\nThe second relaxation scheme, based on a Lagrangian relaxation where all\nconstraints are dualized, leads to a conic quadratic programming problem. We\nalso theoretically prove and empirically illustrate that both relaxation\nschemes provide better results than those given in [22]."}, "authors": ["Raphael Fonteneau", "Damien Ernst", "Bernard Boigelot", "Quentin Louveaux"], "author_detail": {"name": "Quentin Louveaux"}, "author": "Quentin Louveaux", "links": [{"href": "http://arxiv.org/abs/1202.5298v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1202.5298v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.SY", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.SY", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1202.5298v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1202.5298v2", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "MIN MAX GENERALIZATION FOR TWO-STAGE DETERMINISTIC BATCH\nMODE REINFORCEMENT LEARNING: RELAXATION SCHEMES\n\narXiv:1202.5298v2 [cs.SY] 30 Oct 2012\n\nR. FONTENEAU\u2020, D. ERNST\u2020, B. BOIGELOT\u2020, AND Q. LOUVEAUX\u2020\nAbstract. We study the min max optimization problem introduced in [22] for computing policies for batch\nmode reinforcement learning in a deterministic setting. First, we show that this problem is NP-hard. In the twostage case, we provide two relaxation schemes. The first relaxation scheme works by dropping some constraints in\norder to obtain a problem that is solvable in polynomial time. The second relaxation scheme, based on a Lagrangian\nrelaxation where all constraints are dualized, leads to a conic quadratic programming problem. We also theoretically\nprove and empirically illustrate that both relaxation schemes provide better results than those given in [22].\nKey words. Reinforcement Learning, Min Max Generalization, Non-convex Optimization, Computational\nComplexity\nAMS subject classifications. 60J05 Discrete-time Markov processes on general state spaces\n\n1. Introduction. Research in Reinforcement Learning (RL) [48] aims at designing computational agents able to learn by themselves how to interact with their environment to maximize a numerical reward signal. The techniques developed in this field have appealed researchers trying to solve sequential decision making problems in many fields such as Finance\n[26], Medicine [34, 35] or Engineering [42]. Since the end of the nineties, several researchers\nhave focused on the resolution of a subproblem of RL: computing a high-performance policy\nwhen the only information available on the environment is contained in a batch collection of\ntrajectories of the agent [10, 17, 28, 38, 42, 19]. This subfield of RL is known as \"batch mode\nRL\".\nBatch mode RL (BMRL) algorithms are challenged when dealing with large or continuous state spaces. Indeed, in such cases they have to generalize the information contained in\na generally sparse sample of trajectories. The dominant approach for generalizing this information is to combine BMRL algorithms with function approximators [6, 28, 17, 11]. Usually,\nthese approximators generalize the information contained in the sample to areas poorly covered by the sample by implicitly assuming that the properties of the system in those areas\nare similar to the properties of the system in the nearby areas well covered by the sample.\nThis in turn often leads to low performance guarantees on the inferred policy when large state\nspace areas are poorly covered by the sample. This can be explained by the fact that when\ncomputing the performance guarantees of these policies, one needs to take into account that\nthey may actually drive the system into the poorly visited areas to which the generalization\nstrategy associates a favorable environment behavior, while the environment may actually be\nparticularly adversarial in those areas. This is corroborated by theoretical results which show\nthat the performance guarantees of the policies inferred by these algorithms degrade with the\nsample dispersion where, loosely speaking, the dispersion can be seen as the radius of the\nlargest non-visited state space area.\nTo overcome this problem, [22] propose a min max-type strategy for generalizing in\ndeterministic, Lipschitz continuous environments with continuous state spaces, finite action\nspaces, and finite time-horizon. The min max approach works by determining a sequence\nof actions that maximizes the worst return that could possibly be obtained considering any\nsystem compatible with the sample of trajectories, and a weak prior knowledge given in the\nform of upper bounds on the Lipschitz constants related to the environment (dynamics, reward\n\u2020 Department\n\nof Electrical Engineering and Computer Science, University of Li\u00e8ge, Belgium\n1\n\n\f2\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n\nfunction). However, they show that finding an exact solution of the min max problem is far\nfrom trivial, even after reformulating the problem so as to avoid the search in the space of\nall compatible functions. To circumvent these difficulties, they propose to replace, inside this\nmin max problem, the search for the worst environment given a sequence of actions by an\nexpression that lower-bounds the worst possible return which leads to their so called CGRL\nalgorithm (the acronym stands for \"Cautious approach to Generalization in Reinforcement\nLearning\"). This lower bound is derived from their previous work [20, 21] and has a tightness\nthat depends on the sample dispersion. However, in some configurations where areas of the\nthe state space are not well covered by the sample of trajectories, the CGRL bound turns to\nbe very conservative.\nIn this paper, we propose to further investigate the min max generalization optimization\nproblem that was initially proposed in [22]. We first show that this optimization problem\nis NP-hard. We then focus on the two-stage case, which is still NP-hard. Since it seems\nhopeless to exactly solve the problem, we propose two relaxation schemes that preserve the\nnature of the min max generalization problem by targetting policies leading to high performance guarantees. The first relaxation scheme works by dropping some constraints in order\nto obtain a problem that is solvable in polynomial time. This results into a well known configuration called the trust-region subproblem [13]. The second relaxation scheme, based on a\nLagrangian relaxation where all constraints are dualized, can be solved using conic quadratic\nprogramming in polynomial time. We prove that both relaxation schemes always provide\nbounds that are greater or equal to the CGRL bound. We also show that these bounds are\ntight in a sense that they converge towards the actual return when the sample dispersion converges towards zero, and that the sequences of actions that maximize these bounds converge\ntowards optimal ones.\nThe paper is organized as follows:\n\u2022 in Section 2, we give a short summary of the literature related to this work,\n\u2022 Section 3 formalizes the min max generalization problem in a Lipschitz continuous,\ndeterministic BMRL context,\n\u2022 in Section 4, we focus on the particular two-stage case, for which we prove that it\ncan be decoupled into two independent problems corresponding respectively to the\nfirst stage and the second stage (Theorem 4.2):\n\u2013 the first stage problem leads to a trivial optimization problem that can be solved\nin closed-form (Corollary 4.3),\n\u2013 we prove in Section 4.2 that the second stage problem is NP-hard (Corollary\n4.7), which consequently proves the NP-hardness of the general min max generalization problem (Theorem 4.8),\n\u2022 we then describe in Section 5 the two relaxation schemes that we propose for the\nsecond stage problem:\n\u2013 the trust-region relaxation scheme (Section 5.1),\n\u2013 the Lagrangian relaxation scheme (Section 5.2), which is shown to be a conicquadratic problem (Theorem 5.4),\n\u2022 we prove in Section 5.3.1 that the first relaxation scheme gives better results than\nCGRL (Theorem 5.9),\n\u2022 we show in Section 5.3.2 that the second relaxation scheme povides better results\nthan the first relaxation scheme (Theorem 5.13), and consequently better results than\nCGRL (Theorem 5.14),\n\u2022 we analyze in Section 5.4 the asymptotic behavior of the relaxation schemes as a\nfunction of the sample dispersion:\n\u2013 we show that the the bounds provided by the relaxtion schemes converge to-\n\n\fMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\nGeneral problem\n\n3\n\nNP-hard\n\nTwo-stage problem\n1st stage\n\ndecoupled\n\nClosed-form\n\n2nd stage\nNP-hard\n\nRelaxation schemes for the 2nd stage\nTrust-region\nbetter than [22]\nLagrangian relaxation\nbetter than Trust-region\nthus better than [22]\n\nConvergence\nwhen the sample\ndispersion\ngoes to 0\n\nF IG . 1.1. Main results of the paper.\n\nwards the actual return when the sample dispersion decreases towards zero\n(Theorem 5.17),\n\u2013 we show that the sequences of actions maximizing such bounds converge towards optimal sequences of actions when the sample dispersion decreases towards zero (Theorem 5.20),\n\u2022 Section 6 illustrates the relaxation schemes on an academic benchmark,\n\u2022 Section 7 concludes.\nWe provide in Figure 1.1 an illustration of the roadmap of the main results of this paper.\n2. Related Work. Several works have already been built upon min max paradigms for\ncomputing policies in a RL setting. In stochastic frameworks, min max approaches are often\nsuccessful for deriving robust solutions with respect to uncertainties in the (parametric) representation of the probability distributions associated with the environment [16]. In the context\nwhere several agents interact with each other in the same environment, min max approaches\nappear to be efficient strategies for designing policies that maximize one agent's reward given\nthe worst adversarial behavior of the other agents. [29, 43]. They have also received some\nattention for solving partially observable Markov decision processes [30, 27].\nThe min max approach towards generalization, originally introduced in [22], implicitly\nrelies on a methodology for computing lower bounds on the worst possible return (considering any compatible environment) in a deterministic setting with a mostly unknown actual\nenvironment. In this respect, it is related to other approaches that aim at computing performance guarantees on the returns of inferred policies [33, 41, 39].\nOther fields of research have proposed min max-type strategies for computing control\npolicies. This includes Robust Control theory [24] with H\u221e methods [2], but also Model\nPredictive Control (MPC) theory - where usually the environment is supposed to be fully\nknown [12, 18] - for which min max approaches have been used to determine an optimal\nsequence of actions with respect to the \"worst case\" disturbance sequence occurring [44, 4].\nFinally, there is a broad stream of works in the field of Stochastic Programming [7] that\n\n\f4\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n\nhave addressed the problem of safely planning under uncertainties, mainly known as \"robust\nstochastic programming\" or \"risk-averse stochastic programming\" [15, 45, 46, 36]. In this\nfield, the two-stage case has also been particularly well-studied [23, 14].\n3. Problem Formalization. We first formalize the BMRL setting in Section 3.1, and\nwe state the min max generalization problem in Section 3.2.\n3.1. Batch Mode Reinforcement Learning. We consider a deterministic discrete-time\nsystem whose dynamics over T stages is described by a time-invariant equation\nt = 0, . . . , T \u2212 1,\n\nxt+1 = f (xt , ut )\n\nwhere for all t, the state xt is an element of the state space X \u2282 Rd where Rd denotes\nthe d\u2212dimensional\nEuclidean space and ut is an element of the finite (discrete) action space\n\b\nU = u(1) , . . . , u(m) that we abusively identify with {1, . . . , m}. T \u2208 N \\ {0} is referred\nto as the (finite) optimization horizon. An instantaneous reward\nrt = \u03c1 (xt , ut ) \u2208 R\nis associated with the action ut taken while being in state xt . For a given initial state x0 \u2208 X\nand for every sequence of actions (u0 , . . . , uT \u22121 ) \u2208 U T , the cumulated reward over T stages\n(also named T \u2212stage return) is defined as follows:\nD EFINITION 3.1 (T \u2212stage Return).\n(u ,...,uT \u22121 )\nJT 0\n\nT\n\n\u2200 (u0 , . . . , uT \u22121 ) \u2208 U ,\n\n,\n\nT\n\u22121\nX\n\n\u03c1 (xt , ut ) ,\n\nt=0\n\nwhere\nxt+1 = f (xt , ut ) ,\n\n\u2200t \u2208 {0, . . . , T \u2212 1} .\n\nAn optimal sequence of actions is a sequence that leads to the maximization of the T \u2212stage\nreturn:\nD EFINITION 3.2 (Optimal T \u2212stage Return).\nJT\u2217 ,\n\nmax\n\n(u0 ,...,uT \u22121 )\u2208U T\n\n(u0 ,...,uT \u22121 )\n\nJT\n\n.\n\nWe further make the following assumptions that characterize the batch mode setting:\n1. The system dynamics f and the reward function \u03c1 are unknown;\n2. For each action u \u2208 U, a set of n(u) \u2208 N one-step system transitions\nF (u) =\n\nn\u0010\n\u0011on(u)\nx(u),k , r(u),k , y (u),k\nk=1\n\nis known where each one-step transition is such that:\n\u0010\n\u0011\n\u0010\n\u0011\ny (u),k = f x(u),k , u and r(u),k = \u03c1 x(u),k , u .\n3. We assume that every set F (u) contains at least one element:\n\u2200u \u2208 U,\n\nn(u) > 0 .\n\n\fMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\n5\n\nIn the following, we denote by F the collection of all system transitions:\nF = F (1) \u222a . . . \u222a F (m)\nUnder those assumptions, batch mode reinforcement learning (BMRL) techniques propose\nto infer from the sample of one-step system transitions F a high-performance sequence of\n\u0001\n(\u0169\u2217 ,...,\u0169\u2217\nT \u22121 )\nactions, i.e. a sequence of actions \u0169\u22170 , . . . , \u0169\u2217T \u22121 \u2208 U T such that JT 0\nis as close\nas possible to JT\u2217 .\n3.2. Min max Generalization under Lipschitz Continuity Assumptions. In this section, we state the min max generalization problem that we study in this paper. The formalization was originally proposed in [22].\nWe first assume that the system dynamics f and the reward function \u03c1 are assumed to be\nLipschitz continuous. There exist finite constants Lf , L\u03c1 \u2208 R such that:\n\u2200(x, x0 ) \u2208 X 2 , \u2200u \u2208 U,\n\nkf (x, u) \u2212 f (x0 , u)k \u2264 Lf kx \u2212 x0 k ,\n|\u03c1 (x, u) \u2212 \u03c1 (x0 , u)| \u2264 L\u03c1 kx \u2212 x0 k ,\n\nwhere k.k denotes the Euclidean norm over the space X . We also assume that two constants\nLf and L\u03c1 satisfying the above-written inequalities are known.\nFor a given sequence of actions, one can define the worst possible return that can be obtained by any system whose dynamics f 0 and \u03c10 would satisfy the Lipschitz inequalities and\nthat would coincide with the values of the functions f and \u03c1 given by the sample of system\ntransitions F. As shown in [22], this worst possible return can be computed by solving a\nfinite-dimensional optimization problem over X T \u22121 \u00d7 RT . Intuitively, solving such an optimization problem amounts in determining a most pessimistic trajectory of the system that\nis still compliant with the sample of data and the Lipschitz continuity assumptions. More\nspecifically, for a given sequence of actions (u0 , . . . , uT \u22121 ) \u2208 U T , some given constants Lf\nand L\u03c1 , a given initial state x0 \u2208 X and a given sample of transitions F, this optimization\nproblem writes:\n(PT (F, Lf , L\u03c1 , x0 , u0 , . . . , uT \u22121 )) :\n\nr\u03020\nx\u03020\n\nmin\n. . . r\u0302T\u22121 \u2208 R\n. . . x\u0302T\u22121 \u2208 X\n\nT\n\u22121\nX\n\nr\u0302t ,\n\nt=0\n\nsubject to\nr\u0302t \u2212 r(ut ),kt\n\n2\n\nx\u0302t+1 \u2212 y (ut ),kt\n2\n\n2\n\n\u2264 L2f\n\n2\n\nn\no\n, \u2200(t, kt ) \u2208 {0, . . . , T \u2212 1} \u00d7 1, . . . , n(ut ) ,\nn\no\n2\nx\u0302t \u2212 x(ut ),kt , \u2200(t, kt ) \u2208 {0, . . . , T \u2212 1} \u00d7 1, . . . , n(ut ) ,\n\n\u2264 L2\u03c1 x\u0302t \u2212 x(ut ),kt\n\n2\n\n|r\u0302t \u2212 r\u0302t0 | \u2264 L2\u03c1 kx\u0302t \u2212 x\u0302t0 k , \u2200t, t0 \u2208 {0, . . . , T \u2212 1|ut = ut0 } ,\n2\n\n2\n\nkx\u0302t+1 \u2212 x\u0302t0 +1 k \u2264 L2f kx\u0302t \u2212 x\u0302t0 k , \u2200t, t0 \u2208 {0, . . . , T \u2212 2|ut = ut0 } ,\nx\u03020 = x0 .\nNote that, throughout the paper, optimization variables will be written in bold.\nThe min max approach to generalization aims at identifying which sequence of actions\nmaximizes its worst possible return, that is which sequence of actions leads to the highest\nvalue of (PT (F, Lf , L\u03c1 , x0 , u0 , . . . , uT \u22121 )).\n\n\f6\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n\nWe focus in this paper on the design of resolution schemes for solving the program\n(PT (F, Lf , L\u03c1 , x0 , u0 , . . . , uT \u22121 )). These schemes can afterwards be used for solving the\nmin max problem through exhaustive search over the set of all sequences of actions.\nLater in this paper, we will also analyze the computational complexity of this min max\ngeneralization problem. When carrying out this analysis, we will assume that all the data of\nthe problem (i.e., T, F, Lf , L\u03c1 , x0 , u0 , . . . , uT \u22121 ) are given in the form of rational numbers.\n4. The Two-stage Case. In this section, we restrict ourselves to the case where the\ntime horizon contains only two steps,\u0001 i.e. T = 2, which is an important particular case\nof PT (F, Lf , L\u03c1 , x0 , u0 , . . . , uT \u22121 ) . Many works in optimal sequential decision making\nhave considered the two-stage case [23, 14], which relates to many applications, such as for\ninstance medical applications where one wants to infer \"safe\" clinical decision rules from\nbatch collections of clinical data [1, 31, 32, 49].\nIn Section 4.1, we show that this problem can be decoupled into two subproblems. While\nthe first subproblem is straightforward to solve, we prove in Section 4.2 that the second one\nis NP-hard, which proves that the two-stage problem as well as the generalized T \u2212stage\nproblem (PT (F, Lf , L\u03c1 , x0 , u0 , . . . , uT \u22121 )) are also NP-hard.\n2\nGiven a two-stage sequence of actions\n\u0001 (u0 , u1 ) \u2208 U , the two-stage version of the problem PT (F, Lf , L\u03c1 , x0 , u0 , . . . , uT \u22121 ) writes as follows:\n\u0001\nP2 (F, Lf , L\u03c1 , x0 , u0 , u1 ) :\nmin\nr\u03020 , r\u03021 \u2208 R\nx\u03020 , x\u03021 \u2208 X\n\nr\u03020 + r\u03021 ,\n\nsubject to\n2\n\n2\n\nn\no\n, \u2200k0 \u2208 1, . . . , n(u0 ) ,\nn\no\n2\n2\n, \u2200k1 \u2208 1, . . . , n(u1 ) ,\nr\u03021 \u2212 r(u1 ),k1 \u2264 L2\u03c1 x\u03021 \u2212 x(u1 ),k1\nn\no\n2\n2\nx\u03021 \u2212 y (u0 ),k0 \u2264 L2f x\u03020 \u2212 x(u0 ),k0\n, \u2200k0 \u2208 1, . . . , n(u0 ) ,\n\nr\u03020 \u2212 r(u0 ),k0\n\n\u2264 L2\u03c1 x\u03020 \u2212 x(u0 ),k0\n\n2\n\n2\n\n(4.1)\n(4.2)\n(4.3)\n\n|r\u03020 \u2212 r\u03021 | \u2264 L2\u03c1 kx\u03020 \u2212 x\u03021 k if u0 = u1 ,\n\n(4.4)\n\nx\u03020 = x0 .\n\n(4.5)\n\nFor a matter of simplicity, we will often drop the arguments in the definition of the\n\u0001\n(u ,u )\noptimization problem and refer P2 (F, Lf , L\u03c1 , x0 , u0 , u1 ) as (P2 0 1 ). We denote by\n(u ,u )\n(u ,u )\nB2 0 1 (F) the lower bound associated with an optimal solution of (P2 0 1 ):\n(u0 ,u1 )\n\nD EFINITION 4.1 (Optimal\nValue\n\u0010\n\u0011 B2\n(u0 ,u1 )\n\nbe an optimal solution to P2\n\n(F)). Let (u0 , u1 ) \u2208 U 2 , and let (r\u0302\u22170 , r\u0302\u22171 , x\u0302\u22170 , x\u0302\u22171 )\n\n. Then,\n\n(u0 ,u1 )\n\nB2\n\n(F) , r\u0302\u22170 + r\u0302\u22171 .\n\n0(u0 ,u1 )\n\n4.1. Decoupling Stages. Let (P2\nlems:\n\n00(u0 ,u1 )\n\n) and (P2\n\n) be the two following subprob-\n\n\f7\n\nMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\n\u0010\n\n0(u0 ,u1 )\n\nP2\n\n\u0011\n\n:\nmin\nr\u03020 \u2208 R\nx\u03020 \u2208 X\n\nr\u03020\n\nsubject to\nr\u03020 \u2212 r(u0 ),k0\n\n2\n\n\u2264 L2\u03c1 x\u03020 \u2212 x(u0 ),k0\n\n2\n\no\nn\n, \u2200k0 \u2208 1, . . . , n(u0 ) ,\n\nx\u03020 = x0 .\n\u0010\n\n00(u0 ,u1 )\n\nP2\n\n\u0011\n\n:\nmin\nr\u03021 \u2208 R\nx\u03021 \u2208 X\n\nr\u03021\n\n(4.6)\n\nsubject to\nr\u03021 \u2212 r(u1 ),k1\nx\u03021 \u2212 y (u0 ),k0\n\n2\n\n\u2264 L2\u03c1 x\u03021 \u2212 x(u1 ),k1\n2\n\n\u2264 L2f x0 \u2212 x(u0 ),k0\n\n2\n\nn\no\n, \u2200k1 \u2208 1, . . . , n(u1 ) ,\nn\no\n2\n, \u2200k0 \u2208 1, . . . , n(u0 ) .\n\n(4.7)\n(4.8)\n\n(u ,u )\n\nWe show in this section that an optimal solution to (P2 0 1 ) can be obtained by solving\n0(u ,u )\n00(u ,u )\nthe two subproblems (P2 0 1 ) and (P2 0 1 ) corresponding to the first stage and the\nsecond stage. Indeed, one can see that the stages t = 0 and t = 1 are theoretically coupled\nby constraint (4.4), except in the case where the two actions u0 and u1 are different for which\n(u ,u )\n(P2 0 1 ) is trivially decoupled. We prove in the following that, even in the case u0 = u1 ,\n0(u ,u )\n00(u ,u )\noptimal solutions to the two decoupled problems (P2 0 1 ) and (P2 0 1 ) also satisfy\n0(u ,u )\nconstraint (4.4). Additionally, we provide the solution of (P2 0 1 ).\n\u0010\n\u0011\n0(u ,u )\nT HEOREM 4.2. Let (u0 , u1 ) \u2208 U 2 . If (r\u0302\u22170 , x\u0302\u22170 ) is an optimal solution to P2 0 1 and\n\u0010\n\u0011\n00(u ,u )\n(r\u0302\u22171 , x\u0302\u22171 ) is an optimal solution to P2 0 1 , then (r\u0302\u22170 , r\u0302\u22171 , x\u0302\u22170 , x\u0302\u22171 ) is an optimal solution to\n\u0010\n\u0011\n(u ,u )\nP2 0 1 .\nProof.\n\u2022 First case: u0 6= u1 .\nThe constraint (4.4) drops and the theorem is trivial.\n\u2022 Second case: u0 = u1 .\nThe rationale of the proof is the following. We first relax constraint (4.4), and consider the two\n0(u ,u )\n00(u ,u )\n0(u ,u )\nproblems (P2 0 1 ) and (P2 0 1 ). Then, we show that optimal solutions of (P2 0 1 )\n00(u0 ,u1 )\nand (P2\n) also satisfy constraint (4.4).\n0(u ,u )\n\n0(u ,u )\n\nAbout (P2 0 1 ). The problem (P2 0 1 ) consists in the minimization of r\u03020 under\nthe intersection of interval constraints. It is therefore straightforward to solve. In particular\nthe optimal solution r\u0302\u22170 lies at the lower value of one of the intervals. Therefore there exists\n\n\f8\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n\n\u2217\n\u2217\n\u2217\u0001\nx(u0 ),k0 , r(u0 ),k0 , y (u0 ),k0 \u2208 F (u0 ) such that\n\u2217\n\n\u2217\n\nr\u0302\u22170 = r(u0 ),k0 \u2212 L\u03c1 x0 \u2212 x(u0 ),k0 .\n\n(4.9)\n\nFurthermore r\u0302\u22170 must belong to all intervals. We therefore have that\no\nn\n\u2200k0 \u2208 1, . . . , n(u0 ) .\nr\u0302\u22170 \u2265 r(u0 ),k0 \u2212 L\u03c1 x0 \u2212 x(u0 ),k0 ,\n\n(4.10)\n\nIn other words,\nr\u0302\u22170 =\n\nmax\n\nr(u0 ),k0 \u2212 L\u03c1 x0 \u2212 x(u0 ),k0\n\n.\n\nk0 \u2208{1,...,n(u0 ) }\n\n00(u ,u )\n\nAbout (P2 0 1 ). Again we observe that it is the minimization of r\u03021 under the intersection of interval constraints as well. The sizes of the intervals are however not fixed but\n00(u ,u )\ndetermined by the variable x\u03021 . If we denote the optimal solution of (P2 0 1 ) by r\u0302\u22171 and\nx\u0302\u22171 , we know that r\u0302\u22171 also\nlies at the lower value of one of the intervals. Hence there exists\n\u2217\u0001\n\u2217\n\u2217\nx(u),k1 , r(u),k1 , y (u),k1 \u2208 F (u) such that\n\u2217\n\n\u2217\n\nr\u0302\u22171 = r(u),k1 \u2212 L\u03c1 x\u0302\u22171 \u2212 x(u),k1 .\n\n(4.11)\n\nFurthermore r\u0302\u22171 must belong to all intervals. We therefore have that\nn\no\nr\u0302\u22171 \u2265 r(u),k1 \u2212 L\u03c1 x\u0302\u22171 \u2212 x(u),k1 ,\n\u2200k1 \u2208 1, . . . , n(u) .\n\n(4.12)\n\nWe now discuss two cases depending on the sign of r\u0302\u22170 \u2212 r\u0302\u22171 .\n\u2212 If r\u0302\u22170 \u2212 r\u0302\u22171 \u2265 0\nUsing (4.9) and (4.12) with index k0\u2217 , we have\n\u0011\n\u0010\n\u2217\n\u2217\nr\u0302\u22170 \u2212 r\u0302\u22171 \u2264 L\u03c1 x\u0302\u22171 \u2212 x(u),k0 \u2212 x0 \u2212 x(u),k0\n\n(4.13)\n\nSince r\u0302\u22170 \u2212 r\u0302\u22171 \u2265 0, we therefore have\n\u0010\n\u0011\n\u2217\n\u2217\n|r\u0302\u22170 \u2212 r\u0302\u22171 | \u2264 L\u03c1 x\u0302\u22171 \u2212 x(u),k0 \u2212 x0 \u2212 x(u),k0\n.\n\n(4.14)\n\nUsing the triangle inequality we can write\n\u2217\n\n\u2217\n\nx\u0302\u22171 \u2212 x(u),k0 \u2264 kx\u0302\u22171 \u2212 x0 k + x0 \u2212 x(u),k0\n\n.\n\nReplacing (4.15) in (4.14) we obtain\n|r\u0302\u22171 \u2212 r\u0302\u22170 | \u2264 L\u03c1 kx\u0302\u22171 \u2212 x0 k\nwhich shows that r\u0302\u22170 and r\u0302\u22171 satisfy constraint (4.4).\n\u2212 If r\u0302\u22170 \u2212 r\u0302\u22171 < 0\nUsing (4.11) and (4.10) with index k1\u2217 , we have\n\u0011\n\u0010\n\u2217\n\u2217\nr\u0302\u22171 \u2212 r\u0302\u22170 \u2264 L\u03c1 x0 \u2212 x(u),k1 \u2212 x\u0302\u22171 \u2212 x(u),k1\n\n(4.15)\n\n\f9\n\nMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\nand since r\u0302\u22170 \u2212 r\u0302\u22171 < 0,\n|r\u0302\u22171 \u2212 r\u0302\u22170 | \u2264 L\u03c1\n\n\u0010\n\n\u2217\n\n\u2217\n\nx0 \u2212 x(u),k1 \u2212 x\u0302\u22171 \u2212 x(u),k1\n\n\u0011\n\n.\n\n(4.16)\n\nUsing the triangle inequality we can write\n\u2217\n\n\u2217\n\nx0 \u2212 x(u),k1 \u2264 kx0 \u2212 x\u0302\u22171 k + x\u0302\u22171 \u2212 x(u),k1 .\n\n(4.17)\n\nReplacing (4.17) in (4.16) yields\n|r\u0302\u22171 \u2212 r\u0302\u22170 | \u2264 L\u03c1 kx0 \u2212 x\u0302\u22171 k ,\nwhich again shows that r\u0302\u22170 and r\u0302\u22171 satisfy constraint (4.4).\nIn both cases r\u0302\u22170 \u2212r\u0302\u22171 \u2265 0 and r\u0302\u22170 \u2212r\u0302\u22171 < 0, we have shown that constraint (4.4) is satisfied.\n0(u ,u )\n00(u ,u )\nIn the following of the paper, we focus on the two subproblems (P2 0 1 ) and (P2 0 1 )\n(u0 ,u1 )\nrather than on (P2\n). From the proof of Theorem 4.2 given above, we can directly obtain\n0(u ,u )\nthe solution of (P2 0 1 ):\n0(u ,u )\nC OROLLARY 4.3. The solution of the problem (P2 0 1 ) is\nr\u0302\u22170 =\n\nmax\n\nr(u0 ),k0 \u2212 L\u03c1 x0 \u2212 x(u0 ),k0\n\nk0 \u2208{1,...,n(u0 ) }\n\n00(u ,u )\n\n.\n\n0(u ,u )\n\n4.2. Complexity of (P2 0 1 ). The problem (P2 0 1 ) being solved, we now fo00(u ,u )\ncus in this section on the resolution of (P2 0 1 ). In particular, we show that it is NPhard, even in the particular case where there is only one element in the sample F (u1 ) =\n\b (u ),1 (u ),1 (u ),1 \u0001\n00(u ,u )\nx 1 ,r 1 ,y 1\n. In this particular case, the problem (P2 0 1 ) amounts to maximizing of the distance x\u03021 \u2212 x(u1 ),1 under an intersection of balls as we show in the following lemma.\nL EMMA 4.4. If the cardinality of F (u1 ) is equal to 1:\nn\u0010\n\u0011o\nF (u1 ) =\nx(u1 ),1 , r(u1 ),1 , y (u1 ),1\n,\n\u0010\n\u0011\n00(u ,u )\nthen the optimal solution to P2 0 1 satisfies\nr\u0302\u22171 = r(u1 ),1 \u2212 L\u03c1 x\u0302\u22171 \u2212 x(u1 ),1\nwhere x\u0302\u22171 maximizes x\u03021 \u2212 x(u1 ),1 subject to\nx\u03021 \u2212 y (u0 ),k0\n\n2\n\n\u2264 L2f x0 \u2212 x(u0 ),k0\n\n2\n\n,\n\n\u0010\n\u0011\n\u2200 x(u0 ),k0 , r(u0 ),k0 , y (u0 ),k0 \u2208 F (u0 ) .\n\nProof. The unique constraint concerning r\u03021 is an interval. Therefore r\u0302\u22171 takes the value of\nthe lower bound of the interval. In order to obtain the lowest such value, the right-hand-side\nof (4.7) must be maximized under the other constraints.\n(u ,u )\nNote that if the cardinality n(u0 ) of F (u0 ) is also equal to 1, then (P2 0 1 ) can be solved\nexactly, as we will later show in Corollary 5.3. But, in the general case where n(u0 ) > 1, this\n\n\f10\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n\nproblem of maximizing a distance under a set of ball-constraints is NP-hard as we now prove.\nTo do it, we introduce the MNBC (for \"Max Norm with Ball Constraints\") decision problem:\nD EFINITION 4.5 (MNBC Decision Problem). Given x(0) \u2208 Qd , y i \u2208 Qd , \u03b3i \u2208 Q, i \u2208\n{1, . . . , I}, C \u2208 Q, the MNBC problem is to determine whether there exists x \u2208 Rd such that\nx \u2212 x(0)\n\n2\n\n\u2265C\n\nand\nx \u2212 yi\n\n2\n\n\u2264 \u03b3i ,\n\n\u2200i \u2208 {1, . . . , I} .\n\nL EMMA 4.6. MNBC is NP-hard.\nProof. To prove it, we will do a reduction from the {0, 1}\u2212programming feasibility\nproblem [40]. More precisely, we consider in this proof the {0, 2}\u2212programming feasibility\nproblem, which is equivalent. The problem is, given p \u2208 N, A \u2208 Zp\u00d7d , b \u2208 Zp to find\nwhether there exists x \u2208 {0, 2}d that satisfies Ax \u2264 b. This problem is known to be NP-hard\nand we now provide a polynomial reduction to MNBC.\nThe dimension d is kept the same in both problems. The first step is to define a set of\nconstraints for MNBC such that the only potential feasible solutions are exactly x \u2208 {0, 2}d .\nWe define\nx(0) , (1, . . . , 1)\nand\nC , d.\nFor i = 1, . . . , d, we define\ny 2i , y12i , . . . , yd2i\n\n\u0001\n\nwith yi2i , 0 and yj2i , 1 for all j 6= i and \u03b3i , d + 3.\nSimilarly for i = 1, . . . , d, we define\ny 2i+1 , (y12i+1 , . . . , yd2i+1 )\nwith yi2i+1 , 2 and yj2i+1 , 1 for all j 6= i and \u03b3i , d + 3.\nClaim\nn\no\nx \u2208 Rd | kx \u2212 x(0) k2 \u2265 d \u2229\n\n2d+1\n\\\n\n!\n\b\n\nd\n\ni 2\n\nx \u2208 R | kx \u2212 y k \u2264 \u03b3i\n\n= {0, 2}d\n\ni=2\n\nIt is readily verified that any x \u2208 {0, 2}d belongs to the 2d + 1 above sets.\nConsider x \u2208 Rd that belongs to the 2d + 1 above sets. Consider an index k \u2208 {1, . . . , d}.\nUsing the constraints defining the sets, we can in particular write\nk(x1 , . . . , xk\u22121 , xk , xk+1 , . . . , xd ) \u2212 (1, . . . , 1)k2 \u2265 d\nk(x1 , . . . , xk\u22121 , xk , xk+1 , . . . , xd ) \u2212 (1, . . . , 1, 0, 1, . . . , 1)k2 \u2264 d + 3\nk(x1 , . . . , xk\u22121 , xk , xk+1 , . . . , xd ) \u2212 (1, . . . , 1, 2, 1, . . . , 1)k2 \u2264 d + 3\n\n\fMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\nthat we can write algebraically\nX\n(xj \u2212 1)2 + (xk \u2212 1)2 \u2265 d\n\n11\n\n(4.18)\n\nj6=k\n\nX\n(xj \u2212 1)2 + x2k \u2264 d + 3\n\n(4.19)\n\nj6=k\n\nX\n(xj \u2212 1)2 + (xk \u2212 2)2 \u2264 d + 3.\n\n(4.20)\n\nj6=k\n\nBy computing (4.19) \u2212 (4.18) and (4.20) \u2212 (4.18), we obtain xk \u2264 2 and xk \u2265 0 respectively.\nThis implies that\nd\nX\n\n2\n\n(xk \u2212 1) \u2264 d\n\nk=1\n\nand the equality is obtained if and only if we have that xk \u2208 {0, 2} for all k which proves the\nclaim.\nIt remains to prove that we can encode any linear inequality through a ball constraint. ConPd\nsider an inequality of the type j=1 aj xj \u2264 b. We assume that a 6= 0 and that b is even and\ntherefore that there exists no x \u2208 {0, 2}d such that aT x = b + 1. We want to show that there\nexists y \u2208 Qd and \u03b3 \u2208 Q such that\n\b\n\b\nx \u2208 {0, 2}d | aT x \u2264 b = x \u2208 {0, 2}d | kx \u2212 yk2 \u2264 \u03b3 .\n(4.21)\nLet \u0233 \u2208 Rd be the intersection point of the hyperplane aT x = b + 1 and the line (1 * * * 1)T +\n\u03bb(a1 * * * ad )T , \u03bb \u2208 R. Let r be defined as follows:\n\uf8f9\n\uf8ee v\nu d\nuX\nd\nt\na2j + 1\uf8fa\nr=\uf8ef\n\uf8fa.\n\uf8ef2\n\uf8fa\n\uf8ef\nj=1\nWe claim that choosing \u03b3 , r2 and y , \u0233 \u2212 ra allows us to obtain (4.21). To prove it,\nwe need to show that x \u2208 {0, 2}d belongs to the ball if and only if it satisfies the constraint\naT x \u2264 b. Let x\u0304 \u2208 {0, 2}d . There are two cases to consider:\n\u2022 Suppose first that aT x\u0304 \u2265 b + 2.\nSince \u0233 is the closest point to y that satisfies aT y = b + 1, it also implies that any point x\nsuch that aT x > b + 1 is such that kx \u2212 yk2 > r2 proving that:\n\b\nx\u0304 \u2208\n/ x \u2208 Rd | kx \u2212 yk2 \u2264 r2 .\n\u2022 Suppose now that aT x\u0304 \u2264 b and in particular that aT x\u0304 = b \u2212 k with k \u2208 N (see\nFigure 4.1).\nLet \u1ef9 \u2208 Rd be the intersection point of the hyperplane\naT x = b \u2212 k and the line (1 * * * 1)T +\n\u0001\nT\nT\n\u03bb(a1 * * * ad ) , \u03bb \u2208 R. Since (1 * * * 1) , \u1ef9, x\u0304 form a right triangle with the right angle in \u1ef9\nand since k(1 * * * 1)T \u2212 x\u0304k2 \u2264 d, we have\nk\u1ef9 \u2212 x\u0304k2 \u2264 d.\nBy definition of y, we have:\nky \u2212 \u0233k = r ,\n\n(4.22)\n\n\f12\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n\nF IG . 4.1. The case when aT x\u0304 \u2264 b.\n\nand by definition of \u0233 and \u1ef9, we have:\n1\nk\u0233 \u2212 \u1ef9k \u2265 qP\nd\n\n.\n\n2\nj=1 aj\n\nSince \u0233, \u1ef9 and y belong to the same line, we have\n1\nky \u2212 \u1ef9k \u2264 r \u2212 qP\nd\n\n.\n\nj=1\n\n(4.23)\n\na2j\n\nAs (y, \u1ef9, x\u0304) form a right triangle with the right angle in \u1ef9, we have that\nkx\u0304 \u2212 yk2 = ky \u2212 \u1ef9k2 + kx\u0304 \u2212 \u1ef9k2\n\uf8eb\n\uf8f62\n1\n\uf8f8 + d using (4.22), (4.23)\n\u2264 \uf8edr \u2212 qP\nd\n2\nj=1 aj\n2r\n= r2 \u2212 qP\nd\n\n2\nj=1 aj\n\nSince by definition, r \u2265\n\nd\n2\n\nqP\nd\n\nj=1\n\n+ Pd\n\n1\n\nj=1\n\na2j\n\n+ d.\n\na2j + 1, we can write\n\n2\nkx\u0304 \u2212 yk2 \u2264 r2 \u2212 d \u2212 qP\nd\n\n2\nj=1 aj\n\n= r 2 \u2212 Pd\n\n+ Pd\n\n1\n\nj=1\n\na2j\n\n+d\n\n1\n\nj=1\n\na2j\n\n\u2264 r2 .\n\b\nThis proves that the chosen ball x \u2208 Rd | kx \u2212 yk2 \u2264 r2 includes the same points from\n{0, 2}d as the linear inequality aT x \u2264 b.\n\n\fMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\n13\n\nThe encoding length of all data is furthermore polynomial in the encoding length of the\ninitial inequalities. This completes the reduction and proves the NP-hardness of MNBC.\nNote that the NP-hardness of MNBC is independent from the choice of the norm used\nover the state space X . The two results follow:\n\u0010\n\u0011\n00(u ,u )\nC OROLLARY 4.7. P2 0 1 is NP-hard.\n\u0010\n\u0011\n(u ,u )\nT HEOREM 4.8. The two-stage problem P2 0 1 and the generalized T \u2212stage problem (PT (F, Lf , L\u03c1 , x0 , u0 , . . . , uT \u22121 )) are NP-hard.\n5. Relaxation Schemes for the Two-stage Case. The two-stage case with only one\nelement in the set F (u1 ) was proven to be NP-hard in the previous section (except if the car(u ,u )\ndinality of n(u0 ) of F (u0 ) is also equal to 1, in this case (P2 0 1 ) is solvable in polynomial\ntime as we will see later in Corollary 5.3). It is therefore unlikely that one can design an\nalgorithm that optimally solves the general two-stage case in polynomial time (unless P =\nNP). The aim of the min max optimization problem is to obtain a sequence of actions that\nhas a performance guarantee. Therefore solving the optimization problem approximately or\nobtaining an upper bound would be irrelevant. Instead we want to propose some relaxation\nschemes that are computationally more tractable, and that are still leading to lower bounds on\nthe actual return of the sequences of actions.\nThe first relaxation scheme works by dropping some constraints in order to obtain a\nproblem that is solvable in polynomial time. We show that this scheme provides bounds that\nare greater or equal to the CGRL bound introduced in [22]. The second relaxation scheme is\nbased on a Lagrangian relaxation where all constraints are dualized. Solving the Lagrangian\ndual is shown to be a conic-quadratic problem that can be solved in polynomial time using\ninterior-point methods. We also prove that this relaxation scheme always gives better bounds\nthan the first relaxation scheme mentioned above, and consequently, better bounds than [22].\nWe also prove that the bounds computed from these relaxation schemes converge towards the\nactual return of the sequence (u0 , u1 ) when the sample dispersion converges towards zero.\nAs a consequence, the sequences of actions that maximize those bounds also become optimal\nwhen the dispersion decreases towards zero.\n(u ,u )\n\nFrom the previous section, we know that the two-stage problem (P2 0 1 ) can be de0(u ,u )\n00(u ,u )\n0(u ,u )\ncoupled into two subproblems (P2 0 1 ) and (P2 0 1 ), where (P2 0 1 ) can be solved\nstraightforwardly (cf Theorem 4.2). We therefore only focus on relaxing the subproblem\n00(u ,u )\n(P2 0 1 ):\n\u0010\n\n00(u0 ,u1 )\n\nP2\n\nsubject to\n\n\u0011\n\n:\n\nmin\nr\u03021 \u2208 R\nx\u03021 \u2208 X\n\nr\u03021\n\nr\u03021 \u2212 r(u1 ),k1\nx\u03021 \u2212 y (u0 ),k0\n\n2\n\n\u2264 L2\u03c1 x\u03021 \u2212 x(u1 ),k1\n\n2\n\n\u2264 L2f x0 \u2212 x(u0 ),k0\n\n2\n\nn\no\n\u2200k1 \u2208 1, . . . , n(u1 )\n(5.1)\nn\no\n2\n\u2200k0 \u2208 1, . . . , n(u0 ) (5.2)\n\n5.1. The Trust-region Subproblem Relaxation Scheme. An easy way to obtain a relaxation from an optimization problem is to drop some constraints. We therefore suggest to\ndrop all constraints (5.1) but one, indexed by k1 . Similarly we drop all constraints (5.2) but\n00(u ,u )\none, indexed by k0 . The following problem is therefore a relaxation of (P2 0 1 ):\n\n\f14\n\u0010\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n00(u ,u1 )\n\nPT R 0\n\n\u0011\n(k0 , k1 ) :\nmin\nr\u03021 \u2208 R\nx\u03021 \u2208 X\n\nr\u03021\n\nsubject to\nr\u03021 \u2212 r(u1 ),k1\nx\u03021 \u2212 y (u0 ),k0\n\n2\n\n\u2264 L2\u03c1 x\u03021 \u2212 x(u1 ),k1\n2\n\n\u2264 L2f x0 \u2212 x(u0 ),k0\n\n2\n\n,\n\n(5.3)\n\n2\n\n.\n\n(5.4)\n\nWe then have the following theorem:\n00(u ,u ),k ,k\nT HEOREM 5.1. Let us denote by BT R 0 1 0 1 (F) the bound given by the resolution\n00(u0 ,u1 )\nof (PT R\n(k0 , k1 )). We have:\n00(u ,u1 ),k0 ,k1\n\nBT R 0\n\n(F) = r(u1 ),k1 \u2212 L\u03c1 x\u0302\u22171 (k0 , k1 ) \u2212 x(u1 ),k1 ,\n\nwhere\n.\nx\u0302\u22171 (k0 , k1 ) = y (u0 ),k0 + Lf\n\n\u0010\n\u0011\nx0 \u2212 x(u0 ),k0\n(u0 ),k0\n(u1 ),k1\ny\n\u2212\nx\nif y (u0 ),k0 6= x(u1 ),k1\ny (u0 ),k0 \u2212 x(u1 ),k1\n\nand, if y (u0 ),k0 = x(u1 ),k1 , x\u0302\u22171 (k0 , k1 ) can be any point of the sphere centered in y (u0 ),k0 =\nx(u1 ),k1 with radius Lf kx0 \u2212 x(u0 ),k0 k.\nProof. Observe that it consists in the minimization of r\u03021 under one interval constraint for\nr\u03021 where the size of the interval is determined through the constraint (5.4). The problem is\ntherefore equivalent to finding the largest right-hand-side of (5.3) under constraint (5.4). An\nequivalent problem is therefore\nmax\n\nx\u03021 \u2208X\n\nx\u03021 \u2212 x(u1 ),k1\n\n2\n\nsubject to x\u03021 \u2212 y (u0 ),k0 \u2264 Lf x0 \u2212 x(u0 ),k0 .\nThis is the maximization of a quadratic function under a norm constraint. This problem is\nreferred to in the literature as the trust-region subproblem [13]. In our case, the optimal value\nfor x\u03021 - denoted by x\u0302\u22171 (k0 , k1 ) - lies on the same line as x(u1 ),k1 and y (u0 ),k0 , with y (u0 ),k0\nlying in between x(u1 ),k1 and x\u0302\u22171 (k0 , k1 ), the distance between y (u0 ),k0 and x\u0302\u22171 (k0 , k1 ) being\nexactly equal to the distance between x0 and x(u0 ),k0 . An illustration is given in Figure 5.1.\n00(u ,u )\n\nSolving (PT R 0 1 (k0 , k1 )) provides us with a family of relaxations for our initial problem by considering any combination (k0 , k1 ) of two non-relaxed constraints. Taking the\nmaximum out of these lower bounds yields the best possible bound out of this family of re(u ,u )\nlaxations. Finally, if we denote by BT R0 1 (F) the bound made of the sum of the solution\n00(u ,u )\n0(u ,u )\nof (P2 0 1 ) and the maximal Trust-region relaxation of the problem (P2 0 1 ) over all\npossible couples of constraints, we have:\n(u ,u )\nD EFINITION 5.2 (Trust-region Bound BT R0 1 (F)).\n\u2200(u0 , u1 ) \u2208 U 2 ,\n\n(u ,u1 )\n\nBT R0\n\n(F) , r\u0302\u22170 +\n\n00(u ,u1 ),k0 ,k1\n\nmax\nBT R 0\n(u1 )\nk1 \u2208 {1, . . . , n\n}\nk0 \u2208 {1, . . . , n(u0 ) }\n\n(F).\n\n\f15\n\nMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\nF IG . 5.1. A simple geometric algorithm to solve (PT00 R (k0 , k1 )).\n\nNotice that in the case where n(u0 ) and n(u1 ) are both equal to 1, then the trust-region\n(u ,u )\nrelaxation scheme provides an exact solution of the original optimization problem (P2 0 1 ):\nC OROLLARY 5.3.\n\u0012\u001a\n\n2\n\n\u2200(u0 , u1 ) \u2208 U ,\n\nn(u0 ) = 1\nn(u1 ) = 1\n\n\u0013\n\n(u ,u1 )\n\n=\u21d2 BT R0\n\n(u0 ,u1 )\n\n(F) = B2\n\n(F).\n\n5.2. The Lagrangian Relaxation. Another way to obtain a lower bound on the value of\na minimization problem is to consider a Lagrangian relaxation. In this section, we show that\nthe Lagrangian relaxation of the second stage problem is a conic quadratic optimization pro00(u ,u )\ngram. Consider again the optimization problem (P2 0 1 ). If we multiply the constraints\n(5.1) by dual variables \u03bc1 , . . . , \u03bck1 , . . . , \u03bcn(u1 ) \u2265 0 and the constraints (5.2) by dual variables\n\u03bb1 , . . . , \u03bbk0 , . . . , \u03bbn(u0 ) \u2265 0, we obtain the Lagrangian dual:\n\u0010\n\n00(u ,u1 )\n\nPLD 0\n\n\u0011\n\n:\n\nmax\n\u03bb1 , . . . , \u03bbn(u0 ) \u2208 R+\n\u03bc1 , . . . , \u03bcn(u1 ) \u2208 R+\n\nmin\nr\u03021 \u2208 R\nx\u03021 \u2208 X\n+\n\n(u1 )\nnX\n\nr\u03021\n\n\u03bck1\n\n\u0012\u0010\n\nr\u03021 \u2212 r(u1 ),k1\n\n\u00112\n\n\u2212 L2\u03c1 x\u03021 \u2212 x(u1 ),k1\n\n2\n\n\u0013\n\n2\n\n\u0013\n\nk1 =1\n\n+\n\n(u0 )\nnX\n\n\u0012\n\u03bbk0\n\nx\u03021 \u2212 y\n\n(u0 ),k0\n\n2\n\n\u2212\n\nL2f\n\nx0 \u2212 x\n\n(u0 ),k0\n\n.\n\nk0 =1\n\n(5.5)\n00(u ,u )\n\nObserve that the optimal value of (PLD 0 1 ) is known to provide a lower bound on the\n00(u ,u )\noptimal value of (P2 0 1 ) [25].\n\u0010\n\u0011\n00(u ,u )\nT HEOREM 5.4. PLD 0 1 is a conic quadratic program.\n\n\f16\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n\nProof. In (5.5), we can decompose the squared norms and obtain\n\u0010\n\u0011\n00(u ,u )\nPLD 0 1 :\n\uf8eb (u )\n\uf8f6\n\uf8eb\n\uf8f6\n(u1 )\n(u0 )\n1\nnX\nnX\nnX\nmax\nmin r\u030221 \uf8ed\n\u03bck1 \uf8f8 + kx\u03021 k2 \uf8ed\u2212L2\u03c1\n\u03bck1 +\n\u03bbk0 \uf8f8\n\u03bb1 , . . . , \u03bbn(u0 ) \u2208 R+ r\u03021 \u2208 R\nk1 =1\nk1 =1\nk0 =1\n\u03bc1 , . . . , \u03bcn(u1 ) \u2208 R+ x\u03021 \u2208 X\n(5.6)\n\uf8eb\n\uf8f6\n(u1 )\n(u1 )\n(u0 )\nnX\nnX\nE nX\nE\nD\nD\n+ r\u03021 \uf8ed1 \u2212 2\nr(u1 ),k1 \uf8f8 +\n2L2\u03c1 \u03bck1 x\u03021 , x(u1 ),k1 \u2212\n2\u03bbk0 x\u03021 , y (u0 ),k0\nk1 =1\n\nk1 =1\n\nk0 =1\n\n(5.7)\n(u1 )\n\n+\n\nnX\n\n\u03bck1\n\n\u0012\u0010\n\nr(u1 ),k1\n\n\u00112\n\n2\n\n\u2212 L2\u03c1 x(u1 ),k1\n\n\u0013\n\nk1 =1\n\n+\n\n(u0 )\nnX\n\n\u0012\n\u03bbk0\n\ny\n\n2\n\n(u0 ),k0\n\n\u2212\n\nL2f\n\nx\n\n(u0 ),k0\n\n2\n\n\u0013\n\n\u2212 x0\n\n,\n\n(5.8)\n\nk0 =1\n\nwhere ha, bi denotes the inner product of a and b. We observe that the minimization problem\nin r\u03021 and x\u03021 contains a quadratic part (5.6), a linear part (5.7) and a constant part (5.8)\nonce we fix \u03bbk0 and \u03bck1 . In particular, observe that the optimal solution of the minimization\nproblem is \u2212\u221e as soon as the quadratic term is negative, i.e. if :\n(u1 )\nnX\n\n\u03bck1 \u2264 0\n\n(5.9)\n\nk1 =1\n\nor\n\uf8eb\n\uf8ed\u2212L2\u03c1\n\n(u1 )\nnX\n\n\u03bck1 +\n\nk1 =1\n\n(u0 )\nnX\n\n\uf8f6\n\u03bbk0 \uf8f8 \u2264 0.\n\n(5.10)\n\nk0 =1\n\nSince we want to find the maximum of this series of optimization problems, we are only\ninterested in the problems for which the solution is finite. Observe that, since \u03bck1 \u2265 0 for\nall k1 , the inequality (5.9) is never satisfied, unless if \u03bck1 = 0 for all k1 . Therefore in the\nfollowing, we will constraint \u03bbk0 and \u03bck1 to be such that inequalities (5.9) and (5.10) are\nnever satisfied, i.e.:\n(u1 )\nnX\n\n\u03bck1 > 0\n\nk1 =1\n\n\u2212L2\u03c1\n\n(u1 )\nnX\n\nk1 =1\n\n\u03bck1 +\n\n(u0 )\nnX\n\n\u03bbk0 > 0.\n\nk0 =1\n\nOnce that constraint is enforced, we observe that the minimization program is the minimization of a convex quadratic function for which the optimum can be found as a closed form\nformula. In order to simplify the rest of the proof, we introduce some useful notations:\n\n\f17\n\nMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\nD EFINITION 5.5 (Additional Notations).\n\nM,\n\n(u1 )\nnX\n\n\u03bck1\n\n,\n\nL,\n\nk1 =1\n\n(u0 )\nnX\n\n\u03bbk0 ,\n\nk0 =1\n\n\u0010\n\u0011\n(u1 )\nX , x(u1 ),1 * * * x(u1 ),n\n\u03bb , \u03bb1\n\n...\n\n\u03bbn(u0 )\n\n\u0001T\n\n\u0010\n\u0011\n(u0 )\nY , y (u0 ),1 * * * y (u0 ),n\n,\n\n,\n\n\u03bc , \u03bc1\n\n,\n\n...\n\n\u03bcn(u1 )\n\n\u0001T\n\n\u0010\nr\u0304 , r(1)\n\n,\n\n...\n\nr(n\n\n(u1 )\n)\n\n\u0011T\n\n,\n\n\u2200p \u2208 N0 , Ip is an identity matrix of size p.\nThe quadratic form coming from (5.6), (5.7) and (5.8) can be written in the form\nz T Qz + lT z + c\nwith\n\u0012\nz,\n\nx\u03021\nr\u03021\n\n\u0013\n\u2208R\n\nd+1\n\n\u0001\n\u2212M L2\u03c1 + L Id\n\n\u0012\n,\n\nQ,\n\n\u0013\nM\n\n\u0012\n,\n\nl,\n\n2L2\u03c1 X\u03bc \u2212 2Y \u03bb\n1 \u2212 2r\u0304T \u03bc\n\nand the constant term is given by (5.8). The minimum of a convex quadratic form z T Qz +\nlT z + c is known to take the value \u2212 41 lT Q\u22121 l + c. In our case, the inverse of the matrix Q is\n00(u ,u )\ntrivial to compute and we obtain finally that (PLD 0 1 ) can be written as\n\u0010\n\u0011\n00(u ,u )\nPLD 0 1 :\n\nmax\n(u0 )\n\n\u03bb\u2208Rn\n+\n\n+\n\n(u0 )\nnX\n\n(u1 )\n\n,\u03bc\u2208Rn\n+\n\n\u0012\n\u03bbk0\n\ny\n\n\u2212kL2\u03c1 X\u03bc \u2212 Y \u03bbk2\n1 \u2212 2r\u0304T \u03bc\n\u2212\n\u2212M L2\u03c1 + L\n4M\n\n(u0 ),k0\n\n2\n\n\u2212\n\nL2f\n\nx\n\n(u0 ),k0\n\n2\n\n\u00012\n(5.11)\n\n\u0013\n\n\u2212 x0\n\nk0 =1\n\n+\n\n(u1 )\nnX\n\n\u03bck1\n\n\u0012\u0010\n\nr(u1 ),k1\n\n\u00112\n\n\u2212 L2\u03c1 x(u1 ),k1\n\n2\n\n\u0013\n\nk1 =1\n\nsubject to\n\nM >0\nL > M L2\u03c1\n\nThe optimization problem (5.11) is in variables \u03bb1 , . . . , \u03bbn(u0 ) and \u03bc1 , . . . , \u03bcn(u1 ) . Observe that, with our notation, M and L are linear functions of the variables. The objective\nfunction contains linear terms in \u03bb1 , . . . , \u03bbn(u0 ) and \u03bc1 , . . . , \u03bcn(u1 ) as well as a fractionalquadratic function ([5]), i.e. the quotient of a concave quadratic function with a linear function. The constraint is linear. This type of problem is known as a rotated quadratic conic\nproblem and can be formulated as a conic quadratic optimization problem ([5]) that can be\nsolved in polynomial time using interior point methods [5, 37, 9].\n\n\u0013\n\n\f18\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n\nFrom there, we have the following corollary:\nC OROLLARY 5.6. \u2200(u0 , u1 ) \u2208 U 2 ,\n00(u ,u )\nBLD 0 1 (F)\n\nmax\n\n,\n\n(u0 )\n\n\u03bb\u2208Rn\n+\n\n+\n\n(u1 )\n\n,\u03bc\u2208Rn\n+\n\n(u0 )\nnX\n\n\u0012\n\u03bbk0\n\n\u00012\n\u2212kL2\u03c1 X\u03bc \u2212 Y \u03bbk2\n1 \u2212 2r\u0304T \u03bc\n\u2212\n\u2212M L2\u03c1 + L\n4M\ny (u0 ),k0\n\n2\n\n\u2212 L2f x(u0 ),k0 \u2212 x0\n\n2\n\n(5.12)\n\n\u0013\n(5.13)\n\nk0 =1\n\n+\n\n(u1 )\nnX\n\n\u03bck1\n\n\u0012\u0010\n\nr\n\n(u1 ),k1\n\n\u00112\n\n\u2212\n\nL2\u03c1\n\n(u1 ),k1\n\n2\n\n\u0013\n\nx\n\nk1 =1\n\nM >0\n\nsubject to\n\nL > M L2\u03c1\n(u ,u )\n\nIn the following, we denote by BLD0 1 (F) the lower bound made of the sum of the solution\n0(u ,u )\n00(u ,u )\nof (P2 0 1 ) and the relaxation of (P2 0 1 ) computed from the Lagrangian relaxation:\n(u ,u )\nD EFINITION 5.7 (Lagrangian Relaxation Bound BLD0 1 (F)).\n(u ,u1 )\n\n\u2200(u0 , u1 ) \u2208 U 2 ,\n\nBLD0\n\n00(u ,u1 )\n\n(F) , r\u0302\u22170 + BLD 0\n\n(F)\n\n(5.14)\n\n5.3. Comparing the Bounds. The CGRL algorithm proposed in [21, 22] for addressing\nthe min max problem uses the procedure described in [20] for computing a lower bound on\nthe return of a policy given a sample of trajectories. More specifically, for a given sequence\n(u0 , u1 ) \u2208 U 2 , the program (PT (F, Lf , L\u03c1 , x0 , u0 , . . . , uT \u22121 )) is replaced by a lower bound\n(u0 ,u1 )\nBCGRL\n(F). We may \u0010\nnow wonder\n\u0011 how this bound compares in the two-stage case with\n(u ,u1 )\n\nthe two new bounds of P2 0\nLagrangian relaxation bound.\n\nthat we have proposed: the trust-region bound and the\n\n5.3.1. Trust-region Versus CGRL. We first recall the definition of the CGRL bound in\nthe two-stage case.\n(u0 ,u1 )\nD EFINITION 5.8 (CGRL Bound BCGRL\n(F)). \u2200(u0 , u1 ) \u2208 U 2 ,\n(u ,u )\n\n0\n1\nBCGRL\n(F) ,\n\nmax\nr(u0 ),k0 \u2212 L\u03c1 (1 + Lf ) x(u0 ),k0 \u2212 x0\nk1 \u2208 {1, . . . , n(u1 ) }\nk0 \u2208 {1, . . . , n(u0 ) }\n+r(u1 ),k1 \u2212 L\u03c1 y (u0 ),k0 \u2212 x(u1 ),k1 .\n\nThe following theorem shows that the Trust-region bound is always greater than or equal to\nthe CGRL bound.\nT HEOREM 5.9.\n\u2200(u0 , u1 ) \u2208 U 2 ,\n\n(u ,u )\n\n(u ,u1 )\n\n0\n1\n(F) \u2264 BT R0\nBCGRL\n\n(F) .\n\n\f19\n\nMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\n\b\n\b\nProof. Let k0\u2217 \u2208 1, . . . , n(u0 ) and k1\u2217 \u2208 1, . . . , n(u1 ) be such that\n\u2217\n\n\u2217\n\n\u2217\n\n\u2217\n\n(u ,u )\n\n\u2217\n\n0\n1\nBCGRL\n(F) = r(u0 ),k0 \u2212 L\u03c1 (1 + Lf ) x(u0 ),k0 \u2212 x0 + r(u1 ),k1 \u2212 L\u03c1 y (u0 ),k0 \u2212 x(u1 ),k1 .\n\n00(u ,u ),k\u2217 ,k\u2217\n\n00(u ,u )\n\nNow, let us consider the solution BT R 0 1 0 1 (F) of the problem (PT R 0 1 (k0\u2217 , k1\u2217 )), and\n\u2217 \u2217\nlet us denote by B (u0 ,u1 ),k0 ,k1 the bound obtained if, in the definition of the value of r\u03020\u2217 given\nin Corollary 4.3, we fix the value of k00 to k0\u2217 instead of maximizing over all possible k00 :\n\u2217\n\n\u2217\n\n00(u ,u1 ),k0\u2217 ,k1\u2217\n\n\u2217\n\n\u2217\n\nB (u0 ,u1 ),k0 ,k1 = r(u0 ),k0 \u2212 L\u03c1 x0 \u2212 x(u0 ),k0 + BT R 0\n\u2217\n\n(F)\n0(u0 ,u1 )\n\n\u2217\n\nSince r(u0 ),k0 \u2212 L\u03c1 x0 \u2212 x(u0 ),k0 is smaller or equal to the solution r\u0302\u22170 of (P2\nhas:\n(u ,u1 ),k0\u2217 ,k1\u2217\n\nBT R0\n\n\u2217\n\n\u2217\n\n(F) \u2265 B (u0 ,u1 ),k0 ,k1 .\n\n), one\n\n(5.15)\n\nNow, observe that:\n\u2217\n\n\u2217\n\n\u2217\n\n(u ,u )\n\n\u2217\n\n\u2217\n\n0\n1\nB (u0 ,u1 ),k0 ,k1 \u2212 BCGRL\n(F) = L\u03c1 Lf x(u0 ),k0 \u2212 x0 + L\u03c1 y (u0 ),k0 \u2212 x(u1 ),k1\n\u2217\n\n\u2212 L\u03c1 x\u0302\u22171 (k0\u2217 , k1\u2217 ) \u2212 x(u1 ),k1\n\n.\n\n(5.16)\n\n\u2217\n\n\u2217\n\nBy construction, x\u0302\u22171 (k0\u2217 , k1\u2217 ) lies on the same line as y (u0 ),k0 and x(u1 ),k1 (see Figure 5.1).\nFurthermore\n\u2217\n\n\u2217\n\n\u2217\n\n\u2217\n\nx\u0302\u22171 (k0\u2217 , k1\u2217 ) \u2212 x(u1 ),k1 = x\u0302\u22171 (k0\u2217 , k1\u2217 ) \u2212 y (u0 ),k0 + y (u0 ),k0 \u2212 x(u1 ),k1 .\n\n(5.17)\n\nUsing (5.17) in (5.16) yields\n\u2217\n\n(u ,u ),k\u2217 ,k\u2217\n\n\u2217\n\n\u2217\n\n0\n1\n0\n1\nB (u0 ,u1 ),k0 ,k1 \u2212 BCGRL\n(F) = L\u03c1 Lf x(u0 ),k0 \u2212 x0\n\u0011\n\u0010\n\u2217\n\u2217\n\u2217\n\u2217\n\u2217\n+L\u03c1 y (u0 ),k0 \u2212 x(u1 ),k1 \u2212 x\u0302\u22171 (k0\u2217 , k1\u2217 ) \u2212 y (u0 ),k0 \u2212 y (u0 ),k0 \u2212 x(u1 ),k1\n\u0010\n\u0011\n\u2217\n\u2217\n= L\u03c1 Lf x(u0 ),k0 \u2212 x0 \u2212 x\u0302\u22171 (k0\u2217 , k1\u2217 ) \u2212 y (u0 ),k0 .\n(5.18)\n\nBy construction, Equation (5.18) is equal to 0 (see Figure 5.1), which proves the equality of\nthe two bounds:\n\u2217\n\n\u2217\n\n(u ,u )\n\n0\n1\nB (u0 ,u1 ),k0 ,k1 = BCGRL\n(F) .\n\n(5.19)\n\nThe final result is given by combining Equations (5.15) and (5.19).\nFrom the proof, one can observe that the gap between the CGRL bound and the Trust0(u ,u )\nregion bound is only due to the resolution of (P2 0 1 ). Note that in the case where k0\u2217 also\n(u0 ),k0\nbelongs to the set arg max r\n\u2212 L\u03c1 x(u0 ),k0 \u2212 x0 , then the bounds are equal.\nk0 \u2208{1,...,n(u0 ) }\n\nThe two corollaries follow:\n\b\n\b\nC OROLLARY 5.10. Let (u0 , u1 ) \u2208 U 2 . Let k0\u2217 \u2208 1, . . . , n(u0 ) and k1\u2217 \u2208 1, . . . , n(u1 )\nbe such that:\n(u ,u )\n\n\u2217\n\n\u2217\n\n\u2217\n\n\u2217\n\n\u2217\n\n0\n1\nBCGRL\n(F) = r(u0 ),k0 \u2212 L\u03c1 (1 + Lf ) x(u0 ),k0 \u2212 x0 + r(u1 ),k1 \u2212 L\u03c1 y (u0 ),k0 \u2212 x(u1 ),k1 .\n\n\f20\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n\nThen,\n!\nk0\u2217 \u2208\n\nr(u0 ),k0 \u2212 L\u03c1 x(u0 ),k0 \u2212 x0\n\narg max\nk0\n\n\u2208{1,...,n(u0 ) }\n\n(u ,u )\n\n(u ,u1 )\n\n0\n1\n=\u21d2 BCGRL\n(F) = BT R0\n\n(F) .\n\nC OROLLARY 5.11.\n\u0010\n\n\u2200(u0 , u1 ) \u2208 U 2 ,\n\n\u0011\n(u0 ,u1 )\n(u ,u )\nn(u0 ) = 1 =\u21d2 BCGRL\n(F) = BT R0 1 (F) .\n\n5.3.2. Lagrangian Relaxation Versus Trust-region. In this section, we prove that the\nlower bound obtained with the Lagrangian relaxation is always greater than or equal to the\nTrust-region bound. To prove this result, we give a preliminary\nlemma:\n\b\n\b\nL EMMA 5.12. Let (u0 ,\u0010u1 ) \u2208 U 2 and (k0\u0011, k1 ) \u2208 1, . . . , n(u0 ) \u00d7 1, . . . , n(u1 ) .\n00(u ,u1 )\n\nConsider again the problem PT R 0\nthe two defined by (k0 , k1 ):\n\u0010\n\u0011\n00(u ,u )\nPT R 0 1 (k0 , k1 ) :\n\nmin\nr\u03021 \u2208 R\nx\u03021 \u2208 X\nsubject to\n\n(k0 , k1 ) where all constraints are dropped except\n\nr\u03021\n\nr\u03021 \u2212 r(u1 ),k1\n\n2\n\nx\u03021 \u2212 y (u0 ),k0\n\n\u2264 L2\u03c1 x\u03021 \u2212 x(u1 ),k1\n2\n\n\u2264 L2f x0 \u2212 x(u0 ),k0\n\n2\n\n2\n\n.\n\n\u0010\n\u0011\n00(u ,u )\nThen, the Lagrangian relaxation of PT R 0 1 (k0 , k1 ) leads to a bound denoted by\n00(u ,u1 ),k0 ,k1\n\nBLD 0\n\n00(u ,u1 ),k0 ,k1\n\n(F) which is equal to the Trust-region bound BT R 0\n00(u ,u1 ),k0 ,k1\n\nBLD 0\n\n00(u ,u1 ),k0 ,k1\n\n(F) = BT R 0\n\n(F), i.e.\n\n(F) .\n\nProofs of this lemma can be found in [3] and [8], but we also provide in Appendix A a\nproof in our particular case. We then have the following theorem:\nT HEOREM 5.13.\n\u2200 (u0 , u1 ) \u2208 U 2 ,\n\n(u ,u1 )\n\nBT R0\n\n(u ,u1 )\n\n(F) \u2264 BLD0\n\n(F).\n\n\b\n\b\nProof. Let (u0 , u1 ) \u2208 U 2 . Let (k0\u2217 , k1\u2217 ) \u2208 1, . . . , n(u0 ) \u00d7 1, . . . , n(u1 ) be such that:\n(u ,u1 )\n\nBT R0\n\n00(u ,u1 ),k0\u2217 ,k1\u2217\n\n(F) = r\u0302\u22170 + BT R 0\n\n(F).\n\nConsidering (k0 , k1 ) = (k0\u2217 , k1\u2217 ) in Lemma 5.12, we have:\n(u ,u1 )\n\nBT R0\n\n00(u ,u1 ),k0\u2217 ,k1\u2217\n\n(F) = r\u0302\u22170 + BLD 0\n\n(F)\n\n(5.20)\n00(u ,u )\n\nThen, one can observe that the Lagrangian relaxation of the problem (PT R 0 1 (k0\u2217 , k1\u2217 ))\n00(u ,u ),k\u2217 ,k\u2217\n00(u ,u )\n- from which BLD 0 1 0 1 (F) is computed - is also a relaxation of the problem (PLD 0 1 )\n\n\f21\n\nMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\nfor which all the dual variables corresponding\nto constraints that are not related\nwith the sys\u2217\n\u2217\n\u2217\u0001\n\u2217\n\u2217\n\u2217\u0001\ntem transitions x(u0 ),k0 , r(u0 ),k0 , y (u0 ),k0 and x(u1 ),k1 , r(u1 ),k1 , y (u1 ),k1 would be forced\nto zero, i.e.\n\u00012\n\u2212kL2\u03c1 X\u03bc \u2212 Y \u03bbk2\n1 \u2212 2r\u0304T \u03bc\n00(u0 ,u1 ),k0\u2217 ,k1\u2217\n\u2212\nBLD\n(F) =\nmax\n(u )\n(u )\n\u2212M L2\u03c1 + L\n4M\n\u03bb\u2208Rn 0 ,\u03bc\u2208Rn 1\n+\n\n+\n\n+\n\n(u0 )\nnX\n\n\u0012\ny\n\n\u03bbk0\n\n2\n\n(u0 ),k0\n\n\u2212\n\nL2f\n\nx\n\n(u0 ),k0\n\n2\n\n\u0013\n\n\u2212 x\u03020\n\nk0 =1\n\n+\n\n(u1 )\nnX\n\n\u03bck1\n\n\u0012\u0010\n\nr(u1 ),k1\n\n\u00112\n\n\u2212 L2\u03c1 x(u1 ),k1\n\n2\n\n\u0013\n\nk1 =1\n\nM >0,\n\nsubject to\n\nL > M L2\u03c1 ,\nn\no\n\u03bbk0 = 0 if k0 6= k0\u2217 , \u2200k0 \u2208 1, . . . , n(u0 ) ,\nn\no\n\u03bck1 = 0 if k1 6= k1\u2217 , \u2200k1 \u2208 1, . . . , n(u1 ) .\nWe therefore have:\n00(u ,u1 ),k0\u2217 ,k1\u2217\n\nBLD 0\n\n00(u ,u1 )\n\n(F) \u2264 BLD 0\n\n(u ,u1 )\n\nBy definition of the Lagrangian relaxation bound BLD0\n(u ,u1 )\n\nBLD0\n\n(5.21)\n\n(F), we have:\n\n00(u ,u1 )\n\n(F) = r\u0302\u22170 + BLD 0\n\n(F) .\n\n(F)\n\n(5.22)\n\nEquations (5.20), (5.21) and (5.22) finally give:\n(u ,u1 )\n\nBT R0\n\n(u ,u1 )\n\n(F 0 ) = BLD0\n\n(F) .\n\n5.3.3. Bounds Inequalities: Summary. We summarize in the following theorem all the\nresults that were obtained in the previous sections.\nT HEOREM 5.14. \u2200 (u0 , u1 ) \u2208 U 2 ,\n(u ,u )\n\n(u ,u1 )\n\n0\n1\nBCGRL\n(F) \u2264 BT R0\n\n(u ,u1 )\n\n(F) \u2264 BLD0\n\n(u0 ,u1 )\n\n(F) \u2264 B2\n\n(u0 ,u1 )\n\n(F) \u2264 J2\n\n.\n\nProof. Let (u0 , u1 ) \u2208 U 2 . The inequality\n(u ,u )\n\n(u ,u1 )\n\n0\n1\nBCGRL\n(F) \u2264 BT R0\n\n(u ,u1 )\n\n(F) \u2264 BLD0\n\n(F)\n\n(5.23)\n\nis a straightforward consequence of Theorems 5.9 and 5.13. The inequality\n(u ,u1 )\n\nBLD0\n\n(u0 ,u1 )\n\n(F) \u2264 B2\n\n(F)\n\n(5.24)\n\nis a property of the Lagrangian relaxation, and the inequality\n(u0 ,u1 )\n\nB2\n\n(u0 ,u1 )\n\n(F) \u2264 J2\n\nis derived from the formalization of the min max generalization problem introduced in [22].\n\n\f22\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n\n5.4. Convergence Properties. We finally propose to analyze the convergence of the\nbounds, as well as the sequences of actions that lead to the maximization of the bounds, when\nthe sample dispersion decreases towards zero. We assume in this section that the state space\nX is bounded:\n\u2203CX > 0 : \u2200(x, x0 ) \u2208 X 2 ,\n\nkx \u2212 x0 k \u2264 CX .\n\nLet us now introduce the sample dispersion:\nD EFINITION 5.15 (Sample Dispersion). Since X is bounded, one has:\n\u2203 \u03b1 > 0 : \u2200u \u2208 U ,\n\nsup\n\nmin\n\nk\u2208{1,...,n(u) }\n\nx\u2208X\n\nx(u),k \u2212 x \u2264 \u03b1 .\n\n(5.25)\n\nThe smallest \u03b1 which satisfies equation (5.25) is named the sample dispersion and is denoted\nby \u03b1\u2217 (F). Intuitively, the sample dispersion \u03b1\u2217 (F) can be seen as the radius of the largest\nnon-visited state space area.\n5.4.1. Bounds. We analyze in this subsection the tightness of the Trust-region and the\nLagrangian relaxation lower bounds as a function of the sample dispersion.\nL EMMA 5.16.\nn\no\n(u0 ,u1 )\n(u ,u )\n(u ,u )\n\u2203 C > 0 : \u2200(u0 , u1 ) \u2208 U 2 , \u2200B (u0 ,u1 ) (F) \u2208 BCGRL\n(F), BT R0 1 (F), BLD0 1 (F) ,\n(u0 ,u1 )\n\nJ2\n\n\u2212 B (u0 ,u1 ) (F) \u2264 C\u03b1\u2217 (F).\n(u ,u )\n\n0\n1\nProof. The proof for the case where B (u0 ,u1 ) (F) = BCGRL\n(F) is given in [21]. According to Theorem 5.14, one has:\n\n\u2200 (u0 , u1 ) \u2208 U 2 ,\n\n(u ,u )\n\n(u ,u1 )\n\n0\n1\nBCGRL\n(F) \u2264 BT R0\n\n(u ,u1 )\n\n(F) \u2264 BLD0\n\n(u0 ,u1 )\n\n(F) \u2264 J2\n\n,\n\nwhich ends the proof.\nWe therefore have the following theorem:\nT HEOREM 5.17.\no\nn\n(u ,u )\n(u ,u )\n(u0 ,u1 )\n(F), BT R0 1 (F), BLD0 1 (F) ,\n\u2200(u0 , u1 ) \u2208 U 2 , \u2200B (u0 ,u1) (F) \u2208 BCGRL\n(u0 ,u1 )\n\nlim\n\n\u03b1\u2217 (F )\u21920\n\nJ2\n\n\u2212 B (u0 ,u1 ) (F) = 0 .\n\n(\u2217)\n\n5.4.2. Bound-optimal Sequences of Actions. In the following, we denote by BCGRL (F)\n(\u2217)\n(\u2217)\n(resp. BT R (F) and BLD (F) ) the maximal CGRL bound (resp. the maximal Trust-region\nbound and maximal Lagrangian relaxation bound) over the set of all possible sequences of\nactions, i.e.,\nD EFINITION 5.18 (Maximal Bounds).\n(\u2217)\n\nBCGRL (F) ,\n(\u2217)\n\nBT R (F) ,\n(\u2217)\n\nBLD (F) ,\n\n(u ,u )\n\nmax\n\n0\n1\nBCGRL\n(F) ,\n\nmax\n\nBT R0\n\nmax\n\nBLD0\n\n(u0 ,u1 )\u2208U 2\n(u0 ,u1 )\u2208U 2\n(u0 ,u1 )\u2208U 2\n\n(u ,u1 )\n\n(F) ,\n\n(u ,u1 )\n\n(F) .\n\n\fMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\nCGRL\n\nTR\n\n23\n\nLD\n\nWe also denote by (u0 , u1 )F\n(resp. (u0 , u1 )F and (u0 , u1 )F ) three sequences of\nactions that maximize the bounds:\nD EFINITION 5.19 (Bound-optimal Sequences of Actions).\no\nn\n(u0 ,u1 )\n(\u2217)\nCGRL\n(u0 , u1 )F\n\u2208 (u0 , u1 ) \u2208 U 2 |BCGRL\n(F) = BCGRL (F)\nn\no\n(u ,u )\n(\u2217)\nTR\n(u0 , u1 )F \u2208 (u0 , u1 ) \u2208 U 2 |BT R0 1 (F) = BT R (F)\nn\no\n(u ,u )\n(\u2217)\nLD\n(u0 , u1 )F \u2208 (u0 , u1 ) \u2208 U 2 |BLD0 1 (F) = BLD (F)\nWe finally give in this section a last theorem that shows the convergence of the sequences\nCGRL\nTR\nLD\nof actions (u0 , u1 )F\n, (u0 , u1 )F and (u0 , u1 )F towards optimal sequences of actions\n- i.e. sequences of actions that lead to an optimal return J2\u2217 - when the sample dispersion\n\u03b1\u2217 (F) decreases towards zero.\nT HEOREM 5.20. Let J\u2217 be the set of optimal two-stage sequences of actions:\nn\no\n(u ,u )\nJ\u22172 , (u0 , u1 ) \u2208 U 2 |J2 0 1 = J2\u2217 ,\nand let us suppose that J\u22172 6= U 2 (if J\u22172 = U 2 , the search for an optimal sequence of actions\nis indeed trivial). We define\nn\no\n(u ,u )\n\u000f,\nmin 2 \u2217 J2\u2217 \u2212 J2 0 1 .\n(u0 ,u1 )\u2208U \\J2\n\nn\no\nCGRL\nTR\nLD\nThen, \u2200 (\u01690 , \u01691 )F \u2208 (u0 , u1 )F\n, (u0 , u1 )F , (u0 , u1 )F ,\n\u0010\n\n\u0011\nC\u03b1\u2217 (F) < \u000f =\u21d2 (\u01690 , \u01691 )F \u2208 J\u22172 .\n\n(5.26)\n\n\u2217\nProof. Let us\nn prove the theorem by contradiction. Letous assume that C\u03b1 (F) < \u000f. Let\n(u\n,u\n)\n(u\n,u\n)\n(u\n,u\n)\n0\n1\n0\n1\n0\n1\nB (u0 ,u1) (F) \u2208 BCGRL (F), BT R\n(F), BLD (F) , and let (\u01690 , \u01691 )F be a sequence\nsuch that\n\n(\u01690 , \u01691 )F \u2208 arg max B (u0 ,u1 ) (F)\n(u0 ,u1 )\u2208U 2\n\nand let us assume that (\u01690 , \u01691 )F is not optimal. This implies that\n(\u01690 ,\u01691 )F\n\nJ2\n\n\u2264 J2\u2217 \u2212 \u000f .\n\nNow, let us consider a sequence (u\u22170 , u\u22171 ) \u2208 J\u22172 . Then\n\u2217\n(u\u2217\n0 ,u1 )\n\nJ2\n\u2217\n\n= J2\u2217 .\n\n\u2217\n\nThe lower bound B (u0 ,u1 ) (F) satisfies the relationship\n\u2217\n\n\u2217\n\nJ2\u2217 \u2212 B (u0 ,u1 ) (F) \u2264 C\u03b1\u2217 (F).\nKnowing that C\u03b1\u2217 (F) < \u000f, we have\n\u2217\n\n\u2217\n\nB (u0 ,u1 ) (F) > J2\u2217 \u2212 \u000f.\n\n\f24\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n\nSince\n(\u01690 ,\u01691 )F\n\nJ2\n\n\u2265 B (\u01690 ,\u01691 )F (F),\n\nwe have\n\u2217\n\n\u2217\n\nB (u0 ,u1 ) (F) > B (\u01690 ,\u01691 )F (F)\nwhich contradicts the fact that (\u01690 , \u01691 )F belongs to the set arg max B (u0 ,u1 ) (F). This ends\n(u0 ,u1 )\u2208U 2\n\nthe proof.\n5.4.3. Remark. It is important to notice that the tightness of the bounds resulting from\nthe relaxation schemes proposed in this paper does not depend explicitly on the sample dispersion (which suffers from the curse of dimensionality), but depends rather on the initial\nstate for which the sequence of actions is computed and on the local concentration of samples\naround the actual (unknown) trajectories of the system. Therefore, this may lead to cases\nwhere the bounds are tight for some specific initial states, even if the sample does not cover\nevery area of the state space well enough.\n6. Experimental Results. We provide some experimental results to illustrate the theoretical properties of the CGRL, Trust-region and Lagrangian relaxation bounds given below.\nWe compare the tightness of the bounds, as well as the performances of the bound-optimal\nsequences of actions, on an academic benchmark.\n6.1. Benchmark. We consider a linear benchmark whose dynamics is defined as follows :\n\u2200(x, u) \u2208 X \u00d7 U,\n\nf (x, u) = x + 3.1416 \u00d7 u \u00d7 1d ,\n\nwhere 1d \u2208 Rd denotes a d\u2212dimensional vector for which each component is equal to 1. The\nreward function is defined as follows:\n\u2200(x, u) \u2208 X \u00d7 U,\n\n\u03c1(x, u) =\n\nd\nX\n\nx(i) ,\n\ni=1\n\nwhere x(i) denotes the i\u2212th component of x. The state space X is included in Rd and\nthe finite action space is equal to U =\u221a{0, 0.1}. The system dynamics f is 1\u2212Lipschitz\ncontinuous and the reward function is d\u2212Lipschitz continuous. The initial state of the\nsystem is set to\nx0 = 0.5772 \u00d7 1d .\nThe dimension d of the state space is set to d = 2. In all our experiments, the computation\nof the Lagrangian relaxations, which requires to solve a conic-quadratic program, are done\nusing SeDuMi [47].\n6.2. Protocol and Results.\n6.2.1. Typical Run. For different cardinalities ci = 2i2 , i = 1, . . . , 15, we generate a\nsample of transitions Fci using a grid over [0, 1]d \u00d7 U, as follows: \u2200u \u2208 U,\n\u001a\u0012\u0014\n\u0015\n\u0012\u0014\n\u0015 \u0013 \u0012\u0014\n\u0015 \u0013\u0013\n\u001b\ni1 i2\ni1 i2\ni1 i2\n2\n(u)\nFci =\n;\n, u, \u03c1\n;\n,u ,f\n;\n,u\n(i1 , i2 ) \u2208 {1, . . . , i}\ni i\ni i\ni i\n\n\fMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\n(\u2217)\n\nFci\n\n(\u2217)\n\n25\n\n(\u2217)\n\nF IG . 6.1. Bounds BCGRL (Fci ), BT R (Fci ) and BLD (Fci ) computed from all samples of transitions\ni \u2208 {1, . . . , 15} of cardinality ci = 2i2 .\n\nR\nLD\nF IG . 6.2. Returns of the sequences (u0 , u1 )CGRL\n, (u0 , u1 )T\nFc\nFc and (u0 , u1 )Fc computed from all samples\ni\n\nof transitions Fci\n\ni \u2208 {1, . . . , 15} of cardinality ci = 2i2 .\n\ni\n\nand\nFci = Fc(0)\n\u222a Fc(.1)\ni\ni\n\ni\n\n\f26\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n(\u2217)\n\nWe report in Figure 6.1 the values of the maximal CGRL bound BCGRL (Fci ), the maximal\n(\u2217)\n(\u2217)\nTrust-region bound BT R (Fci ) and the maximal Lagrangian relaxation bound BLD (Fci ) as\na function of the cardinality ci of the samples of transitions Fci . We also report in Figure\n(u0 ,u1 )CGRL\nFc\n\nR\n(u0 ,u1 )T\nFc\n\n(u0 ,u1 )LD\nFc\n\ni\ni\n6.2 the returns J2\n, J2\nand J2\nCGRL\nTR\nLD\nactions (u0 , u1 )Fc\n, (u0 , u1 )Fc and (u0 , u1 )Fc .\ni\n\ni\n\ni\n\nof the bound-optimal sequences of\n\ni\n\nAs expected, we observe that the bound computed with the Lagrangian relaxation is\nalways greater or equal to the Trust-region bound, which is also greater or equal to the CGRL\nbound as predicted by Theorem 5.14. On the other hand, no difference were observed in\nterms of return of the bound-optimal sequences of actions.\n\nF IG . 6.3. Average values ACGRL (ci ), AT R (ci ) and ALD (ci ) of the bounds computed from all samples of\ntransitions Fci ,k k \u2208 {1, . . . , 100} of cardinality ci = 2i2 .\n\n6.2.2. Uniformly Drawn Samples of Transitions. In order to observe the influence of\nthe dispersion of the state-action points of the transitions on the quality of the bounds, we\npropose the following protocol. For each cardinality ci = 2i2 , i = 1, . . . , 15, we generate\n100 samples of transitions Fci ,1 , . . . , Fci ,100 using a uniform probability distribution over the\nspace [0, 1]d \u00d7 U. For each sample of transition Fci ,k i \u2208 {1, . . . , 15}, k \u2208 {1, . . . , 100},\n(\u2217)\nwe compute the maximal CGRL bound BCGRL (Fci ,k ), the maximal Trust-region bound\n(\u2217)\n(\u2217)\nBT R (Fci ,k ) and the maximal Lagrangian relaxation bound BLD (Fci ,k ). We then compute\n\n\f27\n\nMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\nF IG . 6.4. Average values JCGRL , JT R and JLD of the return of the bound-optimal sequences of actions\ncomputed from all samples of transitions Fci ,k k \u2208 {1, . . . , 100} of cardinality ci = 2i2 .\n\nthe average values of the maximal CGRL, Trust-region and Lagrangian relaxation bounds :\n100\n\n\u2200i \u2208 {1, . . . , 15},\n\nACGRL (ci ) =\n\n1 X (\u2217)\nBCGRL (Fci ,k )\n100\nk=1\n100\n\n1 X (\u2217)\nBT R (Fci ,k )\nAT R (ci ) =\n100\nk=1\n100\n\nALD (ci ) =\n\n1 X (\u2217)\nBLD (Fci ,k )\n100\nk=1\n\nand we report in Figure 6.3 the values ACGRL (ci ) (resp. AT R (ci ) and ALD (ci )) as a function of the cardinality ci of the samples of transitions. We also report in Figure 6.4 the\nCGRL\nTR\naverage returns of the bound-optimal sequences of actions (u0 , u1 )Fc ,k , (u0 , u1 )Fc ,k and\nLD\n\n(u0 , u1 )Fc\n\ni\n\ni\n\ni\n\n:\n,k\n100\n\n\u2200i \u2208 {1, . . . , 15},\n\nJCGRL (ci ) =\n\nCGRL\n\n1 X (u0 ,u1 )Fci ,k\nJ2\n100\nk=1\n100\n\nJT R (ci ) =\n\nTR\n\n1 X (u0 ,u1 )Fci ,k\nJ2\n100\nk=1\n100\n\nJLD (ci ) =\n\nLD\n\n1 X (u0 ,u1 )Fci ,k\nJ2\n.\n100\nk=1\n\nas a function of the cardinality ci of the samples of transitions.\n\n\f28\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n\nWe observe that, on average, the Lagrangian relaxation bound is much tighter that the\nTrust-region and the CGRL bounds. The CGRL bound and the Trust-region bound remain\nvery close on average, which illustrates, in a sense, Corollary 5.10. Moreover, we also observe\nLD\nthat the bound-optimal sequences of actions (u0 , u1 )Fc ,k better perform on average.\ni\n\n7. Conclusions. We have considered in this paper the problem of computing min max\npolicies for deterministic, Lipschitz continuous batch mode reinforcement learning. First,\nwe have shown that this min max problem is NP-hard. Afterwards, we have proposed for the\ntwo-stage case two relaxation schemes. Both have been extensively studied and, in particular,\nthey have been shown to perform better than the CGRL algorithm that has been introduced\nearlier to address this min-max generalization problem.\nA natural extension of this work would be to investigate how the proposed relaxation\nschemes could be extended to the T -stage (T \u2265 3) framework. Lipschitz continuity assumptions are common in a batch mode reinforcement learning setting, but one could imagine developing min max strategies in other types of environments that are not necessarily\nLipschitzian, or even not continuous. Additionnaly, it would also be interesting to extend\nthe resolution schemes proposed in this paper to problems with very large/continuous action\nspaces.\nAcknowledgements. Raphael Fonteneau is a Post-doctoral fellow of the FRS-FNRS\n(Funds for Scientific Research). This paper presents research results of the Belgian Network\nDYSCO (Dynamical Systems, Control and Optimization) funded by the Interuniversity Attraction Poles Programme, initiated by the Belgian State, Science Policy Office. The authors\nthank Yurii Nesterov for pointing out the idea of using Lagrangian relaxation. The scientific\nresponsibility rests with its authors.\nAppendix A. Proof of Lemma 5.12.\n\u0001\nProof. For conciseness, we denote x(u0 ),k0 , r(u0 ),k0 , y (u0 ),k0 ( resp.\n\u0001\n\u0001\n\u0001\nx(u1 ),k1 , r(u1 ),k1 , y (u1 ),k1 ) by x0 , r0 , y 0 (resp. x1 , r1 , y 1 ), and \u03bb1 (resp. \u03bc1 ) by \u03bb\n(resp. \u03bc). We assume that x0 6= x0 and x1 6= y 0 otherwise the problem is trivial.\n\u2022 Trust-region solution.\nAccording to Definition 5.2, we have:\n00(u ,u1 ),k0 ,k1\n\nBT R 0\n\n(F) = r1 \u2212 L\u03c1 x\u0302\u22171 (k0 , k1 ) \u2212 x1 ,\n\nwhere\nx\u0302\u22171 (k0 , k1 ) = y 0 + Lf\n\n\u0001\nx0 \u2212 x0\ny 0 \u2212 x1 ,\n0\n1\nky \u2212 x k\n\nwhich writes\n00(u ,u1 ),k0 ,k1\n\nBT R 0\n\n\u0001\nx0 \u2212 x0\ny 0 \u2212 x1 \u2212 x1 ,\n0\n1\nky \u2212 x k\n!\nx0 \u2212 x0\n0\n1\ny \u2212x\n1 + Lf 0\nky \u2212 x1 k\n\n(F) = r1 \u2212 L\u03c1 y 0 + Lf\n= r1 \u2212 L\u03c1\n\n= r1 \u2212 L\u03c1 y 0 \u2212 x1 \u2212 L\u03c1 Lf x0 \u2212 x0\n\u2022 Lagrangian relaxation based solution.\n\n\f29\n\nMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\nAccording to Equation (5.11), we can write:\n00(u ,u ),k ,k\nBLD 0 1 0 1 (F)\n\n=\n\nmax\n\n\u03bb\u2208R+ ,\u03bc\u2208R+\n\n+\u03bb\n\n\u0010\n\ny0\n\n2\n\n\u2212 L2f x0 \u2212 x0\n\n2\n\n\u00012\n1 \u2212 2r1 \u03bc\n\u2212\n4\u03bc\n\u0011\n\u0010 \u00012\n2\n+ \u03bc r1 \u2212 L2\u03c1 x1\n\n\u2212 L2\u03c1 x1 \u03bc \u2212 y 0 \u03bb\n\u2212\u03bcL2\u03c1 + \u03bb\n\n2\n\n\u0011\n\nsubject to\n\u03bc>0\n\u03bb > \u03bcL2\u03c1\nWe denote by L(\u03bb, \u03bc) the quantity:\n\u00012\n2\n\u0010\n\u2212 L2\u03c1 x1 \u03bc \u2212 y 0 \u03bb\n1 \u2212 2r1 \u03bc\ny0\n\u2212\n+\n\u03bb\nL(\u03bb, \u03bc) =\n\u2212\u03bcL2\u03c1 + \u03bb\n4\u03bc\n\u0011\n\u0010 \u00012\n2\n+\u03bc r1 \u2212 L2\u03c1 x1\n\n2\n\n\u2212 L2f x0 \u2212 x0\n\n00(u ,u1 )\n\nLet \u03bb and \u03bc be such that \u03bb > \u03bcL2\u03c1 . Since the Trust-region solution to (PT R 0\noptimal, and by property of the Lagrangian relaxation [25], one has:\n00(u ,u1 ),k0 ,k1\n\nL(\u03bb, \u03bc) \u2264 BT R 0\n\n(F) .\n\n2\n\n\u0011\n\n(k0 , k1 )) is\n\n(A.1)\n\nIn order to prove the lemma, it is therefore sufficient to determine two values \u03bb0 and \u03bc0 such\nthat the inequality (A.1) is an equality. By differentiating L(\u03bb, \u03bc), we obtain, after a long\ncalculation (that we omit here):\n\uf8eb\uf8f1\n\uf8f6\n\u2202L(\u03bb,\u03bc)\n(\n\uf8f4\n\uf8f2 \u2202\u03bb = 0\n\uf8ec \u2202L(\u03bb,\u03bc)\n\uf8f7\n= 0 \uf8f8 =\u21d2\n\uf8ed\n\u2202\u03bc\n\uf8f4\n\u03bc=\n\uf8f3 \u03bb > \u03bcL2\n\u03c1\n\nL\u03c1\n2Lf kx0 \u2212x0 k ,\n1\n2L\u03c1 (ky 0 \u2212x1 k+Lf kx0 \u2212x0 k)\n\n\u03bb=\n\nWe denote by \u03bb0 and \u03bc0 the following values for the dual variables:\nL\u03c1\n,\n2Lf kx0 \u2212 x0 k\n1\n.\n\u03bc0 ,\n2L\u03c1 (ky 0 \u2212 x1 k + Lf kx0 \u2212 x0 k)\n\u03bb0 ,\n\nWe have:\n\u03bc0 =\n\n1\n>0\n2L\u03c1 (ky 0 \u2212 x1 k + Lf kx0 \u2212 x0 k)\n!\ny 0 \u2212 x1\n\u03bb0\n2\n= L\u03c1 1 +\n> L2\u03c1 .\n\u03bc0\nLf kx0 \u2212 x0 k\n\n.\n\n\f30\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n\n\u0012\n\u0013\nky0 \u2212x1 k\nIn the following, we denote 1 + Lf kx0 \u2212x0 k by K. We now give the expression of L(\u03bb0 , \u03bc0 )\nusing only \u03bc0 and K:\n2\n\n\u00012\nL4\u03c1 \u03bc20 x1 \u2212 Ky 0\n1\n\u2212\n+ r1 \u2212 r1 \u03bc0\n2\n\u03bc0 L\u03c1 (\u22121 + K)\n4\u03bc0\n\u0010\n\u0011\n\u0010 \u00012\n2\n2\n+\u03bc0 KL2\u03c1 y 0 \u2212 L2f x0 \u2212 x0\n+ \u03bc0 r1 \u2212 L2\u03c1 x1\n\nL(\u03bb0 , \u03bc0 ) = \u2212\n\n2\n\n\u0011\n\n2\n\nL2\u03c1 \u03bc0 x1 \u2212 Ky 0\n1\n\u2212\n+ r1\nK \u22121\n4\u03bc0\n\u0010\n\u0011\n2\n2\n+L2\u03c1 \u03bc0 K y 0 \u2212 L2f x0 \u2212 x0\n\u2212 L2\u03c1 \u03bc0 x1\n\n=\u2212\n\n2\n\n.\n\nUsing the fact that x1 \u2212 Ky 0 = x1 \u2212 y 0 \u2212 (K \u2212 1)y 0 , we can write:\n\u0011\nL2\u03c1 \u03bc0 \u0010 1\n2\n2\nx \u2212 y 0 + (K \u2212 1)2 y 0 \u2212 2(K \u2212 1)(x1 \u2212 y 0 )T y 0\nK \u22121\n\u0010\n\u0011\n1\n2\n2\n2\n\u2212\n+ r1 + L2\u03c1 \u03bc0 K y 0 \u2212 L2f x0 \u2212 x0\n\u2212 L2\u03c1 x1\n4\u03bc0\n\nL(\u03bb0 , \u03bc0 ) = \u2212\n\nand\nL2\u03c1 \u03bc0\n2\n2\nx1 \u2212 y 0 \u2212 L2\u03c1 \u03bc0 (K \u2212 1) y 0 + 2L2\u03c1 \u03bc0 (x1 \u2212 y 0 )T y 0\nK \u22121\n\u0010\n\u0011\n1\n2\n2\n2\n\u2212\n+ r1 + L2\u03c1 \u03bc0 K y 0 \u2212 L2f x0 \u2212 x0\n\u2212 L2\u03c1 x1 .\n4\u03bc0\n\nL(\u03bb0 , \u03bc0 ) = \u2212\n\nFrom there,\nL2\u03c1 \u03bc0\nx1 \u2212 y 0\nK \u22121\n\n2\n\n+ y0\n\n2\n\n\u0001\n\u2212L2\u03c1 \u03bc0 (K \u2212 1) \u2212 2L2\u03c1 \u03bc0 + L2\u03c1 \u03bc0 K\n\u0010\n\u0011\n1\n2\n\u22122L2\u03c1 \u03bc0 (x1 )T y 0 \u2212\n+ r1 + L2\u03c1 \u03bc0 K \u2212L2f x0 \u2212 x0\n\u2212 L2\u03c1 x1\n4\u03bc0\n\nL(\u03bb0 , \u03bc0 ) = \u2212\n\n\u0001\nand, since \u2212L2\u03c1 \u03bc0 (K \u2212 1) \u2212 2L2\u03c1 \u03bc0 + L2\u03c1 \u03bc0 K = \u2212L2\u03c1 \u03bc0 , we have that\nL2\u03c1 \u03bc0\n2\n2\nx1 \u2212 y 0 \u2212 L2\u03c1 \u03bc0 y 0 \u2212 2L2\u03c1 \u03bc0 (x1 )T y 0\nK \u22121\n\u0010\n\u0011\n1\n2\n2\n+ r1 + L2\u03c1 \u03bc0 K \u2212L2f x0 \u2212 x0\n\u2212 L2\u03c1 x1\n\u2212\n4\u03bc0\n\nL(\u03bb0 , \u03bc0 ) = \u2212\n\nand\n\u0010\nL2\u03c1 \u03bc0\n2\n2\nx1 \u2212 y 0 \u2212 L2\u03c1 \u03bc0 y 0 + x1\nK \u22121\n\u0010\n\u0011\n1\n2\n+ r1 + L2\u03c1 \u03bc0 K \u2212L2f x0 \u2212 x0\n.\n\u2212\n4\u03bc0\n\nL(\u03bb0 , \u03bc0 ) = \u2212\n\n2\n\n\u2212 2(x1 )T y 0\n\n\u0011\n\n2\n\n\f31\n\nMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\nSince\n\n\u0010\n\ny0\n\n2\n\n+ x1\n\n2\n\n\u0011\n\u2212 2(x1 )T y 0 = x1 \u2212 y 0\n\n2\n\n, we have:\n\nL2\u03c1 \u03bc0\n2\n2\nx1 \u2212 y 0 \u2212 L2\u03c1 \u03bc0 x1 \u2212 y 0\nK \u22121\n\u0010\n\u0011\n1\n2\n\u2212\n+ r1 + L2\u03c1 \u03bc0 K \u2212L2f x0 \u2212 x0\n4\u03bc0\nK\n2\n= \u2212L2\u03c1 \u03bc0 x1 \u2212 y 0\nK \u22121\n\u0010\n\u0011\n1\n2\n\u2212\n+ r1 + L2\u03c1 \u03bc0 K \u2212L2f x0 \u2212 x0\n4\u03bc0\n!\n2\nx1 \u2212 y 0\n1\n2\n2\n0\n2\n+ Lf x \u2212 x0\n+ r1 .\n\u2212\n= \u2212KL\u03c1 \u03bc0\nK \u22121\n4\u03bc0\n\nL(\u03bb0 , \u03bc0 ) = \u2212\n\nSince K ,\n\n\u0012\n\u0013\nky0 \u2212x1 k\n1 + Lf kx0 \u2212x0 k , we have:\n\ny 0 \u2212 x1\nL(\u03bb0 , \u03bc0 ) = \u2212 1 +\nLf kx0 \u2212 x\u03020 k\n\u2212\n\n!\n\n\uf8eb\nL2\u03c1 \u03bc0 \uf8ed \u0010\n\n\u0011\n\n1+\n\n\u0001\n\nLf x0 \u2212 x0 x1 \u2212 y 0\nkx1 \u2212 y 0 k\n\n\u22121\n\n2\n\n+ L2f x0 \u2212 x0\n\nky 0 \u2212x1 k\nLf kx0 \u2212x0 k\n\n\uf8f8\n\n2\n\n!\n+\n\nL2f\n\n0\n\nx \u2212 x0\n\n1\n+ r1\n4\u03bc0\n\n= \u2212 L2\u03c1 \u03bc0 Lf x0 \u2212 x0 + y 0 \u2212 x1\nSince \u03bc0 =\n\n\uf8f6\n\n2\n\n1\n+ r1\n4\u03bc0\n\nL2\u03c1 \u03bc0 Lf x0 \u2212 x0 + y 0 \u2212 x1\n=\u2212\nLf kx0 \u2212 x0 k\n\u2212\n\nx1 \u2212 y 0\n\n1\n2L\u03c1 (ky 0 \u2212x1 k+Lf kx0 \u2212x0 k) ,\n\n\u0001\n\nx1 \u2212 y 0 + Lf x0 \u2212 x0\n\n\u0001 L\u03c1\nL\u03c1\ny 0 \u2212 x1 + Lf x0 \u2212 x0 \u2212\n2\n2\n= r1 \u2212 L\u03c1 y 0 \u2212 x1 \u2212 L\u03c1 Lf x0 \u2212 x0\n00(u ,u1 ),k0 ,k1\n\n\u2212\n\n1\n+ r1 .\n4\u03bc0\n\nwe finally obtain:\n\nL(\u03bb0 , \u03bc0 ) = \u2212\n\n= BT R 0\n\n\u0001\n\ny 0 \u2212 x1 + Lf x0 \u2212 x0\n\n\u0001\n\n+ r1\n\n(F) ,\n\nwhich ends the proof.\nREFERENCES\n[1] A. BANERJEE AND A.A. T SIATIS, Adaptive two-stage designs in phase ii clinical trials, Statistics in\nmedicine, 25 (2006), pp. 3382\u20133395.\n[2] T. BA\u015eAR AND P. B ERNHARD, H\u221e -optimal control and related minimax design problems: a dynamic game\napproach, vol. 5, Birkhauser, 1995.\n[3] A. B ECK AND Y.C. E LDAR, Strong duality in nonconvex quadratic optimization with two quadratic constraints, SIAM Journal on Optimization, 17 (2007), pp. 844\u2013860.\n[4] A. B EMPORAD AND M. M ORARI, Robust model predictive control: A survey, Robustness in Identification\nand Control, 245 (1999), pp. 207\u2013226.\n[5] A. B EN -TAL AND A.S. N EMIROVSKI, Lectures on Modern Convex Optimization, Siam, 2001.\n[6] D.P. B ERTSEKAS AND J.N. T SITSIKLIS, Neuro-Dynamic Programming, Athena Scientific, 1996.\n\n2\n\n\f32\n\nR. Fonteneau, D. Ernst, B. Boigelot, Q. Louveaux\n\n[7] J.R. B IRGE AND F. L OUVEAUX, Introduction to Stochastic Programming, Springer Verlag, 1997.\n[8] JF B ONNANS , J.C. G ILBERT, C. L EMAR \u00c9CHAL , AND C. S AGASTIZ \u00c1BAL, Numerical optimization, theoretical and numerical aspects, 2006.\n[9] S.P. B OYD AND L. VANDENBERGHE, Convex Optimization, Cambridge Univ Pr, 2004.\n[10] S.J. B RADTKE AND A.G. BARTO, Linear least-squares algorithms for temporal difference learning, Machine Learning, 22 (1996), pp. 33\u201357.\n[11] L. B USONIU , R. BABUSKA , B. D E S CHUTTER , AND D. E RNST, Reinforcement Learning and Dynamic\nProgramming using Function Approximators, Taylor & Francis CRC Press, 2010.\n[12] E.F. C AMACHO AND C. B ORDONS, Model Predictive Control, Springer, 2004.\n[13] A.R. C ONN , N.I.M. G OULD , AND P.L. T OINT, Trust-region Methods, vol. 1, Society for Industrial Mathematics, 2000.\n[14] K. DARBY-D OWMAN , S. BARKER , E. AUDSLEY, AND D. PARSONS, A two-stage stochastic programming\nwith recourse model for determining robust planting plans in horticulture, Journal of the Operational\nResearch Society, (2000), pp. 83\u201389.\n[15] B. D EFOURNY, D. E RNST, AND L. W EHENKEL, Risk-aware decision making and dynamic programming,\nSelected for oral presentation at the NIPS-08 Workshop on Model Uncertainty and Risk in Reinforcement\nLearning, Whistler, Canada, (2008).\n[16] E. D ELAGE AND S. M ANNOR, Percentile optimization for Markov decision processes with parameter uncertainty, Operations Research, 58 (2010), pp. 203\u2013213.\n[17] D. E RNST, P. G EURTS , AND L. W EHENKEL, Tree-based batch mode reinforcement learning, Journal of\nMachine Learning Research, 6 (2005), pp. 503\u2013556.\n[18] D. E RNST, M. G LAVIC , F. C APITANESCU , AND L. W EHENKEL, Reinforcement learning versus model\npredictive control: a comparison on a power system problem, IEEE Transactions on Systems, Man,\nand Cybernetics - Part B: Cybernetics, 39 (2009), pp. 517\u2013529.\n[19] R. F ONTENEAU, Contributions to Batch Mode Reinforcement Learning, PhD thesis, University of Li\u00e8ge,\n2011.\n[20] R. F ONTENEAU , S. M URPHY, L. W EHENKEL , AND D. E RNST, Inferring bounds on the performance of a\ncontrol policy from a sample of trajectories, in Proceedings of the 2009 IEEE Symposium on Adaptive\nDynamic Programming and Reinforcement Learning (IEEE ADPRL 09), Nashville, TN, USA, 2009.\n[21] R. F ONTENEAU , S.A. M URPHY, L. W EHENKEL , AND D. E RNST, A cautious approach to generalization in\nreinforcement learning, in Proceedings of the Second International Conference on Agents and Artificial\nIntelligence (ICAART 2010), Valencia, Spain, 2010.\n[22] R. F ONTENEAU , S. A. M URPHY, L. W EHENKEL , AND D. E RNST, Towards min max generalization in reinforcement learning, in Agents and Artificial Intelligence: International Conference, ICAART 2010,\nValencia, Spain, January 2010, Revised Selected Papers. Series: Communications in Computer and Information Science (CCIS), vol. 129, Springer, Heidelberg, 2011, pp. 61\u201377.\n[23] K. F RAUENDORFER, Stochastic Two-stage Programming, Springer, 1992.\n[24] L.P. H ANSEN AND T.J. S ARGENT, Robust Control and Model Uncertainty, American Economic Review,\n(2001), pp. 60\u201366.\n[25] J.B. H IRIART-U RRUTY AND C. L EMAR \u00c9CHAL, Convex Analysis and Minimization Algorithms: Fundamentals, vol. 305, Springer-Verlag, 1996.\n[26] J.E. I NGERSOLL, Theory of Financial Decision Making, Rowman and Littlefield Publishers, Inc., 1987.\n[27] S. KOENIG, Minimax real-time heuristic search, Artificial Intelligence, 129 (2001), pp. 165\u2013197.\n[28] M.G. L AGOUDAKIS AND R. PARR, Least-squares policy iteration, Jounal of Machine Learning Research, 4\n(2003), pp. 1107\u20131149.\n[29] M. L. L ITTMAN, Markov games as a framework for multi-agent reinforcement learning, in Proceedings of\nthe Eleventh International Conference on Machine Learning (ICML 1994), New Brunswick, NJ, USA,\n1994.\n, A tutorial on partially observable markov decision processes, Journal of Mathematical Psychology,\n[30]\n53 (2009), pp. 119 \u2013 125. Special Issue: Dynamic Decision Making.\n[31] Y. L OKHNYGINA AND A.A. T SIATIS, Optimal two-stage group-sequential designs, Journal of Statistical\nPlanning and Inference, 138 (2008), pp. 489\u2013499.\n[32] J.K. L UNCEFORD , M. DAVIDIAN , AND A.A. T SIATIS, Estimation of survival distributions of treatment\npolicies in two-stage randomization designs in clinical trials, Biometrics, (2002), pp. 48\u201357.\n[33] S. M ANNOR , D. S IMESTER , P. S UN , AND J.N. T SITSIKLIS, Bias and variance in value function estimation,\nin Proceedings of the Twenty-first International Conference on Machine Learning (ICML 2004), Banff,\nAlberta, Canada, 2004.\n[34] S.A. M URPHY, Optimal dynamic treatment regimes, Journal of the Royal Statistical Society, Series B, 65(2)\n(2003), pp. 331\u2013366.\n[35] S.A. M URPHY, An experimental design for the development of adaptive treatment strategies, Statistics in\nMedicine, 24 (2005), pp. 1455\u20131481.\n[36] A. N EMIROVSKI , A. J UDITSKY, G. L AN , AND A. S HAPIRO, Robust stochastic approximation approach to\n\n\fMin Max Generalization for Two-stage Deterministic Batch Mode RL: Relaxation Schemes\n\n33\n\nstochastic programming, SIAM Journal on Optimization, 19 (2009), pp. 1574\u20131609.\n[37] Y. N ESTEROV AND A. N EMIROVSKI, Interior point polynomial methods in convex programming, Studies in\napplied mathematics, 13 (1994).\n[38] D. O RMONEIT AND S. S EN, Kernel-based reinforcement learning, Machine Learning, 49 (2002), pp. 161\u2013\n178.\n[39] C. PADURARU , D. P RECUP, AND J. P INEAU, A framework for computing bounds for the return of a policy,\nin Ninth European Workshop on Reinforcement Learning (EWRL9), 2011.\n[40] C.H. PAPADIMITRIOU, Computational Complexity, John Wiley and Sons Ltd., 2003.\n[41] M. Q IAN AND S.A. M URPHY, Performance guarantees for individualized treatment rules, Tech. Report 498,\nDepartment of Statistics, University of Michigan, 2009.\n[42] M. R IEDMILLER, Neural fitted Q iteration - first experiences with a data efficient neural reinforcement learning method, in Proceedings of the Sixteenth European Conference on Machine Learning (ECML 2005),\nPorto, Portugal, 2005, pp. 317\u2013328.\n[43] M. ROVATOUS AND M. L AGOUDAKIS, Minimax search and reinforcement learning for adversarial tetris, in\nProceedings of the 6th Hellenic Conference on Artificial Intelligence (SETN'10), Athens, Greece, 2010.\n[44] P. S COKAERT AND D. M AYNE, Min-max feedback model predictive control for constrained linear systems,\nIEEE Transactions on Automatic Control, 43 (1998), pp. 1136\u20131142.\n[45] A. S HAPIRO, A dynamic programming approach to adjustable robust optimization, Operations Research\nLetters, 39 (2011), pp. 83\u201387.\n, Minimax and risk averse multistage stochastic programming, tech. report, School of Industrial &\n[46]\nSystems Engineering, Georgia Institute of Technology, 2011.\n[47] J.F. S TURM, Using SeDuMi 1.02, a MATLAB toolbox for optimization over symmetric cones, Optimization\nmethods and software, 11 (1999), pp. 625\u2013653.\n[48] R.S. S UTTON AND A.G. BARTO, Reinforcement Learning, MIT Press, 1998.\n[49] A.S. WAHED AND A.A. T SIATIS, Optimal estimator for the survival distribution and related quantities for\ntreatment policies in two-stage randomization designs in clinical trials, Biometrics, 60 (2004), pp. 124\u2013\n133.\n\n\f"}