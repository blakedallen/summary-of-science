{"id": "http://arxiv.org/abs/astro-ph/0703437v1", "guidislink": true, "updated": "2007-03-16T11:35:28Z", "updated_parsed": [2007, 3, 16, 11, 35, 28, 4, 75, 0], "published": "2007-03-16T11:35:28Z", "published_parsed": [2007, 3, 16, 11, 35, 28, 4, 75, 0], "title": "A 3D radiative transfer framework: II. line transfer problems", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=astro-ph%2F0703650%2Castro-ph%2F0703420%2Castro-ph%2F0703808%2Castro-ph%2F0703006%2Castro-ph%2F0703658%2Castro-ph%2F0703059%2Castro-ph%2F0703485%2Castro-ph%2F0703693%2Castro-ph%2F0703771%2Castro-ph%2F0703605%2Castro-ph%2F0703011%2Castro-ph%2F0703701%2Castro-ph%2F0703269%2Castro-ph%2F0703447%2Castro-ph%2F0703233%2Castro-ph%2F0703714%2Castro-ph%2F0703348%2Castro-ph%2F0703586%2Castro-ph%2F0703575%2Castro-ph%2F0703734%2Castro-ph%2F0703367%2Castro-ph%2F0703331%2Castro-ph%2F0703521%2Castro-ph%2F0703246%2Castro-ph%2F0703359%2Castro-ph%2F0703589%2Castro-ph%2F0703081%2Castro-ph%2F0703534%2Castro-ph%2F0703383%2Castro-ph%2F0703677%2Castro-ph%2F0703438%2Castro-ph%2F0703740%2Castro-ph%2F0703265%2Castro-ph%2F0703398%2Castro-ph%2F0703496%2Castro-ph%2F0703042%2Castro-ph%2F0703692%2Castro-ph%2F0703304%2Castro-ph%2F0703312%2Castro-ph%2F0703003%2Castro-ph%2F0703005%2Castro-ph%2F0703538%2Castro-ph%2F0703206%2Castro-ph%2F0703548%2Castro-ph%2F0703365%2Castro-ph%2F0703452%2Castro-ph%2F0703595%2Castro-ph%2F0703651%2Castro-ph%2F0703180%2Castro-ph%2F0703412%2Castro-ph%2F0703326%2Castro-ph%2F0703470%2Castro-ph%2F0703515%2Castro-ph%2F0703248%2Castro-ph%2F0703450%2Castro-ph%2F0703437%2Castro-ph%2F0703285%2Castro-ph%2F0703360%2Castro-ph%2F0703569%2Castro-ph%2F0703187%2Castro-ph%2F0703727%2Castro-ph%2F0703130%2Castro-ph%2F0703266%2Castro-ph%2F0703766%2Castro-ph%2F0703270%2Castro-ph%2F0703642%2Castro-ph%2F0703138%2Castro-ph%2F0703505%2Castro-ph%2F0703697%2Castro-ph%2F0703686%2Castro-ph%2F0703436%2Castro-ph%2F0703133%2Castro-ph%2F0703445%2Castro-ph%2F0703347%2Castro-ph%2F0703710%2Castro-ph%2F0703545%2Castro-ph%2F0703630%2Castro-ph%2F0703730%2Castro-ph%2F0703611%2Castro-ph%2F0703481%2Castro-ph%2F0703236%2Castro-ph%2F0703535%2Castro-ph%2F0703524%2Castro-ph%2F0703670%2Castro-ph%2F0703624%2Castro-ph%2F0703478%2Castro-ph%2F0703558%2Castro-ph%2F0703431%2Castro-ph%2F0703757%2Castro-ph%2F0703163%2Castro-ph%2F0703297%2Castro-ph%2F0703562%2Castro-ph%2F0703340%2Castro-ph%2F0703509%2Castro-ph%2F0703763%2Castro-ph%2F0703289%2Castro-ph%2F0703188%2Castro-ph%2F0703691%2Castro-ph%2F0703060%2Castro-ph%2F0703129%2Castro-ph%2F0703473&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A 3D radiative transfer framework: II. line transfer problems"}, "summary": "Higher resolution telescopes as well as 3D numerical simulations will require\nthe development of detailed 3D radiative transfer calculations. Building upon\nour previous work we extend our method to include both continuum and line\ntransfer. We present a general method to calculate radiative transfer including\nscattering in the continuum as well as in lines in 3D static atmospheres. The\nscattering problem for line transfer is solved via means of an operator\nsplitting (OS) technique. The formal solution is based on a\nlong-characteristics method. The approximate $\\Lambda$ operator is constructed\nconsidering nearest neighbors {\\em exactly}. The code is parallelized over both\nwavelength and solid angle using the MPI library. We present the results of\nseveral test cases with different values of the thermalization parameter and\ntwo choices for the temperature structure. The results are directly compared to\n1D spherical tests. With our current grid setup the interior resolution is much\nlower in 3D than in 1D, nevertheless the 3D results agree very well with the\nwell-tested 1D calculations. We show that with relatively simple\nparallelization that the code scales to very large number of processors which\nis mandatory for practical applications. Advances in modern computers will make\nrealistic 3D radiative transfer calculations possible in the near future. Our\ncurrent code scales to very large numbers of processors, but requires larger\nmemory per processor at high spatial resolution.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=astro-ph%2F0703650%2Castro-ph%2F0703420%2Castro-ph%2F0703808%2Castro-ph%2F0703006%2Castro-ph%2F0703658%2Castro-ph%2F0703059%2Castro-ph%2F0703485%2Castro-ph%2F0703693%2Castro-ph%2F0703771%2Castro-ph%2F0703605%2Castro-ph%2F0703011%2Castro-ph%2F0703701%2Castro-ph%2F0703269%2Castro-ph%2F0703447%2Castro-ph%2F0703233%2Castro-ph%2F0703714%2Castro-ph%2F0703348%2Castro-ph%2F0703586%2Castro-ph%2F0703575%2Castro-ph%2F0703734%2Castro-ph%2F0703367%2Castro-ph%2F0703331%2Castro-ph%2F0703521%2Castro-ph%2F0703246%2Castro-ph%2F0703359%2Castro-ph%2F0703589%2Castro-ph%2F0703081%2Castro-ph%2F0703534%2Castro-ph%2F0703383%2Castro-ph%2F0703677%2Castro-ph%2F0703438%2Castro-ph%2F0703740%2Castro-ph%2F0703265%2Castro-ph%2F0703398%2Castro-ph%2F0703496%2Castro-ph%2F0703042%2Castro-ph%2F0703692%2Castro-ph%2F0703304%2Castro-ph%2F0703312%2Castro-ph%2F0703003%2Castro-ph%2F0703005%2Castro-ph%2F0703538%2Castro-ph%2F0703206%2Castro-ph%2F0703548%2Castro-ph%2F0703365%2Castro-ph%2F0703452%2Castro-ph%2F0703595%2Castro-ph%2F0703651%2Castro-ph%2F0703180%2Castro-ph%2F0703412%2Castro-ph%2F0703326%2Castro-ph%2F0703470%2Castro-ph%2F0703515%2Castro-ph%2F0703248%2Castro-ph%2F0703450%2Castro-ph%2F0703437%2Castro-ph%2F0703285%2Castro-ph%2F0703360%2Castro-ph%2F0703569%2Castro-ph%2F0703187%2Castro-ph%2F0703727%2Castro-ph%2F0703130%2Castro-ph%2F0703266%2Castro-ph%2F0703766%2Castro-ph%2F0703270%2Castro-ph%2F0703642%2Castro-ph%2F0703138%2Castro-ph%2F0703505%2Castro-ph%2F0703697%2Castro-ph%2F0703686%2Castro-ph%2F0703436%2Castro-ph%2F0703133%2Castro-ph%2F0703445%2Castro-ph%2F0703347%2Castro-ph%2F0703710%2Castro-ph%2F0703545%2Castro-ph%2F0703630%2Castro-ph%2F0703730%2Castro-ph%2F0703611%2Castro-ph%2F0703481%2Castro-ph%2F0703236%2Castro-ph%2F0703535%2Castro-ph%2F0703524%2Castro-ph%2F0703670%2Castro-ph%2F0703624%2Castro-ph%2F0703478%2Castro-ph%2F0703558%2Castro-ph%2F0703431%2Castro-ph%2F0703757%2Castro-ph%2F0703163%2Castro-ph%2F0703297%2Castro-ph%2F0703562%2Castro-ph%2F0703340%2Castro-ph%2F0703509%2Castro-ph%2F0703763%2Castro-ph%2F0703289%2Castro-ph%2F0703188%2Castro-ph%2F0703691%2Castro-ph%2F0703060%2Castro-ph%2F0703129%2Castro-ph%2F0703473&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Higher resolution telescopes as well as 3D numerical simulations will require\nthe development of detailed 3D radiative transfer calculations. Building upon\nour previous work we extend our method to include both continuum and line\ntransfer. We present a general method to calculate radiative transfer including\nscattering in the continuum as well as in lines in 3D static atmospheres. The\nscattering problem for line transfer is solved via means of an operator\nsplitting (OS) technique. The formal solution is based on a\nlong-characteristics method. The approximate $\\Lambda$ operator is constructed\nconsidering nearest neighbors {\\em exactly}. The code is parallelized over both\nwavelength and solid angle using the MPI library. We present the results of\nseveral test cases with different values of the thermalization parameter and\ntwo choices for the temperature structure. The results are directly compared to\n1D spherical tests. With our current grid setup the interior resolution is much\nlower in 3D than in 1D, nevertheless the 3D results agree very well with the\nwell-tested 1D calculations. We show that with relatively simple\nparallelization that the code scales to very large number of processors which\nis mandatory for practical applications. Advances in modern computers will make\nrealistic 3D radiative transfer calculations possible in the near future. Our\ncurrent code scales to very large numbers of processors, but requires larger\nmemory per processor at high spatial resolution."}, "authors": ["E. Baron", "Peter H. Hauschildt"], "author_detail": {"name": "Peter H. Hauschildt"}, "author": "Peter H. Hauschildt", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1051/0004-6361:20066755", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/astro-ph/0703437v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/astro-ph/0703437v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "A&A, in press, 9 pages, 9 Figures. Full resolution version available\n  at ftp://phoenix.hs.uni-hamburg.de/preprints/3DRT_paper2.pdf", "arxiv_primary_category": {"term": "astro-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "astro-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/astro-ph/0703437v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/astro-ph/0703437v1", "journal_reference": null, "doi": "10.1051/0004-6361:20066755", "fulltext": "c ESO 2018\n\nAstronomy & Astrophysics manuscript no. paper\nJuly 16, 2018\n\nA 3D radiative transfer framework: II. line transfer problems\nE. Baron1,2,3 and Peter H. Hauschildt1\n1\n2\n\narXiv:astro-ph/0703437v1 16 Mar 2007\n\n3\n\nHamburger Sternwarte, Gojenbergsweg 112, 21029 Hamburg, Germany; yeti@hs.uni-hamburg.de\nDept. of Physics and Astronomy, University of Oklahoma, 440 W. Brooks, Rm 100, Norman, OK 73019 USA; baron@nhn.ou.edu\nNERSC, Lawrence Berkeley National Laboratory, MS 50F-1650, 1 Cyclotron Rd, Berkeley, CA 94720-8139 USA\n\nReceived date Accepted date\nABSTRACT\n\nContext. Higher resolution telescopes as well as 3D numerical simulations will require the development of detailed 3D radiative\ntransfer calculations. Building upon our previous work we extend our method to include both continuum and line transfer.\nAims. We present a general method to calculate radiative transfer including scattering in the continuum as well as in lines in 3D static\natmospheres.\nMethods. The scattering problem for line transfer is solved via means of an operator splitting (OS) technique. The formal solution is\nbased on a long-characteristics method. The approximate \u039b operator is constructed considering nearest neighbors exactly. The code\nis parallelized over both wavelength and solid angle using the MPI library.\nResults. We present the results of several test cases with different values of the thermalization parameter and two choices for the\ntemperature structure. The results are directly compared to 1D spherical tests. With our current grid setup the interior resolution is\nmuch lower in 3D than in 1D, nevertheless the 3D results agree very well with the well-tested 1D calculations. We show that with\nrelatively simple parallelization that the code scales to very large number of processors which is mandatory for practical applications.\nConclusions. Advances in modern computers will make realistic 3D radiative transfer calculations possible in the near future. Our\ncurrent code scales to very large numbers of processors, but requires larger memory per processor at high spatial resolution.\nKey words. Radiative transfer \u2013 Scattering\n\n1. Introduction\nHydrodynamical calculations in two and three spatial dimensions are necessary in a broad range of astrophysical contexts. With modern parallel supercomputers, they are also becoming more realistic, in that they can be run at modest\nto high resolution. Performing full radiation hydrodynamical\ncalculations is presently still too computationally expensive.\nRecently, Hubeny & Burrows (2006) have presented a mixed\nframe method of solving the time-dependent radiative transfer problem in 2D, but their work is tailored toward neutrino transport where the absence of rapidly changing opacity\nsuch as a spectral line makes their approximations appropriate.\nSimilar work has been presented by Mihalas & Klein (1982),\nLowrie et al. (1999), and Lowrie & Morel (2001). Taking a different approach Krumholz et al. (2006) derive the flux-limiter\nto O(v/c) for use in radiation hydrodynamics calculations.\nSimilar work was presented by Cooperstein & Baron (1992).\nEven though these recent first steps are improvements, they suffer from a loss of accuracy, either in dealing with spectral lines,\nor in obtaining the correct angular dependence of the photon distribution function or the specific intensity. While these recent\nworks are expedient, they are crude enough that the results of the\nhydrodynamical calculations cannot be compared directly with\nobserved spectra. Given the fact that computational resources\nare finite, a final post-processing step is necessary to compare\nthe results of hydrodynamical calculations to observations.\nIn Hauschildt & Baron (2006, hereafter: Paper I) we described a framework for the solution of the radiative trans-\n\nfer equation for scattering continua in 3D (when we say 3D\nwe mean three spatial dimensions, plus three momentum dimensions) for the time independent, static case. Here we extend our method to include transfer in lines including the case\nthat the line is scattering dominated. Fabiani Bendicho et al.\n(1997) presented a multi-level, multi-grid, multi-dimensional\nradiative transfer scheme, using a lower triangular ALO and\nsolving the scattering problem via a Gauss-Seidel method.\nvan Noort, Hubeny, & Lanz (2002) presented a method of solving the full NLTE radiative transfer problem using the short\ncharacteristics method in 2-D for Cartesian, spherical, and\ncylindrical geometry. They also used the technique of accelerated lambda iteration (ALI) (Olson et al. 1987; Olson & Kunasz\n1987), however they restricted themselves to the case of a diagonal accelerated lambda operator (ALO).\nWe describe our method, its rate of convergence, and present\ncomparisons to our well-tested 1-D calculations.\n\n2. Method\nIn the following discussion we use notation of Hauschildt (1992)\nand Paper I. The basic framework and the methods used for the\nformal solution and the solution of the scattering problem via\noperator splitting are discussed in detail in paper I and will thus\nnot be repeated here. We have extended the framework to solve\nline transfer problems with a background continuum. The basic\napproach is similar to that of Hauschildt (1993). In the simple\ncase of a 2-level atom with background continuum we consider\nhere as a test case, we use a wavelength grid that covers the pro-\n\n\f2\n\nBaron and Hauschildt: 3D radiative transfer framework II\n\nfile of the line including the surrounding continuum. We then\nuse the wavelength dependent mean intensities J\u03bb and approximate \u039b operators \u039b\u2217 to compute the profile integrated line mean\nintensities J \u0304 and \u039b\u0304\u2217 via\nZ\n \u0304\nJ=\n\u03c6(\u03bb)J\u03bb d\u03bb\n\n7. Parameterized coherent & isotropic continuum scattering by\ndefining\n\nand\n\nThe line of the simple 2-level model atom is parameterized\nby the ratio of the profile averaged line opacity \u03c7l to the continuum opacity \u03c7c and the line thermalization parameter \u01ebl . For\nthe test cases presented below, we have used \u01ebc = 1 and a constant temperature and thus a constant thermal part of the source\nfunction for simplicity (and to save computing time) and set\n\u03c7l /\u03c7c = 106 to simulate a strong line, with varying \u01ebl (see below). With this setup, the optical depths as seen in the line range\nfrom 10\u22122 to 106 . We use 32 wavelength points to model the full\nline profile, including wavelengths outside the line for the continuum. We did not require the line to thermalize at the center of\nthe test configurations, this is a typical situation one encounters\nin a full 3D configurations as the location (or even existence) of\nthe thermalization depths becomes more ambiguous than in the\n1D case.\nThe sphere is put at the center of the Cartesian grid, which is\nin each axis 10% larger than the radius of the sphere. For the test\ncalculations we use voxel grids with the same number of spatial\npoints in each direction (see below). The solid angle space was\ndiscretized in (\u03b8, \u03c6) with n\u03b8 = n\u03c6 if not stated otherwise. In the\nfollowing we discuss the results of various tests. In all tests we\nuse the LC method for the 3D RT solution. Unless otherwise\nstated, the tests were run on parallel computers using 128 CPUs.\nFor the 3D solver we use n x = ny = nz = 2 \u2217 64 + 1 or n x = ny =\nnz = 2 \u2217 96 + 1 points along each axis, for a total of 1293 or 1933\nspatial points, depending on the test case. The solid angle space\ndiscretization uses n\u03b8 = n\u03c6 = 64 points.\n\n\u039b\u0304\u2217 =\n\nZ\n\n\u03c6(\u03bb)\u039b\u2217 d\u03bb.\n\nJ \u0304 and \u039b\u0304\u2217 are then used to compute an updated value for J \u0304 and\nthe line source function\nS = (1 \u2212 \u01eb) J \u0304 + \u01ebB\nwhere \u01eb is the line thermalization parameter (0 for a purely absorptive line, 1 for a purely scattering line). B is the Planck function, B\u03bb, profile averaged over the line\nZ\nB=\n\u03c6(\u03bb)B\u03bb d\u03bb\nvia the standard iteration method\n\u0002\n\u0003  \u0304\n \u0304 ,\n1 \u2212 \u039b\u2217 (1 \u2212 \u01eb) J \u0304new\n= J \u0304fs \u2212 \u039b\u2217 (1 \u2212 \u01eb) J \u0304old\n\nwhere J \u0304fs = \u039b\u0304S old . This equation is solved directly to get the\nnew values of J \u0304 which is then used to compute the new source\nfunction for the next iteration cycle.\nWe construct the line \u039b\u0304\u2217 directly from the wavelength dependent \u039b\u2217 's generated by the solution of the continuum transfer problems. For practical reasons, we use in this paper only\nthe nearest neighbor \u039b\u2217 discussed in paper I. Larger \u039b\u2217 s require\nsignificantly more storage and small test cases indicate that they\ndo not decrease the number of iterations enough to warrant their\nuse as long as they are not much larger than the nearest neighbor\n\u039b\u2217 .\n\n\u03c7c = \u01ebc \u03bac + (1 \u2212 \u01ebc )\u03c3c\nwith 0 \u2264 \u01ebc \u2264 1. \u03bac and \u03c3c are the continuum absorption and\nscattering coefficients.\n\n3.1. LTE tests\n\n3. Application examples\nWe use the framework discussed in paper I as the baseline for\nthe line transfer problems discussed in this paper. In addition to\nthe highly efficient parallelization of solid angle space, we have\nimplemented a parallelization over wavelength space using the\nMPI distributed memory model. For static configurations (or for\nconfigurations with velocity fields treated in the Eulerian frame)\nthere is no direct coupling between different wavelength points.\nOur basic setup is similar to that discussed in paper I. We\nuse a sphere with a grey continuum opacity parameterized by a\npower law in the continuum optical depth \u03c4std . The basic model\nparameters are\n1. Inner radius rc = 1013 cm, outer radius rout = 1.01 \u00d7 1015 cm.\n\u22124\n2. Minimum optical depth in the continuum \u03c4min\nand\nstd = 10\nmax\nmaximum optical depth in the continuum \u03c4std = 1.\n3. constant temperature structure with T = 104 K or\n4. grey temperature structure with T eff = 104 K.\n\u2212\n5. Outer boundary condition Ibc\n\u2261 0 and diffusion inner boundary condition for all wavelengths.\n6. Continuum extinction \u03c7c = C/r2 , with the constant C fixed\nby the radius and optical depth grids.\n\nIn this test we have set \u01ebl = 1 to test the accuracy of the formal solution by comparing to the results of the 1D code. The 1D\nsolver uses 64 radial points, distributed logarithmically in optical\ndepth. In Fig. 2 we show the line mean intensities J \u0304 as function\nof distance from the center for both the 1D (+ symbols) and the\n3D solver. The results plotted in Fig. 1 show an excellent agreement between the two solutions, showing that the line 3D RT formal solution is comparable in accuracy with the corresponding\n1D formal solution. Note that the difference of the distribution\nof spatial points (linear in the 3D case, approximately logarithmic in the 1D case) causes a much lower resolution of the 3D\ncalculations in the central regions and in a higher resolution of\nthe 3D calculations in the outer regions compared to the 1D test\ncase.\n3.2. Tests with line scattering\n\nWe have run a number of test calculation similar to the LTE case\nbut with line scattering included. In Fig. 3 we show the results for\n\u01ebl = 10\u22124 and in Fig. 4 we show the results for \u01ebl = 10\u22128 as examples. In both cases, the dynamical ranges of J \u0304 are much larger\nthan in the LTE case. The 3D calculations compare very well to\n\n\fBaron and Hauschildt: 3D radiative transfer framework II\n\nthe 1D calculations, in particular in the outer zones. In the inner\nparts the resolution of the 3D models is substantially lower than\nfor the 1D models, therefore the differences are largest there.\nIn Figs. 3 and 4 we show the results for a test model with a\ngrey temperature structure. In these models, the 3D spatial grid\nwas substantially larger (n x = ny = nz = 2 \u2217 96 + 1) in order\nto help resolve the inner regions where the temperature gradients are very large. As expected, the agreement is not as good\nin the inner regions as in the models with a constant temperature, however, the models agree very well in the outer regions.\nOverall, the agreement is very similar in quality compared to the\ncase with constant temperatures. The differences in the mean intensity J \u0304 between the 1D comparison case and the 3D case is\nseveral per-cent in the innermost layers where the grid of the\n3D case is under-sampled, the differences are below 0.1% in the\nouter zones.\n3.3. Convergence\n\nThe convergence properties of the line transfer tests presented\nhere are shown in Figs. 7\u201310. In each figure, we show the convergence rates, as measured by the relative corrections per iteration, for a number of test runs. In all tests show here we have\nused n x = ny = nz = 2\u221732+1 points and n\u03b8 = n\u03c6 = 32 solid angle\npoints for the 3D test case and 64 radial points for the 1D comparison test. The iterations were started with S l = J \u0304 = B at all\nspatial points, this initial guess causes a relative error of about 10\nin J \u0304 at the outer zones for the case with \u01ebl = 10\u22122 and about 104\nin J \u0304 at the outer zones for the case with \u01ebl = 10\u22128 . The plots show\nthat the \u039b iteration is useless even for the relatively benign case\nof \u01ebl = 10\u22122 . The operator splitting method delivers much larger\ncorrections and is substantially accelerated by the Ng method,\nsimilar to the results shown in Paper I. The nearest-neighbor operator gives substantially better convergence rates than the diagonal operator, cf. Fig 7, for the test cases with with \u01ebl < 10\u22122\nthe convergence behavior of the diagonal operator is unstable,\nthe corrections tend to show oscillations. The nearest-neighbor\noperator shows stable convergence with quickly declining corrections for all test cases, its convergence rate can be accelerated\nwith Ng's method. The total number of iterations required for\nthe nearest-neighbor operator is essentially identical to the 1D\ncase with a tri-diagonal operator.\n3.4. Parallelization\n\nWe have implemented a hierarchical parallelization scheme on\ndistributed memory machines using the MPI framework similar to the scheme discussed in Baron & Hauschildt (1998).\nBasically, the most efficient parallelization opportunities in the\nproblem are the solid angle and wavelength sub-spaces. The total number of solid angles in the test models is at least 4096,\nthe number of wavelength points is 32 in the tests presented\nhere but will be much larger in large scale applications. Thus\neven in the simple tests presented here, the calculations could\ntheoretically be run on 131072 processors. The work required\nfor each solid angle is roughly constant (the number of points\nthat need to be calculated depends on the angle points) and during the formal solution process the solid angles are independent\nfrom each other. The mean intensities (and other solid angle in-\n\n3\n\nTable 1. Scaling results for different parallel configurations.\nNworker is the number of MPI processes working on a formal solution for a single wavelength, Ncluster is the number of\nNworker sets of processes working on different wavelength, the\ntotal number of MPI processes is Ncluster \u00d7 Nworker . The column\n'FS+\u039b\u2217 +OS step' gives teh wallclock time (in seconds) for the\ncalculation of the first formal solution plus the construction of\nthe \u039b\u2217 operator plus the time for the first operator splitting step,\nthe column 'FS+OS step' is the time for the second (and subsequent) formal solution and operator splitting step.\nNworker\n128\n64\n32\n16\n8\n4\n\nNcluster\n1\n2\n4\n8\n16\n32\n\nFS+\u039b\u2217 +OS step\n3018\n2595\n2340\n2308\n2264\n2318\n\nFS+OS step\n1143\n1072\n1032\n1018\n1052\n1054\n\ntegrated quantities) are only needed after the formal solution for\nall solid angles is complete, so a single collective MPI operation is needed to finish the computation of the mean intensities\nat each wavelength. Similarly, the wavelength integrated mean\nintensities J \u0304 are needed only after the formal solutions are completed for all wavelengths (and solid angles). Therefore, the different wavelength points can be computed in parallel also with\nthe only communication occurring as collective MPI operations\nafter all wavelength points have been computed. We thus divide\nthe total number of processes up in a number of 'wavelength\nclusters' (each working on a different set of wavelength points)\nthat each have a number of 'worker' processes which work on\na different set of solid angle points for any wavelength. In the\nsimplest case, each wavelength cluster has the same number of\nworker processes so that Ntot = Ncluster \u00d7 Nworker where Ntot is the\ntotal number of MPI processes, Ncluster is the number of wavelength clusters and Nworker is the number of worker processes\nfor each wavelength cluster. For our tests we could use a maximum number of 128 CPUs on the HLRN IBM Regatta (Power4\nCPUs) system. In Table 1 we show the results for the 3 combinations that we could run (due to computer time limitations)\nfor a \u01ebl = 10\u22124 line transfer test case with 32 wavelength points,\nn x = ny = nz = 2 \u2217 64 + 1 spatial points and n\u03b8 = n\u03c6 = 64\nsolid angle points. For example, the third row in the table is for a\nconfiguration with 4 wavelength clusters, each of them using 32\nCPUs working in parallel on different solid angles, for a total of\n128 CPUs. The 3rd and 4th columns give the time (in seconds)\nfor a full formal solution, the construction of the \u039b\u2217 operator\nand an OS step (the first iteration) and the time for a formal solution and an OS step (the second iteration), respectively. As the\n\u039b\u2217 has to be constructed only in the first iteration, the overall\ntime per iteration drops in subsequent iterations. Similarly to the\n1D case, the construction of the \u039b\u2217 is roughly equivalent to one\nformal solution. We have verified that all parallel configurations\nlead to identical results. The table shows that configurations with\nmore clusters are slightly more efficient, mostly due to better\nload balancing. However, the differences are not really significant in practical applications so that the exact choice of the setup\nis not important. This also means that the code can easily scale\nto much larger numbers of processors since realistic applications\nwill require much more than the 32 wavelength points used in the\n\n\f4\n\nBaron and Hauschildt: 3D radiative transfer framework II\n\ntest calculations. Note that the MPI parallelization can be combined with shared memory parallelization (e.g., using openMP)\nin order to more efficiently utilize modern multi-core processors\nwith shared caches. Although this is implemented in the current\nversion of the 3D code, we do not have access to a machine with\nsuch an architecture and it was not efficient to use openMP on\nmultiple single core processors.\n\n4. Conclusions\nUsing rather difficult test problems, we have shown that our 3D\nlong-characteristics method gives very good results when compared to our well-tested 1D code. The main differences are due\nto poorer spatial resolution close to the center of the grid in the\n3D case. The code has also been parallelized and scales to very\nlarge numbers of processors. Future work will examine a shortcharacteristics method of solution which should enable higher\nresolution grids with the same memory requirements and an extension to full multi-level NLTE modeling.\nAcknowledgements. This work was supported in part by by NASA grants\nNAG5-12127 and NNG04GD368, and NSF grants AST-0204771 and AST0307323. Some of the calculations presented here were performed at the\nH\u00f6chstleistungs Rechenzentrum Nord (HLRN); at the NASA's Advanced\nSupercomputing Division's Project Columbia, at the Hamburger Sternwarte\nApple G5 and Delta Opteron clusters financially supported by the DFG and the\nState of Hamburg; and at the National Energy Research Supercomputer Center\n(NERSC), which is supported by the Office of Science of the U.S. Department\nof Energy under Contract No. DE-AC03-76SF00098. We thank all these institutions for a generous allocation of computer time.\n\nReferences\nBaron, E. & Hauschildt, P. H. 1998, ApJ, 495, 370\nCooperstein, J. & Baron, E. 1992, ApJ, 398, 531\nFabiani Bendicho, P., Trujillo Bueno, J., & Auer, L. 1997, A&A, 324, 161\nHauschildt, P. H. 1992, JQSRT, 47, 433\nHauschildt, P. H. 1993, JQSRT, 50, 301\nHauschildt, P. H. & Baron, E. 2006, A&A, 451, 273\nHubeny, I. & Burrows, A. 2006, ArXiv Astrophysics e-prints\nKrumholz, M. R., Klein, R. I., & McKee, C. F. 2006, ArXiv Astrophysics e-prints\nLowrie, R. B. & Morel, J. E. 2001, JQSRT, 69, 475\nLowrie, R. B., Morel, J. E., & Hittinger, J. A. 1999, ApJ, 521, 432\nMihalas, D. & Klein, R. I. 1982, Journal of Computational Physics, 46, 97\nOlson, G. L., Auer, L. H., & Buchler, J. R. 1987, JQSRT, 38, 431\nOlson, G. L. & Kunasz, P. B. 1987, JQSRT, 38, 325\nvan Noort, M., Hubeny, I., & Lanz, T. 2002, ApJ, 568, 1066\n\n\fBaron and Hauschildt: 3D radiative transfer framework II\n\nFig. 1. Comparison of the results obtained for the LTE line test\nwith the 1D solver (\u00d7 symbols) and the 3D line solver. This figure shows cuts along the x, y, and z axes of the 3D grid for a\ngrid with n x = ny = nz = 2 \u2217 64 + 1 spatial points. The ordinate\naxis shows the coordinates, the y axis the log of the mean inten \u0304 for cuts along the axes of\nsity averaged over the line profiles ( J)\nthe 3D grid. For the 1D comparison case the ordinate shows \u00b1\ndistance from the center.\n\n5\n\nFig. 4. Comparison of the results obtained for the \u01ebl = 10\u22128\nline test (constant T ) with the 1D solver (\u00d7 symbols) and the\n3D line solver. This figure shows cuts along the x, y, and z axes\nof the 3D grid with n x = ny = nz = 2 \u2217 64 + 1 spatial points.\nThe ordinate axis shows the coordinates, the y axis the log of the\n \u0304 for cuts along\nmean intensity averaged over the line profiles ( J)\nthe axes of the 3D grid. For the 1D comparison case the ordinate\nshows \u00b1 distance from the center.\n\nFig. 2. Comparison of the results obtained for the LTE line test\nwith the 1D solver (+ symbols) and the 3D line solver. The x\naxis shows the distances from the center of the sphere, the y axis\n \u0304\nthe log of the mean intensity averaged over the line profiles ( J).\nThe 3D model uses n x = ny = nz = 2 \u2217 64 + 1 spatial points.\n\nFig. 3. Comparison of the results obtained for the \u01ebl = 10\u22124\nline test (constant T ) with the 1D solver (\u00d7 symbols) and the\n3D line solver. This figure shows cuts along the x, y, and z axes\nof the 3D grid with n x = ny = nz = 2 \u2217 64 + 1 spatial points.\nThe ordinate axis shows the coordinates, the y axis the log of the\n \u0304 for cuts along\nmean intensity averaged over the line profiles ( J)\nthe axes of the 3D grid. For the 1D comparison case the ordinate\nshows \u00b1 distance from the center.\n\nFig. 5. Comparison of the results obtained for the \u01ebl = 10\u22124 line\ntest (grey T ) with the 1D solver (\u00d7 symbols) and the 3D line\nsolver. This figure shows cuts along the x, y, and z axes of the\n3D grid with n x = ny = nz = 2 \u2217 96 + 1 spatial points. The\nordinate axis shows the coordinates, the y axis the log of the\n \u0304 for cuts along\nmean intensity averaged over the line profiles ( J)\nthe axes of the 3D grid. For the 1D comparison case the ordinate\nshows \u00b1 distance from the center.\n\n\f6\n\nBaron and Hauschildt: 3D radiative transfer framework II\n\nFig. 7. Convergence of the iterations for the line transfer case with \u01ebl = 10\u22122 . The maximum relative corrections (taken over all\nspatial points) are plotted vs. iteration number.\n\n\fBaron and Hauschildt: 3D radiative transfer framework II\n\n7\n\nFig. 8. Convergence of the iterations for the line transfer case with \u01ebl = 10\u22124 . The maximum relative corrections (taken over all\nspatial points) are plotted vs. iteration number.\n\n\f8\n\nBaron and Hauschildt: 3D radiative transfer framework II\n\nFig. 9. Convergence of the iterations for the line transfer case with \u01ebl = 10\u22128 . The maximum relative corrections (taken over all\nspatial points) are plotted vs. iteration number.\n\n\fBaron and Hauschildt: 3D radiative transfer framework II\n\n9\n\nFig. 10. Convergence of the iterations for the line transfer case with different \u01ebl as indicated in the legend. The maximum relative\ncorrections (taken over all spatial points) are plotted vs. iteration number. The symbols without connecting lines are the convergence\nrates obtained without using Ng acceleration.\n\n\f\fA&A manuscript no.\n(will be inserted by hand later)\nYour thesaurus codes are:\nmissing; you have not inserted them\n\nMAINTITLE should be given\nName(s) and initial(s) of author(s) should be given\nAddress(es) of author(s) should be given.\n\narXiv:astro-ph/0703437v1 16 Mar 2007\n\n[the date of receipt and acceptance should be inserted later]\n\nAbstract. Not yet given.\nKey words: Not yet given.\n\nASTRONOMY\nAND\nASTROPHYSICS\n16.7.2018\n\n\f"}