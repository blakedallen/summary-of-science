{"id": "http://arxiv.org/abs/1105.0270v2", "guidislink": true, "updated": "2012-12-25T10:07:04Z", "updated_parsed": [2012, 12, 25, 10, 7, 4, 1, 360, 0], "published": "2011-05-02T09:17:33Z", "published_parsed": [2011, 5, 2, 9, 17, 33, 0, 122, 0], "title": "Stability of a Markov-modulated Markov Chain, with application to a\n  wireless network governed by two protocols", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1105.5970%2C1105.0850%2C1105.4297%2C1105.0814%2C1105.1099%2C1105.3535%2C1105.0075%2C1105.2273%2C1105.0241%2C1105.1915%2C1105.5393%2C1105.6177%2C1105.4444%2C1105.2753%2C1105.3400%2C1105.4435%2C1105.5024%2C1105.2279%2C1105.0662%2C1105.6310%2C1105.3555%2C1105.2341%2C1105.3151%2C1105.3750%2C1105.5275%2C1105.2719%2C1105.1981%2C1105.0794%2C1105.2961%2C1105.2470%2C1105.2585%2C1105.4342%2C1105.1021%2C1105.1266%2C1105.3303%2C1105.6319%2C1105.5099%2C1105.1602%2C1105.2282%2C1105.2841%2C1105.4310%2C1105.0924%2C1105.2490%2C1105.4092%2C1105.4636%2C1105.3864%2C1105.1526%2C1105.2984%2C1105.4810%2C1105.4868%2C1105.1101%2C1105.1722%2C1105.5298%2C1105.5436%2C1105.5828%2C1105.3388%2C1105.4772%2C1105.4599%2C1105.0982%2C1105.1512%2C1105.0330%2C1105.4171%2C1105.1566%2C1105.0730%2C1105.0890%2C1105.5626%2C1105.2152%2C1105.1680%2C1105.3530%2C1105.3451%2C1105.3728%2C1105.4498%2C1105.2301%2C1105.0161%2C1105.0894%2C1105.0304%2C1105.4217%2C1105.4118%2C1105.5309%2C1105.6101%2C1105.2589%2C1105.1036%2C1105.0121%2C1105.0404%2C1105.0226%2C1105.4579%2C1105.4951%2C1105.4899%2C1105.3156%2C1105.1815%2C1105.4353%2C1105.5548%2C1105.2456%2C1105.3814%2C1105.5586%2C1105.2131%2C1105.3285%2C1105.4485%2C1105.0270%2C1105.2109%2C1105.0332&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Stability of a Markov-modulated Markov Chain, with application to a\n  wireless network governed by two protocols"}, "summary": "We consider a discrete-time Markov chain $(X^t,Y^t)$, $t=0,1,2,...$, where\nthe $X$-component forms a Markov chain itself. Assume that $(X^t)$ is\nHarris-ergodic and consider an auxiliary Markov chain ${\\hat{Y}^t}$ whose\ntransition probabilities are the averages of transition probabilities of the\n$Y$-component of the $(X,Y)$-chain, where the averaging is weighted by the\nstationary distribution of the $X$-component.\n  We first provide natural conditions in terms of test functions ensuring that\nthe $\\hat{Y}$-chain is positive recurrent and then prove that these conditions\nare also sufficient for positive recurrence of the original chain $(X^t,Y^t)$.\nThe we prove a \"multi-dimensional\" extension of the result obtained. In the\nsecond part of the paper, we apply our results to two versions of a\nmulti-access wireless model governed by two randomised protocols.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1105.5970%2C1105.0850%2C1105.4297%2C1105.0814%2C1105.1099%2C1105.3535%2C1105.0075%2C1105.2273%2C1105.0241%2C1105.1915%2C1105.5393%2C1105.6177%2C1105.4444%2C1105.2753%2C1105.3400%2C1105.4435%2C1105.5024%2C1105.2279%2C1105.0662%2C1105.6310%2C1105.3555%2C1105.2341%2C1105.3151%2C1105.3750%2C1105.5275%2C1105.2719%2C1105.1981%2C1105.0794%2C1105.2961%2C1105.2470%2C1105.2585%2C1105.4342%2C1105.1021%2C1105.1266%2C1105.3303%2C1105.6319%2C1105.5099%2C1105.1602%2C1105.2282%2C1105.2841%2C1105.4310%2C1105.0924%2C1105.2490%2C1105.4092%2C1105.4636%2C1105.3864%2C1105.1526%2C1105.2984%2C1105.4810%2C1105.4868%2C1105.1101%2C1105.1722%2C1105.5298%2C1105.5436%2C1105.5828%2C1105.3388%2C1105.4772%2C1105.4599%2C1105.0982%2C1105.1512%2C1105.0330%2C1105.4171%2C1105.1566%2C1105.0730%2C1105.0890%2C1105.5626%2C1105.2152%2C1105.1680%2C1105.3530%2C1105.3451%2C1105.3728%2C1105.4498%2C1105.2301%2C1105.0161%2C1105.0894%2C1105.0304%2C1105.4217%2C1105.4118%2C1105.5309%2C1105.6101%2C1105.2589%2C1105.1036%2C1105.0121%2C1105.0404%2C1105.0226%2C1105.4579%2C1105.4951%2C1105.4899%2C1105.3156%2C1105.1815%2C1105.4353%2C1105.5548%2C1105.2456%2C1105.3814%2C1105.5586%2C1105.2131%2C1105.3285%2C1105.4485%2C1105.0270%2C1105.2109%2C1105.0332&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We consider a discrete-time Markov chain $(X^t,Y^t)$, $t=0,1,2,...$, where\nthe $X$-component forms a Markov chain itself. Assume that $(X^t)$ is\nHarris-ergodic and consider an auxiliary Markov chain ${\\hat{Y}^t}$ whose\ntransition probabilities are the averages of transition probabilities of the\n$Y$-component of the $(X,Y)$-chain, where the averaging is weighted by the\nstationary distribution of the $X$-component.\n  We first provide natural conditions in terms of test functions ensuring that\nthe $\\hat{Y}$-chain is positive recurrent and then prove that these conditions\nare also sufficient for positive recurrence of the original chain $(X^t,Y^t)$.\nThe we prove a \"multi-dimensional\" extension of the result obtained. In the\nsecond part of the paper, we apply our results to two versions of a\nmulti-access wireless model governed by two randomised protocols."}, "authors": ["Sergey Foss", "Seva Shneer", "Andrey Tyurlikov"], "author_detail": {"name": "Andrey Tyurlikov"}, "author": "Andrey Tyurlikov", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1214/11-SSY30", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1105.0270v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1105.0270v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "23 pages", "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "60J05, 60K20 (Primary)", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1105.0270v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1105.0270v2", "journal_reference": "Stochastic Systems, 2012, Vol. 2, No. 1, 208-231", "doi": "10.1214/11-SSY30", "fulltext": "Stochastic Systems\n\narXiv:1105.0270v2 [math.PR] 25 Dec 2012\n\nSTABILITY OF A MARKOV-MODULATED MARKOV\nCHAIN, WITH APPLICATION TO A WIRELESS\nNETWORK GOVERNED BY TWO PROTOCOLS\nBy Sergey Foss\n\n\u2217,\u2020,\u2021\n\n, Seva Shneer\n\n\u2217,\u2020\n\nand Andrey Tyurlikov\n\n\u2217,\u00a7\n\nHeriot-Watt University, Edinburgh\u2020 , Institute of Mathematics, Novosibirsk\u2021\nand St. Petersburg State University of Aerospace Instrumentation\u00a7\nWe consider a discrete-time Markov chain (X t , Y t ), t = 0, 1, 2, . . .,\nwhere the X-component forms a Markov chain itself. Assume that\n(X t ) is Harris-ergodic and consider an auxiliary Markov chain {Yb t }\nwhose transition probabilities are the averages of transition probabilities of the Y -component of the (X, Y )-chain, where the averaging is\nweighted by the stationary distribution of the X-component.\nWe first provide natural conditions in terms of test functions ensuring that the Yb -chain is positive recurrent and then prove that\nthese conditions are also sufficient for positive recurrence of the original chain (X t , Y t ). The we prove a \"multi-dimensional\" extension\nof the result obtained. In the second part of the paper, we apply our\nresults to two versions of a multi-access wireless model governed by\ntwo randomised protocols.\n\n1. Introduction. We develop an approach to the stability analysis\nbased on an averaging Lyapunov criterion. More precisely, we consider a\ndiscrete-time Markov chain {Z t , t = 0, 1, 2, . . .} with values in a general\nstate space which has two components, Z t = (X t , Y t ). We assume that the\nfirst component {X t } forms a Markov chain itself. We further assume that\nthe Markov chain {X t } is Harris-ergodic, i.e. there exists a unique stationary distribution \u03c0X and, for any initial value X 0 = x, the distribution of X t\nconverges to the stationary distribution in the total variation norm:\nsup |P(X t \u2208 A) \u2212 \u03c0X (A)| \u2192 0 as\n\nt \u2192 \u221e.\n\nA\u2208BX\n\nIn many known models in applied probability, the time evolution of the\nprocess describing the state of the system may be expressed as a multicomponent Markov chain where one of the components is either a Markov\nchains itself (see, e.g. [13], [14], [17], [7] and references therein) or, more\n\u2217\nThe research of the authors was partially supported by the Royal Society International\nJoint Project\nAMS 2000 subject classifications: Primary 93E15; secondary 60K25, 68M20\nKeywords and phrases: stochastic stability, Markov-modulated Markov chain\n\n1\n\n\f2\n\ngenerally, behaves as\"almost stable\", changing only relatively slowly, while\nthe other component changes more rapidly (see, e.g., [22]).\nOur aim is to formulate and prove a stability criterion for the two-component\nMarkov chain Z t = (X t , Y t ) by making links to an auxiliary Markov chain\nb t , Yb t ), where {X\nb t } is an i.i.d. sequence with common distribution \u03c0X .\n(X\nFirst, one can recall a standard approach to the stability analysis which\nmay be used for this model and which is based on the following two-step\nscheme. To simplify the explanation, assume that the first-component Markov\nchain {X t } is regenerative with regeneration times 0 \u2264 T0 < T1 < . . ., so\nthat all values X Tn are equal to, say, x0 = const.\ne n , Ye n ) =\nStep 1. Consider an embedded 2-component Markov chain (X\nT\nT\nn\nn\n(X , Y ) at the regenerative epochs T0 < T1 < . . . < Tn < . . .. Since\ne n \u2261 x0 , the sequence {Ye n } also forms a Markov chain. For this chain one\nX\nmay show that, under appropriate assumptions and for an appropriate test\n(Lyapunov) function L, the drift EL(Ye 1 | Yf0 = y) \u2212 L(y) is bounded from\nabove by the same constant for all values of y and is also uniformly negative\nif y is outside of a certain \"bounded\" set, and hence this bounded set is\npositive recurrent. For that, it is necessary to find or estimate from above\nthe average drift of L(Y n ) over a typical cycle, say T1 \u2212 T0 . By introducing\nfurther smoothness condition(s), one can then ensure that the Markov chain\n{Ye n } is also Harris ergodic.\nStep 2. According to step 1, one can say that the Markov chain {(X n , Y n )}\nis regenerative, then verify its aperiodicity and conclude that it is Harris\nergodic.\nHowever, the first step of the proposed scheme may not be implementable\nif the transition function is not sufficiently smooth (and, in particular, has\ndiscontinuities) as then it may be difficult to find/estimate the value of the\naverage drift of L(Y ) during a typical cycle.\nAnother approach to proving stability is the use of fluid limits (see, e.g.,\n[9], [10] and Chapter 10 of [18]). To apply this method, one needs to prove the\nconvergence of an appropriately scaled version of the process, establish the\ndynamics of the limit, show that these dynamics are in some sense stable and\nthen prove that this \"stability\" of the limit implies stability of the original\nMarkov Chain. This is however often rather cumbersome and technically\ninvolved and moreover requires additional assumptions on the Markov chain.\nIn this paper we introduce a different approach which is based on the\nfollowing idea.\nFirst, we find the (unique) stationary distribution \u03c0X for the X-component.\nSecond, we introduce an auxiliary (time-homogeneous) Markov chain {Yb t }\n\n\fMULTI-RADIO\n\n3\n\nwith transition probabilities\n(1)\n\nP(Yb t+1 \u2208 * |Yb t = y) =\n\nZ\n\n\u03c0X (dx)P(Y 1 \u2208 * X 1 = x, Y 0 = y) a.s.\nX\n\nThis Markov chain can also be viewed as an outcome of the following recurb t , Yb t ) whose first\nsive construction of a two-dimensional Markov chain (X\nb t have common distribution \u03c0X . First, for each t, we decomponents X\nt+1\nb\ntermine X\nas a random variable which does not depend on all r.v.'s\nb k }k\u2264t , {Yb k }k\u2264t , and has distribution \u03c0X . Second, we determine Yb t+1 as\n{X\na random variable which is\nb k }k\u2264t , {Yb k }k\u2264t\u22121 given X\nb t+1 and Yb t ,\n(a) conditionally independent of {X\nand\n(b) has distribution\nb t+1 = x, Yb t = y) = P(Y 1 \u2208 * X 1 = x, Y 0 = y) a.s.\nP(Yb t+1 \u2208 * |X\n\nThen, indeed, {Yb t } forms a (time-homogeneous) Markov chain with transition probabilities given by (1).\nIn this paper, we formulate and prove general stability criteria in terms\nof averaging Lyapunov functions. In particular, we introduce natural conditions for the following implication to hold: if the Markov chain {X t } is\nHarris ergodic then the Markov chain {Yb t } is positive recurrent. The same\nconditions are then proved to imply that the Markov chain {(X t , Y t )} is\npositive recurrent too.\nWe formulate and prove general stability results (Theorems 1 and 2) in\nSection 2. In Theorem 1 we obtain a \"one-dimensional\" result and then in\nTheorem 2 its multivariate analogue. Then in Section 3 we study the stability of two systems with multiple access random protocols in a changing\nenvironment. The proofs for their stability are carried out by applying Theorem 2 and using the monotonicity arguments. In these particular scenarios\nwe also show that the stability conditions are necessary (if they do not hold,\nthen the system under consideration is unstable).\n2. Stability of two-component Markov chains using averaging\nLyapunov functions. In this section we consider a general framework\nfor the stability of a Markov Chain containing two components one of which\nis a Markov Chain itself.\nIn what follows, we write for short Px (. . .) instead of P(. . . | X0 = x),\nPy (. . .) instead of P(. . . | Y0 = y), and Px,y (. . .) instead of P(. . . | X0 =\nx, Y0 = y). We use similar notation Ex , Ey , and Ex,y for conditional expectations.\n\n\f4\n\n2.1. One-dimensional case. Let {X t } and {Y t } be random sequences\ntaking values in measurable spaces (X , BX ) and (Y, BY ), respectively, with\ncountably generated sigma-algebras BX and BY . Assume that {(X t , Y t )}\nis a Markov Chain on the state space (X \u00d7 Y, BX \u00d7 BY ) (here BX \u00d7 BY is\nthe minimal sigma-algebra generated by sets B1 \u00d7 B2 where B1 \u2208 BX and\nB2 \u2208 BY ). Assume also the following:\nA0. {X t } is a Markov Chain with \"autonomous\" dynamics: for all x \u2208\nX and y \u2208 Y,\nPx,y (X 1 \u2208 *) = Px (X 1 \u2208 *).\nFurther, the Markov chain {X t } satisfies the following conditions:\nA1. It is aperiodic;\nA2. There exists a set V \u2208 BX such that\n(2)\n\n\u03c4 \u2261 \u03c4 (V ) = min{t \u2265 1 : X t \u2208 V } < \u221e Px \u2212 a.s.\n\nfor any initial value X0 = x \u2208 X and, moreover,\ns0 = sup Ex \u03c4 < \u221e.\n\n(3)\n\nx\u2208V\n\n(We say that the set V is positive recurrent for {X t } if conditions (2) and (3)\nhold.)\nA3. The set V admits a minorant measure, or is petite (in the terminology of [19]), i.e. there exist a number 0 < p \u2264 1, a measure \u03bc and an\ninteger m \u2265 1 such that\nPx (X m \u2208* ) \u2265 p\u03bc(* )\nfor any x \u2208 V .\nConditions A1\u2013A3 imply that the X-chain is Harris ergodic, so there\nexists a stationary distribution \u03c0 = \u03c0X such that\n\u0001\n(4)\nsup Px X t \u2208 B \u2212 \u03c0(B) \u2192 0\nB\u2208B\n\nas t \u2192 \u221e, for any x \u2208 X . Moreover, Conditions A1-A3 imply that\n(5)\n\nconvergence in (4) is uniform in x \u2208 V,\n\nsee e.g. [6], [23] or [16]. We can formulate also a coupling version of conditions\n(4)\u2013(5):\nfor any x \u2208 V , there is a coupling of {X t } and of a stationary Markov chain\nb t } having distribution \u03c0 such that\n{X\n\n(6)\n\nb k , for all k \u2265 t} < \u221e Px \u2212 a.s.\n\u03bd = min{t : X k = X\n\n\f5\n\nMULTI-RADIO\n\nfor X0 = x and\n(7)\n\n\u03b4t := sup Px (\u03bd > t) \u2192 0,\n\nt \u2192 \u221e,\n\nx\u2208V\n\nsee Appendix A for a proof of (6) and (7).\nIntroduce a function\n(\nEx \u03c4, if x \u2208\n/ V,\n(8)\nL1 (x) =\n0, if x \u2208 V.\nThen\n(9)\nfor all x \u2208\n/ V and\n(10)\n\n\u0001\nEx L1 (X 1 ) \u2212 L1 (x) = \u22121\n\n\u0001\nEx L1 (X 1 ) \u2212 L1 (x) \u2264 sup Ex \u03c4 \u2212 1 < \u221e\nx\u2208V\n\nfor all x \u2208 V . These inequalities follow from observing that \u03c4X1 = \u03c4x \u2212 1\nPx \u2212 a.s. if X1 \u2208\n/ V . Inequalities (9) and (10) mean that the function L1 is\nan appropriate Lyapunov function for the Markov Chain {X t } in the sense\nthat it satisfies the standard conditions for the Foster criterion to hold.\nIt is known (see, e.g., [6], [23] or [16]) that Conditions A1\u2013A3 imply that\n(11)\n\nlim\n\nt\u2192\u221e\n\n1\nsup Ex L1 (X t ) = 0.\nt x\u2208V\n\nB. For the sequence {Y t } we assume that there exists a non-negative\nmeasurable function L2 such that:\nB1. The expectations of the absolute values of the increments of the\nsequence {L2 (Y t )} are bounded from above by a constant U :\n\u0001\n\u0001\nsup Ex,y L2 Y 1 \u2212 L2 Y 0 \u2264 U < \u221e.\nx\u2208X ,y\u2208Y\n\nB2. There exist a non-negative and non-increasing function h(N ), N \u2265\n0 such that h(N ) \u2193 0 as N \u2192 \u221e, and a measurable function f : X \u2192\n(\u2212\u221e, \u221e) such that\nZ\nf (x)\u03c0(dx) := \u2212\u03b5 < 0\n\nX\n\nand\n\n(12)\n\n\u0001\n\u0001\nEx,y L2 Y 1 \u2212 L2 (y) \u2264 f (x) + h(L2 (y))\n\n\f6\n\nfor all x \u2208 X and y \u2208 Y.\nIt follows from Condition B1 that, without loss of generality, the function\nf may be assumed to be bounded:\n(13)\n\nsup |f (x)| = K < \u221e.\nx\u2208X\n\nRemark 1. Note that conditions B are sufficient for stability of the\nchain Yb introduced in (1), due to the standard Foster criterion. We are\ngoing to show that they (together with conditions A) are also sufficient for\nstability of the original chain {Z t }.\nLemma 1. Conditions A and B imply that, for some positive integer t0\nand for any integer t \u2265 t0 there exists a positive number N0 = N0 (t0 ) such\nthat if L2 (y) \u2265 N0 , then\n\u0001\n(14)\nEx,y L2 (Y t ) \u2212 L2 (y) \u2264 \u2212t\u2206\nfor all x \u2208 V with \u2206 = \u03b5/10.\n\nProof. Due to conditions (5) and (13), for any c1 \u2208 (0, 1) one can choose\na number n0 such that\nZ\n\u0001\u0001\nt\nf (z)\u03c0(dz) \u2264 c1 .\n\u2212\n(15)\nsup sup Ex f X\nt\u2265n0 x\u2208V\n\nX\n\nLet t = n0 + m. Then, for x \u2208 V , y \u2208 Y and for U from Condition B1,\n\nEx,y (L2 (Y t ) \u2212 L2 (y)) =\n\nt\u22121\nX\ni=0\n\n\u0001\u0001\n\u0001\nEx,y L2 Y i+1 \u2212 L2 Y i\n\n\u2264 U n0 +\n\nt\u22121\nX\n\nEx,y E L2 Y i+1\n\ni=n0\n\n\u2264 U n0 +\n\nt\u22121\nX\n\ni=n0\n\n\u0001\u0001\n\u0001\n| X i , Y i \u2212 L2 Y i\n\n\u0001\n\u0001\u0001\nEx,y f X i + h Y i\n\n\u2264 U n0 \u2212 (\u03b5 \u2212 c1 )m +\n\u0012\n\n\u0001\n\nt\u22121\nX\n\ni=n0\n\nEx,y h Y i\n\u0012\n\n\u0001\n\nb\n\u2264 U n0 \u2212 m \u03b5 \u2212 c1 \u2212 h(0)Px,y min L2 (Y ) < N\ni\n\ni\u2264t\n\n\u0013\n\n\u0013\nb)\n\u2212 h(N\n\n\fMULTI-RADIO\n\n7\n\nb is any positive number. Take c1 = \u03b5/5 and then m0 = max(n0 , 5U n0 /\u03b5)\nwhere N\nb be such that h(N\nb ) \u2264 \u03b5/5\nand t0 = n0 + m0 . Then, for any m \u2265 m0 , let N\n2\nb \u2264 \u03b5/5. Further, let N0 = 2N\nb . If L2 (y) \u2265 N0 , then\nand h(0)(n0 + m) U/N\n\u0012\n\u0013\n\u0010\n\u0011\ni\nb /t\nb\nPx,y min L2 (Y ) < N\n\u2264 t sup Pz,u L2 (Y 1 ) \u2212 L2 (u) \u2264 \u2212N\n1\u2264i\u2264t\n\nz,u\n\nb \u2264 \u03b5/5,\n\u2264 h(0)t2 U/N\n\nwhere we applied the Markov inequality. Hence, for x \u2208 V and y such that\nL2 (y) \u2265 N0 ,\n\u03b5\n\u03b5\nEx,y (L2 (Y t ) \u2212 L2 (y)) \u2264 \u2212m \u2264 \u2212t\n5\n10\nand therefore inequality (14) holds with \u2206 = \u03b5/10.\nTheorem 1. Under the conditions A and B there exists N0 such that\nthe set D := V \u00d7 {y : L2 (y) \u2264 N0 } is positive recurrent for the Markov\nChain {(X t , Y t )}.\nCorollary 1. Assume Conditions A and Condition B1 to hold. As- \u0001\nsume further that, uniformly in x \u2208 X , the conditional distribution Px,y (L2 Y 1 \u2212\nL2 (y) \u2208 *) converges weakly and in L1 to a limiting one, say Hx (*), as\nL2 (y) \u2192 \u221e, where\nZ Z\n\u03c0(dx)yHx (dy)\n\nX\n\nY\n\nis negative. Then the Markov Chain {(X t , Y t )} is positive recurrent.\n\nProof of Theorem 1. We use the following extension of the Foster\ncriterion (see, e.g., [12, Theorem 1] or [8] and references therein). Let L :\nX \u00d7 Y \u2192 [0, \u221e) be a measurable function. Then a set D = {(x, y) :\nL(x, y) \u2264 N } is positive recurrent if there exists a positive integer-valued\nmeasurable function T on X \u00d7 Y such that\nT (x, y)\n< \u221e,\nx,y max(1, L(x, y))\n\u0011\n\u0010\nsup Ex,y L X T (x,y) , Y T (x,y) < \u221e\nsup\n\n(x,y)\u2208D\n\nand\n(16)\n\n\u0011\n\u0010\nEx,y L X T (x,y) , Y T (x,y) \u2212 L(x, y) \u2264 \u2212cT (x, y)\n\nfor some c > 0 and for all (x, y) \u2208\n/ D.\n\n\f8\n\nLet H > U with U from condition B1 and let t0 be such that\n(17)\n\nsup\nt\u2265t0\n\n\u2206\n1\nsup Ex L1 (X t ) \u2264\n,\nt x\u2208V\n2H\n\nb be\nwhich is possible due to (11). Here again \u2206 = \u03b5/10. Let n0 ,m and N\nb.\nchosen according to Lemma 1 with t0 from (17). Let again N0 = 2N\nWe take the set D = V \u00d7 {y : L2 (y) \u2264 N0 } and define a function\nL(x, y) = HL1 (x) + L2 (y).\n\nFurther, take T (x, y) = 1 if either (x, y) \u2208 D or x \u2208\n/ V and T (x, y) = t if\nx \u2208 V and L2 (y) > N0 , where t = n0 + m is from the proof of Lemma 1.\nNow, if (x, y) \u2208 D, then\nEx,y L(X 1 , Y 1 ) \u2212 L(x, y) \u2264 H sup Ex \u03c4 + U.\nx\u2208V\n\nIf x \u2208\n/ V , then\nEx,y L(X 1 , Y 1 ) \u2212 L(x, y) \u2264 \u2212H + U < 0.\nFinally, if x \u2208 V and L2 (y) > N0 , then, by (14),\n\u0011\n\u0010\n\u2206\n\u2206\n\u2212 t\u2206 = \u2212t .\nEx,y L X T (x,y) , Y T (x,y) \u2212 L(x, y) \u2264 Ht\n2H\n2\n2.2. Multivariate case. Now we formulate and prove a multivariate analogue of Theorem 1. We modify the model as follows. We continue to assume\nthat {(X t , Y t )} is a Markov Chain on the state space (X \u00d7 Y, BX \u00d7 BY ) and\nthat {X t } is a Markov chain satisfying conditions A0\u2013A3. But now we asf1 \u00d7 . . . \u00d7 Y\ng\nsume that the state space Y is a product of M spaces Y = Y\nM\n(with the product sigma-algebra), so the Y -component of the Markov chain\nt ). Clearly, the results of the previous\nhas M coordinates, Y t = (Y1t , . . . , YM\nsection hold in this case too. However, they turn out not to be applicable\nin the examples we are going to consider in the second part of the paper,\nand in this section we develop conditions only involving each individual coordinate of the Y -chain. We believe that these conditions may be useful in\nmany applied models and, in particular, where the Y -chain has a number of\ncoordinates which may be dependent but have simple individual dynamics.\nWe assume that there is a non-negative function L2,i defined on Yei and\nthat conditions similar to B1 \u2212 B2 hold for each coordinate.\n\n\fMULTI-RADIO\n\n9\n\nf\nB1.\nFor any i = 1, . . . , M , the expectations of the absolute values of the\nincrements of the sequence {L2,i (Yit )} are bounded from above by a constant\nU:\n\u0001\n\u0001\nsup Ex,y L2,i Yi1 \u2212 L2,i Yi0 \u2264 U < \u221e.\nx\u2208X ,y\u2208Y\n\nf\nB2.\nFor each i, there exists a function hi (N ), N \u2265 0 such that hi (N ) \u2193\n0 as N \u2192 \u221e and a measurable function fi : X \u2192 (\u2212\u221e, \u221e) such that\nsupx |fi (x)| := Ki < \u221e,\nZ\nfi (x)\u03c0(dx) := \u2212\u03b5i < 0\n(18)\nX\n\nand\n(19)\n\n\u0001\n\u0001\nEx,y L2,i Yi1 \u2212 L2,i (yi ) \u2264 fi (x) + hi (L2,i (yi ))\n\nfor all x \u2208 X and y \u2208 Y, where the RHS depends only on the x and on the\nith coordinate of the y.\nIn the multivariate case, the statement of Lemma 1 holds for each coordinate i, and we restate it here for convenience.\nf B2\nf imply that, for some integer t\u2032 and\nLemma 2. Conditions A and B1\u2013\n\u2032\nfor any integer t \u2265 t , there exists a positive number N0 such that, for any\ni, if L2,i (y) \u2265 N0 then for all x \u2208 V\n\u0001\n(20)\nEx,y L2,i (Y t ) \u2212 L2,i (y) \u2264 \u2212t\u2206,\n\nwhere \u2206 = min \u03b5i /10.\n\nt , Y t )} is a Markov chain for each i, then\nIf the sequence {(X1t , .., XM\ni\nclearly, Theorem 1 also holds for each coordinate i, meaning that the Markov\nt , Y t )} for any coordinate i is positive recurrent. However,\nchain {(X1t , .., XM\ni\nthis does not imply the positive recurrence of the entire chain\nt , Y t , .., Y t )}. In order to obtain conditions for stability in the\n{(X1t , .., XM\n1\nM\nmultivariate case (also without assuming that each of the above sequences\nis itself a Markov chain), we require an extra assumption to hold:\nf\nB3.\nFor each i it holds that\n\u0001\nEx,y L2,i (Y t ) \u2212 L2,i (y)|Y 0 = y\n\u21920\nsup sup\nt\nt\u2265N y\u2208Y,x\u2208V\n\nas N \u2192 \u221e.\n\n\f10\n\nf means that the drift of the function L2,i in t steps grows\nAssumption B3\nb\nslower than any linear function of t. Below we provide a simple condition B\nf\nb\nwhich is sufficient for B3 to hold. Note that condition B is a stronger version\ne2 and that it can be easily verified in many applications.\nof condition B\n\nLemma 3. Assume that the following condition holds:\nb\nB.\nFor each i, there exist a non-negative and non-increasing function\nhi (N ),N \u2265 0 such that hi (N ) \u2193 0 as N \u2192 \u221e, and a family of mutually\nindependent random variables {\u03c6tx,i }, x \u2208 X , t = 0, 1, . . . such that,\n(i) for each t and i these random variables are uniformly integrable;\n(ii) for each i and x, the random variables {\u03c6tx,i , t = 0, 1, . . .} are identically distributed with common distribution function Fx,i , which is such\nthat Fx,i (y) is measurable as a function of x for any fixed y;\n(iii) the inequality\n\u0001\n\u0001\n(21)\nL2,i Yit+1 \u2212 L2,i Yit \u2264 \u03c6tX t ,i + hi (L2,i (Yit )) a.s.\nholds for all x \u2208 X , y \u2208 Y and t = 0, 1, . . .;\n(iv) functions fi (x) = E\u03c61x,i satisfy condition (18).\n\nf holds too.\nThen assumption B3\n\nWe will now formulate the main theorem and then prove it. A proof of\nLemma 3 is presented after the proof of the main theorem.\n\nf \u2212 B3\nf (or asTheorem 2. Under assumptions A and assumptions B1\nf and B),\nb there exists N1 \u2265 N0 such that the set D := V \u00d7 {y :\nsumptions B1\nM\nP\nL2 (yi ) \u2264 N1 } is positive recurrent for the Markov Chain {(X t , Y t )}.\n1=i\n\nProof of Theorem 2. We may apply Lemma 2 to each of Yi and may\ntherefore assume that inequality (20) holds for each coordinate, with the\nsame t\u2032 and the same \u2206.\nDue to condition (11), we may also assume that t\u2032 is such that\n\n(22)\n\nsup\nt\u2265t\u2032\n\n1\n\u2206\nsup Ex L1 (X t ) \u2264\n,\nt x\u2208V\n2H\n\nwhere H is any positive number larger than M U with U from assumption\nf\nB1.\nChoose also n0 such that\n(23)\n\n\u0001\n\u2206\nt\nEx,y L2,i (Y t ) \u2212 L2,i (y)|Y 0 = y \u2264\n2M\n\n\f11\n\nMULTI-RADIO\n\nf\nfor all t \u2265 n0 and for all y. This is possible due to condition B3.\nWe again use Theorem 1 of [12]. Take N1 = M N0 so that D = V \u00d7 {y :\nM\nP\nL2 (yi ) \u2264 M N0 } and introduce test function\n\ni=1\n\nL(x, y) = HL1 (x) +\n\nX\n\nL2,i (yi ).\n\ni\n\nLet T (x, y) = 1 if either (x, y) \u2208 D or x \u2208\n/ V and T (x, y) = t1 := max{t\u2032 , n0 },\notherwise.\nNow, if (x, y) \u2208 D, then\nEx,y L(X 1 , Y 1 ) \u2212 L(x, y) \u2264 H sup Ex \u03c4 + M U < \u221e.\nx\u2208V\n\nIf x \u2208\n/ V , then\nEx,y L(X 1 , Y 1 ) \u2212 L(x, y) \u2264 \u2212H + M U < 0.\nAnd if x \u2208 V and\n\nM\nP\n\nL2,i (yi ) > M N0 , then L2,i (yi ) > N0 for at least one\n\ni=1\n\nindex i. Denote by k the number of such indices. Then, by (20), (22) and\n(23),\n\u0011\n\u0010\n\u2206\n\u2206\n\u2206\n\u2212kt1 \u2206+(M \u2212k)\nt1 \u2264 \u2212t1\nEx,y L X T (x,y) , Y T (x,y) \u2212L(x, y) \u2264 Ht1\n2H\n2M\n2M\n\nT (x,y)\nas k \u2265 1. Clearly, supx,y max(1,L(x,y))\n< \u221e, so the theorem is proved.\nProof of lemma 3. Let C1 = max1\u2264i\u2264M hi (0) and C2 > 0 be such that\nhi (C2 ) \u2264 \u03b5i /2 for all i. Then inequality (21) implies that\n\n(24)\n\nt\nt\nL2,i (Yit+1 ) \u2212 L2,i (Yit ) \u2264 \u03c8X\na.s.,\nt ,i + C1 I(L2,i (Yi ) \u2264 C2 )\n\nt\nt\nwhere \u03c8X\nt ,i = \u03c6X t ,i + \u03b5i /2.\nLet \u03bdt \u2264 t be the last time k before t when L2,i (Yik ) \u2264 C2 (we let \u03bdt = 0\nif such k does not exist). Then\n\nL2,i (Yit+1 ) \u2212 L2,i (Yi0 ) \u2264 C1 + C2 +\n\nt\nX\n\nk\n\u03c8X\nk ,i\n\nk=\u03bdt\n\n\u2264 C1 + C2 + max\n\n0\u2264j\u2264t\n\nt\nX\nk=j\n\nk\n\u03c8X\nk ,i .\n\n\f12\n\nb t be a stationary sequence satisfying conditions (6)-(7).\nFor each x \u2208 V , let X\nThen\nt\n\nX\n1\nk\n\u03c8X\n\u2264\nmax\nk ,i\nt 0\u2264j\u2264t\nk=j\n\nt\n\nt\n\nX\n1X k\n1\nk\nk\n\u03c8X\n+\nmax\n\u03c8X k ,i \u2212 \u03c8X\nb k ,i\nb k ,i .\nt 0\u2264j\u2264t\nt 0\nk=j\n\nHere the first summand on the RHS tends to 0 both a.s. and in mean, since\nthe sequence {\u03c8 kb k } is stationary ergodic with negative mean E\u03c8 1b 1 \u2264\nX ,i\nX ,i\n\u2212\u03b5i /2. The second summand also tends to 0 in mean uniformly in x \u2208 V ,\ndue to uniform integrability. Indeed, for any \u2206 > 0 let R be such that\n1 I(|\u03c8 1 | > R) \u2264 \u2206, for all x \u2208 X. Then for any x \u2208 V and any k\nE \u03c8x,i\nx,i\n\u0010\n\u0011\nk\nk\nk\nE \u03c8X\nI\n\u03c8\n=\n6\n\u03c8\nk ,i\nb k ,i\nX k ,i\nX\n\n\u2264 \u2206 + R\u03b4k\n\nand a similar inequality holds for \u03c8 kb k . Therefore,\nX ,i\n\nt\n\nE\n\n1X k\nk\n\u03c8X k ,i \u2212 \u03c8X\nb k ,i\nt\n0\n\n\u2264\n\nt\n\u0011\n\u0011 \u0010\n1X \u0010 k\nk\nk\nk\nE \u03c8X k ,i + \u03c8X\nI\n\u03c8\n=\n6\n\u03c8\nb k ,i\nb k ,i\nb k ,i\nX\nX\nt\n0\n\nt\n\n\u2264 2\u2206 + 2R\n\n1X\n\u03b4k .\nt\n0\n\nAs \u2206 is arbitrary small and \u03b4t \u2192 0, the second summand on the RHS of the\nlatter inequality may be made arbitrarily small, and the result follows.\n3. Stability of two systems with two random multiple-access\nprotocols and a finite number of stations. In order to improve performance and usability of laptops, tablet computers and other portable equipment, such devices are nowadays often endowed with several wireless interfaces. For example, if a device is equipped with the WiFi interface (protocol standard IEEE 802.11) and the WiMax interface (protocol standard\nIEEE 802.16), the user has a wide range of possibilities for the wireless\nexchange of data. However, it is known that if the same device uses both\nthese standards, their data streams interfere with each other and the speed\nof transmission and throughputs therefore deteriorate. There are currently\nattempts to minimise the effect of such interference (see, e.g. [2], [25]).\nIn this paper we introduce a simplified model that mimics the essential\nfeatures of both standards and of the interference between them described in\nthe previous paragraph. The IEEE 802.11 standard uses a random-access algorithm for message transmissions, therefore multiple message transmissions\n\n\fMULTI-RADIO\n\n13\n\nmay be attempted simultaneously and collide with each other. Such conflicts\nare then resolved according to a specific algorithm. In the IEEE 802.16 standard message transmission follow a schedule and no conflicts occur. In our\nmodel, we assume that in the random-access algorithm every station transmits with a certain probability, independently of everything else (cf. ALOHA\nalgorithm, see [1] and [21]). Each message that experienced a collision then\nsimply returns to its origin and is treated as any other message. In other\nwords, no conflict-resolution mechanism is implemented. Our model also assumes that the scheduling is completely symmetric: every node receives time\nintervals of the same duration to transmit their messages, successively.\nWe consider two cases. In the first case the system has the so-called MACcoordinator (see [2] and [25]) which gives a priority to the IEEE 802.16\nprotocol. This case is considered in subsection 3.1. The second case concerns\na system without a MAC-coordinator and is considered in subsection 3.2.\n3.1. Network with a MAC-coordinator. Assume there are M identical\nstations numbered 1, ..., M . There are 2 types of messages called \"red\" and\n\"green\", and each station has two infinite buffers where these messages may\nbe stored, one for each type.\nWe make a few assumptions:\nAssumption 1. Time is slotted, stations may only start transmissions at\nthe beginning of a time slot, and each transmission time is equal to the length\nof a slot. Hence, we may assume that the events (such as arrival of a new\nmessage, the beginning of a transmission and the end of a transmission) may\nonly happen at time instants 1, 2, ..... We also assume that the transmission\nchannel is such that, at a given time slot, at most one red and at most one\ngreen message may be transmitted. Note also that any single station cannot\ntransmit two messages (red and green) simultaneously during the same time\nslot. Summarising, in any time slot, there may be no transmissions at all.\nOtherwise, there may be a transmission of either only one red message or\nonly one green message or one red and one green message, but in the latter\ncase the transmissions have to be made by different stations.\nAssumption 2. Transmissions of red messages are scheduled and do\nnot collide. More precisely, for t = 1, 2, . . ., time slot t is scheduled for\na transmission from node i(t) = ((t \u2212 1) mod M ) + 1: if the queue of red\nmessages at that node is non-empty, then there is a (successful) transmission\nof the first one of them; otherwise there is no transmission of red messages\nat that time slot.\nAssumption 3. Transmissions of green messages follow the well-known\nALOHA protocol (see [21]): at a given time slot, every node that is not\n\n\f14\n\ntransmitting a red message and whose queue of green messages is not empty,\ntransmits a green message (say, first in the queue) with probability p, independently of everything else. Then one of three events may occur:\n\u2022 Only one node attempts to transmit a green message. Then the transmission is successful;\n\u2022 No transmission attempted;\n\u2022 Two or more nodes attempt transmissions of green messages. Then all\nthese transmissions fail due to collision, and the messages stay in their\nqueues.\nAssumption 4. Red messages arrive in the system as an i.i.d. sequence\n{\u03be t }t\u22650 with a finite rate \u03bbR = E\u03be t (here \u03be t is the total number of new\nred messages within time slot (t \u2212 1, t]). Similarly, green messages arrive\nindependently as a renewal sequence {\u03b7 t }t\u22650 with a finite rate \u03bbG = E\u03b7 t .\nEvery arriving message is assigned to a node at random with equal probabilities 1/M .\nLet Rit and Gti be the numbers of red and green messages respectively\nin the queue of node i at the beginning of a time slot t. The sequence\nt )} forms a Markov Chain, and so does the sequence {(Rt , ..., Rt , Gt , ..., Gt )}.\n{(R1t , ..., RM\n1\n1\nM\nM\nNote also that the latter Markov Chain describes the state of the system\ncompletely. We will say that the system is stable if its underlying Markov\nChain is positive recurrent.\nFor such an algorithm we prove the following\nTheorem 3. Assume \u03bbR < 1. Then the system is stable if\n(25)\n(\n\u03bbG < (1 \u2212 \u03bbR )p, if M = 1,\n\u03bbG < \u03bbR (M \u2212 1)p(1 \u2212 p)M \u22122 + (1 \u2212 \u03bbR )M p(1 \u2212 p)M \u22121 , if\n\nM >1\n\nand unstable if the opposite strict inequality holds.\nRemark 2. The conditions of the theorem seem to be intuitively clear.\nConsider a single time slot. The average number of new green messages in\na time slot is equal to \u03bbG . Let us now consider the average number of green\nmessages leaving the system. For that, assume that all nodes have a green\nmessage (this may be thought as the \"worst-case\" scenario). Assume also\nthat the Markov chain representing the states of the queues of red messages\nin all nodes is in its stationary regime. In that case, when we look at a single\ntime slot, the queue of red messages of the node that is scheduled to transmit\na red message in the time slot will be non-empty with probability \u03bbR (this\nis quite clear intuitively but see Appendix B for a proof ) and empty with\n\n\fMULTI-RADIO\n\n15\n\nprobability 1 \u2212 \u03bbR . In the former case, there are M \u2212 1 nodes that can\nsuccessfully transmit a green message and probability of success for each of\nthem is p(1 \u2212 p)M \u22122 and therefore the expected number of green messages\nleaving the system is (M \u2212 1)p(1 \u2212 p)M \u22122 . The latter case may be considered\nin a similar way.\nThe simple heuristic argument presented above depends heavily on the\nsymmetry of the system. The symmetry is also essential for our strict analysis.\nProof of Theorem 3. We give a proof only for M > 1. The case M = 1\nmay be considered following the same lines and applying straightforward\nchanges. We start by proving stability, a proof of instability follows.\nProof of stability. We apply Theorem 2. Denote by \u03beit and \u03b7it the\nnumbers of new red and, respectively, green packets arriving at time slot t\nto station i. Since the total number of red arrivals in time slot t is \u03be t and\neach of them chooses one of the stations at random, each \u03beit has\nP a tcondit\ntional binomial distribution with parameters \u03be t and 1/M and M\n1 \u03bei = \u03be .\nt\nSimilarly, for t = 0, 1, . . ., a random variable \u03b7i has a binomial distribution\nwith parameters \u03b7 t and 1/M . Denote also by\n(\n1, with probability p,\n\u03b1ti =\n0, with probability 1 \u2212 p\nthe sequence of i.i.d. random variables representing the decisions taken by\nthe nodes on whether or not to attempt a transmission of a green mest , Gt , ..., Gt )} has the following\nsage. Then the Markov Chain {(R1t , ..., RM\n1\nM\ntransitions:\n(\nRit + \u03beit , if i 6= i(t),\nRit+1 =\nRit + \u03beit \u2212 I{Rit > 0}, if i = i(t),\nwhere, as before, i(t) = ((t\u22121) mod M )+1. Further, let \u03b3jt = \u03b1tj I{Gtj > 0}.\nThen\n\uf8f1\n\u0011\u0010\n\u0011\nQ \u0010\nt\nt I{Rt\nt + \u03b7t \u2212 \u03b3 t\n\uf8f4\n1\n\u2212\n\u03b3\n1\n\u2212\n\u03b3\n=\n0}\n, if i =\n6 i(t),\nG\n\uf8f4\nj\ni\ni\n\uf8f2 i\ni(t)\ni(n)\nj6=i,j6=i(t)\nt+1\n\u0011\nGi =\nQ\u0010\nt ,\nt + \u03b7 t \u2212 I{Rt = 0}\u03b3 t\n\uf8f4\n1\n\u2212\n\u03b3\nif i = i(t).\nG\n\uf8f4\nj\ni\ni\ni\ni\n\uf8f3\nj6=i\n\nt ,G\net )} where the\net , ..., G\nIntroduce now a new Markov Chain {(R1t , ..., RM\n1\nM\nfirst M components (representing the states of the red queues) are the same\n\n\f16\n\nas before, and the remaining components (representing the states of the\ngreen queues) have the following transitions:\n\uf8f1\n\u0011\u0010\n\u0011\nQ \u0010\nt\nt I{Rt\nt\n\uf8f4\net + \u03b7t \u2212 \u03b3\n1\n\u2212\n\u03b1\n1\n\u2212\n\u03b1\n=\n0}\n, if i =\n6 i(t),\n\uf8f4\nG\ne\nj\ni\ni\n\uf8f2 i\ni(t)\ni(t)\nj6=i,j6=i(t)\nt+1\ne\n\u0011\nGi =\nQ\u0010\nt\nt\n\uf8f4\net\n1 \u2212 \u03b1tj , if i = i(t).\n\u03b3it\n\uf8f4\n\uf8f3Gi + \u03b7i \u2212 I{Ri = 0}e\nj6=i\n\net > 0}, for all j and t.\nHere \u03b3\nejt = \u03b1tj I{G\nj\nt ,G\net )} represents the\net , ..., G\nIn words, the Markov Chain {(R1t , ..., RM\n1\nM\nstate of the system where each station with an empty green queue (if not\nblocked by a transmission of a red message) may send (and does so with\nprobability p) a \"dummy\" packet which interferes with (dummy or legitimate) packets of other stations.\nSince \u03b3it \u2264 \u03b1ti a.s. for all i and t, it follows from the two systems of\nequations displayed above that the new Markov Chain dominates the initial\ne1 )}, then\ne1 , ..., G\none: if {(G11 , ..., G1M )} = {(G\n1\nM\nt\nt\net1 , ..., G\netM )}\n{(R1t , ..., RM\n, Gt1 , ..., GtM )} \u2264 {(R1t , ..., RM\n,G\n\na.s., for any t. Hence, to prove stability of the initial Markov Chain, it is\nsufficient to prove stability of the new one. As it follows from Theorem 2,\nLemma 3 and the symmetry of the system, it is sufficient to show that condiet )}.\nf and conditions of Lemma 3 hold for the sequence {(Rt , ..., Rt , G\ntion B1\n1\n1\nM\nNote that it forms a Markov chain in this case. For simplicity, we will\nalso omit the coordinate index 1 in all the functions appearing in conditions. Take function L2 (y) = y and consider the state of the Markov\nt ,G\net )} after every M steps.\nChain {(R1t , ..., RM\n1\nOne can see that, for t = 0, 1, . . .,\n(26)\n\n\u2212\n\nM\nX\nj=2\n\ne(t+1)M +1\nG\n1\n+j\n\u03b1tM\n1\n\n\uf8eb\n\n\u0010\n\n\u2212\n\netM +1\nG\n1\n\n\uf8edI RtM +j\nj\n\n=\n\n\u0011\n=0\n\n\u0012X\nM\ni=1\n\nM\nY\n\nM\n\u0010\n\u0011Y\n+1\n(1 \u2212 \u03b1tM\n)\n\u03b71tM +i \u2212 I R1tM +1 = 0\nj\nj=2\n\n\u0010\n\u0011\n+j\ntM +j\n(1 \u2212 \u03b1tM\n)\n+\nI\nR\n>\n0\nj\nk\n\nk=2\n\nY\n\nk\u22652,k6=j\n\n(1 \u2212\n\n\uf8f6\n\n+j \uf8f8\n\u03b1tM\n)\nk\n\nP\ntM +k\nLet Sit+1 = M\nbe the total number of arrivals into the red queue\nk=1 \u03bei\nof node i within the consecutive M time slots, and let\n\n\u0013+\n\n.\n\n\f17\n\nMULTI-RADIO\n\n+1\n\u03c6tM\n=\nx,1\n\nM\nX\n\n\u03b71tM +i \u2212 I (x1 = 0)\n\n\u2212\n\nM\nX\nj=2\n\n+1\n(1 \u2212 \u03b1tM\n)\nj\n\nj=2\n\ni=1\n\n\uf8eb\n\nM\nY\n\n\u0010\n\n+j \uf8ed\n\u03b1tM\nI xj + Sjt+1\n1\n\nM\n\u0011Y\n=0\n(1 \u2212 \u03b1jk ) + I (xj + Sj > 0)\nk=2\n\nY\n\nk\u22652,k6=j\n\n\uf8f6\n\n(1 \u2212 \u03b1jk )\uf8f8 .\n\nThen the RHS of equation (26) may be estimated from above by random\n+1\nvariable \u03c6tM\nR1 ,1 .\nf and conditions of Lemma 3 hold for the\nWe prove now that condition B1\nt\nt\nt\ne } in M steps. Indeed, we have\nMarkov Chain {R1 , ..., RM , G\n1\nE\n\n\u0010\n\n)\n(M\n\u0011\nX\n1\neM +1 \u2212 G\ne11 |(R11 , ..., RM\nG\n\u03b71i , M ,\n, G11 ) = (r1 , ..., rM , g1 ) \u2264 E max\n1\ni=1\n\nP\ni\nsince at most M\ni=1 \u03b71 new messages may arrive in the system and at most M\nf thus holds. Conditions (i)\nmessages may leave the system. Condition B1\n+1\n. Take C1 =\nand (ii) of Lemma 3 clearly hold for random variables \u03c6tM\nx,1\nC2 = M , then condition (iii) of Lemma 3 also holds with hi (yi ) = C1 I(L2,i (yi ) \u2264\nt\nC2 ). To verify the last condition (iv), we note that P(Ri(t)\n= 0) \u2192 1 \u2212 \u03bbR\nas t \u2192 \u221e (this follows from a known general result that, for a stationary\nMarkov chain Zt+1 = max(Zt \u22121, 0)+\u03c7t with i.i.d. integer-valued increments\n{\u03c7t } such that E\u03c71 = c < 1 and P(\u03c71 \u2265 0) = 1, we have with necessity\nP(Zt = 0) = 1 \u2212 c, in order to keep our paper self-contained, we provide a\nproof in Appendix B). Therefore, we get\nZ\n1\nE\u03bex,1\n\u03c0(dx) = (1 \u2212 \u03bbR )p(1 \u2212 p)M \u22121\n+\n\nM\nX\nj=2\n\n\u0001\n(1 \u2212 \u03bbR )p(1 \u2212 p)M \u22121 + \u03bbR p(1 \u2212 p)M \u22122 < 0,\n\nprovided the conditions of the Theorem hold.\nt\nProof of instability. As was mentioned in the stability proof, P(Ri(t)\n=\nt\n0) \u2192 (1 \u2212 \u03bbR ) as n \u2192 \u221e. We can choose t so large that |P(Ri(t) =\n0) \u2212 (1 \u2212 \u03bbR )| < \u03b4 for an arbitrarily small \u03b4 > 0. For simplicity of cacut\nlations, let us assume that P(Ri(t)\n= 0) = (1 \u2212 \u03bbR ) (it will not be difficult\nfor the reader to repeat the same proof with an extra \u03b4 added and then let \u03b4\n\n\f18\n\ngo to 0). We prove that, for any i = 1, . . . , M , Gti \u2192 \u221e with at least a linear\nspeed, i.e.\n(27)\n\nlim inf Gti /t > 0 a.s.\nt\u2192\u221e\n\n(note that by the SLLN the speed of growth can not be superlinear). Consider the embedded epochs M, 2M, . . . , kM, . . . that are the multiples of\nM . Choose a positive number N >> 1. Since all states in the positive M dimensional lattice are communicating, there exists an a.s. finite (random)\ntime, say, T \u2208 {kM, k \u2265 0} such that GTi \u2265 N for all i. Starting from time\nT , all coordinates of the process GkM coincide with those of the auxiliary\nekM which starts with the same G\neT = GT \u2013 until the first time\nprocess G\nwhen one of the coordinates becomes zero. Since, for any i, the increments\ne(k+1)M \u2212 G\nekM form a stationary ergodic sequence with a positive mean,\nG\ni\ni\nsay \u2206 (which is a difference of the RHS and the LHS in equation (25)),\nekM /k \u2192 \u2206\nG\ni\n\na.s.\n\neT +lM \u2265\nand, for any \u03b5 > 0, one can choose N >> 1 such that inf l\u22650 G\nM + 1 with probability at least 1 \u2212 \u03b5. If one takes \u03b5 < 1/M , then all the\nekM always stay above M after time T with probability at\ncoordinates of G\nleast 1 \u2212 M \u03b5 > 0. Then the same holds for the coordinates of the process\nGkM . Since Gt+1\n\u2212 Gti \u2265 \u22121 a.s., it then follows that, with probability at\ni\nleast 1 \u2212 M \u03b5 > 0, the coordinates of Gti stay strictly positive for all t \u2265 T .\nSince \u03b5 may be taken as small as possible, (27) follows.\nRecall that i(t) = ((t \u2212 1) mod M ) + 1. Introduce a Markov Chain\n\u0011\no\nn\u0010\n\b t\n\u0001\nt\nt\nt\nt\nt\n,\nt\n\u2265\n0\n\u01581 , . . . , \u0158M\n,t \u2265 0 =\nRi(t)\n, Ri(t+1)\n, Ri(t+2)\n, . . . , Ri(t+M\n\u22121)\n\n\u0001\n\b t\nt , \u01e6t , . . . , \u01e6t\nand another Markov Chain (\u0158, \u01e6) =\n\u01581 , . . . , \u0158M\n1\nM ,t \u2265 0 ,\nwhere a similar interchange of the G-coordinates is also made. In words, the\nnew Markov chain is obtained from the original one with a cyclic change of\ncoordinates such that at every time slot the first coordinate corresponds to\nthe node whose first red message is scheduled for service (if there is any).\nCorollary 2. Under the assumptions of Theorem 3, the Markov Chain\n(\u0158, \u01e6) is Harris ergodic.\nProof. Indeed, the new chain is aperiodic and positive recurrent. The\nlatter follows from the fact that the Lyapunov function used in the proof of\n\n\fMULTI-RADIO\n\n19\n\nTheorem 3 is the sum of all coordinates and hence does not change when the\norder of the coordinates is changed. To infer ergodicity it is then sufficient\nto show that the state (0, ..., 0) is achievable from any other state. To show\nthat, note first that there exists a compact set V which is positively recurrent\nfor the new chain. This implies that with a positive probability the chain\nwill reach a state (r1 , .., rM , g1 , P\n..gM ) \u2208 V . Due toPcompactness of V , there\nM\n0\n0\nexist finite r 0 and g0 such that M\ni=1 ri \u2264 r and\ni=1 gi \u2264 g for all points\nfrom V . It is then clear that there exists a finite time such that with a\npositive probability all red and all green messages will be transmitted and\nno new messages will arrive. Hence the state (0, ..., 0) may be reached in a\nfinite number of steps from any other state.\n\n3.2. Network without a MAC-coordinator. Now consider the system which\ndiffers from the system described above only in the following: we assume here\nthat a station which is transmitting a red message can also attempt a transmission of a green message and, if that happens, these two transmissions\ncollide.\nNow the following may happen at a time slot t regarding red messages:\n\u2022 There is one attempted (and successful) transmission. This happens\nwhen the queue of the red messages of node i(t) is non-empty and there\nis no attempted transmission of a green message by the same station\n(this may happen if either the queue of green messages is empty, or it\nis not empty but the station takes a decision not to transmit a green\nmessage);\n\u2022 There is one attempted (and unsuccessful) transmission. This happens\nwhen both queues of red and green messages of station i(t) are nonempty and the station decides to attempt a transmission of a green\nmessage.\n\u2022 There are no attempted transmissions. This happens when the queue\nof the red messages of node i(t) is empty;\nThe following may occur regarding green messages:\n\u2022 There is one transmission attempt. Then it is successful, if it did not\noriginate from node i(t) or if it did originate from node i(t) but its\nqueue of red messages is empty;\n\u2022 No transmission attempted;\n\u2022 Two or more transmissions attempted. In this case all these transmissions fail due to the collision.\nWe are still assuming that the ALOHA algorithm is used to govern the\n\n\f20\n\nbehaviour of the green queues of all stations. For this system, the following\nholds.\nTheorem 4. The system is stable if \u03bbR < 1 \u2212 p and\n(28)\n\uf8f1\n\u0011\n\u0010\n\uf8f2\u03bbG < 1 \u2212 \u03bbR p, if M = 1,\n1\u2212p\n\u0011\n\u0010\n\uf8f3\u03bbG < \u03bbR (M \u2212 1)p(1 \u2212 p)M \u22121 + 1 \u2212 \u03bbR M p(1 \u2212 p)M \u22121 ,\n1\u2212p\n1\u2212p\n\nif\n\nM > 1.\n\nProof of Theorem 4 may be given following the lines of the proof of\nTheorem 3. The only difference is that one needs to bound the Markov\nChain representing the state of the system under consideration by a Markov\nChain representing the state of the system where each station with an empty\ngreen queue transmits a \"dummy\" message with probability p.\nNote that in this case the first component (counting the number of red\nmessages) of the initial Markov Chain describing the state of the system\nis not a Markov Chain itself, so Theorem 2 can not be applied directly.\nHowever, the Markov Chain used to bound the initial one from above has\nthe first component which is a Markov Chain itself, and the use of Theorem 2\nis justified.\nAcknowledgement. The authors would like to thank Maxim Grankin for\nhis simulation work that numerically confirmed the correctness of stability\nresults in the case of a network without a MAC-coordinator.\n\nAppendix A. Proof of (6)-(7). Assume p < 1 (where p is from the\nminorisation condition, see Assumption A3)\u2013 otherwise the result is obvious.\nConsider, for simplicity, the case m = 1 only (the general case requires an\nextra technical work which is not essential). For x \u2208 V , consider the standard\nsplitting identity\nPx (X 1 \u2208 *) = p\u03bc(*) + (1 \u2212 p)\n\nPx (X 1 \u2208 *) \u2212 p\u03bc(*)\n1\u2212p\n\nand denote the fraction in the RHS by Qx (*) which is a probability measure.\nWe know that sigma-algebra BX is countably generated. Therefore, one can\ndefine two measurable functions f, g : X \u00d7 [0, 1] \u2192 X such that if U is a\nr.v. uniformly distributed in [0, 1], then f (x, U ) has distribution Px (*), for\nx \u2208 X , and g(x, U ) has distribution Qx (*), for x \u2208 V \u2013 see, e.g., [15] for\nbackground.\nIntroduce three sequences of mutually independent r.v.'s, each of which\nis i.i.d.:\n1) a sequence of 0 \u2212 1-valued r.v.'s \u03b2t , with common distribution P(\u03b2t =\n\n\fMULTI-RADIO\n\n21\n\n1) = p = 1 \u2212 P(\u03b2t = 0),\n2) a sequence {Ut } of uniformly distributed in [0, 1] r.v.'s, and\n3) a sequence {Wt } of X -valued r.v.'s with common distribution \u03bc.\nThen Markov chain X t may be represented as a stochastic recursive sequence (SRS):\n(29)\n\u0001\nX t+1 = \u03b2t Wt + (1 \u2212 \u03b2t )g(X t , Ut ) I(X t \u2208 V ) + f (X t , Ut )I(X t \u2208 X \\ V ).\n\nThe pairs (X t , \u03b2t ) also form a time-homogeneous Markov chain. Start with\nX 0 = x \u2208 V . Let T0 = 0 and, for k \u2265 1,\nTk = min{t > Tk\u22121 : X t \u2208 V }.\nFurther, let\n\u03b8 = min{k \u2265 0 : \u03b2Tk = 1}.\n\nThen \u03b8 has a geometric distribution with parameter p, P(\u03b8 = k) = p(1\u2212p)k ,\nk = 0, 1, . . .. Let \u03ba = T\u03b8 + 1. Note that r.v. X \u03ba has distribution \u03bc and that,\nfor x \u2208 V ,\nEx \u03ba \u2264 s0 E\u03b8 + 1 =: C\nwhere s0 is from (3). Clearly, C does not depend on x \u2208 V . Then, in particular, random variables \u03ba are uniformly bounded in probability:\nsup Px (\u03ba > t) \u2192 0, t \u2192 \u221e,\nx\u2208A\n\nby Markov inequality.\nLet now {\u03b2\u0304t }, {\u016at }, and {W\u0304t } be three other i.i.d. sequences which do\nnot depend on the first three sequences. Consider a stationary Markov\nchain {X\u0304 t } which is defined as follows: X\u0304 0 has distribution \u03c0 and does\nnot depend on all r.v.'s defined earlier, and\n(30)\n\u0001\nX\u0304 t+1 = \u03b2\u0304t W\u0304t + (1 \u2212 \u03b2\u0304t )g(X\u0304 t , \u016at ) I(X\u0304 t \u2208 V ) + f (X\u0304 t , \u016at )I(X\u0304 t \u2208 X \\ V ).\n\nDue to independence of the two SRS's, r.v. X\u0304 \u03ba has distribution \u03c0. Finally,\nlet\n\u03b3 = min{j \u2265 0 : X \u03ba+j \u2208 A, X\u0304 \u03ba+j \u2208 A, \u03b2\u03ba+j = 1}.\n\nBy aperiodicity, \u03b3 is finite a.s. Also, it does not depend on \u03ba and, therefore,\nits distribution does not depend on x. Then one can define another sequence\nb n by\nX\nb t = X\u0304 t I(t \u2264 \u03ba + \u03b3) + X t I(t > \u03ba + \u03b3)\nX\n\n\f22\n\nb t } have\nand find that, first, since \u03ba + \u03b3 is a stopping time, {X\u0304 t } and {X\nt\nb\nthe same distribution and, in particular, {X } is also a stationary Markov\nchain (see, e.g. [23, p.34] or [16]), second, random variables \u03bd = \u03ba + \u03b3 are\nuniformly bounded in probability, i.e. (7) holds, and, third, r.v.'s \u03bd satisfy\n(6).\nRemark. The first intention of the authors was to find this result in [23].\nHowever, Hermann Thorisson has confirmed that it is not there, but he is\nthinking to have it in the second edition of the book (with a complete proof,\nfor any m \u2265 1).\nAppendix B.\nLemma 4. Consider a stationary Markov chain Zt+1 = max(Zt \u2212 1, 0) +\n\u03c7t with a stationary and ergodic sequence of integer-valued increments {\u03c7t }\nsuch that E\u03c71 = c < 1 and P(\u03c71 \u2265 0) = 1. Then P(Zt = 0) = 1 \u2212 c.\nProof.\nLet us rewrite the evolution equation as\nZt+1 = Zt \u2212 1 + I{Zt = 0} + \u03c7t ,\nwhere I{* } is the indicator function. With a positive integer T we now have\nZt+T = Zt \u2212 T +\n\nT\n\u22121\nX\n\nI{Zt+i = 0} +\n\ni=0\n\nT\n\u22121\nX\n\n\u03c7t+i .\n\ni=0\n\nIf we now divide both sides of the latter expression by T , take expectations\nand let T tend to infinity, we will get\nEZt+T\n= \u22121 + P(Zt = 0) + c,\nT \u2192\u221e\nT\nlim\n\nwhere we used the Strong Law of Large Numbers and the stationarity of the\nMarkov chain {Zt }. Using stationarity again, we conclude that the LHS of\nthe latter equality is equal to 0, and the proof is complete.\nREFERENCES\n[1] Abramson, N. (1970). The ALOHA System - Another Alternative for Computer\nCommunications. AFIPS Conference Proceedings. 36, 295\u2013298.\n[2] Andreev, S., Dubkov, K., Turlikov, A. (2010) IEEE 802.11 and 802.16 cooperation within multi-radio stations. Wireless Personal Communications, Springer Science+Business Media B.V., 1\u201319.\n\n\fMULTI-RADIO\n\n23\n\n[3] Berlemann, L., Hoymann, C., Hiertz, G.R., Mangold, S. (2006). Coexistence and\ninterworking of IEEE 802.16 and IEEE 802.11(e). IEEE 63rd Vehicular Technology\nConference, 1, 27\u201331.\n[4] Bonald, T., Borst, S., Hedge, N., Proutiere, A. (2004). Wireless Data Performance in\nMulti-Cell Scenarios. Proc. of ACM SIGMETRICS, 378\u2013387.\n[5] Bordenave, C., McDonald, D., Proutiere, A. (2008). Performance of Random\nMuedium Access Control, An Asymptotic Approach. Proc. of ACM SIGMETRICS/Performance, 1\u201312.\n[6] Borovkov, A.A. (1998) Ergodicity and Stability of Stochastic Processes, Wiley.\n[7] Borst, S., Jonckheere, M., Leskel\u00e4, L. Stability of parallel queueing systems with\ncoupled service rates. Discrete Event Dynamic Systems, 18, 4, 447\u2013472\n[8] Bramson, M.Stability of queueing networks, Probab. Surveys, 5 (2008), 169\u2013345.\n[9] Dai, J.G. (1995). On positive Harris recurrence of multiclass queueing networks: a\nunified approach via fluid limits. Annals Applied Probability, 5, 49\u201377.\n[10] Dai, J.G. and Meyn, S.P. (1995). Stability and convergence of moments for multiclass\nqueueing networks via fluid limit models. IEEE Transactions on Automatic Control.,\n40, 11, 1889\u20131904.\n[11] Ephremides A., Hajek, B. (1998). Information Theory and Communication Networks:\nan Unconsummated Union. IEEE Transactions on Information Theory. 44, 2416\u2013\n2434.\n[12] Foss, S., Konstantopoulos, T. (2004). An overview of some stochastic stability methods. Journal of Operation Research Society Japan, 47, 275\u2013303.\n[13] Gamarnik, D. (2004). Stochastic bandwidth packing process: stability conditions via\nLyapunov function technique. Queueing systems, 48, 339\u2013363.\n[14] Gamarnik, D., Squillante, M. (2005). Analysis of stochastic online bin packing processes. Stochastic Models, 21, 401\u2013425.\n[15] Kifer, Yu. (1986). Ergodic theory of random transformations. Progress in Probability\nand Statistics, Birkhauser.\n[16] Lindvall, T. (2002). Lectures on the Coupling Method, 2nd edition, Dover.\n[17] Litvak, N., Robert, P. (2012). A scaling analysis of a cat and mouse Markov chain.\nAnnals of Probability, 22, 2, 792\u2013826.\n[18] Meyn, S.P. (2007). Control Techniques for Complex Networks, Cambridge University\nPress.\n[19] Meyn, S.P., Tweedie, R.L. (1993). Markov Chains and Stochastic Stability, Springer\nVerlag.\n[20] Mikhailov, V.A., Tsybakov, B.S. (1979). Ergodicity of a Slotted ALOHA System.\nProblems of Information Transmission, 15, 301\u2013312.\n[21] Roberts, L. (1972). ALOHA Packet System with and without Slots and Capture.\nAdvanced research projects agency, Network information center, Tech. Rep. ASS Note\n8.\n[22] Shah, D., Shin, J. (2012). Randomized scheduling algorithm for queueing networks.\nAnnals of Applied Probability, to appear.\n[23] Thorisson, H. (2000). Coupling, Stationarity, and Regeneration, Springer Verlag.\n[24] Walke, B., Mangold, S., Berlemann, L. (2007). IEEE 802 wireless systems: Protocols,\nmulti-Hop mesh/relaying, performance and spectrum coexistence. NJ: Wiley.\n\n\f24\n[25] Zhu, J., Waltho, A., Yang, X., Guo, X. (2007). Multi-radio coexistence: Challenges\nand opportunities. Proceedings of 16th International Conference on Computer Communications and Networks, 13-16, 358\u2013364.\nSchool of Mathematical and Computer Sciences, St. Petersburg\nState University of Aerospace Instrumentation\nHeriot-Watt University,\nE-mail: turlikov@vu.spb.ru\nEH14 4AS, Edinburgh, UK\nE-mail: s.foss@hw.ac.uk\nv.shneer@hw.ac.uk\n\n\f"}