{"id": "http://arxiv.org/abs/0901.1708v1", "guidislink": true, "updated": "2009-01-13T04:49:14Z", "updated_parsed": [2009, 1, 13, 4, 49, 14, 1, 13, 0], "published": "2009-01-13T04:49:14Z", "published_parsed": [2009, 1, 13, 4, 49, 14, 1, 13, 0], "title": "A statistical mechanical interpretation of instantaneous codes", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0901.1133%2C0901.3106%2C0901.2240%2C0901.0694%2C0901.3126%2C0901.3795%2C0901.2108%2C0901.3201%2C0901.1221%2C0901.0983%2C0901.2084%2C0901.2594%2C0901.1675%2C0901.3681%2C0901.0980%2C0901.2856%2C0901.1255%2C0901.2347%2C0901.1415%2C0901.1334%2C0901.3380%2C0901.0804%2C0901.1990%2C0901.3638%2C0901.3842%2C0901.4005%2C0901.0782%2C0901.2227%2C0901.3691%2C0901.1632%2C0901.2400%2C0901.4772%2C0901.0226%2C0901.0552%2C0901.4212%2C0901.4797%2C0901.2645%2C0901.1453%2C0901.1510%2C0901.3449%2C0901.3208%2C0901.4003%2C0901.0112%2C0901.3037%2C0901.3959%2C0901.3445%2C0901.3863%2C0901.2986%2C0901.4421%2C0901.0031%2C0901.1462%2C0901.4594%2C0901.4620%2C0901.0567%2C0901.1648%2C0901.2632%2C0901.2154%2C0901.3885%2C0901.4605%2C0901.4269%2C0901.0134%2C0901.2551%2C0901.1708%2C0901.4109%2C0901.4156%2C0901.2455%2C0901.4133%2C0901.4867%2C0901.0711%2C0901.2021%2C0901.0114%2C0901.0754%2C0901.0103%2C0901.2152%2C0901.1732%2C0901.0731%2C0901.1836%2C0901.2807%2C0901.3292%2C0901.0653%2C0901.2067%2C0901.0290%2C0901.0350%2C0901.3610%2C0901.3583%2C0901.4390%2C0901.3630%2C0901.1224%2C0901.3811%2C0901.2669%2C0901.1542%2C0901.0817%2C0901.1569%2C0901.4538%2C0901.0672%2C0901.4159%2C0901.3490%2C0901.0220%2C0901.0147%2C0901.4613%2C0901.4209&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A statistical mechanical interpretation of instantaneous codes"}, "summary": "In this paper we develop a statistical mechanical interpretation of the\nnoiseless source coding scheme based on an absolutely optimal instantaneous\ncode. The notions in statistical mechanics such as statistical mechanical\nentropy, temperature, and thermal equilibrium are translated into the context\nof noiseless source coding. Especially, it is discovered that the temperature 1\ncorresponds to the average codeword length of an instantaneous code in this\nstatistical mechanical interpretation of noiseless source coding scheme. This\ncorrespondence is also verified by the investigation using box-counting\ndimension. Using the notion of temperature and statistical mechanical\narguments, some information-theoretic relations can be derived in the manner\nwhich appeals to intuition.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0901.1133%2C0901.3106%2C0901.2240%2C0901.0694%2C0901.3126%2C0901.3795%2C0901.2108%2C0901.3201%2C0901.1221%2C0901.0983%2C0901.2084%2C0901.2594%2C0901.1675%2C0901.3681%2C0901.0980%2C0901.2856%2C0901.1255%2C0901.2347%2C0901.1415%2C0901.1334%2C0901.3380%2C0901.0804%2C0901.1990%2C0901.3638%2C0901.3842%2C0901.4005%2C0901.0782%2C0901.2227%2C0901.3691%2C0901.1632%2C0901.2400%2C0901.4772%2C0901.0226%2C0901.0552%2C0901.4212%2C0901.4797%2C0901.2645%2C0901.1453%2C0901.1510%2C0901.3449%2C0901.3208%2C0901.4003%2C0901.0112%2C0901.3037%2C0901.3959%2C0901.3445%2C0901.3863%2C0901.2986%2C0901.4421%2C0901.0031%2C0901.1462%2C0901.4594%2C0901.4620%2C0901.0567%2C0901.1648%2C0901.2632%2C0901.2154%2C0901.3885%2C0901.4605%2C0901.4269%2C0901.0134%2C0901.2551%2C0901.1708%2C0901.4109%2C0901.4156%2C0901.2455%2C0901.4133%2C0901.4867%2C0901.0711%2C0901.2021%2C0901.0114%2C0901.0754%2C0901.0103%2C0901.2152%2C0901.1732%2C0901.0731%2C0901.1836%2C0901.2807%2C0901.3292%2C0901.0653%2C0901.2067%2C0901.0290%2C0901.0350%2C0901.3610%2C0901.3583%2C0901.4390%2C0901.3630%2C0901.1224%2C0901.3811%2C0901.2669%2C0901.1542%2C0901.0817%2C0901.1569%2C0901.4538%2C0901.0672%2C0901.4159%2C0901.3490%2C0901.0220%2C0901.0147%2C0901.4613%2C0901.4209&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this paper we develop a statistical mechanical interpretation of the\nnoiseless source coding scheme based on an absolutely optimal instantaneous\ncode. The notions in statistical mechanics such as statistical mechanical\nentropy, temperature, and thermal equilibrium are translated into the context\nof noiseless source coding. Especially, it is discovered that the temperature 1\ncorresponds to the average codeword length of an instantaneous code in this\nstatistical mechanical interpretation of noiseless source coding scheme. This\ncorrespondence is also verified by the investigation using box-counting\ndimension. Using the notion of temperature and statistical mechanical\narguments, some information-theoretic relations can be derived in the manner\nwhich appeals to intuition."}, "authors": ["Kohtaro Tadaki"], "author_detail": {"name": "Kohtaro Tadaki"}, "author": "Kohtaro Tadaki", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/ISIT.2007.4557499", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0901.1708v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0901.1708v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "5 pages, Proceedings of the 2007 IEEE International Symposium on\n  Information Theory, pp.1906 - 1910, Nice, France, June 24 - 29, 2007", "arxiv_primary_category": {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0901.1708v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0901.1708v1", "journal_reference": null, "doi": "10.1109/ISIT.2007.4557499", "fulltext": "A Statistical Mechanical Interpretation of\nInstantaneous Codes\nKohtaro Tadaki\n\narXiv:0901.1708v1 [cs.IT] 13 Jan 2009\n\nResearch and Development Initiative, Chuo University\n1-13-27 Kasuga, Bunkyo-ku, Tokyo 112-8551, Japan\ntadaki@kc.chuo-u.ac.jp\n\nAbstract- In this paper we develop a statistical mechanical\ninterpretation of the noiseless source coding scheme based on an\nabsolutely optimal instantaneous code. The notions in statistical\nmechanics such as statistical mechanical entropy, temperature,\nand thermal equilibrium are translated into the context of\nnoiseless source coding. Especially, it is discovered that the\ntemperature 1 corresponds to the average codeword length of an\ninstantaneous code in this statistical mechanical interpretation\nof noiseless source coding scheme. This correspondence is also\nverified by the investigation using box-counting dimension. Using\nthe notion of temperature and statistical mechanical arguments,\nsome information-theoretic relations can be derived in the manner which appeals to intuition.\n\nII. I NSTANTANEOUS CODES\nWe start with some notation on instantaneous codes from\ninformation theory [9], [1], [3].\nFor any set S, #S denotes the number of elements in S.\nWe denote the set of all finite binary strings by {0, 1}\u2217. For\nany s \u2208 {0, 1}\u2217, |s| is the length of s. We define an alphabet\nto be any nonempty finite set.\nLet X be an arbitrary random variable with an alphabet H\nand a probability mass function pX (x) = Pr{X = x}, x \u2208 H.\nThen the entropy H(X) of X is defined by\nX\nH(X) \u2261 \u2212\npX (x) log pX (x),\nx\u2208H\n\nI. I NTRODUCTION\nWe introduce a statistical mechanical interpretation to the\nnoiseless source coding scheme based on an absolutely optimal\ninstantaneous code. The notions in statistical mechanics such\nas statistical mechanical entropy, temperature, and thermal\nequilibrium are translated into the context of noiseless source\ncoding.\nWe identify a coded message by an instantaneous code with\nan energy eigenstate of a quantum system treated in statistical\nmechanics, and the length of the coded message with the\nenergy of the eigenstate. The discreteness of the length of\ncoded message naturally corresponds to statistical mechanics\nbased on quantum mechanics and not on classical mechanics.\nThis is because the energy of a quantum system takes discrete\nvalue while an energy takes continuous value in classical\nphysics in general. Especially, in this statistical mechanical\ninterpretation of noiseless source coding, the energy of the\ncorresponding quantum system is bounded to the above, and\ntherefore the system has negative temperature. We discover\nthat the temperature 1 corresponds to the average codeword\nlength of an instantaneous code in the interpretation. This\ncorrespondence is also verified by the investigation based on\nbox-counting dimension.\nNote that, we do not stick to the mathematical strictness\nof the argument in this paper. We respect the statistical mechanical intuition in order to shed light on a hidden statistical\nmechanical aspect of information theory, and therefore make\nan argument on the same level of mathematical strictness as\nstatistical mechanics.\n\nwhere the log is to the base 2. We will introduce the notion\nof a statistical mechanical entropy later. Thus, in order to\ndistinguish H(X) from it, we particularly call H(X) the\nShannon entropy of X. A subset S of {0, 1}\u2217 is called a prefixfree set if no string in S is a prefix of any other string in S. An\ninstantaneous code C for the random variable X is an injective\nmapping from H to {0, 1}\u2217 such that C(H) \u2261 {C(x)|x \u2208 H}\nis a prefix-free set. For each x \u2208 H, C(x) is called the\ncodeword corresponding to x and |C(x)| is denoted by l(x). A\nsequence x1 , x2 , . . . , xN with xi \u2208 H is called a message. On\nthe other hand, the finite binary string C(x1 )C(x2 ) * * * C(xN )\nis called the coded message for a message x1 , x2 , . . . , xN .\nAn instantaneous code play an important role in the\nnoiseless source coding problem described as follows. Let\nX1 , X2 , . . . , XN be independent identically distributed random variables drawn from the probability mass function pX (x). The objective of the noiseless source coding\nproblem is to minimize the length of the binary string\nC(x1 )C(x2 ) * * * C(xN ) for a message x1 , x2 , . . . , xN generated by the random variables {Xi } as N \u2192 \u221e. For that\npurpose, it is sufficient to consider the average codeword\nlength LX (C) of an instantaneous code C for the random\nvariable X, which is defined by\nX\nLX (C) \u2261\npX (x)l(x)\nx\u2208H\n\nindependently on the value of N . We can then show that\nLX (C) \u2265 H(X) for any instantaneous code C for the\nrandom variable X. Hence, the Shannon entropy gives the\ndata compression limit for the noiseless source coding problem\nbased on instantaneous codes. Thus, it is important to consider\n\n\fthe notion of absolutely optimality of an instantaneous code,\nwhere we say that an instantaneous code C for the random\nvariable X is absolutely optimal if LX (C) = H(X). We can\nsee that an instantaneous code C is absolutely optimal if and\nonly if pX (x) = 2\u2212l(x) for all x \u2208 H.\nFinally, for each xN = (x1 , x2 , . . . , xN ) \u2208 HN , we define\npX (xN ) as pX (x1 )pX (x2 ) * * * pX (xN ).\n\nin statistical mechanics, the entropy S(E, N ) is normally\nestimated to first order in N and E. Thus the magnitude of\nthe indeterminacy \u03b4E of the energy does not matter unless it\nis too small. The temperature T (E, N ) of the system Stotal is\ndefined by\n\u2202S\n1\n\u2261\n(E, N ).\nT (E, N )\n\u2202E\n\nIII. S TATISTICAL M ECHANICAL I NTERPRETATION\nIn this section, we develop a statistical mechanical interpretation of the noiseless source coding by an instantaneous\ncode. In what follows, we assume that an instantaneous code\nC for a random variable X is absolutely optimal.\nIn statistical mechanics [7], [11], [8], we consider a quantum\nsystem Stotal which consists in a large number of identical\nquantum subsystems. Let N be a number of such subsystems.\nFor example, N \u223c 1022 for 1 cm3 of a gas at room temperature. We assume here that each quantum subsystem can\nbe distinguishable from others. Thus, we deal with quantum\nparticles which obey Maxwell-Boltzmann statistics and not\nBose-Einstein statistics or Fermi-Dirac statistics. Under this\nassumption, we can identify the ith quantum subsystem Si\nfor each i = 1, . . . , N . In quantum mechanics, any quantum\nsystem is described by a quantum state completely. In statistical mechanics, among all quantum states, energy eigenstates\nare of particular importance. Any energy eigenstate of each\nsubsystem Si can be specified by a number n = 1, 2, 3, . . . ,\ncalled a quantum number, where the subsystem in the energy\neigenstate specified by n has the energy En . Then, any\nenergy eigenstate of the system Stotal can be specified by an\nN -tuple (n1 , n2 , . . . , nN ) of quantum numbers. If the state\nof the system Stotal is the energy eigenstate specified by\n(n1 , n2 , . . . , nN ), then the state of each subsystem Si is the\nenergy eigenstate specified by ni and the system Stotal has\nthe energy En1 + En2 + * * * + EnN . Then, the fundamental\npostulate of statistical mechanics is stated as follows.\n\nThus the temperature is a function of E and N . The average\nenergy \u03b5 per one subsystem is given by E/N .\nNow we give a statistical mechanical interpretation to the\nnoiseless source coding scheme based on an instantaneous\ncode. Let X be an arbitrary random variable with an alphabet H, and let C be an absolutely optimal instantaneous\ncode for the random variable X. Let X1 , X2 , . . . , XN be\nindependent identically distributed random variables drawn\nfrom the probability mass function pX (x) for a large N , say\nN \u223c 1022 . We relate the noiseless source coding based on C\nto the above statistical mechanics as follows. The sequence\nX1 , X2 , . . . , XN corresponds to the quantum system Stotal ,\nwhere each Xi corresponds to the ith quantum subsystem\nSi . We relate x \u2208 H, or equivalently, C(x) to an energy\neigenstate of a subsystem, and we relate l(x) = |C(x)| to an\nenergy En of the energy eigenstate of the subsystem. Then a\nsequence (x1 , . . . , xN ) \u2208 HN , or equivalently, a finite binary\nstring C(x1 ) * * * C(xN ) corresponds to an energy eigenstate of\nStotal specified by (n1 , . . . , nN ). Thus, l(x1 ) + * * * + l(xN ) =\n|C(x1 ) * * * C(xN )| corresponds to the energy En1 + * * *+ EnN\nof the energy eigenstate of Stotal .\nWe define a subset C(L, N ) of {0, 1}\u2217 as the set of all\ncoded messages C(x1 ) * * * C(xN ) whose length lies between\nL and L + \u03b4L. Then \u03a9(L, N ) is defined as #C(L, N ).\nTherefore \u03a9(L, N ) is the total number of coded messages\nwhose length lies between L and L + \u03b4L. We can see that\nif C(x1 ) * * * C(xN ) \u2208 C(L, N ), then 2\u2212L \u2264 p(xN ) \u2264\n2\u2212(L+\u03b4L) . This is because C is an absolutely optimal instantaneous code. Thus all coded messages C(x1 ) * * * C(xN ) \u2208\nC(L, N ) occur with the probability 2\u2212L . Note here that we\ncare nothing about the magnitude of \u03b4L, as in the case of\nstatistical mechanics. Thus, given that the length of coded message is L, all coded messages occur with the same probability\n1/\u03a9(L, N ). We introduce a micro-canonical ensemble on the\nnoiseless source coding in this manner. Thus we can develop\na certain sort of statistical mechanics on the noiseless source\ncoding scheme.\nThe statistical mechanical entropy S(L, N ) of the instantaneous code C is defined by\n\nFundamental Postulate: If the energy of the system Stotal\nis known to have a constant value in the range between E\nand E + \u03b4E, where \u03b4E is the indeterminacy in measurement\nof the energy of the system Stotal , then the system Stotal is\nequally likely to be in any energy eigenstate specified by\n(n1 , n2 , . . . , nN ) such that E \u2264 En1 + En2 + * * * + EnN \u2264\nE + \u03b4E.\nLet \u03a9(E, N ) be the total number of energy eigenstates of\nStotal specified by (n1 , n2 , . . . , nN ) such that E \u2264 En1 +En2 +\n* * * + EnN \u2264 E + \u03b4E. The above postulate states that any\nenergy eigenstate of Stotal whose energy lies between E and\nE + \u03b4E occurs with the probability 1/\u03a9(E, N ). This uniform\ndistribution of energy eigenstates whose energy lies between E\nand E + \u03b4E is called a microcanonical ensemble. In statistical\nmechanics, the entropy S(E, N ) of the system Stotal is then\ndefined by\nS(E, N ) \u2261 k ln \u03a9(E, N ),\nwhere k is a positive constant, called the Boltzmann Constant, and the ln denotes the natural logarithm. Note that,\n\nS(L, N ) \u2261 log \u03a9(L, N ).\nThe temperature T (L, N ) of C is then defined by\n\u2202S\n1\n\u2261\n(L, N ).\nT (L, N )\n\u2202L\nThus the temperature is a function of L and N . The average\nlength \u03bb of coded message per one codeword is given by L/N .\nThe average length \u03bb corresponds to the average energy \u03b5 in\nthe statistical mechanics above.\n\n\fIV. P ROPERTIES\n\nOF\n\nS TATISTICAL M ECHANICAL E NTROPY\n\nIn statistical mechanics, it is important to know the values\nof the energy En of subsystem Si for all quantum numbers n,\nsince the values determine the entropy S(E, N ) of the quantum system Stotal . Corresponding to this fact, the knowledge\nof l(x) for all x \u2208 H is important to calculate S(L, N ). We\ninvestigate some properties of S(L, N ) and T (L, N ) based on\nl(x) in the following.\nAs is well known in statistical mechanics, if the energy of a\nquantum system Stotal is bounded to the above, then the system\ncan have negative temperature. The same situation happens in\nour statistical mechanics developed on an instantaneous code\nC, since there are only finite codewords of C. We define\nlmin and lmax as min{l(x) | x \u2208 H} and max{l(x) | x \u2208\nH}, respectively. Given N , the statistical mechanical entropy\nS(L, N ) is a unimodal function of L and takes nonzero value\nonly between N lmin and N lmax . Let L0 be the value L which\nmaximizes S(L, N ). If L < L0 then T (L, N ) > 0. On the\nother hand, if L > L0 then T (L, N ) < 0. The temperature\nT (L, N ) takes \u00b1\u221e at L = L0 .\nAccording to the method of Boltzmann and Planck (see\ne.g. [11]), we can show that\nS(L, N ) = N H(G(C, T (L, N ))),\n\n(1)\n\nwhere G(C, T ) is the random variable with the alphabet H and\nthe probability mass function pG(C,T ) (x) = Pr{G(C, T ) = x}\ndefined by\n2\u2212l(x)/T\n.\n\u2212l(a)/T\na\u2208H 2\n\npG(C,T ) (x) \u2261 P\n\nThe temperature T (L, N ) is implicitly determined through the\nequation\nX\nL\n=\nl(x)pG(C,T (L,N )) (x)\n(2)\nN\nx\u2208H\n\nas a function of L and N . These properties of S(L, N ) and\nT (L, N ) are derived only based on a combinatorial aspect of\nS(L, N ).\nNow, let us take into account the probabilistic issue given by\nthe random variables X1 , X2 , . . . , XN . Since the instantaneous\ncode C is absolutely optimal, a particular coded message of\nlength L occurs with probability 2\u2212L . Thus the probability\nthat some coded message of length L occurs is given by\n2\u2212L \u03a9(L, N ). Hence, by differentiating 2\u2212L \u03a9(L, N ) on L and\nsetting the result to 0, we can determine the most probable\nlength L\u2217 of coded message, given N . Thus we have the\nrelation\n\u2202\n{\u2212L + S(L, N )}\n= 0,\n\u2202L\n(L,N )=(L\u2217 ,N )\nwhich is satisfied by L\u2217 . It follows that T (L\u2217 , N ) = 1, Thus,\nthe temperature 1 corresponds to the most probable length\nL\u2217 . On the other hand, pG(C,1) (x) = 2\u2212l(x) at T (L\u2217 , N ) = 1,\nand therefore, by (2), we have L\u2217 /N = H(X) = LX (C).\nSince C is absolutely optimal, this result is consistent with the\nlaw of large numbers. Thus, the temperature 1 corresponds to\n\nthe average codeword length LX (C), which is equal to the\naverage length \u03bb of coded message per one codeword at the\ntemperature 1.\nV. T HERMAL E QUILIBRIUM BETWEEN T WO\nI NSTANTANEOUS C ODES\nLet X I be an arbitrary random variable with an alphabet\nH , and let C I be an absolutely optimal instantaneous code\nI\nfor the random variable X I . Let X1I , X2I , . . . , XN\nI be independent identically distributed random variables drawn from the\nprobability mass function pX I (x) for a large N I . On the other\nhand, let X II be an arbitrary random variable with an alphabet\nHII , and let C II be an absolutely optimal instantaneous code\nII\nfor the random variable X II . Let X1II , X2II , . . . , XN\nII be independent identically distributed random variables drawn from\nthe probability mass function pX II (x) for a large N II .\nConsider the following problem: Find the most probable\nvalues LI and LII , given that the sum LI + LII of the length\nLI of coded message by C I for the random variables {XiI }\nand the length LII of coded message by C II for the random\nvariables {XjII } is equal to L.\nIn order to solve this problem, the statistical mechanical\nnotion of \"thermal equilibrium\" can be used. We first note that\na particular coded message by C I of length LI and a particular\ncoded message by C II of length LII occur with probability\n2\u2212LI 2\u2212LII = 2\u2212L , since the instantaneous codes C I and C II\nare absolutely optimal. Thus, any particular pair of coded\nmessages by C I and C II occurs with an equal probability, given\nthat the total length of coded messages for {XiI } and {XjII }\nis L. Therefore, the most probable allocation LI \u2217 and LII \u2217 of\nL = LI + LII maximizes the product \u03a9I (LI , NI )\u03a9II (LII , NII ).\nWe see that this condition is equivalent to the equality:\nI\n\nTI (L\u2217I , NI ) = TII (L\u2217II , NII ),\nwhere the functions TI and TII are the temperature of C I and\nC II , respectively. This equality corresponds to the condition\non the thermal equilibrium between two systems, given a\ntotal energy, in statistical mechanics. Using (2), the value of\nTI (L\u2217I , NI ) = TII (L\u2217II , NII ) is obtained by solving the equation\non T :\nNI X\nC I (x) pG(C I ,T ) (x) +\nL\nI\nx\u2208H\n\nII\n\nN X\nC II (x) pG(C II ,T ) (x)\nL\nII\nx\u2208H\n\n= 1.\nThen, again by (2), the most probable values L\u2217I and L\u2217II are\ndetermined.\nVI. D IMENSION\n\nOF\n\nC ODED M ESSAGES\n\nThe notion of dimension plays an important role in fractal\ngeometry [6]. In this section, we investigate our statistical\nmechanical interpretation of the noiseless source coding from\nthe point of view of dimension. Let F be a bounded subset\nof R, and let Nn (F ) be the number of 2\u2212n -mesh cubes that\n\n\fintersect F , where 2\u2212n -mesh cube is a subset of R in the form\nof [m2\u2212n , (m + 1)2\u2212n] for some integer m. The box-counting\ndimension dimB F of F is then defined by\ndimB F \u2261 lim\n\nn\u2192\u221e\n\nlog Nn (F )\n.\nn\n\nLet {0, 1}\u221e = {b1 b2 b3 * * * | bi = 0, 1 for all i = 1, 2, 3, . . . }\nbe the set of all infinite binary strings. In [10] we investigate\nthe dimension of sets of coded messages of infinite length,\nwhere the number of distinct codewords is finite or infinite.\nIn a similar manner, we investigate the set of coded messages\nof infinite length by an absolutely optimal instantaneous code\nC.\nBy (2), the ratio L/N is uniquely determined by temperature\nT . Thus, by letting L, N \u2192 \u221e while keeping the ratio\nL/N constant, we can regard the set C(L, N ) as a subset of\n{0, 1}\u221e. This kind of limit is called the thermodynamic limit\nin statistical mechanics. Taking the thermodynamic limit, we\ndenote C(L, N ) by F (T ), where T is related to the limit value\nof L/N through (2). Although F (T ) is a subset of {0, 1}\u221e,\nwe can regard F (T ) as a subset of [0, 1] by identifying\n\u03b1 \u2208 {0, 1}\u221e with the real number 0.\u03b1. In this manner, we can\nconsider the box-counting dimension dimB F (T ) of F (T ).\nWe investigate the dependency of dimB F (T ) on temperature T with \u2212\u221e \u2264 T \u2264 \u221e. First it can be shown that\nlog \u03a9(L, N )\nL,N \u2192\u221e\nL\nS(L, N )\n=\nlim\n,\nL,N \u2192\u221e\nL\n\ndimB F (T ) =\n\nlim\n\nwhere the limits are taken while satisfying (2) for each T .\nThus the statistical mechanical entropy S(L, N ) and the boxcounting dimension dimB F (T ) of F (T ) are closely related.\nBy (1) and (2), we can obtain, as an explicit formula of T ,\nX\n1\n1\ndimB F (T ) = +\nlog\n2\u2212l(x)/T ,\n(3)\nT\n\u03bb(T )\nx\u2208H\n\nwhere \u03bb(T ) is defined by\nX\n\u03bb(T ) \u2261\nl(x)pG(C,T ) (x).\nx\u2208H\n\nWe define the \"degeneracy factors\" dmin and dmax of the lowest\nand highest \"energies\" by dmin \u2261 #{x \u2208 H | l(x) = lmin } and\ndmax \u2261 #{x \u2208 H | l(x) = lmax }, respectively.PNote here that\nsince C is assumed to be absolutely optimal, x\u2208H 2\u2212l(x) =\n1 and therefore dmax can be shown to be an even number. In\nthe increasing order of the ratio L/N (i.e. \u03bb(T )), we see from\n(3) that\nlim dimB F (T ) =\n\nT \u2192+0\n\ndimB F (1) =\nlim dimB F (T ) =\n\nT \u2192\u00b1\u221e\n\nlim dimB F (T ) =\n\nT \u2192\u22120\n\nlog dmin\n,\nlmin\n1,\nn log n\nP\n,\nx\u2208H l(x)\nlog dmax\n.\nlmax\n\nP\nWe can show that n log n < x\u2208H l(x) unless all codewords\nhave the same length, and obviously log dmin /lmin < 1 and\nlog dmax /lmax < 1 except for such a trivial case. Thus,\nin general, the dimension dimB F (T ) is maximized at the\ntemperature T = 1. This can be checked using (3) based on\nthe differentiation of dimB F (T ). That is, we can show that, if\nall codewords do not have the same length, then the following\nhold:\nd\n(i)\ndimB F (T )\n= 0 if and only if T0 = 1,\ndT\nT =T0\n(ii)\n\nd2\ndimB F (T )\ndT 2\n\nT =1\n\n< 0.\n\nNote that all coded messages C(x1 )C(x2 ) * * * of infinite\nlength form the set {0, 1}\u221e and therefore the interval [0, 1],\nsince C is an absolutely optimal instantaneous code. Thus,\nsince dimB F (1) is equal to dimB [0, 1], the set F (1) is as\nrich as the set [0, 1] in a certain sense. This can be explained\nas follows. Since L/N = LX (C) at the temperature T = 1,\nas seen in Section IV, by the law of large numbers, the length\nof coded message for a message of length N is likely to\nequal N LX (C), for a sufficiently large N . Thus F (1) contains\nalmost all finite binary string of length L. In other words, F (1)\nconsists in coded messages for all messages which form the\ntypical set in a sense.\nVII. C ONCLUSION\nIn this paper we have developed a statistical mechanical\ninterpretation of the noiseless source coding scheme based\non an absolutely optimal instantaneous code. The notions in\nstatistical mechanics such as statistical mechanical entropy,\ntemperature, and thermal equilibrium are translated into the\ncontext of information theory. Especially, it is discovered\nthat the temperature 1 corresponds to the average codeword\nlength LX (C) in this statistical mechanical interpretation of\ninformation theory. This correspondence is also verified by the\ninvestigation using box-counting dimension. The argument is\nnot necessarily mathematically rigorous. However, using the\nnotion of temperature and statistical mechanical arguments,\nseveral information-theoretic relations can be derived in the\nmanner which appeals to intuition.\nA statistical mechanical interpretation of the general case\nwhere the underlying instantaneous code is not necessarily\nabsolutely optimal is reported in another work.\nACKNOWLEDGMENTS\nThe author is grateful to the 21st Century COE Program and\nthe Research and Development Initiative of Chuo University\nfor the financial supports.\nR EFERENCES\n[1] R. B. Ash, Information Theory. Dover Publications, Inc., New York,\n1990.\n[2] C. S. Calude and M. A. Stay, \"Natural halting probabilities, partial randomness, and zeta functions,\" Inform. and Comput., vol. 204, pp. 1718\u2013\n1739, 2006.\n[3] T. M. Cover and J. A. Thomas, Elements of Information Theory. John\nWiley & Sons, Inc., New York, 1991.\n\n\f[4] A. Dembo and O. Zeitouni, Large Deviations Techniques and Applications, 2nd ed. Springer, New York, 1998.\n[5] P. A. M. Dirac, The Principles of Quantum Mechanics, 4th ed. Oxford\nUniversity Press, London, 1958.\n[6] K. Falconer, Fractal Geometry, Mathematical Foundations and Applications. John Wiley & Sons, Inc., Chichester, 1990.\n[7] F. Reif, Fundamentals of Statistical and Thermal Physics. McGraw-Hill,\nInc., Singapore, 1965.\n[8] D. Ruelle, Statistical Mechanics, Rigorous Results, 3rd ed. Imperial\nCollege Press and World Scientific Publishing Co. Pte. Ltd., Singapore,\n1999.\n[9] C. E. Shannon, \"A mathematical theory of communication,\" Bell Syst.\nTech. J., vol. 27, pt. I, pp. 379\u2013423, 1948; pt. II, pp. 623\u2013656, 1948.\n[10] K. Tadaki, \"A generalization of Chaitin's halting probability\n\u03a9 and halting self-similar sets,\" Hokkaido Math. J., vol.\n31,\npp.\n219\u2013253,\n2002.\nElectronic\nVersion\nAvailable:\nhttp://arxiv.org/abs/nlin/0212001\n[11] M. Toda, R. Kubo, and N. Sait\u00f4, Statistical Physics I. Equilibrium\nStatistical Mechanics, 2nd ed. Springer, Berlin, 1992.\n\n\f"}