{"id": "http://arxiv.org/abs/1201.0461v1", "guidislink": true, "updated": "2012-01-02T12:56:30Z", "updated_parsed": [2012, 1, 2, 12, 56, 30, 0, 2, 0], "published": "2012-01-02T12:56:30Z", "published_parsed": [2012, 1, 2, 12, 56, 30, 0, 2, 0], "title": "Pattern Clustering using Cooperative Game Theory", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1201.0818%2C1201.2331%2C1201.3678%2C1201.6082%2C1201.2553%2C1201.2777%2C1201.1626%2C1201.4262%2C1201.2308%2C1201.2299%2C1201.6015%2C1201.6543%2C1201.3199%2C1201.1355%2C1201.4732%2C1201.6444%2C1201.1595%2C1201.1816%2C1201.2063%2C1201.3833%2C1201.0311%2C1201.0874%2C1201.6111%2C1201.5284%2C1201.3453%2C1201.2893%2C1201.5191%2C1201.3672%2C1201.4636%2C1201.4841%2C1201.2462%2C1201.4006%2C1201.2481%2C1201.1928%2C1201.0031%2C1201.2236%2C1201.0243%2C1201.1462%2C1201.0978%2C1201.1777%2C1201.0068%2C1201.0602%2C1201.1913%2C1201.4686%2C1201.6567%2C1201.5055%2C1201.5535%2C1201.5444%2C1201.2448%2C1201.5435%2C1201.2536%2C1201.4587%2C1201.2112%2C1201.3083%2C1201.4298%2C1201.5525%2C1201.2689%2C1201.4673%2C1201.1596%2C1201.6286%2C1201.2424%2C1201.4039%2C1201.6062%2C1201.6142%2C1201.5635%2C1201.2696%2C1201.0461%2C1201.5726%2C1201.0427%2C1201.1488%2C1201.6105%2C1201.1360%2C1201.3869%2C1201.1065%2C1201.3953%2C1201.4900%2C1201.1403%2C1201.2113%2C1201.3736%2C1201.4089%2C1201.4937%2C1201.6667%2C1201.5271%2C1201.5926%2C1201.0987%2C1201.5891%2C1201.0792%2C1201.5360%2C1201.0048%2C1201.5316%2C1201.1748%2C1201.0161%2C1201.0625%2C1201.2519%2C1201.5687%2C1201.4413%2C1201.2961%2C1201.3068%2C1201.5358%2C1201.6014%2C1201.0269&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Pattern Clustering using Cooperative Game Theory"}, "summary": "In this paper, we approach the classical problem of clustering using solution\nconcepts from cooperative game theory such as Nucleolus and Shapley value. We\nformulate the problem of clustering as a characteristic form game and develop a\nnovel algorithm DRAC (Density-Restricted Agglomerative Clustering) for\nclustering. With extensive experimentation on standard data sets, we compare\nthe performance of DRAC with that of well known algorithms. We show an\ninteresting result that four prominent solution concepts, Nucleolus, Shapley\nvalue, Gately point and \\tau-value coincide for the defined characteristic form\ngame. This vindicates the choice of the characteristic function of the\nclustering game and also provides strong intuitive foundation for our approach.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1201.0818%2C1201.2331%2C1201.3678%2C1201.6082%2C1201.2553%2C1201.2777%2C1201.1626%2C1201.4262%2C1201.2308%2C1201.2299%2C1201.6015%2C1201.6543%2C1201.3199%2C1201.1355%2C1201.4732%2C1201.6444%2C1201.1595%2C1201.1816%2C1201.2063%2C1201.3833%2C1201.0311%2C1201.0874%2C1201.6111%2C1201.5284%2C1201.3453%2C1201.2893%2C1201.5191%2C1201.3672%2C1201.4636%2C1201.4841%2C1201.2462%2C1201.4006%2C1201.2481%2C1201.1928%2C1201.0031%2C1201.2236%2C1201.0243%2C1201.1462%2C1201.0978%2C1201.1777%2C1201.0068%2C1201.0602%2C1201.1913%2C1201.4686%2C1201.6567%2C1201.5055%2C1201.5535%2C1201.5444%2C1201.2448%2C1201.5435%2C1201.2536%2C1201.4587%2C1201.2112%2C1201.3083%2C1201.4298%2C1201.5525%2C1201.2689%2C1201.4673%2C1201.1596%2C1201.6286%2C1201.2424%2C1201.4039%2C1201.6062%2C1201.6142%2C1201.5635%2C1201.2696%2C1201.0461%2C1201.5726%2C1201.0427%2C1201.1488%2C1201.6105%2C1201.1360%2C1201.3869%2C1201.1065%2C1201.3953%2C1201.4900%2C1201.1403%2C1201.2113%2C1201.3736%2C1201.4089%2C1201.4937%2C1201.6667%2C1201.5271%2C1201.5926%2C1201.0987%2C1201.5891%2C1201.0792%2C1201.5360%2C1201.0048%2C1201.5316%2C1201.1748%2C1201.0161%2C1201.0625%2C1201.2519%2C1201.5687%2C1201.4413%2C1201.2961%2C1201.3068%2C1201.5358%2C1201.6014%2C1201.0269&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this paper, we approach the classical problem of clustering using solution\nconcepts from cooperative game theory such as Nucleolus and Shapley value. We\nformulate the problem of clustering as a characteristic form game and develop a\nnovel algorithm DRAC (Density-Restricted Agglomerative Clustering) for\nclustering. With extensive experimentation on standard data sets, we compare\nthe performance of DRAC with that of well known algorithms. We show an\ninteresting result that four prominent solution concepts, Nucleolus, Shapley\nvalue, Gately point and \\tau-value coincide for the defined characteristic form\ngame. This vindicates the choice of the characteristic function of the\nclustering game and also provides strong intuitive foundation for our approach."}, "authors": ["Swapnil Dhamal", "Satyanath Bhat", "K. R. Anoop", "Varun R Embar"], "author_detail": {"name": "Varun R Embar"}, "author": "Varun R Embar", "arxiv_comment": "6 pages, 6 figures, published in Proceedings of Centenary Conference\n  - Department of Electrical Engineering, Indian Institute of Science :\n  653-658, 2011", "links": [{"href": "http://arxiv.org/abs/1201.0461v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1201.0461v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1201.0461v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1201.0461v1", "journal_reference": null, "doi": null, "fulltext": "CENTENARY CONFERENCE, 2011 - ELECTRICAL ENGINEERING, INDIAN INSTITUTE OF SCIENCE, BANGALORE\n\n1\n\nPattern Clustering using Cooperative Game Theory\n\narXiv:1201.0461v1 [cs.GT] 2 Jan 2012\n\nSwapnil Dhamal, Satyanath Bhat, Anoop K R, and Varun R Embar\n\nAbstract-In this paper, we approach the classical problem of\nclustering using solution concepts from cooperative game theory\nsuch as Nucleolus and Shapley value. We formulate the problem\nof clustering as a characteristic form game and develop a novel\nalgorithm DRAC (Density-Restricted Agglomerative Clustering)\nfor clustering. With extensive experimentation on standard data\nsets, we compare the performance of DRAC with that of well\nknown algorithms. We show an interesting result that four\nprominent solution concepts, Nucleolus, Shapley value, Gately\npoint and \u03c4 -value coincide for the defined characteristic form\ngame. This vindicates the choice of the characteristic function of\nthe clustering game and also provides strong intuitive foundation\nfor our approach.\nIndex Terms-Pattern clustering, Characteristic form game,\nNucleolus, Shapley value.\n\nI. I NTRODUCTION\nLUSTERING or unsupervised classification of patterns\ninto groups based on similarity is a very well studied\nproblem in pattern recognition, data mining, information retrieval, and related disciplines. Besides, clustering has also\nbeen used in solving extremely large scale problems. Clustering also acts as a precursor to many data processing tasks\nincluding classification. According to Backer and Jain [2], in\ncluster analysis, a group of objects is split into a number\nof more or less homogeneous subgroups on the basis of an\noften subjectively chosen measure of similarity (i.e., chosen\nsubjectively based on its ability to create interesting clusters)\nsuch that the similarity between objects within a subgroup\nis larger than the similarity between objects belonging to\ndifferent subgroups. A key problem in the clustering domain\nis to determine the number of output clusters k. Use of\ncooperative game theory provides a novel way of addressing\nthis problem by using a variety of solution concepts.\nIn the rest of this section, we justify the use of game\ntheoretic solution concepts, specifically Nucleolus, for pattern\nclustering, give an intuition why the various solution concepts\ncoincide and refer to a few recent works in clustering using\ngame theory. In Section II, we provide a brief introduction\nto the relevant solution concepts in cooperative game theory.\nSections III explains our model and algorithm for clustering\nbased on cooperative game theory. In Section IV, we describe\nthe experimental results and provide a comparison of our\nalgorithm with some existing related ones. The coincidence of\nNucleolus, Shapley value, Gately point and \u03c4 -value with the\nchosen characteristic function is discussed and formally proved\nin Section V. We conclude with future work in Section VI.\nWe motivate the use of game theory for pattern clustering\nwith an overview of a previous approach. SHARPC [1] proposes a novel approach to find the cluster centers in order to\ngive a good start to K-means, which thus results in the desired\nclustering. The limitation of this approach is that it is restricted\n\nC\n\nto K-means, which is not always desirable especially when\nthe classes have unequal variances or when they lack convex\nnature. We, therefore, extend this approach to a more general\nclustering problem in R2 .\nAs it will be clear in Section II, Shapley value is based\non average fairness, Gately point is based on stability, \u03c4 value is based on efficiency while Nucleolus is based on\nboth min-max fairness and stability. Hence, it is worthwhile\nexploring these solution concepts to harness their properties\nfor the clustering game. Of these solution concepts, the\nproperties of Nucleolus, viz., fairness and stability, are the\nmost suitable for the clustering game. Moreover, we show\nin Section V that all these solution concepts coincide for\nthe chosen characteristic function. As finding Nucleolus, for\ninstance, is computationally expensive, it is to our advantage if\nwe use the computational ease of other solution concepts. We\nsee in Section III that for the chosen characteristic function,\nthe Shapley value can be computed in polynomial time. So\nfor our algorithm, we use Shapley value, which is equivalent\nto using any or all of these solution concepts.\nThe prime reason for the coincidence of the relevant solution\nconcepts is that the core, which we will see in Section II-A, is\nsymmetric about a single point and all these solution concepts\ncoincide with that very point. We will discuss this situation in\ndetail and prove it formally in Section V.\nThere have been approaches proposing the use of game\ntheory for pattern clustering. Garg, Narahari and Murthy\n[1] propose the use of Shapley value to give a good start\nto K-means. Gupta and Ranganathan [11], [12] use a microeconomic game theoretic approach for clustering, which\nsimultaneously optimizes two objectives, viz. compaction and\nequipartitioning. Bulo and Pelillo [10] use the concept of evolutionary games for hypergraph clustering. Chun and Hokari\n[8] prove the coincidence of Nucleolus and Shapley value for\nqueueing problems.\nThe contributions of our work are as follows:\n\u2022 We explore game theoretic solution concepts for the\nclustering problem.\n\u2022 We prove coincidence of Nucleolus, Shapley value,\nGately point and \u03c4 -value for the defined game.\n\u2022 We propose an algorithm, DRAC (Density-Restricted Agglomerative Clustering), which overcomes the limitations\nof K-means, Agglomerative clustering, DBSCAN [13]\nand OPTICS [14] using game theoretic solution concepts.\nII. P RELIMINARIES\nIn this section, we provide a brief insight into the cooperative game theory concepts [4], [7], [8] viz. Core, Nucleolus,\nShapley value, Gately point and \u03c4 -value.\nA cooperative game (N, \u03bd) consists of two parameters\nN and \u03bd. N is the set of players and \u03bd : 2N \u2192 R is\n\n\fCENTENARY CONFERENCE, 2011 - ELECTRICAL ENGINEERING, INDIAN INSTITUTE OF SCIENCE, BANGALORE\n\nthe characteristic function. It defines the value \u03bd(S) of any\ncoalition S \u2286 N .\nA. The Core\nLet (N, \u03bd) be a coalitional game with transferable utility\n(TU). Let x = (x1 , . . . , xn ), where xi represents the payoff\nof player i, the core consists of all payoff allocations x =\n(x1 , ..., xn ) that satisfy the following properties.\n1) individual rationality, i.e.,Pxi \u2265 \u03bd({i}) \u2200 i \u2208 N\n2) collective rationality i.e. Pi\u2208N xi = \u03bd(N ).\n3) coalitional rationality i.e. i\u2208S xi \u2265 \u03bd(S) \u2200S \u2286 N .\nA payoff allocation satisfying individual rationality and collective rationality is called an imputation.\n\nD. The Gately Point\nPlayer i's propensity to disrupt the grand coalition is defined\nto be the following ratio [4].\nP\nj6=i xj \u2212 \u03bd(N \u2212 i)\n(1)\ndi (x) =\nxi \u2212 \u03bd(i)\n\nIf di (x) is large, player i may lose something by deserting\nthe grand coalition, but others will lose a lot more. The\nGately point of a game is the imputation which minimizes\nthe maximum propensity to disrupt. The general way to\nminimize the largest propensity to disrupt is to make all of the\npropensities to disrupt equal. When the game is normalized so\nthat \u03bd(i) = 0 for all i, the way to set all the di (x) equal is to\nchoose xi in proportion to \u03bd(N ) \u2212 \u03bd(N \u2212 i).\n\u03bd(N ) \u2212 \u03bd(N \u2212 i)\n\u03bd(N )\nj\u2208N (\u03bd(N ) \u2212 \u03bd(N \u2212 j))\n\nGvi = P\n\nB. The Nucleolus\nNucleolus is an allocation that minimizes the dissatisfaction\nof the players from the allocation they can receive in a\ngame [5]. For every imputation x, consider the excess defined\nby\nX\neS (x) = \u03bd(S) \u2212\nxi\ni\u2208S\n\neS (x) is a measure of unhappiness of S with x. The goal\nof Nucleolus is to minimize the most unhappy coalition,\ni.e., largest of the eS (x). The linear programming problem\nformulation is as follows\n\nE. The \u03c4 -value\n\u03c4 -value is the unique solution concept which is efficient and\nhas the minimal right property and the restricted proportionality property. The reader is referred to [6] for the details of\nthese properties. For each i \u2208 N , let\nMi (\u03bd) = \u03bd(N ) \u2212 \u03bd(N \u2212 i) and mi (\u03bd) = \u03bd(i)\n\nsubject to\nX\ni\u2208S\n\nxi \u2265 \u03bd(S) \u2200S \u2286 N\n\n(2)\n\nThen the \u03c4 -value selects the maximal feasible allocation on\nthe line connecting M (\u03bd) = (Mi (\u03bd))i\u2208N and m(\u03bd) =\n(mi (\u03bd))i\u2208N [8]. For each convex game (N, \u03bd),\n\nmin Z\n\nZ+\n\n2\n\n\u03c4 (\u03bd) = \u03bbM (\u03bd) + (1 \u2212 \u03bb)m(\u03bd)\n\n(3)\n\nwhere \u03bb \u2208 [0, 1] is chosen so as to satisfy\nX\n[\u03bb(\u03bd(N ) \u2212 \u03bd(N \u2212 i)) + (1 \u2212 \u03bb)\u03bd(i)] = \u03bd(N )\n\n(4)\n\ni\u2208N\n\nX\n\nxi = \u03bd(N )\n\ni\u2208N\n\nThe reader is referred to [7] for the detailed properties of\nNucleolus. It combines a number of fairness criteria with\nstability. It is the imputation which is lexicographically central\nand thus fair and optimum in the min-max sense.\n\nIII. A M ODEL\nON\n\nA LGORITHM FOR C LUSTERING\nC OOPERATIVE G AME T HEORY\n\nAND\n\nBASED\n\nFor the clustering game, the characteristic function is chosen\nas in [1].\n1 X\n\u03bd(S) =\nf (d(i, j))\n(5)\n2\ni,j\u2208S\ni6=j\n\nC. The Shapley Value\nAny imputation \u03c6 = (\u03c61 , ..., \u03c6n ) is a Shapley value if it\nfollows the axioms which are based on the idea of fairness.\nThe reader is referred to [4] for the detailed axioms. For any\ngeneral coalitional game with transferable utility (N, \u03bd), the\nShapley value of player i is given by\n\n\u03c6i\n\n=\n=\n\n1 X\n(|S| \u2212 1)!(n \u2212 |S|)![\u03bd(S) \u2212 \u03bd(S \u2212 i)]\nn!\ni\u2208S\n1 X \u03c0\nxi\nn!\n\u03c0\u2208\u03a0\n\n\u03a0 = set of all permutations on N\nx\u03c0i = contribution of player i to permutation \u03c0\n\nIn Equation 5, d is the Euclidean distance, f : d \u2192 [0, 1] is\na similarity function. Intuitively, if two points i and j have\nsmall euclidean distance, then f (d(i, j)) approaches 1. The\nsimilarity function that we use in our implementation is\nf (d(i, j)) = 1 \u2212\n\nd(i, j)\ndM\n\n(6)\n\nwhere dM is the maximum of the distances between all pairs\nof points in the dataset.\nWhen Equation 5 is used as characteristic function, it is\nshown in [1] that Shapley value of player i can be computed\nin polynomial time and is given by\n1X\nf (d(i, j))\n(7)\n\u03c6i =\n2\nj\u2208N\nj6=i\n\n\fCENTENARY CONFERENCE, 2011 - ELECTRICAL ENGINEERING, INDIAN INSTITUTE OF SCIENCE, BANGALORE\n\nAlso, from Equation 5, it can be derived that\nX\n\u03bd(S) =\n\u03bd(T )\n\n(8)\n\nT \u2286S\n|T |=2\n\nIn Sections I and II, we have discussed the benefits of\nimputations resulting from various game theoretic solution\nconcepts. Also, in Section V, we will show that all these\nimputations coincide. Moreover, as Equation 7 shows the ease\nof computation of Shapley value in the clustering game with\nthe chosen characteristic function, we use Shapley value as\nthe base solution concept for our algorithm.\nThe basic idea behind the algorithm is that we expand the\nclusters based on density. From Equations 6 and 7, Shapley\nvalue represents density in some sense. For every cluster, we\nstart with an unallocated point with the maximum Shapley\nvalue and assign it as the cluster center. If that point has\nhigh density around it, it should only consider the close-by\npoints, otherwise it should consider more faraway points. We\nimplement this idea in step 5 of Algorithm 1 with parameter\n\u03b2. For the point with the globally maximum Shapley value,\n\u03b2 = \u03b4, while it is low for other cluster centers. Also, as\nwe go from cluster center with the highest Shapley value\nto those with lower values, we do not want to degrade the\nvalue of \u03b2 linearly. So we have square-root function in step 5.\nAlternatively, it can be replaced with any other function which\nensures sub-linear degradation of \u03b2. The input parameters \u03b4\nand \u03b3 should be changed accordingly.\n\ncompared to the density around the cluster center of the cluster\nof which it is a part of, it should not be responsible for further\ngrowth of the cluster. This ensures that clusters are not merged\ntogether when they are connected with a thin bridge of points.\nIt also ensures that the density within a cluster does not vary\nbeyond a certain limit. We implement this idea with what we\ncall an expansion queue. We add points to the queue only if\ntheir Shapley value is at least \u03b3-multiple of that of the cluster\ncenter of the cluster of which it is a part of. The expansion\nqueue is responsible for the growth of a cluster and it ceases\nonce the queue is empty. The detailed and systematic steps\nare given in Algorithm 1.\nIV. E XPERIMENTAL R ESULTS\nIn this section, we qualitatively compare our algorithm with\nsome existing related algorithms. SHARPC [1] gives a good\nstart to K-means using a game theoretic solution concept, viz.,\nthe Shapley value. As our algorithm hierarchically allocates\npoints to the cluster starting from a cluster center, we compare\nit with Agglomerative Clustering. The way our characteristic\nfunction and similarity function are defined, the Shapley value\nrepresents density in some sense. So we compare our algorithm with the density-based ones, viz., DBSCAN (DensityBased Spatial Clustering of Applications with Noise) and\nOPTICS (Ordering Points To Identify the Clustering Structure). Throughout this section, 'cluster (<colored marker>)'\nrefers to the cluster marked by that colored marker in the\ncorresponding figure. Noise is represented by (\u25e6).\n\nAlgorithm 1 Density-Restricted Agglomerative Clustering\n(DRAC)\nRequire: Dataset, maximum threshold for similarity \u03b4 \u2208 [0, 1]\nand threshold for Shapley value multiplicity \u03b3 \u2208 [0, 1]\n1: Find the pairwise similarity between all points in dataset.\n2:\n3:\n\n4:\n\n5:\n6:\n\n7:\n8:\n9:\n10:\n\nFor each point i, compute the Shapley value using Equations 6 and 7.\nArrange the points in non-increasing order of their Shapley\nvalues. Let gM be the global maximum of Shapley values.\nStart a new queue, let's call it expansion queue.\nStart a new cluster. Of all the unallocated points, choose\nthe point with maximum Shapley value as the new cluster\ncenter. Let lM be its Shapley value. Mark that point as\nallocated. q\nAdd it to the expansion queue.\nSet \u03b2 = \u03b4 glM\n.\nM\nFor each unallocated point, if the similarity of that point\nto the first point in the expansion queue is at least \u03b2, add\nit to the current cluster and mark it as allocated. If the\nShapley value of that point is at least \u03b3-multiple of lM ,\nadd it to the expansion queue.\nRemove the first point from the expansion queue.\nIf the expansion queue is not empty, go to step 6.\nIf the cluster center is the only point in its cluster, mark\nit as noise.\nIf all points are allocated a cluster, terminate. Else go to\nstep 4.\n\nSecondly, when the density around a point is very low as\n\n3\n\nSHARPC\n600\n\n500\n\n400\n\n300\n\n200\n\n100\n\n0\n\nFig. 1.\n\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\n600\n\n700\n\nClusters as discovered by SHARPC\n\nFigure 1 shows the clusters formed by SHARPC [1] which\ntries to allocate clusters by enclosing points in equal-sized\nspheres. It cannot detect clusters that are not convex. Also,\nthe cluster (\u00d7) is a merging of three different clusters. If the\nthreshold is increased so as to solve the second problem, more\nclusters are formed and the larger clusters get subdivided into\nseveral smaller clusters.\nAgglomerative Clustering, as Figure 2 shows, can detect\nclusters of any shape and size. But owing to a constant\n\n\fCENTENARY CONFERENCE, 2011 - ELECTRICAL ENGINEERING, INDIAN INSTITUTE OF SCIENCE, BANGALORE\n\nAgglomerative Clustering\n\nFig. 2.\n\nOPTICS\n\n600\n\n600\n\n500\n\n500\n\n400\n\n400\n\n300\n\n300\n\n200\n\n200\n\n100\n\n100\n\n0\n\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\n600\n\n0\n\n700\n\nClusters as discovered by Agglomerative Clustering\n\nFig. 4.\n\n0\n\n100\n\nDBSCAN\n\n500\n\n500\n\n400\n\n400\n\n300\n\n300\n\n200\n\n200\n\n100\n\n100\n\nFig. 3.\n\n100\n\n200\n\n300\n\n400\n\n300\n\n400\n\n500\n\n600\n\n700\n\n600\n\n700\n\nDensity Restricted Agglomerative Clustering\n600\n\n0\n\n200\n\nClusters as discovered by OPTICS\n\n600\n\n0\n\n4\n\n500\n\n600\n\n0\n\n700\n\nClusters as discovered by DBSCAN\n\nthreshold for the growth of all clusters, it faces the problem\nof forming several clusters in the lower right part when they\nshould have been part of one single cluster. If the threshold\nis decreased so as to solve this problem, clusters (\u2217) and (\u2217)\nget merged. Another problem is that the bridge connecting the\ntwo classes merges these into one single cluster (\u2217).\nFigure 3 shows the results of DBSCAN [13]. It is well\nknown that it cannot detect clusters with different densities\nin general. The points in the lower right part are detected\nas noise when intuitively, the region is dense enough to be\nclassified as a cluster. An attempt to do so compromises the\nclassification of clusters (\u2217) and (\u2217) as distinct. Moreover, the\nbridge connecting the two classes merges them into one single\ncluster (\u2217). An attempt to do the required classification leads\nto unnecessary subdivision of the rightmost class and more\npoints being detected as noise.\nThe clustering obtained using OPTICS [14] is shown in\n\nFig. 5.\n\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\nClusters as discovered by DRAC\n\nFigure 4. Unlike DBSCAN, clusters (\u2217) and (\u2217) are detected\nas distinct. However, the points in the lower right part are\ndetected as noise when they should have been classified as one\ncluster. The reachability plots for different values of minpts are\nsuch that an attempt to classify some of these points as a part\nof some cluster leads to the merging of clusters (\u2217) and (\u2217). If\nwe continue trying to get more of these points allocated, the\nbridge plays the role of merging the two clusters (\u2217) and (\u2217).\nFigure 5 shows the clustering obtained using DensityRestricted Agglomerative Clustering (DRAC). As cluster (+)\nis highly dense, its cluster center has very high Shapley value\nresulting in a very high value of \u03b2, the similarity threshold.\nNo point in cluster (\u2217) crosses the required similarity threshold\nwith the points in cluster (+), thus ensuring that the two\nclusters are not merged. The points in the central part of\nthe bridge have extremely low Shapley values as compared\nto the cluster center of cluster (+) and so they fail to cross\n\n\fCENTENARY CONFERENCE, 2011 - ELECTRICAL ENGINEERING, INDIAN INSTITUTE OF SCIENCE, BANGALORE\n\nthe Shapley value threshold of having at least \u03b3-multiple of the\nShapley value of the cluster center. This ensures that they are\nnot added to the expansion queue of the cluster, thus avoiding\nthe cluster growth to extend to cluster (\u2217). Cluster (\u2217) extends\nto the relatively low density region because of points being\nadded to the expansion queue owing to their sufficiently high\nShapley value, at least \u03b3-multiple of the Shapley value of the\ncluster center. Cluster (\u00d7) is a low density cluster owing to\nthe low Shapley value of the cluster center and so low value\nof \u03b2, the similarity threshold, thus allowing more faraway\npoints to be a part of the cluster. Cluster centers, which fail\nto agglomerate at least one point with their respective values\nof \u03b2, are marked as noise.\nLike other clustering algorithms, Algorithm 1 faces some\nlimitations. As it uses Equations 6 and 7 to compute the\nShapley values, the Shapley value of a point changes even\nwhen a remote point is altered, which may change its cluster\nallocation. For the same reason, the Shapley values of the\npoints close to the mean of the whole dataset is higher than\nother points even when the density around them is not as high.\nOne solution to this problem is to take the positioning of the\npoint into account while computing its Shapley value. There\nis no explicit noise detection. A point is marked as noise if\nit is the only point in its cluster. For instance, in Figure 5,\nthe two points in the upper right corner are noise points, but\nowing to their low Shapley values, \u03b2 is very low and so they\nare classified as a separate cluster (\u25b3) instead. The amortized\ntime complexity of Algorithm 1 is O(n2 ).\nV. C OINCIDENCE OF N UCLEOLUS , S HAPLEY VALUE ,\nG ATELY POINT AND \u03c4 - VALUE IN THE CURRENT SETTING\nIn the game as defined in Section III, we show in this\nsection, that Nucleolus, Shapley value, Gately point and \u03c4 value coincide. First, we discuss the structure of the core. The\ncore is symmetric about a single point, which is the prime\nreason why the above solution concepts coincide with that\nvery point.\n\n5\n\nAB, CD, EF correspond to coalitional rationality constraints.\nThe reader is referred to [4] for a detailed discussion on\nimputation triangle of a 3-player cooperative game. By simple\ngeometry and theory on imputation\ntriangle, it can be seen\n\u221a\nthat AB = DE = \u03bd({2, 3}) 2. Similarly, all opposite sides\nof the core are equal and so the core is symmetric about its\ncenter P .\nClearly, any point other than P will have more distance\nfrom at least one side and so will be lexicographically greater\nthan P , which means that P is the Nucleolus. Also, as the\ncore is symmetric, it is intuitive that P is the fairest of all\nallocations, which means that it corresponds to the Shapley\nvalue imputation. We prove a general result for n-player\nclustering game that all the relevant solution concepts coincide.\nProposition 1. For the transferable utility (TU) game defined\nby Equation 5, for each i \u2208 N , the Shapley Value is given by\n1 X\n\u03bd(S)\n(9)\n\u03c6i =\n2\nS\u2286N\ni\u2208S\n|S|=2\n\nProof From Equations 5 and 7,\n1X\nf (d(i, j))\n\u03c6i =\n2\nj\u2208N\nj6=i\n\n=\n\n1 1 X\nf (d(k, l))\n2 2\nS\u2286N\n|S|=2\nk,l\u2208S\nk6=l\ni\u2208S\n\n=\n\n1 X 1 X\nf (d(k, l))\n2\n2\nS\u2286N\n|S|=2\n\nk,l\u2208S\nk6=l\n\ni\u2208S\n\n=\n\n1 X\n\u03bd(S)\n2\nS\u2286N\n|S|=2\ni\u2208S\n\n1\nS\nA\n\nB\n\nB\nA\nC\n\nC\nP\n\nP\n\nF\nR\n\nO\n\nLemma 1. [8] For the TU game satisfying Equation 9, for\neach S \u2286 N ,\nX\nX\n\u03c6i\n\u03bd(S) \u2212\n\u03c6i = \u03bd(N \\S) \u2212\ni\u2208S\n\n2\n\ni\u2208N \\S\n\nF\nE\n\nD\n\nD\nE\nT\n3\n\nFig. 6. The game has a symmetric core. This figure shows the core for a\n3-player game.\n\nThe reader is referred to [8] for the proof of Lemma 1.\nTheorem 1. [8] For the TU game satisfying Equation 9,\n\u03c6(\u03bd) = N u(\u03bd)\nwhere N u(\u03bd) is the Nucleolus of the TU game (N, \u03bd).\nThe reader is referred to [8] for the proof of Theorem 1.\n\nFigure 6 shows the core for a 3-player cooperative game,\nin our case, a 3-point clustering game. The ST R plane corresponds to collective rationality constraint, sides AF, BC, DE\ncorrespond to individual rationality constraints while sides\n\nTheorem 2. For the TU game defined by Equation 5,\n\u03c6(\u03bd) = Gv(\u03bd)\nwhere Gv(\u03bd) is the Gately point of the TU game (N, \u03bd).\n\n\fCENTENARY CONFERENCE, 2011 - ELECTRICAL ENGINEERING, INDIAN INSTITUTE OF SCIENCE, BANGALORE\n\nProof By Lemma 1, when S = {i}, we have\nX\n\u03bd(i) \u2212 \u03c6i = \u03bd(N \u2212 i) \u2212\n\u03c6j\nj6=i\n\nFrom Equation 1, the propensity to disrupt for player i when\nimputation is the Shapley value is\nP\nj6=i \u03c6j \u2212 \u03bd(N \u2212 i)\ndi (\u03c6) =\n=1\n\u03c6i \u2212 \u03bd(i)\nAs the propensity to disrupt is 1 for every player i, it is equal\nfor all the players and hence, from the theory in Section II-D,\nthe Shapley value imputation is the Gately point.\n\u03c6(\u03bd) = Gv(\u03bd)\n\nTheorem 3. For the TU game defined by Equation 5,\n\u03c6(\u03bd) = \u03c4 (\u03bd)\nwhere \u03c4 (\u03bd) is the \u03c4 -value of the TU game (N, \u03bd).\nProof From Equations 2 and 8,\nMi (\u03bd)\n\n=\n=\n\n\u03bd(N ) \u2212 \u03bd(N \u2212 i)\nX\nX\n\u03bd(S) \u2212\nS\u2286N\n|S|=2\n\n=\n\nX\n\n\u03bd(S)\n\nVI. C ONCLUSION\n\n6\n\nAND\n\nF UTURE W ORK\n\nWe have explored game theoretic solution concepts as an\nalternative to the existing methods, for the clustering problem. Also, Nucleolus being both min-max fair and stable,\nis the most suitable solution concept for pattern clustering.\nWe have also proved the coincidence of Nucleolus, Shapley\nvalue, Gately point and \u03c4 -value for the given characteristic\nfunction. We have proposed an algorithm, Density-Restricted\nAgglomerative Clustering (DRAC), and have provided a qualitative comparison with the existing algorithms along with its\nstrengths and limitations.\nAs a future work, it would be interesting to test our method\nusing Evolutionary game theory and Bargaining concepts. It\nwould be worthwhile developing a characterization of games\nfor which various game theoretic solution concepts coincide.\nVII. ACKNOWLEDGEMENT\nThis work is an extension of a project as part of Game\nTheory course. We thank Dr. Y. Narahari, the course instructor,\nfor helping us strengthen our concepts in the subject and for\nguiding us throughout the making of this paper. We thank\nAvishek Chatterjee for mentoring our project, helping us get\nstarted with cooperative game theory and for the useful and\nessential criticism which helped us improve our algorithm.\n\nS\u2286N \\{i}\n|S|=2\n\nR EFERENCES\n\n\u03bd(S)\n\nS\u2286N\ni\u2208S\n|S|=2\n\nThis, with Equation 4 and the fact that for our (N, \u03bd) game,\nfor all i, mi (\u03bd) = \u03bd(i) = 0,\nX\n\u03bd(N ) = \u03bb\nMi (\u03bd)\ni\u2208N\n\n= \u03bb\n\nX X\n\n\u03bd(S)\n\ni\u2208N S\u2286N\ni\u2208S\n|S|=2\n\n= 2\u03bb\n\nX\n\n\u03bd(S)\n\nS\u2286N\n|S|=2\n\nUsing Equation 8, we get \u03bb = 12 . This, with Equation 3 and\nthe fact that for all i, mi (\u03bd) = 0,\n1 X\n\u03c4i (\u03bd) =\n\u03bd(S)\n2\nS\u2286N\ni\u2208S\n|S|=2\n\nThis, with Proposition 1, gives\n\u03c6(\u03bd) = \u03c4 (\u03bd)\n\nFrom Theorem 1, Theorem 2 and Theorem 3, the Nucleolus,\nthe Shapley value, the Gately point and the \u03c4 -value coincide\nin the clustering game with the chosen characteristic function.\nThese results further vindicate our choice of characteristic\nfunction for the clustering game.\n\n[1] Garg V.K., Narahari Y. and Murthy N.M., Shapley Value Based Robust\nPattern Clustering, Technical report, Department of Computer Science\nand Automation, Indian Institute of Science, 2011.\n[2] Backer E. and Jain A. A clustering performance measure based on fuzzy\nset decomposition, IEEE Transactions Pattern Analysis and Machine\nIntelligence (PAMI), 3(1), 1981, pages 66-75.\n[3] Pelillo M., What is a cluster? Perspectives from game theory, NIPSWorkshop on Clustering: Science of Art, 2009.\n[4] Straffin P.D., Game Theory and Strategy, The Mathematical Association\nof America, 1993, pages 202-207.\n[5] Schmeidler D., The Nucleolus of a Characteristic Function Game, SIAM\nJournal on Applied Mathematics, 17(6), Nov. 1969, pages 1163-1170.\n[6] Tijs S.H., An Axiomization of the \u03c4 -value, Mathematical Social Sciences,\n13(2), 1987, pages 177-181.\n[7] Saad W., Han Z., Debbah M., Hjorungnes A. and Basar T., Coalitional\nGame Theory for Communication Networks: A Tutorial, IEEE Signal\nProcessing Magazine, Special issue on Game Theory, 2009.\n[8] Chun Y. and Hokari T., On the Coincidence of the Shapley Value and the\nNucleolus in Queueing Problems, Seoul Journal of Economics, 2007.\n[9] Kohlberg E., On the nucleolus of a characteristic function game, SIAM\nJournal on Applied Mathematics, Vol. 20, 1971, pages 62-66.\n[10] Bulo S.R. and Pelillo M., A game-theoretic approach to hypergraph\nclustering, Advances in Neural Information Processing Systems, 2009.\n[11] Gupta U. and Ranganathan N., A microeconomic approach to multiobjective spatial clustering, 19th International Conference on Pattern\nRecognition, 2008, pages 1-4.\n[12] Gupta U. and Ranganathan N., A Game Theoretic Approach for Simultaneous Compaction and Equipartitioning of Spatial Data Sets, IEEE\nTransactions on Knowledge and Data Engineering, 2009, pages 465-478.\n[13] Ester M. Kriegel H.P., Sander J. and Xu X., A Density-Based Algorithm\nfor Discovering Clusters in Large Spatial Databases with Noise, Proceedings of the 2nd International Conference on Knowledge Discovery and\nData mining, 1996, pages 226-231.\n[14] Ankerst M., Breunig M.M., Kriegel H.P. and Sander J. OPTICS: ordering points to identify the clustering structure, ACM SIGMOD Record,\n28(2), 1999, pages 49-60.\n\n\f"}