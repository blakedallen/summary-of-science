{"id": "http://arxiv.org/abs/1011.2953v1", "guidislink": true, "updated": "2010-11-12T15:35:10Z", "updated_parsed": [2010, 11, 12, 15, 35, 10, 4, 316, 0], "published": "2010-11-12T15:35:10Z", "published_parsed": [2010, 11, 12, 15, 35, 10, 4, 316, 0], "title": "A Distributed Clustering Algorithm for Dynamic Networks", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1011.2953%2C1011.1324%2C1011.6199%2C1011.0495%2C1011.3153%2C1011.1450%2C1011.3940%2C1011.4129%2C1011.4615%2C1011.2451%2C1011.5698%2C1011.0206%2C1011.0804%2C1011.5678%2C1011.0985%2C1011.1772%2C1011.2972%2C1011.1853%2C1011.0942%2C1011.4902%2C1011.2177%2C1011.0182%2C1011.1968%2C1011.5785%2C1011.6643%2C1011.0963%2C1011.5643%2C1011.4600%2C1011.6442%2C1011.5662%2C1011.0278%2C1011.2508%2C1011.1038%2C1011.3735%2C1011.4231%2C1011.2688%2C1011.1693%2C1011.1391%2C1011.3330%2C1011.1331%2C1011.3088%2C1011.3821%2C1011.1058%2C1011.1802%2C1011.2330%2C1011.3107%2C1011.4442%2C1011.6308%2C1011.5900%2C1011.5264%2C1011.5551%2C1011.4211%2C1011.0465%2C1011.4114%2C1011.0579%2C1011.5943%2C1011.0153%2C1011.2151%2C1011.6315%2C1011.0621%2C1011.6242%2C1011.1646%2C1011.2121%2C1011.5979%2C1011.3261%2C1011.2392%2C1011.6647%2C1011.1813%2C1011.1797%2C1011.0569%2C1011.2204%2C1011.0381%2C1011.0893%2C1011.4610%2C1011.3938%2C1011.0170%2C1011.4445%2C1011.6601%2C1011.6052%2C1011.2666%2C1011.6494%2C1011.1643%2C1011.3678%2C1011.0356%2C1011.4330%2C1011.2985%2C1011.1918%2C1011.5010%2C1011.4573%2C1011.5904%2C1011.5141%2C1011.4456%2C1011.1995%2C1011.1631%2C1011.1878%2C1011.1633%2C1011.3403%2C1011.2255%2C1011.5098%2C1011.0928%2C1011.0659&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A Distributed Clustering Algorithm for Dynamic Networks"}, "summary": "We propose an algorithm that builds and maintains clusters over a network\nsubject to mobility. This algorithm is fully decentralized and makes all the\ndifferent clusters grow concurrently. The algorithm uses circulating tokens\nthat collect data and move according to a random walk traversal scheme. Their\ntask consists in (i) creating a cluster with the nodes it discovers and (ii)\nmanaging the cluster expansion; all decisions affecting the cluster are taken\nonly by a node that owns the token. The size of each cluster is maintained\nhigher than $m$ nodes ($m$ is a parameter of the algorithm). The obtained\nclustering is locally optimal in the sense that, with only a local view of each\nclusters, it computes the largest possible number of clusters (\\emph{ie} the\nsizes of the clusters are as close to $m$ as possible). This algorithm is\ndesigned as a decentralized control algorithm for large scale networks and is\nmobility-adaptive: after a series of topological changes, the algorithm\nconverges to a clustering. This recomputation only affects nodes in clusters in\nwhich topological changes happened, and in adjacent clusters.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1011.2953%2C1011.1324%2C1011.6199%2C1011.0495%2C1011.3153%2C1011.1450%2C1011.3940%2C1011.4129%2C1011.4615%2C1011.2451%2C1011.5698%2C1011.0206%2C1011.0804%2C1011.5678%2C1011.0985%2C1011.1772%2C1011.2972%2C1011.1853%2C1011.0942%2C1011.4902%2C1011.2177%2C1011.0182%2C1011.1968%2C1011.5785%2C1011.6643%2C1011.0963%2C1011.5643%2C1011.4600%2C1011.6442%2C1011.5662%2C1011.0278%2C1011.2508%2C1011.1038%2C1011.3735%2C1011.4231%2C1011.2688%2C1011.1693%2C1011.1391%2C1011.3330%2C1011.1331%2C1011.3088%2C1011.3821%2C1011.1058%2C1011.1802%2C1011.2330%2C1011.3107%2C1011.4442%2C1011.6308%2C1011.5900%2C1011.5264%2C1011.5551%2C1011.4211%2C1011.0465%2C1011.4114%2C1011.0579%2C1011.5943%2C1011.0153%2C1011.2151%2C1011.6315%2C1011.0621%2C1011.6242%2C1011.1646%2C1011.2121%2C1011.5979%2C1011.3261%2C1011.2392%2C1011.6647%2C1011.1813%2C1011.1797%2C1011.0569%2C1011.2204%2C1011.0381%2C1011.0893%2C1011.4610%2C1011.3938%2C1011.0170%2C1011.4445%2C1011.6601%2C1011.6052%2C1011.2666%2C1011.6494%2C1011.1643%2C1011.3678%2C1011.0356%2C1011.4330%2C1011.2985%2C1011.1918%2C1011.5010%2C1011.4573%2C1011.5904%2C1011.5141%2C1011.4456%2C1011.1995%2C1011.1631%2C1011.1878%2C1011.1633%2C1011.3403%2C1011.2255%2C1011.5098%2C1011.0928%2C1011.0659&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We propose an algorithm that builds and maintains clusters over a network\nsubject to mobility. This algorithm is fully decentralized and makes all the\ndifferent clusters grow concurrently. The algorithm uses circulating tokens\nthat collect data and move according to a random walk traversal scheme. Their\ntask consists in (i) creating a cluster with the nodes it discovers and (ii)\nmanaging the cluster expansion; all decisions affecting the cluster are taken\nonly by a node that owns the token. The size of each cluster is maintained\nhigher than $m$ nodes ($m$ is a parameter of the algorithm). The obtained\nclustering is locally optimal in the sense that, with only a local view of each\nclusters, it computes the largest possible number of clusters (\\emph{ie} the\nsizes of the clusters are as close to $m$ as possible). This algorithm is\ndesigned as a decentralized control algorithm for large scale networks and is\nmobility-adaptive: after a series of topological changes, the algorithm\nconverges to a clustering. This recomputation only affects nodes in clusters in\nwhich topological changes happened, and in adjacent clusters."}, "authors": ["Thibault Bernard", "Alain Bui", "Laurence Pilard", "Devan Sohier"], "author_detail": {"name": "Devan Sohier"}, "author": "Devan Sohier", "links": [{"href": "http://arxiv.org/abs/1011.2953v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1011.2953v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.DC", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.DC", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1011.2953v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1011.2953v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "A Distributed Clustering Algorithm for Dynamic Networks\nThibault Bernard(1) , Alain Bui(2) , Laurence Pilard(2) and Devan Sohier(2)\n\narXiv:1011.2953v1 [cs.DC] 12 Nov 2010\n\n(1)\n\nCReSTIC, Universit\u00e9 de Reims CA, France,\nthibault.bernard@univ-reims.fr\n\n(2)\n\nPRi SM UMR CNRS, Universit\u00e9 de Versailles Saint-Quentin, France,\n{alain.bui, laurence.pilard, devan.sohier}@prism.uvsq.fr\n\nAbstract\nWe propose an algorithm that builds and maintains clusters over a network subject to\nmobility. This algorithm is fully decentralized and makes all the different clusters grow concurrently. The algorithm uses circulating tokens that collect data and move according to a\nrandom walk traversal scheme. Their task consists in (i) creating a cluster with the nodes it\ndiscovers and (ii) managing the cluster expansion; all decisions affecting the cluster are taken\nonly by a node that owns the token. The size of each cluster is maintained higher than m\nnodes (m is a parameter of the algorithm). The obtained clustering is locally optimal in the\nsense that, with only a local view of each clusters, it computes the largest possible number of\nclusters (ie the sizes of the clusters are as close to m as possible). This algorithm is designed\nas a decentralized control algorithm for large scale networks and is mobility-adaptive: after a\nseries of topological changes, the algorithm converges to a clustering. This recomputation only\naffects nodes in clusters in which topological changes happened, and in adjacent clusters.\n\n1\n\nIntroduction\n\nScalability in distributed system has become a major challenge nowadays, in structuring and managing communications. We propose a solution to manage large-scale networks based on the division\nof the system into subsystems, called clusters. We focus in this paper on algorithms that build\nclusters and maintain them after topological reconfiguration. The algorithms we propose are decentralized: all nodes execute the same code. This allows all clusters to be built concurrently, which\nis desirable for efficiency.\nLarge-scale networks are often subject to mobility: their components can connect or disconnect.\nThis phenomenon has to be taken into account. The algorithm being decentralized also allows the\nalgorithm to have no distinguished node, the failure of which would lead to a major re-clustering.\nThe connection or disconnection of a node has only a limited impact (that we can state) on the\nalgorithm.\nRandom walks are naturally adaptive to dynamic networks such as ad-hoc sensors network\n[BBCD02, DSW06] because they make use only of local up-to-date information. Moreover they can\neasily manage connections and disconnections occurring in the network.\nOur solution takes these different constraints into account. It is based on the circulation of\nseveral tokens. Each token creates a cluster and coordinates its growing in a decentralized way.\n1\n\n\fA random walk based algorithm is a token circulation algorithm in which a token randomly\nmoves among the nodes in the network. A random walk can be used as base of a distributed token\ncirculation algorithm. This token collects and disseminates information in the network. At each\nstep of the execution of the algorithm, the random walk (the token) is on a node i of the network.\nThe node that owns the token chooses one of its neigbour j with a probability 1/degree(i). It is\nimportant to remark that this definition ensures that all nodes, with high probability, eventually\nown the token, and that the token, with high probability, eventually hits all nodes [Lov93].\nIn [BBF04, BBFR06], we introduced and used the combination of a circulating word, i.e. the\ntoken has a content to collect and broadcast data (this concept is formally defined in Section 2.3)\nand a random walk as moving scheme of the token. Using this combination, we proposed solutions to\nbuild adaptive spanning trees for systems like ad-hoc sensor networks. These solutions are tolerant\nto transient failures in the network.\nIn these works, we also proposed a fully decentralized solution to the communication deadlock\nproblem, introducing a new control mechanism called reloading wave. These works have been used\nto propose a solution to the resource allocation problem in ad-hoc networks [BBFN10]. Such a\ncombination has also been used in [BBFR06] to build and maintain spanning structures to solve\non-the-fly resources research in peer-to-peer grids.\nAlthough the token perpetually circulates in the network in order to update the underlying\nstructure, we bound the size of the circulating word to 2n \u2212 1 in the case of bidirectional communication links and to n2 /4 in the case of unidirectional communication links, by retaining only the\nmost recent data necessary to build the tree (with n the size of the network, [Ber06]).\nWe use the content of the circulating word to structure the network into different clusters. Their\nconstruction and their maintenance are achieved in a decentralized way. Using the properties of\nrandom walks and of circulating words, the clusters are able to adapt to topological reconfigurations.\nThus, this solution can be used to design distributed control algorithm on large scale dynamic\nnetworks.\nUnlike solutions described in [Bas99, JN06], our solution does not use any local leader on a\ncluster. The advantage of such solutions is that if a node \"moves\" in the network, this never entails\na total reconstruction of the clusters. After a topological change, the system eventually converges\nto a correct global state without having to rebuild all clusters. This kind of approach on a 1-hop\nsolution is described in [TIMF05] in which re-clustering mechanism are used. Our solution is totally\ndecentralized as opposed to [BBCD02], in which a spanning structure of the whole network is built\nin a first step, to be divided using a global mechanism. Our solution is realized in a fully concurrent\nway. As stated in [ABCP96], it considerably accelerates the construction of the different clusters.\nThus our solution satisfies the property highlighted in [TV08].\nMoreover, we guarantee that after a topological change, only a bounded portion of the system\nis affected. Nodes that are in clusters that are not adjacent to the one in which it occurs have no\nextra work, and are not even aware of this event.\nIn the first section, we present some preliminary notions about random walk based distributed\nalgorithms, and we present with more details the clustering problem we solve. The second section\ngives the fundamental distributed clustering algorithm we designed. The third section provides\nproofs about the correctness of the algorithm. The fourth section is about mobility: we present the\nslight adaptations needed to handle nodes and links mobility, as well as proofs of this algorithm;\nwe also present a locality result: after topological modifications, in the worst case, the only clusters\nthat are affected are the clusters in which the topological changes took place and clusters that are\nadjacent to them. Finally, we conclude this paper by presenting some future works.\n\n2\n\n\f2\n\nPreliminaries\n\nIn this section, we define a distributed system, a random walk and a circulating word. We also\nintroduce the notion of clustering.\n\n2.1\n\nDistributed system\n\nA distributed system is a connected graph G = (V, E), where V is a set of nodes with |V | = n\nand E is the set of bidirectional communication links. A node is constituted of a computing unit\nand a message queue. Two nodes are called neighbors if a communication link (i, j) exists between\nthem. Every node i can distinguish between all its communication links and maintains a set of its\nneighbors (denoted Ni ). The degree of i is the number of its neighbors. We consider distributed\nsystems in which all nodes have distinct identities.\nWe consider asynchronous systems: we do not assume any bound on communication delays and\non processing times.\n\n2.2\n\nRandom walk\n\nA random walk is a sequence of nodes visited by a token that starts at i and visits other nodes\naccording to the following transition rule: if the token is at i at step t then at step t + 1, it will\nbe at one of the neighbors of i, this neighbor being chosen uniformly at random among all of them\n[Lov93, AKL+ 79].\nA random walk on a connected graph eventually visits any node with probability 1 (whp in the\nfollowing). It means that, for any finite time t, it is possible that the walk does not hit a given\nnode for t steps, but that the probability that it does so tends to 0 as t grows ([Lov93]).\n\n2.3\n\nCirculating word\n\nA circulating word is a list of data gathered during the circulation of the token in the network.\nIn this work, the gathered data is the identifiers of the visited nodes. The word is represented\nas follow: w = <w[1], . . . , w[k]> where k is the size of the circulating word and w[l] is the node\nidentifier in position l in the word. Each time the token visits a node, the node identifier is added\nat the beginning of the word.\nThe token follows a random walk scheme, which allows an efficient management of network.\nThe word gathers identifiers of the visited nodes in order to maintain an adaptive spanning tree of\nthe network. Only the most recent data is used to build this spanning tree, and, thus, only 2n \u2212 1\nentries of the word are used. Older data can be removed, which bounds the word length to 2n \u2212 1.\nThe detailed procedure to reduce the size of the word is described in [Ber06] (cf. algorithm 2).\nWe use the following procedures:\n\u2022 Procedure Size(w : word) : integer \u2013 returns the size of the word w;\n\u2022 Procedure N b_Identities(w : word) : integer \u2013 returns the number of distinct identities in\nthe word w;\n\u2022 Procedure Add_Begin(j : identif ier, w : word) : word \u2013 adds identifier j at the beginning of\nw.\n\n3\n\n\fThe procedure Build_T ree computes from a word w a tree A rooted in w[1].\nAlgorithm 1 Procedure Build_T ree(w : word) : tree\n1:\n2:\n3:\n4:\n5:\n6:\n7:\n8:\n\nA \u2190\u2212 \u2205\nSet_Root(A, w[1])\nfor k = 2 to Size(w) do\nif w[k] 6\u2208 A then\nadd_T ree(A, w[k], w[k \u2212 1])\nend if\nend for\nreturn A\n\n// add w[k] as the son of w[k\u22121] in A\n\nThe following procedures take a rooted tree as entry (node i executes this procedure):\n\u2022 T ree_T o_W ord(A : tree) : word \u2013 computes a word w such that the first identifier of w is\nthe root of A;\n\u2022 M y_Sons(A : tree) : identif iers_set \u2013 returns the set of i's sons in A;\n\u2022 M y_F ather(A : tree) : identif ier \u2013 returns i's father in A.\nExample 1 Let G = (V, E) with V = {1, . . . , n}. Consider a random-walk based token with word\nw0 = <1, 5, 3, 2, 3, 6, 3, 2, 4> corresponding to a token initially generated at node 4 and arriving at\nnode 1 after 8 movements. By algorithm 1 the tree described in 1 (a) is obtained.\nNow, assume that the link 3 \u2212 2 disappears. At this point, the tree is not consistent with the\nnetwork topology. The traversal technique using random-walk based token is used to maintain an\nadaptive communication structure taking into account last collected elements: if after 4 movements\nthe word becomes w = <1, 6, 2, 4, 1, 5, 3, 2, 3, 6, 3, 2, 4>. The tree evolves over time, cf. figure 1\n(b), taking into account the most recent data and then the tree becomes consistent with the network\ntopology.\nThe idea of the reduction technique is to delete all useless informations in the construction of\nthe tree. Then the word reduction of w0 is the following reduced word: <1, 6, 2, 4, 1, 5, 3> \u2013 we\nobtain the same tree. This reduction is done after each movement of the token using the procedure\nClean_W ord, cf algorithm 2. We prove in [Ber06] that the size of the circulating word is bounded\nby 2n \u2212 1.\n\nFigure 1: Construction of the tree rooted in node 1.\n\nThe procedure Clean_W ord() removes all successive occurrences of i in the word. It also keeps\nthe smallest prefix of the word necessary to represent a sub-tree of the cluster, allowing to bound\nthe size of the word.\n4\n\n\fAlgorithm 2 Procedure Clean_W ord(w : word) : word\n1:\n2:\n3:\n4:\n5:\n6:\n7:\n8:\n9:\n10:\n11:\n12:\n\nz \u2190\u2212 1\nvisited \u2190\u2212 {w[1]}\nwhile z < Size(w) do\nif w[z] = i then\nwhile Size(w) > z + 1 \u2227 ((w[z + 1] = w[z]) \u2228 (w[z + 1] \u2208\n/ visited \u2227 w[z + 1] \u2208\n/ Ni )) do\nDelete_Element(w, z + 1)\nend while\nend if\nvisited \u2190\u2212 visited \u222a {w[z + 1]}\nz \u2190\u2212 z + 1\nend while\nreturn w\n\n2.4\n\nClusters\n\nTo allow scalability of random walk-based algorithms, we propose to divide the system into clusters.\nEach cluster is maintained by a token. The size of all clusters is greater than m, that is a parameter\nof the algorithm. Clusters are larger than m nodes and as close to m nodes as possible. In the\nfollowing, we suppose that the system is connected and contains at least m nodes.\nA cluster is represented by a variable col on each node. This variable is the color (identifier) of\nthe cluster to which the node belongs. Each cluster has to be connected.\nDefinition 1 (Cluster) The cluster of color c, noted Vc , is the set of all nodes having the color c\n(if non-empty).\nVc = {i \u2208 V, coli = c}\nA non-empty set of nodes V 0 is a cluster if there exists a color c such that V 0 = Vc .\nDefinition 2 We call a cluster divisible if it can be split into two connected subgraphs of sizes\ngreater than m.\nDefinition 3 A spanning tree A of a cluster is called divisible if it contains an edge that, when\nremoved, leads to two trees of size greater than m.\nProperty 1 A divisible cluster admits a divisible spanning tree.\nProof Let V a divisible cluster. Then, it admits two connected subgraphs V1 and V2 with sizes\ngreater than m. V1 (resp. V2 ) admits a spanning tree A1 (resp. A2 ). V being connected, consider\nan edge a between a node in V1 and a node in V2 . Then, the tree A obtained from A1 and A2 by\nadding the edge a is a spanning tree of V that is divisible (when removing a, we obtain two trees\nof size greater than m).\n\u0003\nInthe algorithm \"growing\" phase, the clusters grow from an empty set by annexing nodes. Two\nsituations must be managed: divisible clusters, and clusters with a size strictly lower than m.\nDefinition 4 (Stable cluster) A cluster Vc is called stable if it is large enough:\nstable(Vc ) = (|Vc | \u2265 m)\n5\n\n\fDefinition 5 (Free Node) A node is called free if it does not belong to any cluster:\nf ree(i) = (coli = null)\nThus, each node in the network either belongs to a cluster or is free.\n\n2.5\n\nProblem specification\n\nThe aim of this algorithm is to build a clustering. Thus, we want that:\n\u2022 all nodes belong to a cluster;\n\u2022 clusters are connected.\nAdditionally, we require that all clusters have a size greater than m and are not divisible.\nTo forbid a trivial clustering consisting in all nodes setting their color to the same color, we add\nan extra constraint: we require that there is no divisible cluster. No clustering algorithm working\non arbitrary topologies can set both a non-trivial lower and a non-trivial upper bound on the size of\nthe clusters. Indeed, consider a lower bound m > 1 and an upper bound M < n on a star graph on\nn nodes. Then, there is at least two clusters (since M < n), and the central node is in a cluster V .\nThen, any node i that is not in V is in a connected cluster, that can only be {i}, which contradicts\nthe assumption m > 1.\nThus, we try to obtain clusters as small as possible with a size greater than m. Due to the\ndistributed nature of the problem we consider, this \"as small as possible\" has to be detected on a\nbasis that is local to the cluster: no global view can be used to compute the clusters. This is why\nwe translate \"as small as possible\" in \"not divisible\"\nFinally, we are willing to compute clusters of size greater than m that are not divisible.\n\n3\n\nAlgorithm description\n\nOne or several nodes start the algorithm by creating a token. Each token is associated to a cluster\nand circulates perpetually according to a random walk scheme, building and maintaining its own\ncluster. The algorithm execution goes through different phases. At the beginning, a cluster (in fact\nits associated token) sequentially annexes nodes, ie when a token meets a free node, the free node\njoins the cluster: it is the collect mechanism. When a token meets another cluster (maintained by\nanother token), two cases can occur: either the token is sent back to its own cluster, or it triggers\na dissolution mechanism on its own cluster if this cluster has a size below m (i.e. a non-stable\ncluster). The goal of this mechanism is to delete clusters that cannot reach a size of m by making\nall their nodes free. The third mechanism is the division mechanism: if a cluster grows and becomes\ndivisible, then the cluster is divided into two smaller stable clusters.\nThe algorithm uses five types of messages: Token, Dissolution, FeedbackDiss, Division and\nFeedbackDiv. Token messages are the main messages of the algorithm. They represent a cluster\nand collect node identifiers during their circulation (algorithms 4 and 5). The four other types\nof messages are control messages circulating in a cluster built by a token. The dissolution and\ndivision mechanisms are based on a classical propagation of information with feedback [Seg83,\nTel94, BDPV07] over the cluster that has to be dissolved or divided. The dissolution mechanism\nuses Dissolution and FeedbackDiss messages to make all nodes in a cluster free (algorithms 6 and\n7). The division mechanism uses Division and FeedbackDiv messages to divide one large cluster\ninto two smaller clusters (of size still greater than m) (algorithms 8 and 9).\n6\n\n\f3.1\n\nNodes and tokens variables\n\nA cluster is identified by a color : each node having this color belongs to this cluster. The color of\na cluster is the identifier of the node that has created this cluster. A cluster is created when a free\nnode awakens and creates a token (cf. Algorithm 4).\nEach token T contains:\n\u2022 colT : the color (identifier) of the cluster it represents and\n\u2022 wT : the set of nodes that belongs to this cluster (this is the circulating word).\nThe token gathers identities of the visited nodes as explained in the section above.\nA node i saves the identifier of its cluster, and the identifiers of the nodes belonging to this\ncluster. The local variables of a node having the identifier i are:\n\u2022 coli : color of the cluster i belongs to;\n\u2022 wi : circulating word of the last token with the same color as i that has visited i;\n\u2022 nbF eedbackDivi : number of F eedbackDiv messages received during the division phase;\n\u2022 nbF eedbackDissi : number of F eedbackDiss messages received during the dissolution phase.\nThe last two variables are necessary to the Propagation of Information with Feedback algorithms\nused in the dissolution and division mechanisms.\nThe definition domain of coli is: {node identifiers in the network} \u222a {null, \u22121}. We assume\nthere is no node in the network having the identifier -1. A free node is such that coli = null.\nA locked node is such that coli = \u22121. The difference between a free node and a locked node is\nthat a free node does not belong to any cluster and can join one, while a locked node belongs to a\n\"false\" cluster, which forbids the node to join a real one. The locked state is used in the dissolution\nmechanism and it is such that no node will remain locked forever.\nThe variable wi is used to break the symmetry in the dissolution mechanism (cf. section 3.2.1)\nand avoid reciprocal destructions. It also allows node i to know all identifiers of its cluster.\n\n3.2\n\nAlgorithm\n\nIn the following, all procedures are executed by node i.\nInitially, all nodes are free.\nAlgorithm 3 On initialization\n1:\n2:\n3:\n4:\n\ncoli \u2190\u2212 null\nwi \u2190\u2212 \u03b5\nnbF eedbackDivi \u2190\u2212 0\nnbF eedbackDssi \u2190\u2212 0\n\n3.2.1\n\nCollect Mechanism\n\nWhen awakening, a free node creates a token with probability 1/2; otherwise it goes back to sleep\nfor a random time. The color of the created token is the identifier of the node that creates the\ntoken.\n\n7\n\n\fAlgorithm 4 On node i awakening\n1: if coli = null then\n2:\nToss a coin\n3:\nif tail then\n4:\ncoli \u2190\u2212 i\n5:\nwi \u2190\u2212 <i>\n6:\nRandom choice of j \u2208 Ni , Send T oken(coli , wi ) to j\n7:\nend if\n8: end if\n\nTo describe the various cases of the algorithm 5, we assume that node i receives a red token:\nIf i is red or free (Algorithm 5 lines 7 to 23): First i adds its own identifier at the beginning\nof the circulating word and then cleans this word (Algorithm 5 lines 9 and 10). This ensures that\nthe circulating word always represents a spanning tree of the whole cluster.\nSecond, if the tree represented by the word in the token is divisible, then i launches a division:\na spanning tree is built from the circulating word and the division is done over this spanning tree\n(algorithm 5 lines 11 to 16). Otherwise i joins the cluster and sends the token to one of its neighbor\nchosen uniformly at random (algorithm 5 lines 17 to 23).\nIn the following, more details about the division are given (lines 11 to 16). The spanning tree\nis partitioned into two sub-trees using the following procedure Divide(A tree) : (w1 : word, w2 :\nword):\n1. A1 and A2 are two subtrees of A;\n2. the union of A1 and A2 is A and the intersection of A1 and A2 is empty;\n3. the root of A1 is i;\n4. w1 is a word representing A1 ;\n5. w2 is a word representing A2 ;\n6. N b_Identities(w1 ) \u2265 m and N b_Identities(w2 ) \u2265 m.\nSuch an algorithm can, for example, associate to each node in A the size of the subtree rooted\nin this node. If for a node i, this size k is such that k \u2265 m and N b_identities(A) \u2212 k \u2265 m, then it\nreturns the word computed from the subtree rooted in i and the word computed from the subtree\nobtained by removing i and its descendants from A. If no node verifies this, then the tree is not\ndivisible.\ni\n\nr2\n|A1| >= m\nw1 = < i, ... >\n\n|A2| >= m\nw2 = < r2, ... >\n\n8\n\n\fThe node i uses the procedure Is_Divisible in order to know if the spanning tree is divisible:\nProcedure Is_Divisible(A tree) : boolean \u2013 returns true iff Divide(A) is possible\nIf the node i launches a division, then i joins the cluster represented by the word w1 . The color\nof this new cluster is i. Then i initiates a propagation of Division messages in the spanning tree\nof the whole cluster (i.e. the tree A).\nIf i is locked (Algorithm 5 lines 24 and 25):\n\ni sends the token back to its sender.\n\nIf i is blue (Algorithm 5 lines 26 to 35): If the size of the cluster represented by T , noted\n\u03c6T , is too small (|wT | < m), then the cluster is dissolved in order for the cluster to which i belongs\nto grow. This dissolution is achieved by i launching a dissolution mechanism. However, if the size\nof i's cluster, noted \u03c6i , is also too small, then we have to avoid the case when \u03c6i is destroyed by a\nnode in \u03c6T and \u03c6T is destroyed by a node in \u03c6i . Thus i can launch a dissolution mechanism over\n\u03c6T only if the size of wi is large enough (wi \u2265 m) or if i's color is greater than the one of T (lines\n29 to 31).\nNote that wi does not contain all node identifiers in \u03c6i , but a subset of it. Indeed when the\ntoken representing \u03c6i , noted t, arrived in i for the last time, i saved wt in wi . Then all identifiers\nin wi are identifiers of \u03c6i . However, t kept circulating after arriving in i and then some free nodes\nkept joining \u03c6i . Thus, some identifiers in \u03c6i may not belong to wi .\nIf i does not launch a dissolution mechanism, then it sends the token back to its sender (line\n33).\n\n9\n\n\fAlgorithm 5 On the reception of T oken(colT , wT )\n1: if (coli = null \u2228 coli = colT ) then\n2:\n\n//\u2013\u2013\u2013 Case 1:\n\n3:\n4:\n\nwT \u2190\u2212 Add_Begin(i, wT )\nwT \u2190\u2212 Clean_W ord(wT )\n\n5:\n\nif Is_Divisible(wT ) then\n\n6:\n7:\n8:\n9:\n10:\n11:\n\n(i is free) or (i is red and receives a red token)\n\n// If the cluster is large enough, we launch a division\nA \u2190\u2212 Build_T ree(wT )\n(w1 , w2 ) \u2190\u2212 Divide(A)\n// w1 = <i, . . . > and w2 = <r2, . . . >\ncoli \u2190\u2212 i\nwi \u2190\u2212 w1\n\u2200j \u2208 M y_Sons(A) : Send Division(A, w1 , w2 ) to j\nelse\n\n12:\n13:\n14:\n15:\n16:\n\n// Otherwise i joins the cluster and forwards the token\ncoli \u2190\u2212 colT\nwi \u2190\u2212 wT\nRandom choice of j \u2208 Ni , Send T oken(colT , wT ) to j\nend if\n\n17:\n\n18: else if coli = \u22121 then\n19:\nSend T oken(colT , wT ) to wT [1]\n20:\n\n//\u2013\u2013\u2013 Case 2:\n\ni is blue and receives a red token\n\n21: else\n22:\n\n23:\n24:\n25:\n26:\n27:\n28:\n29:\n\n// If the red cluster is too small and under some asymmetric assumptions, i can\ndissolve it\n// Otherwise i sends back the token to its sender\nif N b_Identities(wT ) < m \u2227 (N b_Identities(wi ) \u2265 m \u2228 coli > colT ) then\nA \u2190\u2212 Build_T ree(wT )\nSend Dissolution(A) to wT [1]\nelse\nSend T oken(colT , wT ) to wT [1]\nend if\nend if\n\n3.2.2\n\nDissolution mechanism\n\nThe dissolution mechanism is used to totally delete a cluster with a size smaller than m. This\nmechanism is a classical propagation of information with feedback. A Dissolution message is\npropagated through a spanning tree of the cluster to dissolve, and then during the feedback phase,\na F eedbackDiss message is propagated in the tree. Each of these two kinds of messages has one\nvariable, A that is a rooted spanning tree of the cluster that has to be dissolved. Both propagation\nand feedback waves are propagated on the tree A.\nDuring the propagation phase, a node receiving a Dissolution message leaves its cluster and\nbecomes locked. The propagation phase is used to completely delete the cluster. Then during the\nfeedback phase, a node receiving a F eedbackDiss message becomes a free node. At the end of a\n10\n\n\fdissolution, all nodes that used to be in the cluster are free, and the cluster does not exist anymore.\nAlgorithm 6 On the reception of Dissolution(A)\n1: coli \u2190\u2212 \u22121\n2: wi \u2190\u2212 \u03b5\n3: if |M y_Sons(A)| > 0 then\n4:\n\u2200j \u2208 M y_Sons(A) : Send Dissolution(A) to j\n5:\nnbF eedbackDissi \u2190\u2212 0\n6: else\n7:\nSend F eedbackDiss(A) to M y_F ather(A)\n8:\ncoli \u2190\u2212 null\n9: end if\n\nAlgorithm 7 On the reception of F eedbackDiss(A)\n1: nbF eedbackDissi + +\n\n// if i receives the last feedback it was waiting for\n2: if nbF eedbackDissi = |M y_Sons(A)| then\n3:\nsend F eedbackDiv(A) to M y_F ather(A)\n4:\ncoli \u2190\u2212 null\n5: end if\n\n3.2.3\n\nDivision mechanism\n\nThe division mechanism is used to divide a cluster \u03c6 into two smaller clusters \u03c61 and \u03c62 with a size\ngreater than m. This mechanism is a Propagation of Information with Feedback (PIF). A Division\nmessage is propagated in a spanning tree of the cluster to divide, and then during the feedback\nphase, a F eedbackDiss message is propagated through the tree. Each of these two kind of messages\nhas three variable:\n\u2022 A: a rooted spanning tree of the cluster that has to be dissolved;\n\u2022 w1 : a rooted spanning tree containing all node identifiers of the first sub-cluster \u03c61 ;\n\u2022 w2 : a rooted spanning tree containing all node identifiers of the first sub-cluster \u03c62 .\nSubtrees w1 and w2 are a partition of the tree A. Moreover, the first identifier of w1 (resp.\nw2 ) is the root of the sub-tree built by w1 (resp w2 ). The color of the cluster \u03c61 (resp \u03c62 ) is the\nidentifier of the root of the trees built by w1 (resp. w2 ). The PIF is propagated among the tree A.\nDuring the propagation phase, a node receiving a Division message checks in which subtree,\nw1 or w2 , it belongs to, and joins this cluster accordingly (algorithm 8, lines 2 to 8). Then the node\nexecutes the PIF algorithm (algorithm 8, lines 9 to 14). When the root of w1 (resp. w2 ) receives\nthe last F eedbackDiv message it is waiting for, the node creates a new token initialized with the\nword w1 (resp. w2 ) (algorithm 9).\nThe division mechanism is based on a PIF rather than a diffusion, because when a division is\nlaunched, the token of the cluster disappears. The new tokens are only created during the feedback,\nso that when they are created, they correspond to the existing clusters.\n\n11\n\n\fAlgorithm 8 On the reception of Division(A, w1 , w2 )\n1: if i \u2208 w1 then\n2:\nwi \u2190\u2212 w1\n3:\ncoli \u2190\u2212 w1 [1]\n4: else\n5:\nwi \u2190\u2212 w2\n6:\ncoli \u2190\u2212 w2 [1]\n7: end if\n8: if |M y_Sons(A)| > 0 then\n9:\n\u2200j \u2208 M y_Sons(A) : Send Division(A, w1 , w2 ) to j\n10:\nnbF eedbackDivi \u2190\u2212 0\n11: else\n12:\nSend F eedbackDiv(A, w1 , w2 ) to M y_F ather(A)\n13: end if\n\nAlgorithm 9 On the reception of F eedbackDiv(A, w1 , w2 )\n1: nbF eedbackDivi + +\n\n// if i receives the last feedback it was waiting for\n2: if (i \u2208 w1 \u2227 nbF eedbackDivi = |M y_Sons(w1 )|) \u2228 (i \u2208 w2 \u2227 nbF eedbackDivi = |M y_Sons(w2 )|) then\n3:\nif i = w1 [1] then\n4:\n// if i is the root of the first tree\n5:\nRandom choice of j \u2208 Ni , send T oken(i, w1 ) to j\n6:\nelse if i = w2 [1] then\n7:\n// if i is the root of the second tree\n8:\nRandom choice of j \u2208 Ni , send T oken(i, w2 ) to j\n9:\nelse\n10:\nsend F eedbackDiv(A, w1 , w2 ) to M y_F ather(A)\n11:\nend if\n12: end if\n\n4\n\nProof of correctness\n\nIn this section, we prove that starting from an initial configuration, the clustering eventually meets\nthe problem specification (see subsection 2.5).\n\n4.1\n\nPreliminaries\n\nAssuming G = (V, E) is the communication graph and c a color, we have the following definitions.\nDefinition 6 (Graph induced by a cluster) Let Vc be a cluster. We note Gc the graph induced\nby all the nodes in Vc .\nGc = (Vc , Ec ) with: Ec = E \u2229 (Vc \u00d7 Vc )\nDefinition 7 (Cluster neighbors) Let Vc be a cluster. The neighborhood of Vc , noted N (Vc ), is:\nN (Vc ) = {i \u2208 V, \u2203j \u2208 Vc , j \u2208 Ni } \u222a Vc\n12\n\n\fNote that Vc \u2282 N (Vc ).\nDefinition 8 A configuration \u03b3 is called legitimate iff:\n\u2022 each node belongs to exactly one cluster;\n\u2022 each cluster is connected;\n\u2022 each cluster has a size greater than m;\n\u2022 no cluster is divisible;\n\u2022 there is exactly one token of color c in N (Vc );\n\u2022 there are only T oken messages circulating in the network.\nProperty 2 A legitimate configuration respects the specification of the problem:\n1. all nodes belong to a cluster;\n2. all clusters are connected;\n3. each cluster has a size greater than m;\n4. no cluster is divisible.\nDefinition 9 A configuration is called initial iff:\n\u2022 each node is free;\n\u2022 there is no message circulating in the network.\n\n4.2\n\nCorrectness proofs\n\nWe show in this section that from the initial configuration the system reaches a legitimate configuration.\nAt the initialization, there is no message in the network. Then the only rule a node can execute\nis the algorithm 4. Only free nodes can execute this rule, and its execution makes the node create\na token with probability 21 . Thus a node i will eventually execute this rule and will then create a\ntoken T = T oken(i, < i >).\nAt this point a cluster Vi is created, and node i takes the color i. T begins to circulate in the\nnetwork. We say that Vi is in its growing phase. Each time T is received by a node, this node (i)\nenters in the cluster writing i in its col variable, adds its id at the beginning of the word wT and\nmakes T circulate, or (ii) sends back T to the sender, or (iii) makes the cluster change its phase,\ngoing from phase growing to the phase division (T disappears and the node sends back a division\nmessage) or dissolution (T disappears and the node sends back a division message). Thus, during\nthe growing phase, the cluster Vi is connected, there is only one token of color i in the network and\nwT is a spanning tree of Vi .\nLemma 1 Except when being dissolved or divided, clusters are connected.\n\n13\n\n\fProof Consider a cluster Vc . Vc evolves by being created, recruiting new nodes, being dissolved,\nor being split.\nWhen created, Vc = {c} (no other node can have color c, since this would mean that c had\nalready created a token, in which case it can only get free again after the dissolution of the cluster).\nVc is connected.\nA new node is recruited to Vc when it receives a token with color c, sent by a node that is already\nin Vc : indeed, a token with color c can only be sent by a node that is already in Vc (algorithm 4\nline 6, algorithm 5 lines 16 and 19, algorithm 9 lines 5 and 8), or by a node neighboring Vc that\nsends the token back to its sender (already in Vc ). Thus, there is a link between a newly recruited\nnode and a node that is already in Vc : if Vc is connected, it remains so.\nWhen Vc is dissolved, a PIF is launched on one of its spanning trees, at the end of which all\nnodes have left Vc : Vc is then the empty graph, which is connected.\nWhen Vc is divided, it is divided only when divisible, ie when it can be divided into two\nconnected clusters of size greater than m. Then all nodes leave Vc and join their new clusters, that\nare connected (one of which may still have color c).\n\u0003\nLemma 2 At least one cluster is created whp.\nProof If there is no cluster in the network, on a free node awakening, a token is created infinitely\noften with probability 1/2: eventually, whp, a token is created. Then this token starts building a\ncluster (cf. Algorithm 4).\n\u0003\nLemma 3 Eventually, a token of color c exists if and only if Vc 6= \u2205. In this case, this token is\nunique and is in N (Vc ).\nProof The only token creation is on a free node executing algorithm 4. The color of this token\nis the id of the free node that creates it. Since, after creating a token, a node has a color, it can\nno longer be free. The only cases when a node becomes free again are in algorithms 6 and 7 (in\nalgorithm 8, lines 3 and 6, w1 [1] and w2 [1] cannot be null, since the words computed by procedure\nDivision are non-empty). To execute algorithms 6 and 7, a node has to have received a message\nDissolution or a message F eedbackDiss respectively. A Dissolution message can only be sent\nby its father if it has itself received this message (algorithm 6) or by a node in a stable cluster or\nwith a higher color, in which case the token of its color has been removed (algorithm 5). Messages\nF eedbackDiss can only be received from a son to which the node has already sent a Dissolution\nmessage. Anyway, the dissolution procedure is always triggered on a cluster of color i after a token\nof color i has been removed, and it is the only phase when a node can become free. Thus, after a\nnode i has created a T oken with color i, it can create a new T oken only if the previous one has\nbeen removed. Since it is the only node that can create a token with color i, there is at most one\ntoken with color i at a time in the network.\nThus, if a token of color c exists, the node of id c is in Vc . And if Vc 6= \u2205, then Vc contains c\nand there is a token of color c.\nIf a node outside Vc receives a T oken with color c, it either joins Vc (if it is free; algorithm 5,\nline 9), or triggers the removal of this token and the dissolution of Vc (algorithm 5, line 25), or\nsends it back to its sender (algorithm 5, line 27). Since the token starts in Vc (algorithm 4), the\ntoken can only be in Vc , or on a neighboring node.\n14\n\n\f\u0003\nLemma 4 Eventually, one cluster (at least) is stable whp.\nProof In a given execution of this algorithm, there is a finite number of clusters colors used (at\nmost, as many colors as nodes in the system, since the color of a cluster is the ID of the node that\ninitiated it).\nConsider c the highest color appearing in an execution. Suppose, for the sake of contradiction,\nthat no cluster ever becomes stable.\nSuppose that, in the execution, a cluster with color c is dissolved: then, the dissolution process\ncan only have been initiated by a clustered node neighboring Vc , on the reception of the token with\ncolor i (algorithm 5, line 25). It launches the dissolution only if it is in a cluster with a higher color\nthan c, which is discarded by the definition of c, or if it is in a stable cluster (line 23). Thus, a\ncluster of color c cannot be dissolved.\nNow, suppose that no cluster with color c is dissolved. Then, the token with color c is never\nremoved (see proof of the previous lemma). Thus, the token follows an infinite path. Each time\nthe token hits a free node, this node is added to the cluster: |Vc | is incremented, and the node is\nno longer free, and will remain in Vc until a division occurs (by assumption, Vc is not dissolved in\nthe considered execution), which is possible only if the cluster is stable. Now, whp, any unstable\nneighboring cluster is dissolved, when its token reaches a node in Vc , for example (which will occur\nwhp according to the hitting property of random walks). At this moment, there are free nodes in\nN (Vc ). The token with color c following a random walk on nodes that are either free or in Vc , it will\nreach such a node whp and recruit it to Vc . Since the moves of the different tokens are independent,\nwhp, the token will be able to recruit a new node. Once m nodes are recruited, Vc is stable, which\ncontradicts the assumption.\nThus, whp, at least one cluster is eventually stable.\n\u0003\nLemma 5 A node belonging to a stable cluster remains in a stable cluster.\nProof Consider a node i belonging to a stable cluster of color c. Since its color is not null, i\ncan only change its color in algorithm 5 line 9, algorithms 6 and 7, or algorithm 8, line 3 and 6.\nAlgorithms 6 and 7 correspond to a dissolution phase of Vc , which is impossible since Vc is stable.\nAlgorithm 5 line 9, and algorithm 8, are part of the division process, that divides a stable cluster\ninto two stable clusters (algorithm 5, line 5: the process is launched only when the tree is splittable\ninto two subtrees with sizes greater than m). Thus, the cluster to which i belongs after the division\nis still stable.\n\u0003\nLemma 6 A divisible cluster is eventually divided whp.\nProof Consider a divisible cluster Vc , and suppose it is never divided. Since it is stable, its size\ncan only increase. Suppose it has reached its maximal size. Then, its token browses N (Vc ), and if\nwe put apart the steps when the token goes out of Vc and is sent back, it follows a random walk\non Vc . The spanning tree of Vc is computed according to the last minimal terminal covering path\nof the token: according to [Ald90], it contains a random spanning tree of Vc . Thus, any spanning\ntree of Vc is computed whp. Now, at least one spanning tree is divisible (property 1).\n15\n\n\fThus, whp, the tree computed from the circulating word is eventually divisible, and the cluster\nis divided according to algorithm 5 line 7 to 11.\n\u0003\nLemma 7 The number of nodes in stable clusters grows to n whp.\nProof According to lemma 4, eventually and whp, there exists a stable cluster. Suppose that some\nnodes never belong to a stable cluster, and consider a node i that never belongs to a stable cluster,\nand neighboring a node j in a stable cluster. Such a node exists since the network is connected.\nj remains in a stable cluster according to lemma 5. At some point, and by the assumption above,\nthe algorithm stops recruiting new nodes to stable clusters. Then, at some point, stable clusters do\nnot evolve any longer:\n\u2022 they cannot recruit new nodes;\n\u2022 they cannot be dissolved since they are stable;\n\u2022 they can no longer be split since they do not grow any more (once all splittable clusters are\nsplit, which eventually happens - see demonstration of the previous lemma - they can no\nlonger be split).\nNote Vc the cluster of j.\nThere is a random walk browsing N (Vc ), and, whp, it will hit i infinitely often. Since i is not in\na stable cluster, whp it is infinitely often free (indeed, if it is in a cluster, the token in this cluster\nmust hit Vc infinitely often, and the cluster is dissolved infinitely often, which makes i free). Thus,\nwhp i is eventually hit by the token of Vc while being free (by independency of the moves of the\ndifferent tokens), and is then recruited to the stable cluster Vc , which contradicts the assumption.\nThus, all nodes eventually belong to a stable cluster.\n\u0003\nLemma 8 All clusters eventually have a size greater than m, and are not divisible whp.\nProof Once all node are in stable clusters, all clusters have a size greater than m by definition.\nThen, according to lemma 6, all divisible clusters are divided whp: eventually none of them is\ndivisible.\n\u0003\nTheorem 1 The algorithm converges to a legitimate state whp.\nProof This comes from lemmas 1, 7 and 8.\n\u0003\nCorollary 1 Consider an integer M \u2265 2m. If G is such that all its connected subgraphs of size\ngreater than M can be partitioned into two connected subgraphs of size greater than m, then the\nalgorithm converges whp to a clustering such that all clusters have a size between m and M \u2212 1.\nProof Indeed, in such a graph, all clusters of size greater than M are divisible.\n\u0003\nFor example, on complete graphs or on rings, the algorithm leads to a clustering with clusters\nof sizes between m and 2m \u2212 1.\n16\n\n\f5\n\nAdaptive algorithm\n\nThis algorithm can be made adaptive to mobility. In this section, we call correct configuration\nany configuration that could have arisen from the execution of the algorithm on a static network\ncorresponding to the current state of the network. More precisely:\nDefinition 10 A configuration is called correct if:\n\u2022 each cluster is connected;\n\u2022 there is exactly one token of color c in N (Vc );\n\u2022 if node i's color is c 6= null, i is in the word of the token of color c, and only in this word; if\ni is free, then it does not occur in any circulating word;\n\u2022 if i is the son of j in the tree of some token, then there is a link (i, j) \u2208 E;\n\u2022 no message Delete circulates.\nA correct configuration is not always legitimate, but, without any further topological modifications, the previous section proves that from any correct configuration, the system eventually reaches\na legitimate configuration.\nMobility can manifest in the following ways:\n\u2022 link connection: the configuration remains correct, and nothing has to be done;\n\u2022 node connection: since the node that connects is initially free, it does not appear in any\ncirculating word and the configuration remains correct;\n\u2022 node disconnection: this case is dealt like the disconnection of all adjacent links;\n\u2022 link (i, j) disconnection:\n\u2013 if this link is between two clusters (coli 6= colj , coli 6= null, colj 6= null): the link (i, j)\ncan appear neither on wTcoli nor on on wTcolj ; we use an acknowledgement message to\ndetect the case when a token goes (for instance) from i to j, and a disconnection occurs\nbefore it is sent back to i, leading to no token remaining in the cluster of i; in this case,\nj deletes the token, and i creates a token with the same content as the one of the deleted\ntoken;\n\u2013 if one of this link extremities (or both) is a free node (coli = null \u2228 colj = null): since j\nis free, the link (i, j) could not appear on any circulating word: the configuration is still\ncorrect;\n\u2013 if this link is between two nodes in the same cluster (coli = colj 6= null):\n\u2217 if they are not linked by any father-son relationship: the link (i, j) does not appear\nin the token of the cluster of color coli , and the configuration remains correct;\n\u2217 if i is the father of j: the connectivity of the tree contained in the token of color\ncoli is broken; the configuration is no longer correct, and the different mechanisms\nwe have setup so far cannot work correctly: this is the reason why we introduce the\nmechanisms presented in this section, to deal with this case.\n\n17\n\n\fIf j is its father, i deletes the subtree rooted in itself: in other words, it propagates a wave on\nthis subtree, that makes all its descendants free. Once i has set itself and all its descendant free,\nthe token is no longer correct. When it visits j for the next time, j corrects it by removing the\nsubtree rooted in any son it is supposed to have, but to which it is actually not connected. Thus,\nthe system reaches a correct configuration.\nTo implement this, i must always know which node is its father in the token with the same color\nas it. If j is the father of i in this tree, it means that the last time i owned the token, it transferred\nit to j. Thus, i can remember which node is its father.\nThe algorithms below describe this mobility-adaptive distributed algorithm. The disconnection\nof a node is dealt as the disconnection of all its adjacent links.\nThe initialization phase is left unmodified, except for the initialization of the variable f ather.\nAlgorithm 10 On initialization\n1:\n2:\n3:\n4:\n5:\n6:\n\ncoli \u2190\u2212 null\nwi \u2190\u2212 \u03b5\nnbF eedbackDivi \u2190\u2212 0\nnbF eedbackDssi \u2190\u2212 0\nf atheri \u2190\u2212 null\nversion \u2190\u2212 0\n\nAlgorithm 11 On node i awakening\n1: if coli = null then\n2:\nToss a coin\n3:\nif tail then\n4:\ncoli \u2190\u2212 (i, version + +)\n5:\nwi \u2190\u2212 <i>\n6:\nRandom choice of j \u2208 Ni , Send T oken(coli , wi ) to j\n7:\nf atheri \u2190\u2212 j\n8:\nend if\n9: end if\n\nWhen receiving a token, a node first checks whether it is correct regarding its own neighborhood.\nIf it detects an inconsistency between the tree borne by the token and its neighborhood, it modifies\nthe tree so that it is in accordance with the (new) topology of the system.\n\n18\n\n\fAlgorithm 12 On reception of T oken(colT , wT )\n1:\n2:\n3:\n4:\n5:\n6:\n7:\n8:\n\nA \u2190\u2212 Build_T ree(wT )\nif A contains an edge (j, i) \u2227 j \u2208\n/ N (i) then\n// If i is supposed to be j's father, but is not actually connected to it\nremove the subtree of A rooted in j\nwT \u2190\u2212 T ree_T o_W ord(A)\nend if\nif (coli = null \u2228 coli = colT ) then\n//\u2013\u2013\u2013 Case 1:\n\n(i is free) or (i is red and receives a red token)\n\n9:\n10:\n\nwT \u2190\u2212 Add_Begin(i, wT )\nwT \u2190\u2212 Clean_W ord(wT )\n\n11:\n\nif Is_Divisible(wT ) then\n\n12:\n13:\n14:\n15:\n16:\n17:\n\n// If the cluster is large enough, we launch a division\n(w1 , w2 ) \u2190\u2212 Divide(A)\n// w1 = <i, . . . > and w2 = <r2, . . . >\ncoli \u2190\u2212 i\nwi \u2190\u2212 w1\n\u2200j \u2208 M y_Sons(A) : Send Division(A, w1 , w2 ) to j\nelse\n\n18:\n19:\n20:\n21:\n22:\n23:\n\n// Otherwise i joins the cluster and forwards the token\ncoli \u2190\u2212 colT\nwi \u2190\u2212 wT\nRandom choice of j \u2208 Ni , Send T oken(colT , wT ) to j\nf atheri \u2190\u2212 j\nend if\n\n24: else if coli = \u22121 then\n25:\nSend T oken(colT , wT ) to wT [1]\n26:\n\n//\u2013\u2013\u2013 Case 2:\n\ni is blue and receives a red token\n\n27: else\n28:\n\n29:\n30:\n31:\n32:\n33:\n34:\n35:\n\n// If the red cluster is too small and under some asymmetric assumptions, i can\ndissolve it\n// Otherwise i sends back the token to its sender\nif N b_Identities(wT ) < m \u2227 (N b_Identities(wi ) \u2265 m \u2228 coli > colT ) then\nA \u2190\u2212 Build_T ree(wT )\nSend Dissolution(A) to wT [1]\nelse\nSend T oken(colT , wT ) to wT [1]\nend if\nend if\n\nWhen detecting that it can no longer communicate with its father, i initiates a wave on the\nsubtree rooted in it. Delete messages are sent to all its neighbors, but only those that consider i\nas their father take it into account. They set themselves free, and send Delete messages to their\nneighbors, until all of i's descendants are free. A node always knows its current father, so that the\nnodes that are set free are the current descendants of i. Thus, the set of nodes that are freed in\n\n19\n\n\fthis process is a subtree of the token's tree, and its complement is itself a subtree. If a freed node is\nvisited by the token, then it is recruited, and the tree is modified according to the node to which it\nsends the token. Thus, the set of nodes that are free, but appear in the token, is always a subtree\nof the token's tree, and its complement is always a subtree too. When the token visits i's father, it\nis corrected, and is consistent with the data present on the nodes.\nAlgorithm 13 On a disconnection of node j\n1: if j = f atheri then\n2:\ncoli \u2190\u2212 null\n3:\nf atheri \u2190\u2212 null\n4:\nsend Delete to all neighbors\n5: end if\n\nAlgorithm 14 On reception of Delete on node i from a node j\n1: if j = f atheri then\n2:\ncoli \u2190\u2212 null\n3:\nf atheri \u2190\u2212 null\n4:\nsend Delete to all neighbors\n5: end if\nIf a dissolution occurs on a cluster that has been subject to a disconnection, the Dissolution\nPIF is triggered on the subtree of all nodes that are in the token, and are reachable. The remaining\nof the cluster has already been set free, so that the cluster is eventually dissolved.\nAlgorithm 15 On the reception of Dissolution(A) from k\n1: if k = f atheri then\n2:\ncoli \u2190\u2212 \u22121\n3:\nwi \u2190\u2212 \u03b5\n4: end if\n5: if |M y_Sons(A)| > 0 then\n6:\n\u2200j \u2208 M y_Sons(A) \u2229 N (i) : Send Dissolution(A) to j\n7:\nnbF eedbackDissi \u2190\u2212 0\n8: else\n9:\nSend F eedbackDiss(A) to M y_F ather(A)\n10:\ncoli \u2190\u2212 null\n11:\nf atheri \u2190\u2212 null\n12: end if\n\n20\n\n\fAlgorithm 16 On the reception of F eedbackDiss(A)\n1: nbF eedbackDissi + +\n\n// if i receives the last feedback it was waiting for\n2: if nbF eedbackDissi = |M y_Sons(A) \u2229 N (i)| then\n3:\nsend F eedbackDiv(A) to M y_F ather(A)\n4:\ncoli \u2190\u2212 null\n5:\nf atheri \u2190\u2212 null\n6: end if\n\nIf a division along an edge (a, b) occurs in a cluster that has been subject to the disconnection\nof a link (i, j), three cases can occur:\n1. (i, j) is lower in the tree than (a, b);\n2. (i, j) = (a, b);\n3. (i, j) is higher than (a, b).\nIn all these cases, the division PIF is propagated through the subtree of all the nodes that are still\nconnected through this tree. In the first case, one of the two clusters is correct, and the other is not\n(its token \"believes\" that some node are in the cluster, while they are not). In the second case, only\none clusters exists, and it is correct. In the last case, only one cluster exists, and it is not correct\n(the token \"believes\" that some node are in the cluster, while they are not).\nAlgorithm 17 On the reception of Division(A, w1 , w2 ) from k\n1: if k = f atheri then\n2:\nif i \u2208 w1 then\n3:\nwi \u2190\u2212 w1\n4:\ncoli \u2190\u2212 w1 [1]\n5:\nelse\n6:\nwi \u2190\u2212 w2\n7:\ncoli \u2190\u2212 w2 [1]\n8:\nend if\n9:\nif |M y_Sons(A)| > 0 then\n10:\n\u2200j \u2208 M y_Sons(A) \u2229 N (i) : Send Division(A, w1 , w2 ) to j\n11:\nnbF eedbackDivi \u2190\u2212 0\n12:\nelse\n13:\nSend F eedbackDiv(A, w1 , w2 ) to M y_F ather(A)\n14:\nend if\n15: else\n16:\nif |M y_Sons(A)| > 0 then\n17:\n\u2200j \u2208 M y_Sons(A) \u2229 N (i) : Send Dissolution(A) to j\n18:\nnbF eedbackDissi \u2190\u2212 0\n19:\nelse\n20:\nSend F eedbackDiv(A, w1 , w2 ) to M y_F ather(A)\n21:\nend if\n22: end if\n\n21\n\n\fAlgorithm 18 On the reception of F eedbackDiv(A, w1 , w2 )\n1: nbF eedbackDivi + +\n\n// if i receives the last feedback it was waiting for\n2: if (i \u2208 w1 \u2227nbF eedbackDivi = |M y_Sons(w1 )\u2229N (i)|)\u2228(i \u2208 w2 \u2227nbF eedbackDivi = |M y_Sons(w2 )\u2229\n\nN (i)|) then\n3:\nif i = w1 [1] then\n4:\n// if i is the root of the first tree\n5:\nRandom choice of j \u2208 Ni , send T oken(i, w1 ) to j\n6:\nf atheri \u2190\u2212 j\n7:\nelse if i = w2 [1] then\n8:\n// if i is the root of the second tree\n9:\nRandom choice of j \u2208 Ni , send T oken(i, w2 ) to j\n10:\nf atheri \u2190\u2212 j\n11:\nelse\n12:\nsend F eedbackDiv(A, w1 , w2 ) to M y_F ather(A)\n13:\nend if\n14: end if\n\nFirst we prove that any node has information about its father in the tree borne by the token.\nLemma 9 If i does not own the token, (i, f atheri ) is an edge of the tree of a token of color coli .\nProof f atheri is the last node to which i has sent the token of color coli (algorithm 11, line 7;\nalgorithm 12, line 8 and 27; algorithm 18, lines 6 and 10; algorithm 12, line 38 is when i sends back\na token that is not of its color; algorithm 13 and 14 show that if i has no color anymore, it has no\nfather anymore either).\nThe father of i in the tree computed from a word w is the node j such that the first occurrence\nof i in w is preceded by j. Now, the first occurrence of i in w was written in w the last time the\ntoken visited i. Indeed, no reduction of w can delete the first occurrence of a node. Then, i sent\nthe token to a node, that added its id at the beginning of the token, ie just before i's id. This has\nnever been removed, since i's id would have been removed too in this case. Thus, the node to which\ni sent the token is j. The father of i in the tree of the token is f atheri .\n\u0003\nWe now focus on a link (i, j) disappearing, with f atheri = j, in a cluster of color c.\nLemma 10 When a link (i, j) disappears, with f atheri = j, eventually, all descendants of i are\neventually set free.\nProof When i detects that it is no longer connected to its father, it sends a Delete message to all\nits neighbors (algorithm 13). When a node receives a Delete message, if it comes from its father, it\nsets itself free, and forwards it to all its neighbors (algorithm 14). Thus, all descendants of i that\ncan be reached through the spanning tree are set free. Now, if a descendant of i cannot be reached\nthrough the spanning tree, a link in the subtree rooted in i has also disappeared. Thus, a Delete\nwave has triggered on a subtree of the spanning tree, lower than i, that has reached this node and\nset it free.\n\u0003\n22\n\n\fFigure 2: Descendants of i are set free\nThen, three case can happen:\n\u2022 a dissolution of the cluster occurs before the token of color c hits j;\n\u2022 a division of the cluster occurs before the token of color c hits j;\n\u2022 the token of color c reaches j before a dissolution or a division occurs.\nBasically, when the token of color c hits j, j corrects the token to make it in accordance with the\ndisconnection of (i, j). A dissolution also leads to a correct configuration, and a division transfers\nthe problem to the new cluster in which the disconnected subtree is included.\nNote that a version number in the token ensures that no two tokens (and thus, no two clusters)\ncan have the same color.\nLemma 11 If the token hits j, the token is corrected.\nProof On the token hitting j, j executes algorithm 12, lines 4 and 5, which corrects the token.\n\u0003\nLemma 12 The dissolution process on a tree A makes all nodes in A free, even in case of a\ndisconnection of a link (i, j) in A with f atheri = j, except for nodes that have been recruited to\nother clusters.\nProof When receiving a Dissolution message a node forwards it to all of its reachable sons, so\nthat all reachable nodes in A are hit. Then, it leaves the cluster and gets free.\nNodes that are not reachable have received Delete messages (see lemma above), and are free,\nunless they have been recruited by another cluster.\n\u0003\nLemma 13 After a division process on a tree A along an edge (a, b) with colors c and c0 , and with\nthe disconnection of (i, j), with f atheri = j, nodes that have been recruited to another cluster keep\ntheir colors; nodes that are in the same connected component as a take the color c; nodes that are\nin the same connected component as b take the color c0 ; nodes that are disconnected from both a\nand b (due to the loss of (i, j)) are free, unless they have been recruited to another cluster.\n23\n\n\fc\nc\n\nFigure 3: The dissolution wave when the token hits j\n\nc\n\nFigure 4: The dissolution wave\nProof The division wave is propagated along A minus the subtree rooted in i. All nodes in this\nsubtree have set themselves free.\nThree cases occur:\n\u2022 (i, j) is lower in A than (a, b): the subtree rooted in i is a subtree of the subtree rooted in b;\n\u2022 (i, j) = (a, b): then all nodes in the subtree obtained by removing the subtree rooted in b set\ntheir color to c; the others are either free or recruited by other clusters;\n\u2022 in other cases: all nodes in the subtree obtained by removing the subtree rooted in i set their\ncolor to c; the others are either free or recruited by other clusters.\nIn all of these three cases, at most one cluster is not correct after the division. Other nodes\nhave their expected colors, or are free.\n\u0003\n24\n\n\fc\n\nFigure 5: The division wave\nLemma 14 Eventually, a token of color c exists if and only if Vc 6= \u2205. In this case, this token is\nunique and is in N (Vc ).\nProof Suppose a token of color c exists, and is on a node i. Then i either has created it, or has\nreceived it from a node j. If it has created it, coli = c, and i \u2208 Vc . Thus, Vc 6= \u2205. If it has received\nit from j, and i is not of the color c, then it sends it back to j (algorithm 12, line 33) or it destroys\nboth the token and Vc (algorithm 12 line 31). If the link (i, j) disconnects before j has had the\ntime to send it back to i, then i deletes its cluster (since f atheri = j: algorithm 13 and lemma 10)\nand j deletes the token (algorithm 12, lines 25 and 33: j is unable to send back the token, and does\nnothing, so that the token disappears). Thus, i \u2208 VC , and j \u2208 N (i). In any case, if a token of color\nc exists, then Vc 6= \u2205, and the token is in N (Vc ).\nThe only token creation is on a free node executing algorithm 4. The color of this token is\nconstituted of the id of the free node that creates it, and of a unique version number. Thus, no two\ntokens can have the same color.\nNow, suppose Vc 6= \u2205. Let i \u2208 Vc . Since i is of color c, it has received a token of color c. Now,\nthe only time a token of color c disappears is when a dissolution or a division process is launched:\nin algorithm 12, each time a node receives a T oken message, it sends a T oken message or triggers\na division or a dissolution. When a division is launched, all sites in Vc change their color (lemma\n13), so that eventually Vc = \u2205. When a dissolution is triggered, all sites in Vc are set free (lemma\n12), and eventually Vc = \u2205.\n\u0003\nTheorem 2 From any configuration obtained from a correct configuration by adding and removing\nsome nodes and links, the algorithm converges to a correct configuration whp (and then, to a\nlegitimate configuration).\nProof The addition of a link or a node (that executes its initialization procedure) to a correct\nconfiguration leads to a correct configuration (see definition of a correct configuration).\nIf a node is removed, then we treat it as if all its adjacent links were removed.\n\n25\n\n\fSo, consider the disconnection of a link (i, j). If i and j have no father-son relation, nothing\nhappens (algorithm 13). Assume j is the father of i. Then i sets itself free and sends a Delete\nmessage to all its neighbors (algorithm 13). All nodes descending from i in A are free (lemma 10).\nThen one of the three following events happens first:\n\u2022 the token hits j;\n\u2022 the cluster is dissolved;\n\u2022 the cluster is divided.\nIf the token hits j, lemma 11 shows that the cluster and its token are corrected. If the cluster is\ndissolved, then all nodes are free (lemma 12) , and this is correct. If the cluster is divided, the new\ncluster that inherited the edge (i, j) is still incorrect, and the other cluster either does not exist,\nor is correct (lemma 13). In the latter case, the same applies. Then, by induction, either a token\nof j's color eventually visits j, or j's cluster is eventually dissolved whp. Thus, whp, the clusters\ncontaining j is correct.\nThe same applies to all clusters, and when all clusters are correct, then the configuration is\ncorrect.\n\u0003\nTheorem 3 Starting from a legitimate configuration, and adding a topological modification, the\nalgorithm converges to a correct configuration and the only clusters modified are at worst the cluster\nin which the modification took place, and the adjacent clusters.\nProof A stable non-divisible cluster can be modified by the algorithm only if a neighboring node\nis free (algorithm 12).\nThe starting configuration is a legitimate one, with the addition of a topological modification.\nIf this topological modification is the addition of a link, nothing happens. If this is the addition\nof a node, then, this node will be recruited by a cluster (being surrounded by stable clusters, if it\ncreates its own cluster, at the first step, its token reaches a stable cluster and its cluster is dissolved),\nand, at worst it will trigger a division. Other clusters are stable and non-divisible, and have no\nneighboring free node : they are not modified.\nNow, consider a link disconnection. If this link was between two nodes without father-son\nrelationship, then nothing happens. Thus, let consider the case when a link (i, j) disappears, and i\nis the son of j in cluster Vc . Then, i sets all its descendant free (lemma 11). Neighboring clusters\nmay recruit them. Nodes in the cluster that are not descendant of i remain in the cluster. At some\npoint, the token reaches j and is corrected. If the cluster is still stable, then it goes on. Otherwise,\nits node may be set free by its dissolution. Only nodes in Vc may be set free. Indeed, all other\nnodes are in stable clusters, and remain in stable cluster according to lemma 5. Since only nodes\nin Vc may be set free, and all other clusters are stable and non-divisible, only clusters that have a\nneighbor in Vc can be modified.\n\u0003\n\n26\n\n\f6\n\nConclusion\n\nThe algorithm presented in this paper computes a distributed clustering on arbitrary topologies in\na totally decentralized way, and tolerates mobility. Most of the distributed clustering algorithms so\nfar are based on the election of a leader, called a \"clusterhead\". Most of them suffer from the fact\nthat a single link or node disconnection can entail a complete change of the clustering. Moreover,\nmost of them specify the clustering problem as finding disjoint clusters that are star subgraphs.\nThe specification we use is more advanced: we build clusters with a size higher than a parameter m,\nand are locally optimal, in the sense that no cluster can be divided into two clusters greater than m\n(no global optimum can be computed for such a problem without a global view of the system, which\nwould be in opposition to the distributed nature of the algorithm). The way we handle mobility\nensures that the only clusters affected by a node or link disconnection are, in the worst case, the\nclusters in which it took place, and the clusters adjacent to it. The reconfiguration is, as far as\npossible, local. Indeed, the loss of the mth node in a cluster needs this cluster to be deleted (to fit\nthe |V | \u2265 m constraint), and adjacent clusters to recruit the newly orphan nodes.\nThus, this algorithm provides a locally optimal clustering, and, in terms of affected nodes, an\noptimal reconfiguration. We now aim at better studying the complexity of this algorithm, both\non the theoretical level (although we already know that the size of the network has only a weak\ninfluence on the time to obtain a global clustering, thanks to the concurrent construction of the\ndifferent clusters), and through simulations.\nWe are also interested in making this algorithm self-stabilizing, in order to take into account, for\ninstance, the possible message losses. Starting from any arbitrary configuration, the values of the\nnodes variables being arbitrary, and arbitrary messages being in transit, the system has to reach\na clustering meeting the specification. We already worked on a self-stabilizing random walk based\ntoken circulation ([BBF04]), so that we have clues on how to manage failures on the token. We still\nhave to use this block to compute a self-stabilizing distributed clustering.\n\nReferences\n[ABCP96] B. Awerbuch, B. Berger, L. Cowen, and D. Peleg. Fast distributed network decompositions and covers. Journal of Parallel and Distributed Computing, 39:105\u2013114, 1996.\n[AKL+ 79] R. Aleliunas, R. Karp, R. Lipton, L. Lovasz, and C. Rackoff. Random walks, universal\ntraversal sequences and the complexity of maze problems. In 20th Annual Symposium\non Foundations of Computer Science, pages 218\u2013223, 1979.\n[Ald90]\n\nDJ Aldous. The random walk construction for spanning trees and uniform labelled trees.\nSIAM J Discrete Math, (3):450,465, 1990.\n\n[Bas99]\n\nS. Basagni. Distributed clustering for ad hoc networks. In ISPAN '99, International\nSymposium on Parallel Architectures, Algorithms and Networks, pages 310\u2013315. IEEE\nComputer Society, 1999.\n\n[BBCD02] F. Belkouch, M. Bui, L. Chen, and A. K. Datta. Self-stabilizing deterministic network\ndecomposition. J. Parallel Distrib. Comput., 62(4):696\u2013714, 2002.\n[BBF04]\n\nT. Bernard, A. Bui, and O. Flauzac. Topological adaptability for the distributed token\ncirculation paradigm in faulty environment. In ISPA'04, Internationnal Symposium\n27\n\n\fon Parallel and Distributed Processing and Applications, volume 3358, pages 146\u2013155.\nSpringer Verlag, 2004.\n[BBFN10] T. Bernard, A. Bui, O. Flauzac, and F. Nolot. A multiple random walks based selfstabilizing k-exclusion algorithm in ad-hoc networks. International Journal of Parallel,\nEmergent and Distributed Systems, 25(2):135\u2013152, 2010.\n[BBFR06] T. Bernard, A. Bui, O. Flauzac, and C. Rabat. Decentralized Resources Management\nfor Grid. In RDDS'06, volume 4278 of LNCS, pages 1530\u20131539. Springer-Verlag, 2006.\n[BDPV07] Bui, Datta, Petit, and Villain. Snap-stabilization and PIF in tree networks. DISTCOMP:\nDistributed Computing, 20, 2007.\n[Ber06]\n\nT. Bernard. Marches al\u00e9atoires et mot circulant, adaptativit\u00e9 et tol\u00e9rance aux pannes\ndans les environnements distribu\u00e9s. Ph D Thesis, 2006.\n\n[DSW06] S. Dolev, E. Schiller, and J. L. Welch. Random walk for self-stabilizing group communication in ad hoc networks. IEEE Trans. Mob. Comput., 5(7):893\u2013905, 2006.\n[JN06]\n\nC. Johnen and L. H. Nguyen. Robust self-stabilizing clustering algorithm. In\nOPODIS'06, 10th International Conference On Principles of Distributed Systems, volume 4305, pages 410\u2013424. Springer, 2006.\n\n[Lov93]\n\nL. Lov\u00e1sz. Random walks on graphs : A Survey. In T. Szonyi ed., D. Miklos, and V. T.\nSos, editors, Combinatorics : Paul Erdos is Eighty, volume 2, pages 353\u2013398. Janos\nBolyai Mathematical Society, 1993.\n\n[Seg83]\n\nA. Segall. Distributed network protocols. IEEE Trans. Inf. Theory, 29:23\u201335, 1983.\n\n[Tel94]\n\nG. Tel. Introduction to Distributed Algorithms. Cambridge University Press, 1994.\n\n[TIMF05] H. Taniguchi, M. Inoue, T. Masuzawa, and H. Fujiwara. Clustering algorithms in ad\nhoc networks. Electronics and Communications in Japan, 88(1):127\u2013135, 2005.\n[TV08]\n\nF. Theoleyre and F. Valois. A self-organization structure for hybrid networks. Ad-Hoc\nNetworks, 6(3):393\u2013407, 2008.\n\n28\n\n\f"}