{"id": "http://arxiv.org/abs/cs/0703097v1", "guidislink": true, "updated": "2007-03-20T20:35:02Z", "updated_parsed": [2007, 3, 20, 20, 35, 2, 1, 79, 0], "published": "2007-03-20T20:35:02Z", "published_parsed": [2007, 3, 20, 20, 35, 2, 1, 79, 0], "title": "On Approximating Optimal Weighted Lobbying, and Frequency of Correctness\n  versus Average-Case Polynomial Time", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0703145%2Ccs%2F0703058%2Ccs%2F0703039%2Ccs%2F0703035%2Ccs%2F0703008%2Ccs%2F0703129%2Ccs%2F0703111%2Ccs%2F0703028%2Ccs%2F0703109%2Ccs%2F0703017%2Ccs%2F0703090%2Ccs%2F0703018%2Ccs%2F0703105%2Ccs%2F0703069%2Ccs%2F0703150%2Ccs%2F0703148%2Ccs%2F0703086%2Ccs%2F0703141%2Ccs%2F0703143%2Ccs%2F0703044%2Ccs%2F0703068%2Ccs%2F0703059%2Ccs%2F0703108%2Ccs%2F0703120%2Ccs%2F0703052%2Ccs%2F0703025%2Ccs%2F0703117%2Ccs%2F0703083%2Ccs%2F0703091%2Ccs%2F0703022%2Ccs%2F0703014%2Ccs%2F0703131%2Ccs%2F0703144%2Ccs%2F0703036%2Ccs%2F0703030%2Ccs%2F0703110%2Ccs%2F0703133%2Ccs%2F0703047%2Ccs%2F0703155%2Ccs%2F0703038%2Ccs%2F0703061%2Ccs%2F0703125%2Ccs%2F0703137%2Ccs%2F0703048%2Ccs%2F0703151%2Ccs%2F0703098%2Ccs%2F0703100%2Ccs%2F0703040%2Ccs%2F0703021%2Ccs%2F0703007%2Ccs%2F0703146%2Ccs%2F0703013%2Ccs%2F0703045%2Ccs%2F0703016%2Ccs%2F0703119%2Ccs%2F0703088%2Ccs%2F0703085%2Ccs%2F0703050%2Ccs%2F0703003%2Ccs%2F0703074%2Ccs%2F0703096%2Ccs%2F0703149%2Ccs%2F0703051%2Ccs%2F0703057%2Ccs%2F0703005%2Ccs%2F0703032%2Ccs%2F0703076%2Ccs%2F0703010%2Ccs%2F0703029%2Ccs%2F0703128%2Ccs%2F0703031%2Ccs%2F0703116%2Ccs%2F0703104%2Ccs%2F0703080%2Ccs%2F0703106%2Ccs%2F0703037%2Ccs%2F0703063%2Ccs%2F0703127%2Ccs%2F0703001%2Ccs%2F0703023%2Ccs%2F0703115%2Ccs%2F0703019%2Ccs%2F0703136%2Ccs%2F0703153%2Ccs%2F0703026%2Ccs%2F0703002%2Ccs%2F0703066%2Ccs%2F0703009%2Ccs%2F0703060%2Ccs%2F0703049%2Ccs%2F0703034%2Ccs%2F0703072%2Ccs%2F0703081%2Ccs%2F0703070%2Ccs%2F0703099%2Ccs%2F0703024%2Ccs%2F0703062%2Ccs%2F0703094%2Ccs%2F0703147%2Ccs%2F0703097%2Ccs%2F0703079&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "On Approximating Optimal Weighted Lobbying, and Frequency of Correctness\n  versus Average-Case Polynomial Time"}, "summary": "We investigate issues related to two hard problems related to voting, the\noptimal weighted lobbying problem and the winner problem for Dodgson elections.\nRegarding the former, Christian et al. [CFRS06] showed that optimal lobbying is\nintractable in the sense of parameterized complexity. We provide an efficient\ngreedy algorithm that achieves a logarithmic approximation ratio for this\nproblem and even for a more general variant--optimal weighted lobbying. We\nprove that essentially no better approximation ratio than ours can be proven\nfor this greedy algorithm.\n  The problem of determining Dodgson winners is known to be complete for\nparallel access to NP [HHR97]. Homan and Hemaspaandra [HH06] proposed an\nefficient greedy heuristic for finding Dodgson winners with a guaranteed\nfrequency of success, and their heuristic is a ``frequently self-knowingly\ncorrect algorithm.'' We prove that every distributional problem solvable in\npolynomial time on the average with respect to the uniform distribution has a\nfrequently self-knowingly correct polynomial-time algorithm. Furthermore, we\nstudy some features of probability weight of correctness with respect to\nProcaccia and Rosenschein's junta distributions [PR07].", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cs%2F0703145%2Ccs%2F0703058%2Ccs%2F0703039%2Ccs%2F0703035%2Ccs%2F0703008%2Ccs%2F0703129%2Ccs%2F0703111%2Ccs%2F0703028%2Ccs%2F0703109%2Ccs%2F0703017%2Ccs%2F0703090%2Ccs%2F0703018%2Ccs%2F0703105%2Ccs%2F0703069%2Ccs%2F0703150%2Ccs%2F0703148%2Ccs%2F0703086%2Ccs%2F0703141%2Ccs%2F0703143%2Ccs%2F0703044%2Ccs%2F0703068%2Ccs%2F0703059%2Ccs%2F0703108%2Ccs%2F0703120%2Ccs%2F0703052%2Ccs%2F0703025%2Ccs%2F0703117%2Ccs%2F0703083%2Ccs%2F0703091%2Ccs%2F0703022%2Ccs%2F0703014%2Ccs%2F0703131%2Ccs%2F0703144%2Ccs%2F0703036%2Ccs%2F0703030%2Ccs%2F0703110%2Ccs%2F0703133%2Ccs%2F0703047%2Ccs%2F0703155%2Ccs%2F0703038%2Ccs%2F0703061%2Ccs%2F0703125%2Ccs%2F0703137%2Ccs%2F0703048%2Ccs%2F0703151%2Ccs%2F0703098%2Ccs%2F0703100%2Ccs%2F0703040%2Ccs%2F0703021%2Ccs%2F0703007%2Ccs%2F0703146%2Ccs%2F0703013%2Ccs%2F0703045%2Ccs%2F0703016%2Ccs%2F0703119%2Ccs%2F0703088%2Ccs%2F0703085%2Ccs%2F0703050%2Ccs%2F0703003%2Ccs%2F0703074%2Ccs%2F0703096%2Ccs%2F0703149%2Ccs%2F0703051%2Ccs%2F0703057%2Ccs%2F0703005%2Ccs%2F0703032%2Ccs%2F0703076%2Ccs%2F0703010%2Ccs%2F0703029%2Ccs%2F0703128%2Ccs%2F0703031%2Ccs%2F0703116%2Ccs%2F0703104%2Ccs%2F0703080%2Ccs%2F0703106%2Ccs%2F0703037%2Ccs%2F0703063%2Ccs%2F0703127%2Ccs%2F0703001%2Ccs%2F0703023%2Ccs%2F0703115%2Ccs%2F0703019%2Ccs%2F0703136%2Ccs%2F0703153%2Ccs%2F0703026%2Ccs%2F0703002%2Ccs%2F0703066%2Ccs%2F0703009%2Ccs%2F0703060%2Ccs%2F0703049%2Ccs%2F0703034%2Ccs%2F0703072%2Ccs%2F0703081%2Ccs%2F0703070%2Ccs%2F0703099%2Ccs%2F0703024%2Ccs%2F0703062%2Ccs%2F0703094%2Ccs%2F0703147%2Ccs%2F0703097%2Ccs%2F0703079&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We investigate issues related to two hard problems related to voting, the\noptimal weighted lobbying problem and the winner problem for Dodgson elections.\nRegarding the former, Christian et al. [CFRS06] showed that optimal lobbying is\nintractable in the sense of parameterized complexity. We provide an efficient\ngreedy algorithm that achieves a logarithmic approximation ratio for this\nproblem and even for a more general variant--optimal weighted lobbying. We\nprove that essentially no better approximation ratio than ours can be proven\nfor this greedy algorithm.\n  The problem of determining Dodgson winners is known to be complete for\nparallel access to NP [HHR97]. Homan and Hemaspaandra [HH06] proposed an\nefficient greedy heuristic for finding Dodgson winners with a guaranteed\nfrequency of success, and their heuristic is a ``frequently self-knowingly\ncorrect algorithm.'' We prove that every distributional problem solvable in\npolynomial time on the average with respect to the uniform distribution has a\nfrequently self-knowingly correct polynomial-time algorithm. Furthermore, we\nstudy some features of probability weight of correctness with respect to\nProcaccia and Rosenschein's junta distributions [PR07]."}, "authors": ["Gabor Erdelyi", "Lane A. Hemaspaandra", "Joerg Rothe", "Holger Spakowski"], "author_detail": {"name": "Holger Spakowski"}, "author": "Holger Spakowski", "links": [{"href": "http://arxiv.org/abs/cs/0703097v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cs/0703097v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.GT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.MA", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.2.11; F.2.2; F.1.3", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cs/0703097v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cs/0703097v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "arXiv:cs/0703097v1 [cs.GT] 20 Mar 2007\n\nOn Approximating Optimal Weighted Lobbying,\nand Frequency of Correctness versus\nAverage-Case Polynomial Time\u2217\nG\u00e1bor Erd\u00e9lyi\u2020\n\nLane A. Hemaspaandra\u2021\n\nJ\u00f6rg Rothe\u2020\n\nHolger Spakowski\u2020\n\nMarch 18, 2007\n\nAbstract\nWe investigate issues related to two hard problems related to voting, the optimal\nweighted lobbying problem and the winner problem for Dodgson elections. Regarding\nthe former, Christian et al. [CFRS06] showed that optimal lobbying is intractable in\nthe sense of parameterized complexity. We provide an efficient greedy algorithm that\nachieves a logarithmic approximation ratio for this problem and even for a more general\nvariant-optimal weighted lobbying. We prove that essentially no better approximation\nratio than ours can be proven for this greedy algorithm.\nThe problem of determining Dodgson winners is known to be complete for parallel access to NP [HHR97]. Homan and Hemaspaandra [HH06] proposed an efficient\ngreedy heuristic for finding Dodgson winners with a guaranteed frequency of success,\nand their heuristic is a \"frequently self-knowingly correct algorithm.\" We prove that\nevery distributional problem solvable in polynomial time on the average with respect to\nthe uniform distribution has a frequently self-knowingly correct polynomial-time algorithm. Furthermore, we study some features of probability weight of correctness with\nrespect to Procaccia and Rosenschein's junta distributions [PR07].\nKey words: approximation, Dodgson elections, election systems, frequently selfknowingly correct algorithms, greedy algorithms, optimal lobbying, preference aggregation.\n\u2217\n\nSupported in part by DFG grants RO 1202/9-1 and RO 1202/9-3, NSF grant CCF-0426761, the Alexander von Humboldt Foundation's TransCoop program, and a Friedrich Wilhelm Bessel Research Award. Work\ndone in part while the second author was visiting Heinrich-Heine-Universit\u00e4t D\u00fcsseldorf. Some of the results of Section 3 of this paper were presented at the First International Workshop on Computational Social\nChoice, December 2006. This paper also appears as Univ. of Rochester Comp. Sci. Dept. Technical Report\nTR-2007-914.\n\u2020\nInstitut f\u00fcr Informatik, Heinrich-Heine-Universit\u00e4t D\u00fcsseldorf, 40225 D\u00fcsseldorf, Germany. URLs:\nccc.cs.uni-duesseldorf.de/{\u223c erdelyi,\u223c rothe,\u223c spakowski}.\n\u2021\nDepartment of Computer Science, University of Rochester, Rochester, NY 14627, USA. URL:\nwww.cs.rochester.edu/u/lane.\n\n1\n\n\f1\n\nIntroduction\n\nPreference aggregation and election systems have been studied for centuries in social\nchoice theory, political science, and economics, see, e.g., Black [Bla58] and McLean and\nUrken [MU95]. Recently, these topics have become the focus of attention in various areas of\ncomputer science as well, such as artificial intelligence (especially with regard to distributed\nAI in multiagent settings), systems (e.g., for spam filtering), and computational complexity.\nFaliszewski et al. [FHHR] provides a survey of some recent progress in complexity-related\naspects of elections.\nThis paper's topic is motivated by two hard problems that both are related to voting,\nthe optimal weighted lobbying problem and the winner problem for Dodgson elections.\nRegarding the former problem, Christian et al. [CFRS06] defined its unweighted variant as\nfollows: Given a 0-1 matrix that represents the No/Yes votes for multiple referenda in the\ncontext of direct democracy, a positive integer k, and a target vector (of the outcome of\nthe referenda) of an external actor (\"The Lobby\"), is it possible for The Lobby to reach\nits target by changing the votes of at most k voters? They proved the optimal lobbying\nproblem complete for the complexity class W[2], thus providing strong evidence that it\nis intractable even for small values of the parameter k. However, The Lobby might still\ntry to find an approximate solution efficiently. We propose an efficient greedy algorithm\nthat establishes the first approximation result for the weighted version of this problem in\nwhich each voter has a price for changing his or her 0-1 vector to The Lobby's specification.\nOur approximation result applies to Christian et al.'s original optimal lobbying problem\n(in which each voter has unit price), and also provides the first approximation result for\nthat problem. In particular, we achieve logarithmic approximation ratios for both these\nproblems.\nThe Dodgson winner problem was shown NP-hard by Bartholdi, Tovey, and\nTrick [BTT89]. Hemaspaandra, Hemaspaandra, and Rothe [HHR97] optimally improved\nthis result by showing that the Dodgson winner problem is complete for PNP\nk , the class of\nproblems solvable via parallel access to NP. Since these hardness results are in the worstcase complexity model, it is natural to wonder if one at least can find a heuristic algorithm\nsolving the problem efficiently for \"most of the inputs occurring in practice.\" Homan and\nHemaspaandra [HH06] proposed a heuristic, called Greedy-Winner, for finding Dodgson\nwinners. They proved that if the number of voters greatly exceeds the number of candidates (which in many real-world cases is a very plausible assumption), then their heuristic\nis a frequently self-knowingly correct algorithm, a notion they introduced to formally capture a strong notion of the property of \"guaranteed success frequency\" [HH06]. We study\nthis notion in relation with average-case complexity. We also investigate Procaccia and\nRosenschein's notion of deterministic heuristic polynomial time for their so-called junta\ndistributions, a notion they introduced in their study of the \"average-case complexity of\nmanipulating elections\" [PR07]. We show that under the junta definition, when stripped to\nits basic three properties, every NP-hard set is \u2264pm -reducible to a set in deterministic heuristic polynomial time. We also show a very broad class of sets (including many NP-complete\n\n2\n\n\fsets) to be in deterministic heuristic polynomial time. In an extended digression, we argue\nthat the \"average-case complexity\" results of [PR07] are in fact not average-case complexity\nresults, but rather are frequency of correctness-or, to be more precise, probability weight\nof correctness-results (as are also the results of Homan and Hemaspaandra).\nThis paper is organized as follows. In Section 2, we propose and analyze an efficient\ngreedy algorithm for approximating the optimal weighted lobbying problem. In Section 3,\nwe show that every problem solvable in average-case polynomial time with respect to the\nuniform distribution has a frequently self-knowingly correct polynomial-time algorithm,\nand we study Procaccia and Rosenschein's junta distributions. The appendix presents\nthe heuristic Greedy-Score on which Greedy-Winner is based and the notion of frequently\nself-knowingly correct algorithm [HH06] as well as some needed technical definitions from\naverage-case complexity theory [Lev86, Imp95, Gol97, Wan97].\n\n2\n2.1\n\nApproximating Optimal Weighted Lobbying\nOptimal Lobbying and its Weighted Version\n\nChristian et al. [CFRS06] introduced and studied the following problem. Suppose there\nare m voters who vote on n referenda, and there is an external actor, which is referred to\nas \"The Lobby\" and seeks to influence the outcome of these referenda by making voters\nchange their votes. It is assumed that The Lobby has complete information about the voters'\noriginal votes, and that The Lobby's budget allows for influencing the votes of a certain\nnumber, say k, of voters. Formally, the Optimal-Lobbying problem is defined as follows:\nGiven an m\u00d7n 0-1 matrix V (whose rows represent the voters, whose columns represent the\nreferenda, and whose 0-1 entries represent No/Yes votes), a positive integer k \u2264 m, and a\ntarget vector x \u2208 {0, 1}n , is there a choice of k rows in V such that by changing the entries\nof these rows the resulting matrix has the property that, for each j, 1 \u2264 j \u2264 n, the jth\ncolumn has a strict majority of ones (respectively, zeros) if and only if the jth entry of the\ntarget vector x of The Lobby is one (respectively, zero) [CFRS06]?\nChristian et al. [CFRS06] showed that Optimal-Lobbying (with respect to parameter k,\nthe number of voters influenced by The Lobby) is complete for the complexity class W[2];\nsee, e.g., Downey and Fellows [DF99] and Flum and Grohe [FG06] for background on the\ntheory of parameterized complexity and in particular for the definition of W[2].\nThis result is considered strong evidence that Optimal-Lobbying is intractable, even for\nsmall values of the parameter k. However, even though the optimal goal of The Lobby\ncannot be achieved efficiently, it might be approximable within some factor. That is, given\nan m\u00d7n 0-1 matrix V and a target vector x \u2208 {0, 1}n , The Lobby might try to reach its\ntarget by changing the votes of as few voters as possible.\nWe consider the more general problem Optimal-Weighted-Lobbying, where we assume\nthat influencing the 0-1 vector of each voter vi exacts some price, price(vi ) \u2208 Q, where\nQ denotes the set of nonnegative rational numbers. In this scenario, The Lobby seeks to\nminimize the amount of money spent to reach its goal. The problem Optimal-Lobbying\n\n3\n\n\f(redefined as an optimization problem rather than a parameterized problem) is the unitprices special case of Optimal-Weighted-Lobbying, i.e., where price(vi ) = 1 for each voter vi .\nIt follows that Optimal-Weighted-Lobbying (redefined as a parameterized rather than an\noptimization problem, where the parameter is The Lobby's budget of money to be spent)\ninherits the W[2]-hardness lower bound from its special case Optimal-Lobbying, and that the\nlogarithmic approximation algorithm we build for Optimal-Weighted-Lobbying will provide\nthe same approximation ratio for Optimal-Lobbying.\nIn the remainder of this section, we describe and analyze an efficient greedy algorithm\nfor approximating Optimal-Weighted-Lobbying.\n\n2.2\n\nA Greedy Algorithm for Optimal Weighted Lobbying\n\nLet a matrix V \u2208 {0, 1}m\u00d7n be given, where the columns r1 , r2 , . . . , rn of V represent the\nreferenda and the rows v1 , v2 , . . . , vm of V represent the voters. Without loss of generality,\nwe may assume that The Lobby's target vector is of the form x = 1n (and thus may be\ndropped from the problem instance), since if there is a zero in x at position j, we can simply\nflip this zero to one and also flip the corresponding zeros and ones in column rj .\nFor each column rj , define the deficit dj to be the minimum number of zeros that need\nto be P\nflipped to ones such that there are strictly more ones than zeros in this column. Let\nD0 = nj=1 dj be the sum of all initial deficits.\nFigure 1 gives the greedy algorithm, which proceeds by iteratively choosing a most \"costeffective\" row of V and flipping to ones all those zeros in this row that belong to columns\nwith a positive deficit, until the deficits in all columns have decreased to zero. We assume\nthat ties between rows with equally good cost-effectiveness are broken in any simple way,\ne.g., in favor of the tied vi with lowest i.\nLet R be the set of columns of V whose deficits have already vanished at the beginning\nof an iteration, i.e., all columns in R already have a strict majority of ones. Let vi\u2309Rc denote\nthe entries of vi restricted to those columns not in R, and let #0 (vi\u2309Rc ) denote the number\nof zeros in vi\u2309Rc . (For i such that #0 (vi\u2309Rc ) = 0, we consider price(vi )/#0 (vi\u2309Rc ) to be +\u221e.)\nDuring an iteration, the cost per flipped entry in row vi (for decreasing the deficits in new\ncolumns by flipping vi 's zeros to ones) is price(vi )/#0 (vi\u2309Rc ). We say a voter vi is more costeffective than a voter vj if vi 's cost per flipped entry is less than vj 's. When our algorithm\nchooses to alter a row vi , we will think of its price being distributed equally among the new\ncolumns with decreased deficit, and at that instant will permanently associate with every\nflipped entry, ek , in that row its portion of the cost, i.e., cost (ek ) = price(vi )/#0 (vi\u2309Rc ).\nClearly, the greedy algorithm in Figure 1 always stops, and its running time is polynomial, since the while\nPn loop requires only linear (in the input size) time and has to be executed\nat most D0 = j=1 dj \u2264 n * \u2308(m + 1)/2\u2309 times (note that at most \u2308(m + 1)/2\u2309 flips are\nneeded in each column to achieve victory for The Lobby's position).\nNow, enumerate the D0 entries of V that have been flipped in the order in which they\nwere flipped by the algorithm. Let e1 , , e2 , . . . , eD0 be the resulting enumeration. Let OPT\nbe the money that would be spent by The Lobby for an optimal choice of voters such that\nits target is reached.\n4\n\n\f1. Input: A matrix V \u2208 {0, 1}m\u00d7n .\n2. Initialize:\nCompute the deficits dj , 1 \u2264 j \u2264 n.\nP\nD \u2190 nj=1 dj .\n\n/\u2217 Initially, D = D0 . \u2217/\n\nX \u2190 \u2205.\n\n3. While D 6= 0 do\nLet R be the set of columns rj with dj = 0.\nFind a voter whose cost-effectiveness is greatest, say vi .\nLet \u03b3i = price(vi )/#0 (vi\u2309Rc ).\nChoose vi and flip all zeros in vi\u2309Rc to ones.\nFor each flipped entry e in vi , let cost (e) = \u03b3i .\n/\u2217 cost(e) will be used in our analysis. \u2217/\nX \u2190 X \u222a {i}.\ndj \u2190 dj \u2212 1, for each column rj for which a zero was flipped.\nP\nD \u2190 nj=1 dj .\n\n4. Output: X.\n\nFigure 1: Greedy algorithm for Optimal-Weighted-Lobbying\nLemma 2.1 For each k \u2208 {1, 2, . . . , D0 }, we have cost (ek ) \u2264 OPT/(D0 \u2212 k + 1).\nProof. Let I denote a voter set that realizes the optimal expenditure, OPT, for reducing\nthe deficit to zero. Now, our analysis will follow the structure of the while loop of the\nalgorithm. So consider the algorithm at some point where the current deficit, D, is strictly\ngreater than zero and we are starting a pass through the while loop. So the entry we will\nnext flip will be named eD0 \u2212D+1 .\nIf we were to at this point consider changing all the rows associated with I to all ones,\nthis certainly would reduce the deficit to zero in the current matrix, as it in fact would even\nreduce the deficit to zero in the original matrix, and any prior passes through the while loop\nnever flipped any entry in a way that went against the Lobby's goal (increased any deficit).\nNow, the first important thing to note is that there must be a collection A of exactly D\nzeros in the rows associated with I such that flipping just those zeros reduces the deficit in\nthe current matrix to zero. (This is clearly true due to the way deficits are computed and\nthe separateness of the columns and their deficits.)\n5\n\n\fSo by buying the rows of I at cost OPT we certainly can flip all the D entries composing\nA, i.e., we could image the cost as being distributed equally, and so we could view each such\nflipped entry as being purchased at cost OPT/D. However, the second important thing to\nnote is that this means there is some element i of I that contains at least one element of A\nsuch that for that element, at this moment, price(vi )/#0 (vi\u2309Rc ) is at most OPT/D.1 Since\nour algorithm chooses the most cost-effective row, it will choose a row with at least this\ncost-effectiveness.\nThus the first element of this iteration through the while loop, which will be eD0 \u2212D+1 ,\nis bought at cost at most OPT/D. So, for k = D0 \u2212 D + 1 the claim of this lemma is\nsatisfied, since D0 \u2212 (D0 \u2212 D + 1) + 1 = D.\nHowever, note that each additional entry that we flip during this same pass through\nthe while loop (e.g., some possibly empty prefix of eD0 \u2212D+2 , eD0 \u2212D+3 , etc.) will not only\nsatisfy the claim of this lemma, but also will do even better, as it is (reducing the deficit by\none and is) being bought at the cost of OPT/D, and the claim of the lemma was merely\nrequiring that these additional elements be bought for, respectively, the strictly higher costs\nOPT/(D \u2212 1), OPT/(D \u2212 2), etc.\nSo, for each pass through the while loop, each entry flipped meets or beats the cost\nbound stated in this lemma.\n\u2751\nTheorem 2.2 The greedy algorithm presented in Figure 1 approximates the problem\nOptimal-Weighted-Lobbying with approximation ratio at most\nD0\nX\n1\ni=1\n\n\u0012 \u0018\n\u0019\u0013\nm+1\n\u2264 1 + ln D0 \u2264 1 + ln n\n.\ni\n2\n\nProof. The total price of the set of voters X picked by the greedy algorithm is the sum\nof the costs of those entries flipped. That is,\nprice(X) =\n\nX\n\ni\u2208X\n\nprice(vi ) =\n\nD0\nX\n\ncost(ek ) \u2264\n\nk=1\n\nwhere the last inequality follows from Lemma 2.1.\n\n\u0012\n\n1\n1\n1 + + *** +\n2\nD0\n\n\u0013\n\n* OPT,\n\u2751\n\n1\nThe reason is as follows. Consider for the moment associating with each element of each row of I that\ncontains at least one element of A the portion of OPT indicated by the row's price divided by the number\nof elements of A in that row. Clearly, the average of those D element costs trivially must equal OPT/D,\nthe overall average cost. So since the weighted average equals OPT/D, then at least one of the values being\naveraged must be less than or equal to OPT/D-and let us suppose that value is associated with row i\u2032 \u2208 I.\nSince A is a set of D items that (starting from the current matrix) reduces the deficit by D, every element\nof A in row i\u2032 must reduce the deficit associated with its column by 1. And so every member of A in row\ni\u2032 must be a member of vi\u2032 \u2309Rc . So the value associated with each member of A in row i\u2032 , which we already\nargued is at most OPT/D, is greater than or equal to the value price(vi\u2032 )/#0 (vi\u2032 \u2309Rc ) that the algorithm\ncomputes for each element of A-and indeed each element of vi\u2032 \u2309Rc -in that row.\n\n6\n\n\fr1\n\nr2\n\nr3\n\n***\n\nrn\n\nprice(vi )\n\n..\n.\n\n0\n1\n1\n..\n.\n\n1\n0\n1\n..\n.\n\n1\n1\n0\n..\n.\n\n***\n***\n***\n..\n.\n\n1\n1\n1\n..\n.\n\n1\n1/2\n1/3\n..\n.\n\nvn\nvn+1\nvn+2\nvn+3\nvn+4\n..\n.\n\n1\n0\n1\n0\n0\n..\n.\n\n1\n0\n0\n1\n0\n..\n.\n\n1\n0\n0\n0\n1\n..\n.\n\n***\n***\n***\n***\n***\n..\n.\n\n0\n0\n0\n0\n0\n..\n.\n\n1/n\n1+\u01eb\n2\n2\n2\n..\n.\n\nv2n+1\n\n0\n\n0\n\n0\n\n***\n\n1\n\n2\n\nv1\nv2\nv3\n\nTable 1: A tight example for the greedy algorithm in Figure 1\nSince the input size is lower-bounded by m *n, Theorem 2.2 establishes a logarithmic approximation ratio for Optimal-Weighted-Lobbying (and also for Optimal-Lobbying). Note\nthat the proof of Theorem P\n2.2 establishes an approximation ratio bound that is (sometimes\n0\nnonstrictly) stronger than D\ni=1 1/i. In particular, if the number of zeros flipped in successive iterations of the algorithm's while loop are l1 , l2 , . . . , lp , where l1 + l2 + * * * + lp = D0 ,\nthen the proof gives a bound on the approximation ratio of\nlp\nl2\nl3\nl1\n+ *** +\n+\n+\nD0 D0 \u2212 l1 D0 \u2212 (l1 + l2 )\nD0 \u2212 (l1 + * * * + lp\u22121 )\n\n=\n\np\nX\nj=1\n\nD0 \u2212\n\nlj\nPj\u22121\n\nk=1 lk\n\n.\n\nP 0\nThis is strictly better than D\ni=1 1/i except in the case that each lj equals 1. And this\nexplains why, in the example we are about to give that P\nshows that the algorithm can at\n0\ntimes yield a result with ratio essentially no better than D\ni=1 1/i, each lj will equal 1.\nPD 0\nNow, we show that the i=1 1/i approximation ratio stated in Theorem 2.2 is essentially\nthe best possible that can be stated for the greedy algorithm of Figure 1. Consider the\nexample given in Table 1. The prices for changing the voters' 0-1 vectors are shown in the\nright-most column of Table 1: Set price(vi ) = 1/i for each i \u2208 {1, 2, . . . , n}, set price(vi ) = 2\nfor each i \u2208 {n + 2, n + 3, . . . , 2n + 1}, and set price(vn+1 ) = 1 + \u01eb, where \u01eb > 0 is a fixed\nconstant that can be set arbitrarily small. Note that, for each j, 1 \u2264 j \u2264 n, we have dj = 1,\nand hence D0 = n.\nWhen run on this input, our greedy algorithm sequentially flips, for i = n, n \u2212 1, . . . , 1,\nthe single zero-entry of voter vi to a one. Thus the total money spent is 1+1/2+* * * +1/n =\n1 + 1/2 + * * * + 1/D0 . On the other hand, the optimal choice consists of influencing just\nvoter vn+1 by flipping all of vn+1 's entries to ones, which costs only 1 + \u01eb.\n7\n\n\f3\n\nFrequency of Correctness versus Average-Case Polynomial\nTime\n\n3.1\n\nA Motivation: How to Find Dodgson Winners Frequently\n\nA Condorcet winner of an election is a candidate i such that for each candidate j 6= i, a\nstrict majority of the voters prefer i to j. Not all elections have a Condorcet winner, but\nwhen a Condorcet winner exists, he or she is unique. In 1876, Dodgson [Dod76] proposed\nan election system that is based on a combinatorial optimization problem: An election is\nwon by those candidates who are \"closest\" to being a Condorcet winner. More precisely,\ngiven a Dodgson election (C, V ),2 every candidate c in C is assigned a score, denoted by\nDodgsonScore(C, V, c), which gives the smallest number of sequential exchanges of adjacent\npreferences in the voters' preference orders needed to make c a Condorcet winner with\nrespect to the resulting preference orders. Whoever has the lowest Dodgson score wins.\nThe problem Dodgson-Winner is defined as follows: Given an election (C, V ) and a\ndesignated candidate c in C, is c a Dodgson winner in (C, V )? (The search version of this\ndecision problem can easily be stated.) As mentioned earlier, Hemaspaandra et al. [HHR97]\nhave shown that this problem is PNP\nk -complete.\nIt certainly is not desirable to have an election system whose winner problem is hard,\nas only systems that can be evaluated efficiently are actually used in practice. Fortunately, there are a number of positive results on Dodgson elections and related systems as\nwell. In particular, Bartholdi, Tovey, and Trick [BTT89] proved that for elections with a\nbounded number of candidates or voters Dodgson winners are asymptotically easy to determine. Fishburn [Fis77] proposed a \"homogeneous\" variant of Dodgson elections that Rothe,\nSpakowski, and Vogel [RSV03] proved to have a polynomial-time winner problem. McCabeDansted, Pritchard, and Slinko [MPS06] proposed a scheme (called Dodgson Quick) that\napproximates Dodgson's rule with an exponentially fast convergence. Homan and Hemaspaandra [HH06] proposed a greedy heuristic that finds Dodgson winners with a \"guaranteed\nhigh frequency of success.\" To capture a strengthened version of this property formally, they\nintroduced the notion of a \"frequently self-knowingly correct algorithm\" (see Appendix A\nfor the formal definition and for their heuristic Greedy-Score).\n\n3.2\n\nOn AvgP and Frequently Self-Knowingly Correct Algorithms\n\nOur main result in this section relates polynomial-time benign algorithm schemes (see Definition B.2 in Appendix B) to frequently self-knowingly correct algorithms (see Definition A.1\nin Appendix A). We show that every distributional problem that has a polynomial-time benign algorithm with respect to the uniform distribution scheme must also have a frequently\nself-knowingly correct polynomial-time algorithm. It follows that all uniformly distributed\nAvgP problems have a frequently self-knowingly correct polynomial-time algorithm.\n2\n\nAn election (C, V ) is given by a set C of candidates and a set V of voters, where each vote is specified\nby a preference order on all candidates and the underlying preference relation is strict (i.e., irreflexive and\nantisymmetric), transitive, and complete.\n\n8\n\n\fTheorem 3.1 Suppose that A(x, \u03b4) is a polynomial-time benign algorithm scheme for a\ndistributional problem f on \u03bc\u0302 (the standard uniform distribution, see Appendix B). Then\nthere is a frequently self-knowingly correct polynomial-time algorithm A\u2032 for f .\nProof.\n\nLet \u03b4(n) = 1/(n + 1)3 . Define algorithm A\u2032 as follows:\n\n1. On input x \u2208 \u03a3\u2217 , simulate A(x, \u03b4(|x|)).\n2. If A(x, \u03b4(|x|)) outputs ?, then output (anything, \"maybe\").\n3. If A(x, \u03b4(|x|)) outputs y \u2208 T , where y 6= ?, then output (y, \"definitely\").\nBy Definition B.2 (which is given in Appendix B), algorithm A\u2032 runs in polynomial time.\nIt remains to show that A\u2032 is frequently self-knowingly correct.\nFix an arbitrary n \u2208 N+ . Now, we must be careful regarding the fact that Impagliazzo's\ndefinition of benign algorithm schemes and its \"\u03b4\" guarantees are all with regard to drawing\nnot over inputs of a given length (which is what we wish to consider) but rather regarding\ndrawing from inputs up to and including a given length. Thus, there is some danger that\neven if a benign algorithm performs well when its length parameter is n (meaning related\nto strings of length up to and including n), that such a \"good\" error frequency might be\ndue not to goodness at length n but rather to goodness at lengths n \u2212 1, n \u2212 2, and so on.\nHowever, if one looks carefully at the relative weights of the different lengths this is at most\na quadratically weighted effect (that is, the distribution's probability weight at length n is\njust quadratically less than the weight summed over all lengths less than n), and so our\nchoice of \u03b4(n) = 1/(n + 1)3 is enough to overcome this.\nLet us now handle that rigorously. Recall that n is fixed and arbitrary. Let us set the\nconstant (for fixed n) \u03b4\u2032 to be 1/(n + 1)3 . So, clearly\nProb\u03bc\u0302\u2264n [A(x, \u03b4\u2032 ) = ?] =\nPn\u22121\n1/(i(i + 1))\n1/(n(n + 1))\nPi=1\nProb\u03bc\u0302\u2264n\u22121 [A(x, \u03b4\u2032 ) = ?] + Pn\nProb\u03bc\u0302n [A(x, \u03b4\u2032 ) = ?].\nn\ni=1 1/(i(i + 1))\ni=1 1/(i(i + 1))\n\nSince A is a benign algorithm scheme, Prob\u03bc\u0302\u2264n [A(x, \u03b4\u2032 ) = ?] \u2264 \u03b4\u2032 . So, combining this and\nthe above equality, and solving for Prob\u03bc\u0302n [A(x, \u03b4\u2032 ) = ?], we have\nProb\u03bc\u0302n [A(x, \u03b4\u2032 ) = ?] \u2264\nPn\n\ni=1 1/(i(i + 1))\n1/(n(n + 1))\n\n!\nPn\u22121\n1/(i(i\n+\n1))\nProb\u03bc\u0302\u2264n\u22121 [A(x, \u03b4\u2032 ) = ?] .\n\u03b4\u2032 \u2212 Pi=1\nn\n1/(i(i\n+\n1))\ni=1\n\nAnd so, clearly, Prob\u03bc\u0302n [A(x, \u03b4\u2032 ) = ?] \u2264 n(n + 1)\u03b4\u2032 = n(n + 1)/(n + 1)3 . So\nk{x \u2208 \u03a3n | A\u2032 (x) \u2208 T \u00d7 {\"maybe\"}}k\n= 0,\nn\u2192\u221e\nk\u03a3n k\nlim\n\n\u2751\n\nwhich completes the proof.\n\n9\n\n\fCorollary 3.2 Every distributional problem that under the standard uniform distribution\nis in AvgP has a frequently self-knowingly correct polynomial-time algorithm.\nProof. Impagliazzo proved that any distributional problem on input ensemble \u03bcn is in\nAvgP if and only if it has a polynomial-time benign algorithm scheme; see Proposition 2\nin [Imp95]. The claim now follows from Theorem 3.1.\n\u2751\nIt is easy to see that the converse implication of that in Corollary 3.2 is not true.\nProposition 3.3 There exist (distributional) problems with a frequently self-knowingly correct polynomial-time algorithm that are not in AvgP under the standard uniform distribution.\nProof. For instance, one can define a problem that consists only of strings in {0}\u2217 encoding the halting problem. This problem is clearly not in AvgP, yet it is frequently\nself-knowingly correct.\n\u2751\n\n3.3\n\nA Basic Junta Distribution for SAT (and a Digression on Whether\nHeuristic Polynomial-Time Algorithms Yield Good Average-Case\nComplexity)\n\nProcaccia and Rosenschein [PR07] introduced \"junta distributions\" in their study of NPhard manipulation problems for elections. The goal of a junta is to be such a hard distribution (that is, to focus so much weight on hard instances) that, loosely put, if a problem is\neasy relative to a junta then it will be easy relative to any reasonable distribution (such as\nthe uniform distribution). This is a goal, not (currently) a theorem; Procaccia and Rosenschein [PR07] do not formally establish this, but rather seek to give a junta definition that\nmight satisfy this. Their paper in effect encourages others to weigh in and study the suitability of the notion of a junta and the notion built on top of it, heuristic polynomial time.\nFurthermore, they repeatedly state that their theory is one of average-case complexity.\nRegarding the latter claim, we in Footnote 4 point out that it is inaccurate to describe\ntheir theory as one of average-case complexity. Their theory adds to the study of frequency\nof correctness the notion of probability weight of correctness. This is a very valuable direction, but we point out that it is neither explicitly about, nor does it seem to implicitly\nyield claims about, average-case complexity. Their paper states that work of Conitzer and\nSandholm [CS06] is also about average-case complexity but, similarly, we mention that that\nwork is not about average-case complexity; it is about (and carefully and correctly frames\nitself as being about) frequency of correctness. We do not mean this as a weakness: We\nfeel that frequency of (or probability weight of) correctness, most especially when as in\nthe work of Homan and Hemaspaandra [HH06] the algorithm is \"self-knowingly\" correct a\nguaranteed large portion of the time, is an interesting and important direction.\nRegarding Procaccia and Rosenschein's notion of juntas, they state three \"basic\" conditions for a junta, and then give two additional ones that are tailored specifically to the needs\n10\n\n\fof NP-hard voting manipulation problems. They state their hope that their scheme will extend more generally, using the three basic conditions and potentially additional conditions,\nto other mechanism problems. One might naturally wonder whether their junta/heuristic\npolynomial-time approach applies more generally to studying the probability weight of correctness for NP-hard problems, since their framework in effect (aside from the two \"additional\" junta conditions just about voting manipulation) is a general one relating problems\nto probability weight of correctness. We first carefully note that in asking this we are taking\ntheir notion beyond the realm for which it was explicitly designed, and so we do not claim\nto be refuting any claim of their paper. What we will do, however, is show that the three\nbasic conditions for a junta are sufficiently weak that one can construct a junta relative to\nwhich the standard NP-complete problem SAT-and a similar attack can be carried out on\na wide range of natural NP-complete problems-has a deterministic heuristic polynomialtime algorithm. So if one had faith in the analog of their approach, as applied to SAT, one\nwould have to believe that under essentially every natural distribution SAT is easy (in the\nsense that there is an algorithm with a high probability weight of correctness under that\ndistribution). Since the latter is not widely believed, we suggest that the right conclusion\nto draw from the main result of this section is simply that if one were to hope to effectively\nuse the notion of juntas and heuristic polynomial time on typical NP-complete sets, one\nwould almost certainly have to go beyond the basic three conditions and add additional\nconditions. Again, we stress that Procaccia and Rosenschein didn't focus on examples this\nfar afield, and even within the world of mechanisms implied that unspecified additional conditions beyond the core three might be needed when studying problems other than voting\nmanipulation problems. This section's contribution is to give a construction indicating that\nthe core three junta conditions, standing on their own, seem too weak.\nSince we will use the Procaccia\u2013Rosenschein junta notion in a more general setting than\nmerely manipulation problems, we to avoid any chance of confusion will use the term \"basic\njunta\" to denote that we have removed the word \"manipulation\" and that we are using\ntheir three \"basic\" properties, and not the two additional properties that are specific to\nvoting manipulation. Our definition of \"deterministic heuristic polynomial-time algorithm\"\nis identical to theirs, except we have replaced the word \"junta\" with \"basic junta\"-and so\nagain we are allowing their notion to be extended beyond just manipulation and mechanism\nproblems.\nDefinition 3.4 (see [PR07]) Let \u03bc = {\u03bcn }n\u2208N be a distribution over the possible instances of an NP-hard problem L. (In this model, each \u03bcn sums to 1 over all length n\ninstances.3 ) We say \u03bc is a basic junta distribution if and only if \u03bc has the following\nproperties:\n3\n\nWe say this because in the Procaccia\u2013Rosenschein work, they state that each \u03bcn is a distribution, all\ntheir work and notions are based on looking at a single length at a time, and in their example of building a\njunta they do nothing at all to address relative weights between different lengths (and so a global distribution,\ni.e., one over \u03a3\u2217 , is not being defined). In addition to these three reasons, if one were to try to interpret the\nnotion as saying that there is a (Levin-like) single distribution over all lengths, one would in their definition\nof junta have foundational problems when that single distribution put no weight on any strings of a given\nlength, as one would be faced with conditioning on a set of probability weight zero, which is not well-defined.\n\n11\n\n\f1. S\nHardness: The restriction of L to \u03bc is the problem whose possible instances are only\nn\u2208N {x | |x| = n and \u03bcn (x) > 0}. Deciding this restricted problem is still NP-hard.\n\n2. Balance: There exist constants c > 1 and N \u2208 N such that for all n \u2265 N and for all\ninstances x, |x| = n, we have 1/c \u2264 Prob\u03bcn [x \u2208 L] \u2264 1 \u2212 1/c.\n3. Dichotomy: There exists some polynomial p such that for all n and for all instances x, |x| = n, either \u03bcn (x) \u2265 2\u2212p(n) or \u03bcn (x) = 0.\nLet (L, \u03bc) be a distributional decision problem (see Definition B.1 in Appendix B). An\nalgorithm A is said to be a deterministic heuristic polynomial-time algorithm for (L, \u03bc) if\nA is a deterministic polynomial-time algorithm and there exist a polynomial q and N \u2208 N\nsuch that for each n \u2265 N ,\nProb\u03bcn [x 6\u2208 L \u21d0\u21d2 A accepts x] <\n\n1\n.\nq(n)\n\nWe in the footnote to this sentence digress to suggest that this should not be viewed as\nproviding an average-case complexity theory.4\nOn the other hand, Procaccia\u2013Rosenschein do use the phrase \"distributional problem,\" and we mention that\nin that notion, as it is typically used, the distribution is global; however, for the three reasons mentioned\nabove, the Procaccia\u2013Rosenschein work's use of it is most coherently interpreted as, when the words are\nused, the \"distribution\" being simply a collection of distributions, one per length. We mention in passing\nthat our main theorem of this section, Theorem 3.6, remains true-though one has to shift the values in its\nproof a bit-even under the alternate interpretation of one global distribution. On the other hand, results\nsuch as nonclosure under polynomial-time isomorphisms potentially might not hold under that alternate\nmodel.\n4\nProcaccia and Rosenschein [PR07] in the title and body of their paper repeatedly describe their theory\nas being an \"average-case complexity\" theory for manipulation. We note that this is inaccurate within\nany natural interpretation of the notion of \"average-case complexity.\" We mean this not merely because\ntheir theory lacks what certainly must be a part of any average-case complexity theory, namely, taking an\naverage of complexities. Indeed, their theory is actually an approach to adding probability weights to a\nfrequency of correctness approach. In brief, they look at probability weight (relative to some distribution)\nof correctness. However, they require correctness only for 1 \u2212 1/poly probability weight at each length.\nThis is quite a lot of probability weight, but we now note that that seems not anywhere near enough\nto ensure good average-case complexity. Let us consider taking a deterministic heuristic polynomial-time\nalgorithm for a problem and trying to build from it an algorithm for the problem (i.e., one that is correct\non all instances) that has good average-case running time. First, notice that one is dead from the start, as\ndeterministic heuristic polynomial-time algorithms, though very frequently correct, are not guaranteed to\nknow any easily recognized broad set of inputs on which they are guaranteed to be correct. But for the sake\nof argument, let us suppose that for our given deterministic heuristic polynomial-time algorithm we by good\nluck have that there is a deterministic polynomial-time set, having at each length probability weight under\nthe junta at least 1\u22121/poly , such that for each element of this set the deterministic heuristic polynomial-time\nalgorithm is correct. Of course, for the remaining 1/poly of the weight the algorithm might be correct or\nnot correct-no guarantees. Even with this strong extra assumption (which is basically tossing in a Homan\u2013\nHemaspaandra-like self-knowing correctness property, see [HH06]), the average-case time analysis doesn't\ncome out happily. Note that for the remaining 1/poly of the probability weight (and we are assuming that\nthis is not just an upper bound but that one might actually have about this much weight for these bad\ncases), one would have to potentially brute force those, and as Procaccia and Rosenschein focus on NP-hard\n\n12\n\n\fWe now explore their notion of deterministic heuristic polynomial time5 and their notion of junta, both however viewed for general NP problems and using the \"basic\" three\nconditions. We will note that the notion in such a setting is in some senses not restrictive\nenough and in other senses is too restrictive. Let us start with the former. We need a\ndefinition.\nDefinition 3.5 We will say that a set L is well-pierced (respectively, uniquely well-pierced)\nif there exist sets Pos \u2208 P and Neg \u2208 P such that Pos \u2286 L, Neg \u2286 L, and there is some\nN \u2208 N such that at each length n \u2265 N , each of Pos and Neg has at least one string at\nlength n (respectively, each of Pos and Neg has exactly one string at length n).\nEach uniquely well-pierced set is well-pierced. Note that, under quite natural encodings,\nsuch NP-complete sets as, for example, SAT certainly are well-pierced and uniquely wellproblems, each such brute-forcing would seem to potentially take exponential time. So, very loosely put,\nand under all the assumptions we are making (e.g., about\n\" having \"to use brute force and so on), the expected\ntime (over their own distribution) one gets is roughly\n\n1\u2212\n\n1\npoly\n\n* poly \u2032 +\n\nexponential\npoly\n\n. And, critically, that\n\nis exponential. (What we just argued is that, very informally, in the model of looking at junta-weighted\naverage time over the strings of each length and looking at the asymptotics of that, the obvious attempt\nto convert a deterministic heuristic polynomial-time algorithm into an algorithm (i.e., a correct program\nfor the problem) with good average-case running time yields an exponential average. However, it is true\nthat such asymptotics of averages over each length have in other settings some undesirably properties, see,\ne.g., [Gol97]. Nonetheless, the 1/poly weight of the exponential time here is so bad that going into an even\nmore Levin-like setting by tamping down on the runtimes by adding an \"\u01eb\" exponent still would not seem,\nif done naturally, to tame the exponential nature of the average time.)\nSo in summary Procaccia and Rosenschein do not build a theory of average-case complexity, but rather shift\nthe nature of \"frequency of correctness\" approaches to focus instead on \"probability weight of correctness\n(relative to some distribution)\"-which is a quite natural shift to look at. We mention in passing that the\npapers of Homan and Hemaspaandra [HH06] and of Conitzer and Sandholm [CS06] are about frequency of\ncorrectness-and are quite explicit that that, and not average-case complexity, is what they are about. This\nends our informal digression/discussion of frequency of correctness versus average-case complexity.\nHowever, as a quick postscript just for those interested, we discuss this issue, very informally, regarding\nHoman and Hemaspaandra [HH06]. The reason we do so is that that paper seems to ensure not just an at\nmost 1/poly weight of bad cases, but in fact an at most 1/exponential proportion (note: it is in a uniformlike model) of bad cases. And so one might hope that it might yield average-case polynomial asymptotics.\nHowever, this seems not to be the case. In more detail, yet speaking very informally: Note that if we\nchoose uniformly a random m-candidate, n-voter Dodgson election instance I and use the Greedy-Winner\nalgorithm on it and in the case of a \"maybe\" then brute-force it, the expected running time will be, where\nn\np\n\" is the polynomial nrun\" time of Greedy-Winner and cm nis our brute-force time for a brute-force solution,\n\u2212\n\u2212\n2\n2\n1 \u2212 2(m \u2212 m)e 8m2 *Egood(m,n) [p(|I|)]+2(m \u2212m)e 8m2 *Eunknown(m,n) [p(|I|)+cmn ], where E[*] denotes\nexpectation, good (m, n) denotes the set of m-candidate, n-voter election instances for which the algorithm\nis self-knowingly correct, and unknown(m, n) denotes the set of m-candidate, n-voter election instances for\nwhich the algorithm is not self-knowingly correct. Note that, assuming that the instances with given m and\nn are tightly clustered in the lengths they encode to (and such clustering will typically be the case if we don't\n(n ln m)\u2212 n 2\n\u2212 n\n8m ,\nallow flexible text-string names as part of the input), we have, basically since e 8m2 * mn = e\nthat the expected time is exponential (as n grows).\n5\n\nThey credit their notion as being \"inspired by Trevisan [Tre02] (there the same name is used for a\nsomewhat different definition).\" We mention in passing as an even earlier source for the same name, though\nalso attached to a different definition than that of Procaccia and Rosenschein, Section 3 of [Imp95].\n\n13\n\n\fpierced. (All this says is that, except for a finite number of exceptional lengths, there is\none special string at each length that can easily, uniformly be recognized as in the set and\none that can easily, uniformly be recognized as not in the set.) Indeed, under quite natural\nencodings, undecidable problems such as the halting problem are uniquely well-pierced.\nRecall that juntas are defined in relation to an infinite list of distributions, one per length\n(so \u03bc = {\u03bcn }n\u2208N ). The Procaccia and Rosenschein definition of junta does not explicitly put\ncomputability or uniformity requirements on such distributions in the definition of junta,\nbut it is useful to be able to make claims about that. So let us say that such a distribution is uniformly computable in polynomial time (respectively, is uniformly computable in\nexponential time) if there is a polynomial-time function (respectively, an exponential-time\nfunction) f such that for each i and each x, f (i, x) outputs the value of \u03bci (x) (say, as a\nrational number-if a distribution takes on other values, it simply will not be able to satisfy\nour notion of good uniform time).\nTheorem 3.6 Let A be any NP-hard set that is well-pierced. Then there exists a basic junta\ndistribution relative to which A has a deterministic heuristic polynomial-time algorithm\n(indeed, it even has a deterministic heuristic polynomial-time algorithm whose error weight\n2\nis bounded not merely by 1/poly as the definition requires, but is even bounded by 1/2n \u2212n ).\nFurthermore, the junta is uniformly computable in exponential time, and if we in addition\nassume that A is uniquely well-pierced, the junta is uniformly computable in polynomial\ntime.\nIt follows that, under quite natural encodings, almost any natural set is in deterministic\nheuristic polynomial time. For example, SAT is and the halting problem is, both under\nnatural encodings.6 All it takes is for the given set to have at all but a finite number of\nlengths at least one element each that are uniformly easily recognizable as being in and out\nof the set.\nProof. Let A be well-pierced. So there exists an N , and sets Pos and Neg, that satisfy\nthe definition of well-pierced. For each n \u2265 N , let Pos(n) denote the lexicographically\nsmallest length n string in Pos and let Neg(n) denote the lexicographically smallest length\nn string in Neg.\nDefine the distribution \u03bd = {\u03bdn }n\u2208N as follows:\n2\n\n1. For each length n \u2265 N , put weight\n1/2n\u0011 on all length n strings other than Pos(n)\n\u0010\nn\non each of Pos(n) and Neg(n).\nand Neg(n), and put weight 12 1 \u2212 2 n\u22122\n2\n2\n\n6\n\nAgain, a potential problem when dealing with such claims is details of encoding. For example, if SAT is\nencoded in such a way that the vast majority of the strings (namely all but at most a 1/poly portion of the\nstrings) of each length are obviously syntactically illegal (and such encodings can indeed be totally natural),\nthen an astute reader might well ask, \"Isn't any algorithm that accepts the empty set a deterministic\nheuristic polynomial-time algorithm for SAT, relative to the uniform distribution, which obviously is a basic\njunta.\" However, this reasoning is flawed. If that many strings of each length are obviously syntactically\nillegal and we are using the uniform distribution, then the balance condition for juntas is violated. So the\nbalance condition blocks that argument, and indeed this type of blocking is precisely why Procaccia and\nRosenschein [PR07] have the balance condition.\n\n14\n\n\f2. For each length n < N , let \u03bdn be the uniform distribution over that length, i.e., each\nlength n string has weight 1/2n .\nWe now show that \u03bd is a basic junta distribution.\nS\n1. Hardness: Since n\u2208N {x | |x| = n and \u03bdn (x) > 0} equals \u03a3\u2217 , the restriction of A to\n\u03bd equals A, and so is still NP-hard.\n2. Balance: Since for each length n \u2265 N both Pos(n) \u2208 A and Neg(n) 6\u2208 A\u0010have almost\n\u0011\nn\nhalf of the probability weight of all length n strings (namely, each has 21 1 \u2212 2 n\u22122\n),\n2 2\n\u03bd is balanced.\n2\n\n3. Dichotomy: Since for all n \u2265 N and for all x, |x| = n, we have \u03bdn (x) \u2265 2\u2212n , and for\nall n < N and for all x, |x| = n, we have \u03bdn (x) \u2265 2\u2212n , dichotomy is satisfied.\nNote that the junta is uniformly computable in exponential time, and if A is uniquely\nwell-pierced then the junta is uniformly computable in polynomial time.\nOur deterministic heuristic polynomial-time algorithm for (A, \u03bd) works as follows: On\ninputs that are a Pos(n), it accepts; on inputs that are a Neg(n), it rejects; and on every\nother input, it (for specificity, though it does not matter) accepts.\nFor each n \u2265 N , the error probability of this algorithm on inputs of length n is at most\n2\n2\n\u2751\n(2n \u2212 2)/2n \u2264 1/2n \u2212n .\n2\n\nIn the proof we achieve the error bound 1/2n \u2212n stated in Theorem 3.6. However, this\nk\nbound can easily be strengthened to 1/2n \u2212n , for each fixed constant k, by altering the\nproof. Note that the altered algorithm will depend on k.\nOur point is not that this construction is difficult. Rather, our point is that this construction indicates that the basic three junta conditions on their own can be short-circuited, and\nthus a stronger set of conditions would be needed to seek to create a Procaccia\u2013Rosenscheintype program against, e.g., SAT. More generally, one should probably be exceedingly skeptical about any distribution or distribution type that is being proposed-without proof-as\nperhaps being so hard that it seeks to \"convincingly represent all other distributions with\nrespect to average-case analysis\" [PR07, p. 163]. Again, we should stress that Procaccia and\nRosenschein are clear that this is a hope not a claim, that they repeatedly stress that the\napproach may be controversial, and that their focus is on manipulation/mechanism issues.\nLoosely put, the above result says that the basic junta conditions are in some ways\noverinclusive. We also note that the definition of junta, and the issue of when we will have\na heuristic polynomial-time algorithm, are exceedingly sensitive to details of encoding.7 We\n7\n\nIn contrast, the \"\u01eb\" exponent and |x| denominator (see Definition B.1 in Appendix B) in Levin's [Lev86]\ntheory of AvgP, average-case polynomial-time, were precisely designed, in that different setting, to avoid\nsuch problems-problems that one gets by following the type of asymptotic focus on one length at a time that\nthe Procaccia and Rosenschein model adopts. On the other hand, even Levin's theory has many subtleties\nand downsides, and to this day has not found anything resembling the type of widespread applicability of\nNP-completeness theory; see any of the many surveys on that topic.\n\n15\n\n\fmention quickly two such effects, one that indirectly suggests overinclusiveness and one that\nsuggests underinclusiveness.\nAs to the former, note that every NP-hard set is \u2264pm -reducible to a set that is in\ndeterministic heuristic polynomial time. This applies even to undecidable NP-hard sets,\nsuch as SAT \u2295 HP =def {0x | x \u2208 SAT} \u222a {1y | y \u2208 HP}, where HP denotes the halting\nproblem. The proof is nearly immediate. Given an NP-hard set A (over some alphabet\n\u03a3 that has cardinality at least two, and w.l.o.g. we assume that 0 and 1 are letters of \u03a3),\n2\nnote that A \u2264pm -reduces to the set A\u2032 = {00x | x \u2208 \u03a3\u2217 } \u222a {1x1|x| +2 | x \u2208 A}, and that A\u2032 is\neasily seen to be in deterministic heuristic polynomial time (indeed, with error bound not\njust 1/poly but even 1/exponential ), in particular via the junta (relative to A\u2032 ) that is the\nuniform distribution.\nRegarding underinclusiveness, note that under the definition of junta, no set that at\nan infinite number of lengths either has all strings or has no strings can have a deterministic heuristic polynomial-time algorithm, since for such sets the balance condition of the\nnotion of a junta can never be satisfied. It follows easily that the notion of having a deterministic heuristic polynomial-time algorithm is not even closed under polynomial-time\nisomorphisms.8\n\n4\n\nConclusions\n\nChristian et al. [CFRS06] introduced the optimal lobbying problem and showed it complete\nfor W[2], and so generally viewed as intractable in the sense of parameterized complexity. In\nSection 2, we proposed an efficient greedy algorithm for approximating the optimal solution\nof this problem, even if generalized by assigning prices to voters. This greedy algorithm\nachieves a logarithmic approximation ratio and we prove that that is essentially the best\napproximation ratio that can be proven for this algorithm. We mention as an interesting\nopen issue whether more elaborate algorithms can achieve better approximation ratios.\nSection 3 studied relationships between average-case polynomial time, benign algorithm\nschemes, and frequency (and probability weight) of correctness. We showed that all problems having benign algorithm schemes relative to the uniform distribution (and thus all\nsets in average-case polynomial time relative to the uniform distribution) have frequently\nself-knowingly correct algorithms. We also studied, when limited to the \"basic\" three junta\nconditions, the notion of junta distributions and of deterministic heuristic polynomial time,\nand we showed that they admit some extreme behaviors. We argued that deterministic\nheuristic polynomial time should not be viewed as a model of average-case complexity.\nAcknowledgments: We are deeply grateful to Chris Homan for his interest in this work\n2\n\n8\n\nTo be extremely concrete, the NP-complete set B = {00x | x \u2208 \u03a3\u2217 } \u222a {1x1|x| +2 | x \u2208 SAT} is (as\nper the above) easily seen to be in deterministic heuristic polynomial time, but the NP-complete set B \u2032 =\n{xx | x \u2208 SAT}, though it is by standard techniques polynomial-time isomorphic to B (see [BH77]), is not\nin deterministic heuristic polynomial time. If the reader wonders why we did not simply use two P sets, the\nreason is, under to the Procaccia\u2013Rosenschein definition, one needs NP-hardness to have a junta, and one\nneeds a junta to put something in deterministic heuristic polynomial time.\n\n16\n\n\fand for many inspiring discussions on computational issues related to voting. We also thank\nthe anonymous COMSOC 2006 workshop referees for their helpful comments.\n\nReferences\n[BH77]\n\nL. Berman and J. Hartmanis. On isomorphisms and density of NP and other\ncomplete sets. SIAM Journal on Computing, 6(2):305\u2013322, 1977.\n\n[Bla58]\n\nD. Black. The Theory of Committees and Elections. Cambridge University Press,\n1958.\n\n[BTT89]\n\nJ. Bartholdi III, C. Tovey, and M. Trick. Voting schemes for which it can be\ndifficult to tell who won the election. Social Choice and Welfare, 6(2):157\u2013165,\n1989.\n\n[CFRS06] R. Christian, M. Fellows, F. Rosamond, and A. Slinko. On complexity of lobbying in multiple referenda. In U. Endriss and J. Lang, editors, First International Workshop on Computational Social Choice (COMSOC 2006), pages 87\u201396\n(workshop notes). Universiteit van Amsterdam, December 2006.\n[CS06]\n\nV. Conitzer and T. Sandholm. Nonexistence of voting rules that are usually\nhard to manipulate. In Proceedings of the 21st National Conference on Artificial\nIntelligence. AAAI Press, July 2006.\n\n[DF99]\n\nR. Downey and M. Fellows. Parameterized Complexity. Springer-Verlag, Berlin,\nHeidelberg, New York, 1999.\n\n[Dod76]\n\nC. Dodgson. A method of taking votes on more than two issues. Pamphlet\nprinted by the Clarendon Press, Oxford, and headed \"not yet published\" (see\nthe discussions in [MU95, Bla58], both of which reprint this paper), 1876.\n\n[FG06]\n\nJ. Flum and M. Grohe. Parameterized Complexity Theory. EATCS Texts in\nTheoretical Computer Science. Springer-Verlag, Berlin, Heidelberg, 2006.\n\n[FHHR]\n\nP. Faliszewski, E. Hemaspaandra, L. Hemaspaandra, and J. Rothe. A richer understanding of the complexity of election systems. In S. Ravi and S. Shukla,\neditors, Fundamental Problems in Computing: Essays in Honor of Professor Daniel J. Rosenkrantz. Springer. To appear. Available as Technical Report cs.GT/0609112, ACM Computing Research Repository (CoRR), September\n2006.\n\n[Fis77]\n\nP. Fishburn. Condorcet social choice functions. SIAM Journal on Applied Mathematics, 33(3):469\u2013489, 1977.\n\n17\n\n\f[Gol97]\n\nO. Goldreich. Note on Levin's theory of average-case complexity. Technical Report TR97-058, Electronic Colloquium on Computational Complexity, November\n1997.\n\n[HH06]\n\nC. Homan and L. Hemaspaandra. Guarantees for the success frequency of\nan algorithm for finding Dodgson-election winners. In Proceedings of the 31st\nInternational Symposium on Mathematical Foundations of Computer Science,\npages 528\u2013539. Springer-Verlag Lecture Notes in Computer Science #4162, August/September 2006.\n\n[HHR97] E. Hemaspaandra, L. Hemaspaandra, and J. Rothe. Exact analysis of Dodgson\nelections: Lewis Carroll's 1876 voting system is complete for parallel access to\nNP. Journal of the ACM, 44(6):806\u2013825, November 1997.\n[Imp95]\n\nR. Impagliazzo. A personal view of average-case complexity. In Proceedings\nof the 10th Structure in Complexity Theory Conference, pages 134\u2013147. IEEE\nComputer Society Press, 1995.\n\n[Lev86]\n\nL. Levin. Average case complete problems.\n15(1):285\u2013286, 1986.\n\n[MPS06]\n\nJ. McCabe-Dansted, G. Pritchard, and A. Slinko. Approximability of Dodgson's rule. In U. Endriss and J. Lang, editors, First International Workshop on\nComputational Social Choice (COMSOC 2006), pages 331\u2013344 (workshop notes).\nUniversiteit van Amsterdam, December 2006.\n\n[MU95]\n\nI. McLean and A. Urken. Classics of Social Choice. University of Michigan Press,\nAnn Arbor, Michigan, 1995.\n\n[PR07]\n\nA. Procaccia and J. Rosenschein. Junta distributions and the average-case complexity of manipulating elections. Journal of Artificial Intelligence Research,\n28:157\u2013181, 2007.\n\n[RSV03]\n\nJ. Rothe, H. Spakowski, and J. Vogel. Exact complexity of the winner problem\nfor Young elections. Theory of Computing Systems, 36(4):375\u2013386, June 2003.\n\n[Tre02]\n\nL.\nTrevisan.\nLecture\nnotes\non\ncomputational\ncomplexity.\nwww.cs.berkeley.edu/ \u0303luca/notes/complexitynotes02.pdf (Lecture 12), 2002.\n\n[Wan97]\n\nJ. Wang. Average-case computational complexity theory. In L. Hemaspaandra and A. Selman, editors, Complexity Theory Retrospective II, pages 295\u2013328.\nSpringer-Verlag, 1997.\n\n18\n\nSIAM Journal on Computing,\n\n\fA\n\nHoman and Hemaspaandra's Frequently Self-Knowingly\nCorrect Greedy Algorithm\n\nHoman and Hemaspaandra [HH06] proposed the following definition of a new type of algorithm to capture the notion of \"guaranteed high success frequency\" formally.\nDefinition A.1 ([HH06])\n1. Let f : S \u2192 T be a function, where S and T are sets.\nWe say an algorithm A : S \u2192 T \u00d7 {\"definitely\", \"maybe\"} is self-knowingly correct\nfor f if, for each s \u2208 S and t \u2208 T , whenever A on input s outputs (t, \"definitely\")\nthen f (s) = t.\n2. An algorithm A that is self-knowingly correct for g : \u03a3\u2217 \u2192 T is said to be frequently\nself-knowingly correct for g if\nk{x \u2208 \u03a3n | A(x) \u2208 T \u00d7 {\"maybe\"}}k\n= 0.\nn\u2192\u221e\nk\u03a3n k\nlim\n\nIn their paper [HH06], Homan and Hemaspaandra present two frequently self-knowingly\ncorrect polynomial-time algorithms, which they call Greedy-Score and Greedy-Winner.\nSince Greedy-Winner can easily be reduced to Greedy-Score, we focus on Greedy-Score\nonly and briefly describe the intuition behind this algorithm; for full detail, we refer\nto [HH06]. (But both heuristics work well tremendously often-in a formal sense of the\nnotion-provided that the number of voters greatly exceeds the number of candidates.)\nIf (C, V ) is an election and c is some designated candidate in C, we call (C, V, c) a\nDodgson triple. Given a Dodgson triple (C, V, c), Greedy-Score determines the Dodgson\nscore of c with respect to the given election (C, V ). We will see that there are Dodgson\ntriples (C, V, c) for which this problem is particularly easy to solve.\nFor any d \u2208 C \u2212 {c}, let Deficit[d] be the number of votes c needs to gain in order to\nhave more votes than d in a pairwise contest between c and d.\nDefinition A.2 Any Dodgson triple (C, V, c) is said to be nice if for each candidate d \u2208\nC \u2212 {c}, there are at least Deficit[d] votes for which candidate c is exactly one position below\ncandidate d.\nGiven a Dodgson triple (C, V, c), the algorithm Greedy-Score works as follows:\n1. For each candidate d \u2208 C \u2212 {c}, determine Deficit[d].\n2. If (C, V, c) is not nice then output (\"anything\",\"maybe\"); otherwise, output\nP\n( d\u2208C\u2212{c} Deficit[d], \"definitely\").\nNote that, for nice Dodgson triples, we have\n\nDodgsonScore(C, V, c) =\n\nX\n\nd\u2208C\u2212{c}\n\n19\n\nDeficit[d],\n\n\fIt is easy to see that Greedy-Score is a self-knowingly correct polynomial-time bounded\nalgorithm. To show that it is even frequently self-knowingly correct, Homan and Hemaspaandra prove the following lemma. Their proof uses a variant of Chernoff bounds.\nLemma A.3 (see Thm. 4.1(3) in [HH06]) Let (C, V, c) be a given Dodgson triple with\nn = kV k votes and m = kCk candidates, chosen uniformly at random among all such\nn\nDodgson elections. The probability that (C, V, c) is not nice is at most 2(m \u2212 1)e\u2212 8m2 .\nHoman and Hemaspaandra [HH06] show that the heuristic Greedy-Winner, which is\nbased on Greedy-Score and which solves the winner problem for Dodgson elections, also is\na frequently self-knowingly correct polynomial-time algorithm. This result is stated formally\nbelow.\nTheorem A.4 ([HH06]) For all m, n \u2208 N+ , the probability that a Dodgson election (C, V )\nselected uniformly at random from all Dodgson elections having m candidates and n votes\n(i.e., all (m!)n Dodgson elections having m candidates and n votes have the same likelihood of being selected) has the property that there exists at least one candidate c such that\nGreedy-Winner on input (C, V, c) outputs \"maybe\" as its second output component is less\nn\nthan 2(m2 \u2212 m)e\u2212 8m2 .\n\nB\n\nFoundations of Average-Case Complexity Theory\n\nThe theory of average-case complexity was initiated by Levin [Lev86]. A problem's averagecase complexity can be viewed as a more significant measure than its worst-case complexity\nin many cases, for example in cryptographic applications. We here follow Goldreich's presentation [Gol97]. Another excellent introduction to this theory is that of Wang [Wan97].\nFix the alphabet \u03a3 = {0, 1}, let \u03a3\u2217 denote the set of strings over \u03a3, and let \u03a3n denote\nthe set of all length n strings in \u03a3\u2217 . For any x, y \u2208 \u03a3\u2217 , x < y means that x precedes y in\nlexicographic order, and x \u2212 1 denotes the lexicographic predecessor of x.\nIntuitively, Levin observed that many hard problems-including those that are NP-hard\nin the traditional worst-case complexity model-might nonetheless be easy to solve \"on the\naverage,\" i.e., for \"most\" inputs or for \"most practically relevant\" inputs. He proposed to\ndefine the complexity of problems with respect to some suitable distribution on the input\nstrings.\nWe now define the notion of a distributional problem and the complexity class AvgP.\nHere, we define only distributional search problems; the definition of distributional decision problems is analogous.\nDefinition B.1 ([Lev86], see also [Gol97, Wan97])\n1. A distribution function \u03bc :\n\u2217\n\u03a3 \u2192 [0, 1] is a nondecreasing function from strings to the unit interval that converges\nto one (i.e., \u03bc(0) \u2265 0, \u03bc(x) \u2264 \u03bc(y) for each x < y, and limx\u2192\u221e \u03bc(x) = 1). The\ndensity function associated with \u03bc is defined by \u03bc\u2032 (0) = \u03bc(0) and \u03bc\u2032 (x) = \u03bc(x) \u2212\n\u03bc(x \u2212 1) for each x > 0. That is, each string x gets weight \u03bc\u2032 (x) with this distribution.\n20\n\n\f2. A distributional (search) problem is a pair (f, \u03bc), where f : \u03a3\u2217 \u2192 \u03a3\u2217 is a function\nand \u03bc : \u03a3\u2217 \u2192 [0, 1] is a distribution function.\n3. A function t : \u03a3\u2217 \u2192 N is polynomial on the average with respect to some distribution \u03bc if there exists a constant \u01eb > 0 such that\nX\n\n\u03bc\u2032 (x) *\n\nx\u2208\u03a3\u2217\n\nt(x)\u01eb\n< \u221e.\n|x|\n\n4. The class AvgP consists of all distributional problems (f, \u03bc) for which there exists\nan algorithm A computing f such that the running time of A is polynomial on the\naverage with respect to the distribution \u03bc.\nIn Section 3.2, we focused on the standard uniform distribution \u03bc\u0302 on \u03a3\u2217 , which is defined\nby\n\u03bc\u0302\u2032 (x) =\n\n1\n.\n|x|(|x| + 1)2|x|\n\nThat is, we first choose an input size n at random with probability 1/(n(n + 1)), and\nthen we choose an input string of that size n uniformly at random. (In this model, the\nlength-0 string \u01eb is routinely completely excluded from the probability distribution-it is\nby convention given weight zero.) For each n \u2208 N+ , let \u03bc\u0302n be the restriction of \u03bc\u0302 to strings\nof length exactly n. For each n \u2208 N+ , let \u03bc\u0302\u2264n be the restriction of \u03bc\u0302 to strings of length at\nmost n.\nIn Section 3.2, we considered polynomial-time benign algorithm schemes. This notion\nwas introduced by Impagliazzo [Imp95] to provide an alternative view on the definition of\naverage polynomial time.\nDefinition B.2 ([Imp95])\n1. An algorithm computes a function f with benign faults\nif it either outputs an element of the image of f or \" ?,\" and if it outputs anything\nother than ?, it is correct.\n2. A polynomial-time benign algorithm scheme for a function f on \u03bcn is an algorithm\nA(x, \u03b4) such that:\n(a) A runs in time polynomial in |x| and 1/\u03b4.\n(b) A computes f with benign faults.\n(c) For each \u03b4, 0 < \u03b4 < 1, and for each n \u2208 N+ ,\nProb\u03bc\u0302\u2264n [A(x, \u03b4) = ?] \u2264 \u03b4.\n\n21\n\n\f"}