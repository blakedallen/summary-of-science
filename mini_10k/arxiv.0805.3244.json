{"id": "http://arxiv.org/abs/0805.3244v1", "guidislink": true, "updated": "2008-05-21T10:12:05Z", "updated_parsed": [2008, 5, 21, 10, 12, 5, 2, 142, 0], "published": "2008-05-21T10:12:05Z", "published_parsed": [2008, 5, 21, 10, 12, 5, 2, 142, 0], "title": "Risk and resampling under model uncertainty", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0805.3356%2C0805.0169%2C0805.1494%2C0805.4357%2C0805.3003%2C0805.1765%2C0805.4165%2C0805.1024%2C0805.2793%2C0805.0069%2C0805.0879%2C0805.0899%2C0805.2233%2C0805.3450%2C0805.2863%2C0805.0228%2C0805.4519%2C0805.2762%2C0805.4283%2C0805.1857%2C0805.3558%2C0805.0549%2C0805.3423%2C0805.1652%2C0805.3262%2C0805.0498%2C0805.1997%2C0805.1512%2C0805.1806%2C0805.4212%2C0805.4403%2C0805.0158%2C0805.2659%2C0805.0806%2C0805.0101%2C0805.4154%2C0805.3127%2C0805.0408%2C0805.4637%2C0805.1074%2C0805.2514%2C0805.3244%2C0805.1014%2C0805.2427%2C0805.3853%2C0805.3365%2C0805.0966%2C0805.3439%2C0805.4466%2C0805.2092%2C0805.4350%2C0805.4414%2C0805.4745%2C0805.3196%2C0805.2790%2C0805.2350%2C0805.1215%2C0805.0214%2C0805.0451%2C0805.4419%2C0805.3953%2C0805.1741%2C0805.0824%2C0805.3728%2C0805.4499%2C0805.3094%2C0805.0877%2C0805.3204%2C0805.0512%2C0805.1529%2C0805.4367%2C0805.2077%2C0805.3781%2C0805.3104%2C0805.2710%2C0805.4614%2C0805.2956%2C0805.1107%2C0805.4553%2C0805.3910%2C0805.1413%2C0805.1693%2C0805.4028%2C0805.2147%2C0805.2654%2C0805.1177%2C0805.3790%2C0805.1928%2C0805.0141%2C0805.2357%2C0805.3606%2C0805.2122%2C0805.3609%2C0805.0153%2C0805.0444%2C0805.0651%2C0805.0903%2C0805.0846%2C0805.3631%2C0805.0871%2C0805.3048&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Risk and resampling under model uncertainty"}, "summary": "In statistical exercises where there are several candidate models, the\ntraditional approach is to select one model using some data driven criterion\nand use that model for estimation, testing and other purposes, ignoring the\nvariability of the model selection process. We discuss some problems associated\nwith this approach. An alternative scheme is to use a model-averaged estimator,\nthat is, a weighted average of estimators obtained under different models, as\nan estimator of a parameter. We show that the risk associated with a Bayesian\nmodel-averaged estimator is bounded as a function of the sample size, when\nparameter values are fixed. We establish conditions which ensure that a\nmodel-averaged estimator's distribution can be consistently approximated using\nthe bootstrap. A new, data-adaptive, model averaging scheme is proposed that\nbalances efficiency of estimation without compromising applicability of the\nbootstrap. This paper illustrates that certain desirable risk and resampling\nproperties of model-averaged estimators are obtainable when parameters are\nfixed but unknown; this complements several studies on minimaxity and other\nproperties of post-model-selected and model-averaged estimators, where\nparameters are allowed to vary.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0805.3356%2C0805.0169%2C0805.1494%2C0805.4357%2C0805.3003%2C0805.1765%2C0805.4165%2C0805.1024%2C0805.2793%2C0805.0069%2C0805.0879%2C0805.0899%2C0805.2233%2C0805.3450%2C0805.2863%2C0805.0228%2C0805.4519%2C0805.2762%2C0805.4283%2C0805.1857%2C0805.3558%2C0805.0549%2C0805.3423%2C0805.1652%2C0805.3262%2C0805.0498%2C0805.1997%2C0805.1512%2C0805.1806%2C0805.4212%2C0805.4403%2C0805.0158%2C0805.2659%2C0805.0806%2C0805.0101%2C0805.4154%2C0805.3127%2C0805.0408%2C0805.4637%2C0805.1074%2C0805.2514%2C0805.3244%2C0805.1014%2C0805.2427%2C0805.3853%2C0805.3365%2C0805.0966%2C0805.3439%2C0805.4466%2C0805.2092%2C0805.4350%2C0805.4414%2C0805.4745%2C0805.3196%2C0805.2790%2C0805.2350%2C0805.1215%2C0805.0214%2C0805.0451%2C0805.4419%2C0805.3953%2C0805.1741%2C0805.0824%2C0805.3728%2C0805.4499%2C0805.3094%2C0805.0877%2C0805.3204%2C0805.0512%2C0805.1529%2C0805.4367%2C0805.2077%2C0805.3781%2C0805.3104%2C0805.2710%2C0805.4614%2C0805.2956%2C0805.1107%2C0805.4553%2C0805.3910%2C0805.1413%2C0805.1693%2C0805.4028%2C0805.2147%2C0805.2654%2C0805.1177%2C0805.3790%2C0805.1928%2C0805.0141%2C0805.2357%2C0805.3606%2C0805.2122%2C0805.3609%2C0805.0153%2C0805.0444%2C0805.0651%2C0805.0903%2C0805.0846%2C0805.3631%2C0805.0871%2C0805.3048&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In statistical exercises where there are several candidate models, the\ntraditional approach is to select one model using some data driven criterion\nand use that model for estimation, testing and other purposes, ignoring the\nvariability of the model selection process. We discuss some problems associated\nwith this approach. An alternative scheme is to use a model-averaged estimator,\nthat is, a weighted average of estimators obtained under different models, as\nan estimator of a parameter. We show that the risk associated with a Bayesian\nmodel-averaged estimator is bounded as a function of the sample size, when\nparameter values are fixed. We establish conditions which ensure that a\nmodel-averaged estimator's distribution can be consistently approximated using\nthe bootstrap. A new, data-adaptive, model averaging scheme is proposed that\nbalances efficiency of estimation without compromising applicability of the\nbootstrap. This paper illustrates that certain desirable risk and resampling\nproperties of model-averaged estimators are obtainable when parameters are\nfixed but unknown; this complements several studies on minimaxity and other\nproperties of post-model-selected and model-averaged estimators, where\nparameters are allowed to vary."}, "authors": ["Snigdhansu Chatterjee", "Nitai D. Mukhopadhyay"], "author_detail": {"name": "Nitai D. Mukhopadhyay"}, "author": "Nitai D. Mukhopadhyay", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1214/074921708000000129", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0805.3244v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0805.3244v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Published in at http://dx.doi.org/10.1214/074921708000000129 the IMS\n  Collections (http://www.imstat.org/publications/imscollections.htm) by the\n  Institute of Mathematical Statistics (http://www.imstat.org)", "arxiv_primary_category": {"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.ME", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.TH", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "60F12 (Primary) 60J05, 62C10, 62F40 (Secondary)", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0805.3244v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0805.3244v1", "journal_reference": "IMS Collections 2008, Vol. 3, 155-169", "doi": "10.1214/074921708000000129", "fulltext": "IMS Collections\nPushing the Limits of Contemporary Statistics: Contributions in Honor of\nJayanta K. Ghosh\nVol. 3 (2008) 155\u2013169\nc Institute of Mathematical Statistics, 2008\nDOI: 10.1214/074921708000000129\n\narXiv:0805.3244v1 [math.ST] 21 May 2008\n\nRisk and resampling under model\nuncertainty\nSnigdhansu Chatterjee1 and Nitai D. Mukhopadhyay2\nUniversity of Minnesota and Virginia Commonwealth University\nAbstract: In statistical exercises where there are several candidate models,\nthe traditional approach is to select one model using some data driven criterion and use that model for estimation, testing and other purposes, ignoring\nthe variability of the model selection process. We discuss some problems associated with this approach. An alternative scheme is to use a model-averaged\nestimator, that is, a weighted average of estimators obtained under different\nmodels, as an estimator of a parameter. We show that the risk associated with a\nBayesian model-averaged estimator is bounded as a function of the sample size,\nwhen parameter values are fixed. We establish conditions which ensure that a\nmodel-averaged estimator's distribution can be consistently approximated using the bootstrap. A new, data-adaptive, model averaging scheme is proposed\nthat balances efficiency of estimation without compromising applicability of\nthe bootstrap. This paper illustrates that certain desirable risk and resampling properties of model-averaged estimators are obtainable when parameters\nare fixed but unknown; this complements several studies on minimaxity and\nother properties of post-model-selected and model-averaged estimators, where\nparameters are allowed to vary.\n\nContents\n1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . .\n2 Issues with model selection or averaging . . . . . . . . .\n3 Risk profile of model-averaged estimators . . . . . . . .\n4 Adaptive model-averaged estimators and the bootstrap .\n5 A simulation example . . . . . . . . . . . . . . . . . . .\n6 Discussion and conclusions . . . . . . . . . . . . . . . .\nAcknowledgments. . . . . . . . . . . . . . . . . . . . . . . .\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n\n155\n157\n159\n161\n165\n167\n168\n168\n\n1. Introduction\nIn typical statistical applications, it is rare that a precise model is available to fit\nto the data. Selecting one model from several competing models is often the first\nstep in the process. However, in the subsequent analysis, it is common to ignore the\nvariability in the initial model selection. Two of the many consequences of ignoring\n1 School of Statistics, University of Minnesota, 313 Ford Hall, 224 Church Street SE, Minneapolis, MN 55455, USA, e-mail: chatterjee@stat.umn.edu\n2 Department of Biostatistics, Virginia Commonwealth University, 730 E. Broad Street, Richmond, Virginia 23298, USA, e-mail: ndmukhopadhy@vcu.edu\nAMS 2000 subject classifications: Primary 60F12; secondary 60J05, 62C10, 62F40.\nKeywords and phrases: bootstrap, bounded risk, linear regression, model averaging, model selection.\n\n155\n\n\f156\n\nS. Chatterjee and N. Mukhopadhyay\n\nmodeling variability are (i) under-estimation of the variability of estimators and\npredictors, and (ii) erroneous inference and prediction, resulting from incorrectly\ncomputing the distributions of estimators and predictors. An alternative to selecting\na model first and then computing an estimator under that model is to consider\nseveral models and appropriately average the estimators computed under these\nmodels.\nSeveral studies have been published recently on the properties of post-modelselected and model-averaged estimators; see for example, [8], [23] and [24]. These\nstudies are discouraging as they show that many nice properties associated with\nestimators under a known model vanish when there is model uncertainty. For example, Yang [23] shows that consistent model selection/averaging, and minimax-rate\noptimality cannot be simultaneously obtained. The review of Leeb and P\u00f6tscher [8]\ncontains a discussion of several other problems with inference after model selection.\nIn view of these negative results, it seems desirable to scale down our expectations\nwhile working under model uncertainty, and strive for positive, if weaker, results.\nThis may be achieved in one of two ways: we may either impose less stringent\nconditions on our estimators, or we may relax the criterion by which an estimator\nis evaluated. The latter is the goal of the present study.\nThe computation of an estimator is generally one of the early steps in a statistical exercise. Estimators of parameters are used for various purposes, notably\nfor quantifying evidence for or against scientific hypotheses, obtaining interval estimates for the parameter under consideration, for prediction and forecasting, and\nfor quantifying the accuracy of predictions and forecasts. These applications require\nknowledge about the distribution of the estimator, and knowledge about the risk\nassociated with the usage of such estimators. In this paper, we concentrate on the\nrisk behavior of a model-averaged estimator, and on approximating the distribution\nof a model-averaged estimator using the bootstrap.\nIn the first part of our study we show that under the traditional frequentist assumption that the parameters are fixed but unknown constants, the mean squared\nerror in regression estimation under consistent model selection/averaging is bounded as a function of sample size. This complements Yang [23], where it was shown that\na similar quantity cannot achieve minimax-rate optimality. Several of the negative\nresults, including those of Yang [23], arise when a parameter is a known constant\nin a smaller model, while it is allowed to vary in a local neighborhood of that\nconstant in a larger model. Recently, Hjort and Claeskens [5] studied model averaged estimators under a local parameter framework. Local parameters are ideal for\nmathematical development, but they are not reflective of statistical reality; see [17].\nIndeed, as Hjort and Claeskens themselves remark in the rejoinder to the discussion of their paper, \"a too literal belief in sample-size-dependent parameters would\nclash with Kolmogorov consistency and other requirements of natural statistical\nmodels.\" [5]. In view of this, it is meaningful to verify that estimators have reasonable risk behavior under consistent model selection/averaging when parameters\nare fixed constants. Our result also implies that integrated risks under consistent\nmodel selection/averaging are bounded, when integrals are taken with respect to\nany probability measure on the parameter space that does not depend on sample\nsize.\nIn the second part of our study, in addition to the assumption that the parameters are fixed but unknown constants, we also weaken the consistency requirement\nof the model averaging procedure. In the terminology of Yang [23], a model selection/averaging scheme is consistent if it is asymptotically degenerate at the true\nmodel, when the true model is one of the candidate models. When the models are\n\n\fModel uncertainty\n\n157\n\nnested and several of them can correctly describe the data generation process, the\nmost parsimonious correct model is taken as the true model. We call this strong\nconsistency. We define a model selection/averaging scheme as weakly consistent if it\nselects or averages over all candidate models that correctly describe the data generation process. When only one model is correct, the strong and weak consistency\nrequirements are identical; but if models are nested and several of them are correct, a weakly consistent scheme may distribute weights among all of them while a\nstrongly consistent one is asymptotically degenerate at the smallest one. Recently,\nLeung and Barron [11] proposed a scheme of model averaging that results in nice\nrisk behavior. Their scheme is an example of a weakly consistent procedure. We\nshow that a particular choice of a weakly consistent model-averaged estimator has\na distribution that can be approximated using the bootstrap.\nIn Section 2 we propose a simple linear regression model framework to study\nmodel uncertainty. We also discuss some of the properties of post-model-selection\nestimators that make them unsuitable for further applications, and also some properties of model-averaged estimators. This is followed in Section 3 with a discussion\nof mean squared error of the Bayesian model-averaged estimator. In Section 4 we\npropose a new adaptive, model-averaged estimator whose distribution may be consistently approximated using the bootstrap. A simulation example is discussed in\nSection 5. Finally, in Section 6 we discuss some aspects of our results, and point to\nsome open issues relating to model uncertainty.\n2. Issues with model selection or averaging\nWe select a simple regression framework for our study, which is the same as that\nused by [8], and similar to that of [24]. The observed data {(Yt , xt = (xt1 , xt2 )T ), t =\n1, . . . , n}, are modeled as\n(2.1)\n\nYt = \u03b1xt1 + \u03b2xt2 + et ,\n\nwhere the et 's are independent, identically distributed N (0, \u03c3 2 ), \u03c3 2 known. The\ndesign matrix X with rows given by xTt = (xt1 , xt2 ) is non-random. We denote\nthe two columns of X as X1 and X2 , the vector of errors as e, and the vector\nof observations as Y. The inner products and norms used below are the usual\nEuclidean ones. The notation D is used for the determinant of the design matrix,\nthus D = ||X1 ||2 ||X2 ||2 \u2212 < X1 , X2 >2 . The unknown parameters in this model\nare (\u03b1, \u03b2). Model uncertainty surrounds the issue of whether or not \u03b2 = 0. In this\npaper, for ease in presentation, we consider the problem of estimation of \u03b1.\nWe make the standard assumption that n\u22121 XT X \u2192 Q for a positive definite\nmatrix Q. This, in particular, implies the standard design conditions\n(2.2)\n||X1 ||2\n(2.3) < X1 , X2 >\n\n= O(n),\n= O(n),\n\n||X2 ||2 = O(n),\nD = ||X1 ||2 ||X2 ||2 \u2212 < X1 , X2 >2 = O(n2 ).\n\nWe also assume that n\u22121 < X1 , X2 >6\u2212\u2192 0 as n \u2192 \u221e, since without this restriction\nthe effect of model uncertainty vanishes in this framework.\nThe true model, called M0 , may be described as\n\u001a\nU (unrestricted)\nif \u03b2 6= 0;\nM0 =\nR (restricted)\nif \u03b2 = 0.\n\n\f158\n\nS. Chatterjee and N. Mukhopadhyay\n\nUnder U , we adopt the ordinary least squares or maximum likelihood estid\u03b2) = (XT X)\u22121 XT Y. Our notation for these are (\u03b1\u0302(U ), \u03b2\u0302(U )). Unmators (\u03b1,\nder R, \u03b2\u0302(R) \u2261 0, and the\nP least squares or maximum likelihood estiP ordinary\nmator for \u03b1 is \u03b1\u0302(R) = [ i x21i ]\u22121 x1i yi . Define V1 = \u03c3 \u22121 ||X1 ||\u22121 < X1 , e >\n\b\nand V2 = \u03c3 \u22121 D\u22121/2 ||X1 || < X2 , e > \u2212||X1 ||\u22122 < X1 , X2 >< X1 , e > , thus V =\n(V1 , V2 )T \u223c N (0, I2 ). In terms of V, the estimators are\n\uf8eb\n\uf8f6 \uf8ee\n\uf8f9\n\u03b1\u0302(R)\n\u03b1 + \u03b2||X1 ||\u22122 < X1 , X2 > +\u03c3||X1 ||\u22121 V1 ,\n\uf8ed \u03b1\u0302(U ) \uf8f8 = \uf8f0 \u03b1 + \u03c3||X1 ||\u22121 V1 \u2212 \u03c3||X1 ||\u22121 D\u22121/2 < X1 , X2 > V2 , \uf8fb\n\u03b2 + \u03c3||X1 ||D\u22121/2 V2 .\n\u03b2\u0302(U )\n\nThe dichotomy between the bias of the restricted model R and the variance of the\nunrestricted model U can be clearly seen in the above formula. The restricted model\nestimator \u03b1\u0302(R) has a bias factor \u03b2||X1 ||\u22122 < X1 , X2 >, which vanishes under R,\nwhile \u03b1\u0302(U ) has an extra factor of \u03c3||X1 ||\u22121 D\u22121/2 < X1 , X2 > V2 that inflates its\nvariance relative to \u03b1\u0302(R). Hence, model selection or model averaging is essentially\na process of balancing bias and variance; see [20].\nLet \u03c3\u03b2 be the standard deviation of \u03b2\u0302(U ). This is a non-random, known number\ndepending on \u03c3 2 and X. The following model selection criterion is used:\n(\nU if |n\u22121/2 \u03c3\u03b2\u22121 \u03b2\u0302(U )| > c;\nM\u0302 =\nR if |n\u22121/2 \u03c3\u03b2\u22121 \u03b2\u0302(U )| \u2264 c.\nThe above criterion may be identified as representative of standard model selection\ntools, in the simple regression model. In particular, the above criterion is the traditional pre-test procedure based on the\n\u221a likelihood ratio, coincides with the Akaike\nInformation Criterion (AIC) if c\u221a= 2, and coincides with the Bayesian Information Criterion (BIC) if c = log n. The post-model-selection estimator of \u03b1\nis\n(2.4)\n\n\u03b1\u0303 = \u03b1\u0302(R)I{M\u0302 =R} + \u03b1\u0302(U )I{M\u0302 =U} .\n\nSeveral nice properties are known about M\u0302 and, consequently, it is generally\nbelieved that \u03b1\u0303 will also have good properties. Some of the important properties\ninclude that for all \u03b2 and as c \u2192 \u221e, n\u22121/2 c \u2192 0, P [M\u0302 = M0 ] \u2192 1, {M\u0302 = M0 } \u2286\n{\u03b1\u0303 = \u03b1\u0302(M0 )} and thus P [\u03b1\u0303 = \u03b1\u0302(M0 )] \u2192 1 (see [15]). Note that \u03b1\u0302(M0 ) is the\n\"oracle's guess\" about \u03b1, and is not a statistic, since it is based on the knowledge of\n\u03b2. The above properties tend to give the impression that \u03b1\u0303 is a very good estimator.\nHowever, there are some major problems since the above results are asymptotic in\nnature, and the asymptotics can take a long time to kick in, as well as be dependent\non the value of \u03b2. Our primary reference for this model and its basic properties [8]\nidentifies this as a problem of non-uniformity in \u03b2 of the convergence of M\u0302 and \u03b1\u0303.\nIt \u221a\ncan be immediately seen that the estimator \u03b1\u0303 is super-efficient when c \u2192 \u221e,\nc/ n \u2192 0, as with BIC. The major repercussions of super-efficiency of \u03b1\u0303 and the\nnon-uniformity of its asymptotics is in its risk performance, and in its finite sample\nbehavior. The mean squared error of \u03b1\u0303 is unbounded and depends on \u03b2, while that\nof \u03b1\u0302(M0 ) is a constant. As a consequence, the finite sample behavior of \u03b1\u0303 is erratic\nand can be quite unlike its asymptotic approximation. Available simulations confirm\nthis; see [8]. Several other studies conducted by Leeb, P\u00f6tscher, Yang and others\nreveal how and why the properties of \u03b1\u0303 and \u03b1\u0302(M0 ) differ. For further information\nsee, for example, [6, 7, 8, 9, 10, 22, 24, 25].\n\n\fModel uncertainty\n\n159\n\nThe super-efficiency of \u03b1\u0303 results in most variations of the bootstrap being inapplicable. Only subsampling ([14]) and the m-out-of-n bootstrap with m/n \u2192 0\nwould yield consistent approximations of the distribution of \u03b1\u0303. Unfortunately, these\nmethods have problems of their own, some details of which can be found in [18] and\n[1]. Specifically, although subsampling is asymptotically consistent, it can perform\nmiserably in finite samples. For any \u03b1 \u2208 (0, 1), the actual asymptotic coverage of a\nstandard level (1 \u2212 \u03b1) subsampling confidence interval can be zero; see [1] for details. The finite sample properties of subsampling based methods can be improved\nsometimes by considering hybrid techniques, calibrations and other modifications,\nas documented by [2]. However, the asymptotic zero coverage of subsampling intervals for \u03b1\u0303 cannot be reversed by, for example, size correction, since technical\nconditions that allow for such correction to work are not satisfied by \u03b1\u0303.\nThe above issues with post-model-selection estimators lead to model-averaged\nestimators. A model-averaged estimator of \u03b1 is of the form\n(2.5)\n\n\u03b1\u030c = \u03b1\u0302(R)pR + \u03b1\u0302(U )pU ,\n\nwhere pR and pU are two weights associated with the models R and U . Yang\nand his co-authors have extensively studied aggregation across models for several\nstatistical procedures like estimators and forecasts, in both their algorithmic as well\nas theoretical aspects (see [22, 23, 24, 25]). In particular, a result of [23] implies\nthat when the model averaging technique is strongly consistent, the supremum of\nthe mean squared error of n1/2 (\u03b1\u030c \u2212 \u03b1) over values of (\u03b1, \u03b2) tends to infinity. Thus,\nstrongly consistent model averaging does not attain the minimax rate. Our result\nin Section 3 shows that, up to constant terms, it is no worse than the post-modelselection estimator when (\u03b1, \u03b2) are held fixed.\nRecently, [5] studied several forms of model averaging and showed that a typical\nmodel-averaged estimator converges weakly to a mixture of normal laws, when\nthe parameters of the true model are in a O(n\u22121/2 ) neighborhood of the simplest\ncandidate in a nesting of models. Since subsampling does not seem to perform\nwell in practice, it is important to study conditions on model weights under which\nbootstrap approximations of finite sample distributions hold, i.e., conditions under\nwhich the statistic under consideration is smooth and asymptotically normal (see\n[12], [13]). This is studied in Section 4.\n3. Risk profile of model-averaged estimators\nSeveral problems associated with the post-model-selection estimator can be attributed to its lack of uniformity, as discussed extensively by others [8]. One is the\nsuper-efficiency of \u03b1\u0303, for example, when BIC is used for model selection. The core\nproblem of lack of uniformity in the convergence pattern of \u03b1\u0303 is unavoidable \u2013 even\nwith model averaging \u2013 when a strongly consistent model averaging technique is\nused, as described by [23]. In this section we show that when parameter values are\nfixed, model averaging is no worse than model selection, up to constant terms.\nUnder the unrestricted model, U , we choose the prior on (\u03b1, \u03b2) to be a standard\nmean zero, identity covariance bivariate Normal distribution, N (0, I). Under the\nrestricted model, R, the prior on \u03b1 is a standard univariate Normal distribution,\nN (0, 1). We put equal prior weights, i.e., 1/2, on the models, so the prior odds is\n1. Our notation for the posterior probabilities of the two models are \u03c0nU and \u03c0nR .\nSince \u03c3 is known, without loss of generality we also assume \u03c3 = 1 in this section.\n\n\f160\n\nS. Chatterjee and N. Mukhopadhyay\n\nThus the Bayesian model-averaged estimator of \u03b1 is\n(3.6)\n\n\u03b1\u0302BMA\n\n=\n\n\u03c0nU \u03b1\u0302(U ) + \u03c0nR \u03b1\u0302(R).\n\nWe use the pre-selected, least squares estimators \u03b1\u0302(U ) and \u03b1\u0302(R) as constituents\nof \u03b1\u0302BMA , and consider the squared error loss function. The case where a general\nloss function is used, with \u03b1\u0302(U ) and \u03b1\u0302(R) taken to be the Bayes estimators under\nmodels U and R, is very similar. The following Proposition is our main result in\nthis section.\nProposition 3.1. The normalized risk of \u03b1\u0302BMA , nR(\u03b1) = nE(\u03b1\u0302BMA \u2212 \u03b1)2 ,\nsatisfies sup nR(\u03b1) < \u221e, for every fixed choice of \u03b1 and \u03b2. Hence, the integrated\nn\n\nnormalized risk\nsup\nn\n\nZ\n\n\u03b1, \u03b2\n\nnR(\u03b1)d\u03bb(\u03b1, \u03b2) < \u221e\n\nfor any probability measure \u03bb(*) that does not depend on n.\nProof. In the following, we use C as a generic constant, not depending on the\nparameters \u03b1 and \u03b2 or the sample size n.\nNote that \u03b1\u0302(R) = \u03b1\u0302(U ) + \u03b2\u0302(U )||X1 ||\u22122 < X1 , X2 >. Therefore,\nnR(\u03b1)\n(3.7)\n\n= nE [\u03c0nU \u03b1\u0302(U ) + \u03c0nR \u03b1\u0302(R) \u2212 \u03b1]\n\n2\n\nn\no\n2\n2\n\u2264 2nE (\u03b1\u0302(U ) \u2212 \u03b1) + 2n||X1 ||\u22124 < X1 , X2 >2 E \u03c0nR\n\u03b2\u0302 2 (U ) .\n\ni2\nh\n2\nNote that E (\u03b1\u0302(U ) \u2212 \u03b1) = \u03c3 2 ||X1 ||\u22122 E V1 \u2212 < X1 , X2 > D\u22121/2 V2 = Cn\u22121 and\n2\n2\n2\nE\u03c0nR\n\u03b2\u0302 2 (U ). \u2264 2\u03b2 2 E\u03c0nR\n+ Cn\u22121 . Thus, we need suitable bounds for \u03b2 2 E\u03c0nR\n. We\nnow have\n\u0012\n\u0013\u22121\nmR (Y)\nmR (Y)\nmR (Y)\n1+\n\u2264\n.\npnR = mR (Y)/ (mU (Y) + mU (Y)) =\nmU (Y)\nmU (Y)\nmU (Y)\n\nThen, making use of the moment generating function of a \u03c72 random variable, we\ncan deduce that\nE\n\n\u0012\n\nmR (Y)\nmU (Y)\n\n\u00132\n\n\b\n= Cn2 exp \u2212nC0 (\u03b12 + \u03b2 2 )\n\nfor a particular constant C0 . This yields, at (3.7), that\n\b\nnR(\u03b1) = Cn\u22121 + Cn3 \u03b2 2 exp \u2212nC0 (\u03b12 + \u03b2 2 ) .\n\nwhich is bounded for every fixed (\u03b1, \u03b2), as a function of n. The rest of the result\nfollows.\nRemark 3.1. A lower bound for nR(\u03b1) can also be established using arguments\nsimilar to those above. With slight modification, the above approach using the\nmoment generating function of a non-central \u03c72 random variable can be used to\nprovide an alternative proof of Theorem 2 of [23]. It can also be seen that even when\n(\u03b1, \u03b2) vary over a compact set, the supremum of nR(\u03b1) over (\u03b1, \u03b2) is unbounded.\n\n\fModel uncertainty\n\n161\n\n4. Adaptive model-averaged estimators and the bootstrap\nThe results of Hjort and Claeskens [5] and Leeb and Potscher [8] indicate that\nthe post-model-selection estimator and many model-averaged estimators cannot be\nconsistently bootstrapped. The problems associated with the risk behavior, and\nthose associated with bootstrap approximation, arise from two different sources.\nUndesirable behavior of the risk function arises from considering scenarios as parameters vary, while a major reason why the distribution of post-model-selection\nor model-averaged estimators cannot be approximated by bootstrap methods is\nbecause of lack of smoothness of the estimator, or lack of asymptotic normality.\nIn this section we study the conditions on the model weights which are required\nfor consistent bootstrap approximation of the distribution of the resulting modelaveraged estimator. Clearly, since the distribution of \u03b1\u0302(U ) can be approximated\nusing the bootstrap, putting the entire weight on model U is an option. However,\nbalancing between \u03b1\u0302(U ) and \u03b1\u0302(R) can lead to a more efficient estimator. We propose below a data-adaptive model weighing scheme that achieves the dual goals of\nreasonable efficiency and bootstrap consistency.\nA model-averaged estimator of \u03b1 is of the form\n(4.8)\n\n\u03b1\u030c = \u03b1\u0302(R)pnR + \u03b1\u0302(U )pnU .\n\nNotice that we have adopted a different notation (pnR and pnU ) for the model\nweights in this Section, from those (\u03c0nR and \u03c0nU ) used in Section 3. This is to\nemphasize that the nature of these weights may be different. We retain the condition\nthat the parameters (\u03b1, \u03b2) are fixed but unknown.\nA primary requirement for consistency is pnR + pnU = 1, as pointed out in [5]. In\norder to avoid pathologies, we also specify that pnU \u2208 [0, 1]. Note that the weights\npnR and pnU may depend on the parameters (\u03b1, \u03b2), and the random component V,\napart from the known constants X and \u03c3 2 .\nReplacing pnU by 1 \u2212 pnR , we thus have\n\u03b1\u030c =\n\n\u03b1 + \u03c3||X1 ||\u22121 V1 + \u03b2pnR ||X1 ||\u22122 < X1 , X2 >\n\n\u2212\u03c3||X1 ||\u22121 D\u22121/2 < X1 , X2 > (1 \u2212 pnR )V2 .\n\nA primary requirement on \u03b1\u030c is that it should be consistent, and the following\nproposition establishes a necessary and sufficient condition for this.\nProposition 4.1. The model-averaged estimator \u03b1\u030c converges in probability to \u03b1 if\nand only if \u03b2pnR converges in probability to zero as n \u2192 \u221e.\nProof. The sufficiency part follows easily from the design conditions (2.2)\u2013(2.3).\np\nFor the necessity part, suppose that \u03b2pnR \u2192 c\u0303 6= 0 as n \u2192 \u221e. This is clearly\np\nequivalent nto pnR \u2192 c = c\u0303/\u03b2 6= 0 as n \u2192\no \u221e and \u03b2 6= 0. Hence, we also have\n(1 \u2212 pnR ) \u03c3||X1 ||\u22121 D\u22121/2 < X1 , X2 > V2\n\np\n\np\n\n\u2192 (1 \u2212 c)0 = 0. This implies \u03b1\u030c \u2192\n\n\u03b1 \u2212 c\u0303\u03b3 6= \u03b1, where ||X1 ||\u22121 < X1 , X2 >\u2192 \u03b3 as n \u2192 \u221e. The case where pnR does\nnot have a limit can be treated similarly with a little more algebra.\n\nThe next proposition is an extension of the previous one, and establishes sufficient\nconditions for asymptotic normality of \u03b1\u030c.\nProposition 4.2. The scaled and centered model-averaged estimator n1/2 (\u03b1\u030c \u2212 \u03b1)\nhas an asymptotic normal distribution if (i) n1/2 \u03b2pnR converges in probability to\nzero as n \u2192 \u221e, and (ii) pnR converges in probability as n \u2192 \u221e for all values of\n(\u03b1, \u03b2).\n\n\f162\n\nS. Chatterjee and N. Mukhopadhyay\n\nProof. The first condition forces the bias component in \u03b1\u030c to be o(n\u22121/2 ), while the\nsecond condition allows for use of Slutsky's theorem.\np\n\nBy requiring n1/2 \u03b2pnR \u2192 0 as n \u2192 \u221e we have ensured that, when \u03b2 6= 0, we\np\nhave n1/2 pnR \u2192 0. Thus the model-averaged estimator is close to the unrestricted\nmodel estimator \u03b1\u0302(U ), and has the same limiting distribution up to first order\nterms. However, when \u03b2 = 0, the asymptotic distribution of n1/2 (\u03b1\u030c \u2212 \u03b1) depends\non the limit of pnR , which is between zero and one. Thus, when the restricted model\nholds, the asymptotic variance of \u03b1\u030c is between that of \u03b1\u0302(R) and \u03b1\u0302(U ). The relative\nstrengths of different candidates for model weight pnR may be evaluated by their\nprobability limits when \u03b2 = 0. We note that we consider (\u03b1, \u03b2) as fixed constants\nand do not allow them to vary with n. If, for example, we assumed \u03b2 = O(n\u22121/2 ),\nthen the first condition of Proposition 4.2 would imply asymptotically zero weight\non the restricted model.\nIn order to progress towards bootstrap consistency, apart from asymptotic normality of \u03b1\u030c, we also need pnR to be a smooth function. Thus ruling out the indicator\nfunction pnR = I{|n\u22121/2 \u03c3\u22121 \u03b2\u0302(U)|\u2264c} used in \u03b1\u0303. Keeping in view the nice properties\n\u03b2\nof \u03b1\u0303, we now develop an adaptive, data-driven model weight function pnR that is a\nsmooth version of I{|n\u22121/2 \u03c3\u22121 \u03b2\u0302(U)|\u2264c} .\n\u03b2\n\nFor any kn , we split the event {\u2212kn \u2264 \u03b2\u0302(U ) \u2264 kn } into two events, {\u03b2\u0302(U )\u2212 kn \u2264\n0} and {\u03b2\u0302(U ) + kn \u2265 0}, and approximate the indicators of these events separately.\nOur approximation for I{\u03b2\u0302(U)\u2212kn \u22640} is\n\u0011\n\u0010\n\u03be1n \u2261 \u03be1n \u03b31n , \u03b2\u0302(U ), kn\n\u0010\nn\no\u0011\u22121\nn\no\n=\n1 + exp \u2212\u03b31n (\u03b2\u0302(U ) \u2212 kn )\nexp \u2212\u03b31n (\u03b2\u0302(U ) \u2212 kn ) ,\nand for I{\u03b2\u0302(U)+kn \u22650} is\n\u0011\n\u0010\n\u03be2n \u2261 \u03be2n \u03b31n , \u03b2\u0302(U ), kn\n\u0010\nn\no\u0011\u22121\nn\no\n=\n1 + exp \u03b32n (\u03b2\u0302(U ) + kn )\nexp \u03b32n (\u03b2\u0302(U ) + kn ) .\n\nWe take the two tuning values \u03b31n and \u03b32n to be always positive. However, they\nchange with n; and in a major departure from traditional model weights, they are\nnot equal to each other, and also depend on the data. Thus, \u03b31n \u2261 \u03b31n (\u03b1, \u03b2, V) and\n\u03b32n \u2261 \u03b32n (\u03b1, \u03b2, V) are unequal, random weights.\nEquipped with these functions, we define\npnR = 0.5\u03be1n + 0.5\u03be2n .\nWe adopt the paired bootstrap as our resampling strategy. Thus, we draw a simple\nrandom sample with replacement of the data pairs (Yi\u2217 , x\u2217i ), i = 1, . . . , n, from the\noriginal data (Yi , xi ), i = 1, . . . , n. The entire process of obtaining \u03b1\u0302(R), \u03b1\u0302(U ),\n\u03b2\u0302(R), pnR , and \u03b1\u030c is imitated with the resample (Yi\u2217 , x\u2217i ), i = 1, . . . , n, and we\napproximate the distribution of n1/2 (\u03b1\u030c \u2212 \u03b1) with the distribution of n1/2 (\u03b1\u030c\u2217 \u2212 \u03b1\u030c),\nconditional on (Yi , xi ), i = 1, . . . , n. A technical condition guarantees that the\ndesign matrix from the resampled data is non-singular with high probability; see\ncondition (1.17) of [3].\nThe following Theorem is our main result in this section, and establishes consistency of the bootstrap for a adaptively weighted model-averaged estimator.\n\n\fModel uncertainty\n\n163\n\nTheorem 4.1. Assume that sequence of constants kn \u2193 0 as n \u2192 \u221e. Suppose the\ntuning constants are chosen as \u03b31n = an \u03b2\u0302(U ) \u03b32n = \u2212an \u03b2\u0302(U ) where {an } is a\nsequence of positive constants satisfying a\u22121\nas n \u2192 \u221e.\nn log(n) \u2193 0\nThen n1/2 (\u03b1\u030c\u2212\u03b1) has an asymptotic Normal distribution and the paired bootstrap\nis consistent for it.\nProof. For the asymptotic normality we only need to check that the conditions of\np\nProposition 4.2 are met. We illustrate the calculation for verifying n1/2 \u03be1n \u2192 0,\nwhen \u03b2 6= 0.\nh\ni\nP |n1/2 \u03be1n | > \u01eb\n\u0014 \u0010\nn\no\u0011\u22121\n= P | 1 + exp \u2212\u03b31n (\u03b2\u0302(U ) \u2212 kn )\nn\no\ni\nexp \u2212\u03b31n (\u03b2\u0302(U ) \u2212 kn ) + 0.5 log(n) | > \u01eb\nh\nn\no\ni\n\u2264 P exp \u2212\u03b31n (\u03b2\u0302(U ) \u2212 kn ) + 0.5 log(n) > \u01eb\nh\ni\n= P \u03b2\u0302(U ) lies between the roots of x2 \u2212 kn x \u2212 0.5an\u22121 log(n) + an\u22121 log(\u01eb) = 0 .\n\u22121\nThe roots of the equation x2 \u2212kn x\u22120.5a\u22121\nn log(n)+an log(\u01eb) = 0 are always real\n2\n\u22121\n\u22121\nwhen \u01eb < 1, since kn + 2an log(n) \u2212 4an log(\u01eb) > 0 for all n. Note that the square\n\u0001\n\u22121\nof the distance between the roots is given by kn2 + 2a\u22121\nn log(n) \u2212 4an log(\u01eb) /4.\n\u22121\nWhen kn \u2193 0, kn2 + 2a\u22121\nn log(n) \u2212 4an log(\u01eb) \u2193 0, hence the Lebesgue measure of\nthe interval between the roots goes to zero as n \u2192 \u221e, thus ensuring\nh\ni\n\u22121\nP \u03b2\u0302(U ) lies between the roots of x2 \u2212 kn x \u2212 0.5a\u22121\nn log(n) + an log(\u01eb) = 0 \u2192 0,\n\nas n \u2192 \u221e. Note that this result actually does not depend on the value of \u03b2, as long\nas it is non-zero.\nOther parts of the proof for asymptotic Normality may be verified similarly. Since\n\u03b1\u030c is a smooth function of \u03b1, \u03b2 and V, and has an asymptotic Normal distribution,\nthe consistency of the paired bootstrap procedure follows from [12] and [13].\n\nRemark 4.1. The condition kn \u2193 0 as n \u2192 \u221e is a weaker restriction than typically\n\u22121/2\nfound in literature. Since \u03b2\u0302(U ) = O\n), the AIC criterion uses kn = O(n\u22121/2 ),\np (n\np\nwhile the BIC uses kn = O(n\u22121/2 log(n)).\n\nRemark 4.2. The assumptions of Proposition 4.1 and Proposition 4.2 cannot be\nweakened in general. The example of Section 10.6 of [5] provides a test case. It is\na simpler version of the model described in Section 2, and simply has Y1 , . . . , Yn\nindependent, identically distributed as N (\u03bc, 1) random variables. Model uncertainty\nP\nis about whether \u03bc = 0, and the natural estimator for \u03bc is \u0232n = n\u22121 ni=1 Yi in\nthe unrestricted model, and 0 in the restricted model. A model-averaged estimator\nis \u03bc\u0302 = W (n1/2 \u0232n )\u0232n , for some weight W (*) \u2208 [0, 1]. Note that under a model with\ncontiguous alternatives \u03bctrue = n\u22121/2 \u03b4, the requirement that \u03bc\u0302 be consistent for\n\u03bctrue actually places no restriction on the weight W (*), which may take any value\np\nin [0, 1]. However, if we want consistency under arbitrary \u03bc, W (n1/2 \u0232n ) \u2192 1 is a\nrequirement.\np\n\nFor asymptotic normality, n1/2 \u03bc(1 \u2212 W (n1/2 \u0232n )) \u2192 0 and convergence in probap\nbility of W (n1/2 \u0232n ), are requirements. Under \u03bctrue , this implies that W (n1/2 \u0232n ) \u2192\n\n\f164\n\nS. Chatterjee and N. Mukhopadhyay\np\n\n1 must hold, while for general \u03bc, the stronger condition n1/2 (1 \u2212 W (n1/2 \u0232n )) \u2192 0\nmust be satisfied.\nUnder \u03bctrue , it is of interest to approximate the distribution of the standardized\nstatistic\n\u039bn = n1/2 (\u03bc\u0302 \u2212 \u03bctrue ) = n1/2 W (n1/2 \u0232n )\u0232n \u2212 \u03b4 = W (\u03b4 + Zn )(\u03b4 + Zn ) \u2212 \u03b4,\nwhere Zn \u223c N (0, 1).\nA natural question is what should be a bootstrap equivalent of \u039bn . Suppose\nY1\u2217 , . . . , Yn\u2217 are a random sample from the data Y1 , . . . , Yn . We consider the bootstrap equivalent of n1/2 \u0232n to be n1/2 (\u0232n\u2217 \u2212 \u0232n ), and not n1/2 \u0232n\u2217 . This is in keeping\nwith [4], who put forth the guideline that for good power performance, resampling\nmust be done to reflect the null hypothesis. While model selection is not in general\na hypothesis test, some of the same principles are applicable.\np\nHence, we have \u03bc\u0302\u2217 = W (n1/2 (\u0232n\u2217 \u2212 \u0232n ))\u0232n\u2217 . When 1 \u2212 W (n1/2 \u0232n ) \u2192 0, it can be\nreadily seen that the distribution of \u039b\u2217n = n1/2 (\u03bc\u0302\u2217 \u2212 \u03bc\u0302), conditional on Y1 , . . . , Yn ,\nand that of \u039bn converge to the same limit law.\nRemark 4.3. We conjecture that for the model-averaged estimator proposed in\nthis section, a result similar to [16] would hold. In the framework of this paper,\nthe statement\u0002 corresponding to\n\u0003 the main result of [16] would be as follows: Let\nFn,\u03b1,\u03b2 (t) = P n1/2 (\u03b1\u030c \u2212 \u03b1) \u2264 t , and let F\u0302n (t) be an estimator of Fn,\u03b1,\u03b2 (t) satisfying for every \u03b4 > 0 Pn,\u03b1,\u03b2 [| F\u0302n (t) \u2212 Fn,\u03b1,\u03b2 (t) |> \u03b4] \u2192 0, as n \u2192 \u221e. Then \u2203 \u03b40 > 0\nand \u03c10 > 0 such that\ni\nh\n(4.9)\nPn,\u03b1\u0303,\u03b2\u0303 | F\u0302n (t) \u2212 Fn,\u03b1\u0303,\u03b2\u0303 (t) |> \u03b40 \u2192 1;\nsup\n\u221a\n(\u03b1\u0303,\u03b2\u0303)\u2208B((\u03b1,\u03b2);\u03c10 / n)\n\nwhere\n\nB((\u03b1, \u03b2); a) = {(\u03b1\u0303, \u03b2\u0303) : ||(\u03b1\u0303, \u03b2\u0303) \u2212 (\u03b1, \u03b2)|| < a\n\nis the open ball of radius a around (\u03b1, \u03b2). It can be seen that under standard\n\u22121/2\n)\nconditions, if the supremum\n\u221a in (4.9) is taken over B((\u03b1, \u03b2); an ) with an = o(n\ninstead of B((\u03b1, \u03b2); \u03c10 / n), the limit would be zero instead of 1. Thus the result\nof [16] may be improved to the case where the supremum is taken only over the set\nof parameter values that are exact order n\u22121/2 away from the (\u03b1, \u03b2) under which\nthe estimator F\u0302n (*) is computed. This is easily verified, for example, when \u03b1 = 0,\n\u03c3 = 1 and Xt2 \u2261 1.\nNote that from a bootstrap approximation point of view, (4.9) is not a negative\nresult, but a very positive one. The uses of bootstrap approximation are for constructing interval estimates, testing hypotheses and so on. Equation (4.9) and other\nrelated results from [16] imply that a bootstrap approximation F\u0302n (*) constructed\nunder the \"null\" (\u03b1, \u03b2), has sup-norm distance of 1 from the true distributions\nunder parameter values that are exact order n\u22121/2 away from the (\u03b1, \u03b2). Thus\nF\u0302n (*) has power 1 in hypothesis testing under contiguous alternatives. This is a\nfurther confirmation of the tenet of [4], that resampling procedure ought to reflect\nthe null hypothesis.\nRemark 4.4. It is of interest to know that the asymptotic variance of \u03b1\u030c depends\non \u03b2, and is given by Var(n1/2 (\u03b1\u030c \u2212 \u03b1)) \u2212 Var(n1/2 (\u03b1\u0302(U ) \u2212 \u03b1)) \u2192 0 if \u03b2 6= 0, while\nVar(n1/2 (\u03b1\u030c\u2212\u03b1))\u2212{0.5 Var(n1/2 (\u03b1\u0302(U )\u2212\u03b1))+0.5 Var(n1/2 (\u03b1\u0302(R)\u2212\u03b1))} \u2192 0 if \u03b2 = 0.\nThis is established by checking that both \u03be1n and \u03be2n tend to 1/2 as n \u2192 \u221e when\n\u03b2 = 0. Thus \u03b1\u030c performs like the correct estimator \u03b1\u0302(U ) when model U is valid, and\nbalances between the correct and conservative choices when the restricted model R\nis true.\n\n\fModel uncertainty\n\n165\n\n5. A simulation example\nWe performed a small simulation experiment to illustrate some of the features of\ninference under model uncertainty that have been discussed in the previous sections.\nWe took n = 50, xi1 \u2261 1, and generated 50 numbers from the Uniform distribution\nsupported between zero and three and fixed these as the xi2 values. We fixed \u03b1 = 1,\nand varied the \u03b2 values.\nFor different values of \u03b2 \u2208 [\u22121, 1], we obtained sampling distribution approximations of (i) the post-model-selected estimator \u03b1\u0302MS , (ii) a version of the Bayesian\nmodel-averaged estimator \u03b1\u0302BMA , and (iii) an adaptive model-averaged estimator\n\u03b1\u0302AMA , by 5000 replications for each value of \u03b2. For the Bayesian model-averaged\nestimator, model R was assigned weight qnR = exp(\u2212BICR /2)/(exp(\u2212BICR /2) +\nexp(\u2212BICU /2)) while model U was assigned weight 1 \u2212 qnR . We define\nX\n2\nBICR =\n[Yi \u2212 \u03b1\u0302R xi1 ] + log(n),\ni2\nXh\nYi \u2212 \u03b1\u0302U xi1 \u2212 \u03b2\u0302U xi1 + 2 log(n).\nBICU =\n\nFor the adaptive model-averaged estimator, we took an = (log(n))2 .\nThe requirement that a\u22121\nn log(n) \u2193 0 suggests that an should be an increasing\nsequence, growing faster than log(n). Several choices of an were used initially, and\nit turned out that very slowly increasing sequences like an = (log(n))2 or very\nquickly increasing sequences like an = n0.499 performed better than others. This\nis a reflection on our way of constructing the functions \u03be1n and \u03be2n using \u03b31n and\n\u03b32n . Alternative choices, like \u03b31n = an |\u03b2\u0302(U )|{\u03b2\u0302(U )}\u22121 , are a subject for further\nresearch.\nThe first object of our study is the mean squared error of the three estimators of\n\u03b1, namely, \u03b1\u0302MS , \u03b1\u0302BMA , and \u03b1\u0302AMA . Panel (a) in Figure 1 contains the graphs of the\nmean squared error (MSE) as \u03b2 varies between [\u22121, 1]. In this and all subsequent\nfigures, the solid line corresponds to \u03b1\u0302BMA , the broken line to \u03b1\u0302MS , and the dotted\nline to \u03b1\u0302AMA . In this figure, we have also added the graph for the MSE of \u03b1\u0302(U ),\nwhich is the nearly horizontal dot-and-dash line. First, using model\n\u221a selection or averaging is clearly better than using \u03b1\u0302(U ) only in the region 0 \u00b1 2/ n \u2248 (\u22120.3, 0.3),\nwhere M S, BM A and AM A all perform better than \u03b1\u0302(U ). However, in the neighboring regions |\u03b2| \u2208 (0.3, 0.8), \u03b1\u0302(U ) has smaller MSE than the three estimators. For\nhigh values of |\u03b2|, using model selection/averaging or the unrestricted model makes\nlittle difference. Thus whether model averaging/selection is useful or not depends\nconsiderably on the value of \u03b2. Also note that BM A has a lower MSE compared to\nM S for low values of |\u03b2| and only marginally higher MSE otherwise, with a much\nlower maximum MSE value. The graph for AM A tends to stay closest to the graph\nfor \u03b1\u0302(U ), and thus does better than BM A or M S in the region |\u03b2| \u2208 (0.05, 0.75),\nbut is marginally poorer otherwise.\nIn order to study how the three estimators balance between \u03b1\u0302(R) and \u03b1\u0302(U ), we\ncomputed the Kolmogorov\u2013Smirnov distances KSjR and KSjU , between the distribution of n1/2 (\u03b1\u0302j \u2212 \u03b1), and the distributions of n1/2 (\u03b1\u0302R \u2212 \u03b1) and n1/2 (\u03b1\u0302U \u2212\n\u03b1), where j = M S, BM A, AM A (MS: model selected, BMA=Bayesian modelaveraged, AMA=adaptive model-averaged). We then computed the ratios\nKSRatioj = 100\n\nKSjR\n, j = M S, BM A, AM A.\nKSjR + KSjU\n\nUnder ideal circumstances, this ratio ought to be zero at \u03b2 = 0, and 100 for \u03b2 6= 0.\nPanel (b) in Figure 1 displays the KSRatioj values for the three estimators j =\n\n\f166\n\nS. Chatterjee and N. Mukhopadhyay\n\nFig 1. Panel (a) is the mean squared error of \u03b1\u0302BM A (solid line), \u03b1\u0302M S (broken line), \u03b1\u0302AM A (dotted line), and \u03b1\u0302(U ) (dot-and-dash line). Panel (b) is the ratio of Kolmogorov Smirnov distances\nKSRatioj = KSjR /(KSjR + KSjU ), j = M S, BM A, AM A, scaled by 100; between distributions\nof centered and scaled estimators and \u03b1\u0302(R) (for KSjR ) and \u03b1\u0302(U ) (for KSjU ).\n\nM S, BM A, AM A. When \u03b2 = 0, M S is closest to \u03b1\u0302R , while, as predicted, AM A\nbalances between \u03b1\u0302R and \u03b1\u0302U . The Bayesian model-averaged estimator BM\u221a\nA lies\nbetween M A and AM A, and is quite close to M S. In the region 0 \u00b1 2/ n \u2248\n(\u22120.3, 0.3) both M S and BM A are much closer to \u03b1\u0302R than \u03b1\u0302U .\nNext, we studied resampling for the three estimators. Subsampling with subsample size m = 20 = 0.4n and the bootstrap was studied. Note that subsampling is consistent for all three estimators, but the bootstrap is consistent only for\nAM A. Panels (a) ((b)) of Figure 2, respectively, present the Kolmogorov\u2013Smirnov\ndistance, scaled by 100, between the distributions of n1/2 (\u03b1\u0302j \u2212 \u03b1) and its subsampling (bootstrap)\nversion, j = M S, BM A, AM A. We present the graphs for\n\u221a\n|\u03b2| \u2264 0.4 \u2248 3/ n, since there is not much difference between the three graphs for\nother values of \u03b2. It can be seen that the distances between the actual distribution and its subsampling/bootstrap versions are much smaller for AM A, while the\nresampling approximations for M S and BM A are particularly bad in the regions\n{|\u03b2| \u2208 (0.1, 0.3)}. Also, there is little visual difference between the accuracies of the\nsubsampling and the bootstrap approximations despite their different asymptotic\nbehavior, which confirms some of the observations made in [1], [2] and [18].\n\n\fModel uncertainty\n\n167\n\nFig 2. Panel (a) is the subsampling approximation (subsample size 20) for the distribution of\ncentered and scaled \u03b1\u0302BM A (solid line), \u03b1\u0302M S (broken line), \u03b1\u0302AM A (dotted line). Panel (b) is the\ncorresponding bootstrap approximation.\n\n6. Discussion and conclusions\nThe problems associated with post-model-selection estimation have been discussed\nby several researchers. In current statistical practice, the process of selecting a\nmodel has similarities with hypothesis testing. On the other hand, estimation of\nparameters, some of which may be known constants in some of the models, is\ngenerally entirely separated from model selection. Estimation and testing/selection\nare two different paradigms of statistical analysis that are hard to integrate. The\nlack of uniformity across models that parameter estimators generally display, and\nthe issues that arise subsequently, are products of the less than successful attempt\nto combine the two processes of estimation and selection.\nIn the Bayesian paradigm, model averaging seems to be a good integration of\nthe two, since the selection step here is also an estimation exercise in spirit. The\nstatement about integrated risks in Proposition 3.1 implies that Bayes' risks of\nmodel-averaged estimators are bounded. Thus, while minimaxity seems to be an\nelusive goal under model uncertainty, a fully Bayesian approach to analyzing risk\nbehavior may be more successful.\nIn the context of bootstrapping model-averaged estimators, an alternative to \u03b1\u030c\n\n\f168\n\nS. Chatterjee and N. Mukhopadhyay\n\nis to estimate the bias in \u03b1\u0302 in all the models, and define a bias corrected average\nof these. As the bias of \u03b1\u0302(R) is \u03b2||X1 ||\u22121 < X1 , X2 >, if we estimate this by\n\u03b2\u0302||X1 ||\u22121 < X1 , X2 >, we get back \u03b1\u0302(U ). Nevertheless, in more complex problems\nthe \"bias corrected model averaged\" estimator may be an interesting object to\nstudy.\nIn Theorem 4.1 we established the consistency of the paired bootstrap for a dataadaptive model-averaged estimator. Two other kinds of bootstrap are available in\nthe linear regression context; namely, parametric bootstrap and the residual-based\nbootstrap. When only one model is in use, the parametric bootstrap generates\ndata from it using estimated values for the unknown parameters, while the residual\nbootstrap obtains residuals after fitting the model. The equivalents of these are not\nobvious under model uncertainty.\nIn Section 4 we remarked that the data adaptive weights pnR and pnU may\nnot share the same properties as the posterior model probabilities \u03c0nR and \u03c0nU of\nSection 3. It would be interesting to study when pnR and pnU can be interpreted as\nposterior probabilities, and also under what conditions the frequentist properties\nof a Bayesian model-averaged estimator may be elicited using the bootstrap.\nAcknowledgments. Professor Chatterjee's research was partially supported by\na grant from the University of Minnesota. We thank the referee and the editors of\nthis monograph for some excellent comments and suggestions. Also, we would like\nto thank Professor Yuhong Yang, who carefully read an earlier draft of this paper\nand made several comments; which, along with several illuminating discussions,\ngreatly enhanced our understanding on the scope and issues relating to model\nselection/averaging.\nReferences\n[1] Andrews, D. W. K. and Guggenberger, P. (2005). Hybrid and sizecorrected subsample methods. Cowles Foundation discussion paper # 1605.\n[2] Andrews, D. W. K. and Guggenberger, P. (2005). The limit of finite\nsample size and a problem with subsampling. Cowles Foundation discussion\npaper # 1606.\n[3] Chatterjee, S. and Bose, A. (2000). Variance estimation in high dimensional regression models. Statist. Sinica 10 497\u2013515. MR1769754\n[4] Hall, P. and Wilson, S. R. (1991). Two guidelines for bootstrap hypothesis\ntesting. Biometrics 47 757\u2013762. MR1132543\n[5] Hjort, N. L. and Claeskens, G. (2003). Frequentist model average estimators. J. Amer. Statist. Assoc. 98 879\u2013899. MR2041481\n[6] Leeb, H. (2006). The distribution of a linear predictor after model selection:\nunconditional finite sample distributions and asymptotic approximations. IMS\nLecture Notes Monograph Series 49 291\u2013311. MR2338549\n[7] Leeb, H. and P\u00f6tscher, B. M. (2003). The finite sample distribution of\npost-model-selection estimators and uniform versus non-uniform approximations. Econometric Theory 19 100\u2013142. MR1965844\n[8] Leeb, H. and P\u00f6tscher, B. M. (2005). Model selection and inference: facts\nand fiction. Econometric Theory 21 21\u201359. MR2153856\n[9] Leeb, H. and P\u00f6tscher, B. M. (2006). Performance limits for the estimators\nof the risk or distribution of shrinkage type estimators, and some general lower\nrisk bound results. Econometric Theory 22 69\u201397. MR2212693\n\n\fModel uncertainty\n\n169\n\n[10] Leeb, H. and P\u00f6tscher, B. M. (2006). Can one estimate the conditional\ndistribution of post-model-selection estimators? Ann. Statist. 34 2554\u20132591.\nMR2291510\n[11] Leung, G. and Barron, A. R. (2006). Information theory and mixing least\nsquares regressions. IEEE Trans. Inform. Theory 52 3396\u20133410. MR2242356\n[12] Mammen, E. (1992a). Bootstrap, wild bootstrap and asymptotic normality.\nProbab. Theory Related Fields 93 439\u2013455. MR1183886\n[13] Mammen, E. (1992b). When Does Bootstrap Work: Asymptotic Results and\nSimulations. Springer, Berlin.\n[14] Politis, D. N., Romano, J. P. and Wolf, M. (1999). Subsampling.\nSpringer, New York. MR1707286\n[15] P\u00f6tscher, B. M. (1991). Effects of model selection on inference. Econometric\nTheory 7 163\u2013185. MR1128410\n[16] P\u00f6tscher, B. M. (2006). The distribution of model averaging estimators and\nan impossibility result regarding its estimation. MPRA paper # 73.\n[17] Raftery, A. E. and Zheng, Y. (2003). Comment on \"Frequentist model\naverage estimators,\" by N. L. Hjort and G. Claeskens. J. Amer. Statist. Assoc.\n98 931\u2013938. MR2041481\n[18] Samworth, R. (2003). A note on methods of restoring consistency to the\nbootstrap. Biometrika 90 985\u2013990. MR2024773\n[19] Sethuraman, J. (2004). Are super-efficient estimators super-powerful?\nComm. Statist. Theory and Methods 33 2003\u20132013. MR2103058\n[20] Shen, X. and Dougherty, D. P. (2003). Discussion of \"Frequentist model\naverage estimators,\" by N. L. Hjort and G. Claeskens. J. Amer. Statist. Assoc.\n98 917\u2013919. MR2041481\n[21] Yang, Y. (2003). Regression with multiple candidate models: selecting or\nmixing? Statist. Sinica 13 783\u2013809. MR1997174\n[22] Yang, Y. (2004). Aggregating regression procedures to improve performance.\nBernoulli 10 25\u201347. MR2044592\n[23] Yang, Y. (2005). Can the strengths of AIC and BIC be shared? A conflict\nbetween model identification and regression estimation. Biometrika 92 937\u2013\n950. MR2234196\n[24] Yang, Y. (2007). Prediction/estimation with simple linear model: is it really\nthat simple? Econometric Theory 23 1\u201336. MR2338950\n[25] Yuan, Z. and Yang, Y. (2005). Combining linear regression models: when\nand how? J. Amer. Statist. Assoc. 100 1202\u20131214. MR2236435\n\n\f"}