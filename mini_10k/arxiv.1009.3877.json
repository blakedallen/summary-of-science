{"id": "http://arxiv.org/abs/1009.3877v1", "guidislink": true, "updated": "2010-09-20T16:27:07Z", "updated_parsed": [2010, 9, 20, 16, 27, 7, 0, 263, 0], "published": "2010-09-20T16:27:07Z", "published_parsed": [2010, 9, 20, 16, 27, 7, 0, 263, 0], "title": "Software for physics of tau lepton decay in LHC experiments", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1009.2220%2C1009.5286%2C1009.3428%2C1009.3877%2C1009.1368%2C1009.3764%2C1009.0524%2C1009.2296%2C1009.1542%2C1009.3230%2C1009.1098%2C1009.1258%2C1009.5005%2C1009.3973%2C1009.1689%2C1009.6211%2C1009.0851%2C1009.4558%2C1009.1130%2C1009.6036%2C1009.0037%2C1009.1951%2C1009.2536%2C1009.2104%2C1009.0111%2C1009.1502%2C1009.0578%2C1009.2286%2C1009.2213%2C1009.1816%2C1009.5676%2C1009.3528%2C1009.0525%2C1009.0504%2C1009.0193%2C1009.4587%2C1009.3831%2C1009.2156%2C1009.4433%2C1009.1870%2C1009.0763%2C1009.1863%2C1009.3972%2C1009.3517%2C1009.0097%2C1009.4454%2C1009.0486%2C1009.5281%2C1009.4803%2C1009.3570%2C1009.0158%2C1009.3273%2C1009.1713%2C1009.2753%2C1009.3519%2C1009.4247%2C1009.1285%2C1009.3854%2C1009.4828%2C1009.2746%2C1009.0098%2C1009.4723%2C1009.3437%2C1009.3733%2C1009.1663%2C1009.1614%2C1009.5804%2C1009.2938%2C1009.1160%2C1009.4837%2C1009.6218%2C1009.2935%2C1009.3238%2C1009.2087%2C1009.2777%2C1009.4281%2C1009.3943%2C1009.5932%2C1009.3792%2C1009.1867%2C1009.3735%2C1009.2713%2C1009.6183%2C1009.0470%2C1009.1989%2C1009.2562%2C1009.1200%2C1009.0892%2C1009.1012%2C1009.1758%2C1009.4999%2C1009.1737%2C1009.4541%2C1009.3828%2C1009.5908%2C1009.0274%2C1009.2009%2C1009.1450%2C1009.4741%2C1009.5892%2C1009.0928&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Software for physics of tau lepton decay in LHC experiments"}, "summary": "Software development in high energy physics experiments offers unique\nexperience with rapidly changing environment and variety of different standards\nand frameworks that software must be adapted to. As such, regular methods of\nsoftware development are hard to use as they do not take into account how\ngreatly some of these changes influence the whole structure. The following\nthesis summarizes development of TAUOLA C++ Interface introducing tau decays to\nnew event record standard. Documentation of the program is already published.\nThat is why it is not recalled here again. We focus on the development cycle\nand methodology used in the project, starting from the definition of the\nexpectations through planning and designing the abstract model and concluding\nwith the implementation. In the last part of the paper we present installation\nof the software within different experiments surrounding Large Hadron Collider\nand the problems that emerged during this process.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1009.2220%2C1009.5286%2C1009.3428%2C1009.3877%2C1009.1368%2C1009.3764%2C1009.0524%2C1009.2296%2C1009.1542%2C1009.3230%2C1009.1098%2C1009.1258%2C1009.5005%2C1009.3973%2C1009.1689%2C1009.6211%2C1009.0851%2C1009.4558%2C1009.1130%2C1009.6036%2C1009.0037%2C1009.1951%2C1009.2536%2C1009.2104%2C1009.0111%2C1009.1502%2C1009.0578%2C1009.2286%2C1009.2213%2C1009.1816%2C1009.5676%2C1009.3528%2C1009.0525%2C1009.0504%2C1009.0193%2C1009.4587%2C1009.3831%2C1009.2156%2C1009.4433%2C1009.1870%2C1009.0763%2C1009.1863%2C1009.3972%2C1009.3517%2C1009.0097%2C1009.4454%2C1009.0486%2C1009.5281%2C1009.4803%2C1009.3570%2C1009.0158%2C1009.3273%2C1009.1713%2C1009.2753%2C1009.3519%2C1009.4247%2C1009.1285%2C1009.3854%2C1009.4828%2C1009.2746%2C1009.0098%2C1009.4723%2C1009.3437%2C1009.3733%2C1009.1663%2C1009.1614%2C1009.5804%2C1009.2938%2C1009.1160%2C1009.4837%2C1009.6218%2C1009.2935%2C1009.3238%2C1009.2087%2C1009.2777%2C1009.4281%2C1009.3943%2C1009.5932%2C1009.3792%2C1009.1867%2C1009.3735%2C1009.2713%2C1009.6183%2C1009.0470%2C1009.1989%2C1009.2562%2C1009.1200%2C1009.0892%2C1009.1012%2C1009.1758%2C1009.4999%2C1009.1737%2C1009.4541%2C1009.3828%2C1009.5908%2C1009.0274%2C1009.2009%2C1009.1450%2C1009.4741%2C1009.5892%2C1009.0928&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Software development in high energy physics experiments offers unique\nexperience with rapidly changing environment and variety of different standards\nand frameworks that software must be adapted to. As such, regular methods of\nsoftware development are hard to use as they do not take into account how\ngreatly some of these changes influence the whole structure. The following\nthesis summarizes development of TAUOLA C++ Interface introducing tau decays to\nnew event record standard. Documentation of the program is already published.\nThat is why it is not recalled here again. We focus on the development cycle\nand methodology used in the project, starting from the definition of the\nexpectations through planning and designing the abstract model and concluding\nwith the implementation. In the last part of the paper we present installation\nof the software within different experiments surrounding Large Hadron Collider\nand the problems that emerged during this process."}, "authors": ["Tomasz Przedzinski"], "author_detail": {"name": "Tomasz Przedzinski"}, "author": "Tomasz Przedzinski", "arxiv_comment": "Thesis submitted to Applied Computer Science Department in partial\n  fulfillment of the requirements for the MSc degree. This work is partially\n  supported by EU Marie Curie Research Training Network grant under the\n  contract No. MRTN-CT-2006-0355505, Polish Government grant N202 06434\n  (2008-2011) and EU-RTN Programme: Contract No. MRTN-CT-2006-035482\n  'Flavianet'", "links": [{"href": "http://arxiv.org/abs/1009.3877v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.3877v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "hep-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "hep-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.SE", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.3877v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.3877v1", "journal_reference": null, "doi": null, "fulltext": "Jagiellonian University\nCracow\nFaculty of Physics, Astronomy\nand Applied Computer Science\n\nSoftware for physics of tau lepton\ndecay in LHC experiments\nTomasz Przedzioski\n\nThesis submitted to Applied Computer Science Department\nin partial fulfillment of the requirements for the MSc degree\nunder supervision of prof. dr hab. Zbigniew W\u0105s.\n\nCracow, June 2010\n\n\fAbstract\nSoftware development in high energy physics experiments offers unique\nexperience with rapidly changing environment and variety of different\nstandards and frameworks that software must be adapted to. As such, regular methods of software development are hard to use as they do not take\ninto account how greatly some of these changes influence the whole structure. The following thesis summarizes development of TAUOLA C++ Interface introducing decays to new event record standard. Documentation of the program is already published. That is why it is not recalled here\nagain. We focus on the development cycle and methodology used in the\nproject, starting from the definition of the expectations through planning\nand designing the abstract model and concluding with the implementation.\nIn the last part of the paper we present installation of the software within\ndifferent experiments surrounding Large Hadron Collider and the problems\nthat emerged during this process.\n\n* This work is partially supported by EU Marie Curie Research Training Network grant under the contract No. MRTN-CT-2006-0355505, Polish Government grant N202 06434 (2008-2011) and EU-RTN\nProgramme: Contract No. MRTN-CT-2006-035482, 'Flavianet'.\n\n\fAcknowledgements\nI would like to thank my advisor and the head of the development team, prof. Zbigniew W\u0105s, who gave me a chance to\ntake part in this project. This thesis and the project itself would\nnot be possible without his patience and guidance.\nI am grateful El\u017cbieta Richter-W\u0105s for introducing me to\nhigh energy physics and for her help during last three years. I\nwould also like to thank Nadia Davidson and Gizo Nanava for\ntheir cooperation in project development.\nIt would not be possible to finish the project without the\nhelp of Piotr Golonka and all devoted users, in particular Anna\nKaczmarska, Dmitri Konstantinov, Sami Lehti, Eric Torrence, Marcin Wolter Julia Yarba and Oleg Zenin.\n\n\fContents\n\n1.\n\nOverview ............................................................................................ 2\n1.1\n1.2\n1.3\n\n2.\n\nIntroduction.......................................................................................................... 2\nThe black-box approach ....................................................................................... 3\nMain goals ............................................................................................................ 4\n\nStarting point ..................................................................................... 5\n2.1\n2.2\n2.3\n2.4\n2.5\n2.6\n2.7\n\n3.\n\nSoftware in high energy physics ........................................................................... 5\nDescription of FORTRAN TAUOLA..................................................................... 6\nApplying electroweak corrections ........................................................................ 6\nHepMC event record ............................................................................................ 6\nEvent record standard .......................................................................................... 8\nTesting routine ..................................................................................................... 8\nMC-TESTER ...................................................................................................... 10\n\nAbstract algorithm ............................................................................11\n3.1\n3.2\n3.3\n\n4.\n\nSoftware structure ............................................................................................. 12\nAlgorithm outline ............................................................................................... 13\nDecay tree structure........................................................................................... 14\n\nImplementation ................................................................................16\n4.1\n4.2\n4.3\n4.4\n4.5\n4.5.1\n4.5.2\n4.5.3\n4.5.4\n4.5.5\n4.5.6\n\n5.\n\nMethodology ...................................................................................................... 16\nSpin correlations................................................................................................. 19\nElectroweak corrections ..................................................................................... 20\nFORTRAN TAUOLA interface ........................................................................... 22\nUser configuration .............................................................................................. 23\nDecaying Particle ......................................................................................... 23\nDecay mode selection ................................................................................. 24\nSpin correlations options ............................................................................ 25\nRadiative correction .................................................................................... 25\nDecay of final state scalars .......................................................................... 26\nHelicity states and electroweak correcting weight..................................... 26\n\nNumerical tests and physics results ...................................................27\n5.1\n5.3\n\n5.6\n\n6.\n\nBasic tests ........................................................................................................... 27\n.................................................................................................. 28\n.............................................................................................. 28\n.................................................................... 30\n.................................................................. 31\nTesting \u03c4 decays .................................................................................................. 33\n\nInstallation and user interaction........................................................33\n6.1\n6.2\n6.3\n6.4\n6.5\n\nATLAS .................................................................................................................. 34\nCMS..................................................................................................................... 35\nLCG database ...................................................................................................... 36\nUser feedback..................................................................................................... 36\nFuture plans........................................................................................................ 37\n\n7.\nSummary ...........................................................................................38\nBibliography ..................................................................................................40\n\n1\n\n\f1.\n\nOverview\n\n1.1\n\nIntroduction\n\nHigh energy physics offer excellent environment for understanding development of large\nsoftware engineering projects. The development process changes rapidly as even the team\nresponsible for the project may completely change during software development. Consequently, the development time becomes inappropriately large in comparison to the short\nlifetime of the software version use, creating problems that even agile software development methodologies cannot resolve. At the same time, history of the projects is usually large\nand often extends over decades. The style of the code differs from one part to another and a\nlarge amount of testing procedures, as well as old versions of the algorithms, still remain in\nthe code, commenting not only the algorithm itself but its history of changes and prototypes\nfor future as well. That is why adapting to new technology or rewriting the code to new programming language becomes a hard task. The tests needs to be redone and new members of\nthe team need to learn all the basics regarding the project. Some parts of the original comments must remain intact, as they might be needed in future. It requires a lot of work, which\ninvalidates previously written documentation and leads to loss of experience invested so far.\nThat is why such decisions should be made only when it is absolutely necessary for the survival of the project.\nThe project management also differs from commercial applications, as there is no central\nmanagement regarding its content or financial aspect. It is a challenge for community exceeding sometimes even thousand people. The crucial element in development of project\nspanning many years of work is training new members and wise distribution of their acquired knowledge.\nMy work, as a trainee in such team, focused on the project regarding physics aspect of \u03c4 lepton production and decay as well as creation of tests of Monte Carlo generators. I often had\nto follow other people designs thus my understanding of the work style became clear later in\nthe project. In fact, it became more apparent during my work on the thesis itself. That is also\na reason why some parts of this project I do not fully understand. For example, I have not\ngained experience in software transformation related to evolution of physics model and\nproblems related to it. It comes from the lack of experience and the fact that I was participating in only a step of the whole project development. In result the reason for decisions\nregarding the relation between FORTRAN code or the electroweak corrections module and\nthe C++ interface were, for a longer time, not clear to me. Nonetheless, I blindly had to follow the design only to realize motivation behind these decisions later, as my understanding\nof the project background and the uniqueness of environment for which the project was\nintended expanded.\nThis thesis summarizes effort documented in reference [1], describing development of a\nmodule implementing \u03c4 decays into a simulation chain. It is also an attempt to explain software development strategies used in this project and to point out similarities between methodology used during development cycle and agile approach.\nReference [1] represents the fundaments of this thesis and documents the results of work of\nour team on TAUOLA C++ interface. Reference [2] describes a new version of MC-TESTER,\nwhich was a crucial testing tool used in creation of this project. Reference [3] describes the\npossible future extensions to this work. I am a co-author of these three references. The con-\n\n2\n\n\ftent of [2] and [3] will not be described here. I will not present documentation of the program I was developing, it is documented in reference [1]. My thesis will be focused on general scheme applied in the work. In this respect it can be understood as continuation of effort by P. Golonka [4] to systematize the approach in program development. An outline of\nthe PHOTOS C++ Interface presented in [5] regards the next activity in High energy physics in\nwhich I will be taking part. Both MC-TESTER and PHOTOS has already been subject of extensive studies [4 pp. 149-167, 193-205] and will not be the subject of this paper. The base\nof the project, TAUOLA FORTRAN, is well-known, fully developed software used by a\nrange of specialists. This work will be focused on the planning and development strategy\nused to create TAUOLA C++ interface introducing new C++ event record, new functionality\nand new physics process to generation sequence of \u03c4 decay. Let me follow with a citation\nfrom an introduction to reference [1].\n1.2\n\nThe black-box approach\n\nIn the present day experiments at High energy physics accelerators, interpretation of results\nbecomes increasingly involved. Not only the detector response is complex, but also some\ntheoretical effects need to be removed. Otherwise, results are difficult to interpret for the\nnon-specialist. For that purpose the concept of work with realistic and idealized observables\nwas introduced as well as finally with pseudo-observables which can be easily understood by\ntheorists, such as W, Z masses or couplings. Good examples of such approaches were measurements of the two-fermion final states at LEP. Because of increasing precision of the experimental measurements, definitions of quantities to be measured, simple at first, later\nevolved into several options [6], each based on the properties of individual detectors and\neach requiring individual discussion of the systematic error. One could assume that if all\ntheoretical effects are embodied into one theoretical black-box and, experiments while using it tune parameters (representing pseudo-observables) to the data, interpretation of the\nobserved effects could be separated into theoretical and experimental components. Unfortunately, this strategy is limited, as it leaves little room for cases where theory and experimental effects are convoluted: size and even nature of the theoretical corrections depend on\nthe experimental conditions. Such discussion on observables involving \u03c4 decays can be found\nin [7]. Recently, discussion for the physics of \u03c4 production and decay at low energies where\nsimilar aspects are addressed, was presented in [3].\nFor LHC experiments, \u03c4 decays themselves are not of primary interest, but rather will be\nused to measure properties of \u03c4 production processes. Physics effects necessary for the prediction of hard processes at the LHC experiments can be separated into several parts, among\nthem: parton showers, the underlying event and structure functions, final state QED\nbremsstrahlung, QED bremsstrahlung interference between initial and final states and finally\nthe hard process including electroweak corrections. Such separation is not only for the convenience of organizing theoretical work but also provides efficient and flexible component in\nthe framework for experimental data analysis strategy (see e.g. [8]). Some of such building\nblocks are of genuine theoretical interests; some others are not so much. The hard process\nusually depends on the parameters intended for the measurement, e.g. W or Higgs mass or\nnew coupling constants. Other building blocks may be less interesting; nonetheless, they\nmay affect the results of measurements. This is certainly true in the case of the underlying\nevent or missing transverse energy or\ndistributions generated from parton showers [6]. It\nmay also be the case for QED final state bremsstrahlung or initial-final state interference,\n\n3\n\n\fwhere potential difficulties may be expected [9] and predictions may need to be fixed with\nthe help of experimental data.\nThe black-box approach, where all simulation segments are put together by theorists, may\nlook advantageous to the experimental user. However, in such a case one has less flexibility\nto distinguish experimental effect from the theoretical ones, thus limiting control on the\nsystematic errors. The particular problems may be left unnoticed. Typically, the difficulties\nwill not affect all observables. Unfortunately, complications tend to show up only when\nmore detailed discussion on the systematic errors of experimental analysis is performed.\n1.3\n\nMain goals\n\nThe most important goal of this project is to introduce the software for \u03c4 decays to different\nexperiments environments while still allowing low energy physicists to modify the core of\nthe project. In order to do it, the main engineering goal is to adopt existing FORTRAN code\nto new C++ even records, so that it can be attached to any Monte-Carlo program where \u03c4's\nare generated. The project will focus on adapting to HepMC event record [10], as it seems\nthat HepMC will remain a generally accepted standard for data structure used in phenomenology of high energy physics for the near future. HepMC introduces new data structure as\nwell as new exceptions that need to be handled. Thanks to new event records, introducing \u03c4\ndecays to simulation will become more flexible than its FORTRAN predecessor. It will allow\nextending generation procedure with electroweak corrections and algorithms for handling of\nweighted events.\nSince the slightest change in the code may influence numerical results of the existing Monte\nCarlo generator, it is important to organize a good testing environment. A wide range of\ntests will be needed in order to validate that the communication with the FORTRAN code is\ncorrect as well as the output produced in different event record is acceptable. Since the base\nof the tests for FORTRAN TAUOLA already exists, these tests will have to be moved to C++.\nMoreover, for each new feature introduced to the original generation process a new set of\ntests will be needed as well. Using new environment and new event record a wide range of\nnew tests can be performed for further validation of \u03c4 decays1.\nThe most challenging task will be to coordinate the work between people of different fields\nof expertise. The development will require cooperation with people from different countries\nand living in different time zones, which must be included during the planning. As soon as\nthe first version of the code is present, software will need to be set up under several testing\nenvironments of different experiments, therefore a user friendly, flexible installation procedure will be needed. We have decided to use autoconf [11] as a mean to create configuration procedure for wide range of platforms. Automake scripts has been provided as an alternative method of installation.\nFinally, both the code and the physics content of the software require extensive documentation and the webpage used for promotion. This will be achieved using doxygen [12] software\nallowing automatic generation of source code documentation and introducing an easy way\nto build a front page of the website. Thanks to this, after setting up an SVN repository, we\ncan automatically create a new release archive that can be distributed to pilot users.\n\n1\n\nThese tests may represent starting point for some physics analysis where detector effects are taken into account, see e.g. [37].\n\n4\n\n\f2.\n\nStarting point\n\n2.1\n\nSoftware in high energy physics\n\nThe LHC Computing Grid (LCG) software database stores hundreds of projects, millions lines\nof code. It is designed to help distribute new versions of code for projects, like ours, within\nexperiments surrounding LHC. Internally, collaborations have their own way of supporting\nexternal packages. Integrating a new program designed to cooperate with several already\nexisting projects introduces a list of dependencies that have to be taken into account and\neach of them can create a potential problem. The logical structure of these projects can\nsometimes be very hard to understand and in most cases should not be studied at all. One of\nthe tasks is to decide which parts of the vast amount of knowledge considering these\nprojects are actually relevant to the project and need to be learned, which in most cases is\nvery hard to find out.\nThe target users for the software are physicists interested in analysis of \u03c4 production. This\nelement has to be taken into account when writing the code of the project, as the code directed to physicists is different from the regular, commercial code. In most cases, there is no\nneed for the user to modify any aspect of the code, as the user is more interested in the\ncomplete product itself. In case of High energy physics the approach is exactly opposite than\nthe one expected. The code should be written in such way that the physicists with a basic\nprogramming knowledge should be able to understand the crucial parts of the algorithms\nand modify it if needed. That is why most of the projects contain a lot of obsolete code or\neven hundreds of lines commented out to serve as information on how the project evolved\nor how different solutions can be applied. Such comments may in future prove to be very\nuseful for modifying or debugging the code.\nThat being said, even if better methods of writing the code structure or the algorithm exists,\nthe clarity of the code and flexible modification of its parts gets the priority over the cleaning\nand optimization. This concern the basic data structure as well since the most optimal method of storing the information might not be as clear as the one that is closest to physical\nmodel. The aim of designing such data structure is to balance the performance of the code\nwith its ease of modification, emphasizing the latter rather than the former aspect. However, in most cases, this compromise is hard to achieve and parts of the code remain in disarray, which might confuse future reader. Having read a lot of source code from such projects,\nI have realized that rough, puzzling code is one of the aspects of these projects that cannot\nbe avoided. Even though it was hard to accept at first, I have learned that in case of High\nenergy physics software, the best solution is not always the right one, but more importantly\n\u2013 that the code that is easily readable by the programmer is not easily read by a physicist\nand vice versa.\nApart from that, the development of the software is mixed with the progress of the testing\nenvironment build throughout the project development as well as physics model itself. Since\nthe basic model is often based on insufficient assumptions, new aspects must be introduced\nas soon as part of the model changes which greatly influence the development cycle. Considering that such projects have a limited number of testers, it is very hard to detect bugs introduced by such frequent changes.\n\n5\n\n\fAll of the problems presented above affect both planning and development of the project\nand are the reasons why the strategy used in this project differs from any known methodology.\n2.2\n\nDescription of FORTRAN TAUOLA\n\nFor the purpose of generation of \u03c4 decays themselves, the TAUOLA library, as described in\n[13; 14; 15] is used. This part of the code is expected to be a black-box for the High Energy\nexperimental user. At present, from the technical side, the black-box consists of the same\nFORTRAN code as described in [16]. Such organization makes it easy for low energy phenomenologists or experimentalists to continue their work on this part of the code, such as\nthe activities proposed by us in [3], leading to the new parameterization of hadronic \u03c4 decay\ncurrents becoming available for High Energy experimental users in a rather straightforward\nway.\nThere is virtually no gain in rewriting the FORTRAN TAUOLA to C++, while on the other side\nsuch activity could lead to number of errors and would require a large amount of time dedicated to testing and documenting newly introduced changes. Keeping the code in FORTRAN\nallows the base of users of previous versions of TAUOLA to be able to modify appropriate\naspects of the generator while introducing new functionality through the interface to C++\nevent records. Since we expect FORTRAN part of the code to be modified by low energy\nphysicists, the decision was made to leave TAUOLA FORTRAN intact especially that this arrangement does not pose any troubles for development of the interface.\nThe interface will overwrite filhep_ method for event record I/O, changing the event\nrecord used by TAUOLA FORTRAN and use decay_ method for generating \u03c4 decays. It will\nalso need several common blocks along with their accessors for initialization and setup. The\nsummary of all FORTRAN methods used in the project is located in Appendix of reference\n[1].\n2.3\n\nApplying electroweak corrections\n\nPhysics of spin correlations in \u03c4 pair productions is defined since long. Principles of the necessary algorithms are given in reference [13]. Nothing new is necessary for today applications. However, density matrix for the produced \u03c4 pair must be provided. In our interface\nexample density matrices for basic processes of interest at LHC are given. This is in most cases sufficient, however in case of \u03c4 pair production through intermediate Z and virtual gamma\nborn level predictions are not sufficient. This is known since KKMC [17] or even KORALZ [18]\ntimes, as in these cases one needs a method to calculate \u03c4 pair density matrix including electroweak corrections.\nFortunately, specialized libraries like SANC [19] exist. With their help density matrix as a\nfunction of incoming quark or lepton flavour center of mass energy and angle can be calculated. Such algorithms have already been created in FORTRAN and extensively used by\nKORALZ and KKMC. Using experience from these projects, a separate module will be\ncreated introducing electroweak corrections to the interface.\n2.4\n\nHepMC event record\n\nAs stated in reference [1], in adapting both TAUOLA and MC-TESTER to the C++ event\nrecord format the difference between the HEPEVT event record used in the FORTRAN ver-\n\n6\n\n\fsion of TAUOLA interface and HepMC event record that is used for the C++ based interface\nhas to be taken into account. In the first case, the whole event was represented by a common block containing a list of particles with their properties and with integer variables denoting pointers to their origins and descendants. The HepMC event structure is built from\nvertices, each of them having pointers to their origins and descendants. Links between vertices represent particles or fields. In both, FORTRAN and C++ cases, the event is structured\nas a tree2 the necessary algorithms are analogous, but nonetheless different.\nIn HepMC, an event is represented by a GenEvent object, which contains all information\nregarding itself, including event id, units used for dimensional quantities in the event and the\nlist of produced particles. The particles themselves are grouped into GenVertex objects\nallowing access to mother and daughter particles of a single decay. Vertices provide an easy\nway to point to the whole branch in a decay tree that needs to be accessed, modified or deleted if needed. The information of a particle itself is stored in a GenParticle object containing the particle id, status and momentum as well as information needed to locate its\nposition in the decay tree. This approach allows traversing the event record structure in several different ways.\nIn general, event record represents a tree structure, however due to physics constraints\nthere are options that break this rule. In case of theoretical simulation, when writing to\nevent record, some Monte Carlo generators include extra information regarding the decay\nprocess. While normally such information might be helpful to determine what exactly happened during event generation, the additional information might be misleading requiring the\nalgorithms to account for such generator behavior. In case of experimental data, the event\nstructure must be reconstructed using data taken from different types of detectors. The\noutput might not always represent a consistent structure, as there is always a possibility of\nan error during reconstruction step. Such special cases of event record structures require\nextensive attention. From a point of view of a software engineer, some of them might look\nsimilar to numerical error or a faulty algorithm routine, which is why such errors should be\nanalyzed both from physics and from algorithmic point of view.\nThe HepMC event record format is evolving with time, making it necessary to adapt the code\nto the new versions. The project started with HepMC version 2.03; however, the present\nversion 2.05 already introduced several differences to how the event record is stored, such\nas the different standards of units used to represent particle momentum or vertex position\nin space. This example further emphasizes on need to divide the event record from the physics content of the software.\nSeeing as different standards are quickly becoming more specialized, we have also envisaged\nthe possibility that HepMC may one day be replaced by another standard of event record,\nand we have provided an easy way to extend the interface to a possible new event record\nstandard.\nFor this purpose, an abstract interface will be created containing full functionality of \u03c4 decays. It will be then extended for HepMC event record and for any other event record that\nmight be needed in future. The advantage writing in an object oriented programming style\nallows us to create a modular solution handling any possible future exceptions.\n2\n\nAt least in principle, because in practice its properties may be rather of the graph of not universally defined\nproperties. This makes our task challenging.,\n\n7\n\n\fEvent record standard\n\n2.5\n\nEvolution of the HepMC format itself is not a crucial problem. In contrary, conventions how\nphysics information is filled into HepMC represent the source of main technical and physics\nchallenge for our interface.\nWhile many Monte Carlo generators (e.g. PYTHIA 8.1[20], HERWIG++ [21]) store events\nin HepMC format, the representations of these events are not subject to strict standards,\nwhich can therefore vary between Monte Carlo generators or even physics processes. Some\nexamples of these variations include the conventions of status codes, the way documentary\ninformation on the event is added, the direction of pointers at a vertex and the conservation\n(or lack of conservation) of energy-momentum at a vertex.\nBelow is a list of properties for basic scenario we have observed in Monte Carlo generators\nused for testing the code. This list serves as a declaration for convention of HepMC filling,\nwhich the interface should be able to interpret correctly.\n\uf0b7\n\uf0b7\n\uf0b7\n\n4-momentum conservation is assumed for all vertices in the event record.\nStatus codes: only information whether given particle is incoming, outgoing or intermediate will be used,\nPointers at a vertex are assumed bi-directional. That is, it is possible to traverse the\nrecord structure from mother to daughter and from daughter to mother along the\nsame path.\n\nDetailed conventions for the actual filling of physics information into HepMC format is defined by authors of each Monte Carlo program. Usually they modify some of the above\nproperties.\nIn future, an important special case of event records filling with information extracted from\nexperimentally observed event (e.g.\nmodified later to\n) should be allowed. Obviously, a new type (or types) of HepMC filling will then appear.\n2.6\n\nTesting routine\n\nFor testing purposes, we have focused our attention on PYTHIA 8.1 universal Monte Carlo\ngenerator. As written in introduction to its documentation[20]: The PYTHIA program is a\nstandard tool for the generation of high-energy collisions, comprising a coherent set of physics models for the evolution from a few-body hard processes to a complex multihadronic final\nstate. It contains a library of hard processes and models for initial and final state parton\nshowers, multiple parton-parton interactions, beam remnants, string fragmentation and particle decays. It also has a set of utilities and interfaces to external programs. In particular,\nPYTHIA 8.1 can produce output in HepMC event record format. The simulation routine\nused by PYTHIA 8.1 consists of few basic steps:\n1)\n2)\n3)\n4)\n5)\n6)\n\nChoose simulated process (proton-proton collision, e+e- collision, ...)\nSet center of mass energy (1GeV, 7TeV, 14TeV, ...)\nSelect generation mode / intermediate boson (W, W+, Z0, H, H+, ...)\nChoose an output event record (HEPEVT, HepMC, ...)\nGenerate large set of events\nAnalyze particles of interest\n\n8\n\n\fThe PYTHIA configuration system allows turning off internal computation of \u03c4 decays. This\nway, having a complete event record without the decayed \u03c4 leptons, we can attach our software, produce decay based on data from event record, and save the output inside the same\nevent. The generation procedure of single \u03c4 decay would look like this:\na)\nb)\nc)\nd)\ne)\nf)\ng)\n\nGet all information from event record needed for the decay\nGenerate \u03c4\nModify its kinematic according to its siblings, mothers and grandmothers\nDecay \u03c4\nCompute daughters kinematic\nDecay any unstable daughters (if needed)\nApply post-generation effects (photon emission, ...)\n\nAfter a large set of data is generated, we can then validate them by analyzing the decays\ngenerated by our software and compare them with verified results. For this purpose, MCTESTER, described in the next section, can be easily attached to testing routine. The relations between each component are presented on Fig. 1.\n\nFig. 1 Diagram of relations of different components. By design, event record serves as the means of\ncommunication between each module in the analysis sequence. A red part of a component symbolizes\na separate module or interface used for communication while arrows represent information flow.\n\nFollowing the previously described PYTHIA 8.1 generation routine, we can easily prepare\nan example of use of the interface as well as basic environment for testing purposes, by using the output event record created in step 4 as an input of our interface and by using MCTESTER for analysis (step 6). As a result, a complete analysis process would look like this:\n9\n\n\fDefine all parameters for PYTHIA, TAUOLA interface and MC-TESTER\nSuppress \u03c4 decays generated by PYTHIA.\nInitialize all three modules\nFor each event to be analyzed:\na) Generate new event using PYTHIA\nb) Save generated event to HepMC\nc) Invoke TAUOLA interface to apply \u03c4 decays\nd) Analyze event record using MC-TESTER\n5) Finalize analysis procedure\n6) Save analysis results to ROOT file.\n1)\n2)\n3)\n4)\n\n2.7\n\nMC-TESTER\n\nThe huge amount of distinct distributions produced for analysis purpose would be impossible to interpret without a proper tool. Focusing on \u03c4 decays alone, we have a huge set of\nevents and a set of distributions that need to be compared. For this purpose, we have prepared MC-TESTER [2], which performs such comparison in a semi-automatic way.\nAfter generation of each event by a given Monte Carlo system, the content is searched by\nMC-TESTER for the decay of the particle to be studied. Once it is found the appropriate\ndata is collected and stored in the form of automatically generated histograms and tables. A\nbooklet of comparisons is created: for every decay channel, all histograms present in the two\noutputs are plotted and parameter quantifying shape difference is calculated. Its maximum\nover every decay channel is printed in the summary table.\nDue to flexibility of this software, it is easy to introduce specialized tests for specific physics\neffect such as electroweak corrections or transverse spin correlation. For the purpose of\nbenchmarking our projects, we had to design and maintain tests. Some of those tests gradually evolved into the new version of MC-TESTER. The wide range of uses of MC-TESTER\nfor testing our project was the main reason for the decision to develop a new version of this\ntool as a part of the process of creating the main project. The full development cycle, has\nalready been finished and is documented in [2] therefore, it will not be described in this paper, even though I am co-author of its present version.\nAt present MC-TESTER uses ROOT software analysis framework [22] and is designed to be\neasily extensible by a means of ROOT scripts. Its functionality is nonetheless to a large degree independent. A wide range of options and an easy method to create different tests\nmade MC-TESTER a perfect tool for testing of our software. Because of the tests made during development of the project, new functionality has been added to MC-TESTER and the\nsoftware has been modified to work with HepMC event record as well. These tests are the\nfundamental achievement of the new version of MC-TESTER.\nFor the most basic tests of our software, we have created benchmark files using TAUOLA\nFORTRAN code to verify that transition from HEPEVT to HepMC event record does not\ncreate any unforeseen changes in numerical results. Afterwards, these benchmark files can\nbe used as a base for testing new options introduced in C++ code. The testing process always\ntake large amount of time, however in case of physics software it is an essential part which\nhas to be done from a variety of different perspectives as some significant errors might be\n10\n\n\fvery hard to find from regular point of view. MC-TESTER allowed us to cover several different views and to pinpoint such errors in early stages of software development.\n\n3.\n\nAbstract algorithm\n\nOnce starting point has been defined, let me present the design model used for creation of\nTAUOLA C++ interface. Keeping in mind restrains explained in Section 2.2, the software\nwould work as a bridge between TAUOLA FORTRAN as well as other software created by\nindependent users and the current generation of event records. The design of the starting\nversion for abstract algorithm was based on study of its FORTRAN predecessor.\nThe role of the interface will be to prepare information on the \u03c4 (four-momentum, spin\nstate) in a format, which is understood by TAUOLA FORTRAN and as a post processing step\nto return (insert) \u03c4 decay products to the primary event record. Finally, role of such interfacing code will be to calculate dedicated weights from the production process information as\nwell as from the decay, and unweight accordingly to standard MC procedures.\nAccordingly, the model of this interface will be build upon three separate blocks: C++ interface to FORTRAN routines, abstract structure of the event record interface and implementations of different event records.\nThe original TAUOLA has been written for HEPEVT event record. The trick to connect algorithms based on this event record with the C++ one is to override the methods responsible\nfor event record I/O with their C++ counterparts. Assuring that the C++ code will be executed\ninstead of the old FORTRAN routines, no changes are required to FORTRAN code. This trick\nallows old algorithms to work as thought they use HEPEVT while the actual data from and\nto event record will be fed by the interface, collected from a C++ data structures. In case of\nTAUOLA, this solution becomes pretty simple as only filhep_ method needs overwriting.\nStarting from the FORTRAN code, we have defined the most basic needs for the interface\nand the decay algorithm. Using this approach we have build basic abstract structure and began planning the overall project. Following schema observed in HepMC and used previously\nin MC-TESTER, we have decided to divide algorithms regarding the whole event record and\nindividual particles into separate classes \u2013 TauolaEvent and TauolaParticle. Additionally, knowing that the spin correlation algorithms will require information about pair of\ngenerated particles, we have created TauolaParticlePair to deal with all the information needed for single decay. The following two subsections encapsulate the most important\ninformation presented in the technical part of reference [1].\n\n11\n\n\fSoftware structure\n\n3.1\n\nFig. 2 TAUOLA C++ Interface class relation diagram including TAUOLA FORTRAN and HepMC interface. Classes regarding the interface with electroweak library, random number generators and other\nmethods are not shown.\n\nThe choice of splitting the source code into three main modules, see Fig. 2 (blue part), allows\nto separate the FORTRAN related code from the abstract C++ interface and the concrete\nimplementation of the interface created for the appropriate event record.\n\uf0b7\n\n\uf0b7\n\nTAUOLA FORTRAN Interface\nThis part of the code provides an interface to the FORTRAN library of TAUOLA. In\nparticular, routines necessary for library initialization and wrapper for routine invoking the decay of a single \u03c4. Parts of the interface code are still left in FORTRAN, but\ncan be rather easily rewritten to C++. The most important method, filhep_, has\nbeen implemented in C++. Its FORTRAN predecessor writes single particles to the\nHEPEVT common block. At present, the method filhep_ inserts the particle into\nthe HepMC event record but remains to be called from the FORTRAN library.\nTAUOLA C++ Interface\nThe abstract part of the interface to the event record. The class TauolaEvent contains information regarding the whole event structure, while TauolaParticle\n12\n\n\f\uf0b7\n\nstores all information regarding a single particle. All particles used by the interface\nare located in the event in the form of a list of TauolaParticle objects. The last\nclass located here, TauolaParticlePair, is the core of all polarization and decay algorithms. They are independent from the event record used by the interface as\nthey operate on these two abstract classes presented above.\nEvent Record Interface\nThe event record implementation classes. All classes stored here represent the implementation of specific event record interfaces and are responsible for reading, traversing and writing to the event record structure. Only TauolaEvent and TauolaParticle classes must be implemented. The HepMC event record interface is\nimplemented through TauolaHepMCEvent and TauolaHepMCParticle.\n\nBy dividing the code into these three blocks, all new physics effects introduced independently from FORTRAN generation procedure can be easily implemented into abstract model of\nthe generation process. Spin effects, electroweak corrections and effects of anomalous\ncouplings can be introduced in this way.\nAlgorithm outline\n\n3.2\n\nThe main algorithm used in the project consists of several steps starting from gathering information from event record through main \u03c4 generation to writing decay to event record.\nDocumentation of the TAUOLA FORTRAN Interface [16] describes some aspects of the spin\ncorrelation algorithm, which are also relevant to this interface.\n\uf0b7\n\uf0b7\n\uf0b7\n\uf0b7\n\uf0b7\n\uf0b7\n\uf0b7\n\uf0b7\n\nThe HepMC event record is traversed and a list of all stable \u03c4's in the event is created.\nFrom each found \u03c4 location, the tree is traversed backwards so that information\nabout the production process can be extracted and used for the calculation of the\nspin density matrix.\nThe siblings of the \u03c4 are identified through common parents. In cases such as\n,\nthe parent(s) are defined as the particle(s) that produced the first \u03c4; \u03c4 and siblings\nare paired to the \u03c4.\nThe density matrix is set-up using information about the \u03c4-pair and their parent type\n(for Z/\u03b3 processes, grandparent information is also required).\nThe pair is then decayed by executing the FORTRAN routine dekay_ for each \u03c4 in\nthe pair.\nA spin weight is calculated using the polarimetric vectors returned from TAUOLA\nFORTRAN and the density matrix previously set-up.\nIf the decays are rejected, the pair is decayed anew and the process is repeated until\nthe decays are accepted. In this way unweighting of spin effects is performed.\nOnce accepted, the decay products are added into the event record with the procedure as follows:\no The \u03c4-pair are boosted and rotated into this hard process frame.\no The dekay_ routine of TAUOLA FORTRAN is executed with state = 11 or 12\n(write). This initiates TAUOLA FORTRAN to return the daughter information\nvia the filhep_ routine.\no The \u03c4's status code is changed from stable particle to intermediate particle.\n\n13\n\n\f\uf0b7\n\no A new particle object is created for each daughter and the appropriate tree\nstructure is created and added into the event.\no Each daughter is boosted using the \u03c4's 4-momentum (as TAUOLA constructs\ndecay for a \u03c4 at rest) to the hard process frame.\no The \u03c4's and their decay products are boosted back into the laboratory frame.\nAs the final step, the position of vertices containing the \u03c4's and their decay products\nis set according to the \u03c4's momentum and lifetime.\n\nThe event is hence modified with insertion of \u03c4 decay products.\n3.3\n\nDecay tree structure\n\nA typical structure of High energy physics process is represented by a tree of decaying particles. The decaying particle is considered mother of its decay products. Unstable daughters\nof the mother particle can decay further until stable particles are produced. Such interpretation corresponds to the tracks observed in the detector. In other parts of the tree it\nrepresent dominant, but not exclusive, Feynman diagram. The main algorithm of the interface regards the branch of the whole decay tree containing the decaying \u03c4.\nThe data structures used in FORTRAN were focused on particles as the basic information\nsource. Each particle stored information about itself and its relation with each particle.\nHepMC group particles into vertices representing single particle decay (see Section 2.4). Such\norganization makes it easier to identify decaying process of interest and overcomes limitations present in FORTRAN predecessors. However, with the new approach comes new set of\nexceptions that need to be dealt with, as the tree itself is prone to many assumptions and\nabbreviations that makes searching for mothers and grandmothers of intermediate particle\na hard task.\nFirst of all, the decay tree stored in event record may not have the tree-like structure at all.\nAs indicated previously in Section 2.5, each Monte Carlo generator has its own way of storing information about different processes. Similar, data extracted from the detectors themselves might be corrupted as well. Several nodes might become disjoint due to lack of information and the decays themselves might have connections with completely separate parts\nof the tree. There are also cases when the background information regarding the process is\nstored in the event record as a separate, parallel tree. The tree becomes more of a graph\nand regular algorithms traversing the event record fail to overcome difficult exceptions.\nStructures observed in Monte Carlo generators can be divided into several categories:\n\n14\n\n\fPicture on the right presents the easiest type of event,\nwhere all information about hard process is explicitly\ngiven and there are no troubles finding mother and\ngrandmothers of \u03c4. It can be frequently observed in\nMonte Carlo generation process and is useful for test\npurposes. Unfortunately, such perfect event is rarely\npresent in detector output.\n\nAn example of\nand\ndecay in PYTHIA\nMonte Carlo generator, in which the momentum is not\nconserved. However, this non-conservation is balanced,\nfor example, between two branches outgoing from Z.\n\nAn example of a case when grandmothers are not explicitly given. In such cases, the interface is expected to\nreconstruct grandmothers of \u03c4 based on its mothers and\nsiblings. Solution is not always deterministic.\n\nIn general branching\nis rare. Some cases of \u03c4\nproduction may look like the picture on the right. Such\ncases imply many possible options and are source of\nmany potential traps. The mother of \u03c4 needs to be constructed based on its siblings and grandmothers and the\nkinematics of hard process needs to be reconstructed as\nbest as possible with the data given by event record.\n\n15\n\n\f4.\n\nImplementation\n\nCoordination and role separation within the project proved to be an essential part of the\nplanning. Since the project is spanning over the vast amount of knowledge regarding High\nenergy physics, my first step was to divide this knowledge into several separate block and\ndecide what I had to learn, what might be useful to know, and with what I do not need to be\nconcerned.\nIt came to my understanding that large amount of physics I do not have to understand to be\nable to code the necessary algorithms. This result in a fact that there are parts of the code\nthat I perfectly understand and know how they work, but have no or very little knowledge\nabout their meaning. It does not come natural to write code not knowing its actual meaning\nbut I have realized that this is what is expected from a programmer working with large high\nenergy physics projects as well as any other large industrial project. Having first tasks assigned and the roles in our project decided, we began implementing the abstract model following the outline described in previous chapter.\n4.1\n\nMethodology\n\nStarting our project, we were not expecting how fast the standard within the collaboration\nwill change. Having first part of the code ready, we already got informed that the new version of HepMC has been released introducing few significant changes [23] and forcing us to\nrewrite part of our code completely.\nWe were not too concerned with the changes of HepMC itself, as they could be dealt with\nthanks to separation of the abstract interface from the concrete implementation. The real\nproblem was that these changes resulted in different representations of the physics process\nitself and as the consequence they require change of the abstract level of the algorithm.\nSuch changes imply that software has to be rearranged. Since these changes regard the basis\nof the analysis \u2013 the event record content \u2013 short but non trivial modifications of the code\nmay be necessary.\nSuch changes are host-generator dependent. If more than one interpretation is necessary (as\nin case of PYTHIA 8.1 and 6.4, for example), it may result in multiple implementations. The\ninterface must take into account all of these options as well as the fact that some experiments might not incorporate new versions of physics Monte Carlo generators as quickly as\nthe others might. Compatibility with the older versions must exist as well.\nWe have quickly realized that regular approach to software design fails, as it does not account for such fundamental changes lying completely outside of our project. It became obvious that since the software must be compatible with collaboration standards, it means that\nit must be prepared to the frequency of changes introduced within collaboration. Therefore,\nwe have changed our methodology to iterative one, based on agile software development\n[24], focusing on response to changes rather than following a plan.\nThe development cycle in most popular methodology for well-defined project \u2013 the waterfall\napproach \u2013 starts with definition of requirements, followed by creating the design, implementing the abstract model, testing and maintaining the final software.\n\n16\n\n\fRequirements\nDesign\nImplementation\nTesting\nMaintenance\nFig. 3 Five steps of waterfall approach\n\nIf the specification was detailed enough, and assuming that the communication between the\nteam and the client was as best as possible, creating a design that suits customer the most,\nthen the finished product is expected to have full functionality declared by the customer, will\nbe made within the budget and will be delivered on time. However, the main issue of high\nenergy physics software is the fact, that the main prerequisite for waterfall approach to be\nsuccessful cannot be fulfilled. It is impossible to plan full functionality of the finished project.\nThe basics of the project are already defined and can be easily covered in more details, but\nbecause the software itself is not made for any specific client, organization or specific experiment, with multitude of different uses there is no way to tell what functionality end users\nmight request.\nIn case of rapidly changing projects, where the functionality is created on the fly, an iterative\napproach has been designed and introduced in form of agile software development manifesto [25]. This approach presents a completely different view on software development cycle.\nIt starts with the basic planning followed by a repetition of iterations in form of three steps \u2013\niteration planning, execution and evaluation.\n\nProject\nPlanning\nExecution\n\nIteration\nPlanning\n\nEvaluation\n\nFinalization\n\nFig. 4 Iterative approach of agile methodology\n\n17\n\n\fWithin each cycle, a new functionality is implemented and the list of the next tasks created\nto be assigned in the upcoming iteration. This way each iteration results in the new, extended version of the previously written code. The cycle ends with the consolidation of the\nfinished project. The differences are obvious \u2013 there is no need to define full functionality at\nthe start of the project, but instead the customer is required to verify functionality created in\neach cycle and to provide tasks for the next one. One of the disadvantages of such loosely\ndefined design is that the outcome of the whole development process cannot be fully predicted. It implies that the project can end with more functionality implemented than originally expected at the cost of extended development time or budget. It can also mean that\nthe project might be finished on time and within the budget, but with less functionality than\nexpected. Additionally, since the customer does not fully define the project at the very beginning, his attention is required throughout the whole development process.\nThe agile methodology was created specifically to deal with the problems that regular methodology cannot solve. However, it has many requirements that high energy physics\nprojects cannot comply. For starters, it requires good management and well-coordinated\nteam to be fully successful. Writing software for physics experiments requires cooperation\nwith specialists around the world and implies that some of the team members can join in\nduring project development while others may leave the project due to lack of time or other\nissues that require their attention. The other problem is, as mentioned before, constant interaction with the users, which in case of high energy physics projects is hard to establish.\nThe agile methodologies value interaction with customer in terms of planning the new functionality. However, as writing project for High energy physics experiment is different from\nthe commercial software, it is hard to tell which experiments except ATLAS and CMS might\nactually be interested in the software as well as what potential user might expect. The requirements for new iteration may appear unexpectedly as some of the users find functionality that they would like to be implemented, while for the most of the time user feedback may\nbe simply nonexistent.\nIn search for methodology that would suit our project the most, we started from a popular in\nour country methodology called XPrince [26]. Based on a software management methodology, as well as an agile approach, XPrince is a hybrid methodology defining stable steps of\nsoftware evolution and means to adopt the software to constantly changing requirements.\nAs an alternative approach, we have also tried commercial software offered by Parasoft.\nParasoft Concerto [27] is agile software development management application designed to help planning, defining requirements and managing tasks allocated to different\nteam members. It supports both waterfall and agile approach including hybrid methodologies as well as mixture of these types within groups working on the same project. We were\nnot able to test this solution during development of TAUOLA C++ Interface; however, we\nconsidered its usefulness in projects with larger team requiring much more planning and\ncooperation.\nSince the most basic requirements of our project could be well defined, we were able to plan\nand start implementation of the core functionality of the project. As the first versions became available and first tests were performed, we have started looking for testing environments. It was quite shocking how different experiments focus on their own, unique simulation software rather than following any common standard. It became obvious that our software will require specific arrangement for each experiment, forcing us to create specific fixes\nfor each platform.\n18\n\n\fThe model of our software started to change along with the code and new tasks were assigned based upon the previous iteration. Using doxygen, we have set up a website providing documentation, early software releases and necessary installation information for future\ntesters. We have also set up an automatically generated release archive updated daily,\nwhich created a pace that forced us to quickly incorporate new modifications and always\ncreate a working version. Each day new version was available to the users.\nThanks to user feedback, with new releases came new functionality requests and changes to\nexisting ones which sometimes required complete rewrite of some parts of the code. Before\nintroducing new functionality to the software, we had to be sure that changes will not damage existing code. An extensive testing procedure had to be implemented so additional test\nmodules were created including memory leak tracking function and internal algorithms testing plots as well as extended set of benchmark tests. We have also created several MCTESTER-specific macros for advanced tests3. Having basic installation scripts prepared, the\nfirst stable version has been released.\n4.2\n\nSpin correlations\n\nThis section summarizes the implementation of the spin correlations algorithm used in the\ninterface. The physics aspects of this algorithm are described in more detail in reference [1].\nThe basic algorithms for spin correlations already existed in FORTRAN code. However, we\nhave decided to write it anew as from physics point of view, the code is easy to understand,\nwhile the old algorithm relied on the older event record; therefore, it was worth rewriting it\nto C++ as a part of the interface.\nIf more than one \u03c4 lepton is present in a final state, then not only is the individual spin state\nfor each \u03c4 necessary for proper generation, but the complete correlation matrix of all \u03c4 leptons must be taken into account as well. In the case of \u03c4-pair production, the standard algorithm explained in [13; 15] can be used without much modification. For the single \u03c4 produced\nin a\npair, it is convenient to use the same algorithm as well, even though it is not necessary from the physics point of view.\nAs described in papers mentioned above, spin correlations and spin polarization effects can\nbe simulated by accepting or rejecting a pair of generated \u03c4 decays based on a weighting\nfactor wt.\n\nwhere\nand\nare the polarimetric vectors for the\nand\nrespectively and\nis the\ndensity matrix associated with the \u03c4 production vertex. The matrix\ndepends on the mechanism and particular kinematical configuration of \u03c4 pair production. The ,\ndepend on\nthe respective decays of\nand . The solution can be used for\nproduction as well.\nIn this case, decay is not performed and its polarimetric vector is set to\n.\n\n3\n\nResults of these tests are presented in Section 4.1.\n\n19\n\n\fA pair of \u03c4 decays should be accepted if the weight is greater than a randomly generated\nnumber between 0 and 1. If this condition fails, the \u03c4 pair decays should either be rejected\nand regenerated, or rotated4 and the weight recalculated. The production process does not\nneed to be reprocessed.\nIn the formulas used to create matrix\nthe hard process kinematical variables and\nhave to be known for each event. Those variables are also used by a module for calculating\nelectroweak corrections (see Section 4.3).\nVariable is defined as square of invariant mass of \u03c4 mother. To find the angle we need to\nidentify the four momenta of\nand\npair. Two scattering angles and can be reconstructed. The angle\nis between\nand the first incoming state,\nis between\nand the\n5\nsecond one . Both angles are calculated in the rest frame of the \u03c4 pair. The average angle\naccordingly to the description given in [28] is taken:\n\nThe density matrices\nmented in details in [1].\n\nfor the most standard processes of \u03c4-pair production are docu-\n\nThe algorithm for the spin correlations, in contrast to the other parts of the code, forces to\nlook outside the single node in the decay tree. The gathering of information regarding parents and grandparents of the decayed particle requires traversing the event record backward to search for appropriate particles. However, this poses many problems as in most cases, the decay tree is not as perfect as the theory describes.\nDue to the number of options of possible decay tree structures (see Section 3.3) a unique\nalgorithm had to be written. The hard \u03c4's are used to calculate spin correlation and the stable \u03c4 for kinematics, which complicates the procedure even further. The algorithm was\ntested and was modified using hundreds of different event record examples. As it became\nobvious that any new modules introduced must be easily replaceable in case of fundamental\nchanges, further work on advanced spin effects was gathered into separate class: TauolaParticlePair (see Section 3.1). The algorithm is independent from the rest of the\nproject and if data provided from event record is insufficient, no spin correlation will be calculated. Thanks to this approach, the code becomes more robust as it takes into account any\ntype of event record, including damaged ones with incomplete or invalid tree structure.\n4.3\n\nElectroweak corrections\n\nIn some cases, notably in the case of\nproduced from the annihilation of a pair of\nquarks, the standard density matrices may not be sufficient for some applications. A more\nexact solution is also available. Instead of a native\ndensity matrix, an externally calculated one can be used.\n\n4\n\nRotation instead of rejection increases efficiency by a factor of 4. This however only affects the generation of\n\u03c4 lepton decays and represents a small fraction of the total time of constructing the event.,\n5\nAssuming the first incoming state to be antiparticle.\n\n20\n\n\fThe solution is based on SANC library [19; 29] for calculation of electroweak corrections6.\nWith its help, the density matrix\nfor\nprocess can be calculated as a function\nof the incoming state flavour and Born level variables (Mandelstam and scattering angle\n). Additional two weights are also provided, which include the matrix elements squared and\naveraged over the spin. For additional weights, genuine weak corrections are respectively\nswitched on and off7.\n\nFig. 5 Organization of electroweak corrections module.\n\nKeeping modular approach in mind, and to speed up execution of the program, electroweak\ncorrections has been implemented as a completely standalone unit. A separate program\ngenerates output in form of several tables that the interface can read. The tables calculated\nby this unit store the\nvalues in a lattice of\npoints.\nLater, in the actual execution of our interface, these pretabulated values of\nare interpolated to the actual phase space point. For this purpose, the standard bilinear interpolation\nalgorithm is used. Additionally, in order to avoid numerical errors, for\nvalues near -1\nand 1 we are using the linear extrapolation algorithm.\nThe advantage of this solution is that results of SANC library calculation can be modified by\nthe user before it is loaded into our interface without intervention into the code of the interface itself. Pretabulation is prepared for three domains of s: around the Z peak, close to the\n\n6\n\nIt may serve as an example of how other calculations featuring heavy Z' boson, for example, may be used in\nour interface.\n7\nThis may be helpful for the evaluation of genuine weak corrections for states of large s, significantly above the\nZ peak, where they become sizable. See eg. refs [33],[34].\n\n21\n\n\fWW pair production threshold and over a broad energy range, but the actual choice of pretabulation zones can be easily modified by user. The algorithm outline of applying electroweak corrections is presented below:\n\uf0b7\n\uf0b7\n\uf0b7\n\uf0b7\n\uf0b7\n\uf0b7\n\uf0b7\n\nGet information about the production process\nIf a table for such process does not exist, return\nthe default value8\nCalculate\nand\nas described in Section 4.2\nIf s is below designated threshold, return the default value\nCheck which range of pretabulation is the most\nsuited for interpolation\nFind the four points on the lattice closest to\n(\nInterpolate the value of electroweak correction\n\nThe program generating the tables can be easily adopted to account for new physics\nprocesses or to create a specific tests. For complicated cases or for advanced testing purposes, user might prefer to modify tables manually using external software or a script. Additionally, as in case of spin correlation, in absence of pre-generated tables, or in case these tables\nhas been modified by user in an inappropriate way, the interface will ignore electroweak\ncorrections returning the default value.\nFORTRAN TAUOLA interface\n\n4.4\n\nAs described in Section 3.1, the core algorithm for generating the \u03c4 decays has been integrated into the interface as an interchangeable module with several routines interfaced to\nC++ code:\n\uf0b7\n\n\uf0b7\n\n\uf0b7\n\nfilhep_ - as indicated in Section 3, this routine for event record I/O has been overridden by a new version written in C++. It has been adopted to use HepMC as the\nmeans of communication between FORTRAN and C++ part of the code, however in\nfuture it will be adapted to use all supported C++ event records.\ndekay_ - the most important routine of TAUOLA FORTRAN. It is called to generate \u03c4 and return its polarimetric vector used in algorithm described in Section 3.2 as\nwell as to generate daughters of \u03c4 and save all newly generated particles to event\nrecord.\ntaupi0_, tauk0s_, taueta_ - if appropriate option is used (see Section\n4.5.5), these routines are invoked to generate decays of \u03b7,\nand\nrespectively.\nThis allows short living scalar particles produced in \u03c4 decays to be decayed by the interface rather than by invoking a host generator after \u03c4, decays are produced.\n\nThe rest of the interfaced code consists of the list of common blocks used for setting up options for TAUOLA FORTRAN (for more details see reference [1]). Several routines (such as\nplzap0_) have been left in FORTRAN, but have been statically included into the FORTRAN\n8\n\nAs the default value, the analytic form taken from ref [41] is used. It features all spin and mass effects, but\n2\nelectroweak corrections, and even Z exchange, are not taken into account. This is reasonable for s<36GeV\n\n22\n\n\finterface. They represent parts of old FORTRAN code for calculation of spin correlations and\ninterface to module for calculation of electroweak corrections. They are prepared to be rewritten to C++ in near future. As their use poses no difficulty, they are left as such. In principle, they offer an example of numerically better solution than pretabulation of electroweak\ncorrections method used by us. They operate at the level of form factors used in spin amplitudes calculations instead of the level of density matrix and cross section. Such functions are\nby far smoother.\n4.5\n\nUser configuration\n\nFor purpose of configuring the decays generated by the interface, a new module has been\ncreated in form of a static class Tauola. This class stores configuration options for each\nstep of the simulation. Configuration of both TAUOLA FORTRAN and the interface itself can\nbe performed using options divided into three categories \u2013 initialization, generation and\noutput.\n\nFig. 6 Configuration options of TAUOLA C++ Interface.\nThis list includes options described in Section 6.4.\n\nThis section contains description of several options as an example of functionality implemented during project development. For details regarding rest of the options, see reference\n[1].\n4.5.1 Decaying Particle\nThe following method is prepared to impose the sign for the \"first \u03c4\", that is to reverse signs\nof SameParticle and OppositeParticle used in decay mode selection (see section\nbelow):\n\n23\n\n\f\uf0b7\n\nTauola::setDecayingParticle(int pdg_id)\nSet the PDG id of the particle which TAUOLA should decay as \"first \u03c4\". Both particles\nwith pdg_id and -1*pdg_id will be decayed. Default is 15, one may want to use -15\nfor special applications.\n\nExample:\nTauola::setDecayingParticle(-15);\nSet SameParticle to be\n4.5.2 Decay mode selection\nBy default, all \u03c4 decay modes will be generated according to predefined branching fractions.\nMethods to modify the default values are provided:\n\uf0b7\n\uf0b7\n\nTauola::setSameParticleDecayMode(int mode)\nSet the decay mode of the \u03c4 with the same PGD code as set by setDecayingParticle()\nTauola::setOppositeParticleDecayMode(int mode)\nSet decay mode of the \u03c4 with the opposite PGD code as set in setDecayingParticle()\n\nExample:\nTauola::setSameParticleDecayMode(Tauola::PionMode);\nTauola::setOppositeParticleDecayMode(4);\nForces only the modes\n\uf0b7\n\nand\n\nto be generated\n\nTauola::setTauBr(int mode, double br)\nChange the \u03c4 branching ratio for channel mode from default to br.\n\nExample:\nTauola::setTauBr(3,2.5);\nSets rate for channel\nto 2.5. All channel rates may not sum to unity, normalization will be performed anyway.\nThe int mode enumerators which are arguments of the above functions have the following meaning:\no\no\no\no\no\no\n\n0 \u2013 Tauola::All - All modes switched on\n1 \u2013 Tauola::ElectronMode \u2013\n2 \u2013 Tauola::MuonMode \u2013\n3 \u2013 Tauola::PionMode \u2013\n4 \u2013 Tauola::RhoMode \u2013\n5 \u2013 Tauola::A1Mode \u2013\n24\n\n\fo\no\no\no\no\no\no\no\no\no\no\no\no\no\no\no\no\n\n6 \u2013 Tauola::KMode \u2013\n7 \u2013 Tauola::KStarMode \u2013\n8\u2013\n9\u2013\n10 \u2013\n11 \u2013\n12 \u2013\n13 \u2013\n14 \u2013\n15 \u2013\n16 \u2013\n17 \u2013\n18 \u2013\n19 \u2013\n20 \u2013\n21 \u2013\n22 \u2013\n\n4.5.3 Spin correlations options\nBy default, all spin correlations are turned on. However one may be interested to partially or\ncompletely switch off their effects for the sake of numerical experiments which validate\nwhether a measurement will be sensitive to certain spin correlation components. This technique may be useful to evaluate the significance of spin correlations for signal/background\nseparation as well. For this purpose the following methods are provided:\n\uf0b7\n\n\uf0b7\n\nTauola::spin_correlation.setAll(bool flag)\nTurns all spin correlation computations on or off depending on the flag, which can be\neither true or false. Note: this should be called after Tauola::initialise().\nTauola::spin_correlation.HIGGS=flag\nTurns particular spin correlation computation on or off for a given \u03c4 parent depending\non the flag which can be either true or false. Implementation of this switch is provided for: GAMMA, Z0, HIGGS, HIGGS_H, HIGGS_A, HIGGS_PLUS,\nHIGGS_MINUS, W_PLUS, W_MINUS. The keywords denotes the \u03c4 parent.\n\nExample:\nTauola::spin_correlation.setAll(false);\nTauola::spin_correlation.HIGGS=true;\nTurns all spin correlations off, except HIGGS.\n4.5.4 Radiative correction\nThe user may want to configure parameters used in the generation of QED corrections in the\nleptonic decay channels of \u03c4's. For that purpose the following methods are provided:\n25\n\n\f\uf0b7\n\n\uf0b7\n\nTauola::setRadiation(bool switch)\nRadiative corrections for leptonic \u03c4 decays may be switched on (default) or off by setting the switch to true or false.\nTauola::setRadiationCutOff(double cut_off)\nSet the cut-off for radiative corrections of \u03c4 decays. The default of 0.01 means that\nonly photon of energy (in its rest frame) up to 0.01 of half of the decaying particle\nmass will be explicitly generated.\n\nExample:\nTauola::setRadiation(false);\nSwitch radiative corrections off in \u03c4 decays\n4.5.5 Decay of final state scalars\nIn some cases a user may want TAUOLA to decay short living scalar particles produced in\ndecays, rather than invoking a host generator for the post processing step. For that purpose\na special algorithm is prepared, even though high precision is then not assured. This might\nnot be a problem if the algorithm is used for \u03c4 decays only where events with such decays\nare rather rare:\n\uf0b7\n\nTauola::setEtaK0sPi(int a, int b, int c)\nThree parameters a, b and c switch on or off the decay of \u03b7,\nA value of 1 is on and 0 is off.\n\nand\n\nrespectively.\n\nExample:\nTauola::setEtaK0sPi(1,0,1);\nIn event branch starting from \u03c4, \u03b7 and\n\ndecay, but\n\nremains undecayed.\n\n4.5.6 Helicity states and electroweak correcting weight\nIndependent of the generation process, the information on helicities of\nreturned9 with the help of accessors:\n\nand\n\ncan be\n\nint Tauola::getHelPlus()\nint Tauola::getHelMinus()\nNote that these helicities are not used in the interface and carry approximate information\nonly. The electroweak weight can be returned with the help of accessors:\n\n9\n\nThe actual sign may depend on the process and boosting routine. Approximations in attributing helicities are\nintroduced.\n\n26\n\n\fdouble Tauola::getEWwt()\ndouble Tauola::getEWwt0()\nThese methods provide information once processing of a given event is completed.\n\n5.\n\nNumerical tests and physics results\n\nCreating a solid testing environment is an integral part of the development process. As new\nfunctionality is introduced, new tests needs to be created and the code needs to be validated again before any progress can be made. As soon as the validation of each version of\nthe code ends, new tests can be created to verify less visible effects or to enhance testing\nprocedure.\nStarting from the tests created for number of FORTRAN projects (including TAUOLA\nFORTRAN), our testing evolved throughout the whole development of the interface. It was\nsystematically extended to account for all implemented functionality. For this purpose, all\nFORTRAN benchmark tests had to be rewritten to C++ basing only the concept of the previous tests. It was, nonetheless, a significant help in creating the fundamental part of the\ntests.\nFurthermore, the increase of the level of precision used changes conditions for tests. On one\nside, increased precision help to extend program stability and application domain as numerically small effects in one application confirm that there will be no bigger problems for other\ncases. On the other hand, creation of such tests becomes more complicated as small effects\nare usually more difficult to pin down.\nDue to complexity of the project, there are many cases in which regular user might not be\nable to deduce how the final distributions of different aspects of \u03c4 decays might look like.\nTherefore, it is crucial that the user is able to reproduce these distributions and to study\ntheir individual aspects. Following section contains the most significant results published in\n[1]. The results presented here serve as examples of how both validation of existing\nprocesses and observation of new effects can be achieved.\nThe results of these tests were compared to the results obtained with the FORTRAN Interface (which has been well validated by comparison with analytical and numerical calculations for \u03c4 pair production10. For a review of physics oriented tests of \u03c4 decays themselves,\nand projects for future improvements based on low energy\ndata, see ref. [3]).\nIn addition to this, we created custom MC-TESTER macros for plotting other spin sensitive\nquantities and compared these to published results. Numerical results are presented later in\nthe section see Fig. 9a, Fig. 9b and Fig. 10a, Fig. 10b.\n5.1\n\nBasic tests\n\nThe most basic test, which should be performed, is verification that the interface is installed\ncorrectly, that all \u03c4 leptons are indeed decayed by the program and that energy momentum\nconservation is preserved. TAUOLA has its own database of parameters and as a consequence the \u03c4 lepton mass may differ between the program performing a \u03c4's production and\n10\n\nThis represents tests of interface. In all cases \u03c4 decays are generated with the help of TAUOLA FORTRAN\n\n27\n\n\fTAUOLA performing its decay. This leads to the sum of \u03c4 decay product momenta not exactly matching the \u03c4's momentum. Although this effect may seem negligible, it may break numerical stability of programs like PHOTOS if they are applied later.\nOnce correct execution of the basic program steps have been confirmed, i.e. \u03c4 leptons are\ndecayed, energy momentum is conserved and there are no double decay occurrences in the\nevent tree, step one of the program installation tests is completed. In principle, these tests\nhave to be performed for any new hard process and after any new installation. This is to ensure that information is passed from the event record to the interface correctly and that\nphysics information is filled into event record in expected manner. Misinterpretation of the\nevent record content may result in faulty generation by TAUOLA. For example, spin correlations may be missing or badly represented, or some \u03c4 leptons may remain undecayed.\n5.2\nThe longitudinal spin effects for Z decay into \u03c4's was tested by restricting the \u03c4 decay mode\nto\nand examining the invariant mass of the\npair,\n(see Fig. 7a) and\nthe \u03c0 energy distribution in the rest frame of the Z (see Fig. 7b). The effect of Z polarization\non these distributions was studied in [30] and we obtained consistent results with the new\nC++ implementation of the TAUOLA Interface.\n\nb)\n\na)\n\nFig. 7 Longitudinal spin observables for the Z boson (\nat 500 GeV). Distributions are shown\nfor spin effects switched on (red), spin effects switched off (green), and their ratio (black)\n\n5.3\nAs was done for Z decay in previous section, longitudinal spin effects for Higgs decay into \u03c4's\nwas tested using\n(Fig. 8a) and the \u03c0 energy distribution in the rest frame of the\n(see Fig. 8b), which was flat as expected.\n\n28\n\n\fb)\n\na)\n\nFig. 8 Longitudinal spin observables for the H boson for\n. Distributions are shown for spin\neffects switched on (red), spin effects switched off (green), and their ratio (black)\n\nLet us now turn to transverse spin correlations. In Fig. 9a the benchmark histogram as produced by our FORTRAN Interface and given in Fig. 3 of reference [31] is reproduced11. It features acollinearity of the\npair in the Higgs boson rest frame, both \u03c4's decay to\nFor the same decay set up, Fig. 9b features acoplanarity of the planes built respectively on\ndecay products of\nand . The spin effect is indeed large. However, it requires use of unobservable neutrino momenta. It is difficult or even impossible to achieve sufficient experimental precision in reconstruction of the reaction frame necessary for this observable. In\naddition, the first observable presented on Fig. 9a suffers from the same limitation.\nThe two other tests, Figures Fig. 10a and Fig. 10b present distribution of acoplanarity angle\nfor the two planes built respectively on the momenta of\n- the decay products of\n. All in the rest frame of the \u03c1-pair. It is directly based on measurable\nquantities. The\noriginate respectively from\ndecays. There is no need for Higgs\nrest frame reconstruction in this case. Events are divided into two categories. If the energy\ndifference between charged and neutral pions coming from the two \u03c4's is of the same sign,\nthey contribute to Fig. Fig. 10a, otherwise they contribute to Fig. 10b. For details of the definition and for more numerical results obtained with the FORTRAN Interface, see [32].\n\n11\n\nIn the plot the case of non zero scalar-pseudoscalar mixing was chosen. This is the origin of the difference\nwith ref. [31].\n\n29\n\n\fa)\n\nacollinearity distribution\n\nb)\n\nacoplanarity distribution\n\nFig. 9 Transverse spin observables for the Higgs boson for\nscalar Higgs (red), scalar-pseudoscalar Higgs with mixing angle\n\n.Distributions are shown for\n\nb) acoplanarity distribution\n\na) acoplanarity distribution\n\nFig. 10 Transverse spin observables for the Higgs boson for\n. Distributions are shown\nfor scalar Higgs (red), scalar-pseudoscalar Higgs with mixing angle (green)\n\n5.4\n\nb)\n\na)\n\nFig. 11 Pion energy spectrum in the rest frame of W (left hand side) and\n\n(right-hand side). Spin\n\neffects included (red line) and neglected (green line) are plotted. The variable\nis used respectively\n\n30\n\nor\n\n\fFor the simplest decay mode\nas was already discussed in ref. [30], the pion\nenergy spectrum should be softer in the case of\ndecays and harder in the case of\ncharged Higgs decay. This is indeed reproduced in Figs. Fig. 11a and Fig. 11b and the spectra\nare reversed for the two cases.\n5.5\nOne may wonder whether the numerical results induced by electroweak corrections are of\nany practical purpose. They are expected to be of the order of 1% and indeed are not that\nlarge for the intermediate state virtuality of up to 100 GeV above the Z boson mass. The situation changes however significantly at higher energies. As can be seen from Figures Fig. 12\nand Fig. 13 the effect may be of the order of even 50% at virtualities of several TeV. This is\nquite in agreement with the results of refs. [33; 34]. In Figures Fig. 14a and Fig. 14b we collect\nresults for \u03c4 polarization calculated at cos(\u03b8)=-0.2. Again, the effects are small up to the\nenergy scale of about 500 GeV. At larger scales corrections become sizable. The electroweak\ncorrections should be therefore considered in studies aiming for new physics phenomena\nsuch as\ndecays.\n\nFig. 12 The integrated cross section of \u03c4 pair production from up quarks calculated with and without\nNLO EW corrections (red and blue lines) is shown in the left hand side plot. The ratio of the two distributions is given on the right hand plot. We are using the alpha scheme for electroweak corrections.\nThat is why light fermion loops contribute to the difference between the two lines.\n\n31\n\n\fFig. 13 The integrated cross section of \u03c4 pair production from down quarks calculated with and without NLO EW corrections (red and blue lines) is shown in the left hand side plot. The ratio of the two\ndistributions is given on the right hand plot. We are using the alpha scheme for electroweak corrections. That is why light fermion loops contribute to the difference between the two lines.\n\na)\nb)\nFig. 14 Polarization for \u03c4 leptons produced from up quarks (Fig. a) and down quarks (Fig. b) at\ncos(\u03b8)=-0.2. The red line is with electroweak corrections, the black is Standard Born as is default in the\ninterface. The blue line is Born according to alpha scheme. The main purpose of these results is a\ntechnical test of the software installation. Note however the inadeq7uateness of the alpha scheme\nBorn, which is significantly different from the other two results even at relatively low energies. The\nsmall bump on the red line on Fig. (a) is due to the WW threshold. It is insignificant for positive cos(\u03b8).\n\n32\n\n\f5.6\n\nTesting \u03c4 decays\n\nIt is important to check, if the \u03c4 decays themselves, are generated correctly on the user platform. For this purpose, a separate test routine has been prepared which performs a standard MC-TESTER comparison of program execution with the pre-generated one (of 10 million events). In this case, all \u03c4 decay modes are activated and MC-TESTER is simply analyzing \u03c4 decays themselves.\n\nFig. 15 Ten most populous (out of 30) decay channels of\ntaken from the summary page of MCTESTER analysis. Statistically significant discrepancies between the benchmark (red) and the newly\ngenerated decays (green) can be easily localized and inspected further on plots of the MC-TESTER\ncomparison booklet.\n\nAs seen on Fig. 15 our test can point out possible problems. In this case the differences in\ndecay channels are due to different FORTRAN TAUOLA version used. The benchmark files\nwere generated using TAUOLA-CLEO while the test files use TAUOLA-ALEPH12 introducing different form-factor parameterization.\nAs it was shown in [3] there is plenty of room for improvements in description of \u03c4 decays.\nFor this purpose, data from Belle and BaBar should be used. This test as well as similar other\ntests can be useful for future checks if physics changes are of interest for e.g. LHC phenomenology. In any case, our software is organized to make updates rather straightforward.\n\n6.\n\nInstallation and user interaction\n\nOut of the two projects developed at the same time, the TAUOLA C++ interface and new\nMC-TESTER version, we have decided that the installation procedure should be performed\nfirst on MC-TESTER as it is necessary to test the installation of TAUOLA interface. Whenever a problem with MC-TESTER installation under different environments was found and\nsolved we simultaneously prepared the same patches for TAUOLA so that introducing the\ninterface would go smoothly after all problems with MC-TESTER have been resolved.\n\n12\n\nDetails regarding differences between these versions can be found in reference [16].\n\n33\n\n\f6.1\n\nATLAS\n\nSimulations for ATLAS experiment are created using simulation environment called Athena.\nAs described in reference [35]: \"The Athena framework is an enhanced version of the Gaudi\nframework [36] that was originally developed by the LHCb experiment, but is now a common\nATLAS-LHCb project and is in use by several other experiments including GLAST and HARP.\nAthena and Gaudi are concrete realizations of a component-based architecture (also called\nGaudi) which was designed for a wide range of physics data-processing applications. The fact\nthat it is component-based has allowed flexibility in developing both a range of shared components and, where appropriate, components that are specific to the particular experiment\nand better meet its particular requirements.\"\nAthena uses unique procedure to register generators in a queue distributed to the computer\ngrid. Each generator need its own interface designed for this framework. Fortunately, older\nversion of MC-TESTER and TAUOLA had such interface prepared so we already had a\nstrong starting point to create new interfaces. However, it is worth to note that such module, as well as few other scripts described here, had to be done independently from the rest\nof the code as a means to install the software into Athena environment. This kind of specialized code cannot be used for any other purpose.\nDespite the information that HepMC 2.05 has been introduced as the new standard for experiments, at the moment of installation, and to this day, Athena operated on the older version, 2.03. As described in HepMC release notes [23], the transition between versions 2.03\nand 2.04 was quite major as it introduced the units system used to adapt to different momentum and length units used in experiments. Since our software was specifically converted\nduring development to use this system, in order for our software to work under Athena we\nhad to downgrade it to HepMC version 2.03.\nOf course such downgrade had to be done only to Athena environment and only temporary,\nas sooner or later HepMC 2.05 would have to be installed on Athena as well, therefore we\nhave created it as a means of a shell script that user can execute independently from the\ninstallation. The script was designed to modify the code if the user platform had HepMC version lower than 2.04. To create a user-friendly solution, the script was incorporated into the\nconfiguration procedure so that depending on the HepMC version located by autoconf\nscript, the configuration could downgrade our software automatically.\nUnfortunately, that was not the only problem we have run into. After several trials, thanks to\nMarcin Wolter, Anna Kaczmarska and Eric Torrence, we have figured out that Athena was\nworking with an older, FORTRAN version of PYTHIA Monte Carlo generator \u2013 PYTHIA 6.\nThe problem with this generator was that it already used its own version of TAUOLA\nFORTRAN \u2013 similar to the one used in our software as an independent module. There would\nbe no problem with that if it were not for the collision in function names [37].\nSince FORTRAN names its symbols located in the library in a static way that cannot be\nchanged, the solution that allowed us to communicate between FORTRAN and C++ code by\noverwriting the routine filhep_ routine, failed as Athena took precedence in symbols\nloaded from internal libraries rather than those from a generator attached externally. Even\nthough decays were generated properly, they could not be saved into HepMC event record.\nThis was an unexpected result and we could not anticipate such problem designing our solution. Yet again, it was a problem unique to Athena environment and also seemed to be tem34\n\n\fporary as there were already plans to switch the Athena Monte Carlo generator to PYTHIA\n8.1. The tests with this generator under Athena worked without any problems, but in order\nto allow testing the new C++ interface until PYTHIA 8.1 is introduced, which could take anywhere from a month to a year, we had to come up with yet another fix specific for ATLAS\nexperiment and independent from the rest of the project.\nSince the ATLAS was the first platform we have started tests on, we have figured out that\nsimilar problems will occur with other experiments as well. Even though collaboration tries\nto introduce a single universal standard, separate experiments still focus on their own software management systems and are reluctant to change it as it has proven to work correctly.\nTherefore, each new standard takes different amount of time to be introduced in different\nexperiments. Fortunately, the problem was not hard to resolve and was fixed by renaming\nall FORTRAN symbols, as well as the overwritten filhep_ routine, which was done, again,\nas a shell script that can be executed by the individual user.\n6.2\n\nCMS\n\nThe CMS experiment uses its own software framework called CMSSW. As stated in online\nsources [38]: \"CMSSW is a large-scale software system for data acquisition, triggering, reconstruction and analysis of CMS data. It introduces Event Data Model based on the single\nevent contained in memory with modular content processed by separate units. Each unit has\na well-defined event processing functionality and communication between different steps of\nthe analysis routine is performed only using the event data structure.\" Within CMSSW, the\nindependent projects are managed using Source Configuration, Release, And Management\n(SCRAM) tool. In order to work under CMS we had to learn this environment and compile\nour project within it.\nThe main problem was that none of us had any experience with this environment at all. We\nhad to search for someone within the CMS experiment willing to help us with the installation. We were able to do so thanks to Yulia Yarba and Sami Lehti.\nSCRAM uses very strict compilation procedure forcing us to modify our software to meet\nthese standards. Since we are dealing with an old project, parts of the code had to be\ncleaned up to meet the compiler standards for CMS. In addition, SCRAM had troubles\nprocessing dictionaries generation performed by ROOT framework. It was a well-known\nproblem and the only solution we were able to achieve was to generate them manually and\ninclude them into the installation used by CMS. This operation has to be performed each\ntime the data structure changes, but it does not pose a huge problem, as there should be no\nneed of frequent changes to software architecture.\nAs with ATLAS, we expected that it would not be the end of our troubles. CMS environment\nuses its own system of parallel computation that produces a separate output files meant to\nbe merged together after simulation ends. Unfortunately, the default software used for\nmerging the ROOT output files failed in case of TAUOLA result files. Consequently, a separate ROOT script had to be written that allowed merging of these files. Such functionality\nwas not needed before, but it might become useful in other cases so we decided to add it to\nmain software distribution.\nFinally, the long analysis procedure using several input files proved to create a memory\nmanagement problems that, to this day, remain unresolved. Hopefully, with better under-\n\n35\n\n\fstanding of CMS environment we will be able to figure out and solve the problem as soon as\npossible.\n6.3\n\nLCG database\n\nQuoting the introduction from LCG webpage [39]: \"LHC Computing Grid (LCG) is a global collaboration producing a massive distributed computing infrastructure that provides more than\neight thousands physicists around the world with near real-time access to LHC data, and the\npower to process it. LCG Project manages a multi-platform universal database of all projects\navailable for all experiments around LHC. It is designed to build and maintain data storage\nand analysis infrastructure for the entire high energy physics community that will use the\nLHC.\" Software installation under LCG was a necessary step in order to distribute our software to all interested users with unified installation procedure for all platforms.\nSince the software must be designed to work on all machines connected to a grid, it has to\nbe compatible with different variants of Scientific Linux [40] installed at CERN and different\nOS/X installations along with several compiler versions for both 32bit and 64bit architecture.\nFor this purpose, a series of autotools scripts has been created and adopted by Oleg Zenin\nand Dmitri Konstantinov.\nThis method supposed to work under any platform, however, as with all software designed\nto be universal, there are always a compatibility issues. In case of scripts generated by autotools, the problem regards the ROOT configuration under OS/X and its library freetype,\nwhich does not exist under OS/X installations. It is a common problem and even though\nthis library is not used in our project, the appropriate line of configuration script containing\nthis directive had to be modified by hand. This proves once more that even the smallest\nthings may break the automated processes creating a need for individual solutions.\nIn the end, scripts used for LCG installation are very hard to modify manually and are nearly\nuseless to the regular user. In case of unique platform on which user would like to install the\nsoftware, they provide very limited help on how to solve the installation issues. Moreover,\nany future modification of these scripts would be hard to implement as the base scripts are\ncreated for LCG purpose only. That is why we decided to stick to our previous configuration\noption based only on autoconf software which we know exactly how to modify and can apply to any destination platform required.\nTherefore, the LCG scripts had been used to install the software into the database, and had\nbeen included in our software as an alternative means of installation that can be activated\nusing shell script. This way users familiar with LCG installation procedure can use these\nscripts if they want to, while everyone else may use our configuration procedure or modify\nthe platform dependant options by themselves, which introduces even more flexibility to the\nend user.\n6.4\n\nUser feedback\n\nAs soon as project became accessible to the users, we have received a lot of feedback, which\nallowed us to customize our software even further. This experience expressed yet another\ndifference between the commercial software and project created for wide collaboration.\nSince there is no single customer who would show his list of expectations and pointed out\nwhich parts of the code needs to be improved and which functionality should be implemented, there is a wide variety of users that can express their opinion and request limitless\nnumber of options that were impossible to predict at the planning step. Here I present the\n36\n\n\ffew implemented functionalities requested by the users. They serve as an example of how\nunique expectations users may have.\n\uf0b7\n\n\uf0b7\n\n\uf0b7\n\n6.5\n\nRandom Generator substitution\nThe core of Monte Carlo process is the random generator used within the algorithm.\nSince some experiments require strict verification and full control of the generator itself, we wrote an option Tauola\u2237setRandomGenerator(...) allowing the\nuser to substitute built-in random number generator with the one provided by the\nuser.\nSingle Tau decay\nThere are cases in which the whole event structure is not needed for the particular\nanalysis of a branch of decay tree. In such cases user might prefer to decay a single \u03c4\nmanually inside his own analysis routine. In such cases, the polarization information\nhas to be provided by hand. Tauola\u2237decayOne(...) provides such option generating single \u03c4 decay with or without the polarization information.\nExternal boosting routine\nAn advanced analysis might require that the decayed \u03c4 along with its daughters\nshould be boosted to a custom laboratory frame. Combined with the above option,\nTauola\u2237setBoostRoutine(...) gives flexibility that allows creating a wide\nrange of specialized tests.\nFuture plans\n\nThe development and installation of MC-TESTER is finished. Next step is further extending\nTAUOLA functionality according to new user requests and adopting both projects according\nto changes within the collaboration.\nApart from MC-TESTER and TAUOLA C++ interface, a third project needs to follow the\nsame routine. The abstract model of PHOTOS C++ interface [5] has already been created and\nthe first functionality has been implemented, but the project is far from being completed.\nSimilar to TAUOLA, PHOTOS is a large project requiring specialized approach and extensive\nknowledge in physics. However, it is well defined and with the basic experience gained from\nTAUOLA, the first steps of development of this project become much easier.\nLastly, an extension to low energy project TAUOLA FORTRAN is planned. It regards postgeneration filtering of decay models [3]. In future, the description of hadronic currents might\nchange, a dynamic methodology to introduce and test such changes will be needed. Such\ncurrents are visible through a set of static distributions. The idea is to create an external environment that allows modifying these distributions in order to fit them to already generated\ndata sets. Thanks to this, there will be no need to generate new set of events to test a particular model, saving considerable amount of time as data generation can take hours or days\nfor large data sets.\nAs physics and software engineering blends together, the software development becomes\nmuch harder as both coding and testing requires extensive research and a large amount of\ntime on validation of the results. Thanks to the experience gained during development of\nthis project, I hope to avoid repeating the same mistakes and exert this knowledge to overcome any new problems.\n\n37\n\n\f7.\n\nSummary\n\nThe development process described here does not include development of abstract level of\nmethods for program tests. Such methods were already created for previous version of the\nproject and were sufficient for our needs. That is why this challenging aspect of large project\ndevelopment requiring cooperation between programmers and physicists is not discussed\nhere.\nStarting from basic model prepared by Nadia Davidson and Zbigniew W\u0105s, my part of the\ncontribution to the project consists of:\n\uf0b7\n\n\uf0b7\n\uf0b7\n\uf0b7\n\nDevelopment of user configuration module, in particular writing options described in\nsections 4.5.3 to 4.5.6 as well as options created thanks to user feedback (see section\n6.4 for few examples of such options),\nCreation of configuration scripts and adjusting the installation procedure to user\nneeds,\nIntroduction of Electroweak Corrections module created by Gizo Nanava,\nDebugging, memory leak tracking and testing.\n\nNearing competition of first stable release, I assisted Zbigniew W\u0105s with installation of the\nsoftware within the collaboration experiments (described in Section 5.6). Last, but not least,\nmy responsibility was to assure that program remain coherent and to create throughout\ntests of consecutive versions.\nI have started on the project related to my thesis in fall 2008. The first stable version of\nTAUOLA has been released on 25 January 2010. As software gains more popularity, more\nuser feedback becomes available and new functionality has to be implemented, which show\nthat integration of this software within the collaboration has been successful. All what is left\nis to maintain the software introducing new functionality and implementing new physics\nprocesses currently under test. The pre-print version of the documentation is available under arXiv database [1]. Details regarding the stable TAUOLA release and the newest features, as well as doxygen documentation, can be found on TAUOLA webpage\nhttp://www.ph.unimelb.edu.au/~ndavidson/tauola/doxygen/.\nThe results of work on MC-TESTER has been published as a pre-print under arXiv database\n[2] and its final version containing the update mentioned here has already been prepared.\nMC-TESTER 1.24 has been successfully installed under ATLAS environment and we are\ncurrently performing last step of installation under CMS. It has also been installed within the\nLHC computing grid; users with access to LCG can find MC-TESTER on\n/afs/cern.ch/sw/lcg/external/MCGenerators/mctester directory. More\ninformation, as well as download of the newest version of MC-TESTER, can be found on\nthe webpage http://mc-tester.web.cern.ch/MC-TESTER/.\nThe experience gained from this project helped me understand two aspects of the abstract\nmodel implementation. The first being the creation of the large structure defining the behavior of each component of the project including structure-related algorithms and the main\nalgorithm outline. The second is the numerical programming of formulas, defining and implementing solution for specific exceptions from the regular algorithm behavior and resolving numerical stability issues. The first one can be described as looking on the software from\na macro scale. Typically, the difficulty is to design an appropriate abstract model and to\nmaintain its changes, which in case of high energy physics project, can occur at any time. The\n38\n\n\fsecond, which in comparison can be called microprogramming, on the first glance seems to\nbe easy, showing its true meaning during the most complex tests. Especially tests focused on\nthe precision.\nI have also used this project as opportunity to understand relation of physics-driven software\ndevelopment as well as practical case concepts of agile-based programming methodologies.\nBoth similarities and differences presented in Section 4.1 expanded my knowledge about\npractical implementation of the theory behind the agile approach. This aspect of my work is\nof course not conclusive. I am looking forward to progress on it in my professional life.\n\n39\n\n\fBibliography\n[1] N. Davidson, G. Nanava, T. Przedzinski, E. Richter-Was, Z. Was. Universal Interface of\nTAUOLA Technical and Physics Documentation. 2010. http://arxiv.org/abs/1002.0543.\n[2] N. Davidson, P. Golonka, T. Przedzinski, Z. Was. MC-TESTER v. 1.23: a universal tool for\ncomparisons of Monte Carlo predictions. 2008. http://arxiv.org/abs/0812.3215.\n[3] T. Przedzinski, Z. Was and 54 other co-autors. Quest for precision in hadronic cross\nsections at low energy: Monte Carlo tools vs. experimental data. 2009, pp. 72-82.\nhttp://arxiv.org/abs/0912.0749.\n[4] P. Golonka. Computer Simulation in High Energy Physics: a case for PHOTOS, MCTESTER, TAUOLA and at2sim. 2006. Phd thesis written under supervision of Zbigniew\nW\u0105s.\n[5] PHOTOS C++ interface.\nhttp://www.ph.unimelb.edu.au/~ndavidson/photos/doxygen/index.html.\n[6] Michael Kobel and others. Two-fermion production in electron positron collisions.\n2000. http://arXiv.org/abs/hep-ph/0007180.\n[7] E. Richter-Was, T. Szymocha and Z. Was. Why do we need higher order fully exclusive\nMonte Carlo generator for Higgs boson production from heavy quark fusion at LHC?\nPhys. Lett. 2004, Vol. B589, pp. 125-134. http://arXiv.org/abs/hep-ph/0402159.\n[8] G.Aad and others. Expected Performance of the ATLAS Experiment - Detector, Trigger\nand Physics. 2009. http://arXiv.org/abs/0901.0512.\n[9] J. Abdallah and others. Evidence for an excess of soft photons in hadronic decays of Z0.\nEur. Phys. J. 2006, Vol. C47, pp. 273-294. http://arXiv.org/abs/hep-ex/0604038.\n[10] M. Dobbs and Jorgen B. Hansen. The HepMC C++ Monte Carlo event record for High\nEnergy Physics. Comput. Phys. Commun. 2001, Vol. 134, pp. 41-46.\nhttps://savannah.cern.ch/projects/hepmc/.\n[11] GNU Project. Autoconf. http://www.gnu.org/software/autoconf/.\n[12] Dimitri van Heesch. Doxygen. 1997-2009. www.doxygen.org.\n[13] S. Jadach, Johann H. Kuhn and Z. Was. TAUOLA: A Library of Monte Carlo programs to\nsimulate decays of polarized tau leptons. Comput. Phys. Commun. 1990, Vol. 64, p. 275.\n[14] M. Jezabek, Z. Was, S. Jadach and J. H. Kuhn. The tau decay library TAUOLA, update\nwith exact O(alpha) QED corrections in tau to mu. (e) neutrino anti-neutrino decay\nmodes. Comput. Phys. Commun. 1992, Vol. 70, p. 69.\n[15] S. Jadach, Z. Was, R. Decker and J. H. Kuhn. The tau decay library TAUOLA: Version 2.4.\nComput. Phys. Commun. 1993, Vol. 76, p. 361.\n[16] P. Golonka and others. The tauola-photos-F environment for the TAUOLA and PHOTOS\npackages, release II. Comput. Phys. Commun. 2006, Vol. 174, pp. 818-835.\nhttp://arXiv.org/abs/hep-ph/0312240.\n[17] S. Jadach, Z. Was and B. F. L. Ward. The Precision Monte Carlo Event Generator KKMC\nFor Two-Fermion Final States In e+e- Collisions. Comput. Phys. Commun. 2000, Vol. 130.\n[18] S. Jadach, Z. W\u0105s and B. F. L. Ward. The Monte Carlo program KORALZ version 4.0 for\nthe lepton or quark pair production at LEP/SLC energies. Comput. Phys. Commun. 1994,\nVol. 79.\n[19] A. Andonov and others. SANCscope - v.1.00. Comput. Phys. Commun. 2006, Vol. 174,\npp. 481-517. http://arXiv.org/abs/hep-ph/0411186.\n[20] T. Sj\u00f6strand, S. Mrenna and P. Skands. A Brief Introduction to PYTHIA 8.1. Comput.\nPhys. Commun. 2008, Vol. 178, pp. 852-867. http://arXiv.org/abs/0710.3820.\n\n40\n\n\f[21] M. Bahr and others. Herwig++ Physics and Manual. Eur. Phys. J. 2008, Vol. C58, pp.\n639-707. http://arXiv.org/abs/0803.0883.\n[22] ROOT data analysis framework. http://root.cern.ch/drupal/.\n[23] HepMC 2.04.00 Release Notes. http://lcgapp.cern.ch/project/simu/HepMC/20400/.\n[24] Robert C. Martin. Agile Software Development, Principles, Patterns, and Practices.\n[25] Manifesto for Agile Software Developement. http://www.agilemanifesto.org/.\n[26] J. Nawrocki, \u0141. Olek, M. Jasi\u0144ski, B. Pali\u015bwiat, B. Walter, B. Pietrzak, P. Godek.\nR\u00f3wnowaga mi\u0119dzy zwinno\u015bci\u0105 a dyscyplin\u0105 z wykorzystaniem XPrince.\nhttp://xprince.net/.\n[27] Parasoft Concerto. http://www.parasoft.com/.\n[28] Z. Was and S. Jadach. First and higher order noninterference QED radiative corrections\nto the charge asymmetry at the Z resonance. Phys. Rev. 1990, Vol. D41, p. 1425.\n[29] A. Andonov and others. Standard SANC Modules. 2008.\nhttp://arXiv.org/abs/0812.4207.\n[30] T. Pierzchala, E. Richter-Was, Z. Was and M. Worek. Spin effects in tau-lepton pair\nproduction at LHC. Acta Phys. Polon. 2001, Vol. B32, pp. 1277-1296.\nhttp://arXiv.org/abs/hep-ph/0101311.\n[31] Z. Was and M. Worek. Transverse spin effects in H/A --> tau+ tau-, tau+- --> nu X+-,\nMonte Carlo approach. Acta Phys. Polon. 2002, Vol. B33, pp. 1875-1884.\nhttp://arXiv.org/abs/hep-ph/0202007.\n[32] K. Desch, A. Imhof, Z. Was and M. Worek. Probing the CP nature of the Higgs boson at\nlinear colliders with tau spin correlations: The case of mixed scalar-pseudoscalar\ncouplings. Phys. Lett. 2004, Vol. B579, pp. 157-164. http://arXiv.org/abs/hepph/0307331.\n[33] Nadia E. Adam, Valerie Halyo, Scott A. Yost and Wenhan Zhu. Evaluation of the\nTheoretical Uncertainties in the Z to ll Cross Sections at the LHC. JHEP. 2008, Vol. 05, p.\n62. http://arXiv.org/abs/0802.3251.\n[34] Nadia E. Adam, Valerie Halyo, Scott A. Yost and Wenhan Zhu. Evaluation of the\nTheoretical Uncertainties in the W to Lepton and Neutrino Cross Sections at the LHC.\nJHEP. 2008, Vol. 09, p. 133. http://arXiv.org/abs/0808.0758.\n[35] LHC Experiments Committee; LHCC. ATLAS computing: Technical Design Report. pp. 2731. http://cdsweb.cern.ch/record/837738?ln=pl.\n[36] Gaudi LHCb Data Processing Applications Framework. https://lhcbcomp.web.cern.ch/lhcb-comp/Frameworks/Gaudi/.\n[37] M. Wolter. TAUOLA C++ in the ATLAS athena framework. ATL-COM-SOFT-2010-002,\naccess restricted.\n[38] CMSSW. https://twiki.cern.ch/twiki/bin/view/CMS/SWGuide.\n[39] LCG Computing Grid. http://lcg.web.cern.ch/lcg/.\n[40] Scientific Linux CERN. http://linux.web.cern.ch/linux/scientific.shtml.\n[41] S. Jadach and Z. Was. QED O(alpha**3) radiative corrections to the reaction e+ e- to\ntau+ tau- including spin and mass effects. (erratum). Acta Phys. Polon. 1984, Vol. B15.\n\n41\n\n\f"}