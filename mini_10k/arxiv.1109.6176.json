{"id": "http://arxiv.org/abs/1109.6176v2", "guidislink": true, "updated": "2011-12-12T14:15:05Z", "updated_parsed": [2011, 12, 12, 14, 15, 5, 0, 346, 0], "published": "2011-09-28T11:47:22Z", "published_parsed": [2011, 9, 28, 11, 47, 22, 2, 271, 0], "title": "Estimators for the interval censoring problem", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1109.3533%2C1109.4956%2C1109.6534%2C1109.3623%2C1109.3146%2C1109.4117%2C1109.4005%2C1109.2034%2C1109.4166%2C1109.3879%2C1109.4045%2C1109.5882%2C1109.5049%2C1109.3001%2C1109.3684%2C1109.2207%2C1109.0137%2C1109.0613%2C1109.4139%2C1109.6556%2C1109.2380%2C1109.2239%2C1109.0389%2C1109.5210%2C1109.5812%2C1109.1876%2C1109.1323%2C1109.4823%2C1109.6231%2C1109.6472%2C1109.1872%2C1109.5357%2C1109.5478%2C1109.5418%2C1109.0473%2C1109.4426%2C1109.6904%2C1109.5236%2C1109.0758%2C1109.5755%2C1109.6619%2C1109.2424%2C1109.6176%2C1109.4668%2C1109.2266%2C1109.0807%2C1109.1189%2C1109.6923%2C1109.1058%2C1109.6214%2C1109.4978%2C1109.5239%2C1109.6338%2C1109.1466%2C1109.3390%2C1109.2679%2C1109.4986%2C1109.6047%2C1109.2478%2C1109.1219%2C1109.1170%2C1109.1348%2C1109.1777%2C1109.0344%2C1109.3585%2C1109.1769%2C1109.3935%2C1109.6890%2C1109.3849%2C1109.4581%2C1109.5492%2C1109.4021%2C1109.1570%2C1109.2989%2C1109.4691%2C1109.1247%2C1109.1486%2C1109.6928%2C1109.5860%2C1109.2969%2C1109.1078%2C1109.0042%2C1109.1784%2C1109.2284%2C1109.6351%2C1109.5396%2C1109.1057%2C1109.5647%2C1109.4302%2C1109.5111%2C1109.1851%2C1109.3931%2C1109.1156%2C1109.4633%2C1109.5457%2C1109.2176%2C1109.1782%2C1109.6637%2C1109.6537%2C1109.2983%2C1109.4944&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Estimators for the interval censoring problem"}, "summary": "We study three estimators for the interval censoring case 2 problem, a\nhistogram-type estimator, proposed in Birg\\'e (1999), the maximum likelihood\nestimator (MLE) and the smoothed MLE, using a smoothing kernel. Our focus is on\nthe asymptotic distribution of the estimators at a fixed point. The estimators\nare compared in a simulation study.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1109.3533%2C1109.4956%2C1109.6534%2C1109.3623%2C1109.3146%2C1109.4117%2C1109.4005%2C1109.2034%2C1109.4166%2C1109.3879%2C1109.4045%2C1109.5882%2C1109.5049%2C1109.3001%2C1109.3684%2C1109.2207%2C1109.0137%2C1109.0613%2C1109.4139%2C1109.6556%2C1109.2380%2C1109.2239%2C1109.0389%2C1109.5210%2C1109.5812%2C1109.1876%2C1109.1323%2C1109.4823%2C1109.6231%2C1109.6472%2C1109.1872%2C1109.5357%2C1109.5478%2C1109.5418%2C1109.0473%2C1109.4426%2C1109.6904%2C1109.5236%2C1109.0758%2C1109.5755%2C1109.6619%2C1109.2424%2C1109.6176%2C1109.4668%2C1109.2266%2C1109.0807%2C1109.1189%2C1109.6923%2C1109.1058%2C1109.6214%2C1109.4978%2C1109.5239%2C1109.6338%2C1109.1466%2C1109.3390%2C1109.2679%2C1109.4986%2C1109.6047%2C1109.2478%2C1109.1219%2C1109.1170%2C1109.1348%2C1109.1777%2C1109.0344%2C1109.3585%2C1109.1769%2C1109.3935%2C1109.6890%2C1109.3849%2C1109.4581%2C1109.5492%2C1109.4021%2C1109.1570%2C1109.2989%2C1109.4691%2C1109.1247%2C1109.1486%2C1109.6928%2C1109.5860%2C1109.2969%2C1109.1078%2C1109.0042%2C1109.1784%2C1109.2284%2C1109.6351%2C1109.5396%2C1109.1057%2C1109.5647%2C1109.4302%2C1109.5111%2C1109.1851%2C1109.3931%2C1109.1156%2C1109.4633%2C1109.5457%2C1109.2176%2C1109.1782%2C1109.6637%2C1109.6537%2C1109.2983%2C1109.4944&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We study three estimators for the interval censoring case 2 problem, a\nhistogram-type estimator, proposed in Birg\\'e (1999), the maximum likelihood\nestimator (MLE) and the smoothed MLE, using a smoothing kernel. Our focus is on\nthe asymptotic distribution of the estimators at a fixed point. The estimators\nare compared in a simulation study."}, "authors": ["Piet Groeneboom", "Tom Ketelaars"], "author_detail": {"name": "Tom Ketelaars"}, "author": "Tom Ketelaars", "arxiv_comment": "42 pages, 4 figures", "links": [{"href": "http://arxiv.org/abs/1109.6176v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1109.6176v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.TH", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "62G20, 62N01 (Primary) 60F05 (Secondary)", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1109.6176v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1109.6176v2", "journal_reference": null, "doi": null, "fulltext": "Electronic Journal of Statistics\nISSN: 1935-7524\narXiv: 1109.6176\n\nEstimators for the interval censoring\nproblem\n\narXiv:1109.6176v2 [math.ST] 12 Dec 2011\n\nPiet Groeneboom and Tom Ketelaars\nAddress of the first author\nDelft Institute of Applied Mathematics\nMekelweg 4, 2628 CD Delft\nThe Netherlands\ne-mail: P.Groeneboom@tudelft.nl\nhttp: // dutiosc. twi. tudelft. nl/ ~ pietg/\nAddress of the second author\nCredit Suisse\nAttn.: Tom Ketelaars\n11 Madison Avenue\nNew York, NY, 10010\ne-mail: tom.ketelaars@credit-suisse.com\nAbstract: We study three estimators for the interval censoring case 2\nproblem, a histogram-type estimator, proposed in [1], the maximum likelihood estimator (MLE) and the smoothed MLE, using a smoothing kernel.\nOur focus is on the asymptotic distribution of the estimators at a fixed\npoint. The estimators are compared in a simulation study.\nAMS 2000 subject classifications: Primary 62G20, 62N01; secondary\n60F05.\nKeywords and phrases: Interval censoring, maximum likelihood, Birg\u00e9's\nestimator, asymptotic properties, minimax bounds, smoothed maximum\nlikelihood estimator, kernel estimators.\n\n1. Introduction\nLet X1 , . . . , Xn be a sample of unobservable random variables from an unknown\ndistribution function F0 on the interval [0, 1]. More generally, we could take an\narbitrary closed interval [a, b] as support for the underlying distribution, but for\nthe purposes of the development of the theory, we can just as well take [0, 1], as\nis also done in [1].\nSuppose that one can observe n pairs (Ti , Ui ), independent of Xi , with a joint\ndensity function h on the upper triangle of the unit square, for which the sum\nof the marginal densities is bounded away from zero. Moreover,\n\u2206i1 = 1{Xi \u2264Ti } ,\n\n\u2206i2 = 1{Ti <Xi \u2264Ui } ,\n\n\u2206i3 = 1 \u2212 \u2206i,1 \u2212 \u2206i,1 ,\n\n(1.1)\n\nprovide the only information one has on the position of the random variables\nXi with respect to the observation times Ti and Ui . In this set-up we want to\nestimate the unknown distribution function F0 , generating the \"unobservables\"\nXi . This setting is known as interval censoring, case 2.\n1\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n2\n\nThe model of current status data, also known as interval censoring, case 1,\nhas been thoroughly studied, and has a theory which is considerably simpler\nthan the theory for the interval censoring, case 2, model. In the current status\nmodel one only has one observation time Ti , corresponding to the unobservable\nXi , and the only information we have about Xi is whether Xi is to the left or\nto the right of Ti .\nAlthough the present paper mainly focuses on the case 2 model, we start\nby discussing the current status model, in order to put this paper into a more\ngeneral context and to explain why the case 2 model is so much harder to study.\nIn the current status model, the only observations which are available to us are\nthe pairs\n(Ti , \u2206i ),\n\u2206i = 1{Xi \u2264Ti } ,\nso we do not observe Xi itself, but only its \"current status\" \u2206i . The nonparametric maximumum likelihood estimator, commonly denoted by NPMLE or just\nMLE, maximizes the (partial) log likelihood\nn\nX\n\n{\u2206i log F (Ti ) + (1 \u2212 \u2206i ) log (1 \u2212 F (Ti ))} ,\n\ni=1\n\nwhere the maximization is over all distribution functions F .\nThe MLE can be found in one step by computing the left-continuous slope\nof the greatest convex minorant of the cusum diagram of the points (0, 0) and\nthe points\n\uf8f6\n\uf8eb\nX\n\uf8edi,\n(1.2)\n\u2206(j) \uf8f8 , i = 1, . . . , n,\nj\u2264i\n\nusing a notation, introduced in [10]. Here \u2206(j) denotes the indicator corresponding to the jth order statistic T(j) . The theory for this estimator is further\ndeveloped in [10], where also the (non-normal) pointwise limit distribution is\nderived and it is shown that the rate of convergence is n\u22121/3 .\nIn contrast, there is no such one-step algorithm for computing the MLE in\nthe case 2 situation, where one wants to maximize\nn\nX\n\n{\u2206i1 log F (Ti ) + \u2206i2 log {F (Ui ) \u2212 F (Ti )} + \u2206i3 log (1 \u2212 F (Ui ))} .\n\ni=1\n\nover distribution functions F . One has to take recourse to iterative algorithms,\nfor example the iterative convex minorant algorithm, introduced in [10] and\nfurther developed in [11]. Moreover, the MLE can possibly achieve a faster local\nrate of convergence than in the current status model, depending on properties\nof the bivariate distribution of the observation times (Ti , Ui ).\nIn the so-called non-separated case, the density of the pair of observation\ntimes (Ti , Ui ) is positive on the diagonal, meaning that we can have arbitrarily small observation intervals [Ti , Ui ]. For this situation, [1] proposes a simple\npiecewise constant estimator for F0 , with the purpose of showing that in this\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n3\n\nsituation an estimator can be constructed that achieves the (n log n)\u22121/3 convergence rate, which is optimal in a minimax sense, both using a global loss\nfunction , and using a local loss function for the estimation at a fixed point. In\nthe separated case, the observation times Ti and Ui cannot become arbitrarily\nclose: in this case there exists an \u000f > 0 so that Ui \u2212 Ti > \u000f for each i. In this\ncase the convergence rate of Birg\u00e9's estimator is n\u22121/3 again, which is also the\nminimax rate for the current status model. For both situations we derive the\nasymptotic behavior of Birg\u00e9's estimator, and compare this with the behavior\nof the MLE in a simulation study. The simulations show a better behavior of\nthe MLE, probably caused by the local adaptivity of the MLE.\nA common complaint about the MLEs is that under the conditions for which\nthe local asymptotic distribution result is derived, other estimators can be suggested, which in fact attain a faster rate of convergence. Such estimators are\ndiscussed for the current status model in, e.g., [8], [9] and [7]. We introduce a\nsimilar estimator below for the case 2 model below, the smoothed maximum\nlikelihood estimator (SMLE). The smoothed MLE is defined by\nZ\nF\u0303nM L (t) = IK ((t \u2212 u)/bn ) dF\u0302n (u),\n(1.3)\nwhere\nZ\n\nu\n\nIK(u) =\n\nK(w) dw =\n\u2212\u221e\n\n\uf8f1\n0\n\uf8f4\n\uf8f4\n\uf8f2 Z\n\uf8f4\n\uf8f4\n\uf8f3\n\n, u < \u22121\n\nu\n\nK(w) dw\n\n, u \u2208 [\u22121, 1],\n\n\u22121\n\n1\n\n, u > 1,\n\nletting K be a smooth symmetric kernel, with support [\u22121, 1], like the triweight\nkernel\n\u00013\n35\n1 \u2212 u2 1[\u22121,1] (u),\nK(u) = 32\nand taking the bandwidth bn \u0010 n\u22121/5 . Note that\nZ\n1\ndef d M L\nF\u0303n (t) =\nf \u0303nM L (t) =\nK ((t \u2212 u)/bn ) dF\u0302n (u)\ndt\nbn\nis an estimate of the density f0 of the underlying distribution function F0 .\nAnalogously to what has been proved for the current status model, we expect the smoothed MLE to converge at (at least) rate n\u22122/5 under appropriate\nregularity conditions. It is an attractive alternative to the MLE and histogramtype estimator of [1]. We give a heuristic discussion on this in section 6. Just\nas in [3] and [4], the asymptotic variance depends on the solution of an integral equation. The asymptotic expressions for the variance, obtained by solving\nthese equations numerically, give a rather good fit with the actually observed\nvariances, as shown in section 6. The SMLE can probably also be used for a\ntwo-sample test for interval censored data, analogous to the two-sample test\nfor current status data, introduced in [7]. The MSE of the smoothed MLE is\nmuch smaller than that of Birg\u00e9's estimator or the MLE for smooth underlying\ndistribution functions, as is illustrated in the sections on the simulations.\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n4\n\nA picture of the three estimators is shown in Figure 1. The MLE and smoothed\nMLE are monotone, in contrast with Birg\u00e9's estimator. Also Birg\u00e9's estimator\ncan have negative values and values larger than 1; both events happen in the\npicture shown. This cannot happen for the MLE and smoothed MLE, since these\nare based on isotonization; the smoothed MLE is an integral of a positive kernel\nw.r.t. the (positive) jumps of the MLE, and inherits the monotonicity properties of the MLE. Although histogram-type estimators (like Birg\u00e9's estimator)\nand kernel estimators without any isotonization are much easier to analyze than\nthe estimators, based on isotonization, the price one has to pay is the behavior\nillustrated in Figure 1.\n\n1.2\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n0.0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1.0\n\nFig 1. Birg\u00e9's estimator (dashed), the MLE (dotted), and the smoothed MLE (dashed-dotted)\nfor sample size n = 1000 and bn = n\u22121/5 , when F0 (x) = 1 \u2212 (1 \u2212 x)2 (solid curve) and the\nobservation distribution is uniform on the upper triangle of the unit square.\n\n2. A local minimax result for the non-separated case\nIn this section we derive a local minimax result for the non-separated case of\nthe interval censoring problem, case 2. This result will provide the best possible\nlocal convergence rate and also the best constant, as far as this constant depends\non the underlying distributions.\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n5\n\nOur approach makes use of a perturbation Fn of F0 which is defined by\n\uf8f1\nF0 (x)\nif x < t0 \u2212 c(n log n)\u22121/3\n\uf8f4\n\uf8f4\n\uf8f2\n\u22121/3\nF0 (t0 \u2212 c(n log n)\n) if x \u2208 [t0 \u2212 c(n log n)\u22121/3 , t0 )\nFn (x) =\n\u22121/3\nF (t + c(n log n)\n) if x \u2208 [t0 , t0 + c(n log n)\u22121/3 )\n\uf8f4\n\uf8f4\n\uf8f3 0 0\nF0 (x)\nif x \u2265 t0 + c(n log n)\u22121/3\nfor a c > 0 to be specified below.\nBefore stating the theorem to be proved, we introduce some notation. Let\n\u2206 = (\u22061 , \u22062 ) \u2208 T := {(1, 0), (0, 1), (0, 0)} and define the densities q0 and qn by\nq0 (t, u, \u03b4) = h(t, u)F0 (t)\u03b41 (F0 (u) \u2212 F0 (t))\u03b42 (1 \u2212 F0 (u))1\u2212\u03b41 \u2212\u03b42\nqn (t, u, \u03b4) = h(t, u)Fn (t)\u03b41 (Fn (u) \u2212 Fn (t))\u03b42 (1 \u2212 Fn (u))1\u2212\u03b41 \u2212\u03b42\nwith respect to the measure \u03bc = \u03bb1 \u2297 \u03bb2 on \u03a9 = R2+ \u00d7 T , where \u03bb1 is the\nLebesgue measure and \u03bb2 is counting measure. We note that q0 is the joint\ndensity of (T, U, \u22061 , \u22062 ).\nFurthermore, let (Ln ), n \u2265 1, be a sequence of estimators for F0 (t0 ), based\non samples of size n, generated by q0 . That is, we can write\nLn = ln ((T1 , U1 , \u22061,1 , \u22061,2 ), . . . , (Tn , Un , \u2206n,1 , \u2206n,1 )),\nwhere ln is a Borel measurable function. Then, the following theorem holds:\nTheorem 2.1.\nlim inf(n log n)1/3 max{En,q0 |Ln \u2212 F0 (t0 )|, En,qn |Ln \u2212 Fn (t0 )|}\n\nn\u2192\u221e\n1/3\n\n\u2265\n\n6\n\n4\n\nexp(\u22121/3){f0 (t0 )2 /h(t0 , t0 )}1/3 ,\n\nwhere En,q denotes the expectation with respect to the product measure q \u2297n .\nIn our proof we need the following lemma, which is proved in [6]. This type\nof result is often denoted as \"LeCam's lemma\".\nLemma 2.1. Let G be a set of probability densities on a measurable space\n(\u03a9, A) with respect to a \u03c3-finite dominating measure \u03bc, and let L be a realvalued functional on G. Moreover, let f : [0, \u221e) \u2192 R be an increasing convex\nloss function, with f(0)=0. Then, for any q1 , q2 \u2208 G such that the Hellinger\ndistance H(q1 , q2 ) < 1 :\n\b\ninf max En,q1 f (|Ln \u2212 Lq1 |), En,q2 f (|Ln \u2212 Lq2 |)\nLn\n\u0012\n\u0013\n1\n2\n2n\n\u2265f\n|Lq1 \u2212 Lq2 |{1 \u2212 H (q1 , q2 )}\n.\n4\n\nProof of theorem 2.1. Let the partitioning A1,n \u222a . . . \u222a A6,n of {(t, u) \u2208 R2+ :\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n6\n\nt < u} be defined by\nA1,n = {(t, u) \u2208 R2+ : 0 < t < t0 \u2212 \u03b4n , t0 \u2212 \u03b4n \u2264 u < t0 )}\nA2,n = {(t, u) \u2208 R2+ : 0 < t < t0 \u2212 \u03b4n , t0 \u2264 u < t0 + \u03b4n }\nA3,n = {(t, u) \u2208 R2+ : t0 \u2212 \u03b4n \u2264 t < t0 , t0 + \u03b4n < u < \u221e}\nA4,n = {(t, u) \u2208 R2+ : t0 \u2264 t < t0 + \u03b4n , t0 + \u03b4n < u < \u221e}\nA5,n = {(t, u) \u2208 R2+ : t0 \u2212 \u03b4n \u2264 t < t0 + \u03b4n , t < u < t0 + \u03b4n }\nA6,n = {(t, u) \u2208 R2+ : t < u}\\{A1,n \u222a . . . \u222a A5,n },\nwhere \u03b4n = c(n log n)\u22121/3 . The partitioning is shown in figure 2.\nv\n\n....\n....\n....\n....\n.....\n...\n...\n...\n.....\n..\n.....\n...\n...\n.....\n.\n.\n.\n.\n...\n.\n.\n.\n....\n...\n....\n....\n.....\n...\n.....\n...\n...\n.....\n...\n...\n...\n.....\n.\n.\n.\n.\n.\n...\n.\n.\n.\n....\n... 3,n.... 4,n....\n6,n\n6,n ..........\n...\n...\n...\n.....\n...\n...\n...\n.....\n.\n.\n.\n.\n.\n...\n.\n.\n.\n.\n.....\n...\n....\n....\n.....\n...\n...\n...\n.....\n...\n...\n... .........\n.\n. .....\n...\n.\n.\n.\n..\n.. ...\n..............................................................................................................................................\n.....\n....\nn 0\n..... 0\n.\n.\n.\n.\n.\n.\n2,n\n5,n\n..\n.....\n...\n.........................................................................................\n.....\n.....\n.\n.\n.\n....\n.\n..\n0 0\n... .........\n1,n\n.. .....\n................................................................................................\n.\n.\n.\n..\nn 0\n..... 0\n.....\n.....\n.....\n6,n ..........\n.\n....\n.....\n.....\n.....\n.\n.\n.\n.\n.....\n.....\n.....\n.....\n....\n.\n.\n.\n.\n.....\n.....\n.....\n.....\n.....\n.\n.\n.\n.\n\nA\n\nA\n\nA\n\nA\n\nA\n\nA\n\nA\n\n\u2022\n(t + \u03b4 , t )\n\n\u2022\n(t , t )\n\n\u2022\n(t \u2212 \u03b4 , t )\n\nA\n\nu\n\n(0, 0)\nFig 2. The areas A1,n , . . . , A6,n\n\nThen the squared Hellinger distance between q0 and qn can be written as\nZ\n1\n\u221a\n\u221a\n2\nH (qn , q0 ) :=\n{ qn \u2212 q0 } d\u03bc\n2 \u03a9\n5 Z\n\u0010p\n\u00112\np\n1X\nFn (t) \u2212 F0 (t) dtdu+\n=\nh(t, u)\n2\nk=1 Ak,n\n5 Z\n\u0010p\n\u00112\np\n1X\n+\nh(t, u)\nFn (u) \u2212 Fn (t) \u2212 F0 (u) \u2212 F0 (t) dtdu\n2\nk=1 Ak,n\n5 Z\n\u0010p\n\u00112\np\n1X\n+\nh(t, u)\n1 \u2212 Fn (u) \u2212 1 \u2212 F0 (u) dtdu.\n2\nAk,n\nk=1\n\nWe now calculate the three integrals over A1,n .\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\nObviously, we have\nZ\nh(t, u)\n\n\u0010p\n\nFn (t) \u2212\n\np\n\n\u00112\nF0 (t) dtdu = 0.\n\n7\n\n(2.1)\n\nA1,n\n\nFurthermore,\nZ\nh(t, u)\n\n\u0010p\n\u00112\np\nFn (u) \u2212 Fn (t) \u2212 F0 (u) \u2212 F0 (t) dtdu\n\nA1,n\n\nZ\n=\n\n(h(t, t0 ) + o(1))\nA1,n\n\nZ\n\nt0 \u2212\u03b4n\n\n=\n\nh(t, t0 )\n0\n\n(u \u2212 t0 + \u03b4n )2 f0 (t0 )2 + o(\u03b4n2 )\ndtdu\n4(F0 (t0 ) \u2212 F0 (t))\n\nf0 (t0 )2 (\u03b4n3 + o(\u03b4n3 ))\ndt.\n12(F0 (t0 ) \u2212 F0 (t))\n\nThe last integral can be split into two integrals over the sets [0, t0 \u2212 \u03ban ) and\n[t0 \u2212 \u03ban , t0 \u2212 \u03b4n ], where \u03ban = (log n)\u22121/3 . Since\nZ\n\nt0 \u2212\u03ban\n\nh(t, t0 )\n0\n\nf0 (t0 )2 (\u03b4n3 + o(\u03b4n3 ))\ndt = O(\u03b4n3 \u03ba\u22121\nn )\n12(F0 (t0 ) \u2212 F0 (t))\n\nand\nt0 \u2212\u03b4n\n\n(\u03b4n3 + o(\u03b4n3 ))f0 (t0 )2\ndt\n12(F0 (t0 ) \u2212 F0 (t))\nt0 \u2212\u03ban\nZ t0 \u2212\u03b4n\n= (f0 (t0 )(\u03b4n3 + o(\u03b4n3 ))/12)\n(h(t0 , t0 ) + o(1))\n\nZ\n\nh(t, t0 )\n\nt0 \u2212\u03ban\n\nf0 (t) + o(1)\ndt\n(F0 (t0 ) \u2212 F0 (t))\nt \u2212\u03b4\n\n= (f0 (t0 )h(t0 , t0 )(\u03b4n3 + o(\u03b4n3 ))/12) [\u2212 log(F0 (t0 ) \u2212 F0 (t))]t00 \u2212\u03bann\n= f0 (t0 )h(t0 , t0 )c3 n\u22121 /36 + o(n\u22121 ),\nit follows that\nZ\nh(t, u)\n\n\u0010p\n\nFn (u) \u2212 Fn (t) \u2212\n\np\n\n\u00112\nF0 (u) \u2212 F0 (t) dtdu\n\nA1,n\n\n= f0 (t0 )h(t0 , t0 )c3 n\u22121 /36 + o(n\u22121 ).\n\n(2.2)\n\nNext, a straightforward computation shows that\nZ\n\u00112\n\u0010p\np\n1 \u2212 Fn (u) \u2212 1 \u2212 F0 (u) )dtdu\nh(t, u)\nA1,n\n\nZ\n=\nA1,n\n\n(u \u2212 t0 + \u03b4n )2 f0 (t0 )2\ndtdu = O(\u03b4n3 ).\n4(1 \u2212 F0 (t0 ))\n\n(2.3)\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n8\n\nUsing (2.1), (2.2) and (2.3), we get\nZ\n\u00112\n\u0010p\np\nFn (t) \u2212 F0 (t) dtdu\nh(t, u)\nA1,n\n\nZ\n\n\u00112\n\u0010p\np\nFn (u) \u2212 Fn (t) \u2212 F0 (u) \u2212 F0 (t) dtdu\n\n+\nA1,n\n\nZ\n\n\u0010p\n\u00112\np\n1 \u2212 Fn (u) \u2212 1 \u2212 F0 (u) dtdu\n\n+\nA1,n\n\n= f0 (t0 )h(t0 , t0 )n\u22121 /36 + O(\u03b4n3 \u03ba\u22121\nn ).\nThe integrals over A2,n , A3,n and A4,n can be treated in a similar way. Indeed,\nZ\n\u00112\n\u0010p\np\nFn (t) \u2212 F0 (t) dtdu\nh(t, u)\nAk,n\n\nZ\n+\n\n\u0010p\n\nFn (u) \u2212 Fn (t) \u2212\n\n\u0010p\n\n1 \u2212 Fn (u) \u2212\n\np\n\nF0 (u) \u2212 F0 (t)\n\n\u00112\n\ndtdu\n\nAk,n\n\nZ\n+\n\n\u00112\np\n1 \u2212 F0 (u) dt du\n\nAk,n\n\n= f0 (t0 )h(t0 , t0 )n\u22121 /36 + O(\u03b4n3 \u03ba\u22121\nn ),\n\nk = 2, 3, 4.\n\nMoreover, it is easily verified that\nZ\n\u00112\n\u0010p\np\nFn (t) \u2212 F0 (t) dtdu\nh(t, u)\nA5,n\n\nZ\n\n\u0010p\n\u00112\np\nFn (u) \u2212 Fn (t) \u2212 F0 (u) \u2212 F0 (t) dtdu\n\n+\nA5,n\n\nZ\n\n\u0010p\n\u00112\np\n\u0001\n1 \u2212 Fn (u) \u2212 1 \u2212 F0 (u) dtdu = O \u03b4n3 .\n\n+\nA5,n\n\nThus, we infer that the asymptotic squared Hellinger distance between q0 and\nqn is given by\nH 2 (q0 , qn ) = f0 (t0 )h(t0 , t0 )n\u22121 /18.\nBy using lemma 2.1 we now get:\n(n log n)1/3 inf max{En,q0 |Tn \u2212 F0 (t0 )|, En,qn |Tn \u2212 Fn (t0 )|}\nTn\n\n1\n\u2265 (n log n)1/3 |Fn (t0 ) \u2212 F0 (t0 )|{1 \u2212 H 2 (qn , q0 )}2\n4\n\u001a\n\u001b\n1\n1\n\u2192 cf0 (t0 ) exp \u2212 h(t0 , t0 )f (t0 )c3\n4\n18\nMaximizing the last expression over c yields the desired minimax lower bound.\n\u0003\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n9\n\n3. Asymptotic distribution of Birg\u00e9's estimator in the\nnon-separated case\n[1] constructed a histogram-type estimator to show that the minimax lower\nbound rate of the preceding section can indeed be attained in the non-separated\ncase. It is defined in the following way. Let t0 be an interior point of [0,1], let c\nbe a positive constant and let K = bc\u22121 (n log n)1/3 c, where n is the sample size\nand where bxc denotes the \"floor\" of x, i.e., the largest integer which is smaller\nthan or equal to x. We distinguish two cases.\n(i) If Kt0 \u2208 N, the interval [0, 1] is partitioned into K intervals Ij , j =\n1, . . . , K, of equal length 1/K, where Ij = [tj , tj+1 ), 1 \u2264 j < K, IK =\n[tK , tK+1 ], and t1 = 0, tK+1 = 1.\n(ii) If Kt0 \u2208\n/ N, the interval [0, 1] is partitioned into K + 1 intervals Ij , where\nIj = [tj , tj+1 ), 1 \u2264 j \u2264 K, IK+1 = [tK+1 , tK+2 ], and t1 = 0, tj = t0 \u2212\n(bt0 Kc \u2212 j) /K, 1 \u2264 j \u2264 K + 1, tK+2 = 1. Note that in this case the\nintervals I2 , . . . , IK have length 1/K, but that I1 and IK+1 have a shorter\nlength. Furthermore, just as in case (i), t0 is the left boundary point of\none of the intervals Ij .\nIn fact we slightly modified the definition of Birg\u00e9 who always partitions the\ninterval into K subintervals of equal length. The reason for our modification\nis that we want to assign a fixed position to t0 with respect to the boundary\npoints of the interval Ij to which it belongs, since the bias of the estimator\nheavily depends on this position. Letting t0 be a left boundary point enables us\nto compare the results for different sample sizes \"on equal footing\", so to speak.\nLet \u2206i,1 , \u2206i,2 and \u2206i,3 be defined by (1.1). We define, following [1], for\n1 \u2264 j, k \u2264 K,\nNj = # {Ti : Ti \u2208 Ij } ,\n\nMj = # {Ui : Ui \u2208 Ij }\n\nQj,k = # {(Ti , Ui ) : Ti \u2208 Ij , Ui \u2208 Ik } ,\nand\nNj0 =\n\nX\nTi \u2208Ij\n\n\u2206i,1 ,\n\nQ0j,k =\n\nX\nTi \u2208Ij , Ui \u2208Ik\n\n\u2206i,2 ,\n\nMj0 =\n\nX\n\n\u2206i,3 .\n\nUi \u2208Ij\n\nIn addition to these (integer-valued) random variables, [1] defines the random\nvariables:\n\uf8f1\nQ0j,k\nN0\n\uf8f4\n\uf8f4\n, j < k,\n\uf8f2 k \u2212\nNk\nQj,k\n(3.1)\nF\u0302 (j,k) =\n0\nQ\nM0\n\uf8f4\n\uf8f4\n\uf8f3 1 \u2212 k + k,j , j > k,\nMk\nQk,j\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n10\n\nweights wj,k , defined by\n\nwj,k =\n\nwhere\nWj =\n\nX\nk<j\n\np\n\n\uf8f1 p\nNk \u2227 (KQj,k )\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2 (k \u2212 j + 1)Wj\n\n, j < k,\n\np\n\uf8f4\n\uf8f4\n\uf8f4\nMk \u2227 (KQk,j )\n\uf8f4\n\uf8f3\n(j \u2212 k + 1)Wj\n\n, j > k,\n\nMk \u2227 (KQj,k ) X\n+\nj\u2212k+1\nk>j\n\n(3.2)\n\np\n\nNk \u2227 (KQj,k )\n.\nk\u2212j+1\n\n(3.3)\n\nWe are now ready to define Birg\u00e9's estimator Fen .\nDefinition 3.1. (Birg\u00e9's estimator) Let the intervals Ij be defined as in (i)\nor (ii) above (depending on the value of t0 ), and let F\u0302 (j,k) and the weights wj,k\nbe defined by (3.1) and (3.2), respectively. Then, for t belonging to the interval\nIj , Birg\u00e9's estimator Fen (t) of F0 (t) is defined by\nX\nFen (t) =\nwj,k F\u0302 (j,k) .\n(3.4)\nk:k6=j\n\nIn determining the asymptotic distribution of Birg\u00e9's estimator, we are faced\nwith the following difficulties.\n(1) The weights wj,k are ratios of random variables, which interact with the\nrandom variables Mk0 /Mk , Nk0 /Nk and Q0j,k /Qj,k , for which they are multipliers.\n(2) The ratios Mk0 /Mk , Nk0 /Nk and Q0j,k /Qj,k are themselves ratios of random\nvariables.\n(3) The weighted sum, defining Birg\u00e9's estimator, consists of dependent summands. The dependence is caused by the dependence of the weights, the\ndependence between the Mk0 /Mk , Nk0 /Nk and Q0j,k /Qj,k and the dependence between the weights and these terms. This prevents a straightforward use of the Lindeberg-Feller central limit theorem.\nThese difficulties have to be dealt with in turn. The following crucial lemma\nbears on difficulty (1), by showing that the random weights wj,k are close to\ndeterministic weights w\nej,k .\nLemma 3.1. Consider a partition of [0, 1] into K or K + 1 subintervals, according to the construction of Birg\u00e9's estimator, using the scheme of (i) and (ii)\nat the beginning of this section. Assume that, for a fixed constant c > 0,\nK = Kn \u223c\n\n(n log n)1/3\n, n \u2192 \u221e,\nc\n\n(3.5)\n\nthat is: the asymptotic binwidth is given by c(n log n)\u22121/3 . Moreover, assume\nthat the observation density h is continuous on the upper triangle of the unit\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n11\n\nsquare, staying away from zero on its support. Let g1 and g2 be the first and\nsecond marginal density of h, respectively. Finally, let t0 be the left boundary\npoint of Ij , let a(t) and b(t) be defined by\np\np\nb(t) = h(t, t0 ) \u2227 g2 (t),\n(3.6)\na(t) = h(t0 , t) \u2227 g1 (t),\nand let the deterministic weights w\nej,k be defined by:\n\uf8f1\n3a(tk )\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2 {a(t0 ) + b(t0 )} (k \u2212 j + 1) log n\nw\nej,k =\n\uf8f4\n\uf8f4\n3b(tk )\n\uf8f4\n\uf8f4\n\uf8f3\n{a(t0 ) + b(t0 )} (j \u2212 k + 1) log n\n\n, k > j,\n(3.7)\n, k < j.\n\nThen:\n(i)\nsup (1 + |j \u2212 k|)E |wj,k \u2212 w\nej,k | = o (1/ log n) , n \u2192 \u221e.\n\n(3.8)\n\nk6=j\n\n(ii) Wj , defined by (3.3), satisfies\np\nWj = 31 (log n) n/K {a(t0 ) + b(t0 )} {1 + op (1)} , n \u2192 \u221e,\n\n(3.9)\n\nand, for m = 1, 2, . . .\n\b\n\u2212m\nE 1/Wjm 1{Wj >0} \u223c (9K/n)m/2 {(a(t0 ) + b(t0 )) log n}\n, n \u2192 \u221e.\n(3.10)\nIt may be helpful to give some motivation for the construction of Birg\u00e9's\nstatistic. If we replace Nk , Nk0 , etc. by their expected values, we obtain:\nR\n( R\n)\nX\n{F0 (u) \u2212 F0 (t)} dH(t, u)\nF (u) dG1 (u)\nt\u2208Ij , u\u2208Ik\nIk 0\nR\nwj,k\n\u2212\nG1 (tk+1 ) \u2212 G1 (tk )\ndH(t, u)\nt\u2208Ij , u\u2208Ik\nk>j\n(\nR\nX\n{1 \u2212 F0 (t)} dG2 (u)\n+\nwj,k 1 \u2212 Ik\nG2 (tk+1 ) \u2212 G2 (tk )\nk<j\nR\n)\n{F0 (u) \u2212 F0 (t)} dH(t, u)\nt\u2208Ik , u\u2208Ij\nR\n+\n+\n,\ndH(t, u)\nt\u2208Ik , u\u2208Ij\nwhere G1 and G2 are the first and second marginal distribution functions of H,\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n12\n\nrepectively. By expanding F0 at the left endpoints tk of the intervals, we get:\nX\nwj,k {F0 (tk ) \u2212 {F0 (tk ) \u2212 F0 (tj )}}\nk>j\n\n+\n\nX\n\nwj,k {1 \u2212 {1 \u2212 F0 (tk )} + {F0 (tj ) \u2212 F0 (tk )}}\n\nk<j\n\n1 X\n+\nwj,k\n2K 2\n\n(\n\n{f0 (tk ) \u2212 f0 (tj )} h(tj , tk )\nf0 (tk )g1 (tk )\nR\n\u2212\nG1 (tk+1 ) \u2212 G1 (tk )\nK t\u2208Ij , u\u2208Ik dH(t, u)\n\n)\n\n1 X\n+\nwj,k\n2K 2\nk<j\nX\n= F0 (tk )\nwj,k\n\n(\n\n{f0 (tj ) \u2212 f0 (tk )} h(tk , tj )\nf0 (tk )g1 (tk )\nR\n+\nG2 (tk+1 ) \u2212 G2 (tk )\nK t\u2208Ik , u\u2208Ij dH(t, u)\n\n)\n\nk>j\n\n+ ...\n\nk:k6=j\n\n\u001a\n\u001b\n1 X\nf0 (tk )g1 (tk ) {f0 (tk ) \u2212 f0 (tj )} h(tj , tk )\nwj,k\n\u2212\n2K\ng1 (tk )\nh(tj , tk )\nk>j\n\u001b\n\u001a\n1 X\nf0 (tk )g1 (tk ) {f0 (tj ) \u2212 f0 (tk )} h(tk , tj )\n+\nwj,k\n+\n+ ...\n2K\ng2 (tk )\nh(tk , tj )\n\n+\n\nk<j\n\n= F0 (tj ) +\n\n1 X\nwj,k {f0 (tk ) \u2212 {f0 (tk ) \u2212 f0 (tj )}}\n2K\nk>j\n\n1 X\n+\nwj,k {f0 (tk ) + f0 (tj ) \u2212 f0 (tk )} + . . .\n2K\nk<j\n\n= F0 (tj ) +\n\n1\nf0 (tj ) + . . .\n2K\n\n(3.11)\n\nOne of the difficulties in this expansion that we have glossed over for the moment\nis that g1 (tk ) tends to zero, if tk \u2192 1, and that similarly g2 (tk ) tends to zero,\nif tk \u2192 0. This difficulty has to be dealt with separately. We do not have that\ndifficulty for h, since we assume that h stays away from zero on its support.\nThe expansion suggests that the asymptotic bias at tj will be f0 (tj )/(2K),\nwhich is indeed the case. However, the expansion does not explain the particular\nchoice of the weights. Considering the deterministic counterparts w\nej,k of wj,k ,\ngiven by (3.7) in Lemma 3.1, we see that the weights are proportional to 1/(1 +\n|j \u2212 k|), which has the effect that the smaller observation intervals give the\nbiggest contribution to the estimator, taking advantage of the fact that the\nsmaller observation intervals do indeed give more precise information on the\n\"unobservable\" Xi , if we know that Xi is contained in the interval (see the\ndiscussion on this point in section 1. The choice of these weights reduces the\nvariance of the estimator. Only this fact is responsible for the fact that the rate\nof convergence is slightly faster than n\u22121/3 .\nIt seems that the MLE is doing something similar automatically, but in a\nmore efficient way, if we believe the \"working hypothesis\", discussed in section\n1. Assuming the truth of this \"working hypothesis\", the asymptotic variance\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n13\n\nof the MLE only involves the local joint density h of (Ti , Ui ) at (t0 , t0 ) and\nthe density f0 (t0 ) of Xi at t0 , whereas the variance of Birg\u00e9's estimator also\ninvolves the marginal densities of (Ti , Ui ), which do not appear in the local\nminimax lower bound, derived in section 2.\nAlso note that the partition, needed in the construction of Birg\u00e9's estimator,\nis dependent on an a priori knowledge of whether we are in the separated or\nnon-separated case; in the non-separated case binwidths of order (n log n)\u22121/3\nare taken (otherwise the higher rate (n log n)\u22121/3 would not be attained), and\nin the separated case binwidths of order n\u22121/3 (taking (n log n)\u22121/3 would let\nthe variance dominate the bias, as the sample size tends to infinity). For the\ncomputation of the maximum likelihood estimator (MLE), discussed in section\n5, it is not necessary to use a priori knowledge on the observation distribution;\nthe MLE, considered as a histogram adapts automatically to the separated\nor non-separated case and will choose generally smaller binwidth for the nonseparated case. This is one of the major advantages of the MLE over Birg\u00e9's\nestimator, apart from being monotone with values restricted to [0, 1].\nUsing the notation of Lemma 3.1 we can now formulate the main result for\nBirg\u00e9's estimator.\nTheorem 3.1. Let the observation density h satisfy the same condition as in\nLemma 3.1, and let F0 have a continuous derivative f0 on (0, 1), satisfying\n(n)\nf0 (t0 ) > 0. Furthermore, let Ij be a subinterval, belonging to the partition of\n[0, 1] into K intervals, corresponding to the construction of Birg\u00e9's estimator\nfor a sample of size n, where K is defined by (3.5) in Lemma 3.1. Finally, let\n\u03b1n be defined by\n\u03b1n = (n log n)\u22121/3 ,\n(3.12)\n(n)\n\n(n)\n\nand let tj be the left boundary point of Ij , for which we assume that it\nconverges to an interior point t0 \u2208 (0, 1), as n \u2192 \u221e. Then:\n(i)\nn \u0010\n\u0011\n\u0010\n\u0011o\nD\n(n)\n(n)\n\u03b1n\u22121 Fen tj\n\u2212 F0 tj\n\u2212\u2192 N\n\n2\n1\n2 cf0 (t0 ), \u03c30\n\n\u0001\n\n, n \u2192 \u221e.\n\n(3.13)\n\nwhere the right-hand side of (3.13) denotes a normal random variable,\nwith expectation 12 cf0 (t0 ) and variance\n\b\n3f0 (t0 ) a(t0 )2 + b(t0 )2\n2\n\u03c30 =\n(3.14)\n2 ,\nch(t0 , t0 ) {a(t0 ) + b(t0 )}\nand where c, a(t0 ) and b(t0 ) are defined by (3.5) and (3.6).\n(ii)\nn\no\nlim \u03b1n\u22121 E Fen (tj ) \u2212 F0 (tj ) = 12 cf0 (t0 ),\n\n(3.15)\n\nn \u0010\n\u0011o\n(n)\nlim \u03b1n\u22122 var Fen tj\n= \u03c302 .\n\n(3.16)\n\nn\u2192\u221e\n\nand\n\nn\u2192\u221e\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n14\n\nNote that Theorem 3.1 implies that the optimal value of c is given by\n\u0012\n\n3\n2\n\n9f0 (t)4\n2h(t, t)2\n\n\u00131/3 \u0012\n\na(t)2 + b(t)2\n{a(t) + b(t)}2\n\n\u00132/3\n.\n\nThis value of the constant was used in the simulations, reported below.\n4. Birg\u00e9's estimator in the separated case\nWe consider the asymptotic behavior of Birg\u00e9's estimator in the separated case.\nThis is mainly meant for illustrative purposes and to give background to the\nsimulation study. We therefore do not aim to prove results in the widest generality and confine our discussion to the case where the density h of the observed\npairs (Ti , Ui ) has as support the triangle with vertices (0, \u000f), (0, 1) and (1 \u2212 \u000f, 1)\nand stays away from zero on its support, which is the situation we consider in\nthe simulation study. In this case the faster rate (n log n)\u22121/3 is unattainable,\nand we know that Birg\u00e9's estimator (and also the MLE) can only achieve the\nrate n\u22121/3 . We therefore assume K to be of order n1/3 and set K = bc\u22121 n1/3 c.\nAs in section 3 we introduce deterministic weights w\nej,k to replace the random\nweights wj,k . Recall that, by definition,\n\uf8f1 p\nNk \u2227 (KQj,k )\n\uf8f4\n\uf8f4\n, j < k,\n\uf8f4\n\uf8f4\n\uf8f2 (k \u2212 j + 1)Wj\nwj,k =\n(4.1)\np\n\uf8f4\n\uf8f4\n\uf8f4\nM\n\u2227\n(KQ\n)\nk\nk,j\n\uf8f4\n\uf8f3\n, j > k,\n(j \u2212 k + 1)Wj\nand\nX\n\nWj =\n\n1\u2264k<j\n\np\np\nX\nMk \u2227 (KQj,k )\nNk \u2227 (KQj,k )\n+\n.\nj\u2212k+1\nk\u2212j+1\nj<k\u2264K\n\nLet g1 and g2 be the first and second marginal density of h, respectively, that\nis:\nZ 1\nZ t\ng1 (t) =\nh(t, u) du, g2 (t) =\nh(t0 , t) dt0 , t \u2208 [0, 1].\n(4.2)\nt\n\n0\n\nThen, if 2\u000f \u2264 t0 \u2264 1 \u2212 2\u000f,\np\nX\ncn2/3 {h(tk , tj ) \u2227 g2 (tk )}\nWj \u223c\nj\u2212k+1\nk:tj \u2212tk >\u000f\n\n\u223c n1/3\n\nZ\n\u000f\n\nt0 \u2212\u000f\n\np\n\ncn2/3 {h(tj , tk ) \u2227 g1 (tk )}\nk\u2212j+1\nk:tk \u2212tj >\u000f\np\np\nZ 1\u2212\u000f\nc {h(t, t0 ) \u2227 g2 (t)}\nc {h(t0 , t) \u2227 g1 (u)}\ndt + n1/3\ndt,\nt0 \u2212 t\nt \u2212 t0\nt0 +\u000f\n+\n\nX\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\nshowing Wj \u0010 n1/3 . The deterministic weights w\nej,k are now defined by:\n\uf8f1 p\nh(tk , tj ) \u2227 g2 (tk )\n\uf8f4\n\uf8f4\n\uf8f4\n, k < j,\n\uf8f4\n\uf8f4\nf (t0 ) (t0 \u2212 tk )\n\uf8f2 KW\nw\nej,k =\np\n\uf8f4\n\uf8f4\n\uf8f4\nh(tj , tk ) \u2227 g1 (tk )\n\uf8f4\n\uf8f4\n, k > j,\n\uf8f3\nf (t0 ) (tk \u2212 t0 )\nKW\n\n15\n\n(4.3)\n\nwhere\nZ\nf (t0 ) =\nW\n\u000f\n\nt0 \u2212\u000f\n\np\nZ 1\u2212\u000f p\nh(t, t0 ) \u2227 g2 (t)\nh(t0 , u) \u2227 g1 (u)\ndt +\ndu.\nt0 \u2212 t\nu \u2212 t0\nt0 +\u000f\n\n(4.4)\n\nWe assume that the integrals on the right-hand side of (4.4) are finite, and hence\nf (t0 ) < \u221e.\nthat W\nWe now have the following lemma, which plays a similar role as Lemma 3.1\nin section 3.\nLemma 4.1. Consider a partition of [0, 1] into K or K + 1 subintervals, according to the construction of Birg\u00e9's estimator, using the scheme of (i) and (ii)\nat the beginning of section 3. Assume that\nK = Kn \u223c\n\nn1/3\n, n \u2192 \u221e,\nc\n\nfor a fixed constant c > 0, that is: the asymptotic binwidth is given by cn\u22121/3 .\nLet the weights wj,k and w\nej,k be defined by (4.1) and (4.3), respectively, where\nf (t0 ) < \u221e. Then:\nwe assume W\n\u0010\n\u0011\nsup (1 + |j \u2212 k|) |wj,k \u2212 w\nej,k | = op n\u22121/3 ,\n(4.5)\nk6=j\n\nUsing this lemma, we get the following limit result (compare with Theorem\n3.1).\nTheorem 4.1. Suppose that the observation density h has as support the triangle with vertices (0, \u000f), (0, 1) and (1 \u2212 \u000f, 1) and stays away from zero on its\nsupport. Let F0 have a continuous derivative f0 on (0, 1), satisfying f0 (t0 ) > 0.\n(n)\nMoreover, let Ik be a subinterval, belonging to the partition of [0, 1] into K\nintervals, corresponding to the construction of Birg\u00e9's estimator for a sample of\nf (t0 ) be defined by (4.4), where we assume W\nf (t0 ) < \u221e.\nsize n. Finally, let W\n(n)\n1/3\nAssume that, for a fixed constant c > 0, K = Kn \u223c n /c, and let tk be the\n(n)\nleft boundary point of Ik , for which we assume that it converges to an interior\npoint t0 \u2208 (0, 1), as n \u2192 \u221e. Then we have, as n \u2192 \u221e\nn \u0010\n\u0011\n\u0010\n\u0011o\n\u0001\nD\n(n)\n(n)\n(4.6)\nn1/3 Fen tk\n\u2212 F0 tk\n\u2212\u2192 N 12 cf0 (t0 ), \u03c3 2\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n16\n\nwhere the right-hand side of (4.6) denotes a normal random variable, with expectation 12 cf0 (t0 ) and variance\n\u03c32\n=\n\nZ\n\n1\nf (t0 )2\ncW\n+\n\n1\u2212\u000f\n\nt0 +\u000f\n\nZ\n\n1\nf (t0 )2\ncW\n\ng1 (u) \u2227 h(t0 , u)\n{F0 (u) \u2212 F0 (t0 )} {1 \u2212 (F0 (u) \u2212 F0 (t0 ))} du\nh(t0 , u)(u \u2212 t0 )2\n\nt0 \u2212\u000f\n\n\u000f\n\ng2 (t) \u2227 h(t, t0 )\n{F0 (t0 ) \u2212 F0 (t)} {1 \u2212 (F0 (t0 ) \u2212 F0 (t))} dt.\nh(t, t0 )(t0 \u2212 t)2\n(4.7)\n\nIn the simulation study we take the observation density h uniform on the\ntriangle of its support. For ease of reference, we here determine the value of\nthe variance \u03c3 2 of the asymptotic distribution for this case. If h is uniform, its\ndensity is given by\n\u001a\n2(1 \u2212 \u000f)\u22122 , 0 \u2264 t + \u000f \u2264 u \u2264 1\n.\n(4.8)\nh(t, u) =\n0,\nelsewhere\nHence the marginal densities g1 and g2 are given by:\nZ 1\n2{1 \u2212 t \u2212 \u000f}\n2\ndu =\n, t \u2208 [0, 1 \u2212 \u000f],\ng1 (t) =\n(1 \u2212 \u000f)2 t+\u000f\n(1 \u2212 \u000f)2\nand\ng2 (u) =\n\n2\n(1 \u2212 \u000f)2\n\nZ\n\nu\u2212\u000f\n\ndu =\n0\n\n2{u \u2212 \u000f}\n, u \u2208 [\u000f, 1].\n(1 \u2212 \u000f)2\n\nf (t0 ) we get:\nFor W\nf (t0 ) =\nW\n\n1\n1\u2212\u000f\n\nZ\n\u000f\n\nt0 \u2212\u000f\n\np\nZ 1\u2212\u000f p\n2(t \u2212 \u000f)\n2(1 \u2212 u \u2212 \u000f)\n1\ndt +\ndu.\nt0 \u2212 t\n1 \u2212 \u000f t0 +\u000f\nu \u2212 t0\n\n(4.9)\n\nHence, using (4.7), we obtain:\nZ 1\u2212\u000f\n1\n1\u2212u\u2212\u000f\n2\n{F0 (u) \u2212 F0 (t0 )} {1 \u2212 (F0 (u) \u2212 F0 (t0 ))} du\n\u03c3 =\n2\nf\ncW (t0 ) t0 +\u000f (u \u2212 t0 )2\nZ t0 \u2212\u000f\n1\nt\u2212\u000f\n{F0 (t0 ) \u2212 F0 (t)} {1 \u2212 (F0 (t0 ) \u2212 F0 (t))} dt.\n+\n2\nf\n(t\n\u2212 t)2\n0\ncW (t0 ) \u000f\n(4.10)\nf (t0 ) is defined by (4.9).\nwhere W\n5. The maximum likelihood estimator\nAs mentioned in section 1, the (nonparametric) maximum likelihood estimator\n(MLE or NPMLE) maximizes the (partial) log likelihood\nn\nX\n\n{\u2206i1 log F (Ti ) + \u2206i2 log {F (Ui ) \u2212 F (Ti )} + \u2206i3 log (1 \u2212 F (Ui ))} ,\n\ni=1\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n17\n\nwhere the maximization is over all distribution functions F . For the non-separated case the following conjecture was given in [5] (the lecture notes of a\nsummer course given at Stanford University in 1990), which later appeared as\npart 2 of [10]):\nTheorem 5.1. (Conjecture in [5]) Let F0 and H be continuously differentiable at t0 and (t0 , t0 ), respectively, with strictly positive derivatives f0 (t0 ) and\nh(t0 , t0 ), where H is the distribution function of (Ti , Ui ). By continuous differentiability of H at (t0 , t0 ) is meant that the density h(t, u) is continuous at\n(t, u), if t < u and (t, u) is sufficiently close to (t0 , t0 ), and that h(t, t), defined\nby\nh(t, t) = lim h(t, u),\nu\u2193t\n\nis continuous at t, for t in a neighborhood of t0 .\nLet 0 < F0 (t0 ), H(t0 , t0 ) < 1, and let F\u0302n be the MLE of F0 . Then\nn\no\u000e\b\n1/3 D\n2\n3\n\u2212\u2192 2Z,\n(n log n)1/3 F\u0302n (t0 ) \u2212 F0 (t0 )\n4 f0 (t0 ) /h(t0 , t0 )\nwhere Z is the last time that standard two-sided Brownian motion minus the\nparabola y(t) = t2 reaches its maximum.\nIt was also shown in [5] that Theorem 5.1 is true for a \"toy\" estimator,\nobtained by doing one step of the iterative convex minorant algorithm, starting\nthe iterations at the underlying distribution function F0 ; the \"toy\" aspect is that\nwe can of course not do this in practice. In spite of the fact that now more than\n20 years have passed since this conjecture has been launched, it still has not\nbeen proved. In the simulation section we provide some material which seems to\nsupport the conjecture, but further research is necessary to settle this question.\nFor the separated case one can also introduce a toy estimator of the same\ntype and one can again formulate the \"working hypothesis\" that that the toy estimator and the MLE have the same pointwise limit behavior. Anticipating that\nthis would hold, [14] derived the asymptotic distribution of the toy estimator in\nthe separated case, under the following conditions.\n(C1) The support of F0 is an interval [0, M ], where M < \u221e.\n(C2) F0 and H have densities f0 and h w.r.t. Lebesgue measure on IR and IR2 ,\nrespectively.\n(C3) Let the functions k1,\u000f and k2,\u000f be defined by\nZ M\nh(u, v)\n{F0 (v) \u2212 F0 (u) < \u000f\u22121 } dv,\nk1,\u000f (u) =\nF0 (v) \u2212 F0 (u)\nu\nand\n\nZ\n\nv\n\nh(u, v)\n{F0 (v) \u2212 F0 (u) < \u000f\u22121 } du.\n0 F0 (v) \u2212 F0 (u)\nThen, for i = 1, 2 and each \u000f > 0,\nZ\nlim \u03b1\nki (u, \u000f\u03b1) du = 0.\nk2,\u000f (v) =\n\n\u03b1\u2192\u221e\n\n(t0 ,t0 +t/\u03b1]\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n18\n\n(C4) 0 < F0 (t0 ) < 1 and 0 < H(t0 , t0 ) < 1.\nThe motivation for these conditions is given in [14] and actually become clear\nfrom the proof, which is not given here.\nTheorem 5.2. ([14]) Suppose that assumptions (C1) to (C4) hold. Let ki , i =\n1, 2, be defined by\nZ\n\nM\n\nk1 (u) =\nu\n\nh(u, v)\ndv, and k2 (v) =\nF0 (v) \u2212 F0 (u)\n\nv\n\nZ\n0\n\nh(u, v)\ndu,\nF0 (v) \u2212 F0 (u)\n\nand suppose that f0 , g1 , g2 , k1 and k2 are continuous at t0 , where g1 and g2\nare the first and second marginal densities of h, respectively. Moreover, assume\n(1)\nf0 (t0 ) > 0. Then, if Fn is the estimator of the distribution function F0 , obtained after one step of the iterative convex minorant algorithm, starting the\niterations with F0 , we have\nD\n\nn1/3 {2\u03be(t0 )/f0 (t0 )}1/3 {Fn(1) (t0 ) \u2212 F0 (t0 )} \u2212\u2192 2Z,\nwhere Z is the last time where standard two-sided Brownian motion minus the\nparabola y(t) = t2 reaches its maximum, and where\n\u03be(t0 ) =\n\ng2 (t0 )\ng1 (t0 )\n+ k1 (t0 ) + k2 (t0 ) +\n.\nF0 (t0 )\n1 \u2212 F0 (t0 )\n\nIt is indeed proved in [6] that, under slightly stronger conditions (the most\nimportant one being that an observation interval always has length > \u000f, for\nsome \u000f > 0), which hold for the examples in the simulation below, the MLE has\nthe same limit behavior, using the same norming constants. The expression for\nthe asymptotic variance in the separated case is remarkably different from the\nconjectured variance in the non-separated case, which only depends on F0 via\nf0 (t0 ), showing that only the local behavior, depending on the density at t0 , is\nimportant for the asymptotic variance (assuming that the working hypothesis\nholds).\nNote that if (Ti , Ui ) is uniform on the upper triangle of the unit square, with\nvertices (0, \u000f), (0, 1) and (1 \u2212 \u000f, 1), we have:\ng1 (u) =\n\n2(1 \u2212 u \u2212 \u000f)\n,\n(1 \u2212 \u000f)2\n\ng2 (v) =\n\n2(v \u2212 \u000f)\n,\n(1 \u2212 \u000f)2\n\nand, if F0 is the uniform distribution function on [0, 1],\nk1 (u) =\nso\n\n2 log{(1 \u2212 u)/\u000f}\n,\n(1 \u2212 \u000f)2\n\n2\n\u03be(t0 ) =\n(1 \u2212 \u000f)2\n\n\u001a\n\n1 \u2212 t0 \u2212 \u000f\n+ log\nt0\n\nk2 (v) =\n\u0012\n\n2 log(v/\u000f)\n,\n(1 \u2212 \u000f)2\n\nt0 (1 \u2212 t0 )\n\u000f2\n\n\u0013\n\nt0 \u2212 \u000f\n+\n1 \u2212 t0\n\n\u001b\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n19\n\nin this case. If F0 is given by F0 (x) = 1 \u2212 (1 \u2212 x)4 , x \u2208 [0, 1], we get:\n\u03be(t0 )\n=\n\n(5.1)\n\u001a\n\n\u001b\n\n1 \u2212 t0 \u2212 \u000f\nt0 \u2212 \u000f\n+\nF0 (t0 )\n1 \u2212 F0 (t0 )\n\u001a\n\u0012\n\u0013\n\u0012\n\u0013\n1 \u2212 t0 \u2212 \u000f\n2 \u2212 2t0 \u2212 \u000f\n1\n2\narctan\n+\nlog\n+\n2(1 \u2212 \u000f)2 (1 \u2212 t0 )3\n1 \u2212 t0\n\u000f\n\u0001 !)\n\u0012\n\u0013\n\u0012\n\u0013\nt0 2 \u2212 2t0 + \u000f\n1 \u2212 t0 + \u000f\n1\n+2 arctan\n.\n\u2212 2 arctan\n+ log\n1 \u2212 t0\n1 \u2212 t0\n\u000f(2 \u2212 t0 )\n\n2\n(1 \u2212 \u000f)2\n\n(5.2)\nWe give some results for the latter model in section 8.\n6. The smoothed maximum likelihood estimator\nLet h be the density of (Ti , Ui ), with first marginal density h1 and second\nmarginal h2 , and let \u03c6t,b,F be a solution of the integral equation (in \u03c6):\n\u001a\nZ\n\u03c6(v) \u2212 \u03c6(u)\n\u03c6(u) = dF (u) kt,b (u) +\nh(u, v) dv\nF\n(v) \u2212 F (u)\nv>u\n\u001b\nZ\n\u03c6(u) \u2212 \u03c6(v)\n\u2212\nh(v, u) dv ,\nv<u F (u) \u2212 F (v)\nwhere\n\nF (u){1 \u2212 F (u)}\n,\nh1 (u){1 \u2212 F (u)} + h2 (u)F (u)\nis defined by\n\ndF (u) =\nand the function kt,b\n\nkt,b (u) = b\u22121 K ((t \u2212 u)/b) .\n\n(6.1)\n\nMoreover, let the function \u03b8t,b,F be defined by\n\u03b41 \u03c6t,b,F (u) \u03b42 {\u03c6t,b,F (v) \u2212 \u03c6t,b,F (u)} \u03b43 \u03c6t,b,F (v)\n\u2212\n+\n,\nF (u)\nF (v) \u2212 F (u)\n1 \u2212 F (v)\n(6.2)\nwhere u < v. Then, as in [3] (separated case) and [4] (non-separated case), we\nhave the representation\nZ\nZ\n\u0001\nIK ((t \u2212 u)/b) d F\u0302n \u2212 F0 (u) = \u03b8t,b,F\u0302n (u, v, \u03b41 , \u03b42 ) dP0 (u, v, \u03b41 d2 )\nZ\n\u03c6t,b,F\u0302n (u)\n=\nF0 (u)h1 (u) du\nF\u0302n (u)\nZ\n\u03c6t,b,F\u0302n (v) \u2212 \u03c6t,b,F\u0302n (u)\n+\n{F0 (v) \u2212 F0 (u)}h(u, v) du dv\nF\u0302n (v) \u2212 F\u0302n (u)\nZ\n\u03c6t,b,F\u0302n (v)\n\u2212\n{1 \u2212 F0 (v)}h2 (v) dv.\n1 \u2212 F\u0302n (v)\n\u03b8t,b,F (u, v, \u03b41 , \u03b42 ) = \u2212\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n20\n\nTable 1\nEstimates of the actual variances var(F\u0303n (t)) (times n) and corresponding theoretical\n2\nvariances E\u03b8t,b\n, where bn = n\u22121/5 , for sample size n = 1000. The estimates of of the\nn ,F0\nactual variances were based on 10, 000 samples of size 1000 from a Uniform(0, 1) distribution\nF0 and a uniform observation distribution H on the upper triangle of the unit square.\nt\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n\n2\nE\u03b8t,b\nn ,F0\n0.142235\n0.255404\n0.332985\n0.376413\n0.390382\n0.376340\n0.332856\n0.255255\n0.142129\n\nnvar(F\u0303n (t))\n0.146489\n0.262056\n0.334990\n0.380357\n0.399258\n0.386292\n0.342651\n0.261457\n0.145304\n\nratio\n1.029910\n1.026044\n1.006019\n1.010479\n1.022736\n1.026444\n1.029428\n1.024296\n1.022338\n\nFor F = F0 we get the integral equation:\n\u001a\nZ\n\u03c6(v) \u2212 \u03c6(u)\nh(u, v) dv\n\u03c6(u) = dF0 (u) kt,b (u) +\nF\nv>u 0 (v) \u2212 F0 (u)\n\u001b\nZ\n\u03c6(u) \u2212 \u03c6(v)\n\u2212\nh(v, u) dv .\nv<u F0 (u) \u2212 F0 (v)\nUsing the theory in [3] and [4] again, we get that the solution \u03c6t,b,F0 gives as an\napproximation for n var(F\u0303n (t)):\nE \u03b8t,b,F0 (T1 , U1 , \u220611 , \u220612 )2\nZ\n\u03c6t,b,F0 (u)2\n=\nh1 (u) du\nF0 (u)\nZ \b\n\u03c6t,b,F0 (v) \u2212 \u03c6t,b,F0 (u)\n+\nF0 (v) \u2212 F0 (u)\n\n2\n\nZ\nh(u, v) du dv +\n\n\u03c6t,b,F0 (v)2\nh2 (v) dv.\n1 \u2212 F0 (v)\n\nThe approximation seems to work pretty well, as can be seen in table 1, where\nwe estimated the actual variance for samples of size n = 1000 by generating\n10, 000 samples of size 1000 from a Uniform(0, 1) distribution F0 and a uniform\nobservation distribution H on the upper triangle of the unit square.\nAs in the papers cited above, we do not have an explicit expression for \u03c6t,bn ,F0 ;\na picture of \u03c6t,bn ,F0 for F0 the Uniform(0, 1) distribution F0 and bn = n\u22121/5\nis shown in Figure 3; the function was computed by solving the corresponding\nmatrix equation on a 1000\u00d71000 grid. Note that we apply the smooth functional\ntheory of the above mentioned papers (which is also discussed in [6]) not for\na fixed functional, but for changing functionals on shrinking intervals (in the\nhidden space). The reason we can do this is that the bandwidth b is chosen to be\nof a larger order than the critical rate n\u22121/3 , and that then a different type of\nasymptotics sets in, with asymptotic normality, etc., instead of the non-standard\nasymptotics of the MLE itself. This method is also used in [8], for the current\nstatus model.\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n21\n\n0.5\n\n0.4\n\n0.3\n\n0.2\n\n0.1\n\n0.0\n0.0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1.0\n\nFig 3. The function u 7\u2192 \u03c6t,bn ,F0 (u), u \u2208 [0, 1], for t = 0.7, bn = n\u22121/5 , n = 1000, the\nUniform(0, 1) distribution F0 and a uniform observation distribution H on the upper triangle\nof the unit square.\n\nIn analogy with Theorem 4.2 in [8] we expect the following result to hold,\nusing the conditions on the underlying distributions, discussed in [3] and [4]. To\navoid messy notation, we will denote the smoothed MLE by F\u0303n instead of F\u0303nM L\nin the remainder of this section.\nTheorem 6.1. [Conjectured] Let the conditions of Theorem 1, p. 212, in [3]\n(separated case) or Theorem 3.2, p. 647, in [4] (non-separated case) be satisfied.\nMoreover, let the joint density h of the joint density of (Ti , Ui ) have a continuous\nbounded second total derivative in the interior of its domain and let f0 have a\ncontinuous derivative at the interior point t of the support of f0 , and let F\u0303n be\nthe smoothed MLE, defined by (1.3). Then, if bn \u0010 n\u22121/5 , we have\n\u001a\n\u001b.\nZ\n\u221a\nD\n2\n1 2 0\nn F\u0303n (t) \u2212 F0 (t) \u2212 2 bn f0 (t) u K(u) du\n\u03c3n \u2212\u2192 N (0, 1) , n \u2192 \u221e,\nwhere N (0, 1) is the standard normal distribution and \u03c3n2 is defined by\n2\n\n\u03c3n2 = E \u03b8t,bn ,F0 (T1 , U1 , \u220611 , \u220612 ) ,\n\n(6.3)\n\nwith \u03b8t,bn ,F0 given by (6.2).\nNote that (the conjectured) Theorem 6.1 covers both the separated and the\nnon-separated case. Unfortunately, we do not have an explicit expression for\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n22\n\n(6.3) in Theorem 6.1 at present. The functions \u03c6F0 , defining the function \u03b8F0\nand hence also the variance \u03c3n2 , are of a rather different nature for the separated\ncase and the non-separated case. For an example of this, see Figure 4.\nThe variance \u03c3n2 can be estimated by\nZ\n2\n\u03c3\u0302n = \u03b8\u0303t,bn ,F\u0303n (t, u, \u03b41 , \u03b42 ) dPn (u, v, \u03b41 , \u03b42 ),\nwhere\n\u03b8\u0303t,bn ,F\u0303n (u, v, \u03b41 , \u03b42 ) = \u2212\n\n\u03b41 \u03c6\u0303t,bn ,F\u0303n (u)\nF\u0303n (u)\n\n\u2212\n\n\u03b42 {\u03c6\u0303t,bn ,F\u0303n (v) \u2212 \u03c6\u0303t,bn ,F\u0303n (u)}\nF\u0303n (v) \u2212 F\u0303n (u)\n+\n\n\u03b43 \u03c6\u0303t,bn ,F\u0303n (v)\n1 \u2212 F\u0303n (v)\n\n, u < v,\n\nand \u03c6\u0303t,bn ,F\u0303n solves the integral equation\n\u001a\nZ\n\u03c6(v) \u2212 \u03c6(u)\n\u03c6(u) = dF\u0303n (u) (u) kt,bn (u) +\nhn (u, v) dv\nv>u F\u0303n (v) \u2212 F\u0303n (u)\n\u001b\nZ\n\u03c6(u) \u2212 \u03c6(v)\nhn (v, u) dv ,\n\u2212\nv<u F\u0303n (u) \u2212 F\u0303n (v)\n\n(6.4)\n\nand where hn is a kernel estimate of the density h, and where\nF\u0303n (u){1 \u2212 F\u0303n (u)}\ndF\u0303n (u) (u) =\n,\nhn1 (u){1 \u2212 F\u0303n (u)} + hn2 (u)F\u0303n (u)\nZ\nZ\nhn1 (u) = hn (u, v) dv,\nhn2 (u) = hn (v, u) dv.\nFor bn chosen as in the theorem, the distribution function F\u0303n will be strictly\nincreasing with probability tending to one. Since F\u0303n is also continuously differentiable, the equation (6.4) will have an absolutely continuous solution \u03c6\u0303t,bn ,F\u0303n ,\nand we do not have to take recourse to a solution pair, as in [4], which deals\nseparately with a discrete and absolutely continuous part.\nIn the corresponding result for the current status model we have explicit\nexpressions, and we briefly discuss the analogy here, using a notation of the\n(CS)\nsame type. Let F\u0303n\nbe the smoothed MLE for the current status model,\ndefined by (1.3), but now using the MLE F\u0302n in the current status model. In this\ncase the function \u03b8t,b,F , representing the functional in the observation space, is\ngiven by\n(CS)\n\n(CS)\n\n\u03b8t,b,F (u, \u03b4) = \u2212\n\n\u03b4\u03c6t,b,F (u)\nF (u)\n\n(CS)\n\n+\n\n(1 \u2212 \u03b4)\u03c6t,b,F (u)\n1 \u2212 F (u)\n\n, u \u2208 (0, 1).\n\n(6.5)\n\nwhere \u03c6 is given by:\n(CS)\n\n\u03c6t,b,F (u) =\n\nF (u){1 \u2212 F (u)}\nkt,b (u),\ng(u)\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n23\n\n0.15\n\n0.10\n\n0.05\n\n0.00\n-4\n\n-2\n\n0\n\n2\n\n4\n\nFig 4. The function u 7\u2192 \u03c6t,b,F0 (t \u2212 bu), u \u2208 [\u22125, 5], for t = 0.5, b = 0.1, the Uniform(0, 1)\ndistribution F0 and (non-separated case:) a uniform observation distribution H on the upper\ntriangle of the unit square (solid curve) and the function u 7\u2192 \u03c6t,b,F0 (t\u2212bu) for the (separated)\ncase where the observation distribution H is uniform on the triangle with vertices (0, \u000f), (0, 1)\nand (1 \u2212 \u000f, 1), where \u000f = 0.2 (dashed).\n\nand kt,b is defined by (6.1). Moreover, g is the density of the (one-dimensional)\n(CS)\nobservation distribution. The solution \u03c6t,bn ,F0 gives as an approximation for\nn var(F\u0303n (t)):\nE\n\n(CS)\n\u03b8t,bn ,F0 (T1 , \u22061 )2\n\nZ\n=\n\nZ\n=\n\n(CS)\n\n\u03c6t,bn ,F0 (u)2\n\nZ\n\n(CS)\n\n\u03c6t,bn ,F0 (u)2\n\ng(u) du +\ng(u) du\nF0 (u)\n1 \u2212 F0 (u)\nZ\nF0 (u){1 \u2212 F0 (u)}kt,bn (u)2\nF0 (t){1 \u2212 F0 (t)}\ndu \u223c\nK(u)2 du, bn \u2192 0.\ng(u)\nbn g(t)\n\nMoreover,\n(CS)\n\nlim bE \u03b8t,b,F0 (T1 , \u22061 )2 =\nb\u21930\n\nF0 (t){1 \u2212 F0 (t)}\ng(t)\n\nZ\n\nK(u)2 du,\n\nso in this case we obtain the central limit theorem\n\u001a\n\u001b.\nZ\n\u221a\nD\n2\n1 2 0\nn F\u0303n (t) \u2212 F0 (t) \u2212 2 bn f0 (t) u K(u) du\n\u03c3n \u2212\u2192 N (0, 1) , n \u2192 \u221e,\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\nwhere\n(CS)\n\n\u03c3n2 = E \u03b8t,bn ,F0 (T1 , \u22061 )2 \u223c\n\nF0 (t){1 \u2212 F0 (t)}\nbn g(t)\n\nZ\n\n24\n\nK(u)2 du,\n\nsee Theorem 4.2, p. 365, [8].\nRemark 6.1. It is tempting to think that the asymptotic variance can be found\nfor case 2 by computing\n2\n\nlim bE \u03b8t,b,F0 (T1 , U1 , \u220611 , \u220612 ) ,\nb\u21930\n\njust as in the current status model. However, numerical computations suggested\n2\nthat bE \u03b8t,b,F\ntends to zero in the non-separated case. This might mean that\n0\nthe variance is not of order n\u22124/5 in this case, but perhaps contains a logarithmic factor, in analogy with the variance (n log n)\u22122/3 for the histogram-type\nestimators, like Birg\u00e9's estimator and the MLE without smoothing.\nHowever, we do not expect this to happen for the separated case. All this still\nhas to be determined by the analysis of the difference in asymptotic behavior\nof the functions \u03c6t,bn ,F0 for the separated and non-separated case (see Figure 4\nfor a picture of the rather different behavior of \u03c6t,bn ,F0 in these two situations).\n7. Simulation results for the non-separated case\nIn tables 2 to 5 we present some simulation results for the \"non-separated case\"\nfor both Birg\u00e9's estimator, the MLE and the smoothed MLE. In all cases the\nobservation density was the uniform density on the upper triangle. All results\nare based on 10,000 pseudo-random samples. For Birg\u00e9's estimator the asymptotically optimal binwidth was chosen in all simulations.\nWe study the case where f0 is the uniform density on [0, 1] and give results\nfor the interior points t0 = 0.3, 0.4, 0.5 and 0.6. Although these points are\nsomewhat arbitrarily chosen, the results are representative for what happens in\nthe interior of the interval.\nIt can be seen from the tables that the squared bias for the MLE is, in all\ncases, negligible compared to the variance. We note that this is in contrast with\nBirg\u00e9's estimator. Moreover, the variance of the MLE is generally smaller than\nthat of Birg\u00e9's estimator. Table 5 shows, not unexpectedly, that the MSE of\nthe smoothed MLE is much smaller than the MSE of either the MLE or Birg\u00e9's\nestimator.\n8. Simulation results for the separated case\nFor the separated case the results of a simulation study are provided in the tables\n6 to 14. We first take again F0 to be the uniform(0, 1) distribution function. On\nthe other hand, we chose the observation density defined by (4.8), with \u000f = 0.1,\nso the observation times Ti and Ui cannot become arbitrarily close. The results\nare based on 10,000 pseudo-random samples. As in the non-separated case, the\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n25\n\nTable 2\nMSE for Birg\u00e9's estimator and MLE, times (n log n)2/3 , t0 = 0.3, 0.4, 0.5 and 0.6,\nnon-separated case. The asymptotic MSE of Birg\u00e9's estimator and the conjectured MSE of\nthe MLE are displayed in bold type.\n\nn = 1000\nn = 2500\nn = 5000\nn = 10000\n\nt0 = 0.3\nBirg\u00e9 MLE\n1.01\n0.55\n1.10\n0.50\n1.06\n0.52\n1.05\n0.50\n1.03\n0.51\n\nt0 = 0.4\nBirg\u00e9 MLE\n0.99\n0.55\n1.10\n0.55\n1.08\n0.54\n1.03\n0.54\n1.02\n0.54\n\nt0 = 0.5\nBirg\u00e9 MLE\n0.98\n0.55\n1.09\n0.55\n1.07\n0.55\n1.04\n0.56\n1.00\n0.54\n\nt0 = 0.6\nBirg\u00e9 MLE\n0.99\n0.55\n1.11\n0.55\n1.06\n0.53\n1.03\n0.53\n1.06\n0.54\n\nTable 3\nVariance for Birg\u00e9's estimator and MLE, times (n log n)2/3 , t0 = 0.3, 0.4, 0.5 and 0.6,\nnon-separated case. The asymptotic variance of Birg\u00e9's estimator and the conjectured\nasymptotic variance of the MLE (MLE) are displayed in bold type.\n\nn = 1000\nn = 2500\nn = 5000\nn = 10000\n\nt0 = 0.3\nBirg\u00e9 MLE\n0.67\n0.55\n0.79\n0.50\n0.75\n0.52\n0.74\n0.50\n0.69\n0.51\n\nt0 = 0.4\nBirg\u00e9 MLE\n0.66\n0.55\n0.78\n0.55\n0.75\n0.54\n0.71\n0.54\n0.69\n0.54\n\nt0 = 0.5\nBirg\u00e9 MLE\n0.66\n0.55\n0.78\n0.55\n0.74\n0.55\n0.73\n0.56\n0.69\n0.54\n\nt0 = 0.6\nBirg\u00e9 MLE\n0.66\n0.55\n0.79\n0.55\n0.73\n0.53\n0.72\n0.53\n0.72\n0.54\n\nTable 4\nSquared Bias for Birg\u00e9's estimator and MLE, times (n log n)2/3 , t0 = 0.3, 0.4, 0.5 and 0.6,\nnon-separated case. The asymptotic squared bias of Birg\u00e9's estimator is displayed in bold\ntype.\n\nn = 1000\nn = 2500\nn = 5000\nn = 10000\n\nt0\nBirg\u00e9\n0.34\n0.31\n0.31\n0.30\n0.34\n\n= 0.3\nMLE\n3.4 * 10\u22124\n1.3 * 10\u22124\n5.5 * 10\u22127\n6.3 * 10\u22125\n\nt0\nBirg\u00e9\n0.33\n0.32\n0.32\n0.32\n0.33\n\n= 0.4\nMLE\n1.6 * 10\u22124\n8.4 * 10\u22125\n1.6 * 10\u22124\n4.1 * 10\u22125\n\nt0\nBirg\u00e9\n0.33\n0.31\n0.33\n0.31\n0.31\n\n= 0.5\nMLE\n2.4 * 10\u22125\n7.9 * 10\u22126\n2.5 * 10\u22124\n4.1 * 10\u22126\n\nt0\nBirg\u00e9\n0.33\n0.32\n0.33\n0.31\n0.34\n\n= 0.6\nMLE\n1.3 * 10\u22124\n5.6 * 10\u22127\n3.6 * 10\u22124\n8.2 * 10\u22125\n\nTable 5\nMSE of SMLE divided by MSE of MLE, t0 = 0.3, 0.4, 0.5 and 0.6, non-separated case.\n\nn = 1000\nn = 2500\nn = 5000\nn = 10000\n\nt0 = 0.3\nratio\n0.247\n0.217\n0.203\n0.187\n\nt0 = 0.4\nratio\n0.262\n0.236\n0.219\n0.197\n\nt0 = 0.5\nratio\n0.265\n0.236\n0.224\n0.204\n\nt0 = 0.6\nratio\n0.263\n0.233\n0.216\n0.201\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n26\n\nTable 6\nMSE for Birg\u00e9's estimator divided by its asymptotic value, t0 = 0.3, separated case.\nn = 106\nn = 107\n\nf0 (t) = 1\n1.12\n1.04\n\nf0 (t) = 4(1 \u2212 t)3\n1.09\n1.04\n\nTable 7\nMSE for Birg\u00e9's estimator and MLE, times n2/3 , t0 = 0.3, 0.4, 0.5 and 0.6, separated case.\nThe asymptotic MSE (Birg\u00e9) and \"the asymptotic variance\" (MLE) are displayed in bold\ntype.\n\nn = 1000\nn = 2500\nn = 5000\nn = 10000\n\nt0 = 0.3\nBirg\u00e9 MLE\n0.34\n0.12\n0.58\n0.14\n0.44\n0.13\n0.52\n0.13\n0.46\n0.12\n\nt0 = 0.4\nBirg\u00e9 MLE\n0.32\n0.13\n0.57\n0.15\n0.46\n0.14\n0.48\n0.13\n0.48\n0.13\n\nt0 = 0.5\nBirg\u00e9 MLE\n0.31\n0.13\n0.56\n0.15\n0.49\n0.14\n0.50\n0.14\n0.49\n0.14\n\nt0 = 0.6\nBirg\u00e9 MLE\n0.32\n0.13\n0.57\n0.15\n0.48\n0.14\n0.50\n0.13\n0.49\n0.14\n\nMSE of the MLE turns out to be smaller than the MSE of Birg\u00e9's estimator.\nHere the difference is however even more noticeable.\nIn the tables 7 to 9 we give the results for the MSE, variance and squared bias\nfor both estimators. Again it can be seen that the variance of Birg\u00e9's estimator is\ngenerally larger than the variance of the MLE. Moreover, as in the non-separated\ncase, the squared bias for the MLE is, in all cases, negligible compared to the\nvariance.\nTo show that the results are not specific for the uniform distribution, we\ngive in the tables 11 to 13 the corresponding comparisons for the distribution\nfunction F0 , with density f0 , defined by\nF0 (x) = 1 \u2212 (1 \u2212 x)4 ,\n\nf0 (x) = 4(1 \u2212 x)3 ,\n\nx \u2208 [0, 1].\n\nFor the computation of the asymptotic variance of the MLE we used (5.1) of\nsection 5. It is seen that the correspondence between the asymptotic expression\nfor the variance and the actual sample variance of the MLE is rather good,\nand also that the superiority of the MLE w.r.t. Birg\u00e9's estimator is still more\npronounced for this distribution function. Table 14 shows that the ratio of the\nMSE of the SMLE and the MSE of the actual MLE is somewhat larger here,\nwhich is probably due to the fact that the asymptotic bias plays a larger role for\nthe SMLE in this case (this bias vanishes for the uniform distribution function).\nThe bias of the actual MLE is again very small for this distribution function,\nhowever.\nAs the fit with the asymptotic MSE was not satisfactory for Birg\u00e9's estimator\nin the separated case, we also did some simulations for much larger sample\nsizes. It turns out that the MSE then approximates the values predicted by the\nasymptotic theory. Some evidence is given in table 6. The results are based on\n1000 pseudo-random samples.\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n27\n\nTable 8\nVariance for Birg\u00e9's estimator and MLE, times n2/3 , t0 = 0.3, 0.4, 0.5 and 0.6, separated\ncase. The asymptotic variances are displayed in bold type.\n\nn = 1000\nn = 2500\nn = 5000\nn = 10000\n\nt0 = 0.3\nBirg\u00e9 MLE\n0.23\n0.12\n0.46\n0.14\n0.35\n0.13\n0.42\n0.13\n0.36\n0.12\n\nt0 = 0.4\nBirg\u00e9 MLE\n0.21\n0.13\n0.47\n0.15\n0.36\n0.14\n0.38\n0.13\n0.37\n0.14\n\nt0 = 0.5\nBirg\u00e9 MLE\n0.20\n0.13\n0.46\n0.15\n0.39\n0.14\n0.40\n0.14\n0.39\n0.14\n\nt0 = 0.6\nBirg\u00e9 MLE\n0.21\n0.13\n0.47\n0.15\n0.37\n0.14\n0.39\n0.13\n0.39\n0.14\n\nTable 9\nSquared Bias for Birg\u00e9's estimator and MLE, times n2/3 , t0 = 0.3, 0.4, 0.5 and 0.6,\nseparated case. The asymptotic squared bias (Birg\u00e9) is displayed in bold type.\n\nn = 1000\nn = 2500\nn = 5000\nn = 10000\n\nt0\nBirg\u00e9\n0.11\n0.11\n0.09\n0.11\n0.10\n\n= 0.3\nMLE\n2.3 * 10\u22125\n5.1 * 10\u22126\n4.0 * 10\u22128\n3.2 * 10\u22125\n\nt0\nBirg\u00e9\n0.11\n0.10\n0.10\n0.09\n0.11\n\n= 0.4\nMLE\n1.1 * 10\u22126\n1.7 * 10\u22125\n2.6 * 10\u22126\n2.1 * 10\u22126\n\nt0\nBirg\u00e9\n0.10\n0.10\n0.09\n0.10\n0.10\n\n= 0.5\nMLE\n1.3 * 10\u22126\n3.1 * 10\u22126\n5.9 * 10\u22125\n1.0 * 10\u22125\n\nt0\nBirg\u00e9\n0.11\n0.10\n0.12\n0.11\n0.10\n\n= 0.6\nMLE\n1.2 * 10\u22125\n2.0 * 10\u22125\n1.6 * 10\u22126\n4.6 * 10\u22126\n\nTable 10\nMSE of SMLE divided by MSE of MLE, t0 = 0.3, 0.4, 0.5 and 0.6, separated case.\n\nn = 1000\nn = 2500\nn = 5000\nn = 10000\n\nt0 = 0.3\nratio\n0.258\n0.230\n0.219\n0.199\n\nt0 = 0.4\nratio\n0.272\n0.244\n0.225\n0.201\n\nt0 = 0.5\nratio\n0.274\n0.243\n0.225\n0.206\n\nt0 = 0.6\nratio\n0.268\n0.244\n0.219\n0.203\n\nTable 11\nMSE for Birg\u00e9's estimator and MLE, times n2/3 , f0 (t) = 4(1 \u2212 t)3 , t \u2208 [0, 1],\nt0 = 0.3, 0.4, 0.5 and 0.6, separated case. The asymptotic MSE (Birg\u00e9) and the asymptotic\nvariance (MLE) are displayed in bold type.\n\nn = 1000\nn = 2500\nn = 5000\nn = 10000\n\nt0 = 0.3\nBirg\u00e9 MLE\n0.41\n0.15\n0.53\n0.16\n0.61\n0.16\n0.56\n0.16\n0.49\n0.15\n\nt0 = 0.4\nBirg\u00e9\nMLE\n0.24\n0.081\n0.39\n0.088\n0.33\n0.087\n0.36\n0.083\n0.36\n0.082\n\nt0 = 0.5\nBirg\u00e9\nMLE\n0.14\n0.037\n0.21\n0.041\n0.25\n0.039\n0.18\n0.038\n0.22\n0.037\n\nt0 = 0.6\nBirg\u00e9\nMLE\n0.08\n0.014\n0.101\n0.016\n0.100\n0.015\n0.101\n0.014\n0.120\n0.014\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n28\n\nTable 12\nVariance for Birg\u00e9's estimator and MLE, times n2/3 , t0 = 0.3, 0.4, 0.5 and 0.6,\nf0 (t) = 4(1 \u2212 t)3 , t \u2208 [0, 1], separated case. The asymptotic variances are displayed in bold\ntype.\n\nn = 1000\nn = 2500\nn = 5000\nn = 10000\n\nt0 = 0.3\nBirg\u00e9 MLE\n0.28\n0.15\n0.41\n0.16\n0.48\n0.16\n0.43\n0.16\n0.35\n0.15\n\nt0 = 0.4\nBirg\u00e9\nMLE\n0.16\n0.081\n0.32\n0.087\n0.25\n0.087\n0.28\n0.082\n0.28\n0.082\n\nt0 = 0.5\nBirg\u00e9\nMLE\n0.091 0.037\n0.16\n0.040\n0.19\n0.039\n0.13\n0.038\n0.17\n0.037\n\nt0 = 0.6\nBirg\u00e9\nMLE\n0.051 0.014\n0.070\n0.016\n0.063\n0.015\n0.070\n0.014\n0.090\n0.014\n\nTable 13\nSquared Bias for Birg\u00e9's estimator and MLE, times n2/3 , f0 (t) = 4(1 \u2212 t)3 , t \u2208 [0, 1],\nt0 = 0.3, 0.4, 0.5 and 0.6, separated case. The asymptotic squared bias (Birg\u00e9) is displayed\nin bold type.\n\nn = 1000\nn = 2500\nn = 5000\nn = 10000\n\nt0\nBirg\u00e9\n0.14\n0.12\n0.13\n0.13\n0.13\n\n= 0.3\nMLE\n1.1 * 10\u22124\n3.2 * 10\u22125\n1.4 * 10\u22126\n4.8 * 10\u22125\n\nt0\nBirg\u00e9\n0.079\n0.076\n0.080\n0.075\n0.079\n\n= 0.4\nMLE\n1.6 * 10\u22124\n2.3 * 10\u22124\n3.0 * 10\u22124\n1.4 * 10\u22124\n\nt0\nBirg\u00e9\n0.045\n0.051\n0.054\n0.048\n0.049\n\n= 0.5\nMLE\n2.2 * 10\u22124\n2.0 * 10\u22124\n1.0 * 10\u22124\n1.1 * 10\u22124\n\nt0\nBirg\u00e9\n0.025\n0.030\n0.037\n0.031\n0.030\n\n= 0.6\nMLE\n3.2 * 10\u22124\n1.1 * 10\u22124\n8.7 * 10\u22125\n8.0 * 10\u22125\n\nTable 14\nMSE of SMLE divided by MSE of MLE, times n2/3 , f0 (t) = 4(1 \u2212 t)3 , t \u2208 [0, 1],\nt0 = 0.3, 0.4, 0.5 and 0.6, separated case,\n\nn = 1000\nn = 2500\nn = 5000\nn = 10000\n\nt0 = 0.3\nratio\n0.439\n0.372\n0.350\n0.312\n\nt0 = 0.4\nratio\n0.395\n0.393\n0.354\n0.332\n\nt0 = 0.5\nratio\n0.443\n0.409\n0.383\n0.349\n\nt0 = 0.6\nratio\n0.435\n0.424\n0.391\n0.389\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n29\n\n9. Summary\nIn the preceding, the limit distributions of three estimators for the interval censoring, case 2, problem were discussed: Birg\u00e9's estimator, the (nonparametric)\nmaximum likelihood estimator (MLE) and the smoothed MLE, which is analogous to the smoothed MLE introduced in [8] for the current status model. Birg\u00e9's\nestimator is mainly of theoretical interest and constructed to show that the minimax rate can be attained. The construction uses prior knowledge on whether\nthe observation distribution has arbitrarily small observation intervals (the socalled non-separated case) or not (the separated case). Such prior knowledge is\nnot necessary for the MLE, which adapts automatically to either situation.\nThe conjectured limit distribution of the MLE in the non-separated case,\ngiven in [5], was (partially) checked in a simulation study, comparing Birg\u00e9's\nestimator, the MLE and the smoothed MLE. The simulation study seems to\nsupport the conjecture. The smoothed MLE converges at a faster rate than\neither Birg\u00e9's estimator or the MLE on which it is based if the underlying\ndistribution is smooth, as is also borne out by the simulation study.\nThe limit distribution of the MLE in the separated case was given in [6] and\nthe simulation study for the separated case shows that the asymptotic variance,\narising from this result, provides a good approximation to the actual finite\nsample variance. The difference in behavior for the separated and non-separated\ncases persists for the smoothed MLE and in that case crucially depends on\nproperties of the solution of an integral equation, as discussed in section 6. This\nanalysis is based on a local version of the theory developed in [2], [3] and [4]. The\n(numerical) solution of the integral equation can be used to estimate the variance\nof the smoothed MLE. The theoretically computed asymptotic variance, using\na numerical solution of the integral equation, fits the observed sample variance\nrather well, but the discussion on this matter is heuristic and still contains lots\nof open questions.\n10. Appendix\nWe split the proof of Theorem 3.1 into several parts, dealing with the difficulties\n(1), (2) and (3), mentioned in section 3. Here and in the following we will\nuse some empirical process notation to make the transition to the asymptotic\ndistribution more transparant. As an example, we give a representation of\nP\n\u2206i,1\n0\n.\n(10.1)\nNk /Nk = Ti \u2208Ik\n# {Ti \u2208 Ik }\nin terms of integrals with respect to empirical distributions. First we write:\nZ\n\u22121 0\nn Nk =\n\u03b41 dPn (t, u, \u03b4),\nt\u2208Ik\n\nwhere \u03b4 = (\u03b41 , \u03b42 , \u03b43 ) is the vector of indicators\n\u03b41 = 1{x\u2264t} , \u03b42 = 1{t<x\u2264u} , \u03b43 = 1{x>u} ,\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n30\n\ngiving the position of the unobservable random variables Xi with respect to\nthe observation interval [Ti , Ui ], and where Pn is the empirical measure of the\nrandom variables (Ti , Ui , \u2206i ) = (Ti , Ui , \u2206i,1 , \u2206i,2 , \u2206i,3 ).\nThe denominator of (10.1), after dividing by n, is rewritten in the form:\nZ\nn\u22121 Nk =\ndGn,1 (t) = Gn,1 (tk+1 ) \u2212 Gn,1 (tk ) ,\n(10.2)\nt\u2208Ik\n\nwhere Gn,1 is the empirical distribution function of the Ti , with underlying df G1\nand underlying density g1 , which is the first marginal of h. Using this notation,\nwe get:\nR\n\u03b4 dPn (t, u, \u03b4)\nt\u2208Ik 1\n0\n,\n(10.3)\nNk /Nk =\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nwhere we the define the ratio to be zero if the denominator is zero. The terms\nMk0 /Mk and Q0j,k /Qj,k can be rewritten in a similar way.\nWe will also use the following decomposition:\n\u001a 0\n\u001b\nNk\n\u2212 F0 (tk ) 1{Nk >0}\nNk\nN 0 \u2212 E {Nk0 |Nk }\nE {Nk0 \u2212 Nk F0 (tk )|Nk }\n= k\n1{Nk >0} +\n1{Nk >0} .\n(10.4)\nNk\nNk\nWe similarly have, denoting 1 \u2212 F0 by F 0 ,\n\u001b\n\u001a 0\nMk\n\u2212 F 0 (tk ) 1{Mk >0}\nMk\n\b\nE Mk0 \u2212 Mk F 0 (tk )|Mk\nMk0 \u2212 E {Mk0 |Mk }\n=\n1{Mk >0} +\n1{Mk >0} .\nMk\nMk\n\n(10.5)\n\nand\n\u001b\nQ0j,k\n\u2212 {F0 (tk ) \u2212 F0 (tj )} 1{Qj,k >0}\nQj,k\nn\no\nQ0j,k \u2212 E Q0j,k |Qj,k\n=\n1{Qj,k >0}\nQj,k\nn\no\nE Q0j,k \u2212 Qj,k {F0 (tk ) \u2212 F0 (tj )} |Qj,k\n+\n1{Qj,k >0} .\nQj,k\n\n\u001a\n\n(10.6)\n\nOne can consider this as a decomposition into a \"variance part\" and a \"bias\npart\", where the first terms on the right-hand sides of the above expressions\ncorrespond to the variance part and the second terms to the bias part.\nWe first deal with the bias part.\nLemma 10.1. Let the conditions of Theorem 3.1 be satisfied, and let, for each\n(n)\ninterval Ik of the partition, tk = tk be its left boundary point. Moreover, let\n(n)\ntj = tj \u2192 t0 , and \u03b1n be defined by (3.12). Then we have for Birg\u00e9's statistic,\ndefined by (3.4),\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n31\n\n(i) As n \u2192 \u221e,\no\u00112\n\u0010 n\n\u03b1n\u22122 var E Fen (tj ) \u2212 F0 (tj ) Nk , Qj,k , k > j; Mk , Qk,j , k < j\n\u2192 0.\n(10.7)\n(ii) As n \u2192 \u221e,\no p\nn\n\u03b1n\u22121 E Fen (tj ) \u2212 F0 (tj ) Nk , Qj,k , k > j; Mk , Qk,j , k < j \u2212\u2192 12 cf0 (t0 ).\n(10.8)\nProof.\n(i). If Nk , Mk , Qj,k and Qk,j are strictly positive, for all (relevant) values of k,\nwe can write\no\nn\nE Fen (tj ) \u2212 F0 (tj ) Nk , Qj,k , k > j; Mk , Qk,j , k < j\n\u001a\nX\nE {Nk0 \u2212 Nk F0 (tk )|Nk }\n\u2212\n=\nwj,k\nNk\nk:k>j\nn\no\uf8fc\nE Q0j,k \u2212 Qj,k {F0 (tk ) \u2212 F0 (tj )} |Qj,k \uf8fd\nQj,k\n(\n+\n\nX\nk:k<j\n\nwj,k\n\n\uf8fe\n\nE Mk \u2212 Mk0 F 0 (tk )|Mk\nMk\nn\no\uf8fc\nE Q0k,j \u2212 Qk,j {F0 (tk ) \u2212 F0 (tj )} |Qk,j \uf8fd\n+\n,\n\uf8fe\nQk,j\n\b\n\nsee (10.4) to (10.6). We can write this in the following form:\nn\no\nE Fen (tj ) \u2212 F0 (tj ) Nk , Qj,k , k > j; Mk , Qk,j , k < j\n(R\nX\n{F0 (t) \u2212 F0 (tk )} dGn,1 (t)\nIk\n=\nwj,k\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nk:k>j\nR\n)\n{F0 (u) \u2212 F0 (t) \u2212 F0 (tk ) + F0 (tj )} dHn (t, u)\nt\u2208Ij , u\u2208Ik\nR\n\u2212\ndHn (t, u)\nt\u2208Ij , u\u2208Ik\n(R\nX\n{F0 (t) \u2212 F0 (tk )} dGn,2 (t)\nIk\n+\nwj,k\nGn,2 (tk+1 ) \u2212 Gn,2 (tk )\nk:k<j\nR\n)\n{F0 (u) \u2212 F0 (t) \u2212 F0 (tj ) + F0 (tk )} dHn (t, u)\nt\u2208Ik , u\u2208Ij\nR\n+\n.\ndHn (t, u)\nt\u2208Ik , u\u2208Ij\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n32\n\nBy expanding F0 in tk and tj , as in (3.11), we find that this can be written\nn\no\nE Fen (tj ) \u2212 F0 (tj ) Nk , Qj,k , k > j; Mk , Qk,j , k < j\n(\nR\nX\nf0 (tk ) Ik (t \u2212 tk ) dGn,1 (t)\n=\nwj,k\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nk:k>j\nR\n)\n{f0 (tk ) (u \u2212 tk ) \u2212 f0 (tj ) (t \u2212 tj )} dHn (t, u)\nt\u2208Ij , u\u2208Ik\nR\n\u2212\ndHn (t, u)\nt\u2208Ij , u\u2208Ik\n(\nR\nX\nf0 (tk ) Ik (t \u2212 tk ) dGn,2 (t)\n+\nwj,k\nGn,2 (tk+1 ) \u2212 Gn,2 (tk )\nk:k<j\nR\n)\n{f0 (tj ) (u \u2212 tj ) \u2212 f0 (tk ) (t \u2212 tk )} dHn (t, u)\nt\u2208Ik , u\u2208Ij\nR\n\u2212\ndHn (t, u)\nt\u2208Ik , u\u2208Ij\n+ o (1/K) .\nThe remainder term o(1/K) arises from the fact that we can write, for example,\nR\nR\n{F0 (t) \u2212 F0 (tk )} dGn,1 (t)\nf0 (tk ) Ik (t \u2212 tk ) dGn,1 (t)\nIk\n=\n+ (tk+1 \u2212 tk ) o(1),\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nwhere tk+1 \u2212 tk \u2264 1/K, and the o(1)-factor is uniform in k, by the uniform\ncontiuity of f0 on [0, 1]. A similar expansion is used for the other terms, and the\no(1/K) remainder term now surfaces from the fact that the weights wj,k sum\nto 1.\nFurthermore, if j < k, and tk , tj \u2208 [\u000f, 1 \u2212 \u000f], for some \u000f \u2208 (0, 1/2), we get:\n(\n2\nEwj,k\n\nf0 (tk )\n\nR\nIk\n\n(t \u2212 tk ) dGn,1 (t)\n\nf0 (tk )\n\nR\nIk\n\n(t \u2212 tk ) dG1 (t)\n\n\u2212\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nnR\no2\nnf0 (tk )2 Ik (t \u2212 tk ) d (Gn,1 \u2212 G1 ) (t)\n\u2264E\n1{Nk >0}\n(1 + k \u2212 j)2 Wj2 {Gn,1 (tk+1 ) \u2212 Gn,1 (tk )}\n\u223c\n\n\u223c\n\n)2\n1{Nk >0>0}\n\nf0 (tk )2\n1\nE 2 1{Wj > 0}\n2\n3(1 + k \u2212 j) Kg1 (tk ) Wj\n3f0 (tk )2\n2\n\nn(1 + k \u2212 j)2 g1 (tk ) {a(t0 ) + b(t0 )} (log n)2\n\n,\n\nwhere we use (3.10) and exponential inequalities of the type discussed in the\nproof of Lemma 3.1 below for the probability that\n|Gn,1 (tk+1 ) \u2212 Gn,1 (tk ) \u2212 G1 (tk+1 ) + G1 (tk )| > \u000f.\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n33\n\nWe similarly get, for all k > j,\n(R\nf (t ) (u \u2212 tk ) d (Hn \u2212 H) (t, u)\nt\u2208Ij , u\u2208Ik 0 k\n2\nR\nEwj,k\ndHn (t0 , u0 )\nt0 \u2208Ij , u0 \u2208Ik\nR\n)2\nf (t ) (t \u2212 tj ) d (Hn \u2212 H) (t, u)\nt\u2208Ij , u\u2208Ik 0 j\nR\n\u2212\n1{Qj,k >0}\ndHn (t0 , u0 )\nt0 \u2208Ij , u0 \u2208Ik\n\b\nf0 (tk )2 + f0 (tj )2 {1 + o(1)}\n,\n\u2264E\n2\n3n(1 + k \u2212 j)2 h(tj , tk ) {a(t0 ) + b(t0 )} (log n)2\nwith an analogous upper bound for the terms, involving Qk,j, , with k < j, and,\nfinally, if k < j, and tk , tj \u2208 [\u000f, 1 \u2212 \u000f],\n(\n2\nEwj,k\n\n\u2264\n\nf0 (tk )\n\nR\nIk\n\n(t \u2212 tk ) d (Gn,2 \u2212 G2 ) (t)\n\nGn,2 (tk+1 ) \u2212 Gn,2 (tk )\n\n)2\n1{Mk >0}\n\n3f0 (tk )2 {1 + o(1)}\n2\n\nn(1 + k \u2212 j)2 g2 (tk ) {a(t0 ) + b(t0 )} (log n)2\n\n.\n\nThe terms for tk > 1 \u2212 \u000f are treated by using\n(\n)2\nR\nf0 (tk ) Ik (t \u2212 tk ) dGn,1 (t)\n2\n2\n2\nEwj,k\n\u2264 Ewj,k\nf0 (tk )2 (tk+1 \u2212 tk )\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\n\u2264\n\n2\nwj,k\nf0 (tk )2\n9a(tk )2 f0 (tk )2\n\u223c\n2\n2\nK\nK 2 (k \u2212 j + 1)2 {a(t0 ) + b(t0 )} (log n)2\n9a(tk )2 f0 (tk )2\n,\n\u223c\n2\nK 4 (tk \u2212 tj )2 {a(t0 ) + b(t0 )} (log n)2\n\nwith a similar upper bound for tk < \u000f and\n)2\n(\nR\nf0 (tk ) Ik (t \u2212 tk ) dGn,2 (t)\n2\n.\nEwj,k\nGn,2 (tk+1 ) \u2212 Gn,2 (tk )\nWe also have, for example, if k 0 > k > j,\n(\nR\nwj,k f0 (tk ) Ik (t \u2212 tk ) d (Gn,1 \u2212 G1 ) (t)\nE\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nR\n)\nwj,k0 f0 (tk0 ) I 0 (t \u2212 tk0 ) d (Gn,1 \u2212 G1 ) (t)\nk\n*\nGn,1 (tk0 +1 ) \u2212 Gn,1 (tk0 )\n\u223c\n\n4nK 2 {a(t0 )\n\n9a(tk )a(tk0 )\n,\n+ b(t0 )}2 (k \u2212 j + 1)(k 0 \u2212 j + 1)(log n)2\n\nand the expectation of other cross-product terms can be treated similarly.\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n34\n\nCombining these results, we find that the variance of the conditional expectation\no\nn\n\u03b1n\u22121 E Fen (tj ) \u2212 F0 (tj ) Nk , Qj,k , k > j; Mk , Qk,j , k < j\nis of order O(1/{n(log n)2 \u03b1n2 }) = o(1).\n(ii). We have, if tk \u2208 [\u000f, 1 \u2212 \u000f],\nR\n2\n1 2\n{F0 (t) \u2212 F0 (tk )} dGn,1 (t)\nc f0 (tk ) (tk+1 \u2212 tk ) g1 (tk ) {1 + op (1)}\nIk\n= 2\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\ncg1 (tk ) (tk+1 \u2212 tk ) {1 + op (1)}\n= 21 cf0 (tk ) (tk+1 \u2212 tk ) {1 + op (1)} ,\nand similarly,\nR\n{F0 (t) \u2212 F0 (tk )} dGn,1 (t)\nIk\nGn,2 (tk+1 ) \u2212 Gn,2 (tk )\n\n= 21 cf0 (tk ) (tk+1 \u2212 tk ) {1 + op (1)} ,\n\nMoreover, if k > j,\nR\n{F0 (u) \u2212 F0 (t) \u2212 F0 (tk ) + F0 (tj )} dHn (t, u)\nt\u2208Ij , u\u2208Ik\nR\ndHn (t, u)\nt\u2208Ij , u\u2208Ik\n= 21 c\n\n{f0 (tk ) (tk+1 \u2212 tk ) \u2212 f0 (tj ) (tj+1 \u2212 tj )} h(tj , tk ) {1 + op (1)}\nh(tj , tk ) {1 + op (1)}\n\n= 21 c {f0 (tk ) (tk+1 \u2212 tk ) \u2212 f0 (tj ) (tj+1 \u2212 tj )} {1 + op (1)} ,\nwith a similar expansion for k < j. The op (1)-terms are uniform in k, as follows\nby using exponential inequalities of the same type as used in Lemma 3.1.\nIt is easily seen that the terms, involving values of tk \u2208\n/ [\u000f, 1 \u2212 \u000f] give a\nnegligible contribution, by noting that\nR\nf0 (tk ) Ik (t \u2212 tk ) dGn,1 (t)\n\u2264 f0 (tk ) (tk+1 \u2212 tk ) ,\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nif k > j, with a similar upper bound if tk < tj . The results now follows by\nmultiplying with wj,k and summing over k, see (3.11).\n\u0003\nWe now define\nUn,k = n\u22121 {Nk0 \u2212 E {Nk0 |Nk }} ,\n\n(10.9)\n\nVn,k = n\u22121 {Mk0 \u2212 E {Mk0 |Mk }} .\n\n(10.10)\n\nand\nNote that these are the numerators of the \"variance parts\" in (10.4) and (10.5),\ndivided by n. The following lemma shows that (in the proper scaling for Birg\u00e9's\nstatistic) the variances of the sums of terms, involving Un,k and Vn,k in Birg\u00e9's\nstatistic, tend to zero.\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n35\n\nLemma 10.2. Let the conditions of Theorem 3.1 be satisfied, let tj = t0 , and\nlet \u03b1n be defined by (3.12). Moreover, let Un,k and Vn,k be defined by (10.9) and\n(10.10). Then, as n \u2192 \u221e,\n\uf8f6\n\uf8eb\nX\nX\nwj,k Vn,k\nwj,k Un,k\n\uf8f8 \u2192 0.\n\u03b1n\u22122 var \uf8ed\n+\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nGn,2 (tk+1 ) \u2212 Gn,2 (tk )\nk:k<j\n\nk:k>j\n\nProof. We have:\n\uf8eb\n\uf8f6\nX\nX\nw\nU\nw\nV\nj,k\nn,k\nj,k\nn,k\n\uf8f8\nvar \uf8ed\n+\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nk:k>j\nk:k<j\n\u0012\n\u0013\n\u0012\n\u0013\nX\nX\nwj,k Un,k\nwj,k Vn,k\n=\nvar\n+\nvar\n,\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nGn,2 (tk+1 ) \u2212 Gn,2 (tk )\nk:k>j\n\nk:k<j\n\nsince the covariances of the terms in the sum are zero. As before, we define the\nratios to be zero if the denominator is zero.\nFurthermore:\n\u0012\n\u0013\n\u0012\n\u00132\nwj,k Un,k\nwj,k Un,k\nvar\n=E\n,\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nsince E wj,k Un,k /{Gn,1 (tk+1 ) \u2212 Gn,1 (tk )} = 0. Noting that the weights wj,k\nhave upper bound\np\nn {Gn,1 (tk+1 ) \u2212 Gn,1 (tk )}\n,\n(k \u2212 j + 1)Wj\nwe now obtain:\n\u03b1n\u22122 var\n\n\u0012\n\n\u2264 \u03b1n\u22122 E\n= \u03b1n\u22122 E\n\nwj,k Un,k\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\n\n\u0013\n\n2\nnUn,k\n(k \u2212 j + 1)2 {Gn,1 (tk+1 ) \u2212 Gn,1 (tk )} Wj2\nR\nF (t) {1 \u2212 F0 (t)} dGn,1 (t)\nIk 0\n\n(k \u2212 j + 1)2 {Gn,1 (tk+1 ) \u2212 Gn,1 (tk )} Wj2\n\u03b1\u22122 {F0 (tk ) (1 \u2212 F0 (tk )) + o(1)} \b\n= n\nE 1/Wj2 1{Wj >0} .\n(k \u2212 j + 1)2\nwhere (as before),\ndef\nUn,k / {Gn,1 (tk+1 ) \u2212 Gn,1 (tk )} = 0,\nif Gn,1 (tk+1 ) \u2212 Gn,1 (tk ) = 0.\nBy (3.10):\n\b\nE 1/Wj2 1{Wj >0} \u223c\n\nK\n2\n\nn {a(t0 ) + b(t0 )}\n\n(log n)2\n\n\u0010 n\u22122/3 (log n)\u22125/3 , (10.11)\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n36\n\nSo we obtain\n\u03b1n\u22122\n\n\u0013\nwj,k Un,k\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nk:k>j\n\u0012\n\u0013\nX\nwj,k Vn,k\n\u22122\n+ \u03b1n\nvar\nGn,2 (tk+1 ) \u2212 Gn,2 (tk )\nX\n\n\u0012\n\nvar\n\nk:k<j\n\n= O (1/ log n) .\n\u0003\nWe now define, if j < k,\n\b\n\b\nWn,j,k = (log n) Q0j,k \u2212 E Q0j,k |Qj,k\n\n,\n\n(10.12)\n\n\b\n\b\nWn,j,k = (log n) Q0k,j \u2212 E Q0k,j |Qk,j\n\n.\n\n(10.13)\n\nand, if j > k:\nLemma 10.2 suggests that if (n log n)1/3 {Fen (t0 ) \u2212 F0 (t0 )} has a nondegenerate\ndistribution, this has to come from the sum:\nX\n\n\u2212\n\nk:k>j\n\nwj,k\n\nX\nWn,j,k\nWn,j,k\n+\nwj,k 2\n,\nc2 h(tj , tk )\nc h(tk , tj )\n\n(10.14)\n\nk:k<j\n\nThe following lemma shows that (10.14), with the random weights wj,k replaced\nby the deterministic weights w\nej,k indeed has a nondegenerate limit distribution.\nLemma 10.3. Let the conditions of Theorem 3.1 be satisfied, let tj = t0 . Moreover, let Wn,j,k be defined by (10.12) and (10.13). Then:\n\u2212\n\nX\n\nw\nej,k\n\nk:k>j\n\nWn,j,k\n2\nc h(tj , tk )\n\n+\n\nX\n\nw\nej,k\n\nk:k<j\n\nWn,j,k\n2\nc h(tk , tj )\n\nD\n\n\u2212\u2192 N 0, \u03c302\n\n\u0001\n\nwhere the right-hand side denotes a normal random variable, with expectation 0\nand variance \u03c302 , defined by (3.14) in Theorem 3.1.\nProof. We will prove the result by constructing a martingale-difference array,\nand applying Theorem 1, p. 171 of [12]. Define, for k > j, the random variables\n\u03ben,k = \u2212w\nej,k\n\nWn,j,k\n.\nc2 h(tj , tk )\n\nFor k < j we define\n\u03ben,k = w\nej,k\n\nWn,j,k\n,\n2\nc h(tk , tj )\n\nand (for notational convenience) we define \u03ben,j \u2261 0.\nLet the increasing sequence of \u03c3-fields Fn,k , k = 0, 1, . . . be defined by\nFn,0 = \u2205, Fn,k = \u03c3 {(Ti , Ui , \u2206i ) , Ti \u2264 tk+1 , Ui \u2208 Ij } , k \u2264 j,\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n37\n\nand\nFn,k = \u03c3 {(Ti , Ui , \u2206i ) , Ti \u2208 Ij , Ui \u2264 tk+1 } , j < k,\nwhere \u2206i = (\u2206i,1 , \u2206i,2 , \u2206i,3 ), as before. Note: Ik = [tk , tk+1 ), k < K, and\nIK = [tK , tK+1 ], under scheme (i), and Ik = [tk , tk+1 ), k \u2264 K, and IK+1 =\n[tK+1 , tK+2 ] under scheme (ii) at the beginning of this section.\nThen:\n\b\nE \u03ben,k Fn,k\u22121 = 0, k = 1, 2, . . .\n(10.15)\nHere and in the following the indices k run from 1 to K or to K + 1, depending\non whether scheme (i) or (ii) holds, respectively.\nNote that, if k < j, we can write\nZ\nWn,j,k = n log n\n{\u03b42 \u2212 {F0 (u) \u2212 F0 (t)}} dPn (t, u, \u03b4)\n(t,u)\u2208Ik \u00d7Ij\n\n= log n\n\nn\nX\n\n{\u22062,i \u2212 {F0 (u) \u2212 F0 (t)}} 1{Ti \u2208Ik , Ui \u2208Ij } .\n\ni=1\n\nand that\n\b\nE \u22062,i \u2212 {F0 (Ui ) \u2212 F0 (Ti )} Fn,k = 0,\nif tk < Ti < tj and Ui \u2208 Ij , using the independence of the Xi from the pairs\n(Ti , Ui ). Similar relations hold if ti \u2208 Ij . This implies\n\b\nE \u03ben,k Fn,k\u22121 = 0, k = 1, 2, . . . .\n(10.16)\nIt is also clear that \u03ben,k is measurable with respect to Fn,k .\nLet the conditional variances vn,k be defined by\n\b 2\nvn,k = E \u03ben,k\nFn,k\u22121 , k = 1, 2, . . . .\nWe first consider the indices k such that\n|j \u2212 k| < \u000fn K,\nwhere \u000fn = (log n)\n\n\u22121/3\n\n. We then get, if k < j,\n\nvn,k\n=\n\n2\nw\nej,k\nn(log n)2\nc4 h(tk , t0 )2\n(Z\n*E\n\n)\n{F0 (u) \u2212 F0 (t)} {1 \u2212 F0 (u) + F0 (t)} dHn (t, u) Fn,k\u22121\n\nt\u2208Ik , u\u2208Ij\n\n=\n\n2\nw\nej,k\nn1/3 (log n)4/3 (t0 \u2212 tk )f0 (t0 ) {1 + op (1)}\nc2 h(tk , t0 )\n\n9\u03b2(t0 )2 (n log n)1/3 (j \u2212 k + 1)f0 (t0 ) {1 + op (1)}\nc2 Kh(tk , t0 )(j \u2212 k + 1)2 log n\n9b(t0 )2 f0 (t0 ) {1 + op (1)}\n=\n.\n2\nc {a(t0 ) + b(t0 )} h(tk , t0 )(j \u2212 k + 1) log n\n=\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n38\n\nWe similarly get:\nvn,k =\n\n9a(t0 )2 f0 (t0 ) {1 + op (1)}\n2\n\nc {a(t0 ) + b(t0 )} h(tk , t0 )(j \u2212 k + 1) log n\n\n.\n\nif k > j and k \u2212 j < \u000fn K. The terms vn,k , where |k \u2212 j| \u2265 \u000fn K, give a negligible\ncontribution, since\nX\n\n2\no\nn\nw\nej,k\nn(log n)2\n\u22122/3\nO\n(n\nlog\nn)\np\nc4 h(tk , t0 )2\nk:j\u2212k\u2265\u000fn K\n\u0010\n\u0011\n= Op (log n)\u22122/3 ,\n\nX\n\nvn,k =\n\nk:j\u2212k\u2265\u000fn K\n\nusing\n\uf8eb\nX\n\n2\nw\nej,k\n= O\uf8ed\n\nk:j\u2212k\u2265\u000fn K\n\nX\n\nk:j\u2212k\u2265\u000fn K\n\n\uf8f6\n\u0010\n\u0011\n1\n\uf8f8 = O n\u22121/3 (log n)\u22122 ,\n(j \u2212 k)2 (log n)2\n\nas n \u2192 \u221e. So we find\nX\n\np\n\nvn,k \u2212\u2192 \u03c302 ,\n\n(10.17)\n\nk:k6=j\n\nsince\nX\nm:m<\u000fn K\n\n1\n1\n\u223c log n, n \u2192 \u221e.\nm+1\n3\n\nTo get asymptotic normality, it only remains to show that the Lindeberg-type\ncondition\nX \b\np\n2\nE \u03ben,k\n1{|\u03ben,k |>\u000f} Fn,k\u22121 \u2212\u2192 0,\n(10.18)\nk6=j\n\nholds for each \u000f > 0, since in that case both conditions of Theorem 1 of [12] are\nsatisfied. To this end we use the conditional Cauchy-Schwarz inequality\nr n\no \b\n\b 2\n4\nE \u03ben,k 1{|\u03ben,k |>\u000f} Fn,k\u22121 \u2264 E \u03ben,k\nFn,k\u22121 E 1{|\u03ben,k |>\u000f} Fn,k\u22121 .\n(10.19)\nNote that:\n\b\n\b 2\nE 1{|\u03ben,k |>\u000f} Fn,k\u22121 \u2264 \u000f\u22122 E \u03ben,k\nFn,k\u22121 = \u000f\u22122 vn,k = Op (1/ log n),\n(10.20)\nas n \u2192 \u221e. Using again the conditional independence of the Xi , given the values\nof the pairs (Ti , Ui ), and defining p0 (t, u) = F0 (u) \u2212 F0 (t), p0 (t, u) = 1 \u2212 p0 (t, u),\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n39\n\nwe get, if k < j:\n\b 4\nFn,k\u22121\nE \u03ben,k\n\u223c\n\n4\nw\nej,k\nn(log n)4\n*\nc8 h(tk , t0 )4\n(Z\n)\n\b\n*E\np0 (t, u)p0 (t, u)} p0 (t, u)3 + p0 (t, u)3 dHn (t, u) Fn,k\u22121\nt\u2208Ik , u\u2208Ij\n\n+\n\n4\nw\nej,k\nn2 (log n)4\n*\nc8 h(tk , t0 )4\n(\u001aZ\n)\n\u001b2\n*E\np0 (t, u){1 \u2212 p0 (t, u)} dHn (t, u)\nFn,k\u22121 . (10.21)\nt\u2208Ik , u\u2208Ij\n\nThe first conditional expectation on the right-hand side of (10.21) arises from\nterms of the form\nn\no\n4\nE {\u22062,i \u2212 (F0 (Ui ) \u2212 F0 (Ti ))} Fn,k\u22121 ,\nwhere Ti \u2208 Ik , Ui \u2208 Ij , and the second one from terms of the form\nn\no\n2\n2\nE {\u22062,i \u2212 (F0 (Ui ) \u2212 F0 (Ti ))} {\u22062,i0 \u2212 (F0 (Ui0 ) \u2212 F0 (Ti0 ))} Fn,k\u22121 ,\nwhere i 6= i0 and Ti , Ti0 \u2208 Ik ; Ui , Ui0 \u2208 Ij , where we added the diagonal terms\n(where i = i0 ) for simplicity of notation, since they give a negligible contribution.\nThe other conditional expectations of crossproducts are zero. If k > j we get an\nentirely similar expansion, with the roles of t and u interchanged.\nThe\u221afirst term on the right-hand side of (10.21) gives a contribution of order\nOp (1/ log n) in the summation of the terms\nr n\no\n4\nE \u03ben,k\nFn,k\u22121\n\nover k. The square root of the second term is of order Op (1/{|j \u2212 k| log n}),\nif |j \u2212 k| < \u000fn K, which leads to a contribution of order Op (1) in the above\nsummation. The part where |j \u2212 k| \u2265 \u000fn K is again negligible.\nSo we get, using (10.19) and (10.20),\nK\nX\n\nE\n\n\b\n\n= Op\n\n\u0010\n\n2\n\u03ben,k\n1{|\u03ben,k |>\u000f}\n\nk=1\n\nFn,k\u22121\n\nK r n\n\u0011X\no\n\u0010 p\n4\nE \u03ben,k\nFn,k\u22121\n= Op 1/ log n\nk=1\n\n\u0011\np\n1/ log n .\n\u0003\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n40\n\nProof of Theorem 3.1.\nad (i). Lemma 10.2 shows that the terms involving Nk0 /Nk and Mk0 /Mk only\ngive a contribution to the asymptotic bias of Birg\u00e9's statistic, but not to the\nlimit distribution of the centered part. The limit distribution of the centered\npart therefore arises from the terms Wn,j,k , where\nZ\nWn,j,k = n log n\n{\u03b42 \u2212 {F0 (u) \u2212 F0 (t)}} dPn (t, u, \u03b4),\n(t,u)\u2208Ik \u00d7Ij\n\nwhich are the numerators of the fractions\nn\n\u0010\n\u0011o\n(n log n)1/3 Q0j,k \u2212 E Q0j,k |Qj,k\nQj,k\nn log n\n\nR\n\n=\n\n{\u03b42 \u2212 {F0 (u) \u2212 F0 (t)}} dPn (t, u, \u03b4)\nR\n.\n(n log n)2/3 (t,u)\u2208Ij \u00d7Ik dHn (t, u)\n\n(t,u)\u2208Ik \u00d7Ij\n\nNow note that\n(n log n)\n\n2/3\n\nZ\n\ndHn (t, u) = c2 h(tj , tk ) {1 + op (1)} .\n\n(t,u)\u2208Ij \u00d7Ik\n\nwhere the op (1)-term is uniform in k by the results, given above. Moreover, by\npart (i) of Lemma 3.1,\nX\nk6=j\n\nwj,k\n\nX\nX\nWn,j,k\nWn,j,k\nWn,j,k\n,\n=\nw\nej,k\n+ op (1)\n2\n2\ne\ne\n(k\n\u2212\nj + 1) log n\nc h(tj , tk )\nc h(tj , tk )\nk6=j\n\nk6=j\n\nwhere\ne\nh(t, u) = h(t, u), t < u, e\nh(t, u) = h(u, t), t \u2265 u.\nThe result now follows from Lemma 10.3.\nad (ii). We first prove (3.15). Since E Fen (tj ) is the expectation of\nn\no\nE Fen (tj ) Nk , Qj,k , k > j; Mk , Qk,j , k < j ,\npart (i) of Lemma 10.1 tells us that\nn n\no\no2\n\u03b1n\u22122 E E Fen (tj ) Nk , Qj,k , k > j; Mk , Qk,j , k < j \u2212 E Fen (tj ) \u2192 0,\nas n \u2192 \u221e. This implies:\nn n\no\no p\n\u03b1n\u22121 E Fen (tj ) Nk , Qj,k , k > j; Mk , Qk,j , k < j \u2212 E Fen (tj ) \u2212\u2192 0,\nas n \u2192 \u221e. But since, by part (ii) of Lemma 10.1,\nn n\no\no p\n\u03b1n\u22121 E Fen (tj ) Nk , Qj,k , k > j; Mk , Qk,j , k < j \u2212 F0 (t0 ) \u2212\u2192 21 cf0 (t0 ),\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n41\n\nas n \u2192 \u221e, we must have:\nn\no\n\u03b1n\u22121 E Fen (tj ) \u2212 F0 (t0 ) \u2192 12 cf0 (t0 ), n \u2192 \u221e.\nThis yields (3.15).\nTo prove (3.16), we first note that, by part (i) of Lemma 10.1, the variance\nof the conditional expectation\nn\no\n\u03b1n\u22121 E Fen (tj ) \u2212 F0 (t0 ) Nk , Qj,k , k > j; Mk , Qk,j , k < j\nin the decomposition\nn\no\n\u03b1n\u22121 Fen (tj ) \u2212 F0 (t0 )\nn\nn\noo\n= \u03b1n\u22121 Fen (tj ) \u2212 E Fen (tj ) Nk , Qj,k , k > j; Mk , Qk,j , k < j\nn\no\n+ \u03b1n\u22121 E Fen (tj ) \u2212 F0 (t0 ) Nk , Qj,k , k > j; Mk , Qk,j , k < j\ntends to zero. By Lemma 10.2 the sum of terms involving\nNk and M\nn\no k also gives\n\u22121\ne\nan asymptotically negligible contribution to \u03b1n Fn (tj ) \u2212 F0 (t0 ) .\nSo we only have to consider the contribution of terms of the form\nn\n\u0010\n\u0011o\n\u03b1n\u22121 wj,k Q0j,k \u2212 E Q0j,k |Qj,k\n, k > j,\n(10.22)\nQj,k\nand\n\nn\n\u0010\n\u0011o\n\u03b1n\u22121 wj,k Q0k,j \u2212 E Q0k,j |Qk,j\nQk,j\n\n, k < j.\n\n(10.23)\n\nThe variance of (10.22) is given by\nR\n2\nn(log n)2 wj,k\n{F0 (u) \u2212 F0 (t)} {1 \u2212 (F0 (u) \u2212 F0 (t))} dHn (t, u)\n(t,u)\u2208Ik \u00d7Ij\nE\n.\nnR\no2\n(n log n)4/3 (t,u)\u2208Ij \u00d7Ik dHn (t, u)\nLemma 3.1 gives (uniform) exponential inequalities are derived for the probabilities of the events of the following type:\n(\n)\nZ\ndef\n\nAj,k =\n\n(n log n)2/3\n\ndHn (t, u) \u2212 c2 h(tj , tk ) > \u000fc2 h(tj , tk ) ,\n\n(t,u)\u2208Ij \u00d7Ik\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n42\n\nyielding upper bounds, tending to zero faster than any power of n. So we get:\nR\n(\n2\nn(log n)2 wj,k\n{F0 (u) \u2212 F0 (t)} {1 \u2212 (F0 (u) \u2212 F0 (t))} dHn (t, u)\n(t,u)\u2208Ik \u00d7Ij\nE\nnR\no2\n(n log n)4/3 (t,u)\u2208Ij \u00d7Ik dHn (t, u)\n)\n* 1Aj,k\n\u2264 K {F0 (tk+1 ) \u2212 F0 (tj )} E\n\n(n log n)2/3 {1 + o(1)}\n1Aj,k \u2229{Wj >0}\n(1 + k \u2212 j)2 Wj2\n\n\u2264 K 3 {F0 (tk+1 ) \u2212 F0 (tj )} E\n\n(n log n)2/3 {1 + o(1)}\nP (Aj,k ) ,\n(1 + k \u2212 j)2\n\nwhich tends to zero faster than any power of n, uniformly in k. Here we use the\nlower bound 1/K for Wj 1{Wj >0} .\nSo we find:\nR\n2\nn(log n)2 wj,k\n{F0 (u) \u2212 F0 (t)} ({1 \u2212 (F0 (u) \u2212 F0 (t))} dHn (t, u)\n(t,u)\u2208Ik \u00d7Ij\nE\n(1 \u2212 \u000f)2 c4 h(tj , tk )\n+ o(1/K)\n\u2265E\n\n\u2265E\n\n2\nwj,k\n\nR\n\n2\nn(log n)2 wj,k\n\nR\n\nn(log n)\n\n2\n\n{F0 (u) \u2212 F0 (t)} {1 \u2212 (F0 (u) \u2212 F0 (t))} dHn (t, u)\no2\nnR\n(n log n)4/3 (t,u)\u2208Ij \u00d7Ik dHn (t, u)\n\n(t,u)\u2208Ik \u00d7Ij\n\n(t,u)\u2208Ik \u00d7Ij\n\n{F0 (u) \u2212 F0 (t)} {1 \u2212 (F0 (u) \u2212 F0 (t))} dHn (t, u)\n(1 + \u000f)2 c4 h(tj , tk )\n+ o(1/K).\n\nThis implies:\nE\n\n2\nn(log n)2 wj,k\n\n=E\n\nR\n\n{F0 (u) \u2212 F0 (t)} {1 \u2212 (F0 (u) \u2212 F0 (t))} dHn (t, u)\nnR\no2\n(n log n)4/3 (t,u)\u2208Ij \u00d7Ik dHn (t, u)\n\n(t,u)\u2208Ik \u00d7Ij\n\n2\nn(log n)2 wj,k\n\nR\n(t,u)\u2208Ik \u00d7Ij\n\n{F0 (u) \u2212 F0 (t)} {1 \u2212 (F0 (u) \u2212 F0 (t))} dHn (t, u)\nc4 h(tj , tk )\n+ o(1/K).\n\nNow let, for tk < 1 \u2212 \u03b4, where \u03b4 > 0, the event Bk be defined by\n\u001a\n\u001b\nZ\ndef\nBk = (1 + k \u2212 j) (n log n)1/3\ndGn (u) \u2212 cg1 (tk ) > \u000fcg1 (tk ) ,\nu\u2208Ik\n\nFor tk \u2265 1 \u2212 \u03b4, we define the event Bk by:\n\u001a\nZ\ndef\n1/3\nBk = (1 + k \u2212 j) (n log n)\n\n\u001b\ndGn (u) \u2212 cg1 (tk ) > \u000fc ,\n\nu\u2208Ik\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n43\n\nSimilarly to what is true for Aj,k , we have that P (Bk ) tends to zero faster than\nany power of n, uniformly in k. This shows that we also can replace wj,k by w\nej,k\nin the asymptotic expression for the variance, using the fact that the terms for\ntk > 1 \u2212 \u03b4 will give a contribution of lower order in the summation. So we find:\nn(log n)2 *\n*\n\n2\nX Ewj,k\n\nR\n(t,u)\u2208Ik \u00d7Ij\n\n{F0 (u) \u2212 F0 (t)} {1 \u2212 (F0 (u) \u2212 F0 (t))} dHn (t, u)\nc4 h(tj , tk )\n\nk:j>k\n\n\u223c\n\nX 9na(tk )2 E\n\n\u223c\n\n{F0 (u) \u2212 F0 (t)} {1 \u2212 (F0 (u) \u2212 F0 (t))} dHn (t, u)\n2\n\nX 9na(tk )2 {F0 (tk ) \u2212 F0 (tj )} {1 \u2212 (F0 (tk ) \u2212 F0 (tj ))} (n log n)\u22122/3\n2\n\nc2 {a(t0 ) + b(t0 )} (j \u2212 k + 1)2 h(tj , tk )\n\nk:j>k\n\n\u223c\n\n(t,u)\u2208Ik \u00d7Ij\n\nc4 {a(t0 ) + b(t0 )} (j \u2212 k + 1)2 h(tj , tk )\n\nk:j>k\n\n\u223c\n\nR\n\nX\n\n9na(tj )2 f0 (tj ) (tk \u2212 tj ) (n log n)\u22122/3\n\nk:j>k\n\nc2 {a(t0 ) + b(t0 )} (j \u2212 k + 1)2 h(tj , tk )\n\n2\n\nX\n\n9na(tj )2 f0 (tj )(n log n)\u22121\n2\n\nk:j>k\n\nc {a(t0 ) + b(t0 )} (j \u2212 k + 1)h(tj , tk )\n\n\u223c\n\n3a(t0 )2 f0 (t0 )\n2\n\nc {a(t0 ) + b(t0 )} h(tj , tk )\n\n.\n\nSimilarly we find that the summation for k < j gives a contribution which is\nasymptotically equivalent to\n3b(t0 )2 f0 (t0 )\n2\n\nc {a(t0 ) + b(t0 )} h(tj , tk )\nThis yields (3.16).\n\n.\n\u0003\n\nProof of Lemma 3.1.\nWe first prove (3.9). By Bennett's inequality (see, e.g., [12], p. 192) we have, for\n\u000f > 0,\nn\n\u000fo\nP |Nk /n \u2212 ENk /n| >\nK\n(\n!)\nn\u000f2\n\u000f\nR\nR\n\u2264 2 exp \u2212\n,\n\u03c6\n2K 2 t\u2208Ik g1 (t) dt\nK t\u2208Ik g1 (t) dt\nwhere\n\n2 {(1 + x) log(1 + x) \u2212 x}\n, x > 0.\n(10.24)\nx2\nThis way of stating Bennett's inequality first appeared in [13]. The function \u03c6\nsatisfies limx\u21930 \u03c6(x) = 1 and\n\u03c6(x) =\n\n\u03c6(x) \u2265\n\n1\n, x > 0,\n1 + x/3\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n44\n\nsee [12], p. 192, p. 193.\nBy the continuity of g1 on [0, 1] there exists for each k a \u03bek \u2208 Ik such that\nZ\ng1 (t) dt = g1 (\u03bek ) {tk+1 \u2212 tk } .\nIk\n\nHence we get, for each k,\n\u001a\n\u0012\n\u0013\u001b\nn\nn\u000f2\n\u000f\n\u000fo\n\u2264 2 exp \u2212\n\u03c6\nP |Nk /n \u2212 ENk /n| >\nK\n2Kg1 (\u03bek )\ng1 (\u03bek )\n\u001a\n\u0012\n\u0013\u001b\n2/3 2\ncn \u000f\n\u000f\n= 2 exp \u2212\n\u03c6\n.\ng1 (\u03bek )\n2g1 (\u03bek )(log n)1/3\nSimilarly we get, for each k and points \u03b7k \u2208 Ik ,\n\u0012\n\u001a\n\u0013\u001b\nn\n\u000fo\n\u000f\ncn2/3 \u000f2\n\u03c6\n.\nP |Mk /n \u2212 EMk /n| >\n\u2264 2 exp \u2212\nK\n2g2 (\u03b7k )\n2g2 (\u03b7k )(log n)1/3\nMoreover, if j < k,\nn\n\u000f o\nP |Qj,k /n \u2212 EQj,k /n| > 2\nK\n!)\n(\n2\n\u000f\nn\u000f\nR\nR\n\u03c6\n\u2264 2 exp \u2212\n2K 4 t\u2208Ij , u\u2208Ik h(t, u) dt du\nK 2 t\u2208Ij , u\u2208Ik h(t, u) dt du\n\u001a 2 1/3 2\n\u0012\n\u0013\u001b\nc n \u000f {1 + o(1)}\n\u000f{1 + o(1)}\n= 2 exp \u2212\n\u03c6\n.\n2h(tj , tk )\n2h(tj , tk )(log n)2/3\nwith a similar upper bound, if k < j.\nLet \u000f > 0, let h be defined by\nh(t, u) = h(t, u), u \u2265 t, h(t, u) = h(u, t), u < t,\n\n(10.25)\n\nand similarly Qj,k by\nQj,k (t, u) = Qj,k (t, u), u \u2265 t, k \u2265 j, Qj,k (t, u) = Qk,j (u, t), (u, t), u < t, k < j.\n(10.26)\nMoreover, let the set Aj,\u000f be defined by\n(\n\u000f\n\u000f\nAj,\u000f = sup Qj,k /n \u2212 EQj,k /n \u2264 2 , sup |Nk /n \u2212 ENk /n| \u2264 ,\nK k>j\nK\nk6=j\n)\n\u000f\nsup |Mk /n \u2212 EMk | \u2264\n.\nK\nk<j\nand let\nhj = inf h(tj , tk ).\nk:k6=j\n\n(10.27)\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n45\n\nThen we have:\n\u0012\n1 \u2212 P (Aj,\u000f ) = O n\n\n1/3\n\nc2 n1/3 \u000f2\n\u03c6\nexp \u2212\n4hj (log n)2/3\n\u001a\n\n\u0012\n\n\u000f\n4hj\n\n\u0013\u001b\u0013\n.\n\n(10.28)\n\nFurthermore, as n \u2192 \u221e,\nZ\nsup |KENk /n \u2212 g1 (tk )| = sup K\nk:k>j\n\nk:k>j\n\ng1 (t) dt \u2212 g1 (tk ) \u2192 0,\nt\u2208Ik\n\nalso on the last interval, since g1 (t) \u2192 0 on this interval,\nZ\nsup |KEMk /n \u2212 g2 (tk )| = sup K\ng2 (t) dt \u2212 g2 (tk ) \u2192 0,\nk:k<j\n\nk:k<j\n\nt\u2208Ik\n\nalso on the first interval, since g2 (t) \u2192 0 on this interval. We also have:\nK 2 EQj,k /n \u2212 h(tj , tk ) = K 2\n\nZ\nh(t, u) dt du \u2212 h(tj , tk ) \u2192 0,\nt\u2208Ij , u\u2208Ik\n\nuniformly for all tk , not belonging to the first or last interval, which may not\nhave length 1/K (see the construction of the intervals of Birg\u00e9's statistic at the\nbeginning of section 3). But on these intervals we have\nh(t, tj ) \u2227 g2 (t) = g2 (t) and h(tj , t) \u2227 g1 (t) = g1 (t),\nrespectively. So we get:\n\u0001\nsup (KENk /n) \u2227 K 2 EQj,k /n \u2212 g1 (tk ) \u2227 h(tj , tk ) \u2192 0,\n\n(10.29)\n\nk:k>j\n\nand\n\u0001\nsup (KEMk /n) \u2227 K 2 EQk,j /n \u2212 g2 (tk ) \u2227 h(tk , tj ) \u2192 0,\n\n(10.30)\n\nk:k<j\n\nHence, we get from (10.28), (10.29) and (10.30), on the set Aj,\u000f ,\np\np\nX Mk \u2227 (KQk,j ) X Nk \u2227 (KQj,k )\nWj =\n+\nj\u2212k+1\nk\u2212j+1\nk<j\nk>j\np\np\n\u221a X (Mk /n \u2227 (KQk,j /n) \u221a X (Nk /n) \u2227 (KQj,k /n)\n= n\n+ n\nj\u2212k+1\nk\u2212j+1\nk<j\nk>j\n\uf8f1\n\uf8f2X p(EM /n) \u2227 (KEQ /n)\np\nk\nk,j\n\u2265 n(1 \u2212 \u000f)\n\uf8f3\nj\u2212k+1\nk<j\n\n+\n\nX\nk>j\n\n\uf8fc\np\n(ENk /n) \u2227 (KEQj,k /n) \uf8fd\n\uf8fe\nk\u2212j+1\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\np\n=\n\n46\n\n\uf8f1\np\nn(1 \u2212 \u000f) \uf8f2X (KEMk /n) \u2227 (K 2 EQk,j /n)\n\u221a\n\uf8f3\nj\u2212k+1\nK\nk<j\n\n\uf8fc\n(KENk /n) \u2227 (K 2 EQj,k /n) \uf8fd\n+\n\uf8fe\nk\u2212j+1\nk>j\n\uf8fc\n\uf8f1\np\np\np\nn(1 \u2212 \u000f) \uf8f2X g2 (tk ) \u2227 h(tk , tj ) X g1 (tk ) \u2227 h(tj , tk ) \uf8fd\n\u221a\n=\n+\n,\n\uf8fe\n\uf8f3\nj\u2212k+1\nk\u2212j+1\nK\nX\n\np\n\nk<j\n\nk>j\n\nand similarly\np\nWj \u2264\n\n\uf8f1\n\uf8fc\np\np\nn(1 + \u000f) \uf8f2X g2 (tk ) \u2227 h(tk , tj ) X g1 (tk ) \u2227 h(tj , tk ) \uf8fd\n\u221a\n.\n+\n\uf8f3\n\uf8fe\nj\u2212k+1\nk\u2212j+1\nK\nk<j\nk>j\n\nMoreover, letting \u000fn = (log n)\u22121/3 , we get:,\np\np\nX g2 (tk ) \u2227 h(tk , tj ) X g1 (tk ) \u2227 h(tj , tk )\n+\nj\u2212k+1\nk\u2212j+1\nk>j\nk<j\np\np\nX\nX\ng2 (tk ) \u2227 h(tk , tj )\ng1 (tk ) \u2227 h(tj , tk )\n=\n+\nj\u2212k+1\nk\u2212j+1\nk:tj \u2212tk <\u000fn\nk:tk \u2212tj <\u000fn\np\np\nX\nX\ng2 (tk ) \u2227 h(tk , tj )\ng1 (tk ) \u2227 h(tj , tk )\n+\n+\nj\u2212k+1\nk\u2212j+1\nk:tj \u2212tk \u2265\u000fn\n\n=\n\n1\n3\n\nk:tk \u2212tj \u2265\u000fn\n\n{a(t0 ) + b(t0 )} (log n){1 + o(1)}.\n\nRelation (3.9) now follows.\nTo prove (3.10) we first note that\n\u0012\n\u0012\n\u001a\n\u0013\u001b\u0013\n1\n\u000f\nc2 n1/3 \u000f2\nE m 1{Wj >0}\u2229Acj,\u000f = O (K + 1)m n1/3 exp \u2212\n\u03c6\n,\nWj\n4hj\n4hj (log n)2/3\nwhere hj is defined by (10.27), since Wj \u2265 1/(K + 1), if Wj > 0 Thus we find:\n1\n1\n1\n1{Wj >0} = E m 1{Wj >0}\u2229Aj,\u000f + E m 1{Wj >0}\u2229Acj,\u000f\nWjm\nWj\nWj\n\uf8f1\n\uf8fc\u2212m\n\uf8f2X pEM \u2227 (KEQ ) X pEN \u2227 (KEQ ) \uf8fd\n1\nk\nk,j\nk\nj,k\n\u2264\n+\n\uf8fe\nj\u2212k+1\nj\u2212k+1\n(1 \u2212 \u000f)m/2 \uf8f3k<j\nk>j\n\u0012\n\u001a\n\u0012\n\u0013\u001b\u0013\nc2 n1/3 \u000f2\n\u000f\n+ O (K + 1)m n1/3 exp \u2212\n\u03c6\n2/3\n4hj\n4hj (log n)\n\u0013m/2\n\u0012\n9K\n\u2212m\n{(a(t0 ) + b(t0 )) log n}\n\u223c\n, n \u2192 \u221e.\nn(1 \u2212 \u000f)\n\nE\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n47\n\nand similarly\n1\nE m 1{Wj >0} \u2265\nWj\n\n\u0012\n\n9K\nn(1 + \u000f)\n\n\u0013m/2\n\n\u2212m\n\n{(a(t0 ) + b(t0 )) log n}\n\n, n \u2192 \u221e,\n\nimplying\n1\nE m 1{Wj >0} \u223c\nWj\n\n\u0012\n\n9K\nn\n\n\u0013m/2\n\n\u2212m\n\n{(a(t0 ) + b(t0 )) log n}\n\n, n \u2192 \u221e,\n\nwhich proves (3.10).\nFinally we get for j > k:\n(1 + k \u2212 j)E |wj,k \u2212 w\nej,k | 1{Wj >0}\np\nNk \u2227 (KQk,j )\n3a(tk )\n=E\n1{Wj >0} \u2212\nWj\n{a(t0 ) + b(t0 )} log n\np\n(KNk /n) \u2227 (K 2 Qk,j /n) \u2212 3a(tk )\np\n\u2264E\n1{Wj >0}\nWj K/n\np\nn/K\n1\n+ 3a(tk )E\n.\n1{Wj >0} \u2212\nWj\n{a(t0 ) + b(t0 )} log n\nApplying the Cauchy-Schwarz inequality on the first term on the right-hand\nside yields, if j < k,\np\n(KNk /n) \u2227 (K 2 Qj,k /n) \u2212 3a(tk )\np\nE\n1{Wj >0}\nWj K/n\n( \u001a\n\u001b2 )1/2 q\nq\n\u2264 E\n(KNk /n) \u2227 (K 2 Qj,k /n) \u2212 3a(tk )\nE1/Wj2\n= o(1/ log n),\nuniformly in k, using (3.10) and the exponential inequalities for\nn\nn\n\u000fo\n\u000f o\nP |Nk /n \u2212 ENk /n| >\nand P |Qj,k /n \u2212 EQj,k /n| > 2\nK\nK\nderived above. Using ((3.10)) again, we get that the second term satisfies the\ninequality\np\nn/K\n1\n3a(tk )E\n1{Wj >0} \u2212\nWj\n{a(t0 ) + b(t0 )} log n\n\uf8f1 (\n)2 \uf8fc1/2\np\n\uf8f2\n\uf8fd\nn/K\n1\n\u2264 E\n1{Wj >0} \u2212\n= o(1/ log n).\n\uf8f3\nWj\n{a(t0 ) + b(t0 )} log n \uf8fe\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n48\n\nThe case k < j is treated similarly.\nWe also have:\n(1 + k \u2212 j)E |wj,k \u2212 w\nej,k | 1{Wj =0} = (1 + k \u2212 j) |w\nej,k | P {Wj = 0}\n= o(1/ log n),\nsince, in fact, P {Wj = 0} tends to zero exponentially fast in n. This proves\n(3.8).\n\u0003\nWe next discuss the proof of Theorem 4.1. Since the following lemmas have\nproofs analogous to the proofs of Lemma 10.1 and Lemma 10.2 in section 3 we\nomit their proofs.\nLemma 10.4. Let the observation density h, the number of intervals K and\n(n)\nthe constant c be as in Theorem 3.1, and let tk = tk be the left boundary point\nof a sub-interval of the partition, Moreover, let F0 have a continuous derivative\non [0, 1], and let Gn,1 and Gn,2 be the empirical distribution functions of the Ti\nand Ui , respectively. Then\n(i)\nR\n\u001b\nUn,k + t\u2208Ik {F0 (t) \u2212 F0 (tk )} dGn,1 (t)\nNk0\n,\n\u2212 F0 (tk ) 1{Nk >0} =\nNk\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\n(10.31)\nwhere\nZ\nUn,k =\n{\u03b41 \u2212 F0 (t)} dPn (t, u, \u03b4).\n\u001a\n\nt\u2208Ik\n\n(ii)\nR\n\u001b\nVn,k + t\u2208Ik {F0 (t) \u2212 F0 (tk )} dGn,2 (t)\nMk0\n,\n\u2212 F0 (tk ) 1{Mk >0} =\nMk\nGn,2 (tk+1 ) \u2212 Gn,2 (tk )\n(10.32)\nwhere\nZ\nVn,k =\n{\u03b41 + \u03b42 \u2212 F0 (u)} dPn (t, u, \u03b4).\n\u001a\n\nu\u2208Ik\n\n(iii) Let tj = t0 . Then, if k > j,\n\u001a 0\n\u001b\nQj,k\n1/3\nn\n\u2212 {F0 (tk ) \u2212 F0 (tj )}\nQj,k\n\u001b\n\u001a\nWn,j,k\n1\n{1 + op (1)} ,\n= 2 c {f0 (tk ) \u2212 f0 (t0 )} + 2\nc h(tj , tk )\n\n(10.33)\n\nwhere\nZ\n{\u03b42 \u2212 {F0 (u) \u2212 F0 (t)}} dPn (t, u, \u03b4).\n\nWn,j,k = n\n(t,u)\u2208Ij \u00d7Ik\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\nIf k < j we get:\n\u001a 0\n\u001b\nQj,k\nn1/3\n\u2212 {F0 (t0 ) \u2212 F0 (tk )}\nQj,k\n\u001a\n\u001b\nWn,j,k\n1\n=\nc\n{f\n(t\n)\n\u2212\nf\n(t\n)}\n{1 + op (1)} ,\n+\n0 0\n0 k\nc2 h(tk , tj ) 2\n\n49\n\n(10.34)\n\nwhere\nZ\n{\u03b42 \u2212 {F0 (u) \u2212 F0 (t)}} dPn (t, u, \u03b4).\n\nWn,j,k = n\n(t,u)\u2208Ik \u00d7Ij\n\n(iv) The op (1) terms in (iii) tend to zero uniformly in k.\nLemma 10.5. Let the conditions of Theorem 4.1 be satisfied, and let tj = t0 .\nThen, as n \u2192 \u221e,\n\uf8eb\n\uf8f6\nX\nX\nwj,k Un,k\nwj,k Vn,k\n\uf8f8 \u2192 0.\nn2/3 var \uf8ed\n+\nGn,1 (tk+1 ) \u2212 Gn,1 (tk )\nGn,2 (tk+1 ) \u2212 Gn,2 (tk )\nk:k>j\n\nk:k<j\n\nSince the first moment of the asymptotic distribution follows in a similar\nway as in section 3, using the representations of the components Nk0 /Nk , etc. of\nLemma 10.4, the proof of Theorem 4.1 again boils down to proving the following\nlemma.\nLemma 10.6. Let the conditions of Theorem 4.1 be satisfied, and let tj = t0 .\nMoreover, let Wn,j,k be defined as in part (iii) of Lemma 10.4, and let \u03c3 2 be\ndefined as in Theorem 4.1. Then:\n\u2212\n\nX\n\nw\nej,k\n\nk:k>j\n\nX\n\u0001\nWn,j,k\nWn,j,k\nD\n+\nw\nej,k 2\n\u2212\u2192 N 0, \u03c3 2 ,\nc2 h(tj , tk )\nc h(tk , tj )\nk:k<j\n\nwhere the right-hand side denotes a normal random variable, with expectation 0\nand variance \u03c3 2 , defined by (4.7).\nProof. Since the proof follows the same lines as the proof of Theorem 3.1,\nwe only give the main steps. We define the martingale difference array in the\nsame way as in the proof of Theorem 3.1. Then, if k < j, we get the following\nrepresentation of the conditional variance\nvn,k\n=\n\n2\nnw\nej,k\nc4 h(tk , t0 )2\n(Z\n*E\n\n)\n{F0 (u) \u2212 F0 (t)} {1 \u2212 F0 (u) + F0 (t)} dHn (t, u) Fn,k\u22121\n\nt\u2208Ik , u\u2208Ij\n\n=\n\n2\nn1/3 w\nej,k\n{F0 (t0 ) \u2212 F0 (tk )} {1 \u2212 F0 (t0 ) + F0 (tk )} {1 + op (1)}\n.\nc2 h(tk , t0 )\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n50\n\nSimilarly we get, if k < j,\nvn,k\n=\n\n2\nnw\nej,k\nc4 h(tk , t0 )2\n(Z\n*E\n\n)\n{F0 (u) \u2212 F0 (t)} {1 \u2212 F0 (u) + F0 (t)} dHn (t, u) Fn,k\u22121\n\nt\u2208Ij , u\u2208Ik\n\n=\n\n2\nn1/3 w\nej,k\n{F0 (tk ) \u2212 F0 (t0 )} {1 \u2212 F0 (tk ) + F0 (t0 )} {1 + op (1)}\n.\nc2 h(t0 , tk )\n\nHence, using (4.3) and a Riemann sum approximation, we obtain:\nX\np\nvn,k \u2212\u2192 \u03c3 2 .\n\n(10.35)\n\nk6=j\n\nIt remains to show the Lindeberg-type condition\nX \b\np\n2\nE \u03ben,k\n1{|\u03ben,k |>\u03b4} Fn,k\u22121 \u2212\u2192 0,\n\n(10.36)\n\nk6=j\n\nfor each \u03b4 > 0. We again use the conditional Cauchy-Schwarz inequality\nr n\no \b\n\b 2\n4\nFn,k\u22121 E 1{|\u03ben,k |>\u03b4} Fn,k\u22121 .\nE \u03ben,k\n1{|\u03ben,k |>\u03b4} Fn,k\u22121 \u2264 E \u03ben,k\n(10.37)\nWe have:\n\u0010\n\u0011\n\b\n1 \b 2\nE 1{|\u03ben,k |>\u03b4} Fn,k\u22121 \u2264 2 E \u03ben,k\nFn,k\u22121 = Op (1/K) = Op n\u22121/3 .\n\u03b4\n(10.38)\nLetting p0 (t, u) = F0 (u) \u2212 F0 (t), p0 (t, u) = 1 \u2212 p0 (t, u), we get, if k < j:\n\b 4\nE \u03ben,k\nFn,k\u22121\n\u223c\n\n4\nnw\nej,k\nc8 h(tk , t0 )4\n(Z\n*E\n\n)\n\b\np0 (t, u)p0 (t, u)} p0 (t, u)3 + p0 (t, u)3 dHn (t, u) Fn,k\u22121\n\nt\u2208Ik , u\u2208Ij\n2\n\n4\nn w\nej,k\n+ 8\nE\nc h(tk , t0 )4\n\n(\u001aZ\n\n)\n\u001b2\np0 (t, u){1 \u2212 p0 (t, u)} dHn (t, u)\nFn,k\u22121 .\n\nt\u2208Ik , u\u2208Ij\n\n(10.39)\nThe first and second terms on the right-hand side are, respectively, of order\n\u0012\n\u0013\n\u0012\n\u0013\n1\n1\nand Op\n.\nOp\nK 3 (t0 \u2212 tk )4\nK 2 (t0 \u2212 tk )4\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n51\n\nSo the second term is dominant, and hence:\n2\nnw\nej,k\nc4 h(tk , t0 )2\nk<j\n( (\u001aZ\n\nX\n\n*\n\np0 (t, u){1 \u2212 p0 (t, u)} dHn (t, u)\n\nE\n\n))1/2\n\n\u001b2\nFn,k\u22121\n\nt\u2208Ik , u\u2208Ij\n\n\uf8eb\n\n\uf8f6\n\u0012Z t0 \u2212\u000f\n\u0013\nX\n1\n1\n1\n\uf8ed\n\uf8f8\n= Op\n= Op\ndt = Op (1).\nK\n(t0 \u2212 tk )2\n(t0 \u2212 t)2\n\u000f\n\n(10.40)\n\nk<j\n\nSimilarly the sum of the terms for k > j is Op (1). The result now follows from\n(10.37) and (10.38).\n\u0003\nThe proof of Theorem 4.1 can now be finished by making the transition from\nthe random weights to the deterministic weights, using Lemma 4.1 (see the proof\nof Theorem 3.1 at the end of section 3), and using the central limit result of\nLemma 10.6.\nReferences\n[1] Lucien Birg\u00e9, Interval censoring: a nonasymptotic point of view, Math.\nMethods Statist. 8 (1999), no. 3, 285\u2013298. MR1735467 (2001g:62025)\n[2] R. B. Geskus and P. Groeneboom, Asymptotically optimal estimation of\nsmooth functionals for interval censoring. I, Statist. Neerlandica 50 (1996),\nno. 1, 69\u201388. MR1381209 (97k:62039)\n, Asymptotically optimal estimation of smooth functionals for in[3]\nterval censoring. II, Statist. Neerlandica 51 (1997), no. 2, 201\u2013219.\nMR1466426 (99d:62015)\n[4] Ronald Geskus and Piet Groeneboom, Asymptotically optimal estimation\nof smooth functionals for interval censoring, case 2, Ann. Statist. 27 (1999),\nno. 2, 627\u2013674. MR1714713 (2000j:60044)\n[5] Piet Groeneboom, Nonparametric maximum likelihood estimators for interval censoring and deconvolution, Technical Report 378, Department of\nStatistics, Stanford University, 1991.\n[6]\n, Lectures on inverse problems, Lectures on probability theory and\nstatistics (Saint-Flour, 1994), Lecture Notes in Math., vol. 1648, Springer,\nBerlin, 1996, pp. 67\u2013164. MR1600884 (99c:62092)\n[7]\n, Likelihood ratio type two-sample tests for current status data, Submitted to Scandinavian Journal of Statistics, 2011.\n[8] Piet Groeneboom, Geurt Jongbloed, and Birgit I. Witte, Maximum\nsmoothed likelihood estimation and smoothed maximum likelihood estimation in the current status model, Ann. Statist. 38 (2010), no. 1, 352\u2013387.\nMR2589325 (2011c:62098)\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\fP. Groeneboom and T. Ketelaars/Interval censoring\n\n[9]\n\n[10]\n\n[11]\n\n[12]\n[13]\n\n[14]\n\n52\n\n, A maximum smoothed likelihood estimator in the current status\ncontinuous mark model, To appear in the Journal of Nonparametric Statistics, 2011.\nPiet Groeneboom and Jon A. Wellner, Information bounds and nonparametric maximum likelihood estimation, DMV Seminar, vol. 19, Birkh\u00e4user\nVerlag, Basel, 1992. MR1180321 (94k:62056)\nGeurt Jongbloed, The iterative convex minorant algorithm for nonparametric estimation, J. Comput. Graph. Statist. 7 (1998), no. 3, 310\u2013321.\nMR1646718\nDavid Pollard, Convergence of stochastic processes, Springer Series in\nStatistics, Springer-Verlag, New York, 1984. MR762984 (86i:60074)\nGalen R. Shorack, Some law of the iterated logarithm type results for the\nempirical process, Austral. J. Statist. 22 (1980), no. 1, 50\u201359. MR575000\n(82a:60041)\nJon A. Wellner, Interval censoring, case 2: alternative hypotheses, Analysis of censored data (Pune, 1994/1995), IMS Lecture Notes Monogr. Ser.,\nvol. 27, Inst. Math. Statist., Hayward, CA, 1995, pp. 271\u2013291. MR1483352\n\nimsart-ejs ver. 2011/12/01 file: interval.tex date: November 20, 2018\n\n\f"}