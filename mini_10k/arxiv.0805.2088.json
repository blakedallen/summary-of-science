{"id": "http://arxiv.org/abs/0805.2088v2", "guidislink": true, "updated": "2008-05-28T09:18:48Z", "updated_parsed": [2008, 5, 28, 9, 18, 48, 2, 149, 0], "published": "2008-05-14T15:31:20Z", "published_parsed": [2008, 5, 14, 15, 31, 20, 2, 135, 0], "title": "SUSY Predictions and SUSY Tools at the LHC", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0805.4413%2C0805.3335%2C0805.2057%2C0805.4234%2C0805.3924%2C0805.3193%2C0805.4368%2C0805.4314%2C0805.1220%2C0805.2855%2C0805.3300%2C0805.0873%2C0805.3446%2C0805.3151%2C0805.3830%2C0805.0021%2C0805.3285%2C0805.0267%2C0805.2504%2C0805.1610%2C0805.2138%2C0805.0118%2C0805.1560%2C0805.4472%2C0805.1452%2C0805.2155%2C0805.1332%2C0805.3560%2C0805.2359%2C0805.1798%2C0805.4555%2C0805.4501%2C0805.1612%2C0805.1725%2C0805.3514%2C0805.0508%2C0805.4088%2C0805.3442%2C0805.2968%2C0805.1480%2C0805.3039%2C0805.0506%2C0805.3900%2C0805.4493%2C0805.1637%2C0805.0140%2C0805.4500%2C0805.4481%2C0805.4664%2C0805.3234%2C0805.4104%2C0805.1776%2C0805.2531%2C0805.0990%2C0805.0925%2C0805.1226%2C0805.0349%2C0805.4343%2C0805.2378%2C0805.4304%2C0805.3000%2C0805.4416%2C0805.0400%2C0805.2355%2C0805.1007%2C0805.2088%2C0805.2537%2C0805.2224%2C0805.4635%2C0805.2707%2C0805.4014%2C0805.1903%2C0805.0713%2C0805.0369%2C0805.1248%2C0805.0688%2C0805.2354%2C0805.1033%2C0805.4557%2C0805.3414%2C0805.0762%2C0805.4288%2C0805.0695%2C0805.2955%2C0805.3829%2C0805.1588%2C0805.3935%2C0805.1269%2C0805.3483%2C0805.2123%2C0805.0926%2C0805.1546%2C0805.1778%2C0805.0561%2C0805.3856%2C0805.4433%2C0805.4347%2C0805.1000%2C0805.2264%2C0805.3220%2C0805.0977&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "SUSY Predictions and SUSY Tools at the LHC"}, "summary": "We provide a bestiary of public codes and other algorithmic tools that can be\nused for analysing supersymmetric phenomenology. We also describe the\norganisation of the different tools and communication between them. Tools exist\nthat calculate supersymmetric spectra and decay widths, simulate Monte Carlo\nevents as well as those that make predictions of dark matter relic density or\nthat predict precision electroweak or b-observables. Some global fitting tools\nfor use in SUSY phenomenology are also presented. In each case, a description\nand a link to the relevant web-site is provided. It is hoped that this review\ncould serve as an \"entry-gate\" and map for prospective users.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0805.4413%2C0805.3335%2C0805.2057%2C0805.4234%2C0805.3924%2C0805.3193%2C0805.4368%2C0805.4314%2C0805.1220%2C0805.2855%2C0805.3300%2C0805.0873%2C0805.3446%2C0805.3151%2C0805.3830%2C0805.0021%2C0805.3285%2C0805.0267%2C0805.2504%2C0805.1610%2C0805.2138%2C0805.0118%2C0805.1560%2C0805.4472%2C0805.1452%2C0805.2155%2C0805.1332%2C0805.3560%2C0805.2359%2C0805.1798%2C0805.4555%2C0805.4501%2C0805.1612%2C0805.1725%2C0805.3514%2C0805.0508%2C0805.4088%2C0805.3442%2C0805.2968%2C0805.1480%2C0805.3039%2C0805.0506%2C0805.3900%2C0805.4493%2C0805.1637%2C0805.0140%2C0805.4500%2C0805.4481%2C0805.4664%2C0805.3234%2C0805.4104%2C0805.1776%2C0805.2531%2C0805.0990%2C0805.0925%2C0805.1226%2C0805.0349%2C0805.4343%2C0805.2378%2C0805.4304%2C0805.3000%2C0805.4416%2C0805.0400%2C0805.2355%2C0805.1007%2C0805.2088%2C0805.2537%2C0805.2224%2C0805.4635%2C0805.2707%2C0805.4014%2C0805.1903%2C0805.0713%2C0805.0369%2C0805.1248%2C0805.0688%2C0805.2354%2C0805.1033%2C0805.4557%2C0805.3414%2C0805.0762%2C0805.4288%2C0805.0695%2C0805.2955%2C0805.3829%2C0805.1588%2C0805.3935%2C0805.1269%2C0805.3483%2C0805.2123%2C0805.0926%2C0805.1546%2C0805.1778%2C0805.0561%2C0805.3856%2C0805.4433%2C0805.4347%2C0805.1000%2C0805.2264%2C0805.3220%2C0805.0977&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We provide a bestiary of public codes and other algorithmic tools that can be\nused for analysing supersymmetric phenomenology. We also describe the\norganisation of the different tools and communication between them. Tools exist\nthat calculate supersymmetric spectra and decay widths, simulate Monte Carlo\nevents as well as those that make predictions of dark matter relic density or\nthat predict precision electroweak or b-observables. Some global fitting tools\nfor use in SUSY phenomenology are also presented. In each case, a description\nand a link to the relevant web-site is provided. It is hoped that this review\ncould serve as an \"entry-gate\" and map for prospective users."}, "authors": ["B. C. Allanach"], "author_detail": {"name": "B. C. Allanach"}, "author": "B. C. Allanach", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1140/epjc/s10052-008-0695-2", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0805.2088v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0805.2088v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "29 pages, 9 figures. If this review omits or inaccurately describes\n  your publicly available, supported, documented phenomenological SUSY tool on\n  the date of arXival, please contact the author with the details. The review\n  will be corrected taking your comments into account", "arxiv_primary_category": {"term": "hep-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "hep-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "astro-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "hep-ex", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0805.2088v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0805.2088v2", "journal_reference": "Eur.Phys.J.C59:427-443,2009", "doi": "10.1140/epjc/s10052-008-0695-2", "fulltext": "arXiv:0805.2088v2 [hep-ph] 28 May 2008\n\nPreprint typeset in JHEP style - HYPER VERSION\n\nSUSY Predictions and SUSY Tools at the LHC\n\nB.C. Allanach\u2217 ,\nDAMTP, CMS, University of Cambridge, Wilberforce road, Cambridge, CB3 0WA,\nUnited Kingdom\n\n\u2217\n\nAbstract: We provide a bestiary of public codes and other algorithmic tools that can\nbe used for analysing supersymmetric phenomenology. We also describe the organisation\nof the different tools and communication between them. Tools exist that calculate supersymmetric spectra and decay widths, simulate Monte Carlo events as well as those that\nmake predictions of dark matter relic density or that predict precision electroweak or bobservables. Some global fitting tools for use in SUSY phenomenology are also presented.\nIn each case, a description and a link to the relevant web-site is provided. It is hoped that\nthis review could serve as an \"entry-gate\" and map for prospective users.\n\n\fContents\n1. Introduction\n\n1\n\n2. Spectrum and Decays\n2.1 MSSM Sparticle Decays\n2.2 Higgs Masses and Decays\n2.3 NMSSM\n\n4\n6\n6\n7\n\n3. Matrix Element Generators and Cross Section Calculators\n\n7\n\n4. Event Generators\n\n8\n\n5. Predictions of SUSY Dark Matter\n\n11\n\n6. Predictions for constraints\n6.1 b observables\n6.2 Anomalous magnetic moment of the muon\n6.3 Electric dipole moments\n6.4 Electroweak observables\n\n13\n13\n14\n14\n14\n\n7. Fitting tools\n7.1 Algorithms for multi-dimensional fits\n7.2 Example Global Fits to mSUGRA\n7.3 Data archival\n\n15\n15\n19\n20\n\n8. Summary\n\n21\n\n1. Introduction\nAnalysis in high energy particle physics is becoming increasingly complex; the higher energies and luminosities of current-day colliders lead to higher multiplicities in events. The\ncurrent high-energy frontier is dominated by hadron-hadron colliders, at the Tevatron (pp\u0304\nat 2 TeV) or, in the near future, the Large Hadron Collider (pp at 10 or 14 TeV), leading to additional complications in describing hadronic initial states and radiation. On the\ntheoretical side, the currently most popular solution to the technical hierarchy problem is\nthe Minimal Supersymmetric Standard Model (MSSM). A low energy parametrisation of\nthe MSSM contains over 100 parameters. In fact, a truly supersymmetric version of the\nStandard Model contains one less parameter than the Standard Model, since the quartic\n\n\u20131\u2013\n\n\fTheoretical boundary condition\n\nDark matter\n\nSUSY Spectrum calculator\nInput observables\n\nGlobal fits\n\nElectroweak/flavour observables\nDecays\nEvent generator\nMatrix element\nParton shower/hadronisation\n\nDetector simulation\nFigure 1: Schematic of the interaction between various programs that perform different SUSY\nphenomenology calculations. The need for information exchange is denoted by a line.\n\nHiggs coupling becomes a function of the electroweak gauge couplings in the supersymmetric version, instead of being a free parameter. However, in order for the MSSM to be\nphenomenologically viable, supersymmetry (SUSY) must be broken, and it is in the SUSY\nbreaking sector of the model that the majority of the free parameters lie. The vast majority\nof this 100+ dimensional parameter space is ruled out by fairly tight constraints on flavour\nchanging neutral currents. This is often taken to be evidence of some additional structure\nof the model in the flavour sector. High energy boundary conditions on the supersymmetry\nparameters that are flavour universal are popular, and may be motivated by various string\n(and/or grand-unified theory) models.\nA schematic of SUSY phenomenology calculations is shown in Fig. 1. Typically, one\nmay want to assume some high energy theoretical boundary condition upon the SUSY\nbreaking sector. One wishes to calculate the MSSM spectrum and couplings consistent\nwith this boundary condition and some input observables (MZ , mt . . .) with a spectrum\ncalculator. The spectrum and couplings can then be passed to another program that\ncalculates decays of the various sparticles. Once the masses and decays of the sparticles\nare calculated, this information may be passed to an event generator in order to randomly\nsimulate several events in some high energy collision. This process is often split into two\nsub-steps: one performing the hard 2 \u2192 N particle collision (matrix element generation),\nand one performing hadronic showering, initial state radiation and decays of the sparticles\n(event generation). Experimental colleagues often then want to pass such simulated events\nthrough a detector simulation in order to see how the detector might smear the kinematics.\nAlternatively, the spectrum and coupling information could be passed to packages which\ncalculate indirect observables, such as the dark matter relic density left in the universe,\ndark matter direct detection cross-sections, electroweak or b-observables. These data may\nthen be used in global fits to the particular SUSY breaking scenario assumed. Some of\nthe programs available perform several of these tasks, but there is currently no single\n\n\u20132\u2013\n\n\fprogram that performs all of the tasks. Previously, information was passed around on an\nad hoc basis: each spectrum generator had to be interfaced separately with each program\nthat used its output. With N independent codes, the required number of interfaces such\nthat they could each exchange information to the others was \u223c N !. For this reason,\nseveral accords have been written and agreed upon in order to cut down on the total\nnumber of required interfaces, with an associated reduction in the number of mistakes in\nthe interfacing procedure.\nThe SUSY Les Houches Accord (SLHA) [1] allows information on the masses and decays of SUSY (and some relevant Standard Model) particles to be passed in between codes.\nThe accord is based on ASCII text, in order to allow easy cross-language communication\nwithout introducing platform dependence. The parsing of (files or memory variables containing) such ASCII text is an easy task for many human beings, but the disadvantage\nof an ASCII format is that developers of tools must write parsing code. Luckily, even\nthis task has been performed, with a SLHA-file parser available [2]. The original SLHA\ndealt purely with the \"vanilla-MSSM\": inter-generational sparticle mixing is not taken into\naccount, R-parity and CP are conserved. The second SLHA [3] generalises the possible\nMSSM models: R-parity violating, CP and flavour-violating versions of the MSSM are\nall specified. In addition, the most popular MSSM extension where a Standard Model\nsinglet chiral superfield is added, the Next-to-Minimal Supersymmetric Standard Model\n(NMSSM), is covered.\nThe original Les Houches Accord (LHA) [4], allows hard parton-level events to be\npassed from matrix element calculators onward down the chain to the event generators.\nIt does this by means of a fortran77 common block, which specifies properties of the\nparticular process being simulated such as the types of particles involved and their momenta. Colour flow in the diagrams requires particular attention and is encoded in the\nLHA. However, all of the Les Houches Accords attempt to hide such details and requirements from the user. Only tool developers have to concern themselves with them. More\nrecently, the Les Houches Accord event record has been changed to a minimal XML-style\nstructure, for clarity, simpler parsing and to side-step cross-language difficulties [5] and\nseveral parsers (in different languages) have been developed and are available. The accord\nhas also been re-written to take into account potential new beyond the Standard Model\nphysics models [6].\nIn this review, I shall briefly describe the publicly available, supported, documented\ncodes which allow supersymmetric phenomenological calculations1 . In each case, a link to\na current web-site and a reference to the relevant manual is given. The default language\nof each program is fortran77, but if the code is written in a different language, it shall be\ndetailed in this review at the point when the main functionality of the code is discussed.\nAs time passes, it is foreseen that some of the links listed here will become out of date. The\nreader is advised to read the manual of any code they wish to use from the electronic arXiv\nweb-site in order to find updated links to downloads etc. In addition, more accuracy and\nextended functionality will no doubt be added to the various programs as time passes. This\n1\n\nIn fact, a \"quick guide\" of SUSY tools was written over two years ago [7]. The present review contains\nan updated and much more extensive overview of the field.\n\n\u20133\u2013\n\n\fguide is intended to serve as a snap-shot of documented, supported, publicly available SUSY\nphenomenological tools at the time of writing. It is not practical to continually up-date it\nas the state-of-the-art evolves. However, it should be mostly accurate for a good few years\nand there are plans to extend a Beyond the Standard Model tools repository [8] to a Wiki\nsite, so that the authors of the codes may include up-dates to the accuracy/functionality\nas they occur. We shall not describe here any of the detector simulations. First, in section 2,\nwe shall describe codes that calculate MSSM SUSY spectra and decays. Then, in section 3,\nwe list matrix element generators, followed by event generators in section 4. We then turn\nto constraints: in section 5 we review public SUSY dark matter codes, followed by other\nindirect constraint calculators in section 6. We review some of the algorithms required\nto perform global fits to SUSY models using indirect observables in section 7. Finally, in\nsection 8, we conclude and present a table summarising the functionality of the SUSY tools\nmentioned in this review.\n\n2. Spectrum and Decays\nThere are four publicly available dedicated MSSM spectrum generating codes, displayed\nin Table 1. They all solve the MSSM renormalisation group equations (RGEs) to two-loop\norder, subject to two sets of boundary constraints. One set of boundary constraint is at the\nweak scale, and matches the MSSM parameters to current data on Standard Model particle\nmasses and couplings. It also ensures that electroweak symmetry is broken successfully\nby adjusting the MSSM \u03bc parameter. The other boundary condition is typically at a\nhigh energy scale, and involves setting the SUSY breaking parameters according to some\ntheoretical model of SUSY breaking mediation. Universal mSUGRA, minimal anomaly\nmediation and minimal gauge mediation are supported by all of the codes. In addition,\nnon-universal models such as those that can be invoked by the SLHA are supported. Each\nof the codes supports different additional possible SUSY breaking models. They each also\nsupport the SLHA aside from ISAJET [9]. An unofficial version of ISAJET which outputs\nin SLHA format does exist, however [10].\nName\nISAJET\nSOFTSUSY\nSPheno\nSUSPECT\n\nLanguage\nC++\nfortran90\n\nRGEs\ndominant 3rd\n3-family mixing\n3-family no-mixing\ndominant 3rd\n\ncomment\n\u03bdR\n\u03bdR\n\nmanual\n[9]\n[11]\n[12]\n[13]\n\nTable 1: SUSY Spectrum generators. \u03bdR indicates that the program includes an option for including right-handed neutrinos in the spectrum in order to obtain neutrino masses. Dominant 3rd\nRGEs mean that all Yukawa couplings other than the third family's are neglected in the RGEs\nwhereas 3-family no-mixing means that all diagonal Yukawa couplings are included.\n\nThe details of approximations within the codes can be found within the manuals, and\nalthough similar, do tend to vary somewhat. They may differ by higher-order corrections, for example. The matching conditions to current data at the weak scale is mostly\nin the one-loop approximation. But when one is correcting a QCD cross section with\n\n\u20134\u2013\n\n\fFigure 2: Comparison web-page mSUGRA form [14]\n\nstop loops, for example, in order to extract the MSSM value of \u03b1s (MZ ) that should be\nused, the question arises which stop mass should be used? The codes either use pole\nmasses or running masses evaluated at different scales for the stops running in the loops.\nThe difference between these choices is actually a higher order effect, and could only be\nfixed were the two-loop matching conditions known. Broadly speaking, RGE evolution is\ntwo-loop, in different approximations, as displayed in Table 1. ISAJET differs from the\nother codes in that it decouples sparticles at their mass scales, thus re-summing terms\n\u223c O(1/(16\u03c0 2 ) log[\u2206M/M ]), where \u2206M is the splitting between two sparticles and M is\ntheir average mass. On the other hand, the other three codes all evolve using MSSM RGEs\nabove MZ without decoupling sparticles, but then one-loop decoupling effects are added\nto the weak-scale boundary condition to leading logarithmic order. This latter approach\nallows the easy addition of some one-loop finite pieces, some of which are missed by the\nmass-scale decoupling approach taken by ISAJET. In summary, one may expect the massscale decoupling approach to provide a more accurate answer when sparticle splittings are\nvery large, and MZ decoupling including all finite terms to be more accurate for a more\ntypical sparticle splitting. The codes all agree to the percent level, except in particularly\ndifficult parts of parameter space such as the focus point or very large tan \u03b2 [15], where the\ndifferences can be much larger due to inherent numerical instabilities and the size of higher\norder corrections in those regions. Fortunately, a web-site exists [14] where one can input\na SUSY breaking point on a web form as exemplified in Fig. 2, and quickly compare the\noutput from the different codes. If one is doing a study on a particular point, for example,\nthis provides a quick practical way of finding out if the point comes with particularly large\ntheoretical uncertainties or not.\n\n\u20135\u2013\n\n\f2.1 MSSM Sparticle Decays\nCurrently, the programs that calculate sparticle decay branching ratios are Herwig++ [16]\n(C++), ISAJET [9], MadGraph [17], PYTHIA [18], SDECAY [19] and SPheno [12]. SDECAY,\nPYTHIA and Herwig++ take the SLHA stream from any of the other codes in order to produce SLHA-compliant output including decay information, whereas the other two codes are\nlinked to their spectrum generators. The decay packages implement tree-level two-body decays of fermions and gauginos and three-body decays of charginos, neutralinos and gluinos.\nSPheno includes gluonic QCD corrections into decays by quarks. SDECAY implements some\nthree and four-body decays of top squarks and one-loop corrections to the two-body decays.\nPYTHIA and Herwig++ contain internal routines for calculating sparticle decays, including\ntri-linear R\u2212parity breaking effects. Herwig++ and MadGraph include angular correlations\nbetween subsequent decays in a sparticle cascade decay using the pioneering techniques\nof ref. [20], whereas all the other codes make a phase-space approximation. The program\nBRIDGE [21] was written in order to decay particles passed to it by matrix element generators in general models defined in the MadGraph format, then pass them on to showering\nand hadronisation programs. It calculates two and three-body tree-level decays itself, while\nkeeping track of initial vertex spin structures via HELAS. Typically, phase-space is a reasonable approximation in hadronic collisions unless one is trying to fit the spin of sparticles.\n2.2 Higgs Masses and Decays\nThere are some packages specialising in SUSY Higgs calculations: FEYNHIGGS [22] calculates\nthe Higgs masses in a Feynman diagrammatic approach. In calculating Higgs masses,\nimportant two-loop effects are included for the MSSM with or without complex parameters,\nwith a re-summation of the leading (s)bottom corrections. One-loop non-minimal flavour\nviolating corrections to Higgs masses/mixings are included at the one-loop level. The\nprogram calculates the Higgs spectrum and decays and provides an estimate of theoretical\nuncertainties in the prediction. The two-body tree level decays include dominant one-loop\ncorrections and the Higgs decays to gg and \u03b3\u03b3 include all of the MSSM particles in the loop.\nA FEYNHIGGS web-form interface exists for checking single points in parameter space [22].\nThe program CPsuperH [23] also performs MSSM Higgs calculations when CP violating\nphases are present, including some effects up to two-loop order. The program is based\non renormalisation-group improved diagrammatic calculations that include logarithmic as\nwell as threshold corrections and b-quark Yukawa coupling re-summation. Some dominant\none-loop pieces are included in the Higgs decays, which can be into SUSY or SM particles\n(including some important three body decays). The Higgs couplings and neutral Higgs\nmixings are also provided by the program. HDECAY [24] calculates up to three-loop QCD\ncorrected decays of Higgs bosons in the CP-conserving MSSM where expressions exist in\nthe literature, including some loop-induced decays, decays into two massive gauge bosons,\nthree-body decays and decays into SUSY particles. Leading electroweak corrections are\nincluded (they can become important in the large Higgs mass regime due to enhanced Higgs\nself-interactions). All MSSM particles are included in the loop for the calculation of \u03b3\u03b3 and\ngg Higgs decay modes. The leading QCD corrections are included for the gluonic mode.\n\n\u20136\u2013\n\n\fFCHDECAY [25] computes the flavour changing neutral current decays BR(H 0 \u2192 t\u0304c, tc\u0304)\nand BR(H 0 \u2192 b\u0304s, bs\u0304) in the flavour violating MSSM, using SLHA2 for input/output. It\nincludes full one-loop SUSY QCD contributions.\n2.3 NMSSM\nThe addition of a Standard Model singlet superfield to the MSSM constitutes a potential\nsolution to the \u03bc problem (why \u03bc is of order the electroweak scale rather than some much\nheavier scale) and is called the next-to-MSSM (NMSSM). In the package NMSSMtools [26],\nsparticle masses are calculated using two-loop NMSSM RGEs in the dominant third family\napproximation. Tree level sparticle decay widths and branching ratios are also calculated.\nThe Higgs masses, couplings and widths (for two-body modes) are calculated within the\nNMSSM using approximations to the one and two-loop dominant corrections. For decays\ninto the SM particles, the widths are calculated including one-loop SM QCD corrections.\n\n3. Matrix Element Generators and Cross Section Calculators\nIn the high-energy LHC r\u00e9gime, often we wish to calculate the production of more than two\nhard particles. This is the job of matrix element generators. Matrix element generators can\nusually calculate total or differential cross-sections and/or produce independently sampled\nevents. Simulating (for example) the production of two squarks plus some additional hard\nQCD radiated jets requires us to deal with complicated Feynman diagrams involving many\nparticles in the final state. For this job, one uses a matrix element generator, which simulates or calculates the hard process (e.g. q q\u0304 \u2192 t\u03031 \u0304t\u03031 + jet). The matrix element generators\nare currently mostly at tree-level, particularly as regards SUSY physics. In practice, 2 \u2192 6\nto 2 \u2192 8 processes may be feasible depending upon the number of Feynman diagrams,\nalthough a vast amount of CPU time may be needed to compute them (using, for example,\nthe grid). The number of Feynman diagrams tends to grow to be too large with increasing\nnumbers of final-state particles.\nFeynArts/FormCalc [27] are Mathematica packages for the generation and calculation\nof Feynman diagrams up to one-loop order. They can thus be used to calculate matrix\nelements for scattering processes. Up to 2 \u2192 3 processes can be calculated at the oneloop level with integration optimisation, although FormCalc has been successfully used to\ncompute 2 \u2192 4 processes at tree-level. Vanilla, CP violating and non-minimal flavour\nviolating versions of the MSSM are available. There is also a way of encoding some new\nphysics Lagrangian model for extensions. FormCalc simplifies the amplitudes generated\nby FeynArts analytically and generates fortran77 code for the numerical evaluation of\nthe squared matrix element. Automatic generation and pictorial representation of Feynman diagrams is also supported, as is convolution with parton density functions (PDFs).\nRecently, a program HadCalc [28] has been developed based on FeynArts and FormCalc.\nIt takes the output from those codes in terms of partonic cross sections and convolutes\nthem with PDFs. There are convenient ways to place cuts and an interactive menu-driven\nfront-end that can be used to dial in SUSY parameters.\n\n\u20137\u2013\n\n\fCurrently, CalcHEP [29] and CompHEP [30] (C)2 can cope with up to 6 external legs in\na Feynman diagram, for example (1 \u2192 5 or 2 \u2192 4). The two programs can produce C\noutput of analytical expressions for subsequent compilation and use. They have graphical interfaces which can display modulus squared Feynman diagrams. Models are already\ndefined for the MSSM, NMSSM and the CP-violating MSSM. For the encoding of model\nLagrangians and parameters, LanHEP [31] (C) is used. If the user wishes to extend some\nSUSY model outside of the ones already defined, LanHEP provides the means. MadGraph [17]\nperforms vanilla MSSM matrix element calculation with SLHA input. Helicity amplitudes\nare constructed based on the HELAS [32] library in order to encode spin information of the\nproduced particles, which can be used in their decay. Feynman diagrams are drawn, and\nfortran77 output is produced for the matrix element. A Monte-Carlo integrator package has been included in MadGraph, and SUSY differential or total cross sections can be\ncalculated using it. Alternatively, the final result can be Les Houches Accord formatted\nparton-level events that can be passed into an event generator for subsequent parton showering and hadronisation. The MadGraph web-site has a form that can be filled in to get\nevents returned automatically. The event generator SHERPA [33] utilises an event generator\nAmegic++ [34] (C++) that also uses the helicity amplitude technique and calculates at the\ntree-level, with the possibility of up to six particles in the final state of the hard scattering.\nWhizard [35] (fortran95) includes initial and final state polarisations and can calculate in\nthe vanilla MSSM as well as the CP-violating case. It uses O'Mega [36] (O'Caml) to translate a helicity amplitude into computer code as needed. O'Mega is designed with special\ntricks to avoid the factorial increase in CPU time with the number of external particles. It\nhas been demonstrated to work for some processes with eight particles in the final state.\nSUSYGEN [37] is restricted to 2 \u2192 2 SUSY production processes. It can include polarisation\nin e+ e\u2212 collisions and covers vanilla as well as R-parity or CP-violating MSSM models.\nGRACE [38] performs computations of e+ e\u2212 \u2192 up to four bodies in the MSSM at tree-level.\nGRACE draws the relevant Feynman diagrams for the user.\nNumerical results of several hundred SUSY production cross-sections were compared\nbetween MadGraph [17], SHERPA [33] and Whizard [35] and they were all found (eventually)\nto agree [39]. PROSPINO [40] (fortran90) computes MSSM next-to-leading order cross\nsections for the production of two sparticles at hadron colliders. It can also cope with the\nproduction of weak gauginos in the split SUSY framework. Detailed calculations of crosssections of e+ e\u2212 \u2192 sleptons at the one-loop level are also available from ILCslepton [41].\nFeynHiggs [22] calculates Higgs production cross-sections for the Tevatron and the LHC\nincluding SUSY corrections at the production vertex.\n\n4. Event Generators\nThe most well-known general purpose SUSY event generators (PYTHIA [18], Herwig++ [16])\nusually implement a hard-sub process in terms of two particles scattering on two particles,\nrepresented by the central vertex in Fig. 3. The initial particles in this hard-sub process\n2\n\nThese two programs have the same origin, but at some stage the development of them branched.\nBecause of this, although the programs are now different, many features of them are similar.\n\n\u20138\u2013\n\n\fFigure 3: Schematic of a hadron collision simulation in an event generator.\n\nmay be leptons, or point-like constituents of hadrons. In the latter case, the quarks and\ngluons are extracted from a hadron by means of the parton density functions. The hardsub process is usually calculated at leading order in perturbation theory within event\ngenerators, especially for exotic signals such as SUSY. If SUSY particles are produced in\nthe simulated event, they are then decayed randomly, according to the branching ratios\ncalculated by a program in section 2.1. The resulting cascade decay spits out SM particles,\nsome of which may be quarks or gluons. These quarks and gluons then emit soft QCD\nradiation, which is modelled by the parton shower. Parton showering encodes the fact that\nthe matrix elements of massless coloured particles emitting a gluon have a singularity in\nthe infra-red or collinear limit. The initial state may also shower, emitting QCD radiation.\nIt can be important to include effects in the shower coming from colour coherence in order\nto describe the resulting jets adequately. Various properties such as angular ordering of\nthe shower (with preceding emissions being at smaller angles) are evident in the resulting\nevent. Once the partons are showered down to some energy scale to be decided by the\nevent generator, some non-perturbative modelling (and a tune to data) collects the partons\ntogether into hadrons which, after their decays have been simulated, may be observed in\nthe detector. Finally, the simulated events are often represented by a series of lines in a\ntext file (representing variables held in memory), each line describing the kinematics and\nstate of a particle involved with the event. Information on which particles decayed into\nwhich other particles is also indicated in this event record. We briefly mention some of the\nStandard Model properties of event generators, since elements of them are also relevant to\nSUSY events, but the interested reader should see ref. [42] for a more complete guide to\nStandard Model event generators in hadron collisions.\nA general framework for encoding new physics models is included in Herwig++ [16] so\nthat users may define the relevant particles and Feynman rules for the hard sub-process.\nThe MSSM has already been defined within the framework, but extended SUSY models must\nbe input by using it. It can read SLHA files for input SUSY information. The Herwig++\nshower algorithm treats QCD radiation from coloured heavy objects (for example tops).\n\n\u20139\u2013\n\n\fIt can evolve to zero transverse momentum of emissions, giving an improved simulation of\nthe dead-cone effect for radiation from massive particles. An eikonal multiple scattering\nmodel is used for simulating additional partonic collisions in the same hadronic collision.\nSuch processes form part of the underlying event. Herwig++ uses a cluster model for the\nhadronisation step, clustering quarks and gluons that have similar kinematics into colour\nsinglet states, which decay to hadrons and hadron resonances. Herwig++ treats its decays\nincluding spin correlations all of the way down the various decay chains. Herwig++ relies\non an underlying C++ structure developed for high energy collisions called ThePEG [43].\nPYTHIA [18], on the other hand, does not depend upon ThePEG, but is stand-alone.\nAs well as hadron-hadron collisions, it can deal with e+ e\u2212 beams. Initial and final-state\nparton showers are based on pT -ordered evolution, terminating at 1 GeV. Although there\nis currently a C++ version in development, it does not contain any SUSY physics and so we\nconcentrate on the older fortran77 version in this review. Many different options for the\nchanging the models of parts of the PYTHIA simulation are possible, but here we describe\nthe default models. Hadronisation and hadron fragmentation (decay) are modelled by the\nLund string model, where hadrons are modelled to be a colour flux tube, ended where\nthe (di-)quarks are located. The MSSM, the NMSSM, tri-linear R\u2212parity violation, as\nwell as long-lived coloured sparticles such as those that exist in models of split SUSY, are\nincluded in the PYTHIA distribution. Polarisation is included for e+ e\u2212 incoming beams.\nAll decays of sparticles are using the phase-space approximation, and so sparticle spin is\nnot simulated.\nA new event generator has recently been developed called SHERPA [33] (C++). The\nmain design feature of SHERPA is that it combines parton shower evolution and matrix\nelement generation. The MSSM with or without CP violation and full inter-generational\nmixing is included, as well as a general formalism (compatible with the matrix element\ngenerator Amegic++ [34], which ships with the SHERPA distribution) provided for adding\nnew particles and interactions. Amegic++ can practically handle up to six jets in the\nfinal state for e+ e\u2212 collisions, and up to three jets for hadron collisions. One of the\ndifficulties of combining parton showers and matrix element generation for hard jets is\nthe problem of double-counting. If one simply adds the matrix element generation for\n3 jets to the 2-jet plus parton shower sample, one could easily double count the region\nwhere one of the jets is soft (and therefore already included in the parton shower). In\nSHERPA, the parton shower evolution and matrix element generation are matched via the\nCKKW formalism [44], where the matrix element configurations are re-weighted according\nto a pseudo shower history and shower emissions that overlap with higher order matrix\nelements are rejected. SHERPA also performs the hadronisation/fragmentation step using\nits own cluster model [45], which includes di-quark spin effects and a dynamic separation\nof the r\u00e9gimes of clusters and hadrons according to their masses and flavours. When\ncalculating SUSY decays in SHERPA, there is currently no facility for picking the decay\nproducts automatically, the user must supply which decay chain is required. After this has\nbeen done though, the spin information and off-shell effects are included in each sparticles'\ndecay into the next sparticle and Standard Model particle.\nThe ISAJET [9] event generator simulates pp, pp\u0304 and e+ e\u2212 collisions at high energy,\n\n\u2013 10 \u2013\n\n\fbased on perturbative QCD and phenomenological models for parton and beam jet fragmentation, not including colour coherence effects: the probability of emitting a soft gluon\nis multiplied by a factor given by the Alterelli-Parisi function. ISAJET keeps only the parts\nthat are in the exact collinear limit, but uses non-collinear kinematics. QCD radiation\nfrom initial and final states is simulated. Sparticle pair production at tree-level is supported, along with subsequent decay. The ISAJET hadronisation model is the independent\nfragmentation ansatz of Field and Feynman, which forms new (di-)quark-anti-quark pairs\nout of partons, and groups them together into mesons and baryons with some fraction of\ntheir summed momenta.\n\n5. Predictions of SUSY Dark Matter\nThe recent WMAP5 cosmological fits to the cosmic microwave background and other data\nprovide us with an accurate observation of the density of dark matter in the universe as a\nfraction of the relic density: \u03a9h2 = 0.1143 \u00b1 0034 [46]. The MSSM offers several possible\ncandidates for weakly interacting massive particles that could play the r\u00f4le of cold dark\nmatter, since the lightest supersymmetric particle (LSP) is stable from the assumption\nof R\u2212parity. The dark matter candidate obviously must be without electric charge, so\nthat it does not interact with light, and also should be colourless, otherwise it would have\nfused with nuclei during nucleosynthesis and been discovered in anomalously heavy isotope\nsearches. Gravitinos and lightest neutralinos are possible candidates within the MSSM,\nalthough in extended models, other SUSY particles are possible dark matter candidates.\nIn principle, SUSY dark matter may be discovered in direct detection experiments, where\nnuclear recoils from collisions with SUSY dark matter are possible. If the dark matter candidate interacts too weakly (for example in the case of the gravitino), the direct detection\ncross-sections are far too small to small to be seen in the foreseeable future. However, in\nthe case of the neutralino, there is a chance for direct dark matter observation. In order to\ndetect dark matter on earth, it is of course a necessary condition that there is some dark\nmatter going through the detector. While only a small amount is empirically known about\nthe small-scale structure of dark matter halos, numerical N -body simulations indicate that\neven if one starts with strict filaments or cusps of dark matter, subsequent Newtonian\nevolution will tend to smear it out. Thus, the prospect of having our galaxy's dark matter\nlocalised completely elsewhere in the galaxy seems unlikely, but it should be borne in mind\nthat any calculation of the local dark matter flux on earth is subject to large astrophysical\nmodelling uncertainties. Aside from the direct detection of particulate dark matter, there\nare prospects for indirect detection, where for example, dark matter annihilation in the\nsun, in the earth or in the centre of the galaxy produces high energy particles that can be\ndetected on earth or on satellites.\nOnce a SUSY model's parameters has been fixed and a cosmological model is assumed,\nit is possible to estimate the amount of current dark matter relic density in the universe\nis predicted. The codes tend to assume the \u039b CDM model of a cosmological constant plus\ncold dark matter component, since this is quite a simple and good fit to the WMAP and\nlarge scale structure data. One has to track the abundances of the different species of\n\n\u2013 11 \u2013\n\n\fsparticle through the early evolution of the universe. They can annihilate with each other\ninto Standard Model particles, but eventually, the expansion of the universe makes the\nsparticles too far apart to interact. Aside from losses due to annihilation processes, each\nsparticle will end up as a LSP through its decays. The tracking of the abundances of the\nvarious sparticle species and involves the evolution of coupled Boltzmann equations. There\nare many different annihilation cross-section processes to consider, and the relevant public\ncodes currently calculate at tree-level. The velocity distributions of the SUSY particles are\nderived from Maxwell-Boltzmann approximations. This can still involve the calculation of\nthousands of Feynman diagrams, however. As a consequence, the current tools calculate\nmainly at tree-level. However, loop corrections can give large \u223c O(10)% effects in some\ncases [47].\nDarkSUSY [48] contains hard-coded matrix elements for the many different annihilation\nprocesses of the vanilla MSSM. It can calculate the relic density as well as direct and\nindirect detection rates, with a choice of different nuclear form factors for the direct rates.\nSolar system WIMP velocity distributions can be used to calculate the capture in the\nEarth of dark matter particles. An exotic component of positron, anti-proton and antideuteron in cosmic rays originating from neutralino pair annihilation in the galactic halo\ncan be calculated. Hadronisation and fragmentation was calculated with PYTHIA and the\nresults tabulated from various neutralino masses, which DarkSUSY interpolates in order to\nprovide an estimate of the particle yield. For particle yields coming from annihilation in\nthe earth and the sun, 6 fundamental channels are included: cc\u0304, tt\u0304, bb\u0304, \u03c4 + \u03c4 \u2212 , W + W \u2212 and\nZ 0 Z 0 . Recent solar and terrestrial density models are included as a necessary ingredient in\nthe calculation. For galactic halo annihilations, W + W \u2212 , Z 0 Z 0 , W + H \u2212 , Z 0 h0 , Z 0 H 0 , h0 A0\nand H 0 A0 channels are included, with subsequent decay of these particles, including the\nheavy quarks c, b and t. The gg, \u03b3\u03b3 and Z\u03b3 channels occurring at the one loop level are\nalso included. Anti-matter production yields from dark matter annihilation in the Galactic\nhalo are determined by DarkSUSY. Modelling the propagation of anti-matter is non-trivial,\nbut DarkSUSY attempts this through various approximations which can be found in the\nmanual. High energy neutrinos and neutrino-induced muons can be detected by neutrino\ntelescopes and their yields are calculated. The SLHA is currently not supported, but\ninstead dedicated interfaces to ISAJET and SUSPECT are included for spectrum generation.\nThere is a web interface linked from the DarkSUSY homepage for inputting a MSSM model\nand calculating the relic density and detection cross-sections. Thus, if one is doing an\nanalysis on one point in parameter space, one can check its dark matter properties easily\non-line.\nIsaRED is part of the ISAJET [9] package, and calculates the relic density of neutralino\ndark matter in the MSSM. Annihilations between \u03c701 , \u03c702 , \u03c7\u00b1\n1 , \u1ebd1 , \u03bc\u03031 , \u03c4\u03031 , \u03bd\u0303e , \u03bd\u0303\u03bc , \u03bd\u0303\u03c4 , \u01691 , c\u03031 ,\n \u0303\nt\u03031 , d1 , s\u03031 , b\u03031 and gluinos are taken into account in the calculation. In the same package,\nIsaRES evaluates spin-independent and spin-dependent direct detection rates. Squark, Z 0\nand Higgs exchanges are included at tree-level and neutralino-gluon interactions involving\nquarks, squarks and Higgs bosons are included at the one-loop level.\nmicrOMEGAs (C) [49] calculates the relic density of the LSP at tree-level and direct/indirect\ndetection rates in the vanilla MSSM, the MSSM with complex phases and the NMSSM.\n\n\u2013 12 \u2013\n\n\fImportant higher-order QCD and SUSY QCD corrections to Higgs quark vertices are included. The program can be used to calculate the relic density of a charged and/or coloured\nnext-to-lightest supersymmetric particle. This can be useful in the case of a gravitino LSP.\nGravitinos are not simulated by micrOMEGAs, but a simple formula can be used to extract\ntheir relic density from the relic density of the next-to-lightest supersymmetric particle. The\nmost important annihilation channels for any given model point can be output. micrOMEGAs\nuses CalcHEP [29] in order to calculate any necessary Feynman diagrams, and so extensions\ncan be encoded using the LanHEP [31] Lagrangian formulation, for models where there is\nonly one stable particle. Only diagrams that may contribute up to some specified fraction\n(by default, 10\u22125 ) of the thermally averaged total annihilation cross-section are included,\nwhich makes for faster computation. LSP scattering rates on nucleons and nuclei in the\nspin-independent and spin-dependent interaction cases are also presented. \u03b3, e+ , p\u0304 and \u03bd\nyields for indirect direction purposes (at v \u2192 0 and/or in the continuum) are calculated.\nLike DarkSUSY, micrOMEGAs uses the basic channels q q\u0304, \u03bc+ \u03bc\u2212 , \u03c4 + \u03c4 \u2212 , W + W \u2212 and Z 0 Z 0\nand interpolates tables of \u03b3, e+ , p\u0304 and \u03bd production as obtained by PYTHIA. For channels\nthat contain two different particle species AB, the final spectrum is obtained by taking the\naverage of di-A production and di-B production as a rough approximation. The galactic\ngamma-ray flux is calculated with a modified isothermal distribution of dark matter in\nthe galaxy. For direct detection rates, higher order corrections to Higgs-quark vertices and\none-loop neutralino-gluon interactions are included for the vanilla MSSM, the CP-violating\nMSSM and the NMSSM.\n\n6. Predictions for constraints\nThere are many constraints upon supersymmetric models: direct constraints tend to be the\neasiest to implement, being (usually) phrased as lower bounds on sparticle masses. Relevant indirect constraints are upon branching ratios for rare decays, precision electroweak\nobservables or electric dipole moments for example, and often occur at the loop level. Being of general utility, FormCalc [27] can be used to calculate the relevant SUSY matrix\nelements.\n6.1 b observables\nThe branching ratio of b \u2192 s\u03b3 has long been used to constrain supersymmetric models, and\nis calculated by several codes. Many of the codes calculate it in the vanilla MSSM without\nSUSY flavour mixing. For minimal flavour violating MSSM computations, SusyBSG [50]\ncalculates the branching ratio for the decay b \u2192 s\u03b3 taking into account all of the available next-to-leading order (NLO) contributions, including the complete supersymmetric\ntwo-loop QCD corrections to the Wilson coefficients of the magnetic and chromo-magnetic\noperators, as well as an improved NLO determination of the relation between the Wilson coefficients and the branching ratio. micrOMEGAs [49], predicts the branching ratio\nincluding next-to-leading order contributions for the Standard Model. The charged Higgs\nand supersymmetric large tan \u03b2 effects beyond leading-order are included. DarkSUSY [48]\nperforms a NLO calculation which is complete for the Standard Model prediction and\n\n\u2013 13 \u2013\n\n\fadds some dominant NLO MSSM corrections. SPheno [12] and SUSPECT [13] include oneloop MSSM corrections and some NLO corrections to the branching ratio. SuperIso [51]\ncalculates the b \u2192 s\u03b3 branching ratio in the vanilla MSSM with flavor violation, NLO\nsupersymmetric contributions and next-to-next-to-leading order (NNLO) Standard Model\ncontributions. Flavour violation is supported through the SLHA2 interface. SuperIso is\ncurrently the only code to predict the isospin symmetry breaking \u22060\u2212 of the B \u2192 K \u2217 \u03b3\ndecay including the NLO SUSY contributions. CPsuperH [23] can provide a prediction for\n0 \u2212 B\u0304 0\nthe branching ratio as well as as its CP-asymmetry and SUSY contributions to Bs,d\ns,d\nmass differences (\u2206Ms,d ). FeynHiggs [22] provides a prediction for the b \u2192 s\u03b3 branching ratio including non-minimal flavour violating effects. Another b\u2212physics observable\nthat can constrain SUSY is the to-date unobserved rare decay mode Bs \u2192 \u03bc+ \u03bc\u2212 . The\nSUSY calculation in micrOMEGAS [49] includes the one-loop contributions due to chargino,\nsneutrino, stop and Higgs exchange. mb re-summation effects at high tan \u03b2 are taken into\naccount. CPsuperH [23] also performs the calculation of BR(Bs \u2192 \u03bc+ \u03bc\u2212 ) in the CP violating MSSM, as well as Bd \u2192 \u03c4 + \u03c4 \u2212 , Bu \u2192 \u03c4 + \u03bd\u03c4 . Each branching ratios is calculated in\nthe single-Higgs insertion approximation. NMSSMtools [26] calculates b \u2192 s\u03b3, Bs \u2192 \u03bc+ \u03bc\u2212 ,\nand B + \u2192 \u03c4 + \u03bd\u03c4 branching ratios as well as \u2206Ms,d in the NMSSM at one-loop order.\nISATOOLS [9] includes NLO contributions to some of the Standard Model Wilson coefficients for BR(b \u2192 s\u03b3) and one-loop MSSM corrections. Branching ratios for Bs \u2192 \u03bc+ \u03bc\u2212\nand Bd \u2192 \u03c4 + \u03c4 \u2212 are calculated to one-loop, using approximations for the chargino masses\n(neglecting their mixing). The fitting program SuperBayes [52] uses the micrOMEGAs prediction of BR(b \u2192 s\u03b3) at NLO and then augments it by NNLO Standard Model QCD\ncontributions.\n6.2 Anomalous magnetic moment of the muon\nThe anomalous magnetic moment of the muon is currently around 3\u03c3 higher than the Standard Model prediction. There is thus room for a non-zero SUSY contribution. ISATOOLS [9],\nSPheno [12], SuperIso [51], micrOMEGAS [49] and DarkSUSY [48] calculate the predicted\nSUSY contribution to one-loop order, whereas FEYNHIGGS [22] and SUSPECT [13] also include some two-loop corrections.\n6.3 Electric dipole moments\nFor calculations of electric dipole moments in the CP-violating MSSM, micrOMEGAS [49]\ncan provide estimates for the electron and Thalluim. One-loop neutralino/chargino contributions and two-loop squark, quark and chargino contributions are included as well as\nfour-fermion operators for Thallium. Two-loop Higgs-mediated contributions to electron,\nmuon and Thallium electric dipole moments are calculated in CPsuperH [23]. However, currently some well-known one-loop contributions have yet to be implemented. The Thallium,\nneutron and mercury electric dipole moments are calculated in FEYNHIGGS [22].\n6.4 Electroweak observables\nmicrOMEGAs [49] and SUSPECT [13] can output the \u2206\u03c1 parameter, which describes some\nloop corrections to electroweak observables. They both contain one-loop stop/sbottom\n\n\u2013 14 \u2013\n\n\fcontributions, as well as two-loop QCD corrections due to gluon exchange and the heavygluino limit of gluino exchange. FeynHiggs [22] also contains a calculation of \u2206\u03c1, with\ncorrections up to two-loops. SPheno [12] outputs the one-loop sfermion contributions to\n\u2206\u03c1. In terms of the electroweak observables themselves, FeynHiggs also computes MW\nef f\nand sin2 \u03b8w\nincluding some two-loop SUSY contributions, non-minimal flavour violating\neffects and the effect of complex phases in the stop/sbottom sector at one-loop.\n\n7. Fitting tools\nWe first introduce some necessary statistical terms, then go on to discuss their use in the\ncontext of SUSY fits. Typically, global fits of models to data utilise a statistical \"figure\nof merit\" for each point in parameter space to characterise how well it fits data. The\nmost familiar one for particle physicists is probably \u03c72 , but sometimes likelihood is used\n2\ninstead. Likelihood L can be simply related to the \u03c72 parameter, L \u221d e\u2212\u03c7 /2 . L or \u03c72 are\noften quoted in frequentist statistical interpretations of data. Bayesian statistics turn these\nquantities into probability distributions on the input parameters of the model, requiring\nthe introduction of the infamous prior probability distribution. The probability distribution of some parameter after confrontation with data is called the posterior probability\ndistribution. A global fit of some model to data often consists of finding the variation of\nthe figure of merit with the model parameters. The best-fit set of model parameters is\nsometimes quoted, with the amount of parameter space contained within some expected\namount of statistical variation of data. More complete analyses map out the figure of merit\non the parameter space, and Bayesian analyses then make probabilistic inferences based\nupon the map.\n7.1 Algorithms for multi-dimensional fits\nEven if one restricts the MSSM to some lower number-of-parameters form such as mSUGRA,\nthe parameter space is still of considerable dimensionality: 4 for a given sign of \u03bc (m0 , M1/2 , A0\nand tan \u03b2). Also, if one wants to perform global fits of the model to data, one should include variations of the relevant Standard Model input parameters. mt is proportional to\nthe largest parameter in the model, the top Yukawa coupling, and for high tan \u03b2 the bottom Yukawa coupling, proportional to the bottom quark mass, can change the predicted\nvalues of observables. Variations of \u03b1s within its empirical uncertainties can also have a\nlarge effect on squark and gluino masses through the RGE evolution, since it is the largest\ngauge coupling. If one is including precision electroweak observables in the fit, including\nuncertainties on the fine structure constant \u03b1 becomes essential. Thus, in mSUGRA one\nhas an eight-dimensional relevant parameter space. Scans in such a space are impractical,\nsince the required number of points is exponential in the number of parameters. If one\nrequired a resolution of 25 points for each parameter, 1.5\u00d71011 points would be required\nin total. To make matters worse, there are often sharp features in the \u03c72 distribution that\nwould render such a low resolution insufficient. Such a large number of points cannot be\ncalculated in a reasonable amount of CPU time, even given recent advances in computer\ntechnology. If one has access to a computer farm, calculating a few million points is feasible\n\n\u2013 15 \u2013\n\n\fwithin a few days, for example (unless one wants to simulate event generation, which would\ntake much longer). There is therefore a need for more sophisticated scanning algorithms\nthat can reduce the required number of scanned points for parameter spaces of more than\nthree dimensions.\nThe software tool MINUIT [53] is a well-tried function minimiser. It calculates derivatives of the figure of merit with respect to input parameters and performs hill-climbing\nalgorithms to try to find the best-fit point. It then determines the error matrix from a\nmatrix of second derivatives of \u03c72 . This error matrix contains information about the 1\u03c3\nstandard deviations of the parameters in the Gaussian approximation (where a\u03c72 is assumed to be parabolic around the best-fit point) and including correlations. For cases\nwhere the Gaussian approximation is a bad approximation, another internal MINUIT algorithm can be used for determining errors including non-linearities, but can be very time\nconsuming depending upon the amount of non-linearity. Algorithms that use derivatives\ncan be problematic when the surface that they are minimising are rough. In the SUSY\nfitting case, the original SUSY spectrum is obtained by an iterative process up to some\nnumerical accuracy, which then feeds into the rest of the figure of merit calculation, providing small discontinuities in the surface. A typical numerical fractional accuracy in this\nstage of the calculation might be 10\u22123 . While a fractional accuracy of 10\u22125 is feasible, it\nrequires much more CPU time per scanned point, and is actually unattainable in certain\n\"difficult\" regions of parameter space such as the focus-point region. MINUIT also finds\nparameter degeneracies problematic, where the figure of merit does not change much along\nsome curve in parameter space. Despite these short-comings, MINUIT has been used to\nperform global fits of mSUGRA to global data successfully [54].\nMCMC methods are commonly used in cosmological [55, 56] and other contexts, and\nrecently there has been a realisation that they are very useful to the SUSY high-dimensional\nscanning problem. MCMCs scan more often where the fit is good and the figure of merit\nis high and less often in the tails of distributions. In fact, the density of scanning is\nproportional to the figure of merit. MCMC methods have a high CPU overhead, meaning\nthat they are not the most efficient tool for one or two dimensional problems. But the\nrequired number of points goes roughly linearly with the number of dimensions rather\nthan exponentially, and so they are very useful for our higher-dimensional mSUGRA fitting\nproblem. In this context, a Markov chain consists of a long list, or \"chain\" of points and\ntheir associated likelihoods. Statistical inference can be made by binning these points in\nterms of some quantity of interest. The simplest implementation of MCMC is called the\nMetropolis algorithm [57]. In the Metropolis algorithm, for the first point in the chain, a\npoint x0 is picked at random in parameter space and its posterior density calculated, p0 . A\npotential next point x1 is picked in the vicinity of the previous point, again at random. If\np1 > p0 , the new point is accepted. Otherwise, the new point is accepted with probability\np1 /p0 . If the new point is not accepted, the previous point is added again on to the chain.\nThis algorithm is repeated many times, until it has explored all of the relevant parameter\nspace. There are many choices of how to pick a potential next point \"in the vicinity\" of the\ncurrent one, and some trial and error is usually involved in setting the length scales involved.\nUsually, a Gaussian function is used to randomly choose the distance of the new point away\n\n\u2013 16 \u2013\n\n\ffrom the current one, but formally, any well behaved function would work in the limit of\nan infinite number of MCMC steps provided it has no true zeroes. For efficient scanning,\nthe length scale should be of order the length scale of the likelihood variation. If it is much\nlarger, hardly any new points will be accepted and the efficiency will be too low. If it is\nmuch smaller, many new points will be required to explore all of the good-fit parameter\nspace. In order to verify that the algorithm has indeed explored the parameter space\nproperly, it is good practice to run several statistically independent chains concurrently.\nOne can then compare the results in the different chains statistically to see how similar they\nare [58]. The Metropolis algorithm does not rely on derivatives and is therefore immune\nto serious problems caused by roughness from numerical error. It can easily be used to\ninterpret data in a Bayesian form or in a frequentist form. For the Bayesian inference, one\nplots the quantities in question (say, squark mass vs gluino mass) in bins. The marginal\nposterior probability distribution in terms of these parameters is then proportional to the\nnumber of points in the chain that land in each bin. Marginal refers to the fact that all\nother parameters have been integrated over. In order to interpret the chain in a frequentist\nfashion, one plots the profile likelihood: the likelihood of the maximum likelihood point\nthat lands in each bin [59]. Such a procedure, provided a sufficient number of samples to\nget near the maximum for each bin has been obtained, is equivalent to minimising \u03c72 in\neach bin. Confidence limits can be found in the parameter plane in question by plotting\niso-\u2206\u03c72 contours, where \u2206\u03c72 is \u03c72 assigned to each bin minus the \u03c72 of the minimum bin.\nMCMC methods thus provide full maps of the figure of merit across parameter space or\nother scalar quantities that one is interested in. A package SuperBayeS [52] (fortran77,\nfortran90 and C++) is available for performing global fits to SUSY models using MCMC\nand SOFTSUSY [11], DarkSUSY [48] and FEYNHIGGS [22]. The MCMC routines were adapted\nfrom cosmomc [56], as well as some of the plotting routines. The program SFITTER [60] is\ncurrently being developed which will fit SUSY models to collider data on sparticle masses\nusing MCMC methods.\nA problem that is not addressed by either MINUIT or by the Metropolis algorithm\nis that of well-separated \u03c72 minima. MINUIT only finds a local minima. In principle,\nthe Metropolis algorithm may find all local \u03c72 minima in the limit of infinite number of\nsamples. In practice however, if the local minima are small and require small length scales\nfor suggesting proposed points, and the distance in parameter space between them is large,\nthe chance to \"hop\" from one local minimum to the other may be tiny and require an\nunfeasibly large number of samples. A \"tweak\" to the Metropolis algorithm exists which\ncan solve this problem and is called bank sampling [61]. In bank sampling, one performs\na two-step process. In the first step, many different Metropolis chains are started and run\nfor a small number of steps, but numerous enough to find points somewhere near local\nlikelihood maxima. These points then form the \"bank\" or \"cache\" of points used in a new\nmodified Metropolis algorithm. On each MCMC step, there is a small probability that\nthe chain will propose a point in the vicinity of one of the bank points. If the new point\nis added successfully to the chain, the chain \"teleports\" to the other local maxima. In\nthis way, the relevant local maxima all appear in the fit results, correctly normalised with\nrespect to each other.\n\n\u2013 17 \u2013\n\n\fIf only the global likelihood maximum, or equivalently, the global \u03c72 minimum, is\ndesired, a different modified Metropolis algorithm called simulated annealing can be used.\nSimulated annealed can be used to find a point near a global \u03c72 minimum when several\nlocal ones exist. In simulated annealing, it is imagined that the \u03c72 surface is some potential\nenergy surface upon which a particle moves. A finite temperature is set, which increases\nthe length scale of the proposal step (or, in the analogy, the average distance the particle\nmoves). The temperature is very large at the start of the algorithm and gradually decreases\nto one thereafter. The chance of acceptance of a worse-fit point is also fixed to be higher\n2\nwith increased temperature T , being set to e\u2212\u2206\u03c7 /T , where \u2206\u03c72 is the \u03c72 difference between\nthe current point and the proposed worst-fit one. In the early stages, the algorithm is more\nlikely to traverse bad-fit regions and not be trapped in local minima. The computer code\nFITTINO [62] can fit a 24-parameter simplified weak-scale MSSM to assumed cross-section\nand mass from SUSY signal collider data. Tree-level values of observables and subsets of\nSUSY parameters are used to obtain start values for the \u03c72 -fit. Simulated annealing is then\nperformed in order to find a better approximation to the global \u03c72 minimum. Using these\nparameter values, MINUIT is performed in order to minimise \u03c72 more precisely. In order to\ninvestigate the uncertainties in the fit, a series of fits for many imagined experimental data\nare performed in FITTINO, with data smeared around their nominal values, and the global\n\u03c72 minimum is found in each case.\nIn frequentist statistics, hypothesis testing often reduces to finding the minimum \u03c72\nof different models. However, in Bayesian statistics, one wishes to calculate the evidence\nratio: the ratio of volumes under the posterior probability surfaces, a quantity that can\nbe very computationally intensive to calculate. Bank sampling provides a method for the\nrough computation of the evidence ratio, by having bank points within each of the separate\nmodels. After the MCMC has run, the ratio of points in each model is an estimate of the\nevidence ratio. Such an estimate may not be very accurate, particularly where the evidence\nratio is much larger or smaller than one. In such cases, one can artificially multiply one of\nthe model's likelihoods by a factor which will bring the resulting evidence ratio closer to\none. The normalisation can be un-done, with the result that the ratio can be computed\nwith smaller statistical uncertainty from the likelihood re-scaling. The disadvantage of\nbank sampling for Bayesian evidence evaluation is that only ratios of the evidence can be\ndetermined, not the evidence value on its own.\nAn algorithm which solves this problem as well as the well-separated likelihood maxima\nproblem in a completely different way is the 'MultiNest' technique [63]. MultiNest models\nthe multi-dimensional likelihood surface with a series of (possibly overlapping) ellipsoids.\nClustering algorithms are contained within the larger algorithm. They determine when an\nellipsoid is to be broken up into two different ellipsoids because the initial one does not\nmodel the underlying distribution well enough. Many live points are chosen, sampled from\nthe prior probability distribution. Current live points are described in terms of ellipsoids,\ndetermined by the covariance matrix of the live points, enlarged by about 20% to take nonlinearities into account. The live point with the smallest likelihood is replaced with one with\na higher likelihood re-sampled from the ellipsoids. Thus, the live points gradually home\nin on the likelihood maxima as the algorithm proceeds and the evidence can be calculated\n\n\u2013 18 \u2013\n\n\ffrom the list of live points and their evidences, as can posterior probability inferences. The\nevidence of a single model can be accurately calculated in this approach, in contrast to the\ncase of bank sampling. Thus, as one builds up a list of different models that one is testing\nagainst some set of data, there is no need to run many different comparisons between the\ndifferent pairs of models: a single computation for each model suffices. The nested approach\ndoes need to be able to sample efficiently from the prior probability distribution and so will\nnot work efficiently in cases where there is no analytic form for the prior. For extremely\nhigh dimensional cases (say, 10 and above), a MCMC-hybrid nested sampling approach\nmay be more efficient than the ellipsoidal approach [63] for multi-modal distributions.\n7.2 Example Global Fits to mSUGRA\nWe now display some example results using the various techniques introduced in section 7.1.\nWe pick examples of global fits to mSUGRA in the literature as an example. Typically, the\ndata that authors have chosen to fit to include the relic density of dark matter to the relic\nef f\ndensity of neutralinos, MW , sin2 \u03b8w\n, BR(b \u2192 s\u03b3), BR(Bs \u2192 \u03bc+ \u03bc\u2212 ), (g \u22122)\u03bc mt , mb (mb ),\n\u03b1s (MZ ), \u03b1(MZ ) and direct exclusion limits from colliders. Fig. 4a shows the posterior\nprobability distribution in terms of the m0 \u2212 M1/2 plane for both signs of \u03bc with flat priors\nin m0 , M1/2 , tan \u03b2 and A0 after an MCMC fit using bank sampling [59]. The probability\nrelative to the one in the maximum-posterior bin is shown by the colour, and measured by\nthe bar on the right. The most probable region at low values of m0 and M1/2 corresponds\nto the stau co-annihilation region, where the lightest stau and lightest neutralino are quasimass degenerate. The extended probability mass at m0 , M1/2 \u223c 0.5 TeV corresponds to\nthe A0 boson resonance at high values of tan \u03b2, where dark matter annihilation proceeds\nefficiently through \u03c701 \u03c701 \u2192 A0 \u2192 bb\u0304. At larger values of m0 , we have the focus point\nregion, where efficient annihilation into weak gauge boson pairs is possible. In Fig. 4b, the\nsame data is interpreted in a frequentist fashion using the profile likelihood technique. This\ntechnique picks out the best-fit points, rather than averaging over all points in the unseen\ndimensions. Figs. 4a, b differ where there are significant volume effects, that is where the\nvolume of points in the unseen dimensions enhances or diminishes the Bayesian fit. The\nfact that the frequentist interpretation differs from the Bayesian one can be seen as a signal\nthat more data is required for the fit; indeed we should not be surprised since a complex\nmodel with eight free parameters has been fit with some fairly indirect data. Similar fits to\nthe Bayesian ones above were performed using the Metropolis MCMC algorithm, resulting\nin quite similar posterior probability densities for the particle physics properties, despite\nsome differences in the indirect constraints used [64]. In addition, ref. [64] constrains dark\nmatter detection cross-sections. We show the posterior probability distribution function of\nthe spin-independent direct dark matter detection cross-section in Fig. 4c for flat priors in\nm0 , M1/2 , tan \u03b2 and A0 , for \u03bc > 0. The most constraining direct detection experiment,\nXENON-10, can be seen to cover some of the favoured region already, assuming that the\nflux of dark matter passing through XENON-10 is the same as the galactic average. In\nFig. 4d, we see the results of a more traditional frequentist \u03c72 mSUGRA fit using MINUIT\nin terms of the lightest CP-even Higgs mass of the MSSM [54]. For each value of the\nlightest Higgs mass, a \u03c72 minimisation was performed against all of the other mSUGRA\n\n\u2013 19 \u2013\n\n\fP/P(max)\n\n4\n\n(a)\n\n1 (b)\n\n3.5\n\n3.5\n0.8\n\n2.5\n0.6\n\n2\n1.5\n\n0.4\n\n1\n0.5\n\n3\nm0 (TeV)\n\nm0 (TeV)\n\n3\n\n2.5\n2\n1.5\n1\n0.5\n\n0.2\n\n0\n\n0\n0\n\n0.5\n1\n1.5\nM1/2 (TeV)\n\n2\n\n0\n\n0\n\n0.5\n1\n1.5\nM1/2 (TeV)\n\n2\n\n1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\n\n(d)\nRoszkowski, Ruiz & Trotta (2007)\n\nCMSSM, \u03bc > 0\n\n3.5\n\n\u22125\n\np\n\n\u22128\n\u22129\n\u221210\n0.2\n\n0.4\n\n0.6\n\nm\u03c7 (TeV)\n\n0.8\n\n0.8\n\n2.5\n0.6\n\nXENON\u221210\n\n\u22127\n\n3\n\n2\n1.5\n\n0.4\n\nEDELWEISS\u2212I\nCDMS\u2212II\n\n1\n0.2\n\nRelative probability density\n\nZEPLIN\u2212I\n\n\u22126\n\n\u221211\n\n4\n\n0.5\n\n1\n\n0\n\nTheoretically\ninaccessible\n\nLEP\nexcluded\n\n90\n\n100\n\n110\n\n120\n\n130\n\n140\n\n0\n\n\u22124\n\n1\n\n(c)\n\nLog[\u03c3SI (pb)]\n\n(L/Lmax)\n\n4\n\nFigure 4: Global mSUGRA fits in the m0 \u2212 M1/2 plane: (a) shows the Bayesian posterior probability distribution [59], (b) shows the frequentist interpretation in the same plane [59], (c) displays\nthe direct spin independent detection cross section posterior probability distribution function versus mass of the lightest neutralino for \u03bc > 0 along with some 95% C.L. exclusion contours from\ndirect detection experiments [64]. Inner and outer contours show the 68% and 95% confidence level\nregions respectively. (d) shows the \u2206\u03c72 of the lightest CP-even Higgs mass from all constraints\nexcept for the direct LEP2 Higgs mass constraint [54].\n\nparameters. Many additional electroweak and b observables were included in the \u03c72 of this\nfit, although for comparative purposes the LEP2 direct bound on the Higgs mass was left\nout. This bound is plotted as the yellow excluded region in Fig. 4d. It can be seen that\nthe global \u03c72 minimum occurs at mh \u2248110 GeV, below the direct 95% C.L. lower bound of\n114.4 GeV. The authors of Ref. [54] use the \u03c72 curve to infer that mh = 110+8\n\u221210 \u00b1 3 GeV,\nwhere the first uncertainty is statistical and the second uncertainty is theoretical.\n7.3 Data archival\nThe samples from MCMC fits take some effort and CPU time to obtain. In principle, the\n\n\u2013 20 \u2013\n\n\fmSUGRA fits could be useful to other physicists, who wish to make their own inferences\nabout observables. If a new calculation of SUSY contributions to some observable were\nto come on-line, statistical inference could be made by simply obtaining some independent samples from the MCMC chains and calculating the new observable for each. A few\nthousand points might suffice in terms of statistics. Then, the totality of current empirical\nknowledge about SUSY corrections to the observable is obtained without a need for complicated multi-dimensional fitting procedures. Aside from that, other physicists might be\ninterested in using the chains for their own scans over the points in parameter space that\nare compatible with current data. For this reason, the authors of Ref. [59] have formed the\nKISMET web-site, which contains links to text files of the chain data. The weight of each\npoint (the number of times it was visited in the MCMC procedure), along with the values\nof input parameters, resulting indirect observables, sparticle masses and the likelihood, are\nlisted in the files. Also, 10 000 independent samplings from the chains in SLHA format are\navailable from the web-site.\nThe SuperBayeS [52] data are now available to some extent on-line: one can fill out\na web-form in order to automatically receive plots of the posterior probability density in\ndimensions specified by the user [65]. These dimensions can be specified to be observables,\ninput parameters or sparticle masses.\n\n8. Summary\nCurrently, little is empirically known about supersymmetry except for a few indirect data.\nThis tends to lead to under-constrained SUSY models and consequent degeneracies in\nglobal fits. However, if the LHC provides some signals that are compatible with SUSY,\naside from being an extremely exciting discovery beyond the Standard Model, hypothesis\ntests against alternative models and even between different classes of SUSY models will be\ndesirable. Ideally, constraints upon the SUSY Lagrangian would be derived with the help\nof high energy e+ e\u2212 linear collider experiments. A well defined theoretical framework is\nneeded when higher order corrections are included in trying to reconstruct a fundamental\nSUSY theory and its breaking mechanism. For this purpose, the Supersymmetry Parameter\nAnalysis (SPA) [66] scheme provides a consistent set of conventions and input parameters,\nas well as a repository for programs which connect parameters in different schemes and\nrelate the Lagrangian parameters to quantities that may be more directly extracted from\nphysical observables such as masses, mixings, decay widths and production cross sections\nfor supersymmetric particles.\nThere is a somewhat bewildering proliferation of computer program tools for SUSY\ncalculations and phenomenology in the literature. This proliferation is a useful development, and reflects the interest of the high energy physics community in supersymmetry.\nEven more useful is the collusion, collaboration and organisation between the different\nprograms, to allow results from one to be fed into another program and interpreted automatically. The SUSY Les Houches Accord is a good example of such practice, and it has\nnow become essential for any relevant computer tool to use it so that it can communicate\nwith the other tools. The most popular computer languages that the tools are written in\n\n\u2013 21 \u2013\n\n\fare still various versions of fortran and C++. Following the move of most new high energy\nphysics experiments to C++, there is a tendency for new event generators to be written in\nC++ rather than fortran. In fact the precise language a SUSY tool is written in is becoming less important with the advent of the communication accords, which are in ASCII\nformat. Many of the more sophisticated matrix element or event generators use their own\nencoding of a Lagrangian to enable the user to define new models. This approach is of\nobvious use and generality, but packages have many different definitions of the Lagrangian.\nPerhaps there is a need for yet another accord, so that the same model can easily be fed\nin to different tools without the need for the user to translate the Lagrangian between the\nvarious different conventions.\nFinally, we end with a brief summary of the phenomenological SUSY tools that are\ncovered in this review. Since some programs have several different functions, we summarise\nthem all together in Table 2, although the programs are loosely grouped according to their\nfunctionality. L indicates that the tool includes or uses a method of encoding a Lagrangian\nin order to define extended or new models. In the table, 'Spectrum' indicates that the\ntool includes an SUSY spectrum calculator, \u03bdR indicates that RGEs include an option\nfor including right-handed neutrinos (and therefore neutrino mass models), RPV indicates\nthat the tool can handle R\u2212parity violation, NMSSM that it can calculate in the Nextto-Minimal Supersymmetric Standard Model, CPV that the tool can take into account\ncomplex phases in the SUSY sector and FV that the tool includes some non-minimal flavour\nviolating effects. 'Decays' indicates that the tool automatically calculates the branching\nratios of SUSY or SUSY Higgs decays in the MSSM or extensions. Tools which have a\npositive entry under 'Decay spin' include angular correlation effects from sparticle spins\nwhen simulating decays down cascade decay chains. 'ME' indicates a matrix element\ngenerator: the code can simulate scattering for 2\u2192 N hard particles, where N > 2. 'Initial\npol' shows that polarisations of the colliding particles can be taken into account: usually in\ne+ e\u2212 collisions, but sometimes also in \u03b3\u03b3 or e\u03b3 collisions. A tick under the \u03c3SU SY heading\nmeans that the code has an easy user interface for calculating total or differential crosssections for the production of (sometimes specified) sparticles and/or SUSY Higgs. e+ e\u2212\nand pp indicates that the initial colliding particles can be leptonic or hadronic, respectively.\n'Events' mean that individual events are simulated, PS/Had that the program can perform\nparton showering and/or hadronisation of partons. A tick under the \u03a9DM h2 header means\np\nthat the relic density of dark matter can be calculated, \u03c3SI,SD\nthat an estimate of dark\nmatter direct detection is included and 'Ind. DM' that some indirect dark matter detection\nfluxes are provided. For b-observables, b \u2192 s\u03b3, B \u2192 \u03c4 \u03bd, \u03c4 \u03c4 and Bs \u2192 \u03bc+ \u03bc\u2212 indicates that\nthere is a calculation of the relevant branching ratio including some SUSY effects. A\npositive entry for \u22060\u2212 means that the program calculates the isospin asymmetry in B\n0 \u2212 B\u0304 0 mixing\ndecays, whereas an entry under \u2206MBs that the SUSY contributions to Bs,d\ns,d\nare calculated. A (g \u2212 2)\u03bc entry indicates that a SUSY contribution to the anomalous\nmagnetic moment of the muon can be easily extracted from the tool, whereas EW means\nthat some electroweak observables are provided: usually \u2206\u03c1 and MW . A tick under edm\nmeans that electric dipole moments can be calculated, whereas 'Fits' indicates a fitting tool\nthat can fit either collider observables and/or indirect constraints such as EW observables\n\n\u2013 22 \u2013\n\n\fand dark matter relic densities. An entry under 'Web form' gives the reference including a\nlink to a web-form where results from the program can be automatically obtained by filling\nin a form on the world-wide web. Finally the 'code' column indicates that the package\ncan output computer code, which can then be compiled into a numerical program in order\nto evaluate observables. Prospective users are warned that multi-functionality does not\nnecessarily mean a more accurate calculation and indeed in some cases, the converse will\napply. It is hoped that Table 2 will help point prospective new users towards the SUSY\ntool(s) that they require.\n\nAcknowledgments\nThis review has been partially supported by the STFC. A much shortened form was originally conceived for a talk in the SUSY 07 conference. It borrows heavily from the manuals\nand web-pages of the tools discussed, the BSM tools repository [8] and the SUSY Les\nHouches Accord web-pages [1]. We thank G B\u00e9langer, F Boudjema, T Hahn, S Heinemeyer, J S Lee, N Mahmoudi, F Maltoni, T Plehn, W Porod, P Richardson, S Schumann,\nP Slavich and B Webber for corrections and suggestions on the draft.\n\nReferences\n[1] P. Skands, B.C. Allanach et al, The SUSY Les Houches Accord: Interfacing SUSY Spectrum\nCalculators, Decay Packages and Event Generators, JHEP 0407 (2004) 036,\n[arXiv:hep-ph/0311123].\nhttp://home.fnal.gov/ \u0303skands/slha/\n[2] T. Hahn, SUSY Les Houches Accord I/O made easy, arXiv:hep-ph/0408283; T. Hahn, SUSY\nLes Houches Accord 2 I/O made easy, arXiv:hep-ph/0605049.\nhttp://www.feynarts.de/slha/\n[3] B.C. Allanach et al, Susy Les Houches Accord 2, [arXiv:0801.0045]; ibid, The SUSY Les\nHouches Accord Conventions, in Physics Beyond the Standard Model: Supersymmetry,\nproceedings of the 2007 Les Houches \"Physics at TeV Colliders\" Workshop, [arXiv:0802.3672].\nhttp://home.fnal.gov/ \u0303skands/slha/\n[4] E. Boos et al, Generic user process interface for event generators, in Proceedings of the\nWorkshop on Physics at TeV Colliders II Workshop, [arXiv:0109068].\n[5] J. Alwall et al., A standard format for Les Houches event files, Comput. Phys. Commun. 176\n(2007) 300 [arXiv:hep-ph/0609017].\n[6] J. Alwall et al., A Les Houches Interface for BSM Generators, arXiv:0712.3311 [hep-ph].\n[7] P. Z. Skands, A quick guide to SUSY tools, arXiv:hep-ph/0601103.\n[8] P. Z. Skands et al., A repository for beyond-the-standard-model tools, in BSM Working Group\nsummary report of Les Houches at TeV Colliders 2005, arXiv:hep-ph/0602198.\nhttp://www.ippp.dur.ac.uk/montecarlo/BSM/\n[9] F. E. Paige, S. D. Protopopescu, H. Baer and X. Tata, ISAJET 7.69: A Monte Carlo event\ngenerator for p p, anti-p p, and e+ e- reactions, arXiv:hep-ph/0312045.\nhttp://www.hep.fsu.edu/ \u0303isajet/\n\n\u2013 23 \u2013\n\n\f[10] C. Balazs, see ISALHA.F, ISALHD.F and LHAISA.F links on the SLHA page\nhttp://home.fnal.gov/ \u0303skands/slha/.\n[11] B.C. Allanach, SOFTSUSY: A program for calculating supersymmetric spectra, Comput.\nPhys. Commun. 143 (2002) 305, [arXiv:hep-ph/0104145].\nhttp://projects.hepforge.org/softsusy/.\n[12] W. Porod, SPheno, a program for calculating supersymmetric spectra, SUSY particle decays\nand SUSY particle production at e+ e- colliders, Comput. Phys. Commun. 153 (2003) 275\n[arXiv:hep-ph/0301101].\nhttp://ific.uv.es/ \u0303porod/SPheno.html\n[13] A. Djouadi, J. L. Kneur and G. Moultaka, SuSpect: A Fortran code for the supersymmetric\nand Higgs particle spectrum in the MSSM, Comput. Phys. Commun. 176 (2007) 426\n[arXiv:hep-ph/0211331].\nhttp://www.lpta.univ-montp2.fr/users/kneur/Suspect/\n[14] S. Kraml, Comparison of SUSY spectrum generators: mass spectra, relic densities, etc,\nhttp://kraml.home.cern.ch/kraml/comparison/compare.html\n[15] B.C. Allanach, S. Kraml and W. Porod, Theoretical uncertainties in sparticle mass\npredictions from computational tools, JHEP 03 (2003) 016, hep-ph/0302102; B. C. Allanach,\nA. Djouadi, J. L. Kneur, W. Porod and P. Slavich, Precise determination of the neutral Higgs\nboson masses in the MSSM, JHEP 0409 (2004) 044 [arXiv:hep-ph/0406166]. G. Belanger,\nS. Kraml and A. Pukhov, Comparison of SUSY spectrum calculations and impact on the relic\ndensity constraints from WMAP, Phys. Rev. D 72 (2005) 015003 [arXiv:hep-ph/0502079].\n[16] M. Bahr et al., Herwig++ Physics and Manual, arXiv:0803.0883 [hep-ph].\nhttp://projects.hepforge.org/herwig/\n[17] J. Alwall et al., MadGraph/MadEvent v4: The New Web Generation, JHEP 0709 (2007) 028\n[arXiv:0706.2334 [hep-ph]]; G. C. Cho, K. Hagiwara, J. Kanzaki, T. Plehn, D. Rainwater and\nT. Stelzer, Weak boson fusion production of supersymmetric particles at the LHC, Phys. Rev.\nD 73 (2006) 054002 [arXiv:hep-ph/0601063].\nhttp://cp3wks05.fynu.ucl.ac.be/twiki/bin/view/Main/WebHome\n[18] T. Sjostrand, S. Mrenna and P. Skands, PYTHIA 6.4 physics and manual, JHEP 0605\n(2006) 026 [arXiv:hep-ph/0603175].\nhttp://home.thep.lu.se/ \u0303torbjorn/Pythia.html\n[19] M. Muhlleitner, A. Djouadi and Y. Mambrini, SDECAY: A Fortran code for the decays of the\nsupersymmetric particles in the MSSM, Comput. Phys. Commun. 168 (2005) 46\n[arXiv:hep-ph/0311167].\nhttp://lappweb.in2p3.fr/ \u0303muehlleitner/SDECAY/\n[20] P. Richardson, Spin correlations in Monte Carlo simulations, JHEP 0111 (2001) 029\n[arXiv:hep-ph/0110108].\n[21] P. Meade and M. Reece, BRIDGE: Branching ratio inquiry / decay generated events,\narXiv:hep-ph/0703031.\nhttp://www.lepp.cornell.edu/public/theory/BRIDGE/\n[22] S. Heinemeyer, W. Hollik and G. Weiglein, FeynHiggs: A program for the calculation of the\nmasses of the neutral CP-even Higgs bosons in the MSSM, Comput. Phys. Commun. 124\n(2000) 76 [arXiv:hep-ph/9812320]; S. Heinemeyer, W. Hollik and G. Weiglein, The masses of\n\n\u2013 24 \u2013\n\n\fthe neutral CP-even Higgs bosons in the MSSM: Accurate analysis at the two-loop level, Eur.\nPhys. J. C 9 (1999) 343 [arXiv:hep-ph/9812472]; G. Degrassi, S. Heinemeyer, W. Hollik,\nP. Slavich and G. Weiglein, Towards high-precision predictions for the MSSM Higgs sector,\nEur. Phys. J. C 28 (2003) 133 [arXiv:hep-ph/0212020]; M. Frank, T. Hahn, S. Heinemeyer,\nW. Hollik, H. Rzehak and G. Weiglein, The Higgs boson masses and mixings of the complex\nMSSM in the Feynman-diagrammatic approach, JHEP 0702 (2007) 047\n[arXiv:hep-ph/0611326].\nhttp://www.feynhiggs.de/\n[23] J. S. Lee, M. Carena, J. Ellis, A. Pilaftsis and C. E. M. Wagner, CPsuperH2.0: an Improved\nComputational Tool for Higgs Phenomenology in the MSSM with Explicit CP Violation,\narXiv:0712.2360 [hep-ph]; J. S. Lee, A. Pilaftsis, M. S. Carena, S. Y. Choi, M. Drees,\nJ. R. Ellis and C. E. M. Wagner, CPsuperH: A computational tool for Higgs phenomenology\nin the minimal supersymmetric standard model with explicit CP violation, Comput. Phys.\nCommun. 156 (2004) 283 [arXiv:hep-ph/0307377].\nhttp://www.hep.man.ac.uk/u/jslee/CPsuperH.html\n[24] A. Djouadi, J. Kalinowski and M. Spira, HDECAY: A program for Higgs boson decays in the\nstandard model and its supersymmetric extension, Comput. Phys. Commun. 108 (1998) 56\n[arXiv:hep-ph/9704448].\nhttp://people.web.psi.ch/spira/hdecay/\n[25] S. B\u00e9jar and J. Guasch.\nhttp://fchdecay.googlepages.com/\n[26] U. Ellwanger and C. Hugonie, NMSPEC: A Fortran code for the sparticle and Higgs masses\nin the NMSSM with GUT scale boundary conditions, Comput. Phys. Commun. 177 (2007)\n399 [arXiv:hep-ph/0612134]; U. Ellwanger, J. F. Gunion and C. Hugonie, NMHDECAY: A\nFortran code for the Higgs masses, couplings and decay widths in the NMSSM, JHEP 0502\n(2005) 066 [arXiv:hep-ph/0406215].\nhttp://www.th.u-psud.fr/NMHDECAY/nmssmtools.html\n[27] T. Hahn and M. Perez-Victoria, Automatized one-loop calculations in four and D dimensions,\nComput. Phys. Commun. 118 (1999) 153 [arXiv:hep-ph/9807565]; T. Hahn, Generating\nFeynman diagrams and amplitudes with FeynArts 3, Comput. Phys. Commun. 140 (2001)\n418 [arXiv:hep-ph/0012260]; T. Hahn and C. Schappacher, The implementation of the\nminimal supersymmetric standard model in FeynArts and FormCalc, Comput. Phys.\nCommun. 143 (2002) 54 [arXiv:hep-ph/0105349].\nhttp://www.feynarts.de/\n[28] M. Rauch, Quantum Effects in Higgs-Boson Production Processes at Hadron Colliders,\narXiv:0804.2428 [hep-ph]. http://www.ph.ed.ac.uk/ \u0303mrauch/HadCalc/\n[29] A. Pukhov et al., CompHEP: A package for evaluation of Feynman diagrams and integration\nover multi-particle phase space. User's manual for version 33, arXiv:hep-ph/9908288; A.\nPukhov, CalcHEP 3.2: MSSM, structure functions, event generation, batchs, and generation\nof matrix elements for other packages, arXiv:hep-ph/0412191.\nhttp://www.ifh.de/ \u0303pukhov/calchep.html\n[30] E. Boos et al. [CompHEP Collaboration], CompHEP 4.4: Automatic computations from\nLagrangians to events, Nucl. Instrum. Meth. A 534 (2004) 250 [arXiv:hep-ph/0403113] and\nRef. [29]. http://comphep.sinp.msu.ru/\n\n\u2013 25 \u2013\n\n\f[31] A. V. Semenov, LanHEP: A package for automatic generation of Feynman rules in field\ntheory. Version 2.0, arXiv:hep-ph/0208011.\nhttp://theory.sinp.msu.ru/ \u0303semenov/lanhep.html\n[32] H. Murayama, I. Watanabe and K. Hagiwara, Evaluating cross-sections at TeV energy scale\nby HELAS, Tsukuba Workshop JLC 1992 265.\nhttp://www.pas.rochester.edu/ \u0303rain/smadgraph/HELAS.ps.gz\n[33] T. Gleisberg, S. Hoche, F. Krauss, A. Schalicke, S. Schumann and J. C. Winter, SHERPA\n1.alpha, a proof-of-concept version, JHEP 0402 (2004) 056 [arXiv:hep-ph/0311263].\nhttp://www.sherpa-mc.de/\n[34] F. Krauss, R. Kuhn and G. Soff, AMEGIC++ 1.0: A matrix element generator in C++,\nJHEP 0202 (2002) 044 [arXiv:hep-ph/0109036].\n[35] W. Kilian, T. Ohl and J. Reuter, WHIZARD: Simulating Multi-Particle Processes at LHC\nand ILC, arXiv:0708.4233 [hep-ph].\nhttp://whizard.event-generator.org/\n[36] M. Moretti, T. Ohl and J. Reuter, O'Mega: An optimizing matrix element generator,\narXiv:hep-ph/0102195.\n[37] N. Ghodbane, SUSYGEN3: An event generator for linear colliders, arXiv:hep-ph/9909499.\nhttp://lyoinfo.in2p3.fr/susygen/susygen3.html\n[38] J. Fujimoto et al., GRACE/SUSY: Automatic generation of tree amplitudes in the minimal\nsupersymmetric standard model, Comput. Phys. Commun. 153 (2003) 106\n[arXiv:hep-ph/0208036].\nhttp://minami-home.kek.jp/\n[39] K. Hagiwara et al., Supersymmetry simulations with off-shell effects for LHC and ILC, Phys.\nRev. D 73 (2006) 055005 [arXiv:hep-ph/0512260].\n[40] W. Beenakker, R. Hopker, M. Spira and P. M. Zerwas, Squark and gluino production at\nhadron colliders, Nucl. Phys. B 492 (1997) 51 [arXiv:hep-ph/9610490].\nhttp://www.ph.ed.ac.uk/ \u0303tplehn/prospino/\n[41] A. Freitas, A. von Manteuffel and P. M. Zerwas, Slepton production at e+ e- and e- e- linear\ncolliders, Eur. Phys. J. C 34 (2004) 487 [arXiv:hep-ph/0310182].\nhttp://theory.fnal.gov/people/freitas/\n[42] M. A. Dobbs et al., Les Houches guidebook to Monte Carlo generators for hadron collider\nphysics, arXiv:hep-ph/0403045.\n[43] L. L\u00f6nnbladd, ThePEG Reference Manual.\nhttp://projects.hepforge.org/thepeg/doxygen/index.html\n[44] S. Catani, F. Krauss, R. Kuhn and B. R. Webber, QCD matrix elements + parton showers,\nJHEP 0111 (2001) 063 [arXiv:hep-ph/0109231].\n[45] J. C. Winter, F. Krauss and G. Soff, A modified cluster-hadronization model, Eur. Phys. J. C\n36 (2004) 381 [arXiv:hep-ph/0311085].\n[46] G. Hinshaw et al. [WMAP Collaboration], Five-Year Wilkinson Microwave Anisotropy Probe\n(WMAP) Observations:Data Processing, Sky Maps, & Basic Results, arXiv:0803.0732\n[astro-ph].\n\n\u2013 26 \u2013\n\n\f[47] F. Boudjema, A. Semenov and D. Temes, SUSY dark matter: Loops and precision from\nparticle physics, Nucl. Phys. Proc. Suppl. 157 (2006) 172; N. Baro, F. Boudjema and\nA. Semenov, Full one-loop corrections to the relic density in the MSSM: A few examples,\nPhys. Lett. B 660 (2008) 550 [arXiv:0710.1821 [hep-ph]].\n[48] P. Gondolo, J. Edsjo, P. Ullio, L. Bergstrom, M. Schelke and E. A. Baltz, DarkSUSY:\nComputing supersymmetric dark matter properties numerically, JCAP 0407 (2004) 008\n[arXiv:astro-ph/0406204].\nhttp://www.physto.se/ \u0303edsjo/darksusy\n[49] G. Belanger, F. Boudjema, A. Pukhov and A. Semenov, Dark matter direct detection rate in\na generic model with micrOMEGAs2.1, arXiv:0803.2360 [hep-ph]; G. Belanger, F. Boudjema,\nA. Pukhov and A. Semenov, micrOMEGAs2.0: A program to calculate the relic density of\ndark matter in a generic model, Comput. Phys. Commun. 176 (2007) 367\n[arXiv:hep-ph/0607059].\nhttp://wwwlapp.in2p3.fr/lapth/micromegas/\n[50] G. Degrassi, P. Gambino and P. Slavich, SusyBSG: a fortran code for BR[B \u2192 Xs gamma] in\nthe MSSM with Minimal Flavor Violation, arXiv:0712.3265 [hep-ph].\nhttp://slavich.web.cern.ch/slavich/susybsg/home.html\n[51] F. Mahmoudi, SuperIso: A program for calculating the isospin asymmetry of B \u2192 K \u2217 \u03b3 in the\nMSSM, Comput. Phys. Commun. 178 (2008) 745 [arXiv:0710.2067 [hep-ph]].\nhttp://www.isv.uu.se/ \u0303nazila/superiso/\n[52] R. Ruiz de Austri and R. Trotta, SuperBayeS Supersymmetry Parameters Extraction\nRoutines for Bayesian Statistics.\nhttp://superbayes.org/\n[53] F. James, MINUIT: Function minimization and error analysis, CERN Program Library Long\nWriteup D506,\nhttp://wwwasdoc.web.cern.ch/wwwasdoc/minuit/minmain.html\n[54] O. Buchmueller et al., Prediction for the Lightest Higgs Boson Mass in the CMSSM using\nIndirect Experimental Constraints, Phys. Lett. B 657 (2007) 87 [arXiv:0707.3447 [hep-ph]].\n[55] R. Trotta, Bayes in the sky: Bayesian inference and model selection in cosmology,\narXiv:0803.4089 [astro-ph].\n[56] A. Lewis and S. Bridle, Cosmological parameters from CMB and other data: a Monte-Carlo\napproach, Phys. Rev. D66 (2002) 103511 [arXiv:astro-ph/0205436].\nhttp://cosmologist.info/cosmomc\n[57] N. Metropolis, A.W. Rosenbluth, M.N. Teller and E. Teller, Equations of State Calculations\nby Fast Computing Machines, Journal of Chemical Physics, 21 (1953) 1087-1091\n[58] A. Gelman and D. Rubin, Inference from Iterative Simulation Using Multiple Sequences,\nStat. Sci. 7 (1992) 457.\n[59] B.C. Allanach, K. Cranmer, C.G. Lester and A.M. Weber, Natural priors, CMSSM fits and\nLHC weather forecasts, JHEP 0708 (2007) 023 [arXiv:0705.0487].\nhttp://users.hepforge.org/ \u0303allanach/benchmarks/kismet.html\n[60] R. Lafaye, T. Plehn, M. Rauch and D. Zerwas, Measuring Supersymmetry, arXiv:0709.3985\n[hep-ph].\n\n\u2013 27 \u2013\n\n\f[61] B.C. Allanach and C.G. Lester, Sampling using a 'bank' of clues, arXiv:0705.0486.\n[62] P. Bechtle, K. Desch and P. Wienemann, Fittino, a program for determining MSSM\nparameters from collider observables using an iterative method, Comput. Phys. Commun. 174\n(2006) 47 [arXiv:hep-ph/0412012].\nhttp://www-flc.desy.de/fittino/\n[63] F. Feroz and M. P. Hobson, Multimodal nested sampling: an efficient and robust alternative\nto MCMC methods for astronomical data analysis, arXiv:0704.3704 [astro-ph].\n[64] L. Roszkowski, R. Ruiz de Austri and R. Trotta, Implications for the Constrained MSSM\nfrom a new prediction for b to s gamma, JHEP 0707 (2007) 075 [arXiv:0705.2012 [hep-ph]].\n[65] Dark Matter Network Exclusion Program.\nhttp://pisrv0.pit.physik.uni-tuebingen.de/darkmatter/\n[66] J. A. Aguilar-Saavedra et al., Supersymmetry parameter analysis: SPA convention and\nproject, Eur. Phys. J. C 46 (2006) 43 [arXiv:hep-ph/0511344].\n\n\u2013 28 \u2013\n\n\f\u2013 29 \u2013\n\n\u221a\n\u221a\n\n\u2283\n\u2283\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\n\u2283\n\n\u221a\n\u221a\n\n\u221a\n\u221a\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\u221a\n\n\u221a\n\u2283\n\n\u221a\n\u221a\n\n\u221a\n\n\u221a\n\u221a\n\u221a\n\n\u221a\n\n\u2283\n\u2283\n\u2283\n\n\u2283\n\n\u221a\n\n\u221a\n\n\u2283\n\n\u2283\n\n\u221a\n\n\u221a\n\u221a\n\n\u221a\n\u221a\n\u221a\n\u221a\n\n\u221a\n\u221a\n\u221a\n\n\u221a\n\n\u2283\n\n\u221a\n\n\u221a\n\u221a\n\u221a\n\n\u221a\n\n\u221a\n\u221a\n\u221a\n\u221a\n\n\u221a\n\n\u221a\n\n\u2283\n\n\u2283\n\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\n\u221a\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\n\u221a\n\u221a\n\u221a\n\n\u221a\n\u221a\n\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\n\u2283\n\n\u2283\n\n\u221a\n\u221a\n\n\u221a\n\n\u2283\n\n\u2283\n\n\u221a\n\n\u2283\n\n\u221a\n\ncode\n\n\u221a\n\u221a\n\u221a\n\nWeb form\n\n\u221a\n\u221a\n\nFits\n\nedm\n\n\u221a\n\nEW\n\n\u221a\n\n(g \u2212 2)\u03bc\n\nB \u2192 \u03c4 \u03bd, \u03c4 \u03c4\n\n\u2206MBs\n\n\u221a\n\n\u22060\u2212\n\n\u221a\n\nBs \u2192 \u03bc+ \u03bc\u2212\n\nb \u2192 s\u03b3\n\nInd. DM\n\np\n\n\u03c3SI,SD\n\n\u03a9DM h2\n\nPS/Had\n\nEvents\n\npp\n\n\u221a\n\n\u221a\n\n\u2283\n\ne+ e\u2212\n\n\u221a\n\n\u221a\n\n\u221a\n\n\u03c3SU SY\n\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\u2283\n\n\u221a\n\u221a\n\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\n\nInitial pol\n\n\u221a\n\n\u221a\n\nME\n\n\u221a\n\n\u221a\n\u221a\n\nDecay Spin\n\nDecays\n\n\u221a\n\nFV\n\nNMSSM\n\n\u221a\n\nCPV\n\n\u221a\n\nRPV\n\n\u221a\n\u221a\n\u221a\n\u221a\n\n\u03bdR\n\nSpectrum\n\nL\n\nTool\nNMSSMtools [26]\nSOFTSUSY [11]\nSPheno [12]\nSUSPECT [13]\nBRIDGE [21]\nCPsuperH [23]\nFCHDECAY [25]\nFeynHiggs [22]\nHDECAY [24]\nSDECAY [19]\nCalcHEP [29]\nCompHEP [30]\nFormCalc [27]\nGRACE [38]\nILCslepton [41]\nLanHEP [31]\nMadGraph [17]\nSUSYGEN [37]\nWhizard [35]\nHerwig++ [16]\nISATOOLS [9]\nPYTHIA [18]\nSHERPA [33]\nHadCalc [28]\nDarkSUSY [48]\nmicrOMEGAs [49]\nPROSPINO [40]\nSuperIso [51]\nSusyBSG [50]\nFITTINO [62]\nKISMET [59]\nSuperBayeS [52]\n\n[14]\n[14]\n[14]\n\n\u221a\n\u221a\n\n\u221a\n\n\u221a\n\n[22]\n\u221a\n\u221a\n\u221a\n\u221a\n\n[17]\n\u221a\n\u221a\n\u221a\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\u221a\n\n\u221a\n\u221a\n\n\u221a\n\u221a\n\n\u221a\n\n\u221a\n\n\u221a\n\u221a\n\n\u221a\n\n\u221a\n\u221a\n\u2283\n\u2283\n\n\u2283\n\n\u2283\n\n\u2283\n\u221a\n\n\u221a\n\n\u2283\n\u221a\n\n\u2283\n\n\u2283\n\n\u221a\n\n\u221a\n\u221a\n\n\u221a\n\n[14]\n\n\u221a\n\n[48]\n[14]\n\n\u221a\n\n\u2283\n\n\u221a\n\n\u2283\n\u2283\n\n\u2283\n\u2283\n\n\u221a\n\u221a\n\u221a\n\n[59]\n[65]\n\n\u221a\nTable 2: Summary of functionality of current, publicly available, supported SUSY tools. A indicates that there is some support for the feature\nin question, but makes no claims about the accuracy of the calculation. \u2283 indicates that the one of the other packages in the table is included in\nthe distribution in order to provide the relevant functionality. See section 8 for a description of the various features.\n\n\f"}