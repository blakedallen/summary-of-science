{"id": "http://arxiv.org/abs/0911.4395v1", "guidislink": true, "updated": "2009-11-23T13:14:35Z", "updated_parsed": [2009, 11, 23, 13, 14, 35, 0, 327, 0], "published": "2009-11-23T13:14:35Z", "published_parsed": [2009, 11, 23, 13, 14, 35, 0, 327, 0], "title": "Introduction to Distributed Systems", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0911.1679%2C0911.3108%2C0911.0034%2C0911.4395%2C0911.3191%2C0911.4872%2C0911.5307%2C0911.1244%2C0911.4720%2C0911.1602%2C0911.5228%2C0911.0061%2C0911.4533%2C0911.4904%2C0911.3025%2C0911.5440%2C0911.2207%2C0911.1773%2C0911.0420%2C0911.5432%2C0911.0222%2C0911.0881%2C0911.1445%2C0911.3553%2C0911.4323%2C0911.5301%2C0911.3533%2C0911.3351%2C0911.4626%2C0911.3407%2C0911.3277%2C0911.2069%2C0911.5643%2C0911.5557%2C0911.0275%2C0911.1249%2C0911.2142%2C0911.0702%2C0911.0102%2C0911.2524%2C0911.4968%2C0911.1920%2C0911.2964%2C0911.5477%2C0911.1553%2C0911.0763%2C0911.5466%2C0911.4856%2C0911.1335%2C0911.5647%2C0911.3058%2C0911.1487%2C0911.4536%2C0911.1814%2C0911.2331%2C0911.1863%2C0911.5258%2C0911.4444%2C0911.4612%2C0911.2314%2C0911.5017%2C0911.2569%2C0911.3835%2C0911.4214%2C0911.1601%2C0911.5292%2C0911.1265%2C0911.2326%2C0911.2098%2C0911.2746%2C0911.1312%2C0911.0427%2C0911.3660%2C0911.2707%2C0911.2027%2C0911.2194%2C0911.4902%2C0911.3720%2C0911.5060%2C0911.4080%2C0911.0257%2C0911.4282%2C0911.2484%2C0911.4200%2C0911.2003%2C0911.0305%2C0911.4438%2C0911.2434%2C0911.5659%2C0911.5026%2C0911.1916%2C0911.4694%2C0911.2173%2C0911.3033%2C0911.1125%2C0911.2803%2C0911.2278%2C0911.5338%2C0911.4619%2C0911.3977%2C0911.1077&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Introduction to Distributed Systems"}, "summary": "Computing has passed through many transformations since the birth of the\nfirst computing machines. Developments in technology have resulted in the\navailability of fast and inexpensive processors, and progresses in\ncommunication technology have resulted in the availability of lucrative and\nhighly proficient computer networks. Among these, the centralized networks have\none component that is shared by users all the time. All resources are\naccessible, but there is a single point of control as well as a single point of\nfailure. The integration of computer and networking technologies gave birth to\nnew paradigm of computing called distributed computing in the late 1970s.\nDistributed computing has changed the face of computing and offered quick and\nprecise solutions for a variety of complex problems for different fields.\nNowadays, we are fully engrossed by the information age, and expending more\ntime communicating and gathering information through the Internet. The Internet\nkeeps on progressing along more than a few magnitudes, abiding end systems\nincreasingly to communicate in more and more different ways. Over the years,\nseveral methods have evolved to enable these developments, ranging from\nsimplistic data sharing to advanced systems supporting a multitude of services.\nThis article provides an overview of distributed computing systems. The\ndefinition, architecture, characteristics of distributed systems and the\nvarious distributed computing fallacies are discussed in the beginning.\nFinally, discusses client/server computing, World Wide Web and types of\ndistributed systems.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0911.1679%2C0911.3108%2C0911.0034%2C0911.4395%2C0911.3191%2C0911.4872%2C0911.5307%2C0911.1244%2C0911.4720%2C0911.1602%2C0911.5228%2C0911.0061%2C0911.4533%2C0911.4904%2C0911.3025%2C0911.5440%2C0911.2207%2C0911.1773%2C0911.0420%2C0911.5432%2C0911.0222%2C0911.0881%2C0911.1445%2C0911.3553%2C0911.4323%2C0911.5301%2C0911.3533%2C0911.3351%2C0911.4626%2C0911.3407%2C0911.3277%2C0911.2069%2C0911.5643%2C0911.5557%2C0911.0275%2C0911.1249%2C0911.2142%2C0911.0702%2C0911.0102%2C0911.2524%2C0911.4968%2C0911.1920%2C0911.2964%2C0911.5477%2C0911.1553%2C0911.0763%2C0911.5466%2C0911.4856%2C0911.1335%2C0911.5647%2C0911.3058%2C0911.1487%2C0911.4536%2C0911.1814%2C0911.2331%2C0911.1863%2C0911.5258%2C0911.4444%2C0911.4612%2C0911.2314%2C0911.5017%2C0911.2569%2C0911.3835%2C0911.4214%2C0911.1601%2C0911.5292%2C0911.1265%2C0911.2326%2C0911.2098%2C0911.2746%2C0911.1312%2C0911.0427%2C0911.3660%2C0911.2707%2C0911.2027%2C0911.2194%2C0911.4902%2C0911.3720%2C0911.5060%2C0911.4080%2C0911.0257%2C0911.4282%2C0911.2484%2C0911.4200%2C0911.2003%2C0911.0305%2C0911.4438%2C0911.2434%2C0911.5659%2C0911.5026%2C0911.1916%2C0911.4694%2C0911.2173%2C0911.3033%2C0911.1125%2C0911.2803%2C0911.2278%2C0911.5338%2C0911.4619%2C0911.3977%2C0911.1077&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Computing has passed through many transformations since the birth of the\nfirst computing machines. Developments in technology have resulted in the\navailability of fast and inexpensive processors, and progresses in\ncommunication technology have resulted in the availability of lucrative and\nhighly proficient computer networks. Among these, the centralized networks have\none component that is shared by users all the time. All resources are\naccessible, but there is a single point of control as well as a single point of\nfailure. The integration of computer and networking technologies gave birth to\nnew paradigm of computing called distributed computing in the late 1970s.\nDistributed computing has changed the face of computing and offered quick and\nprecise solutions for a variety of complex problems for different fields.\nNowadays, we are fully engrossed by the information age, and expending more\ntime communicating and gathering information through the Internet. The Internet\nkeeps on progressing along more than a few magnitudes, abiding end systems\nincreasingly to communicate in more and more different ways. Over the years,\nseveral methods have evolved to enable these developments, ranging from\nsimplistic data sharing to advanced systems supporting a multitude of services.\nThis article provides an overview of distributed computing systems. The\ndefinition, architecture, characteristics of distributed systems and the\nvarious distributed computing fallacies are discussed in the beginning.\nFinally, discusses client/server computing, World Wide Web and types of\ndistributed systems."}, "authors": ["Sabu M. Thampi"], "author_detail": {"name": "Sabu M. Thampi"}, "author": "Sabu M. Thampi", "links": [{"href": "http://arxiv.org/abs/0911.4395v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0911.4395v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.DC", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.DC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.NI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0911.4395v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0911.4395v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Introduction to Distributed Systems\nSABU M. THAMPI\nL.B.S INSTITUTE OF TECHNOLOGY FOR WOMEN\nTRIVANDRUM, KERALA, INDIA-695012\nsmtlbs@in.com, smtlbs@gmail.com\n----------------------------------------------------------------------------------------------------------\n\nAbstract: Computing has passed through many transformations since the birth of the\nfirst computing machines. Developments in technology have resulted in the availability\nof fast and inexpensive processors, and progresses in communication technology have\nresulted in the availability of lucrative and highly proficient computer networks. Among\nthese, the centralized networks have one component that is shared by users all the time.\nAll resources are accessible, but there is a single point of control as well as a single point\nof failure. The integration of computer and networking technologies gave birth to new\nparadigm of computing called distributed computing in the late 1970s. Distributed\ncomputing has changed the face of computing and offered quick and precise solutions for\na variety of complex problems for different fields. Nowadays, we are fully engrossed by\nthe information age, and expending more time communicating and gathering information\nthrough the Internet. The Internet keeps on progressing along more than a few\nmagnitudes, abiding end systems increasingly to communicate in more and more\ndifferent ways. Over the years, several methods have evolved to enable these\ndevelopments, ranging from simplistic data sharing to advanced systems supporting a\nmultitude of services. This article provides an overview of distributed computing\nsystems. The definition, architecture, characteristics of distributed systems and the\nvarious distributed computing fallacies are discussed in the beginning. Finally, discusses\nclient/server computing, World Wide Web and types of distributed systems.\n\nWhat is a Distributed System?\nThe scale of networked workstations and plunge of the centralized mainframe has\nbeen the most theatrical change in the last two decades of information technology. This\nshift has placed added processing power in the hands of the end-user and distributed\nhardware resources. When computers work together over a network, the network may use\n\n\fthe power from all the networked computers to perform complex tasks. Computation in\nnetworks of processing nodes can be classified into centralized or distributed\ncomputations. A centralized solution relies on one node being designated as the computer\nnode that processes the entire application locally and the central system is shared by all\nthe users all the time. Hence there is single point of control and single point of failure.\n\nThe motivation behind the growth of decentralised computing is the availability of\nthe low-priced, high performance computers and network tools. When a handful of\npowerful computers are linked together and communicate with each other, the overall\ncomputing power available can be amazingly vast. Such a system can have a higher\nperformance share than a single supercomputer. Distributed computing \u2013 a\ndecentralisation approach to computing is a potentially very powerful approach for\naccessing large amounts of computational power. The objective of such systems is to\nminimize communication and computation cost. In distributed systems, the processing\nsteps of the application are divided among the participating nodes. The basic step in all\ndistributed computing architectures is the notion of communication between computers.\n\nDistributed system is an application that executes a collection of protocols to\ncoordinate the actions of multiple processes on a communication network, such that all\ncomponents cooperate together to perform a single or small set of related tasks. The\ncollaborating computers can access remote resources as well as local resources in the\ndistributed system via the communication network. The existence of multiple\nautonomous computers is transparent to the user in a distributed system. The user is not\naware that the jobs are executed by multiple computers subsist in remote locations. This\nmeans that like centralised systems no single computer in the system carries the entire\nload on system resources that running a computer program usually required.\n\nDistributed System Architecture\nDistributed systems are built up on top of existing networking and operating systems\nsoftware. A distributed system comprises a collection of autonomous computers, linked\nthrough a computer network and distribution middleware. To become autonomous there\nexist a clear master/slave association between two computers in the network. The\nmiddleware enables computers to coordinate their activities and to share the resources of\n\n\fthe system, so that users perceive the system as a single, integrated computing facility.\nThus, middleware is the bridge that connects distributed applications across dissimilar\nphysical locations, with dissimilar hardware platforms, network technologies, operating\nsystems, and programming languages. The middleware software is being developed\nfollowing agreed standards and protocols. It provides standard services such as naming,\npersistence, concurrency control to ensures that accurate results for concurrent processes\nare produced and obtains the results as fast as possible, event distribution, authorization\nto specify access rights to resources, security etc. The middleware service extends over\nmultiple machines. Figure 1 shows a simple architecture of a distributed system\n[GEOR01, ANDR02].\n\nFigure 1. A Distributed System\nThe distributed system can be viewed as defined by the physical components or as\ndefined from user or computation point of view. The first is known as the physical view\nand the second as the logical view. Physically a distributed system consists of a set of\nnodes (computers) linked together by a communication network. The nodes in the\nnetwork are loosely coupled and do not share their memory. The nodes in the system\ncommunicate by passing messages over the communication network. Communication\nprotocols are used for sending messages from one node to another. The logical model is\nthe view that an application has of the system. It contains a set of concurrent processes\nand communication channels between them. The core network is treated as fully\nconnected. Processes communicate by sending messages to each other. A system is\n\n\fsynchronous if during a proper execution, it all the time performs the intended operation\nin a known fixed time, otherwise it is asynchronous. In synchronous system the failure\ncan be noticed by a lack of response from the system. Therefore, timeout based\ntechniques are used for failure discovery.\n\nA distributed system can be constructed by means of fully connected networks or\npartially connected networks [HUAN05, MIN04, NELS01]. A fully connected network\n(figure 2) is a network in which each of the nodes is connected to each other. The\nproblem with such a system is that adding new nodes to the system results in the increase\nof number of nodes connected to the node. Due to this the number of file descriptors and\ncomplexity for each node to implement the connections are increased heavily. Thus, the\nscalability (capability of a system to continue to function well when the system is\nchanged in size or volume) of such systems is limited by each node's capacity to open\nfile descriptors and the ability to handle the new connections. The communication cost the message delay of sending a message from the source to the destination- is low\nbecause a message sent from one computer to another one only goes through one link.\nFully connected systems are reliable because when a few computers or links fail, the rest\nof the computers can still communicate with others.\n\nIn a partially connected network, direct links exist between some, but not all, pairs of\ncomputers. A few of the partially connected network models are star structured networks,\nmulti-access bus networks; ring structured networks, and tree-structured networks (figure\n2). Some of the traditional distributed systems such as client/server paradigm use a star\nas the network topology. The problem with such a system is that when the central node\nfails, the entire system will be collapsed. In a multi-access bus network, a set of clients\nare connected via a shared communications line, called a bus. The bus link becomes the\nbottleneck and if it fails, all the nodes in the system cannot connect to each other.\nAnother disadvantage is that performance degrades as additional computers are added or\non heavy traffic. In a ring network each node connects to exactly two other nodes,\nforming a single continuous pathway for signals through each node. As new nodes are\nadded, the diameter of the system grows as the number of nodes in the system, resulting\nin a longer message transmission delay. A node failure or cable break might isolate every\nnode attached to the ring. In a tree-structured network (hierarchical network), the nodes\nare connected as a tree. Each node in the network having a specific fixed number, of\n\n\fnodes associated to it at the next lower level in the hierarchy. The scalability of the treestructured network is better than that of the fully connected network, since new node can\nbe added as the child node of the leaf nodes or the interior nodes. On the other hand, in\nsuch systems, only messages transmitted between a parent node and its child node go\nthough one link, other messages transmitted between two nodes have to go through one\nor more intermediate nodes.\n\nFully Connected Network\n\nRing Structured Network\n\nTree Structured Network\n\nMulti-access Bus Network\n\nStar Structured Network\nFigure 2. Network Models\n\n\fCharacteristics of a Distributed System\nA distributed system must possess the following characteristics to deliver utmost\nperformance for the users:\n\uf0b7\n\nFault-Tolerant: Distributed systems consist of a large number of hardware and\nsoftware modules that are bound to fail in the long run. Such component failures can\nescort to service unavailability. Hence, the systems should be able to recover from\ncomponent failures without performing erroneous actions. The goal of fault tolerance\nis to avoid failures in the system even in the presence of faults to provide\nuninterrupted service. A system is said to be fault tolerant if it can mask the presence\nof faults. The aim of any fault tolerant system is to increase its reliability or\navailability. The reliability of a system is defined as the probability that the system\nsurvives till that time. A reliable system prevents loss of information even in the\nevent of component failures. Availability is the fraction of time for which a system is\navailable for use. Usually fault tolerance is achieved by providing redundancy.\nRedundancy is defined as those parts of the system that are not needed for its correct\nfunctioning. It is of three types \u2013 hardware, software and time. Hardware redundancy\nis achieved by adding extra hardware components to system which take over the role\nof failed components in case some faults occur in them. Software redundancy\nincludes extra instructions and code included for managing the extra hardware\ncomponents, and using them correctly for uninterrupted service, in case of some\ncomponent failure. In time redundancy the same instruction is executed many times.\nThis is used to handle temporary faults in the system [VIKA04].\n\n\uf0b7\n\nScalable: A distributed system can operate correctly even as some aspect of the\nsystem is scaled to a larger size. Scale has three components: the number of users and\nother entities that are part of the system, the distance between the farthest nodes in the\nsystem, and the number of organizations that exert administrative control over pieces\nof the system. The three elements of scale affect distributed systems in many ways.\nAmong the affected components are naming, authentication for verifying someone's\nidentity, authorization, communication, the use of remote resources, and the\nmechanisms by which users observe the system. Three techniques are employed to\nmanage scale: replication, distribution, and caching [CLIF94].\n\n\fReplication creates multiple copies of resources. Its use in naming, authentication,\nand file services reduces the load on individual servers and improves the reliability\nand availability of the services as a whole. The two important issues of replication are\nthe placement of the replicas and the mechanisms by which they are kept consistent.\nThe placement of replicas in a distributed system depends on the purpose for\nreplicating the resource. If a service is being replicated to reduce the network delays\nwhen the service is accessed, the replicas are sprinkled across the system. If the\nmajority of users are local, and if the service is being replicated to improve its\navailability or to spread the load across multiple servers, then replicas may be placed\nnear one another. If a change is made to the object, the change should be noticeable to\neveryone in the system. For example, the system sends the updates to any replica, and\nthat replica forwards the update to the others as they become available. If inconsistent\nupdates are received by different replicas in different orders, timestamps (the\ndate/time at which the update was generated) are used to differentiate the copies.\n\nDistribution, another mechanism for managing scale in distributed systems, allows\nthe information maintained by a distributed service to be extended across several\nservers. Distributing data across multiple servers reduces the size of the database that\nmust be maintained by each server, dropping the time needed to search the database.\nDistribution also spreads the load across the servers reducing the number of requests\nthat are handled by each. If requests can be distributed to servers in proportion to their\npower, the load on servers can be effectively managed. Network traffic can be\nreduced if data are assigned to servers close to the location from which they are most\nfrequently used. In tree structured system, if cached copies are available from\nsubordinate servers, the upper levels can be avoided.\n\nCaching is another important technique for building scalable systems. Caching\ndecreases the load on servers and the network. Cached data can be accessed faster\nthan if a new request is made. The difference between replication and caching is that\ncached data is a short-term data. Instead of propagating updates on cached data,\nconsistency is maintained by nullifying cached data when consistency can not be\nguaranteed. Caching is usually performed by the client, reducing frequent requests to\nnetwork services. Caching can also occur on the servers executing those services.\n\n\fReading a file from the memory cached copy on the file server is faster than reading it\nfrom the client's local disk.\n\uf0b7\n\nPredictable Performance: Various performance metrics such as response time\n(elapsed time between the end of an inquiry or demand on a computer system and the\nbeginning of a response), throughput (the rate at which a network sends or receives\ndata), system utilization, network capacity etc. are employed to assess the\nperformance. Predictable performance is the ability to provide desired responsiveness\nin a timely manner.\n\n\uf0b7\n\nOpenness: The attribute 'openness' ensures that a subsystem is continually open to\ninteraction with other systems. Web services are software systems designed to\nsupport interoperable machine-to-machine interaction over a network. These\nprotocols allow distributed systems to be extended and scaled. An open system that\nscales has benefit over a completely closed and self-reliant system. A distributed\nsystem independent from heterogeneity of the underlying environment such as\nhardware and software platforms achieves the property of openness. Therefore, every\nservice is equally accessible to every client (local or remote) in the system. The\nimplementation, installation and debugging of new services should not be very\ncomplex in a system possessing openness characteristic.\n\n\uf0b7\n\nSecurity: Distributed systems should allow communication between programs/users/\nresources on different computers by enforcing necessary security arrangements. The\nsecurity features are mainly intended to provide confidentiality, integrity and\navailability. Confidentiality (privacy) is protection against disclosure to unauthorised\nperson. Violation of confidentiality range from the discomforting to the catastrophic.\nIntegrity provides protection against alteration and corruption. Availability keeps the\nresource accessible. Many incidents of hacking compromise the integrity of databases\nand other resources. \"Denial of service\" attacks are attacks against availability. Other\nimportant security concerns are access control and nonrepudiation. Maintaining\naccess control facilitates the users to access only those resources and services to\nwhich they are entitled. It also ensures that users are not denied resources that they\nlegitimately can expect to access. Nonrepudiation provides protection against denial\n\n\fby one of the entities involved in a communication. The security mechanisms put into\npractice should guarantee appropriate use of resources by different users in the\nsystem.\n\uf0b7\n\nTransparency: Distributed systems should be perceived by users and application\ndevelopers as a whole rather than as a collection of cooperating components. The\nlocations of the computer systems involved in the operations, concurrent operations,\ndata replication, resource discovery from multiple sites, failures, system recovery etc.\nare hidden from users. Transparency hides the distributed nature of the system from\nits users and shows the user that the system is appearing and performing as a normal\ncentralized system. The transparency can be employed in different ways in a\ndistributed system (Figure 3) [KAZI00, PRAD02].\n\nScalability\nTransparency\n\nMigration\nTransparency\n\nLocation\nTransparency\n\nPerformance\nTransparency\n\nFailure\nTransparency\n\nReplication\nTransparency\n\nConcurrency\nTransparency\n\nAccess\nTransparency\n\nFigure 3. Transparency in Distributed Systems\n\n\uf0a7\n\nAccess transparency facilitates the users of a distributed system to access local\nand remote resources using identical operations. (e.g. navigation in the web).\n\n\uf0a7\n\nLocation transparency describes names used to identify network resources (e.g.\nIP address) independent of both the user's location and the resource location. In\nother words, location transparency facilitates a user to access resources from\nanywhere on the network without knowing where the resource is located. A file\ncould be on the user's own PC, or thousands of miles away on other servers.\n\n\f\uf0a7\n\nConcurrency transparency enables several processes to operate concurrently\nusing shared information objects without interference between them (e.g.:\nAutomatic Teller Machine network). The users will not notice the existence of\nother users in the system (even if they access the same resources).\n\n\uf0a7\n\nReplication transparency enables the system to make additional copies of files\nand other resources for the purpose of performance and/or reliability, without\nthe users noticing. If a resource is replicated among several locations, it should\nappear to the user as a single resource (e.g. Mirroring - Mirror sites are usually\nused to offer multiple sources of the same information as a way of providing\nreliable access to large downloads).\n\n\uf0a7\n\nFailure transparency enables the applications to complete their task despite\nfailures occurring in certain components of the system. For example, if a server\nfails, but users are automatically redirected to another server and the user never\nnotices the failure, the system is said to show high failure transparency. Failure\ntransparency is one of the most difficult types of transparency to accomplish\nsince it is hard to determine whether a server has actually failed, or whether it is\nsimply responding very slowly. Moreover, it is generally unfeasible to achieve\nfull failure transparency in a distributed system since networks are unreliable.\n\n\uf0a7\n\nMigration transparency facilitates the resources to move from one location to\nanother without having their names changed. (e.g.: Web Pages). Users should\nnot be aware of whether a resource or computing entity possesses the ability to\nmove to a different physical or logical location.\n\n\uf0a7\n\nPerformance transparency ensures the load variation should not lead to\nperformance degradation. This could be achieved by automatic reconfiguration\nas response to changes of the load. (e.g.: load distribution)\n\n\uf0a7\n\nScalability transparency allows the system to remain efficient even with a\nsignificant increase in the number of users and resources connected (e.g.\nWorld-Wide-Web, distributed database).\n\n\fThe Eight fallacies of distributed computing\nIn 1994, Peter Deutsch of SUN drafted 7 assumptions [ARNO06, INGR04],\narchitects and designers of distributed systems are expected to make, which prove wrong\nin the end. In 1997 James Gosling - father of the Java programming language, added\nanother such fallacy \u2013 the eighth fallacy of distributed computing. The assumptions are\nnow collectively known as the \"The 8 fallacies of distributed computing\". The fallacies of\ndistributed Computing are a set of common but false assumptions made by programmers\nwhen first developing distributed applications. Many distributed systems which were\ndeveloped based on these assumptions were needlessly complex caused by mistakes that\nrequired patching later on.\nThe Fallacies of Distributed Computing\n1.\n\nThe network is reliable.\n\n2.\n\nLatency is zero.\n\n3.\n\nBandwidth is infinite.\n\n4.\n\nThe network is secure.\n\n5.\n\nTopology doesn't change.\n\n6.\n\nThere is one administrator.\n\n7.\n\nTransport cost is zero.\n\n8.\n\nThe network is homogeneous.\n\nReliability: The software which has been developed with the assumption that network is\nreliable; the network will lead to trouble when it starts dropping packets. Reliability can\noften be improved by increasing the autonomy of the nodes in a system. Replication can\nalso improve the reliability of a system.\n\nLatency: Latency is the time between initiating a request for data and the beginning of\nthe actual data transfer. Latency can be comparatively good on a LAN; however it\ndeteriorates quickly the user move to WAN scenarios or internet scenarios. Assuming\nlatency is zero will definitely lead to scalability problems as the application grows\ngeographically, or is moved to a different kind of network.\n\n\fBandwidth: A measure of the capacity of a communications channel, i.e. how much data\nwe can transfer during that time. The higher a channel's bandwidth, the more information\nit can carry. However, there are two forces at work to keep this assumption a fallacy. One\nis that while the bandwidth grows, so does the amount of information we try to squeeze\nthrough it. VoIP, videos, and IPTV are some of the newer applications that take up\nbandwidth. The other force at work to lower bandwidth is packet loss (along with frame\nsize). Bandwidth limitations direct us to strive to limit the size of the information we send\nover the wire.\n\nSecurity: The network is never secure since the systems are facing various types of\nthreats. Hence, the developer should perform threat modelling to evaluate the security\nrisks. Following this, analyze which risk should be mitigated by what measures (a\ntradeoff between costs, risks and their probability) and take appropriate measures.\nSecurity is typically a multi-layered solution that is handled on the network,\ninfrastructure, and application levels. The software architect should be conscious that\nsecurity is very essential and the consequences it may have.\n\nTopology: Topology deals with the different configurations that can be adopted in\nbuilding networks, such as a ring, bus, star or fully connected. For example any given\nnode in the LAN will have one or more links to one or more other nodes in the network\nand the mapping of these links and nodes onto a graph results in a geometrical shape that\ndetermines the physical topology of the network. Likewise, the mapping of the flow of\ndata between the nodes in the network determines the logical topology of the network.\nThe physical and logical topologies might be identical in any particular network but they\nalso may be different. When a new application is deployed in an organization, the\nnetwork structure may also be altered. The operations team is likely to add and remove\nservers every once in a while and/or make other changes to the network. Finally, there are\nserver and network faults which can cause routing changes. At the client's side the\nsituation is even worse. There are laptops coming and going, wireless adhoc networks,\nnew mobile devices etc. In a nutshell, topology in a distributed system is changing\npersistently [NELS01].\n\nAdministrator: The sixth distributed computing fallacy is \"there is one administrator\". A\nsimple situation is that with different administrators assigned according to expertise -\n\n\fdatabases, web servers, networks, different operating systems and the like for a company.\nThe problem occurs when the company collaborates with external entities such as a\nbusiness partner, or if the application is deployed for Internet consumption and hosted by\nsome hosting service and the application consumes external services. In these situations,\nthe other administrators are not even under company administrators control and they may\nhave their own rules for administration. Hence the assumption of 'one administrator' is\nproven to be a myth.\n\nMost of the time, the administrators are not part of the software development team.\nTherefore, the developers should provide them with tools to diagnose and find problems.\nA practical approach is to include tools for monitoring ongoing operations as well; for\ninstance, to allow administrators recognize problems when they are small before they\nbecome a system failure. As a distributed system grows, its various components such as\nusers, resources, nodes, networks, etc. will start to cross administrative domains. This\nmeans that the number of organizations or individuals that exert administrative control\nover the system will grow. In a system that scales poorly with regards to administrative\ngrowth, this can lead to problems of resource usage, reimbursement, security, etc.\n\nTransport cost: Transport cost never becomes zero. The costs for setting and running the\nnetwork are not free. There are costs for buying the routers, costs for securing the\nnetwork, costs for leasing the bandwidth for internet connections, and costs for operating\nand maintaining the network running.\n\nHomogeneous network: The eighth distributed computing fallacy is \"network is\nhomogeneous.\" Homogeneous network is a network derived of computers using similar\nconfiguration and protocols. Except a few very trivial ones, no network is homogeneous.\nProprietary protocols are very harder to integrate. Hence, make use of standard\ntechnologies that are widely accepted such as XML (extended markup language) or Web\nServices as these technologies help alleviate the affects of the heterogeneity of the\nenterprise environment.\n\n\fClient/Server Computing\nAs networks of computing resources have become widespread, the notion of\ndistributing interrelated processing amongst several resources has become popular. Over\nthe years, numerous methods have evolved to facilitate this distribution. One of the\npopular distributed models is client/server computing [SILV98]. The client/server model\nis an extension of the modular programming model. Modular programming breaks down\nthe design of a program into individual modules that can be programmed and tested\nindependently. A modular program consists of a main module and one or more auxiliary\nmodules. Like modular programming model, a client/server model consists of clients and\nservers. The clients and servers normally run on different computers interconnected by a\ncomputer network. The calling component becomes the client and the called component\nthe server.\nServer\n\nRequest/Response\n\nClient\n\nClient\n\nClient\n\nClient\n\nFigure 4. Client/server communication\n\nA client application sends messages to a server via the network to request the server\nfor performing a specific task. The client handles local resources such as input-output\ndevices, local disks, and other peripherals. The server program listens for client requests\nthat are transmitted via the network. Servers receive those requests and perform actions.\nMost of the data is processed on the server and only the results are returned to the client.\nThis reduces the amount of network traffic between the server and the client machine.\nThus network performance is improved further. The server controls the allocation of the\ninformation and also optimizes the resource consumption.\n\n\fAn important design consideration for large client/server systems is whether a\nclient talks directly to the server, or whether an intermediary process is introduced\nbetween the client and the server. The former is a two-tier architecture (figure 4); the\nlatter is a three-tier architecture. N-tier architecture is usually used for web applications to\nforward the requests further to other enterprise services. The two-tier architecture is\neasier to implement and is typically used in small environments. However, two-tier\narchitecture is less scalable than a three-tier architecture.\n\nIn the three-tier architecture (figure 5), an intermediate process connects the clients\nand servers [CHAN05, JI96]. The intermediary can accumulate frequently used server\ndata to guarantee enhanced performance and scalability. In database based 3-tier\nclient/server architecture, normally there are three essential components: a client\ncomputer, an application server and a database server. The application server is the\nmiddle tier server which runs the business application. The data is retrieved from\ndatabase server and it is forwarded to the client by the middle tier server. Middleware is a\nkey to developing three-tier client/server application. Database-oriented middleware\noffers an Application Program Interface (API) access to a database. Java Database\nConnectivity (JDBC) is a well-known API, these classes can be inured to aid an applet or\na servlet access any number of databases without considerate the inhabitant features of\nthe database.\n\nClient\nQuery/response\n\nSearch\n\nServer\n\nData\n\nFigure 5. 3-tier Client/server structure\n\nFor security purposes servers must also address the problem of authentication. In a\nnetworked environment, an unauthorized client may attempt to access sensitive data\nstored on a server. Authentication of clients is provided by cryptographic techniques such\nas public key encryption or special authentication servers. Sometimes critical servers are\n\n\freplicated in order to achieve high availability and fault tolerance. If one replica fails then\nthe other replicas hosted in different servers still remain available for the clients.\n\nIn the 3-tier architecture, it is easier to modify or replace any tier without affecting\nthe other tiers. The separation of application and database functionality achieves better\nload balancing. Moreover, necessary security guidelines can be put into effect within the\nserver tiers without hampering the clients.\nWeb Server\n\nRequest/\nResponse\nClient\n\nProxy Server\n\nWeb Server\n\nWeb Server\nFigure 6. Proxy Server Model\n\nA 3-tier client/server model known as 'proxy server model' (figure 6) is commonly\nused to improve retrieval performance of Internet. The intermediate process \u2013 proxy\nserver, distributes client requests to several servers so that requests execute in parallel. A\nclient connects to the proxy server, requesting some service, such as web page available\nin a web server. The proxy server assesses the request based on its filtering policy. For\nexample, it may filter traffic by IP address or protocol. If the request is authenticated by\nthe filter, the proxy presents the resource by connecting to the appropriate server and\ndemanding the required service for the client. A proxy server may sometimes serve the\nrequest without contacting the specified web server. This is made possible by keeping the\npages commonly visited by users in the cache of the proxy. By keeping local copies of\nfrequently accessed file, the proxy can serve those files back to a requesting browser\nwithout going to the external site each time; this dramatically improves the performance\nseen by the end user. A proxy server with the ability to cache information is generally\ncalled a \"proxy-cache server\". A proxy is sometimes used to authenticate users by asking\nthem to identify themselves, such as with a username and password. It is also easy to\ngrant access to external resources only to authorised users, and to record each use of\n\n\fexternal resources in log files. A proxy can also be used in a reverse direction to balance\nthe load amongst a set of identical servers.\n\nAdvantages of client/server model\ni.\n\nAll resources are centralised, hence, server can manage resources that are\ncommon to all users. For example a central database would be used to evade\nproblems caused by redundant and conflicting data.\n\nii.\n\nImproved security is offered as the number of entry points giving access to data is\nnot so important.\n\niii.\n\nServer level administration is adequate as clients do not play a major role in the\nclient/server model, they require less administration.\n\niv.\n\nA scalable network as it is possible to remove or add clients without affecting the\noperation of the network and without the need for major modification.\n\nDisadvantages of the client/server model\ni.\n\nIncreased cost due to the technical complexity of the server.\n\nii.\n\nIf a server fails, none of its clients will get service, unless the system is designed\nto be fault-tolerant.\n\niii.\n\nIf the network fails, all servers become unreachable.\n\niv.\n\nIf one client produces high network traffic, then all clients may suffer from long\nresponse times.\n\nWorld Wide Web\u2013 A massive distributed system\nThe Internet - a massive network of networks, connects millions of computers\ntogether worldwide, forming a network in which any computer can communicate with\nany other computer provided that they are both connected to the Internet. The World\nWide Web (WWW), or simply Web, is a way of accessing information over the medium\nof the Internet. WWW consists of billions of web pages, spread across thousands and\nthousands of servers all over the world. It is an information-sharing model that is built on\ntop of the Internet. The most well-known example of a distributed system is the\ncollection of web servers. Hypertext is a document containing words that bond to other\ndocuments in the Web. These words are known as links and are selectable by the user. A\nsingle hypertext document can hold links to many documents.\n\n\fThe backbone of WWW are its files, called pages or Web pages, containing\ninformation and links to resources - both text and multimedia - throughout the Internet.\nInternet protocols are sets of rules that allow for inter-machine communication on the\nInternet. HTTP (HyperText Transfer Protocol) transmits hypertext over networks. This is\nthe protocol of the Web. Simple Mail Transport Protocol or SMTP distributes e-mail\nmessages and attached files to one or more electronic mailboxes. VoIP (Voice over\nInternet Protocol) allows delivery of voice communications over IP networks, for\nexample, phone calls. A web server accepts HTTP requests from clients, and serving\nthem HTTP responses along with optional data contents such as web pages.\n\nThe operation of the web relies primarily on hypertext as its means of information\nretrieval. Web pages can be created by user activity. Creating hypertext for the Web is\naccomplished by creating documents with a language called hypertext markup language,\nor HTML. With HTML, tags are placed within the text to achieve document formatting,\nvisual features such as font size, italics and bold, and the creation of hypertext links.\nServers implementing the HTTP protocol jointly provide the distributed database of\nhypertext and multimedia documents. The clients access the web through the browser\nsoftware installed on their system. The URL (uniform resource locator) indicates the\ninternet address of a file stored on a host computer, or server, connected to the internet.\nURLs are translated into numeric addresses using the domain name system (DNS). The\nDNS is a worldwide system of servers that stores location pointers to web sites. The\nnumeric address, called the IP (Internet Protocol) address, is actually the \"real\" URL.\nOnce the translation is made by the DNS, the browser can contact the web server and ask\nfor a specific file located on its site. Web browsers use the URL to retrieve the file from\nthe server. Then the file is downloaded to the user's computer, or client, and displayed on\nthe monitor connected to the machine. Due to this correlation between clients and\nservers, the web is a client-server network. The web is used by millions of people\neveryday for different purposes including email, reading news, downloading music,\nonline shopping or simply accessing information about anything. In fact, the web\nsymbolizes a massive distributed system that materializes as a single resource to the user\naccessible at the click of a button. In order for the web to be accessible to anyone, some\nagreed-upon standards must be pursued in the formation and delivery of its content. An\n\n\forganization leading the efforts to standardize the web is the World Wide Web (W3C)\nConsortium.\n\nWeb Information Retrieval\n\nWeb information retrieval [AMI08, AMY04, AMY06, DIRK05, MONI03, VENK97] is\nthe process of searching the world's largest and linked document collection \u2013 the World\nWide Web, for information most relevant to a user's query. The various challenges of\ninformation retrieval on the web are: (i) data is distributed - data spans over many\ncomputers, of a variety of platforms, (ii) data is volatile - computers and files are added\nand removed frequently and unpredictably, (iii) volume of data is very huge - growth\ncontinues exponentially, (iv) data quality is inconsistent - data may be false, error-ridden,\ninvalid, outdated, ambiguous and multiplicity of sources introduces inconsistency and (v)\nheterogeneous data - multiple media types and media formats and multiple languages\nand alphabets. As a result, it would be physically unfeasible for an individual to sift\nthrough and examine all these pages to find the required information. Usually, in order to\nsearch for information on the internet a software tool called Search Engine is used. When\na user enters a query into a search engine from their browser software, their input is\nprocessed and used to search the database for occurrences of particular keywords. A\nvariety of search engines such as Google, Yahoo! Search, are available to make the web\nretrieval process very faster. Two main architectures used for web searching are\ncentralised and distributed search.\nWeb\n\nUsers\n\nInterface\n\nCrawler\n\nQuery Engine\n\nIndexer\n\nIndex\n\nFigure 7. Search Engine: Centralised Architecture\n\n\fCentralised Architecture: The aim of centralised approach is to index sizeable portion of\nWeb, independently of topic and domain. The centralised architecture based search\nengine has main three parts: a crawler, an indexer, and query handler. The crawler\n(spider or robot) retrieves web pages, compress and store into a page repository. This\nprocess is called crawling (sometimes known as robot spidering, gathering or harvesting).\nSome of the most well known crawlers include Googlebot (from Google) MSNBot (from\nMSN) and Slurp (from Yahoo!). Crawlers are directed by a crawler control module that\ngives the URLs to visit next. The indexer processes the web pages collected by the\ncrawler and builds an index, which is the main data structure used by the search engine\nand represents the crawled web pages. The inverted index contains for each word a sorted\nlist of couples such as docID and position in the document. The query engine processes\nthe user queries and returns matching results using the index. The results are returned to\nthe user in an order determined by a ranking algorithm. Each search engine may have a\ndifferent ranking algorithm, which parses the pages in the engine's database to determine\nrelevant responses to search queries. Some search engines keep a local cache copy of\nmany popular pages indexed in their database, to allow for faster access and in case the\ndestination server is temporarily inaccessible.\nUser\nOther\nbrokers\nand\ngatherers\n\nWeb\nSite\n\nUser\n\nBroker\n\nBroker\n\nGatherer\n\nGatherer\n\nWeb\nSite\n\nWeb\nSite\n\nOther\nbrokers\nand\ngatherers\n\nWeb\nSite\n\nFigure 8. Search Engine: Distributed Architecture\n\nDistributed architecture: Searching is a coordinated effort of many information gatherers\nand brokers. Gatherer extracts information (called summaries) from the documents stored\non one or more web servers. It can handle documents in many formats: HTML, PDF,\nPostscript, etc. Broker obtains summaries from gatherers, stores them locally, and\nindexes the data. It can search the data; fetch data from other brokers and makes data\n\n\favailable for user queries and to other brokers. The advantages of distributed architecture\nare the gatherer running on a server reduces the external traffic on that server and evading\nof gatherer sending information to multiple brokers reduces work repetition.\n\nAdvanced Distributed System Models\nThe distributed systems are cost-effective as compared to central systems. The\nintroduction of redundancy amplifies the availability even some parts of the system stop\nworking. Quite a few applications can be run concurrently in a distributed system.\nAdding new components does not influence the performance of distributed systems as the\nsystems are scalable. A large number of computers take part in performing a distributed\ncomputing task. Thus, distributed systems provide shorter response time and superior\nthroughput than centralised systems. Another merit is that distributed systems are very\nreliable. The distributed systems have the benefit of being highly available. Because of\nthese multiple benefits, a range of distributed systems and applications have been\ndeveloped recently and are being used extensively in the real world. Well-known\ndistributed computing systems are clusters, grids, peer-to-peer networks (P2P),\ndistributed storage systems [ANDR02, BUYY99, IAN99, POUR05] and so on.\nMoreover, mobile computing based distributed systems are also emerging.\n\nThe concept behind clustering, in its simplest form, is that many smaller computers\ncan be grouped in a way to make a computing structure that could provide all of the\nprocessing power needed, for much less capital. A grid is a type of distributed system\nthat allows coordinated sharing and aggregation of distributed, heterogeneous resources\nbased on users' requirements. Grids are normally used to support applications emerging\nin the areas of e-Science and e-Business. Usually grid computing involves geographically\ndistributed communities of people who engage in collaborative activities to solve large\nscale problems. This requires sharing of various resources such as computers, data,\napplications and scientific apparatuses. P2P networks are decentralized distributed\nsystems, which enable applications such as file-sharing, instant messaging, internet\ntelephony, content distribution, high performance computing etc... The most renowned\nfunction of peer-to-peer networking is found in file-exchanging communities. P2P\ntechnology is also used for applications such as the harnessing of the dormant processing\npower in desktop PCs and remote storage sharing. Distributed storage systems provide\n\n\fusers with a unified view of data stored on different file systems and computers which\nmay be on the same or different networks.\n\nThe advanced distributed system models are discussed in detail in the subsequent\nchapters of this book. Chapters 2, 3, 4 and 6 are dedicated to P2P networking. An\noverview of cluster and grid computing technologies are presented in Chapter 7. Other\nadvanced topics in distributed computing area are discussed in chapter 8.\n\nConclusions\nIn this chapter an overview of distributed systems are presented. The architecture,\nvarious characteristics, and the myths on distributed computing are discussed. Further to\nthat, an introduction to client/server systems and World Wide Web are given. The future\nof distributed computing is still quite uncertain since it is one of many new types of\ncomputing. The technology has truly shown its worth as a useful tool for various complex\napplications.\n\nBibliography\nAMI08\n\nAmi Motro, Classical and Web Information Retrieval, George Mason University, http://cs.gmu.edu,\n2008.\n\nAMY04\n\nAmy N. Langville and Carl D. Meyer, The Use of Linear Algebra by Web Search Engines, IMAGE\nNewsletter, 33, pp. 2-6, Dec. 2004.\nAmy N. Langville and Carl D. Meyer, Information Retrieval and Web Search, The Handbook of Linear\nAlgebra. CRC Press, 2006.\nAndrew S. Tanenbaum, Maarten van Steen, Distributed Systems: Principles and Paradigms, Pearson\nEducation Asia, 2002.\nAndrew S. Tanenbaum Distributed Operating Systems, Prentice Hall, 1995.\n\nAMY06\nANDR02\nANDR95\nARNO06\n\nArnon\nRotem-Gal-Oz,\nFallacies\nof\nhttp://www.rgoarchitects.com/Files/fallacies.pdf, 2006.\n\nBIRM05\n\nBirman, Kenneth, Reliable Distributed Systems: Technologies, Web Services and Applications,\nSpringer-Verlag, 2005.\nBuyya .R (editor), High Performance Cluster Computing, Prentice Hall, USA, 1999.\n\nBUYY99\nCHAN05\nCLIF94\nDIRK05\nGEOR01\nHUAN05\n\nIAN99\nINGR04\nJI96\n\ndistributed\n\ncomputing\n\nexplained.\n\nChannu Kambalyal, 3-Tier Architecture, http://members.tripod.com, 2005\nClifford Neuman B, Scale in Distributed Systems, Information Sciences Institute University of Southern\nCalifornia., In Readings in Distributed Computing Systems. IEEE Computer Society Press, 1994.\nDirk Lewandowski, Web searching, search engines and Information Retrieval, Information Services and\nUse archive, IOS Press Amsterdam, The Netherlands, vol. 25, Issue 3, 4, pp. 137-147, July 2005.\nGeorge Coulouris, Jean Dollimore, Tim Kindberg, Distributed Systems: Concepts and Design, 4/E,\nPearson Education Ltd, 2001.\nHuang, M.\nBode, B, \"A Performance Comparison of Tree and Ring Topologies in Distributed\nSystems\", Proc. of the 19th IEEE International Parallel and Distributed Processing Symposium\n(IPDPS'05) - Workshop 13 - Volume 14, Page: 258.1, 2005.\nIan Foster, Carl Kesselman, The Grid 2: Blueprint for a New Computing Infrastructure, The Morgan\nKaufmann Series in Computer Architecture and Design, 1999.\nIngrid Van Den Hoogen, Deutsch's Fallacies, 10 Years After, http://java.sys-con.com, 2004.\nJi Hua Xie Li, A Distributed Computing Model Based on Multiserver, ACM SIGOPS Operating\nSystems Review archive, volume 30, issue 4, pp. 3 - 11, October 1996.\n\n\fKAZI00\nKRIS06\n\nMIN04\nMONI03\n\nMUKE94\nNELS01\nPOUR05\nPRAD02\nSILV98\nSUBR05\n\nKazi Farooqui, Luigi Logrippo and Jan de Meer, The ISO Reference Model for Open Distributed\nProcessing: an introduction, ScienceDirect, February 2000.\nKrishna Nadiminti, Marcos Dias de Assun\u00e7\u00e3o, and Rajkumar Buyya, Distributed Systems and Recent\nInnovations: Challenges and Benefits, Grid Computing and Distributed Systems Laboratory, The\nUniversity of Melbourne, InfoNet Magazine, Volume 16, Issue 3, Melbourne, Australia, September\n2006.\nMin Huang, A performance comparison of tree and ring topologies in distributed system, Thesis, Master\nof Science, www.osti.gov, 2004.\nMonika R. Henzinger, Algorithmic Challenges in Web Search Engines, Internet Mathematics, Vol. 1,\nNo. 1: 115-126, pp. 115-123, 2003.\nMukesh Singhal and Niranjan G. Shivaratri, \"Advanced Concepts in Operating Systems\", McGraw-Hill,\n1994.\nNelson Minar, Distributed Systems Topologies: Part 1, http://openp2p.com, 2001.\nPourebrahimi K. Bertels S. Vassiliadis, A Survey of Peer-to-Peer Networks, CiteSeerX - Scientific\nLiterature Digital Library and Search Engine, 2005.\nPradeep K. Sinha, Distributed Operating Systems: Concepts and Design, Prentice-Hall of India Pvt., Ltd,\n2002.\nSilvano Maffeis, Client/Server Term Definition, in: Encyclopaedia of Computer Science, International\nThomson Computer Publishing, 1998.\nSubramanian R and Goodman B(editors), Peer-to-Peer Computing: Evolution of a Disruptive\nTechnology, Idea Group Inc., Hershey, USA, 2005.\n\nTED98\n\nTed Burghart, Distributed Computing Overview, QUOIN Inc., 1998.\n\nVENK97\n\nVenkat N. Gudivada, Vijay V. Raghavan, William I. Grosky, Rajesh Kasanagottu, Information Retrieval\non the World Wide Web, IEEE Internet Computing, pp. 58-68, September -October 1997.\n\nVIKA04\n\nVikas Agarwal, Fault Tolerance in Distributed Systems, Indian Institute of Technology Kanpur,\nwww.cse.iitk.ac.in/report-repository, 2004.\n\nwww.cis.temple.edu\n\nIntroduction to Distributed Systems, Middleware and Client/server and Peer-to-Peer Systems.\n\nwww.code.google.com/ed\nu/\nwww.en.wikipedia.org\n\nTutorial - Introduction to Distributed System Design, 2008.\nThe Eight Fallacies.\n\nwww.n-tier.com\n\nClient/Server and the N-Tier Model of Distributed Computing.\n\nwww.nutech.com.hk/solo\nmon/clientserver.htm\n\nWhat is client/server computing?\n\nwww.simmons.edu\n\nClient/Server Software Architectures- An Overview.\n\nwww.ntrq.cs.tcd.ie\n\nRichard Lee, \"P2P Search Engines\"\n\n\f"}