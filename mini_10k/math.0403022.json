{"id": "http://arxiv.org/abs/math/0403022v2", "guidislink": true, "updated": "2004-10-21T02:14:22Z", "updated_parsed": [2004, 10, 21, 2, 14, 22, 3, 295, 0], "published": "2004-03-01T18:18:03Z", "published_parsed": [2004, 3, 1, 18, 18, 3, 0, 61, 0], "title": "Phase transition of the largest eigenvalue for non-null complex sample\n  covariance matrices", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0403292%2Cmath%2F0403538%2Cmath%2F0403525%2Cmath%2F0403191%2Cmath%2F0403218%2Cmath%2F0403394%2Cmath%2F0403337%2Cmath%2F0403533%2Cmath%2F0403282%2Cmath%2F0403229%2Cmath%2F0403508%2Cmath%2F0403455%2Cmath%2F0403117%2Cmath%2F0403278%2Cmath%2F0403250%2Cmath%2F0403346%2Cmath%2F0403487%2Cmath%2F0403543%2Cmath%2F0403162%2Cmath%2F0403168%2Cmath%2F0403422%2Cmath%2F0403087%2Cmath%2F0403510%2Cmath%2F0403424%2Cmath%2F0403366%2Cmath%2F0403537%2Cmath%2F0403295%2Cmath%2F0403439%2Cmath%2F0403489%2Cmath%2F0403268%2Cmath%2F0403222%2Cmath%2F0403233%2Cmath%2F0403009%2Cmath%2F0403416%2Cmath%2F0403485%2Cmath%2F0403291%2Cmath%2F0403373%2Cmath%2F0403482%2Cmath%2F0403105%2Cmath%2F0403339%2Cmath%2F0403152%2Cmath%2F0403476%2Cmath%2F0403027%2Cmath%2F0403493%2Cmath%2F0403411%2Cmath%2F0403201%2Cmath%2F0403014%2Cmath%2F0403153%2Cmath%2F0403356%2Cmath%2F0403005%2Cmath%2F0403238%2Cmath%2F0403341%2Cmath%2F0403022%2Cmath%2F0403316%2Cmath%2F0403215%2Cmath%2F0403035%2Cmath%2F0403371%2Cmath%2F0403344%2Cmath%2F0403078%2Cmath%2F0403150%2Cmath%2F0403376%2Cmath%2F0403355%2Cmath%2F0403499%2Cmath%2F0403171%2Cmath%2F0403064%2Cmath%2F0403211%2Cmath%2F0403326%2Cmath%2F0403010%2Cmath%2F0403351%2Cmath%2F0403008%2Cmath%2F0403470%2Cmath%2F0403293%2Cmath%2F0403042%2Cmath%2F0403269%2Cmath%2F0403551%2Cmath%2F0403388%2Cmath%2F0403427%2Cmath%2F0403428%2Cmath%2F0403497%2Cmath%2F0403011%2Cmath%2F0403077%2Cmath%2F0403284%2Cmath%2F0403524%2Cmath%2F0403544%2Cmath%2F0403396%2Cmath%2F0403552%2Cmath%2F0403387%2Cmath%2F0403141%2Cmath%2F0403367%2Cmath%2F0403325%2Cmath%2F0403034%2Cmath%2F0403262%2Cmath%2F0403453%2Cmath%2F0403169%2Cmath%2F0403021%2Cmath%2F0403415%2Cmath%2F0403459%2Cmath%2F0403383%2Cmath%2F0403437%2Cmath%2F0403500%2Cmath%2F0403286&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Phase transition of the largest eigenvalue for non-null complex sample\n  covariance matrices"}, "summary": "We compute the limiting distributions of the largest eigenvalue of a complex\nGaussian sample covariance matrix when both the number of samples and the\nnumber of variables in each sample become large. When all but finitely many,\nsay $r$, eigenvalues of the covariance matrix are the same, the dependence of\nthe limiting distribution of the largest eigenvalue of the sample covariance\nmatrix on those distinguished $r$ eigenvalues of the covariance matrix is\ncompletely characterized in terms of an infinite sequence of new distribution\nfunctions that generalize the Tracy-Widom distributions of the random matrix\ntheory. Especially a phase transition phenomena is observed. Our results also\napply to a last passage percolation model and a queuing model.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0403292%2Cmath%2F0403538%2Cmath%2F0403525%2Cmath%2F0403191%2Cmath%2F0403218%2Cmath%2F0403394%2Cmath%2F0403337%2Cmath%2F0403533%2Cmath%2F0403282%2Cmath%2F0403229%2Cmath%2F0403508%2Cmath%2F0403455%2Cmath%2F0403117%2Cmath%2F0403278%2Cmath%2F0403250%2Cmath%2F0403346%2Cmath%2F0403487%2Cmath%2F0403543%2Cmath%2F0403162%2Cmath%2F0403168%2Cmath%2F0403422%2Cmath%2F0403087%2Cmath%2F0403510%2Cmath%2F0403424%2Cmath%2F0403366%2Cmath%2F0403537%2Cmath%2F0403295%2Cmath%2F0403439%2Cmath%2F0403489%2Cmath%2F0403268%2Cmath%2F0403222%2Cmath%2F0403233%2Cmath%2F0403009%2Cmath%2F0403416%2Cmath%2F0403485%2Cmath%2F0403291%2Cmath%2F0403373%2Cmath%2F0403482%2Cmath%2F0403105%2Cmath%2F0403339%2Cmath%2F0403152%2Cmath%2F0403476%2Cmath%2F0403027%2Cmath%2F0403493%2Cmath%2F0403411%2Cmath%2F0403201%2Cmath%2F0403014%2Cmath%2F0403153%2Cmath%2F0403356%2Cmath%2F0403005%2Cmath%2F0403238%2Cmath%2F0403341%2Cmath%2F0403022%2Cmath%2F0403316%2Cmath%2F0403215%2Cmath%2F0403035%2Cmath%2F0403371%2Cmath%2F0403344%2Cmath%2F0403078%2Cmath%2F0403150%2Cmath%2F0403376%2Cmath%2F0403355%2Cmath%2F0403499%2Cmath%2F0403171%2Cmath%2F0403064%2Cmath%2F0403211%2Cmath%2F0403326%2Cmath%2F0403010%2Cmath%2F0403351%2Cmath%2F0403008%2Cmath%2F0403470%2Cmath%2F0403293%2Cmath%2F0403042%2Cmath%2F0403269%2Cmath%2F0403551%2Cmath%2F0403388%2Cmath%2F0403427%2Cmath%2F0403428%2Cmath%2F0403497%2Cmath%2F0403011%2Cmath%2F0403077%2Cmath%2F0403284%2Cmath%2F0403524%2Cmath%2F0403544%2Cmath%2F0403396%2Cmath%2F0403552%2Cmath%2F0403387%2Cmath%2F0403141%2Cmath%2F0403367%2Cmath%2F0403325%2Cmath%2F0403034%2Cmath%2F0403262%2Cmath%2F0403453%2Cmath%2F0403169%2Cmath%2F0403021%2Cmath%2F0403415%2Cmath%2F0403459%2Cmath%2F0403383%2Cmath%2F0403437%2Cmath%2F0403500%2Cmath%2F0403286&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We compute the limiting distributions of the largest eigenvalue of a complex\nGaussian sample covariance matrix when both the number of samples and the\nnumber of variables in each sample become large. When all but finitely many,\nsay $r$, eigenvalues of the covariance matrix are the same, the dependence of\nthe limiting distribution of the largest eigenvalue of the sample covariance\nmatrix on those distinguished $r$ eigenvalues of the covariance matrix is\ncompletely characterized in terms of an infinite sequence of new distribution\nfunctions that generalize the Tracy-Widom distributions of the random matrix\ntheory. Especially a phase transition phenomena is observed. Our results also\napply to a last passage percolation model and a queuing model."}, "authors": ["Jinho Baik", "Gerard Ben Arous", "Sandrine Peche"], "author_detail": {"name": "Sandrine Peche"}, "author": "Sandrine Peche", "arxiv_comment": "50 pages, 8 figures", "links": [{"href": "http://arxiv.org/abs/math/0403022v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/math/0403022v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/math/0403022v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/math/0403022v2", "journal_reference": null, "doi": null, "fulltext": "Phase transition of the largest eigenvalue for non-null\n\narXiv:math/0403022v2 [math.PR] 21 Oct 2004\n\ncomplex sample covariance matrices\nJinho Baik \u2217, G\u00e9rard Ben Arous\u2020and Sandrine P\u00e9ch\u00e9\u00b6\u00a7\u2021\nFebruary 1, 2008\n\nAbstract\nWe compute the limiting distributions of the largest eigenvalue of a complex Gaussian sample\ncovariance matrix when both the number of samples and the number of variables in each sample\nbecome large. When all but finitely many, say r, eigenvalues of the covariance matrix are\nthe same, the dependence of the limiting distribution of the largest eigenvalue of the sample\ncovariance matrix on those distinguished r eigenvalues of the covariance matrix is completely\ncharacterized in terms of an infinite sequence of new distribution functions that generalize\nthe Tracy-Widom distributions of the random matrix theory. Especially a phase transition\nphenomena is observed. Our results also apply to a last passage percolation model and a\nqueuing model.\n\n1\n\nIntroduction\n\nConsider M independent, identically distributed samples ~y1 , . . . , ~yM , all of which are N \u00d7 1 column\nvectors. We further assume that the sample vectors ~yk are Gaussian with mean ~\u03bc and covariance\n\u03a3, where \u03a3 is a fixed N \u00d7 N positive matrix; the density of a sample ~y is\np(~y ) =\n\n1\n\n1\n\n(2\u03c0)N/2 (det \u03a3)1/2\n\ne\u2212 2 <~y\u2212~\u03bc,\u03a3\n\n\u22121 (~\ny \u2212~\n\u03bc)>\n\n,\n\n(1)\n\nwhere <, > denotes the inner product of vectors. We denote by l1 , . . . , lN the eigenvalues of\nthe covariance matrix \u03a3, called the 'population eigenvalues'. The sample mean Y is defined by\n\u2217\n\u2020\n\nDepartment of Mathematics, University of Michigan, Ann Arbor, MI, 48109, USA, baik@umich.edu\nDepartment of Mathematics, Courant Institute of Mathematical Sciences, New York, NY, 10012, USA, be-\n\nnarous@cims.nyu.edu\n\u2021\nDepartment of Mathematics Ecole Polyechnique F\u00e9d\u00e9rale de Lausanne, 1015 Lausanne Switzerland, sandrine.peche@epfl.ch; Current address: Institut Fourier, UJF Grenoble 38000 France, sandrine.peche@ujf-grenoble.fr\n\u00a7\nMSC 2000 Subject Classification: 15A52, 41A60, 60F99, 62E20, 62H20\n\u00b6\nKeywords and phrases: sample covariance, limit theorem, Tracy-Widom distribution, Airy kernel, random matrix\n\n1\n\n\fY :=\n\n1\ny1\nM (~\n\n+ * * * + ~yM ) and we set X = [~y1 \u2212 Y , * * * , ~yM \u2212 Y ] to be the (centered) N \u00d7 M sample\n\nmatrix. Let S =\n\n1\n\u2032\nM XX\n\nbe the sample covariance matrix. The eigenvalues of S, called the 'sample\n\neigenvalues', are denoted by \u03bb1 > \u03bb2 > * * * > \u03bbN > 0. (The eigenvalues are simple with probability\n\n1.) The probability space of \u03bbj 's is sometimes called the Wishart ensemble (see e.g. [29]).\n\nContrary to the traditional assumptions, it is of current interest to study the case when N is of\nsame order as M . Indeed when \u03a3 = I (null-case), several results are known. As N, M \u2192 \u221e such\n\nthat M/N \u2192 \u03b3 2 \u2265 1, the following holds.\n\n\u2022 Density of eigenvalues [27]: For any real x,\n\nwhere\nH \u2032 (x) =\n1+\u03b3 2\n2\nand a = ( \u03b3\u22121\n\u03b3 ) and b = ( \u03b3 ) .\n\n1\n#{\u03bbj : \u03bbj \u2264 x} \u2192 H(x)\nN\n\n(2)\n\n\u03b32 p\n(b \u2212 x)(x \u2212 a),\n2\u03c0x\n\n(3)\n\n\u2022 Limit of the largest eigenvalue [15]:\n\u03bb1 \u2192\n\n\u0012\n\n1+\u03b3\n\u03b3\n\n\u00132\n\na.s.\n\n\u2022 Limiting distribution [23]: For any real x,\nP\n\n\u0012\n\na < x < b,\n\n\u03b3M 2/3\n\u03b3 + 1 \u00012 \u0001\n\u2264x\n*\n\u03bb1 \u2212\n\u03b3\n(1 + \u03b3)4/3\n\n\u0013\n\n(4)\n\n\u2192 FGOE (x)\n\n(5)\n\nwhere FGOE (x) is the so-called GOE Tracy-Widom distribution, which is the limiting distribution of the largest eigenvalue of a random real symmetric matrix from the Gaussian\northogonal ensemble (GOE) as the size of the matrix tends to infinity [40].\n\u2022 Robustness to models [35]: It turned out that the Gaussian assumption is unnecessary\nand a result similar to (5) still holds for a quite general class of independent, identically\ndistributed random samples.\nFrom (2) and (4)/(5), we find that the largest sample eigenvalue \u03bb1 in the null case converges to\nthe rightmost edge of support of the limiting density of eigenvalues. However, in practice (see e.g.\n[23]) there often are statistical data for which one or several large sample eigenvalues are separated\nfrom the bulk of the eigenvalues. For instance, see Figure 1 and 2 of the paper [23] which plot\nthe sample eigenvalues of the functional data consisting of a speech dataset of 162 instances of a\nphoneme \"dcl\" spoken by males calculated at 256 points [9]. Other examples of similar phenomena\n2\n\n\finclude mathematical finance [32], [25], [26], wireless communication [37], physics of mixture [34],\nand data analysis and statistical learning [18]. As suggested in [23], this situation poses a natural\nquestion: when \u03a3 6= I (non-null case), how do a few large sample eigenvalues depend on the\n\npopulation eigenvalues? More concretely, if there are a few large population eigenvalues, do they\n\npull to the sample eigenvalues, and for it to happen, how large the population eigenvalues should\nbe?\nThough this might be a challenging problem for real sample data, it turned out that one could\nanswer some of the above questions in great detail for complex Gaussian samples. Complex sample\ncovariance matrix has an application in multi-antenna Gaussian channels in wireless communication\n[37]. Also the results of complex case lead us to a guess for aspects of the real case (see Conjecture in\nsection 1.3 below). Another reason of studying complex sample covariance matrix is its relation to\na last passage percolation model and a queueing theory. See section 6 below for such a connection.\nBefore we present our work, we first summarize some known results for the complex sample\ncovariance matrices.\n\n1.1\n\nSome known results for the eigenvalues of complex sample covariance matrices\n\nWe assume that the samples ~y are complex Gaussian with mean ~\u03bc and covariance \u03a3. Hence the\ndensity of ~y is precisely given by (1) with the understanding that <, > denotes now the complex\ninner product. The (centered) sample matrix X and the sample covariance matrix S =\n\n1\n\u2217\nN XX\n\nare\n\ndefined as before where X \u2217 is the transpose followed by the complex conjugation. Recall that the\neigenvalues of S, sample eigenvalues, are denoted by \u03bb1 \u2265 * * * \u2265 \u03bbN > 0, and the eigenvalues of \u03a3,\npopulation eigenvalues, are denoted by l1 , . . . , lN > 0.\n\n\u2022 Density of eigenvalues [27], [3] (see also Theorem 3.4 of [2]): When all but finitely many\neigenvalues lj of \u03a3 are equal to 1, as M, N \u2192 \u221e such that M/N \u2192 \u03b3 2 \u2265 1, the limiting\n\ndensity of the sample eigenvalues \u03bbj is given by\n1\n#{\u03bbj : \u03bbj \u2264 x} \u2192 H(x)\nN\nwhere H(x) is again defined by (3).\n\n\u2022 Null case : When \u03a3 = I, as M, N \u2192 \u221e such that M/N \u2192 \u03b3 2 \u2265 1, [15]\n\u0013\n\u0012\n1+\u03b3 2\na.s.\n\u03bb1 \u2192\n\u03b3\nand for any real x (see, e.g. [14], [22])\n\u0012\n\u0013\n1 + \u03b3 \u00012 \u0001\n\u03b3M 2/3\nP \u03bb1 \u2212\n*\n\u2264 x \u2192 FGU E (x)\n\u03b3\n(1 + \u03b3)4/3\n3\n\n(6)\n\n(7)\n\n(8)\n\n\fwhere FGU E (x) is the GUE Tracy-Widom distribution, which is the limiting distribution of\nthe largest eigenvalue of a random complex Hermitian matrix from the Gaussian unitary\nensemble (GUE) as the size of the matrix tends to infinity [39]. Moreover, the limit (8) holds\ntrue for a quite general class of independent, identically distributed random samples, after\nsuitable scaling [35].\nRemark 1.1. The distribution function FGU E is different from FGOE . A formula of FGU E (x) is\ngiven in (18) below and a formula for (FGOE (x))2 is given in (24) below.\nRemark 1.2. When \u03a3 = I, the probability space of the eigenvalues \u03bbj of S is sometimes called\nthe Laguerre unitary ensemble (LUE) since the correlation functions of \u03bbj can be represented in\nterms of Laguerre polynomials. Similarly, for real samples with \u03a3 = I, the probability space of the\neigenvalues of S is called the Laguerre orthogonal ensemble (LOE). See e.g. [12].\nNote that the limiting density of the eigenvalues \u03bbj is known for general \u03a3 6= I, but the\n\nconvergence (7)/(8) of \u03bb1 to the edge of the support of the limiting distribution of the eigenvalues\n\nwas obtained only when \u03a3 = I. The following result of P\u00e9ch\u00e9 [31] generalizes (8) and shows that\nwhen all but finitely many eigenvalues lk of \u03a3 are 1 and those distinguished eigenvalues are \"not\ntoo big\", \u03bb1 is still not separated from the rest of the eigenvalues.\n\u2022 When lr+1 = * * * = lN = 1 for a fixed integer r and l1 = * * * = lr < 2 are fixed, as\nM = N \u2192 \u221e, [31]\n\n\u0001\n\u0001\nP \u03bb1 \u2212 4 * 2\u22124/3 M 2/3 \u2264 x \u2192 FGU E (x).\n\n(9)\n\nA natural question is then whether the upper bound 2 of l1 = * * * = lr is critical. One of our\n\nresult in this paper is that it is indeed the critical value. Moreover, we find that if some of lj are\nprecisely equal to the critical value, then the limiting distribution is changed to something new.\nAnd if one or more lj are bigger than the critical value, the fluctuation order M 2/3 is changed to\n\u221a\nthe Gaussian type order M . In order to state our results, we first need some definitions.\n\n1.2\n1.2.1\n\nDefinitions of some distribution functions\nAiry-type distributions\n\nLet Ai(u) be the Airy function which has the integral representation\nZ\n1 3\n1\nAi(u) =\neiua+i 3 a da\n2\u03c0\n\n(10)\n\nwhere the contour is from \u221ee5i\u03c0/6 to \u221eei\u03c0/6 . Define the Airy kernel (see e.g. [39]) by\nA(u, v) =\n\nAi(u)Ai\u2032 (v) \u2212 Ai\u2032 (u)Ai(v)\nu\u2212v\n4\n\n(11)\n\n\fand let Ax be the operator acting on L2 ((x, \u221e)) with kernel A(u, v). An alternative formula of\n\nthe Airy kernel is\n\nA(u, v) =\n\nZ\n\n\u221e\n\nAi(u + z)Ai(z + v)dz,\n\n(12)\n\n0\n\nwhich can be checked directly by using the relation Ai\u2032\u2032 (u) = uAi(u) and integrating by parts. For\nm = 1, 2, 3, . . . , set\ns(m) (u) =\n\n1\n2\u03c0\n\nZ\n\n1 3\n\neiua+i 3 a\n\n1\nda\n(ia)m\n\n(13)\n\nwhere the contour is from \u221ee5i\u03c0/6 to \u221eei\u03c0/6 such that the point a = 0 lies above the contour. Also\n\nset\n\nt\n\n(m)\n\n1\n(v) =\n2\u03c0\n\nZ\n\n1 3\n\neiva+i 3 a (\u2212ia)m\u22121 da\n\n(14)\n\nwhere the contour is from \u221ee5i\u03c0/6 to \u221eei\u03c0/6 . Alternatively,\n\u001b\nZ u\nX \u001a (\u22121)n\n1\n(m)\nl\nm\u22121\ns (u) =\nu +\n(u \u2212 y)\nAi(y)dy\n3n l!n!\n(m \u2212 1)! \u221e\n\n(15)\n\nl+3n=m\u22121\nl,n=0,1,2,...\n\nand\nt\n\n(m)\n\n(v) =\n\n\u0012\n\nd\n\u2212\ndv\n\n\u0013m\u22121\n\nAi(v).\n\n(16)\n\nSee Lemma 3.3 below for the proof that the two formulas of s(m) (u) are the same.\nDefinition 1.1. For k = 1, 2, . . . , define for real x,\n\u0012\nFk (x) = det(1 \u2212 Ax ) * det \u03b4mn \u2212 <\n\n1\ns(m) , t(n) >\n1 \u2212 Ax\n\n\u0013\n\n,\n\n(17)\n\n1\u2264m,n\u2264k\n\nwhere <, > denotes the (real) inner product of functions in L2 ((x, \u221e)). Let F0 (x) = det(1 \u2212 Ax ).\nThe fact that the inner product in (17) makes sense and hence Fk (x) is well-defined is proved\nin Lemma 3.3 below.\nIt is well-known that (see e.g. [14], [39])\nF0 (x) = det(1 \u2212 Ax ) = FGU E (x)\n\n(18)\n\nand hence F0 is the GUE Tracy-Widom distribution function. There is an alternative expression\nof F0 . Let u(x) be the solution to the Painlev\u00e9 II equation\nu\u2032\u2032 = 2u3 + xu\n\n(19)\n\nsatisfying the condition\nu(x) \u223c \u2212Ai(x),\n5\n\nx \u2192 +\u221e.\n\n(20)\n\n\fThere is a unique, global solution [17], and satisfies (see e.g. [17], [10])\n\u0012 \u2212 4 x3/2 \u0013\n2 3/2\ne 3\ne\u2212 3 x\nas x \u2192 +\u221e\nu(x) = \u2212 \u221a 1/4 + O\n2 \u03c0x\nx1/4\nr\n\u0001\n\u2212x\n1 + O(x\u22122 )\nas x \u2192 \u2212\u221e.\nu(x) = \u2212\n2\n\nThen [39]\n\nF0 (x) = det(1 \u2212\n\nA(0)\nx )\n\n\u0012 Z\n= exp \u2212\n\nx\n\n\u221e\n\n(21)\n(22)\n\n\u0013\n\n2\n\n(y \u2212 x)u (y)dy .\n\n(23)\n\nIn addition to being a beautiful identity, the right-hand-side of (23) provides a practical formula\nto plot the graph of F0 .\nFor k = 1, it is known that (see [11], (3.34) of [8])\n\u0012\n\u0013\n1\n(1) (1)\nF1 (x) = det(1 \u2212 Ax )* 1\u2212 <\ns , t > = (FGOE (x))2 .\n1 \u2212 Ax\n\n(24)\n\nThe function FGOE also has a Painlev\u00e9 formula [40] and\n\u0013\n\u0012Z \u221e\nu(y)dy .\nF1 (x) = F0 (x) exp\n\n(25)\n\nx\n\nThe functions Fk , k \u2265 2, seem to be new. The Painlev\u00e9 formula of Fk for general k \u2265 2 will\n\nbe presented in [4]. For each k \u2265 2, Fk (x) is clearly a continuous function in x. Being a limit\n\nof non-decreasing functions as Theorem 1.1 below shows, Fk (x) is a non-decreasing function. It\n\nis also not difficult to check by using a steepest-descent analysis that Fk (x) \u2192 1 as x \u2192 +\u221e (cf.\n\nProof of Lemma 3.3). However, the proof that Fk (x) \u2192 0 as x \u2192 \u2212\u221e is not trivial. The fact that\n\nFk (x) \u2192 0 as x \u2192 \u2212\u221e is obtained in [4] using the Painlev\u00e9 formula. Therefore Fk (x), k \u2265 2, are\ndistribution functions, which generalize the Tracy-Widom distribution functions. (The functions\nF0 , F1 are known to be distribution functions.)\n1.2.2\n\nFinite GUE distributions\n\nConsider the density of k particles \u03be1 , . . . , \u03bek on the real line defined by\np(\u03be1 , . . . , \u03bek ) =\n\n1\nZk\n\nY\n\n1\u2264i<j\u2264k\n\n|\u03bei \u2212 \u03bej |2 *\n\nk\nY\n\n1 2\n\ne\u2212 2 \u03bei\n\n(26)\n\ni=1\n\nwhere Zk is the normalization constant,\nZk :=\n\nZ\n\n\u221e\n\u2212\u221e\n\n***\n\nZ\n\n\u221e\n\nY\n\n\u2212\u221e 1\u2264i<j\u2264k\n\n2\n\n|\u03bei \u2212 \u03bej | *\n\n6\n\nk\nY\ni=1\n\n\u2212 12 \u03bei2\n\ne\n\nk/2\n\nd\u03be1 * * * d\u03bek = (2\u03c0)\n\nk\nY\n\nj=1\n\nj!,\n\n(27)\n\n\fwhich is called the Selberg's integral (see e.g. [28]). This is the density of the eigenvalues of the\nGaussian unitary ensemble (GUE), the probability space of k \u00d7 k Hermitian matrices H whose\n\nentries are independent Gaussian random variables with mean 0 and standard deviation 1 for the\ndiagonal entries, and mean 0 and standard deviation 1/2 for each of the real and complex parts of\n\nthe off-diagonal entries (see e.g. [28]).\nDefinition 1.2. For k = 1, 2, 3, . . . , define the distribution Gk (x) by\nGk (x) =\n\n1\nZk\n\nZ\n\nx\n\n\u2212\u221e\n\n***\n\nZ\n\nY\n\nx\n\n\u2212\u221e 1\u2264i<j\u2264k\n\n|\u03bei \u2212 \u03bej |2 *\n\nk\nY\ni=1\n\n1 2\n\ne\u2212 2 \u03bei d\u03be1 * * * d\u03bek .\n\n(28)\n\nIn other words, Gk is the distribution of the largest eigenvalue of k \u00d7 k GUE. When k = 1, this\n\nis the Gaussian distribution,\n\n1\nG1 (x) = \u221a\n2\u03c0\n\nZ\n\nx\n\n1 2\n\ne\u2212 2 \u03be1 d\u03be1 = erf (x).\n\n(29)\n\n\u2212\u221e\n\nThere is an alternative expression of Gk in terms of a Fredholm determinant similar to the formula\n(17) of Fk . Let pn (x) = cn xn + * * * be the polynomial of degree n (cn > 0 is the leading coefficient)\n\ndetermined by the orthogonality condition\nZ \u221e\n1 2\npm (x)pn (x)e\u2212 2 x dx = \u03b4mn .\n\n(30)\n\n\u2212\u221e\n\nThe orthonormal polynomial pn is given by\npn (\u03be) :=\n\n1\n\n\u03be\n\u221a Hn ( \u221a ),\n2\n(2\u03c0)1/4 2n/2 n!\n\n(31)\n\nwhere Hn is the Hermite polynomial. The leading coefficient cn of pn is (see e.g. [24])\ncn =\n\n1\n(2\u03c0)1/4\n\n\u221a .\nn!\n\n(32)\n\nThen the so-called orthogonal polynomial method in the random matrix theory establishes that:\nLemma 1.1. For any k = 1, 2, . . . and x \u2208 R,\nGk (x) = det(1 \u2212 H(k)\nx ),\n\n(33)\n\n(k)\n\nwhere Hx is the operator acting on L2 ((x, \u221e)) defined by the kernel\nH(k) (u, v) =\n\nck\u22121 pk (u)pk\u22121 (v) \u2212 pk\u22121 (u)pk (v) \u2212(u2 +v2 )/4\ne\n.\nck\nu\u2212v\n\n(34)\n\nThis is a standard result in the theory of random matrices. The proof can be found, for example,\n(k)\n\nin [28], [41]. There is also an identity of the form (23) for det(1 \u2212 Hx ), now in terms of Painlev\u00e9\nIV equation. See [38].\n\n7\n\n\f1.3\n\nMain Results\n\nWe are now ready to state our main results.\nTheorem 1.1. Let \u03bb1 be the largest eigenvalue of the sample covariance matrix constructed from M\nindependent, identically distributed complex Gaussian sample vectors of N variables. Let l1 , * * * , lN\n\ndenote the eigenvalues of the covariance matrix of the samples. Suppose that for a fixed integer\nr \u2265 0,\n\nlr+1 = lr+2 = * * * = lN = 1.\n\n(35)\n\nAs M, N \u2192 \u221e while M/N = \u03b3 2 is in a compact subset of [1, \u221e), the following holds for any real\nx in a compact set.\n\n(a) When for some 0 \u2264 k \u2264 r,\n\nl1 = * * * = lk = 1 + \u03b3 \u22121\n\n(36)\n\nand lk+1 , . . . , lr are in a compact subset of (0, 1 + \u03b3 \u22121 ),\n\u0012\n\u0013\n\u0001\n\u03b3\n\u22121 2\n2/3\nP \u03bb1 \u2212 (1 + \u03b3 ) *\nM\n\u2264 x \u2192 Fk (x).\n(1 + \u03b3)4/3\n\n(37)\n\nwhere Fk (x) is defined in (17).\n(b) When for some 1 \u2264 k \u2264 r,\n\nl1 = * * * = lk is in a compact set of (1 + \u03b3 \u22121 , \u221e)\nand lk+1 , . . . , lr are in a compact subset of (0, l1 ),\n\u221a\n\u0012\n\u0013\nM\nl1 \u03b3 \u22122 \u0001\u0001\nP \u03bb1 \u2212 l 1 +\n\u2264 x \u2192 Gk (x)\n*q\nl2 \u03b3 \u22122\nl1 \u2212 1\nl2 \u2212 1\n1\n\n(38)\n\n(39)\n\n(l1 \u22121)2\n\nwhere Gk (x) is defined in (28).\n\nHence, for instance, when r = 2,\nl3 = * * * = lN = 1\n\n(40)\n\nand there are two distinguished eigenvalues l1 and l2 of the covariance matrix. Assume without\nloss of generality that l1 \u2265 l2 . Then\n\nP\n\n\u0012\n\n\u0001\n\u03bb1 \u2212 (1 + \u03b3 \u22121 )2 *\n\n\u03b3\nM 2/3 \u2264 x\n(1 + \u03b3)4/3\n\n8\n\n\u0013\n\n\u2192\n\n\uf8f1\n\uf8f4\nF0 (x),\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3\n\n0 < l1 , l2 < 1 + \u03b3 \u22121\n\nF1 (x),\n\n0 < l2 < 1 + \u03b3 \u22121 = l1\n\nF2 (x),\n\nl1 = l2 = 1 + \u03b3 \u22121\n\n(41)\n\n\fand\nP\n\n\u0012\n\n\uf8f1\n\u221a\n\u0013\n\uf8f2G1 (x),\nM\nl1 \u03b3 \u22122 \u0001\u0001\n\u2264\nx\n\u2192\n\u03bb1 \u2212 l 1 +\n*q\nl2 \u03b3 \u22122\n\uf8f3G (x),\nl1 \u2212 1\nl21 \u2212 (l11 \u22121)2\n2\n\nl1 > 1 + \u03b3 \u22121 , l1 > l2\nl1 = l2 > 1 + \u03b3 \u22121 ,\n\n(42)\n\nassuming that l1 , l2 are in compact sets in each case. See Figure 1 for a diagram.\n\n\u03c0\u221212\n\nG2\nG1\n\n1+\u03b3 \u22121\n\nF2\n\nF1\n\nF1\n\nF0\n0\n\nG1\n\n1+\u03b3 \u22121\n\n\u03c01\u22121\n\nFigure 1: Diagram of the limiting distributions for various choices of l1 = \u03c01\u22121 and l2 = \u03c02\u22121 while\nl3 = * * * = lN = 1.\nNote the different fluctuation orders M 2/3 and\n\n\u221a\n\nM depending on the values of l1 , l2 . This type\n\nof 'phase transition' was also observed in [7, 5, 33] for different models in combinatorics and last\npassage percolation, in which a few limiting distribution functions were also computed depending\non parameters. But the functions Fk , k \u2265 2, in Theorem 1.1 seem to be new in this paper. The\n\nlast passage percolation model considered in [5, 33] has some relevance to our problem; see Section\n6 below.\n\nTheorem 1.1 and the fact that Fk and Gk are distribution functions yield the following consequence.\nCorollary 1.1. Under the same assumption of Theorem 1.1, the following holds.\n(a) When for some 0 \u2264 k \u2264 r\n\nl1 = * * * = lk = 1 + \u03b3 \u22121 ,\n\n(43)\n\nand lk+1 , . . . , lr are in a compact subset of (0, 1 + \u03b3 \u22121 ),\n\u03bb1 \u2192 (1 + \u03b3 \u22121 )2\n9\n\nin probability.\n\n(44)\n\n\f(b) When for some 1 \u2264 k \u2264 r,\n\nl1 = * * * = lk > 1 + \u03b3 \u22121\n\nand lk+1 , . . . , lr are in a compact subset of (0, l1 ),\n\u0012\n\u0013\n\u03b3 \u22122\n\u03bb1 \u2192 l 1 1 +\nin probability.\nl1 \u2212 1\n\n(45)\n\n(46)\n\nProof. Suppose we are in the case of (a). For any fixed \u01eb > 0 and x \u2208 R,\nlim sup P \u03bb1 \u2264 (1 \u2212 \u01eb)(1 + \u03b3\n\n\u22121 2\n\n)\n\nM \u2192\u221e\n\nBy taking x \u2192 \u2212\u221e, we find that\n\n\u0001\n\n\u0013\n\u0012\nxM 1/3 \u03b3\n\u22121 2\n= Fk (x).\n\u2264 lim sup P \u03bb1 \u2264 (1 + \u03b3 ) +\n(1 + \u03b3)4/3\nM \u2192\u221e\n\n\u0001\nlim P \u03bb1 \u2264 (1 \u2212 \u01eb)(1 + \u03b3 \u22121 )2 = 0.\n\nM \u2192\u221e\n\n(47)\n\n(48)\n\n\u0001\nSimilar arguments implies that P \u03bb1 \u2265 (1 + \u01eb)(1 + \u03b3 \u22121 )2 \u2192 0. The case of (b) follows from the\nsame argument.\n\nTogether with (6), Theorem 1.1/Corollary 1.1 imply that under the Gaussian assumption, when\nall but finitely many eigenvalues of \u03a3 are 1, \u03bb1 is separated from the rest of eigenvalues if and only\nif at least one eigenvalue of \u03a3 is greater than 1 + \u03b3 \u22121 . Theorem 1.1 also claims that when \u03bb1 is\nseparated from the rest, the fluctuation of \u03bb1 is of order M 1/2 rather than M 2/3 . Here the critical\nvalue 1 + \u03b3 \u22121 comes from a detail of computations and we do not have an intuitive reason yet.\nHowever, see Section 6 below for a heuristic argument from a last passage percolation model.\nCompare the case (b) of Theorem 1.1/Corollary 1.1 with the following result for samples of\nfinite number of variables.\nProposition 1.1. Suppose that there are M samples of N = k variables. Assume that all the\neigenvalues of the covariance matrix are the same;\nl1 = * * * = lk .\nThen for fixed N = k, as M \u2192 \u221e,\nlim P\n\nM \u2192\u221e\n\nand\n\n\u0012\n\n\u00011\u221a\n\u03bb1 \u2212 l 1\nMx\nl1\n\n\u03bb1 \u2192 l1\n\n(49)\n\n\u0013\n\n= Gk (x)\n\nin probability.\n\n10\n\n(50)\n\n(51)\n\n\fThis result shows that the model in the case (b) of Theorem 1.1/Corollary 1.1 is not entirely\ndominated by the distinguished eigenvalues l1 = * * * = lk of the covariance matrix. Instead the\n\ncontribution to \u03bb1 comes from both l1 = * * * = lk and infinitely many unit eigenvalues. The proof\n\nof Proposition 1.1 is given in section 5.\n\nFurther detailed analysis along the line of this paper would yield the convergence of the moments\nof \u03bb1 under the scaling of Theorem 1.1. This will be presented somewhere else.\nThe real question is the real sample covariance. In the null cases, by comparing (5) and (8), we\nnote that even though the limiting distributions are different, the scalings are identical. In view of\nthis, we conjecture the following:\nConjecture. For real sample covariance, the Theorem 1.1 still holds true for different limiting\ndistributions but with the same scaling. In particular, the critical value of distinguished eigenvalues\nlj of the covariance matrix is again expected to be 1 + \u03b3 \u22121 .\n\n1.4\n\nAround the transition point; interpolating distributions\n\nWe also investigate the nature of the transition at lj = 1 + \u03b3 \u22121 . The following result shows that if\nlj themselves scale properly in M , there are interpolating limiting distributions.\nWe first need more definitions. For m = 1, 2, 3, . . . , and for w1 , . . . , wm \u2208 C, set\ns\n\n(m)\n\n1\n(u; w1 , . . . , wm ) =\n2\u03c0\n\nZ\n\n1 3\n\neiua+i 3 a\n\nm\nY\n\nj=1\n\n1\nda\nwj + ia\n\n(52)\n\nwhere the contour is from \u221ee5i\u03c0/6 to \u221eei\u03c0/6 such that the points a = iw1 , . . . , iwm lie above the\n\ncontour. Also set\n\nt\n\n(m)\n\n1\n(v; w1 , . . . , wm\u22121 ) =\n2\u03c0\n\nZ\n\n1 3\n\neivb+i 3 b\n\nm\u22121\nY\nj=1\n\n(wj \u2212 ib) db\n\n(53)\n\nwhere the contour is from \u221ee5i\u03c0/6 to \u221eei\u03c0/6 .\nDefinition 1.3. For k = 1, 2, . . . , define for real x and w1 , . . . , wk ,\nFk (x; w1 , . . . , wk )\n\u0012\n\u0001\n= det 1 \u2212 Ax * det 1\u2212 <\n\n1\ns(m) (w1 , . . . , wm ), t(n) (w1 , . . . , wn\u22121 ) >\n1 \u2212 Ax\n\n\u0013\n\n.\n\n(54)\n\n1\u2264m,n\u2264k\n\nThe function F1 (x; w) previously appeared in [13] in a disguised form. See (4.18) and (4.12) of\n[13]\n\n11\n\n\fThe formula (54) may seem to depend on the ordering of the parameters w1 , . . . , wk . But as\nthe following result (56) shows, it is independent of the ordering of the parameters. This can also\nbe seen from a formula of [4].\nLike Fk , it is not difficult to check that the function Fk (x; w1 , . . . , wk ) is continuous, nondecreasing and becomes 1 as x \u2192 +\u221e. The proof that Fk (x; w1 , . . . , wk ) \u2192 0 as x \u2192 \u2212\u221e is in [4].\n\nTherefore, Fk (x; w1 , . . . , wk ) is a distribution function. It is direct to check that Fk (x; w1 , . . . , wk ) interpolates F0 (x), . . . , Fk (x). For example, limw2 \u2192+\u221e F2 (x, 0, w2 ) = F1 (x), limw1 \u2192+\u221e limw2 \u2192+\u221e F2 (x; w1 , w2 ) =\nF0 (x), etc.\nTheorem 1.2. Suppose that for a fixed r, lr+1 = lr+2 = * * * = lN = 1. Set for some 1 \u2264 k \u2264 r,\nlj = 1 + \u03b3 \u22121 \u2212\n\n(1 + \u03b3)2/3 wj\n,\n\u03b3M 1/3\n\nj = 1, 2, . . . , k.\n\n(55)\n\nWhen wj , 1 \u2264 j \u2264 k, is in a compact subset of R, and lj , k + 1 \u2264 j \u2264 r, is in a compact subset of\n\n(0, 1 + \u03b3 \u22121 ), as M, N \u2192 \u221e such that M/N = \u03b3 2 is in a compact subset of [1, \u221e),\n\u0013\n\u0012\n\u0001\n\u03b3\n2/3\nM\n\u2264\nx\n\u2192 Fk (x; w1 , . . . , wk )\nP \u03bb1 \u2212 (1 + \u03b3 \u22121 )2 *\n(1 + \u03b3)4/3\n\n(56)\n\nfor any x in a compact subset of R.\n\nThe Painlev\u00e9 II-type expression for Fk (x; w1 , . . . , wk ) will be presented in [4].\nThis paper is organized as follows. The basic algebraic formula of the distribution of \u03bb1 in\nterms of a Fredholm determinant is given in Section 2, where an outline of the asymptotic analysis\nof the Fredholm determinant is also presented. The proofs of Theorem 1.1 (a) and Theorem 1.2\nare given in Section 3. The proof of Theorem 1.1 (b) is in Section 4 and the proof of Proposition\n1.1 is presented in Section 5. In Section 6, we indicate a connection between the sample covariance\nmatrices, and a last passage percolation model and also a queueing theory.\nNotational Remark. Throughout the paper, we set\n\u03c0j = l\u22121\nj .\n\n(57)\n\nThis is only because the formulas below involving l\u22121\nj become simpler with \u03c0j .\nAcknowledgments. Special thanks is due to Iain Johnstone for kindly explaining the importance\nof computing the largest eigenvalue distribution for non-null covariance case and also for his constant\ninterest and encouragement. We would like to thank Kurt Johansson for sharing with us his proof\nof Proposition 2.1 below, Eric Rains for useful discussions and also Debashis Paul for finding a\ntypographical error in the main theorem in an earlier draft. The work of the first author was\nsupported in part by NSF Grant # DMS-0350729.\n12\n\n\f2\n\nBasic formulas\n\nNotational Remark. The notation V (x) denotes the Vandermonde determinant\nV (x) =\n\nY\n(xi \u2212 xj )\n\n(58)\n\ni<j\n\nof a (finite) sequence x = (x1 , x2 , . . . ).\n\n2.1\n\nEigenvalue density; algebraic formula\n\nFor complex Gaussian samples, the density of the sample covariance matrix is already known to\nWishart around 1928 (see e.g. [29]):\np(S) =\n\n1 \u2212M *tr(\u03a3\u22121 S)\ne\n(det S)M \u2212N\nC\n\n(59)\n\nfor some normaliztion constant C > 0. As \u03a3 and S are Hermitian, we can set \u03a3 = U DU \u22121 and\n\u22121\n)\nS = HLH \u22121 where U and H are unitary matrices, D = diag(l1 , * * * , lN ) = diag(\u03c01\u22121 , * * * , \u03c0N\n\nand L = diag(\u03bb1 , * * * , \u03bbN ). By taking the change of variables S 7\u2192 (L, H) using the Jacobian\n\nformula dS = cV (L)2 dLdH for some constant c > 0, and then integrating over H, the density of\nthe eigenvalues is (see, e.g. [19])\nN\n\nY\n1\n\u2212N\np(\u03bb) = V (\u03bb)2\n\u03bbM\n*\nj\nC\nj=1\n\nZ\n\ne\u2212M *tr(D\n\n\u22121 QLQ\u22121 )\n\ndQ.\n\n(60)\n\nQ\u2208U (N )\n\nfor some (new) constant C > 0 where U (N ) is the set of N \u00d7 N unitary matrices and \u03bb =\n(\u03bb1 , . . . , \u03bbN ). The last integral is known as Harish-Chandra-Itzykson-Zuber integral (see e.g. [28])\nand we find\n\nN\n\nY\n1 det(e\u2212M \u03c0j \u03bbk )1\u2264j,k\u2264N\n\u2212N\n\u03bbM\n.\np(\u03bb) =\nV (\u03bb)\nj\nC\nV (\u03c0)\n\n(61)\n\nj=1\n\nHere when some of \u03c0j 's coincide, we interpret the formula using the l'Hopital's rule. We note that\nfor a real sample covariance matrix, it is not known if the corresponding integral over the orthogonal\ngroup O(N ) is computable as above. Instead one usually define hypergeometric functions of matrix\nargument and study their algebraic properties (see e.g. [29]). Consequently, the techniques below\nthat we will use for the density of the form (61) is not applicable to real sample matrices.\nFor the density (61), the distribution function of the largest eigenvalue \u03bb1 can be expressed in\nterms of a Fredholm determinant, which will be the starting point of our asymptotic analysis. The\nfollowing result can be obtained by suitably re-interpreting and taking a limit of a result of [30].\nA different proof is given in [31]. For the convenience of reader we include yet another proof by\nJohansson [20] which uses an idea from random matrix theory (see e.g. [41]).\n13\n\n\fProposition 2.1. For any fixed q satisfying 0 < q < min{\u03c0j }N\nj=1 , let KM,N |(\u03be,\u221e) be the operator\n\nacting on L2 ((\u03be, \u221e)) with kernel\nKM,N (\u03b7, \u03b6) =\n\nM\n(2\u03c0i)2\n\nZ\n\ndz\n\n\u0393\n\nZ\n\ndw e\u2212\u03b7M (z\u2212q)+\u03b6M (w\u2212q)\n\u03a3\n\nN\n1\nz \u0001M Y \u03c0k \u2212 w\nw\u2212z w\n\u03c0k \u2212 z\n\n(62)\n\nk=1\n\nwhere \u03a3 is a simple closed contour enclosing 0 and lying in {w : Re(w) < q}, and \u0393 is a simple\n\nclosed contour enclosing \u03c01 , . . . , \u03c0N and lying {z : Re(z) > q}, both oriented counter-clockwise (see\n\nFigure 2). Then for any \u03be \u2208 R,\n\nP(\u03bb1 \u2264 \u03be) = det(1 \u2212 KM,N |(\u03be,\u221e) ).\n\n(63)\n\n\u0393\n\n\u03a3\n0\n\n\u03c01\n\nq\n\n\u03c02\n\n\u03c03 \u03c04\n\nFigure 2: Contours \u0393 and \u03a3\nRemark 2.1. Note that the left-hand-side of (63) does not depend on the parameter q. The Fredholm\ndeterminant on the right-hand-side of (63) is also independent of the choice of q as long as 0 <\nq < min{\u03c0j }N\nj=1 . If we use the notation Kq to denote KM,N |(\u03be,\u221e) for the parameter q, then\n\u2032\n\n\u2032\n\nKq\u2032 = EKq E\u22121 where E is the multiplication by e(q \u2212q)\u03bb ; (Ef )(\u03bb) = e(q \u2212q)\u03bb f (\u03bb). But determinants\nare invariant under conjugations as long as both Kq\u2032 and EKq E\u22121 are in the trace class, which is\nthe case when 0 < q, q \u2032 < min{\u03c0j }N\nj=1 . The parameter q ensures that the kernel KM,N (\u03b7, \u03b6) is finite\n\nwhen \u03b7 \u2192 +\u221e or \u03b6 \u2192 +\u221e and the operator KM,N |(\u03be,\u221e) is trace class. It also helps the proof of\n\nthe convergence of the operator in the next section.\n\nProof. For a moment we assume that all \u03c0j 's are distinct. Note that the density (61) is symmetric\nin \u03bbj 's. Hence using V (\u03bb) = det(\u03bbkj\u22121 ), we find that\nP(\u03bb1 \u2264 \u03be) =\n\n1\nC\u2032\n\nZ\n\n\u221e\n0\n\n***\n\nZ\n\n\u221e\n0\n\ndet(\u03bbkj\u22121 ) det(e\u2212M \u03c0j \u03bbk )\n\nN\nY\n\n\u2212N\n(1 \u2212 \u03c7(\u03be,\u221e) (\u03bbk ))\u03bbM\nd\u03bbk\nk\n\nk=1\n\n14\n\n(64)\n\n\fwith some constant C \u2032 > 0, where \u03c7(\u03be,\u221e) denotes the characteristic function (indicator function).\nUsing the fundamental identity which dates back to [1],\n\u0013\n\u0012Z\nZ\nZ\nY\n* * * det(fj (xk )) det(gj (xk ))\nfj (x)gk (x)d\u03bc(x) ,\nd\u03bc(xk ) = det\n\n(65)\n\nk\n\nwe find\n\n1\nP(\u03bb1 \u2264 \u03be) = \u2032 det\nC\n\n\u0012Z\n\n\u221e\n0\n\nj\u22121+M \u2212N \u2212M \u03c0k \u03bb\n\n(1 \u2212 \u03c7(\u03be,\u221e) (\u03bb))\u03bb\n\ne\n\nd\u03bb\n\n\u0013\n\n.\n\n(66)\n\n1\u2264j,k\u2264N\n\nNow set \u03bd = M \u2212 N , \u03c6j (\u03bb) = \u03bbj\u22121+\u03bd e\u2212M q\u03bb and \u03a6k (\u03bb) = e\u2212M (\u03c0k \u2212q)\u03bb for any q such that 0 < q <\nmin{\u03c0j }N\nj=1 . Also let\n\nA = (Ajk )1\u2264j,k\u2264N ,\n\nAjk =\n\nZ\n\n\u221e\n\n\u03c6j (\u03bb)\u03a6k (\u03bb)d\u03bb =\n\n0\n\n\u0393(j + \u03bd)\n.\n(M \u03c0k )j+\u03bd\n\n(67)\n\nA direct computation shows that\ndet A =\n\nN\nN\nY\nY\n\u0393(j + \u03bd)\n\u0393(j + \u03bd)\n\u2212(j\u22121)\n*\ndet((M\n\u03c0\n)\n)\n=\n*\nj\n\u03bd+1\n(M \u03c0j )\n(M \u03c0j )\u03bd+1\nj=1\n\nj=1\n\nY\n\n1\u2264j<k\u2264N\n\n((M \u03c0j )\u22121 \u2212 (M \u03c0k )\u22121 ). (68)\n\nThus A is invertible. Also define the operators B : L2 ((0, \u221e)) \u2192 l2 ({1, . . . , N }), C : l2 ({1, . . . , N }) \u2192\n\nL2 ((0, \u221e)) by\n\nB(j, \u03bb) = \u03c6j (\u03bb),\n\nC(\u03bb, k) = \u03a6k (\u03bb)\n\n(69)\n\nand let P\u03be be the projection from (0, \u221e) to (\u03be, \u221e). Then as\nZ \u221e\n\u03c7(\u03be,\u221e) (\u03bb)\u03bbj\u22121+M \u2212N e\u2212M \u03c0k \u03bb d\u03bb = (BP\u03be C)(j, k),\n\n(70)\n\n0\n\nwe find that\nP(\u03bb1 \u2264 \u03be) =\n\n1\ndet(A \u2212 BP\u03be C).\nC\u2032\n\n(71)\n\nSo,\nP(\u03bb1 \u2264 \u03be) =\n\ndet(A)\ndet(1 \u2212 A\u22121 BP\u03be C) = C \u2032\u2032 det(1 \u2212 P\u03be CA\u22121 B) = C \u2032\u2032 det(1 \u2212 P\u03be CA\u22121 BP\u03be ) (72)\nC\u2032\n\nfor some constant C \u2032\u2032 which does not depend on \u03be. But by letting \u03be \u2192 +\u221e in both sides of (72),\n\nwe easily find that C \u2032\u2032 = 1. The kernel of the operator in the determinant is\n\u22121\n\n(CA\n\nB)(\u03b7, \u03b6) =\n\nN\nX\n\nC(\u03b7, j)(A\u22121 B)(j, \u03b6),\n\n\u03b7, \u03b6 > \u03be,\n\n(73)\n\nj=1\n\nand from the Cramer's rule,\n(A\u22121 B)(j, \u03b6) =\n15\n\ndet A(j) (\u03b6)\ndet A\n\n(74)\n\n\fwhere A(j) (\u03b6) is the matrix given by A with jth column replaced by the vector (\u03c61 (\u03b6), * * * , \u03c6N (\u03b6))T .\nTo compute A(j) , note (the Hankel's formula for Gamma function) that for a positive integer a\nZ w\ne\n1\n1\n1\n=\n(75)\ndw =\na\n2\u03c0i \u03a3 w\n(a \u2212 1)!\n\u0393(a)\n\nwhere \u03a3 is any simple closed contour enclosing the origin 0 with counter-clockwise orientation. By\nreplacing w \u2192 \u03b6M w and setting a = j + \u03bd, this implies that\nZ\n\u0393(j + \u03bd)\nM\nj\u22121+\u03bd\n\u03b6\n=\ne\u03b6M w\ndw.\n2\u03c0i\n(M w)j+\u03bd\n\u03a3\n\n(76)\n\nSubstituting this formula for \u03c6j (\u03b6) in the jth column of A(j) , and pulling out the integrals over w,\nZ\n1\ndet A(j) (\u03b6) =\ne\u03b6M (w\u2212q) det(A\u2032 (w))M dw\n(77)\n2\u03c0i \u03a3\nwhere pb = M \u03c0b when b 6= j and pb = M w\nwhere the entries of A\u2032 (w) are A\u2032ab (w) = \u0393(a + \u03bd)/pa+\u03bd\nb\nwhen b = j. Hence\n(j)\n\ndet A\n\n(\u03b6) =\n\nY\n\nk6=j\n\nN\n\nY\n1\n1\n*\n\u0393(k + \u03bd) *\n1+\u03bd\n(M \u03c0k )\n2\u03c0i\nk=1\n\nZ\n\ne\u03b6M (w\u2212q)\n\u03a3\n\nY\n\n1\u2264a<b\u2264N\n\n\u22121\n(p\u22121\na \u2212 pb )\n\nM dw\n, (78)\n(M w)1+\u03bd\n\nand so using (68),\n\u22121\n\n(A\n\nB)(j, \u03b6) =\n\nM \u03c0jN +\u03bd\n2\u03c0i\n\nZ\n\ne\u03b6M (w\u2212q)\n\u03a3\n\nY w \u2212 \u03c0k dw\n.\n\u03c0j \u2212 \u03c0k wN +\u03bd\n\n(79)\n\nk6=j\n\nBut for any simple closed contour \u0393 that encloses \u03c01 , . . . , \u03c0N but excludes w, and is oriented\ncounter-clockwise,\n1\n2\u03c0i\n\nZ\n\nz M e\u2212\u03b7M z\n\u0393\n\nN\nN\nY w \u2212 \u03c0k\nX\n1 Y w \u2212 \u03c0k\n\u03c0jM e\u2212M \u03c0j \u03b7\ndz =\n.\nw\u2212z\nz \u2212 \u03c0k\n\u03c0j \u2212 \u03c0k\nj=1\n\nk=1\n\n(80)\n\nk6=j\n\nTherefore, we find (note N + \u03bd = M )\n\u22121\n\n(CA\n\nM\nB)(\u03b7, \u03b6) =\n(2\u03c0i)2\n\nZ\n\ndz\n\u0393\n\nZ\n\ndw e\u2212\u03b7M (z\u2212q)+\u03b6M (w\u2212q)\n\n\u03a3\n\nN\n1 Y w \u2212 \u03c0k\nz \u0001M\n*\nw\u2212z\nz \u2212 \u03c0k\nw\n\n(81)\n\nk=1\n\nwhich completes the proof when all \u03c0j 's are distinct. When some of \u03c0j 's are identical, the result\nfollows by taking proper limits and using the l'Hospital's theorem.\nNote that for z \u2208 \u0393 and w \u2208 \u03a3, Re(w \u2212 z) < 0. Hence using\nZ \u221e\n1\neyM (w\u2212q\u2212(z\u2212q)) dy\n= \u2212M\nw\u2212z\n0\n16\n\n(82)\n\n\ffor 1/(w \u2212 z) in (62), the kernel KM,N (\u03b7, \u03b6) is equal to\nZ \u221e\nH(\u03b7 + y)J(\u03b6 + y)dy\nKM,N (\u03b7, \u03b6) =\n\n(83)\n\n0\n\nwhere\nM\nH(\u03b7 + y) =\n2\u03c0\nand\nM\nJ(\u03b6 + y) =\n2\u03c0\n\n2.2\n\nZ\n\nZ\n\n\u2212(\u03b7+y)M (z\u2212q) M\n\ne\n\nz\n\n\u0393\n\nN\nY\n\n1\ndz\n\u03c0k \u2212 z\n\n(84)\n\n(\u03c0k \u2212 w)dw.\n\n(85)\n\nk=1\n\ne(\u03b6+y)M (w\u2212q) w\u2212M\n\n\u03a3\n\nN\nY\n\nk=1\n\nAsymptotic analysis: basic ideas\n\nFrom now on, as mentioned in the Introduction, we assume that\n\u03c0r+1 = * * * = \u03c0N = 1.\n\n(86)\n\nIn this case, (82), (84) and (85) become\nKM,N (\u03b7, \u03b6) =\nwhere\nM\nH(\u03b7) =\n2\u03c0\n\nZ\n\nM\nJ(\u03b6) =\n2\u03c0\n\nZ\n\nand\n\nSet\n\nZ\n\n\u221e\n\nH(\u03b7 + y)J(\u03b6 + y)dy\nr\nY\nzM\n1\ndz\nN\n\u2212r\n(1 \u2212 z)\n\u03c0k \u2212 z\n\n(88)\n\nr\n(1 \u2212 z)N \u2212r Y\n(\u03c0k \u2212 z)dz.\nzM\n\n(89)\n\ne\u2212M \u03b7(z\u2212q)\n\u0393\n\nk=1\n\neM \u03b6(z\u2212q)\n\u03a3\n\n(87)\n\n0\n\nk=1\n\nM\n= \u03b3 2 \u2265 1.\n(90)\nN\nFor various choices of \u03c0j , 1 \u2264 j \u2264 r, we will consider the limit of P(\u03bb1 \u2264 \u03be) when \u03be is scaled as of\n\nthe form (see Theorem 1.1)\n\n\u03bdx\n(91)\nM\u03b1\nfor some constants \u03bc = \u03bc(\u03b3), \u03bd = \u03bd(\u03b3) and for some \u03b1, while x is a fixed real number. By translation\n\u03be =\u03bc+\n\nand scaling, the equation (63) becomes\n\u0012\n\u0013\n\u03bdx\nP \u03bb1 \u2264 \u03bc + \u03b1 = det(1 \u2212 KM,N |(\u03bc+ M\u03bdx\u03b1 ,\u221e) ) = det(1 \u2212 KM,N )\nM\nwhere KM,N is the operator acting on L2 ((0, \u221e)) with kernel\n\u0013\n\u0012\n\u03bd(x + u)\n\u03bd(x + u)\n\u03bd\n,\u03bc +\n.\nKM,N (u, v) = \u03b1 KM,N \u03bc +\nM\nM\u03b1\nM\u03b1\n17\n\n(92)\n\n(93)\n\n\fUsing (87), this kernel is equal to\nKM,N (u, v) =\nwhere\n\nand\n\n\u03bdM 1\u2212\u03b1\nH(u) =\n2\u03c0\n\nZ\n\n\u03bdM 1\u2212\u03b1\nJ (v) =\n2\u03c0\n\nZ\n\nZ\n\n\u221e\n\n0\n\nH(x + u + y)J (x + v + y)dy\n\n\u2212\u03bdM 1\u2212\u03b1 u(z\u2212q) \u2212M \u03bc(z\u2212q)\n\ne\n\ne\n\n\u0393\n\n(94)\n\nr\nY\nzM\n1\ndz\nN\n\u2212r\n(1 \u2212 z)\n\u03c0l \u2212 z\n\n(95)\n\nr\n\u2212 w)N \u2212r Y\n(\u03c0l \u2212 w)dw.\nwM\n\n(96)\n\nl=1\n\n\u03bdM 1\u2212\u03b1 v(w\u2212q) M \u03bc(w\u2212q) (1\n\ne\n\ne\n\n\u03a3\n\nl=1\n\nWe need to find limits of KM,N (u, v) for various choices of \u03c0j 's as M, N \u2192 \u221e. A sufficient\n\ncondition for the convergence of a Fredholm determinant is the convergence in trace norm of the\noperator. As KM,N is a product of two operators, it is enough to prove the convergences of H and\nJ in Hilbert-Schmidt norm. Hence in sections 3 and 4 below, we will prove that for proper choices\n\nof \u03bc, \u03bd and \u03b1, there are limiting operators H\u221e and J\u221e acting on L2 ((0, \u221e)) such that for any real\nx in a compact set,\n\nZ\nand\n\n0\n\nZ\n\n\u221eZ \u221e\n\nZM HM,N (x + u + y) \u2212 H\u221e (x + u + y) dudy \u2192 0\n\n(97)\n\n\u221eZ \u221e\n\n1\n2\nJM,N (x + u + y) \u2212 J\u221e (x + u + y) dudy \u2192 0\nZM\n\n(98)\n\n0\n\n0\n\n0\n\n2\n\nfor some non-zero constant ZM as M, N \u2192 \u221e satisfying (90) for \u03b3 in a compact set. We will use\nsteepest-descent analysis.\n\n3\n\nProofs of Theorem 1.1 (a) and Theorem 1.2\n\nWe first consider the proof of Theorem 1.1 (a). The proof of Theorem 1.2 will be very similar (see\nthe subsection 3.4 below). We assume that for some 0 \u2264 k \u2264 r,\n\u03c01\u22121 = * * * = \u03c0k\u22121 = 1 + \u03b3 \u22121\n\n(99)\n\n\u22121\nand \u03c0k+1\n\u2265 * * * \u2265 \u03c0r\u22121 are in a compact subset of (0, 1 + \u03b3 \u22121 ).\n\nFor the scaling (91), we take\n\n\u03b1 = 2/3\nand\n\u03bc = \u03bc(\u03b3) :=\n\n\u0012\n\n1+\u03b3\n\u03b3\n\n\u00132\n\n,\n\n\u03bd = \u03bd(\u03b3) :=\n\n18\n\n(100)\n(1 + \u03b3)4/3\n\u03b3\n\n(101)\n\n\fso that\n\n\u03bdx\n.\n(102)\nM 2/3\nThe reason for such choices will be made clear during the following asymptotic analysis. There is\n\u03be =\u03bc+\n\nstill an arbitrary parameter q. It will be chosen in (118) below.\nThe functions (95) and (96) are now\nH(u) =\n\n\u03bdM 1/3\n2\u03c0\n\nZ\n\ne\u2212\u03bdM\n\nJ (v) =\n\n\u03bdM 1/3\n2\u03c0\n\nZ\n\ne\u03bdM\n\nand\n\nwith\n\n1/3 u(z\u2212q)\n\neM f (z)\n\n\u0393\n\n1/3 v(z\u2212q)\n\n\u03a3\n\npc :=\n\n1\ndz\n\u0001k\npc \u2212 z g(z)\n\n\u0001k\ne\u2212M f (z) pc \u2212 z g(z)dz\n\n\u03b3\n,\n\u03b3+1\n\nand\nf (z) := \u2212\u03bc(z \u2212 q) + log(z) \u2212\n\n(103)\n\n(104)\n\n(105)\n1\nlog(1 \u2212 z),\n\u03b32\n\n(106)\n\nwhere we take the principal branch of log (i.e. log(z) = ln |z| + iarg(z), \u2212\u03c0 < arg(z) < \u03c0), and\nr\nY\n1\n(\u03c0l \u2212 z).\ng(z) :=\n(1 \u2212 z)r\n\n(107)\n\nl=k+1\n\nNow we find the critical point of f . As\nf \u2032 (z) = \u2212\u03bc +\n\n1\n1\n\u2212\n,\nz \u03b3 2 (z \u2212 1)\n\n(108)\n\nf \u2032 (z) = 0 is a quadratic equation. But with the choice (101) of \u03bc, there is a double root at\nz = pc =\n\n\u03b3\n\u03b3+1 .\n\ndouble root,\n\nNote that for \u03b3 in a compact subset of [1, \u221e), pc is strictly less than 1. Being a\nf \u2032 (pc ) = f \u2032\u2032 (pc ) = 0,\n\nwhere\nf \u2032\u2032 (z) = \u2212\nIt is also direct to compute\nf (3) (z) =\nand\n\n(109)\n\n1\n1\n+ 2\n.\n2\nz\n\u03b3 (z \u2212 1)2\n\n2\n2\n\u2212 2\n,\n3\nz\n\u03b3 (z \u2212 1)3\n\nf (3) (pc ) =\n\u0012\n\n\u03b3\nf (pc ) = \u2212\u03bc(pc \u2212 q) + log\n\u03b3+1\n19\n\n\u0013\n\n2(\u03b3 + 1)4\n= 2\u03bd 3\n\u03b33\n\n\u0012\n\u0013\n1\n1\n\u2212 2 log\n.\n\u03b3\n\u03b3 +1\n\n(110)\n\n(111)\n\n(112)\n\n\fAs f (3) (pc ) > 0, the steepest-descent curve of f (z) comes to the point pc with angle \u00b1\u03c0/3 to\n\nthe real axis. Once the contour \u0393 is chosen to be the steepest-descent curve near pc and is extended\nproperly, it is expected that the main contribution to the integral of H comes from a contour near\n\npc . There is, however, a difficulty since at the critical point z = pc , the integral (103) blows up\ndue to the term (pc \u2212 z)k in the denominator when k \u2265 1. Nevertheless this can be overcome if we\n\nchoose \u0393 to be close to pc , but not exactly pass through z0 . Also as the contour \u0393 should contain\n\nall \u03c0j 's, some of which may be equal to pc , we will choose \u0393 to intersect the real axis to the left of\npc . By formally approximating the function f by a third-degree polynomial and the function g(z)\nby g(pc ), we expect\n\u03bdM 1/3\nH(u) \u223c\n2\u03c0g(pc )\n\nZ\n\ne\u2212\u03bdM\n\n1/3 u(z\u2212q)\n\neM\n\nf (zc )+ f\n\n(3) (p )\nc\n(z\u2212pc )3\n3!\n\n\u0393\n\n\u0001\n\n1\npc \u2212 z\n\n\u0001k dz\n\n(113)\n\nfor some contour \u0393\u221e . Now taking the intersection point of \u0393 with the real axis to be on the left of\npc of distance of order M \u22121/3 , and then changing of the variables by \u03bdM 1/3 (z \u2212 pc ) = a, we expect\n\nH(u) \u223c\n\n(\u2212\u03bdM 1/3 )k eM f (pc ) \u2212\u03bdM 1/3 u(pc \u2212q)\ne\n2\u03c0g(pc )\n\nZ\n\n1 3\n\ne\u2212ua+ 3 a\n\u0393\u221e\n\n1\nda\nak\n\n(114)\n\nSimilarly, we expect that\ng(pc )e\u2212M f (pc ) \u03bdM 1/3 v(pc \u2212q)\ne\nJ (v) \u223c\n2\u03c0(\u2212\u03bdM 1/3 )k\n\nZ\n\n1 3\n\neva\u2212 3 a ak da\n\n(115)\n\n\u03a3\u221e\n\nfor some contour \u03a3\u221e . When multiplying H(u) and J (v), the constant prefactors\nZM :=\n\ng(pc )\n1/3\n(\u2212\u03bdM )k eM f (pc )\n\nand 1/ZM cancel each other out. However, note that there are still functions e\u2212\u03bdM\n\u03bdM 1/3 v(p\n\ne\n\nc \u2212q)\n\n(116)\n1/3 u(p\n\nc \u2212q)\n\nand\n\n, one of which may become large when M \u2192 \u221e (cf. (97), (98)). This trouble can be\n\navoided if we can simply take q = pc , but since \u0393 should be on the left of q, this simple choice is\n\nexcluded. Nevertheless, we can still take q to be pc minus some positive constant of order M \u22121/3 .\nFix\n\u01eb>0\nand set\nq := pc \u2212\n\n\u01eb\n.\n\u03bdM 1/3\n\n(117)\n\n(118)\n\nWe then take \u0393 to intersect the real axis at pc \u2212 c/(\u03bdM 1/3 ) for some 0 < c < \u01eb. With this choice\nof q and \u0393, \u03a3, we expect that\n\nZM H(u) \u223c H\u221e (u)\n20\n\n(119)\n\n\fwhere\n\ne\u2212\u01ebu\nH\u221e (u) :=\n2\u03c0\n\nand\n\nZ\n\n1 3\n\ne\u2212ua+ 3 a\n\n\u0393\u221e\n\n1\nda,\nak\n\n(120)\n\n1\nJ (v) \u223c J\u221e (v)\nZM\n\nwhere\n\ne\u01ebv\nJ\u221e (v) :=\n2\u03c0\n\nZ\n\n(121)\n\n1 3\n\neva\u2212 3 a ak da.\n\n(122)\n\n\u03a3\u221e\n\nHere the contour \u0393\u221e is, as in the left picture of Figure 3, from \u221eei\u03c0/3 to \u221ee\u2212i\u03c0/3 , passes the real\naxis on the left of the origin and lies in the region Re(a + \u01eb) > 0, is symmetric about the real axis\n\nand is oriented from top to bottom. The contour \u03a3\u221e is, as in the right picture of Figure 3, from\n\n\u221ee\u2212i2\u03c0/3 to \u221eei2\u03c0/3 , lies on the region Re(a + \u01eb) < 0, is symmetric about the real axis and is\n\noriented from bottom to top.\n\n\u0393\n\n\u03a3\n\n2\u03c0/3\n\n\u03c0/3\n\u2212\u03b5\n\n\u2212\u03b5\n\n0\n\n0\n\nFigure 3: Contours \u0393\u221e and \u03a3\u221e of H(u) and J (v)\nThis argument should be justified and the following is a rigorous estimate.\nProposition 3.1. Fix \u01eb > 0 and set q by (118). Define H\u221e (u) and J\u221e (v) by (120) and (122),\n\nrespectively. Then the followings hold for H(u) and J (v) in (103) and (104) for M/N = \u03b3 2 with\n\n\u03b3 in a compact subset of [1, \u221e).\n\n(i) For any fixed U \u2208 R, there are constants C, c > 0, M0 > 0 such that\nZM H(u) \u2212 H\u221e (u) \u2264\nfor u \u2265 U when M \u2265 M0 .\n21\n\nCe\u2212cu\nM 1/3\n\n(123)\n\n\f(ii) For any fixed V \u2208 R, there are constants C, c > 0, M0 > 0 such that\n1\nCe\u2212cv\nJ (v) \u2212 J\u221e (v) \u2264\nZM\nM 1/3\n\n(124)\n\nfor v \u2265 V when M \u2265 M0 .\nThe proof of this result is given in the following two subsections.\n\n3.1\n\nProof of Proposition 3.1 (i)\n\nThe steepest-descent curve of f will depend on \u03b3 and M . Instead of controlling uniformity of the\ncurve in \u03b3 and M , we will rather explicitly choose \u0393 which will be a steep-descent (though not the\nsteepest-descent) curve of f (z). Fix R > 0 such that 1 + R > max{1, \u03c0r+1 , . . . , \u03c0k }. Define\n\u01eb\nei\u03b8 : \u03c0/3 \u2264 \u03b8 \u2264 \u03c0}\n2\u03bdM 1/3\n\u01eb\n:= {pc + tei\u03c0/3 :\n\u2264 t \u2264 2(1 \u2212 pc )}\n2\u03bdM 1/3\n:= {pc + 2(1 \u2212 pc )ei\u03c0/3 + x : 0 \u2264 x \u2264 R}\n\u221a\n:= {1 + R + iy : 0 \u2264 y \u2264 3(1 \u2212 pc )}.\n\n\u03930 := {pc +\n\n(125)\n\n\u03931\n\n(126)\n\n\u03932\n\u03933\nSet\n\n(127)\n(128)\n\n\u0001\n\u0001\n\u0393 = \u222a3k=0 \u0393k \u222a \u222a3k=0 \u0393k\n\n(129)\n\nand choose the orientation of \u0393 counter-clockwise. See Figure 4.\n\u03932\n\u03931\n\u03933\n\u03930\n0\n\nq\n\npc\n\n1\n\n1+R\n\nFigure 4: Contour \u0393\n\n22\n\n\fNote that all the singular points of the integrand of H are inside of \u0393 and hence the deformation\n\nto this new \u0393 is allowed. Direct calculations show the following properties of \u0393. Recall (106),\nf (z) := \u2212\u03bc(z \u2212 q) + log(z) \u2212\n\n1\nlog(1 \u2212 z).\n\u03b32\n\n(130)\n\nLemma 3.1. For \u03b3 \u2265 1, Re(f (z)) is decreasing for z \u2208 \u03931 \u222a \u03932 as Re(z) increases. Also for \u03b3 in\n\na compact subset of [1, \u221e), we can take R > 0 large enough such that\n\u0001\nmax Re(f (z)) \u2264 Re f (p\u2217 ) .\nz\u2208\u03933\n\n(131)\n\nwhere p\u2217 := pc + 2(1 \u2212 pc )ei\u03c0/3 is the intersection of \u03931 and \u03932 .\nProof. For \u03931 , by setting z = pc + tei\u03c0/3 , 0 \u2264 t \u2264 2(1 \u2212 pc ),\n\nand\n\nF1 (t) := Re(f (pc + tei\u03c0/3 ))\n\u0001\n\u0001\n1\n1\n1\n= \u2212\u03bc(pc + t \u2212 q) + ln p2c + pc t + t2 \u2212 2 ln (1 \u2212 pc )2 \u2212 (1 \u2212 pc )t + t2\n2\n2\n2\u03b3\nF1\u2032 (t)\n\n\u0001\nt2 (\u03b3 + 1)2 t2 \u2212 (\u03b3 2 \u2212 1)t + 2\u03b3\n\u0001\n\u0001.\n=\u2212 2 2\n2\u03b3 pc + pc t + t2 (1 \u2212 pc )2 \u2212 (1 \u2212 pc )t + t2\n\n(132)\n\n(133)\n\nThe denominator is equal to 2\u03b3 2 |z|2 |1 \u2212 z|2 , and hence is positive. To show that the numerator is\n\npositive, set\n\nT1 (t) := (\u03b3 + 1)2 t2 \u2212 (\u03b3 2 \u2212 1)t + 2\u03b3.\n\n(134)\n\nA simple calculus shows that\nmin\n\nt\u2208[0,2(1\u2212pc )]\n\nBut T1\n\n\u03b3 2 \u22121 \u0001\n2(\u03b3+1)2\n\nT1 (t) =\n\n\uf8f1\n\uf8f2T1\n\n\u03b3 2 \u22121 \u0001\n,\n2(\u03b3+1)2\n\n\uf8f3T (2(1 \u2212 p )),\n1\nc\n\n1 \u2264 \u03b3 \u2264 5,\n\n(135)\n\n\u03b3 \u2265 5.\n\n\u2265 2 for 1 \u2264 \u03b3 \u2264 5, and T1 (2(1 \u2212 pc )) = 6 for \u03b3 \u2265 5, and hence we find that\n\nT1 (t) > 0 for t \u2208 [0, 2(1 \u2212 pc )] and for all \u03b3 \u2265 1. Thus we find that F1 (t) is an increasing function\nin t \u2208 [0, 2(1 \u2212 pc )].\n\nFor \u03932 , by setting z = pc + 2(1 \u2212 pc )ei\u03c0/3 + x, x \u2265 0,\n\nand\n\n\u0001\nF2 (x) := Re f (pc + 2(1 \u2212 pc )ei\u03c0/3 + x)\n\u0001\n\u0001\n1\n1\n= \u2212\u03bc(1 + x \u2212 q) + ln (1 + x)2 + 3(1 \u2212 pc )2 \u2212 2 ln x2 + 3(1 \u2212 pc )2 ,\n2\n2\u03b3\nF2\u2032 (x) = \u2212\n\n\u03b3 2 (\u03b3\n\n+\n\n1)2\n\n(1 +\n\nx)2\n\nT2 (x)\n\u0001\n\u0001\n+ 3(1 \u2212 pc )2 x2 + 3(1 \u2212 pc )2\n\n23\n\n(136)\n\n(137)\n\n\fwhere\nT2 (x) =(\u03b3 + 1)4 x4 + (\u03b3 4 + 6\u03b3 3 + 12\u03b3 2 + 10\u03b3 + 3)x3\n+ (2\u03b3 3 + 13\u03b3 2 + 20\u03b3 + 9)x2 + 2(2\u03b3 2 + 7\u03b3 + 5)x + 6(\u03b3 + 2) > 0,\nHence F2 (x) is decreasing for x \u2265 0.\n\nFor \u03933 , setting z = 1 + R + iy, 0 \u2264 y \u2264\n\n\u221a\n\n(138)\nx \u2265 0.\n\n3(1 \u2212 pc ),\n\n\u0001\nF3 (y) = Re f (1 + R + iy)\n\u0001\n\u0001\n1\n\u03bc\u01eb\n1\n\u2212 \u03bc(R + 1 \u2212 pc ) + ln (1 + R)2 + y 2 \u2212 2 ln R2 + y 2 .\n=\u2212\n1/3\n2\n2\u03b3\n\u03bdM\n\n(139)\n\nAs 1 \u2264 \u03bc = (\u03b3 + 1)2 /\u03b3 2 \u2264 4 for \u03b3 \u2265 1 and 1 \u2212 pc = 1/(\u03b3 + 1) \u2264 1, F3 (y) can be made arbitrarily\nsmall when R is taken to be large. But\n\n\u0001\nRe(f (p\u2217 )) = Re f (pc + 2(1 \u2212 pc )ei\u03c0/3 )\n\u0001\n\u0001\n1\n\u03bc\u01eb\n1\n2\n2\n2\nln\np\n+\n2p\n(1\n\u2212\np\n)\n+\n4(1\n\u2212\np\n)\nln\n5(1\n\u2212\np\n)\n\u2212\n=\u2212\n\u2212\n\u03bc(1\n\u2212\np\n)\n+\nc\nc\nc\nc\nc\nc\n2\n2\u03b3 2\n\u03bdM 1/3\n\n(140)\n\nis bounded for \u03b3 in a compact subset of [1, \u221e). Thus the result follows.\nAs \u03b3 is in a compact subset of [1, \u221e), we assume from here on that\n1 \u2264 \u03b3 \u2264 \u03b30\n\n(141)\n\nfor a fixed \u03b30 \u2265 1. Now we split the contour \u0393 = \u0393\u2032 \u222a \u0393\u2032\u2032 where \u0393\u2032 is the part of \u0393 in the disk\n\n|z \u2212 pc | < \u03b4 for some \u03b4 > 0 which will be chosen in the next paragraph, and \u0393\u2032\u2032 is the rest of \u0393. Let\n\n\u0393\u2032\u221e be the image of the contour \u0393\u2032 under the map z 7\u2192 \u03bdM 1/3 (z \u2212 pc ) and let \u0393\u2032\u2032\u221e = \u0393\u221e \\ \u0393\u2032\u221e . Set\nH(u) = H\u2032 (u) + H\u2032\u2032 (u),\n\n\u2032\n\u2032\u2032\nH\u221e (u) = H\u221e\n(u) + H\u221e\n(u)\n\n(142)\n\n\u2032 (u)) is the part of the integral formula of H(u) (res. H (u)) integrated\nwhere H\u2032 (u) (resp. H\u221e\n\u221e\n\nonly over the contour \u0393\u2032 (resp. \u0393\u2032\u221e ).\nFix \u03b4 such that\n\nFor |s \u2212 pc | \u2264 \u03b4,\n\n\b \u03bd3\n1\n,\n,\n0 < \u03b4 < min\n6C0 2(1 + \u03b30 )\n\nC0 := 43 + 4(1 + \u03b30 )4 .\n\n\u0013\n\u0012\n1 (4)\n1\n\u03b3 \u22122\n\u03b3 \u22122\n1\n1 \u22121\n\u2264\nf (s) =\n+\n+\n4!\n4 s4\n(1 \u2212 s)4\n4 (pc \u2212 \u03b4)4\n(1 \u2212 pc \u2212 \u03b4)4\n\u0001\n1\n\u2264 44 + 24 (1 + \u03b30 )4 = C0 .\n4\n24\n\n(143)\n\n(144)\n\n\fHence by the Taylor's theorem, for |z \u2212 pc | \u2264 \u03b4,\nRe f (z) \u2212 f (pc ) \u2212\n\n\u0001\nf (3) (pc )\nf (3) (pc )\n(z \u2212 pc )3 \u2264 f (z) \u2212 f (pc ) \u2212\n(z \u2212 pc )3\n3!\n3!\n\u0012\n\u0013\n|f (4) (s)|\n\u2264\nmax\n|z \u2212 pc |4\n4!\n|s\u2212pc |\u2264\u03b4\n\u2264 C0 |z \u2212 pc |4 \u2264\n\n(145)\n\n\u03bd3\n|z \u2212 pc |3 .\n6\n\nTherefore, by recalling (111), we find for 0 \u2264 t \u2264 \u03b4,\n\u0001\n\u03bd3\nRe f (pc + tei\u03c0/3 ) \u2212 f (pc ) \u2264 \u2212 t3 .\n6\n\n(146)\n\nEspecially, from the Lemma 3.1 (note that Re(f (z)) = Re(f (z))),\n\n\u0001\n\u03bd3\nmax\u2032\u2032 Re(f (z)) \u2264 Re f (pc + \u03b4ei\u03c0/3 ) \u2264 f (pc ) \u2212 \u03b43 .\nz\u2208\u0393\n6\n\n(147)\n\nIn the following sub-subsections, we consider two cases separately; first when u is in a compact\nsubset of R, and the other when u > 0.\n3.1.1\n\nWhen u is in a compact subset of R.\n\nSuppose that |u| \u2264 u0 for some u0 > 0. First we estimate\nZ\n|g(pc )|\n1/3\n1\n|dz|.\n|ZM H\u2032\u2032 (u)| \u2264\ne\u2212\u03bdM uRe(z\u2212q) eM Re(f (z)\u2212f (pc ))\n1/3\nk\u22121\n|pc \u2212 z|k |g(z)|\n2\u03c0(\u03bdM )\n\u0393\u2032\u2032\np\nUsing (147) and Re(z \u2212 q) \u2264 (1 + R)2 + 3 for z \u2208 \u0393\u2032\u2032 ,\n\u221a\n3\n|g(pc )|\n\u03bdM 1/3 u0 (1+R1 )2 +3 \u2212M \u03bd6 \u03b43 L\u0393 Cg\ne\n|ZM H\u2032\u2032 (u)| \u2264\n,\ne\n\u03b4k\n2\u03c0(\u03bdM 1/3 )k\u22121\n\n(148)\n\n(149)\n\nwhere L\u0393 is the length of \u0393 and Cg > 0 is a constant such that\n1\n\u2264 min\u2032\u2032 |g(z)| \u2264 Cg .\nCg\nz\u2208\u0393\n\n(150)\n\nFor \u03b3 \u2208 [1, \u03b30 ], L\u0393 , Cg and |g(pc )| are uniformly bounded, and hence\n\u03bd3 3\nM\n\n|ZM H\u2032\u2032 (u)| \u2264 e\u2212 12 \u03b4\n\n(151)\n\nwhen M is sufficiently large.\nOn the other hand, for a \u2208 \u0393\u2032\u2032\u221e , we have a = te\u00b1i\u03c0/3 , \u03b4\u03bdM 1/3 \u2264 t < +\u221e, and hence\n1 3\n1\nZ\nZ\n3\ne\u2212\u01ebu\ne\u2212ua e 3 a\neu0 |a| e 3 Re(a )\ne\u01ebu0\n\u2032\u2032\n|H\u221e\n(u)| =\nda\n|da|\n\u2264\n2\u03c0 \u0393\u2032\u2032\u221e\nak\n2\u03c0 \u0393\u2032\u2032\u221e\n|a|k\n1 3\nZ\n3\neu0 t\u2212 3 t\ne\u01ebu0 \u221e\n\u2212 \u03bd6 \u03b43 M\ndt\n\u2264\ne\n\u2264\n\u03c0 \u03b4\u03bdM 1/3\ntk\n25\n\n(152)\n\n\fwhen M is sufficiently large.\n\u2032 (u)|. Using the change of variables a = \u03bdM 1/3 (z \u2212 p ) for\nNow we estimate |ZM H\u2032 (u) \u2212 e\u2212\u01ebu H\u221e\nc\n\n\u2032 (u),\nthe integral (120) for H\u221e\n\n\u2032\n|ZM H\u2032 (u) \u2212 H\u221e\n(u)|\nZ\n1/3\n3\ne\u2212\u03bdM uRe(z\u2212q) M (f (z)\u2212f (pc ) g(pc )\n\u03bdM 1/3\nM \u03bd3 (z\u2212pc )3\ne\n\u2212\ne\n\u2264\n|dz|.\n1/3 (z \u2212 p )|k\n2\u03c0\ng(z)\nc\n\u0393\u2032 |\u03bdM\n\n(153)\n\nWe split the integral into two parts. Let \u0393\u2032 = \u0393\u20321 \u222a \u0393\u20322 where \u0393\u20321 = \u03930 \u222a \u03930 and \u0393\u20322 = \u0393\u2032 \\ \u0393\u20321 .\nFor z \u2208 \u0393\u20321 , |z \u2212 pc | = \u01eb/(2\u03bdM 1/3 ). Hence using (145),\n|eM (f (z)\u2212f (pc )) \u2212 eM\n\n\u03bd3\n(z\u2212pc )3\n3\n\n|\n\n\u2264 max |eM (f (z)\u2212f (pc )) |, |eM\n\u2264 eM Re(\n1\n\n\u2264 e 16 \u01eb\nAlso\n\n3\n\n\u03bd3\n3\n\n3\n\n(z\u2212pc )3 + \u03bd6 |z\u2212pc |3 )\n\nC0 \u01eb4\n.\n16\u03bd 4 M 1/3\n\ng(pc )\n1\n\u22121 \u2264\ng(z)\n|g(z)|\n\n\u03bd3\n(z\u2212pc )3\n3\n\n\u0001\n\u03bd3\n| * M |f (z) \u2212 f (pc ) \u2212 (z \u2212 pc )3 |\n3\n\nM C0 |z \u2212 pc |4\n\nmax \u01eb\n\n|s\u2212pc |\u2264\n\n2\u03bdM 1/3\n\n|g\u2032 (s)| * |z \u2212 pc | \u2264\n\nC0 C\u01eb\n2\u03bdM 1/3\n\n(154)\n\n(155)\n\nwhere\n\n\u01eb\n, s \u2208 \u0393\u20322 }\n(156)\n2\u03bdM 1/3\nwhich is uniformly bounded as \u0393 is uniformly away from the singular points of g. Hence using\nC := max{|g\u2032 (s)| : |s \u2212 pc | \u2264\n\neM (f (z)\u2212f (pc )\n\n\u03bd3\ng(pc )\n3\n\u2212 eM 3 (z\u2212pc )\ng(z)\n\n\u0001\n\u03bd\n\u03bd3\n3 \u0001 g(pc )\n3 g(pc )\n+ eM 3 (z\u2212pc )\n\u22121\neM (f (z)\u2212f (pc ) \u2212 eM 3 (z\u2212pc )\ng(z)\ng(z)\n\u0012\n\u0013\n4\nC0 \u01eb 1 \u01eb3 C0 C\n1\n\u2264\ne 16 +\n* 1/3 ,\n16\u03bd 4\n2\u03bd\nM\n=\n\n(157)\n\nand the fact that the length of \u0393\u20321 is 4\u03c0R0 /(3M 1/3 ), we find that the part of the integral in (153)\nover \u0393\u20321 is less than or equal to some constant divided by M 1/3 .\nFor z \u2208 \u0393\u20322 , we have z = pc + te\u00b1i\u03c0/3 , \u01eb/(2\u03bdM 1/3 ) \u2264 t \u2264 \u03b4. From (145) (cf. (154))\n|eM (f (z)\u2212f (pc )) \u2212 eM\n\n\u03bd3\n(z\u2212pc )3\n3\n\n|\n\n3\n3\nM Re( \u03bd3 (z\u2212pc )3 + \u03bd6 |z\u2212pc |3 )\n\n\u2264e\n\n\u2264 e\u2212M\n\n\u03bd3 3\nt\n6\n\n* C0 M t4 .\n26\n\nM C0 |z \u2212 pc |4\n\n(158)\n\n\fAlso\n\ng(pc )\n1\n\u22121 \u2264\nmax |g\u2032 (s)| * |pc \u2212 z| \u2264 C0 Ct,\ng(z)\n|g(z)| s\u2208\u0393\u20322\n\n(159)\n\nand hence\neM (f (z)\u2212f (pc )\n=\n\n\u03bd3\ng(pc )\n3\n\u2212 eM 3 (z\u2212pc )\ng(z)\n\neM (f (z)\u2212f (pc ) \u2212 eM\n\n\u2264 e\u2212\n\n\u03bd3\nM t3\n6\n\n\u03bd3\n(z\u2212pc )3\n3\n\u03bd3\nM t3\n3\n\nC03 M t4 + e\u2212\n\n\u0001\n\u0001 g(pc )\n\u03bd3\n3 g(pc )\n\u22121\n+ eM 3 (z\u2212pc )\ng(z)\ng(z)\n\nC0 Ct \u2264 (C03 + C0 C)e\u2212\n\n\u03bd3\nM t3\n6\n\n(160)\n\n(M t4 + t).\n\nUsing\ne\u2212\u03bdM\n\n1/3 uRe(z\u2212q)\n\n\u2264 e\u03bdM\n\n1/3 u\n\n0 (|pc \u2212q|+|z\u2212pq |)\n\n= e\u01ebu0 +\u03bdu0 M\n\n1/3 t\n\n,\n\n(161)\n\nwe find by substituting z = pc + te\u00b1i\u03c0/3 into (153), the part of the integral in (153) over \u0393\u20322 is less\nthan or equal to\n\u03bdM 1/3 3\n(C0 + C0 C)\n\u03c0\n\nZ\n\n1/3\n\n\u03b4\n\u01eb\n2\u03bdM 1/3\n\ne\u01ebu0 +\u03bdu0 M t \u2212 \u03bd 3 M t3\ne 6\n(M t4 + t)dt.\n(\u03bdM 1/3 t)k\n\n(162)\n\nThen by the change of variables s = \u03bdM 1/3 t, the last integral is less than or equal to\n(C03 + C0 C)e\u01ebu0\n\u03c0M 1/3\n\nZ\n\n\u221e\n\n\u01eb/2\n\n1 3\n\neu0 s\u2212 6 s\nsk\n\n1 4 1 \u0001\ns + s ds,\n\u03bd4\n\u03bd\n\n(163)\n\nwhich is a constant divided by M 1/3 . Therefore, together with the estimate for the part over \u0393\u20321 ,\nthis implies that\n\nC1\n(164)\nM 1/3\nfor some positive constant C1 > 0 for any M > 0. Now combining (151), (152) and (164), we find\n\u2032\n|ZM H\u2032 (u) \u2212 H\u221e\n(u)| \u2264\n\nthat for any u0 > 0, there are constants C > 0, M0 > 0 which may depend on u0 such that\n|ZM H(u) \u2212 H\u221e (u)| \u2264\n\nC\nM 1/3\n\n(165)\n\nfor |u| \u2264 u0 and M \u2265 M0 . obtain (123).\n3.1.2\n\nWhen u > 0.\n\nWe first estimate |ZM H\u2032\u2032 (u)| using (148). For z \u2208 \u0393\u2032\u2032 , Re(z \u2212 q) = Re(pc \u2212 q) + Re(z \u2212 pc ) \u2265\n\u01eb\n\u03bdM 1/3\n\n+ 12 \u03b4, and hence as u > 0,\n\n|ZM H\u2032\u2032 (u)| \u2264\n\n3\n|g(pc )|\n\u2212\u01ebu \u2212 21 \u03bdM 1/3 \u03b4u \u2212M \u03bd6 \u03b43 L\u0393\ne\ne\n.\ne\n\u03b4k Cg\n2\u03c0(\u03bdM 1/3 )k\u22121\n\n27\n\n(166)\n\n\fOn the other hand, for a \u2208 \u0393\u2032\u2032\u221e , by estimating as in (152) but now using u > 0 and Re(a) \u2265\n\n1\n1/3\n2 \u03b4\u03bdM\n\nfor a \u2208 \u0393\u2032\u2032\u221e , we find\n\u2032\u2032\n|H\u221e\n(u)|\n\ne\u2212\u01ebu\n\u2264\n2\u03c0\n\nZ\n\n1\n\n\u0393\u2032\u2032\n\u221e\n\n1\n\n3\n\ne\u2212\u01ebu e\u2212 2 \u03b4\u03bdM\ne\u2212Re(a)+ 3 Re(a )\n|da|\n\u2264\n|a|k\n2\u03c0\n\n\u2212 12 \u03b4\u03bdM 1/3 u\n\n\u2264 e\u2212\u01ebu e\n\ne\u2212M\n\n\u03bd3 3\n\u03b4\n6\n\n1/3 u\n\nZ\n\n1\n\n\u0393\u2032\u2032\n\u221e\n\n3\n\ne 3 Re(a )\n|da|\n|a|k\n\n(167)\n\nwhen M is sufficiently large.\n\u2032 (u)|, we note that as u > 0, for z \u2208 \u0393\u2032 ,\nIn order to estimate |ZM H\u2032 (u) \u2212 H\u221e\n\ne\u2212\u03bdM\nwhich is achieved at z = pc \u2212\n\n\u01eb\n.\n2\u03bdM 1/3\n\n1/3 uRe(z\u2212q)\n\n1\n\n\u2264 e\u2212 2 \u01ebu\n\n(168)\n\nUsing the same estimates as in the case when u is in a\n\ncompact set for the rest of the terms of (153), we find that\n1\n\n\u2032\n\n|ZM H (u)\n\n\u2032\n\u2212 H\u221e\n(u)|\n\nC2 e\u2212 2 \u01ebu\n\u2264\nM 1/3\n\n(169)\n\nfor some constant C2 > 0 when M is large enough. Now (166), (167) and (169) yield (123) for the\ncase when u > 0.\n\n3.2\n\nProof of Proposition 3.1 (ii)\n\nWe choose the contour \u03a3 explicitly, which will be a steep-descent curve of \u2212f (z), as follows. Let\nR > 0. Define\n\n(170)\n\n\u03a31\n\n(171)\n\n\u03a32\n\u03a33\nand set\n\n\u03c0\n3\u01eb\nei(\u03c0\u2212\u03b8) : 0 \u2264 \u03b8 \u2264 }\n1/3\n3\n\u03bdM\n3\u01eb\n\u2264 t \u2264 2pc }\n:= {pc + te2i\u03c0/3 :\n\u03bdM 1/3\n:= {pc + 2pc e2i\u03c0/3 \u2212 x : 0 \u2264 x \u2264 R}\n\u221a\n\u221a\n:= {\u2212R + i( 3pc \u2212 y) : 0 \u2264 y \u2264 3pc },\n\n\u03a30 := {pc +\n\n\u0001\n\u0001\n\u03a3 = \u222a3k=0 \u03a3k \u222a \u222a3k=0 \u03a3k .\n\nThe orientation of \u03a3 is counter-clockwise.\n\n(172)\n(173)\n\n(174)\n\nSee Figure 5. We first prove decay properties of\n\nRe(\u2212f (z)) analogous to Lemma 3.1.\nLemma 3.2. For \u03b3 \u2265 1, Re(\u2212f (z)) is decreasing for z \u2208 \u03a31 \u222a \u03a32 as Re(z) decreases. Also for \u03b3\nin a compact subset of [1, \u221e), we can take large R > 0 (independent of \u03b3) such that\n\u0001\nmax Re(\u2212f (z)) \u2264 Re \u2212f (p\u2217 )) .\nz\u2208\u03c33\n\nwhere p\u2217 = pc + 2pc e2i\u03c0/3 is the intersection of \u03a31 and \u03a32 .\n28\n\n(175)\n\n\f\u03a32\n\u03a31\n\u03a33\n\n\u03a30\n0\n\nq pc\n\nFigure 5: Contour \u03a3\nProof. For z \u2208 \u03a31 , by setting z = pc + te2i\u03c0/3 , 0 \u2264 t \u2264 2pc ,\nF1 (t) := Re(\u2212f (pc + te2i\u03c0/3 ))\n1\n1\n1\n= \u03bc(pc \u2212 t \u2212 c) \u2212 ln(p2c \u2212 pc t + t2 ) + 2 ln((1 \u2212 pc )2 + (1 \u2212 pc )t + t2 )\n2\n2\n2\u03b3\nand hence\nF1\u2032 (t)\n\n\u0001\nt2 (\u03b3 + 1)2 t2 + (\u03b3 2 \u2212 1)t + 2\u03b3\n\u0001\n\u0001,\n=\u2212 2 2\n2\u03b3 pc \u2212 pc t + t2 (1 \u2212 pc )2 + (1 \u2212 pc )t + t2\n\n(176)\n\n(177)\n\nwhich is non-negative for all t \u2265 0.\n\nFor \u03a32 , by setting z = pc + 2pc e2i\u03c0/3 \u2212 x, x \u2265 0,\n\n\u0001\nF2 (x) := Re \u2212f (pc + 2pc e2i\u03c0/3 \u2212 x)\n\u0001\n\u0001\n1\n1\n= \u03bc(\u2212x \u2212 c) \u2212 ln x2 + 3p2c + 2 ln (1 + x)2 + 3p2c .\n2\n2\u03b3\n\n(178)\n\nA direct computation shows that\n\nF2\u2032 (x) = \u2212\n\n\u03b3 2 (\u03b3\n\nwhere\n\n+\n\n1)2\n\nx2\n\nT2 (x)\n\u0001\n\u0001\n+ 3p2c (1 + x)2 + 3p2c\n\nT2 (x) =(\u03b3 + 1)4 x4 + (3\u03b3 4 + 10\u03b3 3 + 12\u03b3 2 + 6\u03b3 + 1)x3\n+ (9\u03b3 4 + 20\u03b3 3 + 13\u03b3 2 + 2\u03b3)x2 + 2(5\u03b3 4 + 7\u03b3 3 + 2\u03b3 2 )x + 6(2\u03b3 4 + \u03b3 3 ).\nHence F2 (x) is decreasing for x \u2265 0.\n\n29\n\n(179)\n\n(180)\n\n\f\u221a\n\u221a\nFor \u03a33 , setting z = \u2212R + i( 3pc \u2212 y), 0 \u2264 y \u2264 3pc ,\n\u221a\n\u0001\nF3 (y) = Re \u2212f (\u2212R + i( 3pc \u2212 y)\n\u221a\n\u221a\n\u0001\n\u0001\n1\n1\n= \u03bc(\u2212R \u2212 c) \u2212 ln R2 + ( 3pc \u2212 y)2 + 2 ln (1 + R)2 + ( 3pc \u2212 y)2 .\n2\n2\u03b3\n\n(181)\n\nWhen R \u2192 +\u221e, F3 (y) can be made arbitrarily small. But\n\n\u0001\nRe \u2212f (pc + 2pc e2i\u03c0/3 )\n\u221a \u0001\n\u0001\n1\n= \u2212\u03bcc \u2212 ln 3pc + 2 ln 1 + 3p2c\n2\u03b3\n\n(182)\n\nis bounded for \u03b3 in a compact subset of [1, \u221e). Thus the result follows.\nLet \u03b4 be given in (143). Let \u03a3 = \u03a3\u2032 \u222a \u03a3\u2032\u2032 where \u03a3\u2032 is the part of \u03a3 that lies in the disk\n\n|z \u2212 pc | < \u03b4, and let \u03a3\u2032\u2032 = \u03a3 \\ \u03a3\u2032 . Let \u03a3\u2032\u221e be the image of \u03a3\u2032 under the map z 7\u2192 \u03bdM 1/3 (z \u2212 pc )\nand let \u03a3\u2032\u2032\u221e = \u03a3\u221e \\ \u03a3\u2032\u221e . Set\n\nJ (v) = J \u2032 (v) + J \u2032\u2032 (v),\n\n\u2032\n\u2032\u2032\n(v) + J\u221e\n(v)\nJ\u221e = J\u221e\n\n(183)\n\n\u2032 (v)) is the part of the integral formula of J (v) (resp. J (v)) integrated\nwhere J \u2032 (v) (resp. J\u221e\n\u221e\n\nover the contour \u03a3\u2032 (resp. \u03a3\u2032\u221e ).\n\nAs before, we consider two cases separately; first case when v is in a compact subset of R, and\n\nthe second case when v > 0.\n3.2.1\n\nWhen v is in a compact subset of R.\n\nThere is v0 > 0 such that |v| \u2264 v0 . First, we estimate\nZ\n1/3\n(\u03bdM 1/3 )k+1\n1\n\u2032\u2032\ne\u03bdM v0 |z\u2212q| eM Re(\u2212f (z)+f (pc )) |pc \u2212 z|k |g(z)||dz|.\nJ (v) \u2264\nZM\n2\u03c0|g(pc )| \u03a3\u2032\u2032\n\n(184)\n\nFrom Lemma 3.2 and (145), following the proof of (147), we find\nmax\u2032\u2032 Re(\u2212f (z)) \u2264 Re(\u2212f (pc + \u03b4e2i\u03c0/3 ) \u2264 f (pc ) \u2212\n\nz\u2208\u03a3\n\nHence using |z \u2212 q| \u2264\n\np\n\n\u03bd3 3\n\u03b4 .\n6\n\n(185)\n\n(R1 + 1)2 + 3 for z \u2208 \u03a3\u2032\u2032 ,\n\n1 \u2032\u2032\n(\u03bdM 1/3 )k+1 \u03bdM 1/3 v0 \u221a(R1 +1)2 +3 \u2212 \u03bd 3 \u03b43 M k e\n\u03b4 Cg L\u03a3 ,\nJ (v) \u2264\ne\ne 6\nZM\n2\u03c0|g(pc )|\n\n(186)\n\neg is the maximum of |g(z)| over z \u2208 \u03a3\u2032\u2032 and L\u03a3 is the length of \u03a3\u2032\u2032 , both of which are\nwhere C\n\nuniformly bounded. Hence we find that when M is sufficiently large,\n\u03bd3 3\n1\nJ \u2032\u2032 (v) \u2264 e\u2212 12 \u03b4 M .\nZM\n\n30\n\n(187)\n\n\fWhen a \u2208 \u03a3\u2032\u2032\u221e , a = te\u00b12i\u03c0/3 , \u03b4\u03bdM 1/3 \u2264 t < +\u221e, and\nZ\nZ\n1 3\n\u03bd3 3\ne\u01ebv0 \u221e\ne\u01ebv\nva\u2212 13 a3 k\n\u2032\u2032\ne\nev0 t\u2212 3 t tk dt \u2264 e\u2212 6 \u03b4 M\na da \u2264\n|J\u221e (v)| =\n2\u03c0 \u03a3\u2032\u2032\u221e\n\u03c0 \u03b4\u03bdM 1/3\n\n(188)\n\nwhen M is sufficiently large.\nFinally we estimate\n1\n\u2032\nJ \u2032 (v) \u2212 J\u221e\n(v)\nZM\nZ\n\u03bd3\n1/3\ng(z)\n\u03bdM 1/3\n3\n|e\u03bdM v(z\u2212q) ||\u03bdM 1/3 (z \u2212 pc )|k e\u2212M (f (z)\u2212f (pc ))\n\u2212 e\u2212M 3 (z\u2212pc ) |dz|.\n\u2264\n2\u03c0\ng(pc )\n\u03a3\u2032\n\n(189)\n\nAs before, we split the contour \u03a3\u2032 = \u03a3\u20321 \u222a \u03a3\u20322 where \u03a3\u20321 = \u03a30 \u222a \u03a30 and \u03a3\u20322 = \u03a3\u2032 \\\u03a3\u20321 , and by following\n\nthe steps of (154)-(163), we arrive at\n\n1\nC3\n\u2032\nJ \u2032 (v) \u2212 J\u221e\n(v) \u2264 1/3 ,\nZM\nM\n\n(190)\n\nfor some constant C3 > 0 when M is large enough. From (187), (188) and (190), we obtain (124).\n3.2.2\n\nWhen v > 0.\n\nThe proof in this case is again very similar to the estimate of H(u) when u > 0. Then only change\n\nis the following estimates:\n\nRe(z \u2212 q) \u2264 Re(pc + \u03b4e2i\u03c0/3 \u2212 q) =\n\nRe(z \u2212 q) \u2264 Re(pc +\n\n1\n\u01eb\n\u2212 \u03b4,\n1/3\n2\n\u03bdM\n\n\u01eb\n3\u01eb\ne2i\u03c0/3 \u2212 q) = \u2212\n,\n1/3\n\u03bdM\n2\u03bdM 1/3\n\nz \u2208 \u03a3\u2032\u2032 ,\nz \u2208 \u03a3\u2032 ,\n\n(191)\n\n(192)\n\nand\n\n\u01eb\n1\nRe(z \u2212 q) = \u2212 |z \u2212 pc | +\n,\n2\n\u03bdM 1/3\nThen for large enough M > 0,\n\nz \u2208 \u03a31 .\n\n\u03bd3 3\n1\n1/3\n1 \u2032\u2032\nJ (v) \u2264 e\u01ebv e\u2212 2 \u03b4\u03bdM v e\u2212 12 \u03b4 M ,\nZM\n\n1\n\n\u2032\u2032\nJ\u221e\n(v) \u2264 e\u01ebv e\u2212 2 \u03b4\u03bdM\n\nand\n\n1/3 v\n\ne\u2212\n\n\u03bd3 3\n\u03b4 M\n6\n\n(193)\n\n(194)\n\n,\n\n(195)\n\n1\n1 \u2032\nC\n\u2032\nJ (v) \u2212 J\u221e\n(v) \u2264 1/3 e\u2212 2 \u01ebv\nZM\nM\n\n(196)\n\nfor some constant C > 0. We skip the detail.\n31\n\n\f3.3\n\nProof of Theorem 1.1 (a)\n\nFrom the Proposition 3.1, the discussion on the subsection 2.2 implies that under the assumption\nof Theorem 1.1 (a),\nP\n\n\u0012\n\n\u03bb1 \u2212 (1 + \u03b3\n\n\u22121 2\n\n)\n\n\u0001\n\n\u0013\n\u03b3\n2/3\nM\n\u2264x\n*\n(1 + \u03b3)4/3\n\n(197)\n\nconverges, as M \u2192 \u221e, to the Fredholm determinant of the operator acting on L2 ((0, \u221e)) whose\n\nkernel is\n\nZ\n\n\u221e\n0\n\nH\u221e (x + u + y)J\u221e (x + v + y)dy.\n\n(198)\n\nFrom the integral representation (10) of the Airy function, by simple changes of variables,\nZ\nZ\n1 3\n1 3\n\u22121\n1\nAi(u) =\ne\u2212ua+ 3 a da =\neub\u2212 3 b db,\n2\u03c0i \u0393\u221e\n2\u03c0i \u03a3\u221e\nand hence a simple algebra shows that\nZ\nZ \u221e\nH\u221e (u + y)J\u221e (v + y)dy \u2212\n0\n\n\u221e\n\ne\u2212\u01eb(u+y) Ai(u + y)Ai(v + y)e\u01eb(v+y) dy\n\n0\n\n\u0012\u0012 \u0013k\n\u0013\nb\ne\ndb e\nda\ndy\n\u22121\n=\n(2\u03c0)2 0\na\n\u03a3\u221e\n\u0393\u221e\nZ\nZ\nk\nm\u22121 Z \u221e\nX\ne\u2212\u01eb(u\u2212v)\n\u2212ua+ 13 a3 vb\u2212 13 b3 (b \u2212 a)b\ndb\ne\nda\ne\u2212(a\u2212b)y dy\ne\n=\nm\n(2\u03c0)2 \u0393\u221e\na\n\u03a3\u221e\n0\nm=1\nZ\nZ\nk\nm\u22121\nX\ne\u2212\u01eb(u\u2212v)\n\u2212ua+ 13 a3 vb\u2212 13 b3 b\ndb\ne\nda\n=\u2212\ne\n(2\u03c0)2 \u0393\u221e\nam\n\u03a3\u221e\ne\u2212\u01eb(u\u2212v)\n\n=\n\nZ\n\nm=1\nk\nX\n\u2212\u01ebu (m)\n\ne\n\ns\n\nZ\n\nZ\n\n\u221e\n\n(199)\n\n\u2212(u+y)a+ 13 a3 (v+y)b\u2212 13 b3\n\n(200)\n\n(u)t(m) (v)e\u01ebv ,\n\nm=1\n\nwhere the choice of the contours \u03a3\u221e and \u0393\u221e ensures that Re(a \u2212 b) > 0 which is used in the third\n\nequality.\n\nLet E be the multiplication operator by e\u2212\u01ebu ; (Ef )(u) = e\u2212\u01ebu f (u). The computation (200)\nimplies that (197) converges to\ndet 1 \u2212 EAx E\u22121 \u2212\n\nk\nX\n\nm=1\n\n\u0001\nEsx(m) \u2297 tx(m) E\u22121 .\n\n(201)\n\nThe general formula of the Fredholm determinant of a finite-rank perturbation of an operator yields\nthat this is equal to\ndet 1 \u2212 EAx E\n\n\u22121\n\n\u0001\n\n\u0012\n\n1\n\u22121\n* det \u03b4mn \u2212 <\nEs(m) , t(n)\n>\nx E\n1 \u2212 EAx E\u22121 x\n\n\u0013\n\n,\n\n1\u2264m,n\u2264k\n\nwhich is equal to (17) due to the proof of the following Lemma. This completes the proof.\n32\n\n(202)\n\n\fLemma 3.3. The function Fk (x) in Definition 1.1 is well-defined. Also s(m) (u) defined in (13)\ncan be written as\ns\n\n(m)\n\n(u) =\n\nX\n\nl+3n=m\u22121\n\n1\n(\u22121)n l\nu +\nn\n3 l!n!\n(m \u2212 1)!\n\nZ\n\nu\n\u221e\n\n(u \u2212 y)m\u22121 Ai(y)dy.\n\n(203)\n\nProof. It is known that Ax has norm less than 1 and is trace class (see, e.g. [39]). The only\nthing we need to check is that the product <\n\n1\n(m) , t(n)\n1\u2212Ax s\n\n> is finite. By using the standard\n\nsteepest-descent analysis,\n2 3/2\n1\nAi(u) \u223c \u221a 1/4 e\u2212 3 u ,\n2 \u03c0u\n\nand\n\n2 3/2\nv m/2\nt(m) (v) \u223c \u221a 3/4 e\u2212 3 v ,\n2 \u03c0v\n\nu \u2192 +\u221e.\n\n(204)\n\nv \u2192 +\u221e.\n\n(205)\n\nBut for s(m) , since the critical point a = i is above the pole a = 0, the residue at a = 0 contributes\nto the asymptotics and s(m) (u) grows in powers of u as u \u2192 +\u221e:\nX\n\n2 3/2\n(\u22121)n l\n(\u22121)m\ne\u2212 3 u ,\nu\n+\n\u221a\nm/2 u1/4\n3n l!n!\n2\n\u03c0u\nl+3n=m\u22121\n\ns(m) (u) \u223c\n\nu \u2192 +\u221e.\n\n(206)\n\nBut the asymptotics (204) of the Airy function as u \u2192 \u221e implies that for any U, V \u2208 R, there is a\nconstant C > 0 such that\n\n2\n\n|A(u, v)| \u2264 Ce\u2212 3 (u\n\n3/2 +v 3/2 )\n\n,\n\nu \u2265 U,\n\nv \u2265 V,\n\n1\n(m) , t(n) > is finite.\n1\u2212Ax s\nAi(u). Hence s(m) (u) is m-folds\n\n(207)\n\nwhich, together with (205), implies that the inner product <\nAlso s(m) (u) defined in (13) satisfies\n\ndm (m)\n(u)\ndum s\n\n=\n\nintegral of\n\nAi(u) from \u221e to u plus a polynomial of degree m \u2212 1. But the asymptotics (206) determines the\n\npolynomial and we obtain the result.\n\n3.4\n\nProof of Theorem 1.2\n\nThe analysis is almost identical to that of Proof of Theorem 1.1 (a) with the only change of the\nscaling\n\u03c0j\u22121 = 1 + \u03b3 \u22121 \u2212\nWe skip the detail.\n\n33\n\nwj\n.\nM 1/3\n\n(208)\n\n\f4\n\nProofs of Theorem 1.1 (b)\n\nWe assume that for some 1 \u2264 k \u2264 r,\n\u03c01\u22121 = * * * = \u03c0k\u22121 > 1 + \u03b3 \u22121\n\n(209)\n\n\u22121\nare in a compact subset of (1 + \u03b3 \u22121 , \u221e), and \u03c0k+1\n, . . . , \u03c0r\u22121 are in a compact subset of (0, \u03c01\u22121 ).\n\nFor the scaling (91), we take\n\n\u03b1 = 1/2\n\n(210)\n\nand\n\u03b3 \u22122\n1\n+\n,\n\u03bc = \u03bc(\u03b3) :=\n\u03c01 (1 \u2212 \u03c01 )\nso that\n\n\u03bd = \u03bd(\u03b3) :=\n\ns\n\n1\n\u03b3 \u22122\n\u2212\n\u03c012 (1 \u2212 \u03c01 )2\n\n\u03bdx\n\u03be =\u03bc+ \u221a .\nM\n\n(211)\n\n(212)\n\nIt is direct to check that the term inside the square-root of \u03bd is positive from the condition (209).\nAgain, the reason for such a choice will be clear during the subsequent asymptotic analysis.\nThe functions (95) and (96) are now\nH(u) =\n\n\u03bdM 1/2\n2\u03c0\n\nZ\n\nJ (v) =\n\n\u03bdM 1/2\n2\u03c0\n\nZ\n\nand\n\nwhere\n\ne\u2212\u03bdM\n\n1/2 u(z\u2212q)\n\neM f (z)\n\n\u0393\n\ne\u03bdM\n\n1/2 v(z\u2212q)\n\n\u03a3\n\n1\ndz\n\u0001k\n\u03c01 \u2212 z g(z)\n\n\u0001k\ne\u2212M f (z) \u03c01 \u2212 z g(z)dz\n\nf (z) := \u2212\u03bc(z \u2212 q) + log(z) \u2212\n\n1\nlog(1 \u2212 z),\n\u03b32\n\n(213)\n\n(214)\n\n(215)\n\nwhere log is the principal branch of logarithm, and\nr\nY\n1\ng(z) :=\n(\u03c0l \u2212 z).\n(1 \u2212 z)r\n\n(216)\n\nl=k+1\n\nThe arbitrary parameter q will be chosen in (220) below. Now as\nf \u2032 (z) = \u2212\u03bc +\n\n1\n1\n\u2212 2\n,\nz \u03b3 (z \u2212 1)\n\nwith the choice (211) of \u03bc, two critical points of f are z = \u03c01 and z =\n(209), it is direct to check that\n\u03c01 <\n\n\u03b3\n1\n<\n< 1.\n1+\u03b3\n\u03bc\u03c01\n\n34\n\n(217)\n1\n\u03bc\u03c01 .\n\nFrom the condition\n(218)\n\n\fAlso a straightforward computation shows that\nf \u2032\u2032 (\u03c01 ) = \u2212\u03bd 2 < 0,\n\nf \u2032\u2032\n\n\u00012\n1 \u0001\n= \u03b3\u03bd\u03bc\u03c01 (1 \u2212 \u03c01 ) > 0\n\u03bc\u03c01\n\n(219)\n\nDue to the nature of the critical points, the point z = \u03c01 is suitable for the steepest-descent\nanalysis for J (v) and standard steepest-descent analysis will yield a good leading term of the\n\nasymptotic expansion of J (v). However, for H(u), the appropriate critical point is z = 1/(\u03bc\u03c01 ),\n\nand in order to find the steepest-descent curve passing the point z = 1/(\u03bc\u03c01 ), we need to deform\n\nthe contour \u0393 through the pole z = \u03c01 and possibly some of \u03c0k+1 , \u03c0k+2 , . . . , \u03c0r . In the below, we\nwill show that the leading term of the asymptotic expansion of H(u) comes from the pole z = \u03c01 .\n\nBefore we state precise estimates, we first need some definitions.\nGiven any fixed \u01eb > 0, we set\n\n\u01eb\nq := \u03c01 \u2212 \u221a .\n\u03bd M\n\n(220)\n\nSet\n\u2212\u01ebu\n\nH\u221e (u) := ie\n\n* Resa=0\n\n\u0012\n\n\u0013\n1 \u2212 1 a2 \u2212ua\ne 2\n,\nak\n\n1 \u01ebv\ne\nJ\u221e (v) :=\n2\u03c0\n\nZ\n\n1 2\n+vs\n\nsk e 2 s\n\nds,\n\n(221)\n\n\u03a3\u221e\n\nwhere \u03a3\u221e is the imaginary axis oriented from the bottom to the top, and let\nZM :=\n\n(\u22121)k e\u2212M f (\u03c01 ) g(\u03c01 )\n.\n\u03bd k M k/2\n\n(222)\n\nProposition 4.1. Fix \u01eb > 0 and set q by (220). The followings hold for M/N = \u03b3 2 with \u03b3 in a\ncompact subset of [1, \u221e).\n(i) For any fixed V \u2208 R, there are constants C, c > 0, M0 > 0 such that\n1\nCe\u2212cv\nJ (v) \u2212 J\u221e (v) \u2264 \u221a\nZM\nM\n\n(223)\n\nfor v \u2265 V when M \u2265 M0 .\n(ii) For any fixed U \u2208 R, there are constants C, c > 0, M0 > 0 such that\nCe\u2212cu\nZM H(u) \u2212 H\u221e (u) \u2264 \u221a\nM\nfor u \u2265 U when M \u2265 M0 .\nWe prove this result in the following two subsections.\n\n35\n\n(224)\n\n\f4.1\n\nProof of Proposition 4.1 (i)\n\nLet R > 0 and define\n2\u01eb\n\u03a31 := {\u03c01 \u2212 \u221a + iy : 0 \u2264 y \u2264 2}\n\u03bd M\n2\u01eb\n\u03a32 := {\u03c01 + 2i \u2212 x : \u221a \u2264 x \u2264 R}\n\u03bd M\n\u03a33 := {\u03c01 \u2212 R + i(2 \u2212 y) : 0 \u2264 y \u2264 2},\nand set\n\n(225)\n(226)\n(227)\n\n\u0001\n\u0001\n\u03a3 = \u222a3k=1 \u03a3k \u222a \u222a3k=1 \u03a3k .\n\n(228)\n\nThe orientations of \u03a3j , j = 1, 2, 3 and \u03a3 are indicated in Figure 6.\n\u03a32\n\u03a31\n\n\u03a33\n\n0\n\nq \u03c01\n\n1\n\nFigure 6: Contour \u03a3\nLemma 4.1. For \u03b3 \u2265 1, Re(\u2212f (z)) is decreasing for z \u2208 \u03a31 \u222a \u03a32 as z travels on the contour along\n\nalong the prescribed orientation. Also when \u03b3 is in a compact subset of [1, \u221e), we can take R > 0\nlarge enough so that\n\nmax Re(\u2212f (z)) \u2264 Re(\u2212f (p\u2217 )),\n\n(229)\n\nz\u2208\u03a33\n\nwhere p\u2217 = \u03c01 + 2i is the intersection of \u03a31 and \u03a32 .\nProof. Any z \u2208 \u03a31 is of the form z = x0 + iy, 0 \u2264 y \u2264 2, x0 := \u03c01 \u2212\nF1 (y) := Re(\u2212f (x0 + iy)) = \u03bc(x0 \u2212 q) \u2212\nThen\n\n2\u01eb\n\u221a\n.\n\u03bd M\n\nSet for y \u2265 0,\n\n1\n1\nln(x20 + y 2 ) + 2 ln((1 \u2212 x0 )2 + y 2 ).\n2\n2\u03b3\n\n\u0001\n2 \u2212 1)y 2 + \u03b3 2 (1 \u2212 x )2 \u2212 x2\n\u2212y\n(\u03b3\n0\n0\nF1\u2032 (y) =\n.\n\u03b3 2 (x20 + y 2 )((1 \u2212 x0 )2 + y 2 )\n36\n\n(230)\n\n(231)\n\n\fBut as 0 < x0 < \u03c01 <\n\n\u03b3\n1+\u03b3 ,\n\na straightforward computation shows that \u03b3 2 (1 \u2212 x0 )2 \u2212 x20 > 0.\n\nTherefore, Re(\u2212f (z)) decreases as z moves along \u03a31 .\nFor z \u2208 \u03a32 , we have z = \u03c01 \u2212 x + 2i,\n\n2\u01eb\n\u221a\n\u03bd M\n\n\u2264 x \u2264 R. Set\n\n1\n1\nF2 (x) := Re(\u2212f (\u03c01 \u2212x+2i)) = \u03bc(\u03c01 \u2212q \u2212x)\u2212 ln((\u03c01 \u2212x)2 +y 2 )+ 2 ln((1\u2212\u03c01 +x)2 +y 2 ). (232)\n2\n2\u03b3\nThen\nF2\u2032 (x) = \u2212\u03bc \u2212\nAs the function g(s) =\n\ns\ns2 +4\n\nx \u2212 \u03c01\nx + 1 \u2212 \u03c01\n+ 2\n.\n2\n(x \u2212 \u03c01 ) + 4 \u03b3 ((x + 1 \u2212 \u03c01 )2 + 4)\n\nsatisfies \u2212 14 \u2264 g(s) \u2264\n\nF2\u2032 (x) \u2264 \u2212\u03bc +\n\n1\n4\n\nfor all s \u2208 R, we find that for all x \u2208 R,\n\n1\n1\n4 \u2212 \u03c01\n3 + \u03c01\n+ 2 =\u2212\n\u2212 2\n4 4\u03b3\n4\u03c01\n4\u03b3 (1 \u2212 \u03c01 )\n\nusing the definition (211) of \u03bc. But as 0 < \u03c01 <\n\n(233)\n\n\u03b3\n\u03b3+1\n\nRe(\u2212f (z)) decreases as z moves on \u03a32 .\n\n(234)\n\n< 1, F2\u2032 (x) < 0 for all x \u2208 R, and we find that\n\nFor z \u2208 \u03a33 , z = \u03c01 \u2212 R + i(2 \u2212 y), 0 \u2264 y \u2264 2. Then for \u03b3 in a compact subset of [1, \u221e), we can\n\ntake R > 0 sufficiently large so that\n\nF3 (y) := Re(\u2212f (\u03c01 \u2212 R + i(2 \u2212 y))\n1\n1\n= \u03bc(\u03c01 \u2212 R \u2212 q) \u2212 ln((\u03c01 \u2212 R)2 + (2 \u2212 y)2 ) + 2 ln((1 \u2212 \u03c01 + R)2 + (2 \u2212 y)2 )\n2\n2\u03b3\n\n(235)\n\ncan be made arbitrarily small. However\nRe(\u2212f (\u03c01 + 2i)) = \u03bc(\u03c01 \u2212 q) \u2212\n\n1\n1\nln(\u03c012 + 4) + 2 ln((1 \u2212 \u03c01 )2 + 4)\n2\n2\u03b3\n\n(236)\n\nis bounded for all \u03b3 \u2265 1. Hence the result (229) follows.\nAs \u03b3 is in a compact subset of [1, \u221e), we assume that\n1 \u2264 \u03b3 \u2264 \u03b30\n\n(237)\n\n\u03b3\n), we assume that there is\nfor some fixed \u03b30 \u2265 1. Also as \u03c01 is in a compact subset of (0, \u03b3+1\n\n0 < \u03a0 < 1/2 such that\n\n\u03a0 \u2264 \u03c01\n\n(238)\n\nFix \u03b4 such that\n\u001a\n\u001b\n\u03a0\n1\n\u03bd2\n0 < \u03b4 < min\n,\n,\n,\n2 2(1 + \u03b30 )3 4C1\nThen for |z \u2212 \u03c01 | \u2264 \u03b4, by using the general inequality\n1\nRe(\u2212f (z) + f (\u03c01 ) + f \u2032\u2032 (\u03c01 )(z \u2212 \u03c01 ) \u2264\n2\n37\n\nC1 :=\n\n\u0012\n\n\u0012\n\u0013\n8 1\n3\n+\n(1\n+\n\u03b3\n)\n.\n0\n3 \u03a03\n\n\u0013\n1 (3)\nmax\n|f (s)| |z \u2212 \u03c01 |3\n|s\u2212\u03c01 |\u2264\u03b4 3!\n\n(239)\n\n(240)\n\n\fand the simple estimate for |s \u2212 \u03c01 | \u2264 \u03b4,\n\n2\n2\n\u2212\ns3 \u03b3 2 (s \u2212 1)3\n2\n2\n\u2264\n+\n(\u03c01 \u2212 \u03b4)3 \u03b302 (1 \u2212 \u03c01 \u2212 \u03b4)3\n16\n128\n\u2264 3 + 2 = 6C1 ,\n\u03a0\n\u03b30\n\n|f (3) (s)| =\n\n(241)\n\nwe find that\n1\nRe(\u2212f (z) + f (\u03c01 ) + f \u2032\u2032 (\u03c01 )(z \u2212 \u03c01 ) \u2264 C1 |z \u2212 \u03c01 |3\n2\n(242)\n\u03bd2\n2\n|z \u2212 \u03c01 | \u2264 \u03b4.\n\u2264 |z \u2212 \u03c01 | ,\n4\nWe split the contour \u03a3 = \u03a3\u2032 \u222a \u03a3\u2032\u2032 where \u03a3\u2032 is the part of \u03a3 in the disk |z \u2212 \u03c0| \u2264 \u03b4, and \u03a3\u2032\u2032 is the\n\u221a\nrest of \u03a3. Let \u03a3\u2032\u221e be the image of \u03a3\u2032 under the map z 7\u2192 \u03bd M (z \u2212 \u03c01 ) and let \u03a3\u2032\u2032\u221e = \u03a3\u221e \\ \u03a3\u2032\u221e .\n\nSet\n\nJ (v) = J \u2032 (v) + J \u2032\u2032 (v),\n\n\u2032\n\u2032\u2032\nJ\u221e (v) = J\u221e\n(v) + J\u221e\n(v)\n\n(243)\n\n\u2032 (v)) is the part of the integral formula of J (v) (resp. J (v)) integrated\nwhere J \u2032 (v) (resp. J\u221e\n\u221e\n\nover the contour \u03a3\u2032 (resp. \u03a3\u2032\u221e ).\n\nLemma 4.1 and the inequality (242) imply that\nmax Re(\u2212f (z) + f (\u03c01 )) \u2264 Re(\u2212f (z0 ) + f (\u03c01 ))\n\nz\u2208\u03a3\u2032\u2032\n\n\u03bd2\n1\n(244)\n\u2264 Re(\u2212 f \u2032\u2032 (\u03c01 )(z0 \u2212 \u03c01 )2 ) + |z0 \u2212 \u03c01 |2\n2\n4\n\u03bd2\n1\n= Re( \u03bd 2 (z0 \u2212 \u03c01 )2 ) + \u03b42 .\n2\n4\nwhere z0 is the intersection in the upper half plane of the circle |s \u2212 \u03c01 | = \u03b4 and the line Re(s) =\n\u03c01 \u2212\n\n2\u01eb\n\u221a\n.\n\u03bd M\n\nAs M \u2192 \u221e, z0 becomes close to \u03c01 + i\u03b4. Therefore when M is sufficiently large,\n\n\u03bd2 2\n\u03b4 .\n(245)\nz\u2208\u03a3\n12\nUsing this estimate and the fact that Re(z \u2212 \u03c01 ) < 0 for z \u2208 \u03a3\u2032\u2032 , an argument similar to that in\nmax\u2032\u2032 Re(\u2212f (z) + f (\u03c01 )) \u2264 \u2212\n\nsubsection 3.2 yields (223). We skip the detail.\n\n4.2\n\nProof of Proposition 4.1 (ii)\n\nBy using the Cauchy's residue theorem, for a contour \u0393\u2032 that encloses all the zeros of g but \u03c01 , we\nfind\n\u221a\n\n\u0012\n\n\u221a\n\u2212\u03bd M u(z\u2212q) M f (z)\n\n1\n(\u03c01 \u2212 z)k g(z)\n\nH(u) =i\u03bd M Resz=\u03c01 e\ne\n\u221a Z\n\u221a\n\u03bd M\n1\n+\ne\u2212\u03bd M u(z\u2212q) eM f (z)\ndz.\n2\u03c0\n(\u03c01 \u2212 z)k g(z)\n\u0393\u2032\n38\n\n\u0013\n\n(246)\n\n\fUsing the choice (220) of q and setting z = \u03c01 +\ng(\u03c01 )e\u2212\u01ebu\n\u221a\nZM H(u) =H1 (u) +\n2\u03c0(\u03bd M )k\u22121\nwhere\n\u2212\u01ebu\n\nH1 (u) := ie\n\nResa=0\n\n\u0012\n\nZ\n\ne\u2212\u03bd\n\n\u221a\n\n\u221aa\n\u03bd M\n\nfor the residue term, we find that\n\nM u(z\u2212\u03c01 ) M (f (z)\u2212f (\u03c01 ))\n\ne\n\n\u0393\u2032\n\n1 \u2212ua M\ne\ne\nak\n\nf (\u03c01 +\n\n\u03bd\n\na\n\u221a\nM\n\n\u0001\n\n)\u2212f (\u03c01 )\n\n1\ndz.\n(z \u2212 \u03c01 )k g(z)\n\n\u0013\ng(\u03c01 )\n.\ng(\u03c01 + \u03bd \u221aaM )\n\n(247)\n\n(248)\n\nWe first show that H1 (u) is close to H\u221e (u). Note that all the derivatives f (l) (\u03c01 ) and g(l) (\u03c01 )\n\nare bounded and |g(\u03c01 )| is strictly positive for \u03b3 and \u03c01 under our assumptions. The function\n\u0001\nM f (\u03c01 + \u221aa )\u2212f (\u03c01 )\n\u03bd M\ne\n(249)\nhas the expansion of the form\n\u2212 12 a2 +a2 c1\n\ne\n\n\u221aa\nM\n\n\u0001\n\n+c2\n\n\u221aa\nM\n\n\u00012\n\n+***\n\n\u0001\n\n(250)\n\nfor some constants cj 's when a is close to 0. On the other hand, the function\ng(\u03c01 )\ng(\u03c01 + \u03bd \u221aaM )\n\n(251)\n\nhas the Taylor expansion of the form\na \u00012\na \u0001\n+ c2 \u221a\n+ ***\n1 + c1 \u221a\nM\nM\n\nfor different constants cj 's. Hence we find the expansion\n\u0001\na\ng(\u03c01 )\n\u2212ua M f (\u03c01 + \u03bd \u221aM )\u2212f (\u03c01 )\ne\ne\ng(\u03c01 + \u03bd \u221aaM )\n\u0013\n\u0012\n\u221e\n\u221e\nX\na \u0001m X\na \u0001l\n\u2212ua\u2212 12 a2\n2l\n=e\n1+\n+\ncl a \u221a\ndl \u221a\nM\nM\nl,m=1\nl=1\n\n(252)\n\n(253)\n\nfor some constants cl , dl . Now as\nResa=0\n\n\u0012\n\n1 \u2212au\u2212 1 a2\n2\ne\nal\n\n\u0013\n\nis a polynomial of degree at most l \u2212 1 in u, we find that\n\u0012\n\u0013\n\u0001\ng(\u03c01 )\n1 \u2212ua M f (\u03c01 + \u221aa )\u2212f (\u03c01 )\n\u03bd M\nResa=0 k e\ne\na\ng(\u03c01 + \u03bd \u221aaM )\n\u0013 X\n\u0012\nk\u22121\n1 2\nq (u)\n1\n\u221aj\n= Resa=0 k e\u2212ua\u2212 2 a +\na\n( M )j\nj=1\n\n39\n\n(254)\n\n(255)\n\n\ffor some polynomials qj . Therefore, due to the factor e\u2212\u01ebu in H1 , for any fixed U \u2208 R, there are\n\nconstants C, c, M0 > 0 such that\n\n\u2212\u01ebu\n\nH1 (u) \u2212 ie\n\nResa=0\n\n\u0012\n\n1 \u2212ua\u2212 1 a2\n2\ne\nak\n\n\u0013\n\nCe\u2212cu\n\u2264 \u221a\nM\n\n(256)\n\nfor all u \u2265 U when M \u2265 M0 .\n\nNow we estimate the integral over \u0393\u2032 in (247). We will choose \u0393\u2032 properly so that the integral is\n\nexponentially small when M \u2192 \u221e. Let \u03c0\u2217 := min{\u03c0k+1 . . . , \u03c0r , 1, \u03bc\u03c01 1 }. Then \u03c01 = * * * = \u03c0k < \u03c0\u2217 .\nLet \u03b4 > 0 and R > max{\u03c0k+1 , . . . , \u03c0r , 1} be determined in Lemma 4.2 below. Define\n\u03c01 + \u03c0\u2217\n+ iy : 0 \u2264 y \u2264 \u03b4}\n2\n\u03c01 + \u03c0\u2217\n\u2264 x \u2264 x0 }\n{x + i\u03b4 :\n2\n1 i(\u03c0\u2212\u03b8)\n\u03c0\n{1 +\ne\n: \u03b80 \u2264 \u03b8 \u2264 }\n1+\u03b3\n2\n1\n: 1 \u2264 x \u2264 R}\n{x + i\n1+\u03b3\n1\n1\n{R + i(\n\u2212 y) : 0 \u2264 y \u2264\n}\n1+\u03b3\n1+\u03b3\n\n\u03931 := {\n\n(257)\n\n\u03932 :=\n\n(258)\n\n\u03933 :=\n\u03934 :=\n\u03935 :=\n\n(259)\n(260)\n(261)\n\nwhere x0 and \u03b80 are defined by the relation\nx0 + i\u03b4 = 1 +\nSet\n\n1 i(\u03c0\u2212\u03b80 )\ne\n.\n1+\u03b3\n\n(262)\n\n\u0001\n\u0001\n\u0393\u2032 = \u222a5j=1 \u0393j \u222a \u222a5j=1 \u0393j .\n\n(263)\n\nSee Figure 7 for \u0393\u2032 and its orientation.\n\n\u03b3\n), there\nLemma 4.2. For \u03b3 in a compact subset of [1, \u221e) and for \u03c01 in a compact subset of (0, 1+\u03b3\n\nexist \u03b4 > 0 and c > 0 such that\n\nRe(f (z) \u2212 f (\u03c01 )) \u2264 \u2212c,\n\nz \u2208 \u03931 \u222a \u03932 .\n\n(264)\n\nAlso Re(f (z)) is a decreasing function in z \u2208 \u03933 \u222a \u03934 , and when R > max{\u03c0k+1 , . . . , \u03c0r , 1} is\n\nsufficiently large,\n\n\u0013\n\u0012\n1\n) \u2212 f (\u03c01 ) ,\nRe(f (z) \u2212 f (\u03c01 )) \u2264 Re f (1 + i\n1+\u03b3\nProof. Note that\n|f \u2032 (z)| = \u2212\u03bc +\n40\n\n1\n\u03b3 \u22122\n\u2212\nz z\u22121\n\nz \u2208 \u03935 .\n\n(265)\n\n(266)\n\n\f\u03931\n\n\u03c01\n\n0\n\n\u03934\n\n\u03933\n\n\u03932\n\n\u03c0\u2217\n\n\u03935\n1\n\nFigure 7: Contour \u03a3\u2032\nis bounded for z in the complex plane minus union of two compact disks centered at 0 and 1. For\n\u03b3 and \u03c01 under the assumption, \u03c01 and\n\n1\n\u03bc\u03c01\n\n\u03b3\n1+\u03b3 ).\n[\u03c01 , \u03bc\u03c01 1 ]\n\nare uniformly away from 0 and 1 (and also from\n\nTherefore, in particular, there is a constant C1 > 0 such that for z = x + iy such that x \u2208\nand y > 0,\n\n|Re(f (x + iy) \u2212 f (x))| \u2264 |f (x + iy) \u2212 f (x)| \u2264 max |f \u2032 (x + isy)| * |y| \u2264 C1 |y|.\n0\u2264s\u22641\n\n(267)\n\nOn the other hand, a straightforward calculation shows that when z = x is real, the function\nRe(f (x) \u2212 f (\u03c01 )) = \u2212\u03bc(x \u2212 q) + ln |x| \u2212 \u03b3 \u22122 ln |1 \u2212 x| \u2212 f (\u03c01 )\ndecreases as x increasing when x \u2208 (\u03c01 , \u03bc\u03c01 1 ). (Recall that \u03c01 and\nand 0 < \u03c01 <\n\u03c0k+1 )/2,\n\n\u03b3\n1+\u03b3\n\n1\n\u03bc\u03c01 ],\n\n<\n\n1\n\u03bc\u03c01\n\n1\n\u03bc\u03c01\n\n(268)\n\nare the two roots of F \u2032 (z) = 0\n\n< 1.) Therefore we find that for z = x + iy such that x \u2208 [(\u03c01 +\n\nRe(f (z) \u2212 f (\u03c01 )) \u2264 Re(f (x) \u2212 f (\u03c01 )) + C1 |y|\n\u0001\n\u03c01 + \u03c0\u2217\n\u2264 Re f (\n) \u2212 f (\u03c01 ) + C1 |y|.\n2\n\n(269)\n\nAs \u03c0\u2217 is in a compact subset of (\u03c01 , 1), we find that there is c1 > 0 such that\nRe(f (z) \u2212 f (\u03c01 )) \u2264 \u2212c1 + C1 |y|\n\n(270)\n\nfor above z, and hence there are \u03b4 > 0 and c > 0 such that for z = x + iy satisfying |y| \u2264 \u03b4,\n\u03c01 +\u03c0\u2217\n2\n\n\u2264x\u2264\n\n1\n\u03bc\u03c01 ,\n\nRe(f (z) \u2212 f (\u03c01 )) \u2264 \u2212c.\n41\n\n(271)\n\n\fNote that as\n\n1\n\u03bc\u03c01\n\n\u03b3\nis in a compact subset of ( \u03b3+1\n, 1) under out assumption, we can take \u03b4 small\n\nenough such that x0 defined by (262) is uniformly left to the point\nz \u2208 \u03a31 \u222a \u03a32 .\n\nFor z = 1 +\n\n1\ni(\u03c0\u2212\u03b8)\n1+\u03b3 e\n\n1\n\u03bc\u03c01 .\n\nTherefore (271) holds for\n\n\u2208 \u03933 ,\n\n1 i(\u03c0\u2212\u03b8) \u0001\ne\n)\n1+\u03b3\n\u0001\n1\n1\n2\n1\n= \u2212\u03bc(1 +\ncos(\u03c0 \u2212 \u03b8) \u2212 q) + ln 1 +\ncos(\u03c0 \u2212 \u03b8) +\n2\n1+\u03b3\n2\n1+\u03b3\n(1 + \u03b3)\n\u0012\n\u0013\n1\n1\n\u2212 2 ln\n.\n\u03b3\n1+\u03b3\n\nF3 (\u03b8) := Re f (1 +\n\n(272)\n\nWe set t = cos(\u03c0 \u2212 \u03b8) and define\nG(t) := F3 (\u03b8) = \u2212\u03bc(1 +\nThen\n\n\u0001\n1\n2\n1\n1\n1\nt \u2212 q) + ln 1 +\nt+\n+ 2 ln(1 + \u03b3).\n2\n1+\u03b3\n2\n1+\u03b3\n(1 + \u03b3)\n\u03b3\n\nG\u2032 (t) = \u2212\u03bc\n\n(1 + \u03b3)\u22121\n1\n+\n1 + \u03b3 1 + 2(1 + \u03b3)\u22121 t + (1 + \u03b3)\u22122\n\n(273)\n\n(274)\n\nis a decreasing function in t \u2208 [\u22121, 1] and hence\n\n\u0013\n\u0012\n1 + \u03b3 \u00012\n1\n, \u22640\n\u2212\u03bc +\nG (t) \u2264 G (\u22121) =\n1+\u03b3\n\u03b3\n\u2032\n\nas the function \u03bc =\n\n1\n\u03c01\n\n\u2032\n\n\u03b3 \u22122\n(1\u2212\u03c01 )\n\n+\n\n\u03b3\n] takes the minimum value\nin \u03c01 \u2208 (0, 1+\u03b3\n\n(275)\n(1+\u03b3)2\n\u03b32\n\nat \u03c0 =\n\n\u03b3\n1+\u03b3 .\n\nTherefore, G(t) is a decreasing function in t \u2208 [\u22121, 1] and Re(f (z)) is a decreasing function in\n\nz \u2208 \u03933 .\n\nSet y1 =\n\nThen\n\n1\n1+\u03b3 .\n\nFor z \u2208 \u03934 , z = x + iy1 , x \u2265 1. Let\n\n\u0001\n\u0001\n1\n1\nF4 (x) := Re f (x + iy1 ) = \u2212\u03bc(x \u2212 q) + ln(x2 + y12 ) \u2212 2 ln (x \u2212 1)2 + y12 .\n2\n2\u03b3\nF4\u2032 (x) = \u2212\u03bc +\n\nx2\n\nx\nx\u22121\n\u0001.\n\u2212 2\n2\n+ y1\n\u03b3 (x \u2212 1)2 + y12\n\n(276)\n\n(277)\n\nBut the last term is non-negative and the middle term is less than 1 as x \u2265 1. Also by the\n\ncomputation of (275), \u03bc \u2265\n\ndecreases as x \u2265 1 increases.\n\n(1+\u03b3)2\n\u03b32\n\nFinally, for z = R + iy, 0 \u2264 y \u2264\n\n\u2265 1. Therefore we find that F4\u2032 (x) \u2264 0 for x \u2265 0, and F4 (x)\n1\n1+\u03b3 ,\n\nRe(f (R + iy)) = \u2212\u03bc(R \u2212 q) +\n\n\u0001\n1\n1\nln(x2 + y 2 ) \u2212 2 ln (x \u2212 1)2 + y 2\n2\n2\u03b3\n42\n\n(278)\n\n\fcan be made arbitrarily small when R is taken large enough, while\n\u0012\n\u0012\n\u0013\n\u0013\n1\n1\n1\n1\n1\n)) = \u2212\u03bc(1 \u2212 q) + ln 1 +\n\u2212 2 ln\nRe(f (1 + i\n1+\u03b3\n2\n(1 + \u03b3)2\n\u03b3\n1+\u03b3\n\n(279)\n\nis bounded.\nThis lemma implies that\nRe(f (z) \u2212 f (\u03c01 )) \u2264 \u2212c\n\n(280)\n\nfor all z \u2208 \u0393\u2032 . Also note that Re(z \u2212 \u03c01 ) > 0 for z \u2208 \u0393\u2032 . Therefore for any fixed U \u2208 R, there are\nconstants C, c, M0 > 0 such that\nZ\n\u221a\ng(\u03c01 )e\u2212\u01ebu\n1\n\u221a\ndz \u2264 Ce\u2212\u01ebu e\u2212cM\ne\u2212\u03bd Mu(z\u2212\u03c01 ) eM (f (z)\u2212f (\u03c01 ))\nk g(z)\nk\u22121\n(z\n\u2212\n\u03c0\n)\n\u2032\n2\u03c0(\u03bd M )\n1\n\u0393\n\n(281)\n\nfor M > M0 and for u \u2265 U . Together with (256), this implies Proposition 4.1 (ii).\n\n4.3\n\nProof of Theorem 1.1 (b)\n\nFrom the Proposition 4.1 and the discussion in the subsection 2.2, we find that under the assumption\nof Theorem 1.1 (b)\nP\n\n\u0012\n\n1\n\u03b3 \u22122 \u0001\u0001\n\u03bb1 \u2212\n+\n*q\n\u03c01 1 \u2212 \u03c01\n\n\u221a\n1\n\u03c012\n\nM\n\u03b3 \u22122\n(1\u2212\u03c01 )2\n\n\u2212\n\n\u2264x\n\n\u0013\n\n(282)\n\nconverges, as M \u2192 \u221e, to the Fredholm determinant of the operator acting on L2 ((0, \u221e)) given by\n\nthe kernel\n\nZ\n\n\u221e\n0\n\nH\u221e (x + u + y)J\u221e (x + v + y)dy.\n\n(283)\n\nNow we will express the terms H\u221e (u) and J\u221e (v) in terms of the Hermite polynomials.\nThe generating function formula (see (1.13.10) of [24]) of Hermite polynomials Hn ,\n\u221e\nX\nHn (x)\n\nn=0\n\nn!\n\n2\n\ntn = e2xt\u2212t ,\n\n(284)\n\nimplies that\n\u01ebu\n\n\u2212ie H\u221e (u) = Resa=0\n\n\u0012\n\n1 \u2212 1 a2 \u2212(u+y)a\ne 2\nak\n\n\u0013\n\n=\n\n(\u22121)k\u22121 (2\u03c0)1/4\np\npk\u22121 (u),\n(k \u2212 1)!\n\n(285)\n\nwhere the orthonormal polynomial pk\u22121 (x) is defined in (31). The forward shift operator formula\n(see (1.13.6) of [24])\nHn\u2032 (x) = 2nHn\u22121 (x)\n\n(286)\n\n\u221a\n\n(287)\n\nimplies that\np\u2032k (y) =\n\nkpk\u22121 (y),\n\n43\n\n\fand hence\n\n\u0012\n\n\u0013\n\n(\u22121)k\u22121 (2\u03c0)1/4 \u2032\n\u221a\npk (u).\nk!\nOn the other hand, the Rodrigues-type formula (see (1.13.9) of [24])\n\u0012\n\u0013\nd n \u2212x2\nx2\nHn (x) = e\n\u2212\n[e ]\ndx\n\u01ebu\n\n\u2212ie H\u221e (u) = Resa=0\n\nimplies that\n\n1 \u2212 1 a2 \u2212(u+y)a\ne 2\nak\n\n(288)\n\n=\n\n(289)\n\n\u0012 \u0013n\nd\n(\u22121)n\n2\n\u03be 2 /2\n\u221a e\npn (\u03be) =\n[e\u2212\u03be /2 ].\n1/4\nd\u03be\n(2\u03c0)\nn!\n\n(290)\n\nSine the integral which appears in J\u221e (v) is equal to\n\u0012 \u0013k Z\n\u0012 \u0013k\nZ\n1 2\n1 2\nd\nd\n2\ne\u2212v /2 ,\ne 2 s +vs ds = i\nsk e 2 s +vs ds =\ndv\ndv\n\u03a3\u221e\n\u03a3\u221e\nwe find\n\n(291)\n\n\u221a\n2\ne\u2212\u01ebv J\u221e (v) = (\u22121)k i(2\u03c0)\u22121/4 k!e\u2212v /2 pk (v).\n\n(292)\n\nAfter a trivial translation, the Fredholm determinant of the operator (283) is equal to the\nFredholm determinant of the operator acting on L2 ((x, \u221e)) with the kernel\nZ \u221e\nH\u221e (u + y)J\u221e (v + y)dy.\nK2 (u, v) :=\n\n(293)\n\n0\n\nBy (288) and (292),\n(u \u2212 v)K2 (u, v)e\u01eb(u\u2212v) =\n\nZ\n\n\u221e\n\n0\n\n\u2212\n\nZ\n\n2 /2\n\n(u + y) * p\u2032k (u + y)pk (v + y)e\u2212(v+y)\n\u221e\n\n0\n\np\u2032k (u\n\ndy\n\n\u2212(v+y)2 /2\n\n+ y)pk (v + y) * (v + y)e\n\n(294)\ndy.\n\nNote that pk satisfies the differential equation\np\u2032\u2032k (y) \u2212 yp\u2032k (y) + kpk (y) = 0,\n\n(295)\n\nwhich follows from the differential equation\nHn\u2032\u2032 (x) \u2212 2xHn\u2032 (x) + 2nHn (x) = 0\n\n(296)\n\nfor the Hermite polynomial (see (1.13.5) of [24]). Now use (295) for the first integral of (294) by\n/2\n\nand integrate by parts of the second integral by noting that (v + y)e\u2212(v+y)\nobtain\n\u01eb(u\u2212v)\n\n(u \u2212 v)K2 (u, v)e\n\nZ\n\n\u221e\n\n=\n\nd \u2212(v+y)2 /2\ndy e\n\n2\n\nkpk (u + y)pk (v + y)e\u2212(v+y) /2 dy\n0\nZ \u221e\n2\n\u2032\n\u2212v2 /2\np\u2032k (u + y)p\u2032k (v + y)e\u2212(v+y) /2 dy.\n\u2212 pk (u)pk (v)e\n\u2212\n=\n\nto\n\n0\n\n44\n\n(297)\n\n\fNote that the terms involving p\u2032\u2032k (u + y) are cancelled out. Then integrating by parts the second\nd\ndy pk (u\n\nintegral and noting that p\u2032k (u + y) =\n\n+ y), we obtain\n\n(u \u2212 v)K2 (u, v)e\u01eb(u\u2212v) = \u2212p\u2032k (u)pk (v)e\u2212v\n\n2 /2\n\n+ pk (u)p\u2032k (v)e\u2212v\n\n2 /2\n\n.\n\n(298)\n\nBy using (287), this implies that\nK2 (u, v) =\n\n\u221a\n\nke\u2212\u01ebu\n\npk (u)pk\u22121 (v) \u2212 pk\u22121 (u)pk (v) \u2212v2 /2 \u01ebv\ne\ne .\nu\u2212v\n\n(299)\n\nTherefore, upon conjugations, the Fredholm determinant of K2 is equal to the Fredholm determinant det(1 \u2212 Hx ) in (33). This completes the proof of Theorem 1.1 (b).\n\n5\n\nSamples of finitely many variables\n\nIn this section, we prove Proposition 1.1.\nWe take M \u2192 \u221e and fix N = k. We suppose that\n\u03c01 = * * * = \u03c0k .\n\n(300)\n\nThen from (60), the density of the eigenvalues is\nk\n\nY\n1\n\u2212k\np(\u03bb) = V (\u03bb)2\ne\u2212M \u03c01 \u03bbj \u03bbM\n,\nj\nC\n\n(301)\n\nj=1\n\nand hence\n1\nP(\u03bb1 \u2264 t) =\nC\nwhere\nC=\n\nZ\n\nt\n\n***\n\n0\n\nQk\u22121\n\nj=0 (1\n\nBy using the change of the variables yj =\n\u0012\n\nx\n1\n+ \u221a\nP \u03bb1 \u2264\n\u03c01 \u03c01 M\n\n\u0013\n\n=\n\ne\u2212kM\nkM\n\u03c01 M k2 /2 C\n\nAs M \u2192 \u221e while k is fixed, \u03c01kM M k\n\nconvergence theorem,\n\nlim P\n\nM \u2192\u221e\n\nZ\n\nZ\n\n2 /2\n\n\u0012\n\n1\n\u03c01\nx\n\u221a\n\nt\n\n2\n\nV (y)\n0\n\nk\nY\n\ne\u2212M \u03c01 yj yjM \u2212k dyj\n\n+ j)!(M \u2212 k + j)!\n\n(M \u03c01 )M k\n\u03bej \u0001\n1 + \u221aM\n,\n\n\u2212 M\n\n(302)\n\nj=1\n\n***\n\nZ\n\nx\n\n\u221a\n\nV (\u03be)2\n\n\u2212 M\n\nk\nY\n\n(303)\n\ne\u2212\n\nj=1\n\nekM C \u2192 (2\u03c0)k/2\n\n1\u0001 \u221a\n\u03c01 M x\n\u03bb1 \u2212\n\u03c01\n\n.\n\nQk\u22121\n\n\u0013\n\nj=0 (1\n\n\u221a\n\nM \u03bej\n\n\u03bej\n(1 + \u221a )M \u2212k d\u03bej . (304)\nM\n\n+ j)!. By using the dominated\n\n= Gk (x).\n\nThe result (51) follows from (305) and the fact that Gk is a distribution function.\n45\n\n(305)\n\n\f6\n\nLast passage percolation, queueing theory and heuristic arguments\n\nThere is a curious connection between complex Gaussian sample covariance matrices and a last\npassage percolation model.\nConsider the lattice points (i, j) \u2208 Z2 . Suppose that to each (i, j), i = 1, . . . , N , j = 1, . . . , M ,\n\nan independent random variable X(i, j) is associated. Let (1, 1) \u0580 (N, M ) be the set of 'up/right\n\nN +M \u22121\npaths' \u03c0 = {(ik , jk )}k=1\nwhere (ik+1 , jk+1 ) \u2212 (ik , jk ) is either (1, 0) or (0, 1), and (i1 , j1 ) = (1, 1)\n\u22122\u0001\nand (iN +M \u22121 , jN +M \u22121 ) = (N, M ). There are N +M\nsuch paths. Define\nN \u22121\nX\nL(N, M ) :=\nmax\nX(i, j).\n(306)\n\u03c0\u2208(1,1)\u0580(N,M )\n\n(i,j)\u2208\u03c0\n\nIf X(i, j) is interpreted as time spent to pass through the site (i, j), L(N, M ) is the last passage\ntime to travel from (1, 1) to (N, M ) along an admissible up/right path.\nLet \u03c01 , . . . , \u03c0N be positive numbers. When X(i, j) is the exponential random variable of mean\n1\n\u03c0i M\n\n(the density function of X(i, j) is \u03c0i M e\u2212\u03c0i M x , x \u2265 0), it is known that L(N, M ) has the\n\nsame distribution as the largest eigenvalue of the complex Gaussian sample covariance matrix of\nM sample vectors of N variables (see (61)): for M \u2265 N ,\nZ x det e\u2212M \u03c0i \u03bej \u0001\nZ\nN\nY\n1 x\n1\u2264i,j\u2264N\nP(L(N, M ) \u2264 x) =\n\u03bejM \u2212N d\u03bej .\nV (\u03be)\n***\nC 0\nV\n(\u03c0)\n0\n\n(307)\n\nj=1\n\nWe emphasize that X(i, j), j = 1, 2, . . . , M are identically distributed for each fixed i. As a\nconsequence, we have the following. Recall that\n\u03c0j\u22121 = lj .\n\n(308)\n\nProposition 6.1. Let L(M, N ) be the last passage time in the above percolation model with exponential random variables at each site. Let \u03bb1 be the largest eigenvalue of M (complex) samples of\nN \u00d7 1 vectors as in Introduction. Then for any x \u2208 R,\nP(L(M, N ) \u2264 x) = P(\u03bb1 (M, N ) \u2264 x).\n\n(309)\n\nFormula (307) for the case of \u03c01 = * * * = \u03c0N was obtained in Proposition 1.4 of [21]. The general\n\ncase follows from a suitable generalization. Indeed, let xi , yj \u2208 [0, 1) satisfy 0 \u2264 xi yj < 1 for all\n\ni, j. When the attached random variable, denoted by Y (i, j), is the geometric random variable of\n\nparameter xi yj (i.e. P(X(i, j) = k) = (1 \u2212 xi yj )(xi yj )k , k = 0, 1, 2, . . . ), the last passage time,\nG(N, M ), from (1, 1) to (N, M ) defined as in (306) is known to satisfy\nY\nX\ns\u03bb (x)s\u03bb (y)\nP(G(N, M ) \u2264 n) =\n(1 \u2212 xi yj ) *\ni,j\u22651\n\n\u03bb:\u03bb1 \u2264n\n\n46\n\n(310)\n\n\fwhere the sum is over all partitions \u03bb = (\u03bb1 , \u03bb2 , . . . ) such that the first part \u03bb1 \u2264 n, and s\u03bb\n\ndenotes the Schur function, x = (x1 , x2 , . . . ) and y = (y1 , y2 , . . . ). This identity was obtained by\n\nusing the Robinson-Schensted-Knuth correspondence between generalized permutations (matrices\nof non-negative integer entries) and pairs of semistandard Young tableaux (see, e.g. [21], [30], (7.30)\nof [6]). The normalization constant follows from the well-known Cauchy identity (see, e.g. [36])\nX\nY\ns\u03bb (x)s\u03bb (y) =\n(1 \u2212 xi yj )\n(311)\ni,j\u22651\n\n\u03bb\n\nwhere the sum is over all partitions. Now set xi = 1 \u2212 ML\u03c0i , i = 1, . . . , N , xi = 0, i > N and yj = 1,\nj = 1, . . . , M , yj = 0, j > M , and n = xL. By taking L \u2192 \u221e, it is easy to compute that\n\n1\nLY\n\n(i, j)\n\nconverges to the exponential random variable X(i, j), while one can check that the summation on\nthe right-hand-side of (310) converges to the right-hand-side of (307), and hence the identity (307)\nfollows. There are determinantal formulas for the right-hand-side of (310) (see e.g. [16], [21], [30]),\nsome of which, by taking the above limit, would yield an alternative derivation of Proposition 2.1.\nAnother equivalent model is a queuing model. Suppose that there are N tellers and M customers. Suppose that initially all M customers are on the first teller in a queue. The first customer\nwill be served from the first teller and then go to the second teller. Then the second customer will\ncome forward to the first teller. If the second customer finishes his/her business before the first\ncustomer finishes his/her business from the second teller, the second customer will line up a queue\nin the second teller, and so on. At any instance, only one customer can be served at a teller and\nall customers should be served from all tellers in the order. The question is the total exit time\nE(M, N ) for M customers to exit from N queues. We assume that the service time at teller i is\ngiven by the exponential random variable of mean\n\n1\n\u03c0i M .\n\nAssuming the independence, consideration\n\nof the last customer in the last queue will yield the recurrence relation\nE(M, N ) = max{E(M \u2212 1, N ), E(M, N \u2212 1)} + e(N )\n\n(312)\n\nwhere e(N ) denotes the service time at the teller N . But note that the last passage time in the\npercolation model also satisfies the same recurrence relation\nL(M, N ) = max{L(M \u2212 1, N ), L(M, N \u2212 1)} + X(M, N )\n\n(313)\n\nwhere X(M, N ) is the same exponential random variable as e(N ). Therefore we find that E(M, N )\nand L(M, N ) have the same distribution. Thus all the results in Introduction also applied to\nE(M, N ).\nNow we indicate how the critical value lj = \u03c0j\u22121 = 1 + \u03b3 \u22121 of Theorem 1.1 can be predicted in\nthe last passage percolation model.\n47\n\n\fFirst, when X(i, j) are all identical exponential random variables of mean 1, Theorem 1.6 of\n[21] shows that, as M, N \u2192 \u221e such that M/N is in a compact subset of (0, \u221e), L(N, M ) is\n\napproximately\n\n\u221a\n\u221a\n\u221a 2 ( M + N )4/3\n\u221a\n\u03c70\nL(N, M ) \u223c L(M, N ) \u223c ( M + N ) +\n(M N )1/6\n\n(314)\n\nwhere \u03c70 denotes the random variable of the GUE Tracy-Widom distribution. On the other hand,\nnote that when N = 1, X(1, j) are independent, identically distributed exponential random variables of mean\n\n1\nM \u03c01 ,\n\nand hence the classical central limit theorem implies that the last passage time\n\nfrom (1, 1) to (1, xM ) is approximately\nx\u03c0 \u22121\n\u03c01\u22121 x + \u221a 1 g\nM\n\n(315)\n\nwhere g denotes the standard normal random variable. Note the different fluctuations which is due\nto different dimensions of two models.\nNow consider the case when r = 1 in Theorem 1.1 i.e. \u03c02 = \u03c03 = * * * = \u03c0N = 1; X(i, j),\n\n1 \u2264 j \u2264 M is exponential of mean\n1\nM.\n\nWe take M/N =\n\n\u03b32\n\n1\nM \u03c01\n\nand X(i, j), 2 \u2264 i \u2264 N , 1 \u2264 j \u2264 M is exponential of mean\n\n\u2265 1. An up/right path consists of two pieces; a piece on the first column\n\n(1, j) and the other piece in the 'bulk', (i, j), i \u2265 2. Of course the first part might be empty. We\nwill estimate how long the last passage path stays in the first column. Consider the last passage\npath conditioned that it lies on the first column at the sites (1, 1), (1, 2), . . . (1, xM ) and then enters\nto the bulk (i, j), i \u2265 2. See Figure 8. Then from (315) and (314), we expect that the (conditioned)\n\nlast passage time is, to the leading order,\n\n\u221a\nf (x) = \u03c01\u22121 x + ( 1 \u2212 x + \u03b3 \u22121 )2 .\n\n(316)\n\nIt is reasonable to expect that the last passage time is the maximum of f (x) over x \u2208 [0, 1], to the\nleading order. An elementary Calculus shows that\n\uf8f1\n\uf8f2f (0) = (1 + \u03b3 \u22121 )2 ,\nmax f (x) =\n\uf8f3f 1 \u2212 \u03b3 \u22122 \u0001 = 1 +\nx\u2208[0,1]\n\u03c01\n(\u03c0 \u22121 \u22121)2\n\n\u03b3 \u22122\n1\u2212\u03c01 ,\n\nif \u03c0 \u22121 \u2264 1 + \u03b3 \u22121\nif \u03c0 \u22121 > 1 + \u03b3 \u22121 .\n\n(317)\n\nWhen max f occurs at x = 0, the last passage path enters directly into the bulk and hence the\nfluctuation of the last passage time is of of M \u22122/3 due to (314). But if the max f (x) occurs for\nsome x > 0, then the fluctuation is M \u22121/2 due to (315), which is larger than the fluctuation M \u22122/3\nfrom the bulk. Note that the value of max f in (317) agrees with the leading term in the scaling of\nTheorem 1.1. This provides an informally explanation of the critical value 1 + \u03b3 \u22121 of \u03c01\u22121 .\nIf one can make this kind of argument for the sample covariance matrix, one might be able to\ngeneralize it to real sample covariance matrix.\n48\n\n\fM\n...\nxM\n...\n3\n2\n1\n1\n\n2\n\n...\n\n3\n\nN\n\nFigure 8: Last passage percolation when r = 1\n\nReferences\n[1] C. Andr\u00e9ief. Note sur une relation les int\u00e9grales d\u00e9finies des produits des fonctions. M\u00e9m. de\nla Soc. Sci. Bordeaux, 2, 1883.\n[2] Z. Bai. Methodologies in spectral analysis of large-dimensional random matrices, a review.\nStatist. Sinica, 9:611\u2013677, 1999.\n[3] Z. Bai and J. Silverstein. On the empirical distribution of eigenvalues of a class of large\ndimensional random matrices. J. Multivariate Anal., 54:175\u2013192, 1995.\n[4] J. Baik. Painlev\u00e9 formulas of the limiting distributions for non-null complex sample covariance\nmatrices. in preparation.\n[5] J. Baik and E. M. Rains. Limiting distributions for a polynuclear growth model with external\nsources. J. Stat. Phys., 100(3/4):523\u2013541, 2000.\n[6] J. Baik and E. M. Rains. Algebraic aspects of increasing subsequences. Duke Math. J.,\n109(1):1\u201365, 2001.\n[7] J. Baik and E. M. Rains. The asymptotics of monotone subsequences of involutions. Duke\nMath. J., 109(2):205\u2013281, 2001.\n49\n\n\f[8] A. Borodin and P. Forrester. Increasing subsequences and the hard-to-soft edge transition in\nmatrix ensembles. J. Phys. A., 36(12):2963\u20132981, 2003.\n[9] A. Buja, T. Hastie, and R. Tibshirani. Penalized discriminant analysis. Ann. Statist., 23:73\u2013\n102, 1995.\n[10] P. Deift and X. Zhou. Asymptotics for the Painlev\u00e9 II equation. Comm. Math. Phys., 48:277\u2013\n337, 1995.\n[11] P. Forrester. Painlev\u00e9 transcendent evaluation of the scaled distribution of the smallest eigenvalue in the Laguerre orthogonal and symplectic ensembles. arXive:nlin.SI/0005064.\n[12] P. Forrester. Log-gases and Random matrices. http://www.ms.unimelb.edu.au/~matpjf/matpjf.html,\nin progress.\n[13] P. Forrester and E. Rains. Interpretations of some parameter dependent generalizations of\nclassical matrix ensembles. to appear in Prob. Theory and Related Fields.\n[14] P.J. Forrester. The spectrum edge of random matrix ensembles. Nuclear Physics B, 402:709\u2013\n728, 1993.\n[15] S. Geman. A limit theorem for the norm of random matrices. Ann. Probab., 8(2):252\u2013261,\n1980.\n[16] I. Gessel. Symmetric functions and P-recursiveness. J. Combin. Theory Ser. A, 53:257\u2013285,\n1990.\n[17] S. Hastings and J. McLeod. A boundary value problem associated with the second Painlev\u00e9\ntranscendent and the Korteweg de Vries equation. Arch. Rational Mech. Anal., 73:31\u201351, 1980.\n[18] D. Hoyle and M. Rattray. Limiting form of the sample covariance eigenspectrum in PCA and\nkernel PCA. to appear in proceedings of Neural Information Processing Systems 2003.\n[19] A. James. Distributions of matrix variates and latent roots derived from normal samples.\nAnnals of Mathematical Statistics, 35:475\u2013501, 1964.\n[20] K. Johansson. private communication.\n[21] K. Johansson. Shape fluctuations and random matrices. Comm. Math. Phys., 209(2):437\u2013476,\n2000.\n[22] K. Johansson. Discrete orthogonal polynomial ensembles and the Plancherel measure. Ann.\nof Math. (2), 153:259\u2013296, 2001.\n50\n\n\f[23] I.M Johnstone. On the distribution of the largest Principal Component. Ann. Statist., 29:295\u2013\n327, 2001.\n[24] R. Koekoek and R. Swarttouw. The Askey-scheme of hypergeometric orthogonal polynomials\nand its q-analogue. http://aw.twi.tudelft.nl\u223ckoekoek/askey.html.\n[25] L. Laloux, P. Cizeau, M. Potters, and J. Bouchaud. Random matrix theory and financial\ncorrelations. Intern. J. Theor. Appl. Finanace, 3(3):391\u2013397, 2000.\n[26] Y. Malevergne and D. Sornette. Collective origin of the coexistance of apparent RMT noise\nand factors in large sample correlation matrices. arxiv:cond-mat/0210115.\n[27] V.A. Marcenko and L.A. Pastur. Distribution of eigenvalues for some sets of random matrices.\nMath. USSR-Sbornik, 1:457\u2013486, 1967.\n[28] M. Mehta. Random matrices. Academic press, San Diago, second edition, 1991.\n[29] R. Muirhead. Aspects of multivariate statistical theory. Wiley Series in Probability and Mathematical Statistics., 1982.\n[30] A. Okounkov. Infinite wedge and random partitions. Selecta Math. (N.S.), 7(1):57\u201381, 2001.\n[31] S. P\u00e9ch\u00e9. Universality of local eigenvalue statistics for random sample covariance matrices.\nPh.D. Thesis, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, 2003.\n[32] V. Plerous, P. Gopikrishnan, B. Rosenow, L. Amaral, T. Guhr, and H. Stanley. Random\nmatrix approach to cross correlations in financial data. Phys. Rev. E, 65(6):066126, 2002.\n[33] M. Pr\u00e4hofer and H. Spohn. Current fluctuations for the totally asymmetric simple exclusion process. In V. Sidoravicius, editor, In and out of equilibrium, volume 51 of Progress in\nProbability, pages 185\u2013204. Birkh\u00e4user Boston, 2000.\n[34] R. Sear and J. Cuesta. Instabilities in complex mixtures with a large number of components.\nPhys. Rev. Lett., 91(24):245701, 2003.\n[35] A. Soshnikov. A note on universality of the distribution of the largest eigenvalues in certain\nsample covariance matrices. J. Statist. Phys, 108(5-6), 2001.\n[36] R. P. Stanley. Enumerative Combinatorics, volume 2. Cambridge University Press, Cambridge,\nUnited Kingdom, 1999.\n[37] E. Telatar. Capacity of milti-antenna Gaussian channels. European transactions on Telecommunications, 10(6):585\u2013595, 1999.\n51\n\n\f[38] C. Tracy and H. Widom. Fredholm determinants, differential equations and matrix models.\nComm. Math. Phys, 163:33\u201372, 1994.\n[39] C. Tracy and H. Widom. Level spacing distributions and the Airy kernel. Comm. Math. Phys.,\n159:33\u201372, 1994.\n[40] C. Tracy and H. Widom. On orthogonal and symplectic matrix ensembles. Comm. Math.\nPhys., 177:727\u2013754, 1996.\n[41] C. Tracy and H. Widom. Correlation functions,cluster functions and spacing distributions for\nrandom matrices. J. Stat. Phys., 92, no 5-6:809\u2013835, 1998.\n\n52\n\n\f"}