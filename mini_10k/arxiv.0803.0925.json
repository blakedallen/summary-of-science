{"id": "http://arxiv.org/abs/0803.0925v3", "guidislink": true, "updated": "2010-01-22T16:50:03Z", "updated_parsed": [2010, 1, 22, 16, 50, 3, 4, 22, 0], "published": "2008-03-06T17:42:38Z", "published_parsed": [2008, 3, 6, 17, 42, 38, 3, 66, 0], "title": "Robust Smoothed Analysis of a Condition Number for Linear Programming", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0803.2380%2C0803.1569%2C0803.2369%2C0803.1501%2C0803.3725%2C0803.1000%2C0803.3273%2C0803.0585%2C0803.0437%2C0803.1665%2C0803.3633%2C0803.3131%2C0803.0259%2C0803.4199%2C0803.1122%2C0803.4101%2C0803.2330%2C0803.4011%2C0803.0597%2C0803.0475%2C0803.3724%2C0803.3494%2C0803.3271%2C0803.1463%2C0803.0612%2C0803.0911%2C0803.0694%2C0803.1557%2C0803.0862%2C0803.3213%2C0803.3667%2C0803.2047%2C0803.0484%2C0803.0027%2C0803.1003%2C0803.3749%2C0803.0502%2C0803.2097%2C0803.0974%2C0803.1137%2C0803.3391%2C0803.1251%2C0803.2981%2C0803.4218%2C0803.3328%2C0803.3288%2C0803.0552%2C0803.4328%2C0803.0765%2C0803.3689%2C0803.2045%2C0803.4025%2C0803.3125%2C0803.0667%2C0803.3201%2C0803.3581%2C0803.1934%2C0803.2762%2C0803.2717%2C0803.4195%2C0803.4045%2C0803.0722%2C0803.0925%2C0803.3094%2C0803.2208%2C0803.3232%2C0803.4334%2C0803.0433%2C0803.2612%2C0803.2830%2C0803.4215%2C0803.0288%2C0803.4490%2C0803.4150%2C0803.2545%2C0803.1624%2C0803.1385%2C0803.0735%2C0803.0984%2C0803.2852%2C0803.2733%2C0803.3593%2C0803.4419%2C0803.3654%2C0803.3049%2C0803.1487%2C0803.0956%2C0803.0845%2C0803.0273%2C0803.3322%2C0803.2279%2C0803.1550%2C0803.1143%2C0803.3853%2C0803.2308%2C0803.1997%2C0803.3835%2C0803.2485%2C0803.1163%2C0803.3573%2C0803.1763&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Robust Smoothed Analysis of a Condition Number for Linear Programming"}, "summary": "We perform a smoothed analysis of the GCC-condition number C(A) of the linear\nprogramming feasibility problem \\exists x\\in\\R^{m+1} Ax < 0. Suppose that\n\\bar{A} is any matrix with rows \\bar{a_i} of euclidean norm 1 and,\nindependently for all i, let a_i be a random perturbation of \\bar{a_i}\nfollowing the uniform distribution in the spherical disk in S^m of angular\nradius \\arcsin\\sigma and centered at \\bar{a_i}. We prove that E(\\ln C(A)) =\nO(mn / \\sigma). A similar result was shown for Renegar's condition number and\nGaussian perturbations by Dunagan, Spielman, and Teng [arXiv:cs.DS/0302011].\nOur result is robust in the sense that it easily extends to radially symmetric\nprobability distributions supported on a spherical disk of radius\n\\arcsin\\sigma, whose density may even have a singularity at the center of the\nperturbation. Our proofs combine ideas from a recent paper of B\\\"urgisser,\nCucker, and Lotz (Math. Comp. 77, No. 263, 2008) with techniques of Dunagan et\nal.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0803.2380%2C0803.1569%2C0803.2369%2C0803.1501%2C0803.3725%2C0803.1000%2C0803.3273%2C0803.0585%2C0803.0437%2C0803.1665%2C0803.3633%2C0803.3131%2C0803.0259%2C0803.4199%2C0803.1122%2C0803.4101%2C0803.2330%2C0803.4011%2C0803.0597%2C0803.0475%2C0803.3724%2C0803.3494%2C0803.3271%2C0803.1463%2C0803.0612%2C0803.0911%2C0803.0694%2C0803.1557%2C0803.0862%2C0803.3213%2C0803.3667%2C0803.2047%2C0803.0484%2C0803.0027%2C0803.1003%2C0803.3749%2C0803.0502%2C0803.2097%2C0803.0974%2C0803.1137%2C0803.3391%2C0803.1251%2C0803.2981%2C0803.4218%2C0803.3328%2C0803.3288%2C0803.0552%2C0803.4328%2C0803.0765%2C0803.3689%2C0803.2045%2C0803.4025%2C0803.3125%2C0803.0667%2C0803.3201%2C0803.3581%2C0803.1934%2C0803.2762%2C0803.2717%2C0803.4195%2C0803.4045%2C0803.0722%2C0803.0925%2C0803.3094%2C0803.2208%2C0803.3232%2C0803.4334%2C0803.0433%2C0803.2612%2C0803.2830%2C0803.4215%2C0803.0288%2C0803.4490%2C0803.4150%2C0803.2545%2C0803.1624%2C0803.1385%2C0803.0735%2C0803.0984%2C0803.2852%2C0803.2733%2C0803.3593%2C0803.4419%2C0803.3654%2C0803.3049%2C0803.1487%2C0803.0956%2C0803.0845%2C0803.0273%2C0803.3322%2C0803.2279%2C0803.1550%2C0803.1143%2C0803.3853%2C0803.2308%2C0803.1997%2C0803.3835%2C0803.2485%2C0803.1163%2C0803.3573%2C0803.1763&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We perform a smoothed analysis of the GCC-condition number C(A) of the linear\nprogramming feasibility problem \\exists x\\in\\R^{m+1} Ax < 0. Suppose that\n\\bar{A} is any matrix with rows \\bar{a_i} of euclidean norm 1 and,\nindependently for all i, let a_i be a random perturbation of \\bar{a_i}\nfollowing the uniform distribution in the spherical disk in S^m of angular\nradius \\arcsin\\sigma and centered at \\bar{a_i}. We prove that E(\\ln C(A)) =\nO(mn / \\sigma). A similar result was shown for Renegar's condition number and\nGaussian perturbations by Dunagan, Spielman, and Teng [arXiv:cs.DS/0302011].\nOur result is robust in the sense that it easily extends to radially symmetric\nprobability distributions supported on a spherical disk of radius\n\\arcsin\\sigma, whose density may even have a singularity at the center of the\nperturbation. Our proofs combine ideas from a recent paper of B\\\"urgisser,\nCucker, and Lotz (Math. Comp. 77, No. 263, 2008) with techniques of Dunagan et\nal."}, "authors": ["Peter B\u00fcrgisser", "Dennis Amelunxen"], "author_detail": {"name": "Dennis Amelunxen"}, "author": "Dennis Amelunxen", "arxiv_comment": "34 pages. Version 3: only cosmetic changes", "links": [{"href": "http://arxiv.org/abs/0803.0925v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0803.0925v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.OC", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.OC", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "90C05, 90C31, 52A22, 60D05", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0803.0925v3", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0803.0925v3", "journal_reference": "Mathematical Programming 131(1): 221-251 (2012)", "doi": null, "fulltext": "arXiv:0803.0925v3 [math.OC] 22 Jan 2010\n\nRobust Smoothed Analysis of a Condition\nNumber for Linear Programming\nPeter B\u00fcrgisser\u2217 and Dennis Amelunxen\u2217\nUniversity of Paderborn\n{pbuerg,damelunx}@math.upb.de\nNovember 3, 2018\n\nAbstract\nWe perform a smoothed analysis of the GCC-condition number C (A)\nof the linear programming feasibility problem \u2203x \u2208 Rm+1 Ax < 0.\nSuppose that \u0100 is any matrix with rows ai of euclidean norm 1 and,\nindependently for all i, let ai be a random perturbation of ai following the uniform distribution in the spherical disk in S m of angular radius arcsin \u03c3 and centered at ai . We prove that E(ln C (A)) =\nO(mn/\u03c3). A similar result was shown for Renegar's condition number and Gaussian perturbations by Dunagan, Spielman, and Teng\n[arXiv:cs.DS/0302011]. Our result is robust in the sense that it easily\nextends to radially symmetric probability distributions supported on\na spherical disk of radius arcsin \u03c3, whose density may even have a singularity at the center of the perturbation. Our proofs combine ideas\nfrom a recent paper of B\u00fcrgisser, Cucker, and Lotz (Math. Comp. 77,\nNo. 263, 2008) with techniques of Dunagan et al.\n\nAMS subject classifications: 90C05, 90C31, 52A22, 60D05\nKey words: linear programming, perturbation, condition number, smoothed\nanalysis, spherically convex sets\n\n1\n\nIntroduction\n\nA distinctive feature of the computations considered in numerical analysis is\nthat they are affected by errors. A main character in the understanding of\n\u2217\n\nInstitute of Mathematics, University of Paderborn, Germany. Partially supported by\nDFG grant BU 1371/2-1 and DFG Research Training Group on Scientific Computation\nGRK 693 (PaSCo GK).\n\n1\n\n\fthe effects of these errors is the condition number of the input at hand. This\nis a positive number measuring the sensitivity of the output with respect\nto small perturbations of the input. The best known condition number is\nthat for matrix inversion and linear equation solving, which takes the form\n\u03ba(A) = kAk kA\u22121 k for a square matrix A. Condition numbers not only occur\nin round-off analysis, but also appear as a parameter in complexity bounds\nfor a variety of iterative algorithms in linear algebra, linear and convex\noptimization, and polynomial equation solving. Yet, condition numbers are\nnot easily computable. As a way out for this situation, Smale suggested to\nassume a probability measure on the set of data and to study the condition\nnumber of this data as a random variable. Examples of such results abound\nfor a variety of condition numbers. For more details and references we refer\nto Smale's survey [25] and the recent survey [4].\nRenegar [20, 21, 22] was the first to realize that the computational complexity of linear programming problems can be bounded by a polynomial in\nthe number of variables and inequalities and a certain condition measure of\nthe input. This condition measure is given by the inverse distance of the\ninput to the set of ill-posed systems. More specifically, it is well known that\nfor a given matrix A \u2208 Rn\u00d7(m+1) , either the system Ax < 0 or its dual system AT y = 0, y > 0 have a solution, unless we are in an ill-posed situation.\nThe (homogeneous) linear programming feasibility problem is to decide this\nalternative for given A and to compute a solution of the corresponding system. A primal-dual interior point method is used in [12] to solve the linear\nprogramming feasibility problem within\n\u0001\n\u221a\n(1)\nO m + n (ln(m + n) + ln C (A))\n\niterations, with each step costing at most O((m+n)3 ) arithmetic operations.\nHere, the GCC-condition number C (A) is a variant of Renegar's condition\nnumber introduced by Goffin [17], and later generalized by Cucker and Cheung [8] (see \u00a72.3 for the definition). The advantage of C (A) over Renegar's\ncondition number is that this quantity can be neatly characterized in terms\nof spherical geometry, which greatly facilitates its probabilistic analysis.\nThus the running time of the primal-dual interior point method used\nin [12] is controlled by C (A). Understanding the average-case behaviour\nof this algorithm therefore boils down to studying ln C (A) for random inputs A. Motivated by this observation, a lot of efforts have been devoted to\nthe average-case analysis of the random variable C (A), i.e., to compute the\nexpected value (or the distribution function) of ln C (A) for random matrices A. In most cases, the matrices A are assumed to have random entries\n2\n\n\fwhich are i.i.d. standard normal. We remark that since the condition number\nC (A) is multi-homogeneous in the rows ai of A, this is equivalent to considering C (A) in the case where a1 , . . . , an are i.i.d. uniformly distributed in\nunit sphere S m := {x \u2208 Rm+1 | kxk = 1}.\nThe papers dealing with the average analysis of C (A) are easily summarized. A bound for E(ln C (A)) of the form O(min{n, m ln n}) was shown\nin [9]. This bound was improved in [13] to max{ln m, ln ln n} + O(1) assuming that n is moderately larger than m. Still, in [10], the asymptotic\nbehavior of both C (A) and ln C (A) was exhaustively studied and these results were extended in [18] to matrices A \u2208 (S m )n drawn from distributions\nmore general than the uniform. Finally, in [5], the exact distribution of\nC (A) conditioned to A being feasible was found and asymptotically sharp\ntail bounds for the infeasible case were given. In particular, it was shown\nthat E(ln C (A)) = O(ln m). Our method yields another proof of this result (Cor. 1.3).\n\n1.1\n\nSmoothed analysis\n\nThe problem of average-case analysis is that its results strongly depend on\nthe distribution of the inputs, which is unknown, and usually assumed to\nbe Gaussian for rendering the mathematical analysis feasible. Spielman\nand Teng [26, 27, 28] suggested in 2001 the concept of smoothed analysis\nof algorithms, which is a new form of analysis of algorithms that arguably\nblends the best of both worst-case and average-case. They used this new\nframework to give a more compelling explanation of the speed of the simplex\nmethod (for the shadow-vertex pivot rule).\nThe general idea of smoothed analysis is easy to explain. Let T : Rp \u2192\nR+ \u222a{\u221e} be any function (measuring running time, log of condition numbers\netc.). Instead of showing \"it is unlikely that T (a) will be large,\" one shows\nthat \"for all a \u2208 Rp and all slight random perturbations a of a, it is unlikely\nthat T (a) will be large.\" If we assume that a is multivariate normal with\nmean a and variance \u03c3 2 , in short a \u2208 N (a, \u03c3 2 ), then the goal of a smoothed\nanalysis of T is to give good estimates of\nsup\n\nProb {T (a) > \u03b5\u22121 }.\n\na\u2208Rp a\u2208N (a,\u03c32 )\n\nIn a first approach one may focus on bounds on the expectations.\nFor many situations of interest, it turns out that in smoothed analysis,\nthere is only a weak dependence on the chosen model of random perturbations. A first formal evidence of this robustness phenomenon was given by\n3\n\n\fCucker, Hauser, and Lotz [11] for certain conic condition numbers, stated\nbelow as Theorem 1.1.\nDunagan et al. [15] (see also Spielman and Teng [27]) performed a\nsmoothed analysis of the running time of interior point methods of linear\nprogramming by analyzing Renegar's condition number C \u2032 , a variant of the\nGCC condition number C . Among other things, they proved the following:\n\u0010 mn \u0011\nsup EA\u2208N (\u0100,\u03c32 ) (ln C \u2032 (A)) = O ln\n.\n\u03c3\n\u0100\nHere the supremum is over all \u0100 \u2208 Rn\u00d7(m+1) of Frobenius norm at most\none. Our main result (Theorem 1.2) shows that a similar bound actually\nholds for a large class of random perturbation laws.\n\n1.2\n\nA geometric approach to conic condition numbers\n\nB\u00fcrgisser et al. [6, 7] recently extended a result of Demmel [14] on conic\ncondition numbers from average-case analysis to smoothed analysis. There,\nthe perturbations of the inputs are modelled by uniform instead of Gaussian\ndistributions. This allows to perform the analysis in a general geometric\nframework that we explain next.\nThe set of ill-posed inputs to a computational problem is modelled as\na lower dimensional subset \u03a3 of the data space D, which is assumed to be\nfurnished with a metric d, a distance function dist (not necessarily a metric),\nand a volume measure. In our cases of interest, D is a Riemannian manifold, d is the corresponding metric, and dist = sin(d). The corresponding\ncondition number C (a) of an input a \u2208 D is then defined as\nC (a) =\n\n1\n.\ndist(a, \u03a3)\n\n(2)\n\nThis is an appropriate definition for many applications. In this model, the\nset of inputs a with condition C (a) > \u03b5\u22121 is given by the \u03b5-neighborhood\nTdist (\u03a3, \u03b5) = {a \u2208 D | dist(a, \u03a3) < \u03b5}.\nLet B(a, \u03b1) := {a \u2208 D | d(a, a) \u2264 \u03b1} denote the ball centered at a \u2208 D of\nradius \u03b1. The task of a uniform smoothed analysis of C consists of providing\ngood upper bounds on\nsup Prob {C (a) > \u03b5\u22121 },\n\na\u2208D a\u2208B(a,\u03b1)\n\n4\n\n\fwhere a is assumed to be chosen uniformly at random in B(a, \u03b1). The\nprobability occurring here thus has an immediate geometric meaning:\nvol (Tdist (\u03a3, \u03b5) \u2229 B(a, \u03b1))\n.\nvol (B(a, \u03b1))\n\nProb {C (a) > \u03b5\u22121 } =\n\na\u2208B(a,\u03b1)\n\n(3)\n\nThus uniform smoothed analysis means to provide bounds on the volume\nof the intersection of \u03b5-neighborhoods of \u03a3, relative to the distance function dist, with balls of radius \u03b1. We note that for compact data spaces D,\nuniform smoothed analysis interpolates transparently between worst-case\nand average-case analysis. Indeed, when \u03b1 = 0 we get worst-case analysis,\nwhile for \u03b1 = diam(D) we obtain average-case analysis.\nFor conic condition numbers, this general concept specializes in the following way. The data space is the unit m-sphere S m \u2282 Rm+1 , \u03a3 is a lower\ndimensional subset of S m such that \u03a3 = \u2212\u03a3 (in many applications it is an\nalgebraic hypersurface) and the conic condition number C (a) of a \u2208 S m is\ndefined by (2) with respect to the distance function dist(a, b) := sin d(a, b),\nwhere d refers to the angular (i.e., Riemannian) distance in S m . (We could\nas well consider the data space as the real projective space Pm on which dist\ndefines a metric.)\nFor defining the GCC-condition number, one takes as the data space the\nnth power (S m )n = S m \u00d7* * *\u00d7S m of the sphere S m with the metric defined as\nd(A, B) := max1\u2264i\u2264n d(ai , bi ), where A = (a1 , . . . , an ), B = (b1 , . . . , bn ) and\nd(ai , bi ) again denotes the angular distance in S m . The distance function is\ndefined by dist(A, B) := sin d(A, B) and the GCC-condition number C (A)\nis given by C (A) = 1/dist(A, \u03a3n,m ), where \u03a3n,m \u2282 (S m )n denotes the set of\nill-posed inputs, which is a semialgebraic subset of codimension one (cf. \u00a72.3\nfor details).\n\n1.3\n\nAdversarial distributions\n\nAn advantage of the uniform model is that, for conic condition numbers,\nresults on smoothed analysis easily extend to more general families of probability distributions. To obtain such robustness results we rely on a general\nboosting technique developed in Hauser and M\u00fcller [18] and apply it similarly as in Cucker et al. [11]\nThe framework is the following (cf. \u00a72.4). Consider the spherical cap\nB(a, \u03b1) := {x \u2208 S m | d(x, a) \u2264 \u03b1} in the sphere S m centered at a \u2208 S m and\nhaving angular radius \u03b1 \u2208 (0, \u03c0/2]. Let \u03bd denote the uniform measure on\nB(a, \u03b1) and suppose that\nR \u03bca is a \u03bd-absolutely continuous probability measure\nm\non S , say \u03bca (G) = G f d \u03bd for measurable sets G. We further assume that\n5\n\n\fthe density f is of the form f (x) = g(sin d(x, a)) with a monotonically\ndecreasing function g : [0, \u03c3] \u2192 [0, \u221e] of the form\ng(r) = Cr \u2212\u03b2 h(r),\nwhere \u03c3 := sin \u03b1, \u03b2 < m, h : [0, \u03c3] \u2192 [0, \u221e) is a continuous function satisfying h(0)R 6= 0, and C = Im (\u03b1)/Im\u2212\u03b2 (\u03b1) is a normalizing constant, where\n\u03b1\nIk (\u03b1) := 0 (sin t)k\u22121 dt, cf. \u00a72.2. Thus, the support of \u03bca is contained in\nB(a, \u03b1) and the density of \u03bca is radially symmetric with a pole of order \u03b2\nat a. Such distributions were called adversarial in [11]. The exponent \u03b2\nand the quantity H := sup0\u2264r\u2264\u03c3 h(r) are the only parameters entering the\nbound below. In the special case \u03b2 = 0, the density of \u03bca does not have a\nsingularity and the situation considerably simplifies: We have C = 1, g = h\nand the estimate \u03bc\u0101 (B) \u2264 H * \u03bd(B) holds for any measurable set G.\nTo extend this estimate to the general case, the smoothness parameter s\nof a \u03bd-absolutely continuous distributions was defined in [18], and in [11,\nLemma 3.2], it was shown that s = 1 \u2212 \u03b2/m. This means that s is the\nlargest number s\u2032 > 0 for which the following is true: For every \u03b5 > 0\n\u2032\nthere exists \u03b4(\u03b5) > 0 such that \u03bd(G) \u2264 \u03b4(\u03b5) implies \u03bc\u0101 (G) \u2264 \u03bd(B)s \u2212\u03b5 for\nall measurable sets G. This allows to obtain tail bounds for \u03bca from tail\nbounds for \u03bd.\nB\u00fcrgisser et al. [7] provided a general smoothed analysis of conic condition numbers for uniform perturbations. This was recently extended by\nCucker et al. [11] to the model of adversarial perturbations, who obtained\nthe following robust smoothed analysis estimate.\nTheorem 1.1 Let C be a conic condition number with set of ill-posed\ninputs \u03a3 \u2286 S m and assume that \u03a3 is contained in an algebraic hypersurface\nof degree d. Then we have for a random perturbation from any adversarial\ndistribution \u03bca on B(a, \u03b1) with center a \u2208 S m , angular radius \u03b1 \u2208 (0, \u03c0/2]\nand parameters \u03b2, H, \u03c3 = sin \u03b1 that\nE\u03bca (ln C ) \u2264 ln\n\n1\n2eH 2 m\n13\u03c0\nm2 d\n+\nln\n+ ln\n.\n\u03c3\n1 \u2212 \u03b2/m ln(\u03c0m/2)\n2\n\nIt is remarkable that the only problem dependent parameters entering\nthe above bound are the dimension m and the degree d. The only distribution dependent parameters entering the bound are \u03c3, \u03b2, and H. This result\nhas a wide range of applications to linear and polynomial equation solving.\n\n6\n\n\f1.4\n\nMain results\n\nThe goal of this paper is to prove the following analogue of Theorem 1.1 for\nthe GCC-condition number of the linear programming feasibility problem.\nTheorem 1.2 Let C denote the GCC condition number defined on (S m )n\nand n > m + 1. Suppose that ai is randomly chosen from an adversarial\ndistribution \u03bcai on B(ai , \u03b1) with center ai \u2208 S m , angular radius \u03b1 \u2208 (0, \u03c0/2],\nand parameters \u03b2, H, \u03c3 = sin \u03b1, independently for i = 1, . . . , n. Then the\nrandom matrix A with rows ai satisfies\n\u0010\n\u0001\nnH \u0011\n\u03b2 \u0001\u22122\n* ln\n.\nE ln C (A) = O 1 \u2212 m\n\u03c3\nIn the case \u03b2 = 0, we have more precisely,\n\u0001\n\u0001\nE ln C (A) \u2264 12 ln n + 17 ln m + 6 ln \u03c31 + 8 ln H + 29 = O ln nH\n\u03c3 .\n\nAs an application let T (A) denote the number of iterations of the primaldual interior point method of [12] for solving the linear programming feasibility problem \u2203x \u2208 Rm+1 Ax < 0 (or its dual problem). Theorem 1.2\nimplies that\nnH \u0001\n\u03b2 \u0001\u22122 \u221a\n,\nE(T (A)) = O 1 \u2212 m\n* n * ln\n\u03c3\nfor a random matrix A with independent rows ai from a adversarial distribution \u03bcai with parameters \u03b2, H.\nFor the uniform distribution on S m , by essentially the same method,\nwe can improve the estimates of Theorem 1.2 obtaining a result that was\npreviously shown in [7] by a very different technique.\nCorollary 1.3 Suppose that the rows of the matrix A are independently\nchosen in S m according to the uniform distribution and n > m + 1. Then\n\u0001\n\u0001\nE ln C (A) = O ln m .\n\nThe paper is organized as follows. Section 2 is devoted to preliminaries on\nspherically convex sets, the GCC-condition number, and adversarial probability distributions. In Section 3 we state and prove probability tail bounds\nfor the GCC-condition number under adversarial random perturbations and\nprove our main results. The proof essentially reduces the adversarial to the\nuniform case and then uses geometric arguments for the uniform case. A\nprincipal ingredient of the proof of the uniform case is an upper bound on\n7\n\n\fthe volume of the neighborhood of spherically convex sets (Theorem 3.3),\nthat is stated in Section 3.1, but whose proof is deferred to Section 4. The\nproof of the latter result proceeds along the lines of [7] and uses some deeper\nresults from integral and differential geometry (Weyl's tube formula, kinematic formula).\nAcknowledgments. We thank Felipe Cucker and Martin Lotz for numerous helpful discussions. We are grateful to an anonymous referee for\nconstructive criticism that led to more general results and a significantly\nbetter presentation of the paper.\n\n2\n2.1\n\nPreliminaries\nConvex sets in spheres\n\nA general reference about convex sets is [30]. Glasauer's thesis [16] is a\nuseful reference for the integral geometry of spherically convex sets.\nA convex cone in Rm+1 is a subset that is closed under addition and\nmultiplication with nonnegative scalars. We denote by cone(M ) the convex\ncone generated by a subset M \u2286 Rm+1 . More specifically, the convex cone\ngenerated by points a1 , . . . , ak \u2208 Rm+1 is given by\nP\ncone{a1 , . . . , ak } := {x \u2208 Rm+1 | \u2203\u03bb1 \u2265 0, . . . , \u03bbk \u2265 0 x = ki=1 \u03bbi ai }.\n\nA convex cone C is called pointed iff C \u2229 (\u2212C) = {0}. It is known that\nC is pointed iff C \\ {0} is contained in an open halfspace whose bounding\nhyperplane goes through the origin. Clearly, if ai 6= 0 for i = 1, . . . , k,\nthen cone{a1 , . . . , ak } is pointed iff 0 is not contained in the convex hull\nconv{a1 , . . . , ak }.\nWe use convex cones to define the notion of convexity for subsets of the\nsphere S m = {x \u2208 Rm+1 | kxk = 1}. Let x, y \u2208 S m be such that x 6= \u00b1y.\nWe call [x, y] := cone{x, y}\u2229S m the great circle segment connecting x and y.\nDefinition 2.1 A subset K of S m is called (spherically) convex iff we have\n[x, y] \u2286 K for all x, y \u2208 K with x 6= \u00b1y. We call K properly convex iff it is\nnonempty, convex, and does not contain a pair of antipodal points.\nWe denote by sconv(M ) := cone(M ) \u2229 S m the convex hull of a subset M\nof S m , which is the smallest convex set containing M . Clearly, M is convex\niff M = sconv(M ). The closure of a convex set is convex as well. It is easy to\nsee that a convex subset K of S m is contained in a closed halfspace, unless\nK = S m . A properly convex set K is always contained in an open halfspace.\n8\n\n\fDefinition 2.2 The dual set of a subset M \u2286 S m is defined as\nM\u0306 := {a \u2208 S m | \u2200x \u2208 M ha, xi \u2264 0}.\nClearly, M\u0306 is a closed convex set disjoint to M . The hyperplane separation theorem implies that the dual of M\u0306 equals the closure of sconv(M ).\nWe note that M \u2286 N implies M\u0306 \u2287 N\u0306 . Finally, it is important that M\u0306 has\nnonempty interior iff M does not contain a pair of antipodal points, that is,\n\"nonempty interior\" and \"properly convex\" are dual properties.\nBy a convex body K in S m we will understand a closed convex set K such\nthat both K and K\u0306 have nonempty interior, i.e., both are properly convex.\nThe map K 7\u2192 K\u0306 is an involution of the set of convex bodies in S m .\n\n2.2\n\nDistances, neighborhoods, and volumes\n\nWe denote by d(a, b) \u2208 [0, \u03c0] the angular distance between two points a, b\non the sphere S m . Clearly, this defines a metric on S m . The (closed) ball of\nradius \u03b1 \u2208 [0, \u03c0] around a \u2208 S m is defined as\nB(a, \u03b1) := {x \u2208 S m | d(x, a) \u2264 \u03b1} = {x \u2208 S m | ha, xi \u2265 cos \u03b1}.\nThis is the same as the spherical cap with center a and angular radius \u03b1.\nB(a, \u03b1) is convex iff \u03b1 \u2264 \u03c0/2 or \u03b1 = \u03c0. In the case \u03b1 \u2264 \u03c0/2, the dual set of\nB(a, \u03b1) equals B(\u2212a, \u03c0/2 \u2212 \u03b1).\nFor a nonempty subset M of S m we define the distance of a \u2208 S m to M\nas d(a, M ) := inf{d(a, x) | x \u2208 M }. The dual set of M can be characterized\nin terms of distances by: a \u2208 M\u0306 \u21d0\u21d2 d(a, M ) \u2265 \u03c0/2.\nLemma 2.3 Let K be a convex body in S m and a \u2208 S m \\ (K \u222a K\u0306). Then\nd(a, K) + d(a, K\u0306) = \u03c0/2.\nProof. Let b \u2208 K such that \u03c6 := d(a, b) = d(a, K). Since a 6\u2208 K\u0306 we have\n\u03c6 < \u03c0/2. The point b\u2217 := ha, bi b is therefore nonzero and contained in\nC := cone(K). Put p\u2217 := a \u2212 b\u2217 . Then hp\u2217 , bi = 0, hp\u2217 , ai = sin2 \u03c6, and\nhp\u2217 , p\u2217 i = sin2 \u03c6. In particular p\u2217 6= 0.\nBy construction, b\u2217 is the point of C closest to a. It follows that {x \u2208\nm+1\nR\n| hp\u2217 , xi = 0} is a supporting hyperplane of C. Hence hp\u2217 , xi \u2264 0 for\nall x \u2208 C and the point p := p\u2217 /kp\u2217 k therefore belongs to K\u0306. Moreover,\nhp, ai = sin \u03c6, which implies d(a, p) = \u03c0/2 \u2212 \u03c6. Hence\nd(a, K) + d(a, K\u0306) \u2264 d(a, b) + d(a, p) = \u03c0/2.\n9\n\n\fTo complete the proof it suffices to show that d(a, K\u0306) = d(a, p). Suppose\nthere exists p\u2032 \u2208 K\u0306 such that d(a, p\u2032 ) < d(a, p). Then d(b, p\u2032 ) \u2264 d(b, a) +\nd(a, p\u2032 ) < d(b, a) + d(a, p) = \u03c0/2 which contradicts the fact that b \u2208 K\u0306. \u2737\nSometimes it will be useful to consider the projective distance between\ntwo points a, b \u2208 S m , which is defined as dP (a, b) := sin d(a, b). It is straightforward to check that dP satisfies the triangle inequality. However, it is not\na metric on S m , as dP (a, b) = 0 iff a = \u00b1b. Hence the ball of radius sin \u03b1,\nmeasured with respect to the projective distance, equals B(a, \u03b1) \u222a B(\u2212a, \u03b1).\nWe denote this set suggestively by B(\u00b1a, \u03b1) and call it the projective ball\nwith center \u00b1a and radius \u03b1.\nFor 0 \u2264 \u03c6 \u2264 \u03c0/2, the \u03c6-neighborhood of a nonempty subset M of S m is\ndefined as T (M, \u03c6) := {x \u2208 S m | d(x, M ) < \u03c6}. If M is the boundary \u2202K\nof a properly convex set K in S m , we call\nTo (\u2202K, \u03c6) := T (\u2202K, \u03c6) \\ K\n\nand Ti (\u2202K, \u03c6) := T (\u2202K, \u03c6) \u2229 K\n\nthe outer \u03c6-neighborhood and inner \u03c6-neighborhood of \u2202K, respectively.\nClearly, we have T (\u2202K, \u03c6) = To (\u2202K, \u03c6) \u222a Ti (\u2202K, \u03c6).\nIn order to compute the m-dimensional volume of such neighborhoods,\nthe following functions Jm,k (\u03b1) are relevant:\nZ \u03b1\n(sin \u03c1)k\u22121 (cos \u03c1)m\u2212k d\u03c1 (1 \u2264 k \u2264 m).\n(4)\nJm,k (\u03b1) :=\n0\n\nRecall that Om := volS m = 2\u03c0 (m+1)/2 /\u0393((m+1)/2) equals the m-dimensional\nvolume of S m . It is known that vol T (S m\u2212k , \u03b1) = Om\u2212k Ok\u22121 Jm,k (\u03b1). Some\nestimations of these volumes can be found in [7, Lemmas 2.1-2.2].\n\n2.3\n\nThe GCC condition number\n\nWe study the problem of deciding for a given instance A \u2208 Rn\u00d7(m+1) whether\nthere exists a nonzero solution x \u2208 Rm+1 \\ {0} such that Ax \u2264 0. In the\nfollowing we assume that n > m + 1. (The other case is considerably less\ninteresting.) Without loss of generality we may assume that the row vectors\nai have euclidean length one, and hence interpret A = (a1 , . . . , an ) as an\nelement of the product (S m )n of spheres.\nWe write sconv(A) := sconv{a1 , . . . , an } for the convex hull of the given\npoints. The set of solutions in S m of the system of inequalities Ax \u2264 0\nequals the dual set of sconv(A).\n\n10\n\n\fDefinition 2.4 An instance A \u2208 (S m )n is called feasible iff its set of solutions is nonempty, otherwise A is called infeasible. An instance A is called\nstrictly feasible iff its set of solutions has nonempty interior. We denote by\n\u25e6\nFn,m and Fn,m\nthe set of feasible and strictly feasible instances, respectively.\n\u25e6 . The set of\nThe set of ill-posed instances is defined as \u03a3n,m := Fn,m \\ Fn,m\ninfeasible instances is denoted by In,m .\nRemark 2.5 An instance A \u2208 (S m )n is strictly feasible iff sconv(A) is properly convex, that is, cone(A) is pointed. Furthermore, a feasible instance A\nis ill-posed iff 0 is contained in the euclidean convex hull of a1 , . . . , an (cf. [5,\nLemma 3.2]).\nWe remark that Fn,m is a compact subset of (S m )n with nonempty inte\u25e6\nrior Fn,m\nand topological boundary \u03a3n,m. Moreover, In,m is nonempty and\n\u03a3n,m is also the topological boundary of In,m. (Here we use n > m + 1.)\nWe define a metric on (S m )n by setting for A, B \u2208 (S m )n with components ai , bi \u2208 S m\nd(A, B) := max d(ai , bi ) .\n1\u2264i\u2264n\n\nThe distance of A to a nonempty subset M \u2286 (S m )n is defined as d(A, M ) :=\ninf{d(A, B) | B \u2208 M }. We denote by B(\u0100, \u03b1) := {A \u2208 (S m )n | d(A, \u0100) \u2264 \u03b1}\nthe closed ball with center \u0100 and radius \u03b1. Clearly, this is the product of\nthe balls B(\u0101i , \u03b1) for i = 1, . . . , n.\nThe following definition is due to Goffin [17] and Cheung and Cucker [8].\nDefinition 2.6 The GCC condition number of A \u2208 (S m )n is defined as\nC (A) = 1/ sin d(A, \u03a3n,m ).\nThis condition number can be characterized in a more explicit way.\nDefinition 2.7 A smallest including cap (SIC) for A \u2208 (S m )n is a spherical\ncap of minimal radius containing the points a1 , . . . , an .\nWe remark that by a compactness argument, a SIC always exists. It can\nbe shown that a SIC is unique if A is strictly feasible. However, for infeasible A, there may be several SICs (consider for instance three equidistant\npoints on the circle). We denote the radius of a SIC of A by \u03c1(A). An\ninstance A is strictly feasible iff \u03c1(A) < \u03c0/2. For more information on this\nwe refer to [10, 5].\nThe following result is due to Cheung and Cucker [8]. This characterization is essential for any probabilistic analysis of the GCC condition number.\n\n11\n\n\fTheorem 2.8 We have\nd(A, \u03a3n,m ) =\nIn particular, d(A, \u03a3n,m ) \u2264\n\n2.4\n\n(\n\n\u03c0\n2\n\n\u03c0\n2\n\nand C (A)\u22121 = | cos \u03c1(A)|.\n\n\u2212 \u03c1(A)\n\u03c1(A) \u2212 \u03c02\n\nif A \u2208 Fn,m ,\nif A \u2208 (S m )n \\ Fn,m .\n\nAdversarial probability distributions\n\nThe proof of our robustness result relies on a general boosting technique\ndeveloped in [18], that allows to extend probability tail bounds obtained\nfor one fixed distribution to larger classes of distributions. We explain this\ntechnique in our situation of interest.\nLet \u03bd := \u03bda,\u03c3 denote the uniform distribution on the spherical disk B(a, \u03b1),\nwhere \u03b1 \u2208 (0, \u03c02 ] and \u03c3 := sin \u03b1. We assume that \u03bc is a \u03bd-absolutely continuous Rprobability measure, i.e., it can be written with a density f as\n\u03bc(G) = G f d \u03bd for Borel measurable sets G. In certain cases, it is possible\nto bound \u03bc(G) in terms of \u03bd(G) if the latter is sufficiently small. This is done\nwith the smoothness parameter s of \u03bc with respect to \u03bd, which is defined\nas s := lim\u03b4\u21920 inf \u03b4, where we have set for \u03b4 \u2208 (0, 1), using the convention\nln 0 := \u2212\u221e,\no\nn ln \u03bc(G)\n| 0 < \u03bd(G) \u2264 \u03b4 .\ninf \u03b4 := inf\nln \u03bd(G)\n\nIf s is positive, we say that \u03bc is uniformly \u03bd-absolutely continuous. In this\ncase, it is easy to see that s is the largest nonnegative real number s\u2032 with\nthe property that for all \u03b5 > 0 there exists a tolerance \u03b4(\u03b5) > 0 such that\n\u2032\n\u03bd(G) \u2264 \u03b4(\u03b5) implies \u03bc(G) \u2264 \u03bd(G)s \u2212\u03b5 for all G, cf. [18].\nWe will apply this framework to a specific class of distributions \u03bc. Not\nonly will it be important to know the smoothness parameter, but also to\nexplicitly compute bounds for the tolerance \u03b4(\u03b5).\nAn adversarial probability distribution \u03bca , for a \u2208 S mR, was defined in [11]\nas a \u03bd-absolutely continuous measure given by \u03bca (G) = G f d \u03bd, where again\n\u03bd denotes the uniform distribution on B(a, \u03b1). We further require that the\ndensity f is of the form f (x) = g(sin d(x, a)) with a monotonically decreasing\nfunction g : [0, \u03c3] \u2192 [0, \u221e] given by\ng(r) = Cr \u2212\u03b2 h(r),\n\nwhere 0 \u2264 \u03b2 < m, and h : [0, \u03c3] \u2192 [0, \u221e) is a continuous function satisfying\nh(0) 6= 0. Thus, the support of \u03bca is contained in B(a, \u03b1) and the density\nof \u03bca is radially symmetric with a pole of order \u03b2 at a. Clearly, a is the\n12\n\n\fmean of a with respect to \u03bca . It is convenient to assume the normalization\nC := Im (\u03b1)/Im\u2212\u03b2 (\u03b1), where\nZ \u03b1\n(sin t)k\u22121 dt,\nIk (\u03b1) := Jk,k (\u03b1) =\n0\n\ncompare (4) (we slightly deviate here from the notation in [11]). Then \u03bca is\na probability distribution iff\nZ \u03b1\n(sin t)m\u2212\u03b2\u22121 h(sin t) dt.\nIm\u2212\u03b2 (\u03b1) =\n0\n\nThe maximum of h is denoted by H := sup0\u2264r\u2264\u03c3 h(r), which is easily seen to\nsatisfy H \u2265 1. We note that the uniform distribution on B(a, \u03b1) is obtained\nby choosing \u03b2 = 0, C = 1 and for g = h the function identically equal to 1.\nThe following technical lemma is an immediate consequence of [11, Lemmas 3.2-3.3, Equation (3.1)].\nLemma 2.9\n1. The smoothness parameter of \u03bc with respect to \u03bd equals\ns = 1 \u2212 \u03b2/m.\n2. For c := 12 s = 12 (1 \u2212\n\n\u03b2\nm)\n\n\u03b4c :=\n\n\u2264\n\n1\n2\n\nand the tolerance \u03b4c defined by\n\n\uf8eb\n\n2 \uf8ed1\n*\n\u03c0m H\n\ns\n\n1\u2212\n\nwe have for all measurable G \u2286 S m ,\n\n\u0012\n\n2\n\u03c0m\n\n\u00131\n\nm\n\n\uf8f61/c\n\uf8f8\n\n\u03bd(G) \u2264 \u03b4c =\u21d2 \u03bca (G) \u2264 (\u03bd(G))c .\nRemark 2.10 In the case \u03b2 = 0 where the density of \u03bca has no singularity\nthe situation simplifies. Clearly, \u03bca (G) \u2264 H\u03bd(G) for all G. This directly\nimplies that the smoothness parameter equals 1. Moreover, the tolerance\n1\n\u03b4 = H12 is sufficient for the implication \u03bd(G) \u2264 \u03b4 \u21d2 \u03bca (G) \u2264 \u03bd(G) 2 .\nSince we will work in the product of spheres (S m )n we define on it\nthe adversarial distributions \u03bc\u0100 with center \u0100 = (a1 , . . . , an ) \u2208 (S m )n by\ntaking the product measure \u03bc\u0100 := \u03bca1 \u00d7 . . . \u00d7 \u03bcan . This is a probability\ndistribution whose support is contained in the product of caps B(\u0100, \u03b1) :=\nB(a1 , \u03b1) \u00d7 . . . \u00d7 B(an , \u03b1).\n\n13\n\n\f3\n\nRobust smoothed analysis of C (A)\n\nThe goal of this section is to provide smoothed analysis estimates for the\ncondition number C (A) in the model where A = (a1 , . . . , an ) is chosen at\nrandom according to an adversarial distribution \u03bc\u0100 . The center \u0100 \u2208 (S m )n\nof the perturbation is arbitrary. Recall that Fn,m and In,m denote the sets\nof feasible and infeasible instances A \u2208 (S m )n , respectively.\nTheorem 3.1 Let \u03b1 \u2208 (0, \u03c0/2], \u03c3 = sin \u03b1, and \u0100 \u2208 (S m )n , where n > m + 1.\nAssume that A \u2208 B(\u0100, \u03b1) is chosen at random according to an adversarial\ndistribution \u03bc\u0100 . Let the exponent c = 12 (1 \u2212 \u03b2/m) and the tolerance \u03b4c be\ndefined as in Lemma 2.9. Then we have\n\u0012\n\u0013\n13m(m + 1) c \u2212c\nProb{A \u2208 Fn,m and C (A) \u2265 t} \u2264 n\nt .\n(F)\n2\u03c3\nprovided t \u2265\n\n13m(m+1)\n.\n2\u03c3\u03b4c\n\nMoreover, we have for t \u2265 1,\n\nProb{A \u2208 In,m and C (A) \u2265 t} \u2264 n\n\n\u0012\n\n1690m2 (m + 1)\n4\u03c3 2\n\n\u0013c\n\nt\u2212c (\u03b4c\u2212c + cn ln t).\n(I)\n\nRemark 3.2 For the uniform distribution (\u03b2 = 0, h \u2261 1) the bounds in (F)\nand (I) can easily be improved by avoiding the use of Lemma 2.9. In particular, on the right-hand side of (F) and (I) one gets t\u22121 and t\u22121 ln t instead\nof t\u22121/2 and t\u22121/2 ln t.\nThe overall strategy of the proof of Theorem 3.1 is the same as in [15].\nHowever, the crucial component in [15], namely a result due to Ball [2], is\nsubstituted by Corollary 3.4, which is stated in the next section.\n\n3.1\n\nA bound on the volume of convex neighborhoods\n\nWe state here an upper bound on the volume of the intersection of neighborhoods of spherically convex sets with spherical caps.\nTheorem 3.3 Let K be a properly convex subset of S m , let a \u2208 S m , and\n0 < \u03b1, \u03c6 \u2264 \u03c0/2. Then, writing \u03c3 = sin \u03b1 and \u03b5 = sin \u03c6, we have the\nfollowing upper bound for the volume of the outer neighborhood of \u2202K:\nm\u22121\nX \u0012m \u0013 \u0010\nmOm \u0010 \u03b5 \u0011m\n\u03b5 \u0011m\u2212k \u0010 \u03b5 \u0011k\nvol(To (\u2202K, \u03c6) \u2229 B(\u00b1a, \u03b1))\n+\n.\n\u2264\n1+\nvolB(\u00b1a, \u03b1)\n\u03c3\n\u03c3\n2Om\u22121 \u03c3\nk\nk=1\n\n14\n\n\fThe same upper bound holds for the volume\nneighborhood of \u2202K.\n\nvol(Ti (\u2202K,\u03c6)\u2229B(\u00b1a,\u03b1))\nvolB(\u00b1a,\u03b1)\n\nof the inner\n\nThe main result of [7, Theorem 1.2] gives a bound on the volume of the\nintersection of a projective ball B(\u00b1a, \u03b1) = B(a, \u03b1) \u222a B(\u2212a, \u03b1) with the \u03c6neighborhood of a real algebraic hypersurface in the sphere S m , given as the\nzero set of polynomial of degree d. The above theorem says that essentially\nthe same volume bound holds for the boundary of a properly convex set K\nin S m , if we formally replace in this bound the degree d by 1/2.\nThe proof of Theorem 3.3, which is quite involved, is deferred to Section 4. By essentially the same argument as in the proof of [7, Prop. 3.5]\none can derive from Theorem 3.3 the following corollary.\nCorollary 3.4 Under the assumptions of Theorem 3.3 we have the following upper bound for the volume of the outer neighborhood of \u2202K:\n13m \u03b5\nvol(To (\u2202K, \u03c6) \u2229 B(\u00b1a, \u03b1))\n\u2264\nvolB(\u00b1a, \u03b1)\n4 \u03c3\n\nif \u03b5 \u2264\n\n\u03c3\n2m .\n\nThe same upper bound holds for the relative volume of the inner neighborhood of \u2202K.\n\n3.2\n\nTwo auxiliary results\n\nThe proofs of the following two results are similar as in Dunagan et al. [15].\nWe use the notation [n] := {1, 2, . . . , n} for n \u2208 N.\n\u25e6 , 0 < \u03c6 \u2264 \u03c0/2, and \u03b5 = sin \u03c6.\nProposition 3.5 Let A = (a1 , . . . , an ) \u2208 Fn,m\n\u22121\nIf C (A) \u2265 (m + 1) \u03b5 , then there exists i \u2208 [n] such that\n\nai \u2208 T (\u2202Ki , \u03c6) \\ Ki ,\nwhere Ki := \u2212sconv{a1 , . . . , ai\u22121 , ai+1 , . . . , an }.\nProof. There exists q \u2208 sconv(A) such that hai , qi > 0 for all i \u2208 [n].\nIndeed, if q is taken as the center of the SIC of A then this follows from [10,\nLemma 4.5] (see also [5, Lemma 3.2]).\nWe note that ai 6\u2208 Ki for all i \u2208 [n]. Otherwise 0 \u2208 conv{a1 , . . . , an },\nhence A \u2208 \u03a3n,m , which contradicts our assumption that A is strictly feasible.\nIt follows that d(ai , \u2202Ki ) = d(ai , Ki ).\nWe assume now d(ai , Ki ) > \u03c6 for all i \u2208 [n]. Our goal is to show that\n1\n\u03b5. Then we are done, since C (A)\u22121 = sin d(A, \u03a3n,m )\nsin d(A, \u03a3n,m ) > m+1\nby Definition 2.6.\n15\n\n\fWe proceed now similarly as in [15, Lemma 2.3.10]. By continuity we\nassume w.l.o.g. that \u03c6 < \u03c0/2. We distinguish two cases. If ai 6\u2208 K\u0306i , then\nLemma 2.3 tells us that d(ai , Ki ) + d(ai , K\u0306i ) = \u03c0/2. Hence d(ai , K\u0306i ) <\n\u03c0/2 \u2212 \u03c6. Choose pi \u2208 int(K\u0306i ) such that d(ai , pi ) < \u03c0/2 \u2212 \u03c6. This implies\nhai , pi i > cos(\u03c0/2 \u2212 \u03c6) = \u03b5. In the case ai \u2208 K\u0306i we take any pi \u2208 int(K\u0306i )\nclose enough to ai such that hai , pi i > \u03b5.\nIn both cases we have achieved the following\nhai , pi i > \u03b5 and \u2200j 6= i haj , pi i > 0.\n\n(5)\n\nThis implies for all i that hpi , qi > 0, as q \u2208 cone{a1 , . . . , an }.\nConsider now for i \u2208 [n] the following convex sets in S m\n\u03b5\nand hx, qi > 0}\nCi := {x \u2208 S m | hai , xi >\nm+1\ncontaining pi . We claim that the intersection of any m + 1 of these sets\nis nonempty.\nIndeed, let I \u2286 [n] be of cardinality m + 1 and consider\n1 P\n\u2217\np := m+1 j\u2208I pj . Note that kp\u2217 k \u2264 1. We obtain for any i \u2208 I, using (5),\nhai , p\u2217 i =\n\n1\n\u03b5\n1 X\nhai , pj i \u2265\nhai , pi i >\n.\nm+1\nm+1\nm+1\nj\u2208I\n\nMoreover, hp\u2217 , qi > 0, hence p\u2217 6= 0. It follows that p := p\u2217 /kp\u2217 k is contained\nin Ci for any i \u2208 I, which shows the claim.\nConsider the affine hyperplane E := {x \u2208 Rm+1 | hx, qi = 1} of dimension m and the perspective map\n\u03c0 : {x \u2208 S m | hx, qi > 0} \u2192 E, x 7\u2192 hq, xi\u22121 x.\nThen the \u03c0(Ci ) are convex subsets of E, with the property that any m + 1\nof these have a nonempty intersection. Helly's theorem [30] T\nimplies that\n\u03c0(C1 ) \u2229 * * * \u2229 \u03c0(Cn ) is nonempty. Hence there is a point a \u2208 ni=1 Ci . We\nhave d(ai , a) < \u03b1 := arccos((m + 1)\u22121 \u03b5) for all i \u2208 [n]. Hence the spherical\ncap B(a, \u03b1) strictly contains all ai . The radius \u03c1(A) of the SIC of A is\ntherefore strictly smaller than \u03b1. Hence, by Theorem 2.8, sin d(A, \u03a3n,m ) =\ncos \u03c1(A) > cos \u03b1 = (m + 1)\u22121 \u03b5, as claimed.\n\u2737\nThe next proposition on the transition from the feasible to the infeasible\ncase is similar as [15, Lemma 2.3.14].\nProposition 3.6 Let A = (a1 , . . . , an ) \u2208 Fn,m and K := \u2212sconv(A). If\nb \u2208 K, then (A, b) := (a1 , . . . , an , b) is infeasible or ill-posed and we have\nC (A, b) sin d(b, \u2202K) \u2264 10 C (A).\n16\n\n\fProof. W.l.o.g. A is strictly feasible. The set of solutions\nC := {x \u2208 S m | ha1 , xi \u2264 0, . . . , han , xi \u2264 0}\nis the dual of sconv(A). Hence C\u0306 = sconv(A). This means that a \u2208 K iff\nha, xi \u2265 0 for all x \u2208 C. Therefore, we have for all a \u2208 S m ,\na 6\u2208 K \u21d0\u21d2 \u2203x \u2208 C ha, xi < 0 \u21d0\u21d2 (a1 , . . . , an , a) is strictly feasible,\n\n(6)\n\nwhere the second equivalence follows from the assumption that C has nonempty interior. A similar argument shows that (a1 , . . . , an , a) is ill-posed iff\na \u2208 \u2202K. Therefore, we have\nd(b, \u2202K) = min{d(b, a) | a \u2208 S m such that (a1 , . . . , an , a) \u2208 \u03a3n+1,m }.\nFor proving the proposition we can assume without loss of generality\nthat b \u2208 K \\ \u2202K. Then (A, b) is not strictly feasible by (6). Moreover,\nsince b 6\u2208 \u2202K, (A, b) is not ill-posed. Hence (A, b) is infeasible. We put now\n\u03c9 := sin d(b, \u2202K) and claim that\n\u03c9 \u2264 minhb, xi.\nx\u2208C\n\n(7)\n\nIn order to show this, suppose q \u2208 C. The equivalence (6) and b \u2208 K\nimply that cos \u03b8 := hb, qi \u2265 0. W.l.o.g. we may assume that kb \u2212 q cos \u03b8k2 =\n1\u2212cos2 \u03b8 is positive (otherwise \u03b8 = 0, b = q, and hb, qi = 1 \u2265 \u03c9). It therefore\nmakes sense to define b\u2032 := (b \u2212 q cos \u03b8)/kb \u2212 q cos \u03b8k. Then b\u2032 \u2208 S m and\nhb\u2032 , qi = 0. Note that d(b, b\u2032 ) = \u03c0/2 \u2212 \u03b8. Therefore (a1 , . . . , an , b\u2032 ) is feasible.\nIt is either strictly feasible, in which case b\u2032 6\u2208 K, or ill-posed, in which case\nb\u2032 \u2208 \u2202K (use (6)). Since b \u2208 K we conclude that d(b, \u2202K) \u2264 d(b, b\u2032 ) =\n\u03c0/2 \u2212 \u03b8. This implies\n\u03c9 = sin d(b, \u2202K) \u2264 cos \u03b8 = hb, qi\nand hence the claimed inequality (7). Moreover note that d(b, \u2202K) \u2264 \u03c0/2\nand \u03c9 > 0 as b 6\u2208 \u2202K.\nSuppose now that B(p, \u03c1) is the SIC for A. Since we assume A to be\nstrictly feasible t := cos \u03c1 is positive. By the characterization of the GCC\ncondition number in Theorem 2.8 we have t = sin d(A, \u03a3n,m ) = C (A)\u22121 .\n1\nPut \u03c6 := arcsin( 10\nt\u03c9). For proving the proposition, it is enough to show\nthe implication\n\u2200(A\u2032 , b\u2032 ) \u2208 (S m )n+1\n\nd((A\u2032 , b\u2032 ), (A, b)) \u2264 \u03c6 =\u21d2 (A\u2032 , b\u2032 ) infeasible.\n17\n\n(8)\n\n\fIndeed, this implies (using d((A, b), \u03a3n+1,m ) \u2264 \u03c0/2, cf. Theorem 2.8)\nC (A, b)\u22121 = sin d((A, b), \u03a3n+1,m ) \u2265 sin \u03c6 =\n\n1\n1\nt\u03c9 =\nC (A)\u22121 \u03c9,\n10\n10\n\nas claimed in the proposition.\nWe argue by contradiction. Suppose there is a feasible (A\u2032 , b\u2032 ) having\ndistance at most \u03c6 from (A, b). Then there exists x\u2032 \u2208 S m such that\nha\u20321 , x\u2032 i \u2264 0, . . . , ha\u2032n , x\u2032 i \u2264 0, hb\u2032 , x\u2032 i \u2264 0.\n\nTaking into account that d(a\u2032i , ai ) \u2264 \u03c6, we see that d(ai , x\u2032 ) \u2265 \u03c0/2 \u2212 \u03c6 and\nhence hai , x\u2032 i \u2264 sin \u03c6.\nWe put now x\u0303 := x\u2032 \u2212 \u03bbp with \u03bb := t\u22121 sin \u03c6. As hai , pi \u2265 t, we have for\ni \u2208 [n]\nhai , x\u0303i = hai , x\u2032 i \u2212 \u03bbhai , pi \u2264 sin \u03c6 \u2212 \u03bbt = 0.\n\nNote that x\u0303 6= 0 (otherwise t = sin \u03c6, which is impossible). Therefore, x\u0303/kx\u0303k\nis well-defined and lies in C. Inequality (7) implies that \u03c9kx\u0303k \u2264 hb, x\u0303i.\nPut \u2206b := b\u2032 \u2212b. Then k\u2206bk \u2264 2 sin(\u03c6/2) by our assumption d(b\u2032 , b) \u2264 \u03c6.\nWe obtain\nhb, x\u0303i = hb\u2032 \u2212 \u2206b, x\u2032 \u2212 \u03bbpi = hb\u2032 , x\u2032 i \u2212 h\u2206b, x\u2032 i \u2212 hb\u2032 , \u03bbpi + h\u2206b, \u03bbpi\n\u2264 0 + k\u2206bk + \u03bb + k\u2206bk\u03bb.\n\nTo arrive at a contradiction it is enough to verify that\nk\u2206bk + \u03bb + k\u2206bk\u03bb < \u03c9kx\u0303k.\nNote that kx\u0303k \u2265 1 \u2212 \u03bb, k\u2206bk \u2264 2, and \u03c9 \u2264 1. It is therefore sufficient to\ncheck that\nk\u2206bk + \u03bb + 2\u03bb < \u03c9 \u2212 \u03bb,\n\nthat is,\n\nk\u2206bk + 4\u03bb < \u03c9.\n\nUsing sin \u03c6 = 2 sin(\u03c6/2) cos(\u03c6/2) we get \u03bb = t\u22121 sin \u03c6 \u2264 2t\u22121 sin(\u03c6/2). It is\ntherefore sufficient to show that\n\u03c6\n\u03c6\n2 sin + 8t\u22121 sin < \u03c9,\n2\n2\nwhich is equivalent to\n\u03c6\n1\n(t + 4) sin < t\u03c9.\n2\n2\nAs t \u2264 1, it is enough to show that 5 sin \u03c62 < 12 t\u03c9. This is true, since by our\n1\nassumption sin \u03c62 < sin \u03c6 = 10\nt\u03c9.\n\u2737\n18\n\n\f3.3\n\nFeasible instances\n\nWe provide here the proof of the part of Theorem 3.1 dealing with feasible\ninstances. That is, we wish to show the claimed bound (F).\nLet \u0100 \u2208 (S m )n , 0 < \u03b1 \u2264 \u03c0/2, \u03c3 = sin \u03b1, and t \u2265 13m(m + 1)(2\u03c3\u03b4c )\u22121 .\nPut \u03b5 := (m+1)t\u22121 and \u03c6 := arcsin \u03b5. We suppose that A \u2208 (S m )n is chosen\nat random according to a distribution \u03bc\u0100 on (S m )n as defined in Section 2.4.\nUsing Proposition 3.5 and the notation introduced there, we have\n\u25e6\nProb{A \u2208 Fn,m\nand C (A) \u2265 t} \u2264\n\nn\nX\ni=1\n\n\u25e6\nProb{A \u2208 Fn,m\nand ai \u2208 To (\u2202Ki , \u03c6)}.\n\nWe first bound the probability on the right-hand side for i = n by expressing\nit as an integral over A\u2032 := (a1 , . . . , an\u22121 ) of probabilities conditioned on A\u2032 .\n\u25e6\nNote that \u03bc\u0100 = \u03bc\u0100\u2032 \u00d7 \u03bcan where \u0100\u2032 := (\u01011 , . . . , \u0101n\u22121 ). Moroever, A \u2208 Fn,m\n\u2032\n\u25e6\niff A \u2208 Fn\u22121,m and an 6\u2208 Kn , where we set now KA\u2032 := Kn = \u2212sconv(A\u2032 ),\nsee (6). This implies\n\u25e6\nProb{A \u2208 Fn,m\nand an \u2208 To (\u2202Kn , \u03c6)}\n\u03bc\u0100\n\n\u25e6\n= Prob{A\u2032 \u2208 Fn\u22121,m\nand an \u2208 To (\u2202KA\u2032 , \u03c6)}\n\u03bc\u0100\nZ\n=\nProb{an \u2208 To (\u2202KA\u2032 , \u03c6)} d\u03bc\u0100\u2032 .\n\n(9)\n\n\u03bcan\n\n\u25e6\nA\u2032 \u2208Fn\u22121,m\n\n\u25e6\nand consider the properly convex set Kn = KA\u2032 in S m .\nWe fix A\u2032 \u2208 Fn\u22121,m\nThe bound in Corollary 3.4 on the outer neighborhood of \u2202Kn yields\n\nProb{an \u2208 To (\u2202Kn , \u03c6)} =\n\u03bd\n\n13m\nvol(To (\u2202Kn , \u03c6) \u2229 B(\u0101n , \u03b1))\n\u2264\nsin \u03c6,\nvolB(\u0101n , \u03b1)\n2\u03c3\n\nwhere \u03bd denotes the uniform distribution on B(an , \u03b1). The reader should\nnote that \u03b5 \u2264 2\u03c3\u03b4c /(13m) \u2264 \u03c3/(2m) by assumption. (We win a factor of\ntwo by considering B(\u0101n , \u03b1) instead of B(\u00b1\u0101n , \u03b1).) Hence, using sin \u03c6 =\n\u03b5 = (m + 1)t\u22121 , we conclude\nProb{an \u2208 To (\u2202Kn , \u03c6)} \u2264\n\u03bd\n\n13m(m + 1)\n13m\nsin \u03c6 =\n.\n2\u03c3\n2\u03c3t\n\nWe assume that 13m(m + 1)(2\u03c3t)\u22121 \u2264 \u03b4c . Hence we can apply Lemma 2.9,\nwhich yields\n\u0012\n\u0013\n13m(m + 1) c\nProb{an \u2208 To (\u2202Kn , \u03c6)} \u2264\n.\n\u03bcan\n2\u03c3t\n19\n\n\f\u25e6\n. We therefore obtain from (9)\nThis bound holds for any A\u2032 \u2208 Fn\u22121,m\n\u25e6\nProb{A \u2208 Fn,m\nand an \u2208 To (\u2202Kn , \u03c6)}\n\u03bc\u0100\n\u0012\n\u0012\n\u0013\n\u0013\n13m(m + 1) c\n13m(m + 1) c\n\u2032\n\u2264\nProb{A feasible} \u2264\n. (10)\n\u03bc\u0100\u2032\n2\u03c3t\n2\u03c3t\n\nThe same upper bound holds for any Ki . Altogether, we obtain\n\u0012\n\u0013\n13m(m + 1) c \u2212c\n\u25e6\nProb{A \u2208 Fn,m and C (A) \u2265 t} \u2264 n\nt ,\n\u03bc\u0100\n2\u03c3\nwhich proves Claim (F), since Prob{A \u2208 \u03a3n,m} = 0.\n\n3.4\n\nInfeasible instances\n\nWe start with a general observation. For A = (a1 , . . . , an ) \u2208 (S m )n and\n1 \u2264 k \u2264 n we will write Ak := (a1 , . . . , ak ) and \u0100k := (\u01011 , . . . , \u0101k ).\nLemma 3.7 Let A \u2208 (S m )n , k < n, such that Ak+1 be infeasible. Then\nC (Ak+1 ) \u2265 C (A).\nProof. As Ak+1 is infeasible, A must be infeasible as well. Let A\u2032 =\n(a\u20321 , . . . , a\u2032n ) be feasible such that d(A, A\u2032 ) = d(A, \u03a3n,m ) \u2264 \u03c0/2. Then\nA\u2032k = (a\u20321 , . . . , a\u2032k+1 ) is feasible and d(Ak , A\u2032k ) \u2264 d(A, A\u2032 ). Hence we have\nd(Ak+1 , \u03a3k+1,m ) \u2264 d(A, \u03a3n,m ) and\nC (Ak+1 )\u22121 = sin d(Ak+1 , \u03a3k+1,m ) \u2264 sin d(A, \u03a3n,m ) = C (A)\u22121 ,\nwhich was to be shown.\n\n\u2737\n\nWe also need the following probabilistic lemma.\nLemma 3.8 Let U and V be random variables taking positive values and\nxU \u2265 \u03b1 > 0, xV \u2265 \u03b2 > 0, and c > 0. We assume\nProb{U \u2265 x} \u2264 \u03b1 * x\u2212c\n\nProb{V \u2265 x | U } \u2264 \u03b2 * x\n\n\u2212c\n\nfor x \u2265 xU\n\nfor x \u2265 xV .\n\nThen we have\nProb{U V \u2265 x} \u2264 c \u03b1\u03b2 x\u2212c ln max\n\n\b\n\n20\n\nx\n, 1 + min{\u03b1 xcV , \u03b2 xcU } x\u2212c .\nxU xV\n\n\fProof. [23, Lemma C.1] with the functions f, g defined as\n\u001a\n\u001a\n1\nif x < xV\n1\nif x < xU\ng(x)\n=\nf (x) =\n\u03b2 * x\u2212c if x \u2265 xV\n\u03b1 * x\u2212c if x \u2265 xU\nyields\nProb{U V \u2265 x} \u2264\nIf x \u2265 xU xV we estimate this by\nProb{U V \u2265 x} \u2264\n\nZ\n\nx/xU\n\n\u03b1x\n\nZ\n\n\u221e\n\nf\n0\n\n\u2212c c\n\nx\u0001\n(\u2212g \u2032 (s)) ds.\ns\n\ns c\u03b2 s\n\n\u2212c\u22121\n\nds +\n\nZ\n\n(11)\n\n\u221e\n\nc \u03b2 s\u2212c\u22121 ds\n\nx/xU\n\nxV\n\n= c \u03b1\u03b2 x\u2212c ln\n\nx \u0001\n+ \u03b2 xcU x\u2212c .\nxU xV\n\nIf x < xU xV one argues similarly.\n\u0001\nR\u221e\nFinally note that (11) implies Prob{U V \u2265 x} \u2264 0 g xs (\u2212f \u2032 (s)) ds,\nusing integration by parts. Estimating this as before, with the roles of f\nand g exchanged, completes the proof.\n\u2737\nWe provide now the proof of the part of Theorem 3.1 dealing with infeasible instances, i.e., of the claimed bound (I). Fix \u0100 \u2208 S m , 0 < \u03b1 \u2264 \u03c0/2,\n\u03c3 = sin \u03b1, and t \u2265 1. Assume A = (a1 , . . . , an ) to be chosen at random according to \u03bc\u0100 . Then Am+1 is always feasible. Hence, if A = An is infeasible,\nthen there exists a smallest index k > m such that Ak is feasible and Ak+1\nis infeasible. If we denote by Ek the event\nAk feasible and Ak+1 infeasible and C (Ak+1 ) \u2265 t,\n\n(12)\n\nand take into account Lemma 3.7, we obtain\nProb{A \u2208 In,m and C (A) \u2265 t} \u2264\n\nn\u22121\nX\n\nk=m+1\n\nProb Ek .\n\n(13)\n\nFor bounding the probability of Ek , a change of notation is convenient.\nWe fix k and write from now on\nA := (a1 , . . . , ak ),\n\nKA := \u2212sconv{a1 , . . . , ak },\n\nb := ak+1 ,\n\nand similarly \u0100 := (\u01011 , . . . , \u0101k ), b\u0304 := \u0101k+1 . We note that A and b are chosen\nindependently and at random according to \u03bc\u0100 and \u03bcb\u0304 , respectively.\n\n21\n\n\fProposition 3.6 implies that\n\u001a\nProb Ek \u2264 Prob A \u2208 Fk,m and b \u2208 KA and\n\u03bc\u0100\n\n\u03bc\u0100\n\nt\nC (A)\n\u2265\nsin d(b, KA )\n10\n\n\u001b\n\n.\n\nThe first part of Theorem 3.1 tells us that\n\b\nProb A \u2208 Fk,m and C (A) \u2265 x \u2264 k\n\u03bc\u0100\n\n\u0012\n\n13m(m + 1)\n2\u03c3\n\n\u0013c\n\nx\u2212c\n\n(14)\n\nprovided x \u2265 xU := 13m(m + 1)/(2\u03c3\u03b4c ). For a fixed strictly feasible A, the\nset KA is properly convex in S m . The bound in Corollary 3.4 on the inner\n\u25e6\nneighborhood of \u2202KA yields for any A \u2208 Fk,m\nn\nProb b \u2208 KA and\n\u03bd\n\no 13m 1\n1\n\u2265x A \u2264\n,\nsin d(b, \u2202KA )\n2\u03c3 x\n\n(15)\n\nprovided x \u2265 2m/\u03c3 (again \u03bd denotes the uniform distribution on B(b\u0304, \u03b1)).\nApplying Lemma 2.9 yields\no \u0012 13m \u0013c\nn\n1\n\u2265x A \u2264\nx\u2212c ,\n(16)\nProb b \u2208 KA and\n\u03bcb\u0304\nsin d(b, \u2202KA )\n2\u03c3\n\nprovided x \u2265 xV := 13m/(2\u03c3\u03b4c ).\nLet 1M denote the indicator function of a set M . We combine the above\ntwo probability estimates in (14) and (16) with Lemma 3.8, setting\nU (A) := 1Fk,m (A) C (A),\n\nV (A, b) := 1KA (b)\n\n1\n.\nsin d(b, \u2202KA )\n\nNote that\nProb Ek \u2264 Prob{U (A) * V (A, b) \u2265 t/10}.\nWe have for t \u2265 1 and x = t/10\n\u001a\n\u001b\n\u001a\n\u001b\nx\n4 \u03c3 2 \u03b4c2 t\nmax\n, 1 = max\n, 1 \u2264 t.\nxU xV\n1690 m2 (m + 1)\n\u0010\n\u0010\n\u0011c\n\u0011\n\u0001\n169 m2 (m+1) c\n13m c\nLet \u03b1 := k 13m(m+1)\n.\nNote\nthat\n\u03b1\u03b2\n=\nk\n*\nand\n\u03b2\n:=\n2\n2\u03c3\n2\u03c3\n4\u03c3\n\u0011\n\u0010\n169m2 (m+1) c\nc\nc\n. Lemma 3.8 implies that\nand min{\u03b1xV , \u03b2xU } =\n4\u03c32 \u03b4c\nProb Ek \u2264 c k\n\n\u0012\n\n1690 m2 (m + 1)\n4 \u03c32\n\n\u0013c\n\nt\n\n\u2212c\n\n1690 m2 (m + 1)\nln t+\n4\u03c3 2 \u03b4c\n\u0012\n\n\u0013c\n\nt\u2212c . (17)\n\nPlugging in this bound into (13) finishes the proof of Theorem 3.1.\n22\n\n\u2737\n\n\f3.5\n\nProof of Theorem 1.2\n\nWe will now give the proof of Theorem 1.2 by deriving estimates of the expectation of ln C from the tail bounds given in Theorem 3.1. Let A \u2208 (S m )n\nbe chosen at random according to an adversarial distribution \u03bc\u0100 . Combining (F) and (I) from Theorem 3.1 we have for t \u2265 13m(m + 1)(2\u03c3\u03b4c )\u22121 ,\nProb{C (A) \u2265 t} = Prob{A \u2208 Fn,m and C (A) \u2265 t}\n\u2264 n\n\n\u0010\n\n+ Prob{A \u2208 In,m and C (A) \u2265 t}\n\u0011\n\u0011\n\u0010\n13m(m+1) c \u2212c\n1690m2 (m+1) c \u2212c\nt\nt\n+\nn\n2\u03c3\n4\u03c32 \u03b4c\n\u0010\n\u0011\nc\n2\n+cn2 1690m4\u03c3(m+1)\nt\u2212c ln t.\n2\n\n\u0010\n\u0011c\n\u0011c\n\u0010\n130m\nDefining D1 := n 13m(m+1)\n, D3 := cn D1 *\n,\nD\n:=\nD\n*\n2\n1\n2\u03c3\n2\u03c3\u03b4c\nwe can write shortly\n\n\u0001\n130m c\n2\u03c3\n\nProb{C (A) \u2265 t} \u2264 D1 t\u2212c + D2 t\u2212c + D3 t\u2212c ln t.\nNote that D2 \u2265 D1 and D3 \u2265 D1 . It is convenient to use tail estimates of\nln C instead of C , so we reformulate\nProb{ln C (A) \u2265 s} \u2264 D1 e\u2212cs + D2 e\u2212cs + D3 e\u2212cs s,\n(18)\n\u0011\n\u0010\n1/c\n. We define si := ln Di + ln \u03b4c\u22121 , i.e. \u03b4c =\nwhich holds for s \u2265 ln 13m(m+1)\n2\u03c3\u03b4c\n\u0011\n\u0010\n1/c\n\u2265 s1 , s3 =\nDi * e\u2212si , for i = 1, 2, 3. Note that s2 = s1 + ln 130m\n2\u03c3\u03b4c\n\u0001\n130m\n\u22121\ns1 + c ln(cn) + ln 2\u03c3 \u2265 s1 , and\n\u0011\n\u0010\n\u0011\n\u0010\n\u22121 \u2265 ln 13m(m+1) .\ns1 = 1c ln n + ln 13m(m+1)\n+\nln\n\u03b4\nc\n2\u03c3\n2\u03c3\u03b4c\nThe definition of \u03b4c in Lemma 2.9 and the inequality\n\u0010\n1\u2212\n\n2\n\u03c0m\n\n\u0001 1 \u0011\u22121/2\nm\n\n\u2264\n\nq\n\n2m\nln(\u03c0m/2) ,\n\n(19)\n\nwhich is shown by a small computation, lead to the following estimate of s1\n\u0010\n\u0011\n1/c\n1\n2H 2 m\ns1 \u2264 ln D1 + ln \u03c0m\n+\nln\n2\n2c\nln(\u03c0m/2)\n\u0011\n\u0010\n\u0010\n\u0011\n(20)\n13m(m+1)\n1\n\u03c0m\n2H 2 m\n\u22121\n= c ln n + ln\n+ ln 2 + 2c ln ln(\u03c0m/2) .\n2\u03c3\n23\n\n\fWe distinguish the cases s3 \u2265 s2 and s3 < s2 . For s3 \u2265 s2 we get with (18)\nZ \u221e\n\u0001\nProb{ln C (A) \u2265 s} ds\nE ln C\n=\n0\nZ \u221e\nZ s3\n\u0001\nD1 e\u2212cs + D2 e\u2212cs + D3 e\u2212cs s ds\n1 ds +\n\u2264\n0\nZ \u221e\nZ \u221e\nZ \u221e s3\n\u2212cs\n\u2212cs\n\u2264 s3 +\nD1 e\nds +\nD2 e\nds +\nD3 e\u2212cs s ds\n= s3 +\n\ns1\n\u22121 c\nc \u03b4c\n\u22121\n\n\u2264 (1 + c\n\n= (1 +\n\n+\n\ns2\n\u22121 c\n\u22122\nc \u03b4c + c (1\n\u22121\n\u22122\n\n) s3 + 2c\n\ns3\n\n+ cs3 )\u03b4cc\n\n+c\n\nc\u22121 ) s\n\n+ (1 + c\u22121 )c\u22121 ln(cn) + (1 + c\u22121 ) ln\n\n+2c\n\n+ c\u22122 .\n\n1\n\u22121\n\n130m\n2\u03c3\n\n\u0001\n\nWith the estimate of s1 in (20) a small computation yields\n\u0010\n1\n\u2264 (1 + c\u22121 ) 2c\u22121 ln n + 3 ln m + ln(m + 1) + 2 ln\n\u03c3\n\u0013\n\u0012\n\u0011\n2m\n2H\n+ c\u22121 + c\u22121 ln c + 6.5 + c\u22121 .\n+(2c)\u22121 ln\nln(\u03c0m/2)\n\u0001\u0001\n\u0001\n. In the case s3 < s2 a similar arguThis yields E ln C = O c\u22122 ln nH\n\u03c3\nment holds. This shows the first statement of Theorem 1.2. Finally, tracing\nthe constants in the case \u03b2 = 0, yields the asserted explicit bound.\n\u2737\nE ln C\n\n3.6\n\n\u0001\n\nAverage-case analysis\n\nWe show here that for the uniform distribution on S m , the probability tail\nestimates in Theorem 3.1 on C (A) can be significantly improved by essentially the same method.\nProposition 3.9 For A \u2208 (S m )n chosen uniformly at random we have\nProb{C (A) \u2265 t} = O (m + 1)5\n\n\u0001\n1\nln t .\nt\n\nMoreover, E(ln C (A)) = O(ln m) as stated in Corollary 1.3.\nProof (Sketch). A result due to Wendel [31] states that for k > m\n\u0013\nm \u0012\nvolFk,m\n1 X k\u22121\np(k, m) :=\n= k\u22121\n.\n(volS m )k\n2\ni\ni=0\n\n24\n\n(21)\n\n\fWe refer to the proof in \u00a73.3 for the uniform distribution on S m instead\nof \u03bc\u0100 (think of \u03c3 = 1). We write k instead of n. We do not need to use\nLemma 2.9. Moreover we do not bound p(k, m) = Prob{A \u2208 Fk,m } by 1 as\nin Equation (10). Taking account of this, the proof in \u00a73.3 shows that\n\b\n13m(m + 1)\n1\nProb A \u2208 Fk,m and C (A) \u2265 x \u2264 k *\np(k, m) ,\n2\nx\n\nprovided x \u2265 xU := 2m(m + 1).\nWe proceed now as in \u00a73.4, using the same notation. For a fixed strictly\nfeasible A = (a1 , . . . , ak ) we have by (15)\nn\nProb b \u2208 KA and\n\n1\n\u2265x\nsin d(b, \u2202KA )\n\no 13m 1\nA \u2264\n2 x\n\nprovided x \u2265 xV := 2m. Recall the definition of the event Ek from (12).\nSimilarly as for (17) we conclude with the help of Lemma 3.8 that\nProb Ek \u2264 Cm3 k p(k, m)\n\n1\nln t\nt\n\nfor t \u2265 e,\n\nwhere C stands for a universal constant. Using Lemma 3.10 stated below\nwe get\nn\u22121\nX\n\nk=m+1\n\nk p(k, m) \u2264\n\n4m\nX\n\nk p(k, m) +\n\n\u221e\nX\n\nk=4m+1\n\nk=m+1\n\nk p(k, m) = O(m2 ).\n\nHence, by Equation (13),\nProb{A \u2208 In,m and C (A) \u2265 t} \u2264\n\nn\u22121\nX\n\nk=m+1\n\nProb Ek \u2264 C \u2032 m5\n\n1\nln t\nt\n\nfor some constant C \u2032 . It is obvious that Prob{A \u2208 Fn,m and C (A) \u2265 t} can\nalso be bounded this way. Finally, the claimed bound on the expectation of\nln C (A) follows immediately with the help of [6, Prop. 2.4].\n\u2737\nLemma 3.10 We have\n\nP\u221e\n\nk=4m+1 k p(k, m)\n\n= o(1) for m \u2192 \u221e.\n\nProof. Let k > 4m. Wendel's result (21) implies\n\u0012\n\u0013\n2(m + 1) km+1\n(m + 1) k \u2212 1\n.\n\u2264\nk p(k, m) \u2264 k k\u22121\n2\nm!\n2k\nm\n25\n\n\fWe have km+1 2\u2212k \u2264 2\u2212k/2 for k \u2265 Cm log m, and sufficiently large m, where\nC > 0 is a suitable universal constant. Therefore, we get\n\u221e\n\nX\n\nk\u2265Cm log m\n\nk p(k, m) \u2264\n\n2(m + 1) X 1\n= o(1) (m \u2192 \u221e).\nm!\n2k/2\nk=0\n\nThe function x 7\u2192 xm+1 2\u2212x is monotonically decreasing for x \u2265 (m+1)/ ln 2.\nHence, as k > 4m, and using m! \u2265 (m/e)m we get\n1 km+1\ne \u0001m\n1 (4m)m+1\n\u2264\n\u2264\n4m\n.\nm! 2k\nm!\n24m\n4\n\nSince e/4 < 1, we conclude\nCm\nlog m\nX\nk=4m+1\n\nk p(k, m) \u2264 8m(m + 1)\n\ne \u0001m\nCm log m = o(1) (m \u2192 \u221e),\n4\n\nwhich completes the proof.\n\n4\n\n\u2737\n\nSome spherical convex geometry\n\nThe goal of this section is to provide the proof of Theorem 3.3, following the\nlines of [7, Theorem 1.2]. We proceed in several steps.\n\n4.1\n\nIntegrals of curvature and Weyl's tube formula\n\nFor the following material from differential geometry we refer to [29]. A\ngood reference for the differential geometry of convex sets is [3].\nLet V be a smooth hypersurface in S m with unit normal vector field\n\u03bd : V \u2192 S m . The principal curvatures of V at x \u2208 V are defined as the\neigenvalues \u03ba1 (x), . . . , \u03bam\u22121 (x) of the Weingarten map \u2212D\u03bd(x) : Tx V \u2192\nTx V . The ith curvature KV,i (x) of V at x is the ith symmetric polynomial\nin the principal curvatures:\nXY\nKV,i (x) :=\n\u03baj (x) (0 \u2264 i < m).\n|I|=i j\u2208I\n\nInteresting special cases are KV,0 (x) = 1 and\nKV,m\u22121 (x) = \u03ba1 (x) * * * \u03bam\u22121 (x) = det(\u2212D\u03bd(x)),\n26\n\n(22)\n\n\fwhich is called the Gaussian curvature of V at x. Let U be an open subset\nof V . In [7] the integral \u03bci (U ) of ith curvature and the integral |\u03bci |(U ) of\nith absolute curvature were defined as\nZ\nZ\n|KV,i | dV.\nKV,i dV, |\u03bci |(U ) :=\n\u03bci (U ) :=\nU\n\nU\n\nTwo special cases deserve special mention: \u03bc0 (U ) = vol U equals the (m\u22121)dimensional volume of U . Moreover, \u03bcm\u22121 (V ) is the integral of the Gaussian\ncurvature of V .\nBy a smooth convex body K in S m we will understand a convex body\nsuch that its boundary \u2202K is a smooth hypersurface in S m (of type C \u221e )\nand its Gaussian curvature does not vanish in any point of \u2202K.\nLet K be a smooth convex body in S m with boundary V := \u2202K. We\ndenote by \u03bd : V \u2192 S m the unit normal vector field of the hypersurface V that\npoints inwards of K. Here all the principal curvatures \u03baj (x) are nonnegative,\ncf. [3]. Hence the ith curvatures are nonnegative as well and therefore we\nhave \u03bci (U ) = |\u03bci |(U ) for any open subset U of V .\nFor 0 < \u03c6 \u2264 \u03c0/2 we define the \u03c6-tube T \u22a5 (U, \u03c6) around U as\nT \u22a5 (U, \u03c6) := {x \u2208 S m | \u2203y \u2208 U such that d(x, y) < \u03c6 and\n\n[x, y] intersects U orthogonally at y}.\n\nThe outer \u03c6-tube To\u22a5 (U, \u03c6) and inner \u03c6-tube Ti\u22a5 (U, \u03c6) of U are defined as\nTo\u22a5 (U, \u03c6) := T \u22a5 (U, \u03c6) \\ K and Ti\u22a5 (U, \u03c6) := T \u22a5 (U, \u03c6) \u2229 K.\nIn an important paper, Weyl [32] derived a formula for the volume of\ntubes around compact submanifolds of euclidean spaces or spheres. His\nresult can be seen as extension of Steiner's formula on the volume of \"parallel\nconvex sets\" in euclidean space, see also Allendoerfer [1]. Weyl's formula\nonly holds for a sufficiently small radius. In [7, Prop. 3.1], it was observed\nthat when replacing integrals of curvature by absolute integrals of curvature,\none obtains an upper bound on the volume of tubes holding for any radius.\nAs the above two notions of curvature coincide for boundaries of convex\nsets, we get the following result. (An inspection of the proof of [7, Prop. 3.1]\nreveals that separate bounds on the inner and outer tube hold.)\nProposition 4.1 Let K be a smooth convex body in S m and U be an open\nsubset of \u2202K. Then we have for all 0 < \u03c6 \u2264 \u03c0/2\nmax{volTo\u22a5 (U, \u03c6), volTi\u22a5 (U, \u03c6)}\n27\n\n\u2264\n\nm\u22121\nX\ni=0\n\nJm,i+1 (\u03c6) \u03bci (U ),\n\n\fwhere Jm,i+1 denotes the function defined in (4). Moreover, this upper\nbound is sharp for sufficiently small \u03c6, cf. [32].\n\n4.2\n\nSome integral geometry\n\nWe will need a special case of the principal kinematic formula of integral\ngeometry for spheres. We denote by G the orthogonal group O(m + 1), that\noperates on S m in the natural way, and denote by dG its volume element\nnormalized such that the volume of G equals one. The following result is\nTheorem 2.7. in [7]. (For related information see [19] and [16].)\nTheorem 4.2 Let U be an open subset of a compact oriented smooth hypersurface M of S m and 0 \u2264 i < m \u2212 1. Then we have\nZ\n\u03bci (gU \u2229 S i+1 ) dG(g),\n\u03bci (U ) = C(m, i)\ng\u2208G\n\nwhere C(m, i) = (m \u2212 i \u2212 1)\n\nOm\u22121 Om\nm\u22121\u0001\ni\nOi Oi+1 Om\u2212i\u22122 .\n\nThe special case i = 0 yields an effective tool for estimating volumes,\nusually referred to as Poincar\u00e9's formula:\nZ\nOm\u22121\n#(U \u2229 gS 1 ) dG(g),\n(23)\nvolm\u22121 U =\n2\ng\u2208G\nwhere #(U \u2229 gS 1 ) denotes the number of elements in U \u2229 gS 1 (note that this\nis a finite set for almost all g \u2208 G). Here is an application of (23). Clearly,\nthe given bound is sharp (consider spherical caps with radius almost \u03c0/2).\nCorollary 4.3 Any smooth convex body K in S m satisfies vol \u2202K \u2264 Om\u22121 .\nProof. Almost surely, the intersection \u2202K \u2229 gS 1 is finite. Then it consists\nof at most two points by convexity.\n\u2737\n\n4.3\n\nIntegrals of curvature for boundaries of convex sets\n\nIn this section we assume that K is a smooth convex body in S m and \u03bd is\nthe unit normal vector field on \u2202K pointing inwards of K. This means that\nfor x \u2208 V , the unit vector \u03bd(x) is uniquely characterized by the conditions\nhv, xi = 0 and hv, yi \u2265 0 for all y \u2208 K.\nLemma 4.4 We have \u2212\u03bd(\u2202K) = \u2202 K\u0306.\n28\n\n\fProof. The characterization of \u03bd(x) implies that \u2212\u03bd(x) \u2208 \u2202 K\u0306 for x \u2208 \u2202K.\nFor the other inclusion, let v be a unit vector satisfying \u2212v \u2208 \u2202 K\u0306. Then\nhv, yi \u2265 0 for all y \u2208 K. Moreover, there exists x \u2208 K such that hv, xi = 0.\nThis implies x \u2208 \u2202K. It follows that v = \u03bd(x).\n\u2737\nThe following bound is crucial for all what follows. Again, considering\nspherical caps with radius almost \u03c0/2, shows the optimality of the bound.\nProposition 4.5 The integral of Gaussian curvature of \u2202K is bounded as\n\u03bcm\u22121 (\u2202K) \u2264 Om\u22121 .\nProof. Put V := \u2202K. By Lemma 4.4, \u03bd : V \u2192 \u2202 K\u0306 is surjective. By (22)\nwe have KV,m\u22121 (x) = det(\u2212D\u03bd(x)) for x \u2208 V . Since we assume that the\nGaussian curvature does not vanish, the map \u03bd has no singular values.\nWe claim that \u03bd is injective. Otherwise, we had \u03bd(x) = \u03bd(y) for distinct\nx, y \u2208 V . Since h\u03bd(x), xi = 0 and h\u03bd(y), yi = 0 we had h\u03bd(x), zi = 0 for all\nz \u2208 [x, y]. Hence \u03bd would be constant along this segment and therefore x\nwould be a critical point, contradicting our asumption.\nWe conclude that \u2212\u03bd : V \u2192 \u03bd(V ) is a diffeomorphism onto the smooth\nhypersurface \u2202 K\u0306. The transformation theorem yields\nZ\nZ\ndet(\u2212D\u03bd) dV = vol \u2202 K\u0306.\nKV,m\u22121 dV =\n\u03bcm\u22121 (V ) =\nV\n\nV\n\nCorollary 4.3 implies now the assertion.\n\n\u2737\n\nLemma 4.6 For a \u2208 S m , 0 < \u03b1 \u2264 \u03c0/2, \u03c3 = sin \u03b1, and 0 \u2264 i < m we have\n\u0012\n\u0013\nm\u22121\n\u03bci (\u2202K \u2229 B(a, \u03b1)) \u2264\nOm\u22121 \u03c3 m\u2212i\u22121 .\ni\nProof. This is similar, but somewhat simpler than the proof of [7, Prop. 3.2].\nThe case i = m \u2212 1 is already established by Proposition 4.5. Hence we assume i < m \u2212 1. Let g \u2208 G = O(m + 1) be such that V := \u2202K intersects\ngS i+1 transversally with nonempty intersection. We apply Proposition 4.5\nto the convex body K \u2229 gS i+1 in the sphere gS i+1 , which has the smooth\nboundary V \u2229 gS i+1 . Hence \u03bci (V \u2229 gS i+1 ) \u2264 Oi . The kinematic formula of\nTheorem 4.2 applied to the open subset U := V \u2229 int(B(a, \u03b1)) of V yields\nZ\n\u03bci (gU \u2229 S i+1 ) dG(g)\n\u03bci (U ) = C(m, i)\ng\u2208G\n\n\u2264 C(m, i) Oi Prob{gU \u2229 S i+1 6= \u2205}.\ng\u2208G\n\n29\n\n\fUsing gU \u2286 B(ga, \u03b1), this probability may be estimated as follows\nProb{gU \u2229 S i+1 6= \u2205} \u2264 Prob{B(ga, \u03b1) \u2229 S i+1 6= \u2205}\ng\u2208G\n\n=\n\n\u2032\n\nProb {B(a , \u03b1) \u2229 S\n\ng\u2208G\ni+1\n\na\u2032 \u2208S m\n\n\u22121\n6= \u2205} = Om\nvolT (S i+1 , \u03b1).\n\nLemma 2.1 in [7] implies vol T (S i+1 , \u03b1) = Oi+1 Om\u2212i\u22122 Jm,m\u2212i\u22121 (\u03b1). Moroever, Lemma 2.2 in [7] says that\nJm,k (\u03b1) \u2264\n\n\u03c3k\nk\n\nfor 1 \u2264 k < m.\n\n(24)\n\nBy combining these estimates and plugging in the formula for C(m, i) from\nTheorem 4.2, the\nexpression considerably simplifies and we get\n\u0001 resulting\nm\u2212i\u22121 as claimed.\n\u03bci (U ) \u2264 m\u22121\nO\n\u03c3\n\u2737\nm\u22121\ni\n\n4.4\n\nProof of Theorem 3.3\n\nWe can finally provide the proof of Theorem 3.3. We assume first that K is\na smooth convex body in S m . Let a \u2208 S m , 0 < \u03b1, \u03c6 \u2264 \u03c0/2, put \u03c3 = sin \u03b1,\n\u03b5 = sin \u03c6, and let U = \u2202K \u2229 B(a, \u03b1). By combining Proposition 4.1 with\nLemma 4.6 we get\nvolTo\u22a5 (U, \u03c6) \u2264\n\nm\u22121\nX\u0012\ni=0\n\n\u0013\nm\u22121\nOm\u22121 \u03c3 m\u2212i\u22121 Jm,i+1 (\u03c6).\ni\n\nUsing the\u0001 estimate\n\u0001 (24) we obtain after a short calculation (put k = i + 1,\nk m\nuse m\u22121\n=\nm k and consider separately the term for k = m)\nk\u22121\nvolTo\u22a5 (\u2202K\n\nm\u22121 \u0012 \u0013\nOm\u22121 X m k m\u2212k\n1\n\u2229 B(a, \u03b1), \u03c6) \u2264\n\u03b5 \u03c3\n+ Om \u03b5m .\nm\n2\nk\n\n(25)\n\nk=1\n\nThe same upper bound holds for the volume of Ti\u22a5 (\u2202K \u2229 B(a, \u03b1), \u03c6).\nWe claim that\nTo (\u2202K, \u03c6) \u2229 B(\u00b1a, \u03b1) \u2286 To\u22a5 (\u2202K \u2229 B(\u00b1a, \u03b2), \u03c6)\n\n(26)\n\nwhere \u03b2 = arcsin min{1, \u03c3 + \u03b5}. Indeed, suppose x \u2208 To (\u2202K, \u03c6) \u2229 B(\u00b1a, \u03b1)\nand let y \u2208 \u2202K be a closest point to x. Then d(x, y) \u2264 \u03c6 and [x, y] intersects \u2202K orthogonally (as \u2202K is smooth without boundary). The triangle inequality for projective distance (cf. \u00a72.2) implies that sin d(a, y) <\n30\n\n\fsin d(a, x) + sin d(x, y) \u2264 \u03c3 + \u03b5. Hence sin d(a, y) \u2264 sin \u03b2 and therefore\ny \u2208 B(\u00b1a, \u03b2) which shows the claim.\nBy combining (26) with (25) we get\nm\u22121 \u0012 \u0013\n2Om\u22121 X m k\nvol(To (\u2202K, \u03c6) \u2229 B(\u00b1a, \u03b1)) \u2264\n\u03b5 (\u03c3 + \u03b5)m\u2212k + Om \u03b5m .\nm\nk\nk=1\n\nm\n\nWe have volB(\u00b1a, \u03b1) \u2265 2Om\u22121 \u03c3m , cf. [7, Lemmas 2.1-2.2]. Using this, we\nobtain\nm\u22121\nX \u0012m \u0013 \u0010\nvol(To (\u2202K, \u03c6) \u2229 B(\u00b1a, \u03b1))\n\u03b5 \u0011m\u2212k \u0010 \u03b5 \u0011k\nmOm \u0010 \u03b5 \u0011m\n1+\n\u2264\n+\n.\nk\nvolB(\u00b1a, \u03b1)\n\u03c3\n\u03c3\n2Om\u22121 \u03c3\nk=1\n(27)\nThis shows the assertion of Theorem 3.3 for the outer neighborhood in the\ncase where K is a smooth convex body. The bound for the inner neighborhood is shown similarly.\nThe general case where K is any properly convex set in S m will follow\nby a pertubation argument. We define the Hausdorff distance d(K, K \u2032 ) of\ntwo convex sets K and K \u2032 in S m as the infimum of the real numbers \u03b4 \u2265 0\nsatisfying K \u2286 T (K \u2032 , \u03b4) and K \u2032 \u2286 T (K, \u03b4). This defines a metric and allows\nto speak about the convergence of convex sets. (For compact convex sets in\neuclidean space the Hausdorff distance is a well known notion.)\n\nLemma 4.7 Any properly convex set K in S m is the limit of a sequence of\nsmooth convex bodies.\nProof. The euclidean version of the claim is a well known result due to\nMinkowski, see [3, \u00a76] (or [24]) for more information.\nA properly convex set K \u2282 S m is contained in an open halfspace. For\nm := {x \u2208 S m | hx, pi >\nfixed p \u2208 S m consider now the open halfsphere S+\n0} with center p and the affine space E := {x \u2208 Rm+1 | hx, pi = 1}.\nm \u2192 E, x 7\u2192 hp, xi\u22121 x maps an intersection\nThe \"perspective map\" \u03c0 : S+\nm\nof a linear space with S to an affine linear subspace of E and vice versa.\nMoreover, \u03c0 maps convex sets to convex sets and vice versa. Moreover, one\nsees that \u03c0 induces a homeomorphism between the set of convex subsets of\nm and the set of compact convex subsets of E. It is easily checked that\nS+\nif K\u0303 \u2282 E smooth compact convex has nonvanishing Gaussian curvature on\nthe boundary, then this also holds for \u03c0(K\u0303). The assertion follows from the\neuclidean version of our claim.\n\u2737\n\n31\n\n\fTo finish the proof of Theorem 3.3 let now K \u2282 S m be a properly\nconvex set and \u03b4 > 0. By Lemma 4.7 there exists a smooth convex body K \u2032\nsuch that K and K \u2032 have Hausdorff distance at most \u03b4, which means that\nK \u2286 T (K \u2032 , \u03b4) and K \u2032 \u2286 T (K, \u03b4). This implies K \u2032 \\ K \u2286 T (\u2202K, \u03b4) and\nTo (\u2202K, \u03c6) \u2286 To (\u2202K \u2032 , \u03c6 + \u03b4) \u222a (K \u2032 \\ K).\nBy applying (27) to To (\u2202K \u2032 , \u03c6+\u03b4), letting \u03b4 \u2192 0, and noting that volT (\u2202K, \u03b4)\ngoes to zero, the desired assertion follows. For the inner neighborhood one\nargues similarly.\n\u2737\n\nReferences\n[1] C.B. Allendoerfer. Steiner's formulae on a general S n+1 . Bull. Amer. Math.\nSoc., 54:128\u2013135, 1948.\n[2] K. Ball. The reverse isoperimetric problem for Gaussian measure. Discrete\nComput. Geom., 10(4):411\u2013420, 1993.\n[3] T. Bonnesen and W. Fenchel. Theorie der konvexen K\u00f6rper. Springer-Verlag,\nBerlin, 1974. Berichtigter Reprint.\n[4] P. B\u00fcrgisser. Smoothed analysis of condition numbers. In Foundations of Computational Mathematics, Hong Kong 2008, pages 1\u201341. Cambridge University\nPress, 2009.\n[5] P. B\u00fcrgisser, F. Cucker, and M. Lotz. Coverage processes on spheres and\ncondition numbers for linear programming. To appear in Annals of Probability.\n[6] P. B\u00fcrgisser, F. Cucker, and M. Lotz. Smoothed analysis of complex conic\ncondition numbers. J. Math. Pures et Appl., 86:293\u2013309, 2006.\n[7] P. B\u00fcrgisser, F. Cucker, and M. Lotz. The probability that a slightly perturbed\nnumerical analysis problem is difficult. Math. Comp., 77(263):1559\u20131583, 2008.\n[8] D. Cheung and F. Cucker. A new condition number for linear programming.\nMath. Program., 91(1, Ser. A):163\u2013174, 2001.\n[9] D. Cheung and F. Cucker. Probabilistic analysis of condition numbers for linear\nprogramming. Journal of Optimization Theory and Applications, 114:55\u201367,\n2002.\n[10] D. Cheung, F. Cucker, and R. Hauser. Tail decay and moment estimates\nof a condition number for random linear conic systems. SIAM J. Optim.,\n15(4):1237\u20131261 (electronic), 2005.\n[11] F. Cucker, R. Hauser, and M. Lotz. Adversarial smoothed analysis. To appear\nin J. of Complexity.\n\n32\n\n\f[12] F. Cucker and J. Pe\u00f1a. A primal-dual algorithm for solving polyhedral conic\nsystems with a finite-precision machine. SIAM J. Optim., 12(2):522\u2013554 (electronic), 2001/02.\n[13] F. Cucker and M. Wschebor. On the expected condition number of linear\nprogramming problems. Numer. Math., 94:419\u2013478, 2002.\n[14] J. Demmel. The probability that a numerical analysis problem is difficult.\nMath. Comp., 50:449\u2013480, 1988.\n[15] J. Dunagan, D.A. Spielman, and S.-H. Teng. Smoothed analysis of condition\nnumbers and complexity implications for linear programming. Math. Programm. Series A, 2009. To appear.\n[16] S. Glasauer. Integralgeometrie konvexer K\u00f6rper im sph\u00e4rischen Raum. PhD\nthesis, Universit\u00e4t Freiburg im Br., 1995.\n[17] J.-L. Goffin. The relaxation method for solving systems of linear inequalities.\nMath. Oper. Res., 5(3):388\u2013414, 1980.\n[18] R. Hauser and T. M\u00fcller. Conditioning of random conic systems under a\ngeneral family of input distributions. Found. Comput. Math., 9(3):335\u2013358,\n2009.\n[19] R. Howard. The kinematic formula in Riemannian homogeneous spaces. Mem.\nAmer. Math. Soc., 106(509):vi+69, 1993.\n[20] J. Renegar. Some perturbation theory for linear programming. Math. Programming, 65(1, Ser. A):73\u201391, 1994.\n[21] J. Renegar. Incorporating condition measures into the complexity theory of\nlinear programming. SIAM J. Optim., 5(3):506\u2013524, 1995.\n[22] J. Renegar. Linear programming, complexity theory and elementary functional\nanalysis. Math. Programming, 70(3, Ser. A):279\u2013351, 1995.\n[23] A. Sankar, D.A. Spielman, and S.H. Teng. Smoothed analysis of the condition numbers and growth factors of matrices. SIAM J. Matrix Anal. Appl.,\n28(2):446\u2013476 (electronic), 2006.\n[24] R. Schneider. Smooth approximation of convex bodies. Rend. Circ. Mat.\nPalermo (2), 33(3):436\u2013440, 1984.\n[25] S. Smale. Complexity theory and numerical analysis. In A. Iserles, editor,\nActa Numerica, pages 523\u2013551. Cambridge University Press, 1997.\n[26] D.A. Spielman and S.-H. Teng. Smoothed analysis of algorithms. In Proceedings of the International Congress of Mathematicians, volume I, pages 597\u2013606,\n2002.\n[27] D.A. Spielman and S.-H. Teng. Smoothed analysis of termination of linear\nprogramming algorithms. Math. Programm. Series B, 97:375\u2013404, 2003.\n\n33\n\n\f[28] D.A. Spielman and S.-H. Teng. Smoothed analysis: Why the simplex algorithm\nusually takes polynomial time. Journal of the ACM, 51:385\u2013463, 2004.\n[29] M. Spivak. A comprehensive introduction to differential geometry. Vol. III.\nPublish or Perish Inc., Wilmington, Del., second edition, 1979.\n[30] R. Webster. Convexity. Oxford Science Publications. The Clarendon Press\nOxford University Press, New York, 1994.\n[31] J. G. Wendel. A problem in geometric probability. Math. Scand., 11:109\u2013111,\n1962.\n[32] H. Weyl. On the Volume of Tubes. Amer. J. Math., 61(2):461\u2013472, 1939.\n\n34\n\n\f"}