{"id": "http://arxiv.org/abs/quant-ph/0307217v4", "guidislink": true, "updated": "2004-05-29T11:41:32Z", "updated_parsed": [2004, 5, 29, 11, 41, 32, 5, 150, 0], "published": "2003-07-29T18:59:40Z", "published_parsed": [2003, 7, 29, 18, 59, 40, 1, 210, 0], "title": "The chaotic chameleon", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=quant-ph%2F0307144%2Cquant-ph%2F0307035%2Cquant-ph%2F0307208%2Cquant-ph%2F0307231%2Cquant-ph%2F0307196%2Cquant-ph%2F0307106%2Cquant-ph%2F0307209%2Cquant-ph%2F0307087%2Cquant-ph%2F0307078%2Cquant-ph%2F0307067%2Cquant-ph%2F0307161%2Cquant-ph%2F0307124%2Cquant-ph%2F0307018%2Cquant-ph%2F0307121%2Cquant-ph%2F0307019%2Cquant-ph%2F0307050%2Cquant-ph%2F0307027%2Cquant-ph%2F0307017%2Cquant-ph%2F0307240%2Cquant-ph%2F0307107%2Cquant-ph%2F0307051%2Cquant-ph%2F0307151%2Cquant-ph%2F0307010%2Cquant-ph%2F0307008%2Cquant-ph%2F0307221%2Cquant-ph%2F0307233%2Cquant-ph%2F0307102%2Cquant-ph%2F0307120%2Cquant-ph%2F0307170%2Cquant-ph%2F0307140%2Cquant-ph%2F0307181%2Cquant-ph%2F0307190%2Cquant-ph%2F0307005%2Cquant-ph%2F0307210%2Cquant-ph%2F0307218%2Cquant-ph%2F0307229%2Cquant-ph%2F0307016%2Cquant-ph%2F0307215%2Cquant-ph%2F0307074%2Cquant-ph%2F0307079%2Cquant-ph%2F0307075%2Cquant-ph%2F0307001%2Cquant-ph%2F0307142%2Cquant-ph%2F0307068%2Cquant-ph%2F0307214%2Cquant-ph%2F0307153%2Cquant-ph%2F0307006%2Cquant-ph%2F0307217%2Cquant-ph%2F0307166%2Cquant-ph%2F0307175%2Cquant-ph%2F0307023%2Cquant-ph%2F0307058%2Cquant-ph%2F0307082%2Cquant-ph%2F0307212%2Cquant-ph%2F0307038%2Cquant-ph%2F0307004%2Cquant-ph%2F0307137%2Cquant-ph%2F0307163%2Cquant-ph%2F0307055%2Cquant-ph%2F0307200%2Cquant-ph%2F0307179%2Cquant-ph%2F0307152%2Cquant-ph%2F0307045%2Cquant-ph%2F0307145%2Cquant-ph%2F0307160%2Cquant-ph%2F0307015%2Cquant-ph%2F0307071%2Cquant-ph%2F0307237%2Cquant-ph%2F0307115%2Cquant-ph%2F0307052%2Cquant-ph%2F0307132%2Cquant-ph%2F0307009%2Cquant-ph%2F0307099%2Cquant-ph%2F0307183%2Cquant-ph%2F0307063%2Cquant-ph%2F0307076%2Cquant-ph%2F0307159%2Cquant-ph%2F0307084%2Cquant-ph%2F0307136%2Cquant-ph%2F0307097%2Cquant-ph%2F0307127%2Cquant-ph%2F0307180%2Cquant-ph%2F0307206%2Cquant-ph%2F0307228%2Cquant-ph%2F0307148%2Cquant-ph%2F0307182%2Cquant-ph%2F0307109%2Cquant-ph%2F0502110%2Cquant-ph%2F0502065%2Cquant-ph%2F0502085%2Cquant-ph%2F0502179%2Cquant-ph%2F0502124%2Cquant-ph%2F0502147%2Cquant-ph%2F0502113%2Cquant-ph%2F0502010%2Cquant-ph%2F0502107%2Cquant-ph%2F0502133%2Cquant-ph%2F0502178%2Cquant-ph%2F0502078%2Cquant-ph%2F0502053%2Cquant-ph%2F0502079&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The chaotic chameleon"}, "summary": "Various local hidden variables models for the singlet correlations exploit\nthe detection loophole, or other loopholes connected with post-selection on\ncoincident arrival times. I consider the connection with a probabilistic\nsimulation technique called rejection-sampling, and pose some natural questions\nconcerning what can be achieved and what cannot be achieved with local (or\ndistributed) rejection sampling. In particular a new and more serious loophole,\nwhich we call the coincidence loophole, is introduced.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=quant-ph%2F0307144%2Cquant-ph%2F0307035%2Cquant-ph%2F0307208%2Cquant-ph%2F0307231%2Cquant-ph%2F0307196%2Cquant-ph%2F0307106%2Cquant-ph%2F0307209%2Cquant-ph%2F0307087%2Cquant-ph%2F0307078%2Cquant-ph%2F0307067%2Cquant-ph%2F0307161%2Cquant-ph%2F0307124%2Cquant-ph%2F0307018%2Cquant-ph%2F0307121%2Cquant-ph%2F0307019%2Cquant-ph%2F0307050%2Cquant-ph%2F0307027%2Cquant-ph%2F0307017%2Cquant-ph%2F0307240%2Cquant-ph%2F0307107%2Cquant-ph%2F0307051%2Cquant-ph%2F0307151%2Cquant-ph%2F0307010%2Cquant-ph%2F0307008%2Cquant-ph%2F0307221%2Cquant-ph%2F0307233%2Cquant-ph%2F0307102%2Cquant-ph%2F0307120%2Cquant-ph%2F0307170%2Cquant-ph%2F0307140%2Cquant-ph%2F0307181%2Cquant-ph%2F0307190%2Cquant-ph%2F0307005%2Cquant-ph%2F0307210%2Cquant-ph%2F0307218%2Cquant-ph%2F0307229%2Cquant-ph%2F0307016%2Cquant-ph%2F0307215%2Cquant-ph%2F0307074%2Cquant-ph%2F0307079%2Cquant-ph%2F0307075%2Cquant-ph%2F0307001%2Cquant-ph%2F0307142%2Cquant-ph%2F0307068%2Cquant-ph%2F0307214%2Cquant-ph%2F0307153%2Cquant-ph%2F0307006%2Cquant-ph%2F0307217%2Cquant-ph%2F0307166%2Cquant-ph%2F0307175%2Cquant-ph%2F0307023%2Cquant-ph%2F0307058%2Cquant-ph%2F0307082%2Cquant-ph%2F0307212%2Cquant-ph%2F0307038%2Cquant-ph%2F0307004%2Cquant-ph%2F0307137%2Cquant-ph%2F0307163%2Cquant-ph%2F0307055%2Cquant-ph%2F0307200%2Cquant-ph%2F0307179%2Cquant-ph%2F0307152%2Cquant-ph%2F0307045%2Cquant-ph%2F0307145%2Cquant-ph%2F0307160%2Cquant-ph%2F0307015%2Cquant-ph%2F0307071%2Cquant-ph%2F0307237%2Cquant-ph%2F0307115%2Cquant-ph%2F0307052%2Cquant-ph%2F0307132%2Cquant-ph%2F0307009%2Cquant-ph%2F0307099%2Cquant-ph%2F0307183%2Cquant-ph%2F0307063%2Cquant-ph%2F0307076%2Cquant-ph%2F0307159%2Cquant-ph%2F0307084%2Cquant-ph%2F0307136%2Cquant-ph%2F0307097%2Cquant-ph%2F0307127%2Cquant-ph%2F0307180%2Cquant-ph%2F0307206%2Cquant-ph%2F0307228%2Cquant-ph%2F0307148%2Cquant-ph%2F0307182%2Cquant-ph%2F0307109%2Cquant-ph%2F0502110%2Cquant-ph%2F0502065%2Cquant-ph%2F0502085%2Cquant-ph%2F0502179%2Cquant-ph%2F0502124%2Cquant-ph%2F0502147%2Cquant-ph%2F0502113%2Cquant-ph%2F0502010%2Cquant-ph%2F0502107%2Cquant-ph%2F0502133%2Cquant-ph%2F0502178%2Cquant-ph%2F0502078%2Cquant-ph%2F0502053%2Cquant-ph%2F0502079&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Various local hidden variables models for the singlet correlations exploit\nthe detection loophole, or other loopholes connected with post-selection on\ncoincident arrival times. I consider the connection with a probabilistic\nsimulation technique called rejection-sampling, and pose some natural questions\nconcerning what can be achieved and what cannot be achieved with local (or\ndistributed) rejection sampling. In particular a new and more serious loophole,\nwhich we call the coincidence loophole, is introduced."}, "authors": ["Richard D. Gill"], "author_detail": {"name": "Richard D. Gill"}, "author": "Richard D. Gill", "arxiv_comment": "v.2: 7pp; conjecture 1 disproved by Gisin & Gisin (1999) but which\n  leads to new open problems and conjectures. v.3: minor correction and\n  addition. To appear in proceedings of \"Quantum Probability and Infinite\n  Dimensional Analysis\", Greifswald, 2003; World Scientific. v.4: major\n  revision in view of solution of another conjecture by Larsson & Gill (2003)", "links": [{"href": "http://arxiv.org/abs/quant-ph/0307217v4", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/quant-ph/0307217v4", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "quant-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "quant-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.PR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/quant-ph/0307217v4", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/quant-ph/0307217v4", "journal_reference": "pp. 269--276 in: M. Sch\"urmann and U. Franz (eds.), Quantum\n  Probability and Infinite Dimensional Analysis: from Foundations to\n  Applications. QP--PQ: Quantum Probability and White Noise Analysis, Volume 18\n  (2005). World Scientific.", "doi": null, "fulltext": "arXiv:quant-ph/0307217v4 29 May 2004\n\nOctober 30, 2018\n\n3:6\n\nProceedings Trim Size: 9in x 6in\n\nchaoticcham3b\n\nTHE CHAOTIC CHAMELEON\n\nRICHARD D. GILL\nMathematical Institute, University of Utrecht, Netherlands, &\nEURANDOM, Eindhoven, Netherlands\ngill@math.uu.nl\nhttp://www.math.uu.nl/people/gill\n\nVarious local hidden variables models for the singlet correlations exploit the detection loophole, or other loopholes connected with post-selection on coincident\narrival times. I consider the connection with a probabilistic simulation technique\ncalled rejection-sampling, and pose some natural questions concerning what can\nbe achieved and what cannot be achieved with local (or distributed) rejection sampling. In particular a new and more serious loophole, which we call the coincidence\nloophole, is introduced.\n\n1. Introduction\nIt has been well known since Pearle (1970) that local realistic models can\nexplain the singlet correlations when these are determined on the basis of\npost-selected coincidences rather than on pre-selected event pairs. These\nmodels are usually felt to be unphysical and conspiratorial, and especially\nthat they simply exploit defects of present day detection apparatus (hence\nthe name \"the detection loophole\"). However, Accardi, Imafuku and Regoli\n(2002, 2003) (\"the chameleon effect \"), Thompson and Holstein (2002) (\"the\nthe chaotic ball effect \"), and others have argued that their models could\nmake physical sense. Further examples are provided by Hess and Philipp\n(2001a,b, 2004), Kracklauer (2002), Sanctuary (2003), in many cases unwittingly. Already, Gisin and Gisin (1999) show that these models can be\nsimple and elegant, and should not be thought of as being artificial.\nAccardi et al. (2002, 2003) furthermore insist that their work, based\non the chameleon effect, has nothing to do with the so-called detection\nloophole. Rather, they claim that the chameleon model is built on a fundamental legacy of measurement of quantum systems, that there is also\nindeterminacy in whether or not a particle gets measured at all, and when\nit gets measured. Furthermore, they focus entirely on perceived defects of\n1\n\n\fOctober 30, 2018\n\n3:6\n\nProceedings Trim Size: 9in x 6in\n\nchaoticcham3b\n\n2\n\nthe landmark paper Bell (1964), where the incompatibility of the singlet\ncorrelations with local realism was first established. Now Bell himself became well aware of imperfections in his original work and in Bell (1981)\n(reprinted in Bell, 1987), taking account of one and a half decades of intense debate, he explicitly elaborated on the experimental protocol which\nis necessary, before one can conclude from an experimental violation of\nthe Bell-CHSH inequality, that a local realistic explanation of the observed\nphenomena is impossible. That protocol is not adhered to by Accardi et al.\n(2002, 2003), nor (of course) by any of the previously cited works in which\nlocal realistic violations of Bell-CHSH inequalities are obtained.\nIt is a mathematical fact that \"chameleon model\" of the type proposed\nby Accardi et al. (2002, 2003) can be converted into a \"detection loophole\nmodel\", and vice-versa. This result has been independently obtained by\nTakayuki Miyadera and Masanori Ohya, and by the present author (unpublished).\nIn this paper I do not want to continue the philosophical debate, nor\naddress questions of physical legitimacy of these models. See Gill (2003) for\nan overview, and in particular, for a discussion of the option that quantum\nmechanics itself could prevent a succesfull loophole-free experiment by preventing us from achieving the required initial conditions. Instead I would\nlike to extract a mathematical kernel from this literature, exposing some\nnatural open problems concerning properties of these models. Possibly\nsome answers are already known to experts on Bell-type experiments and\non distributed quantum computation. I would especially like to pose these\nproblems to experts in probability theory, since the basic renormalization\ninvolved both in the chameleon model (under the name of a \"form factor\")\nand in detection-loophole models, is well known in probability theory under the name of rejection-sampling. From now I will use the language of\nApplied Probability: simulation, rejection-sampling, and so on; and avoid\nreference to physics or philosophy.\nThe main new contribution of this paper is the discovery of a new loophole, which we call the coincidence loophole, which occurs when particle\npairs are selected on the basis of nearly coincident arrival times. It has\nrecently been shown by Larsson & Gill (2003) that this loophole is in a\ncertain sense twice as serious as the well-known detection loophole.\n\n\fOctober 30, 2018\n\n3:6\n\nProceedings Trim Size: 9in x 6in\n\nchaoticcham3b\n\n3\n\n2. The Problem\nSuppose we want to simulate two random variables X, Y from a joint probability distribution depending on two parameters a, b. To fix ideas, let me\ngive two key examples:\nCase 1 The Singlet Correlations. X, Y are binary, taking the values\n\u00b11. The parameters a, b are two directions in real, three dimensional space.\nWe will represent them with two unit vectors in R3 (two points on the unit\nsphere S2 ). The joint density of X, Y (their joint probability mass function)\nis\n\u0011\n1\u0010\n1 \u2212 xy a * b ,\n(1)\nPra,b {X = x, Y = y} = p(x, y; a, b) =\n4\nwhere a * b stands for the inner product of the unit vectors a and b and\nx, y = \u00b11. Note that the marginal laws of X and Y are both Bernoulli ( 12 )\non {\u22121, +1}, and their covariance equals their correlation equals \u2212a * b. In\nparticular, the marginal law of X does not depend on b nor that of Y on\na.\nCase 2 The Singlet Correlations Restricted. This is identical to the\nprevious example except that we are only interested in a and b taking values\nin two particular, possibly different, finite sets of points on S2 .\nNext I describe two different protocols for \"distributed Monte-Carlo simulation experiments\"; the difference is that one allows rejection sampling, the\nother does not. The idea is that the random variables X and Y are going to\nbe generated on two different computers, and the inputs a, b are only given\nto each computer separately. The two computers are to generate dependent\nrandom variables, so they will start with having some shared randomness\nbetween them. The programmer is allowed to start with any number of random variables, distributed just how he likes, for this purpose. Cognoscenti\nwill realize that it suffices to have just one random variable, uniformly distributed on the interval [0, 1], or equivalently, an infinite sequence of fair\nindependent coin tosses. There is no need for the two computers to have access to further randomness-they may as well share everything they might\never need, separately or together, from the start.\nThe difference between the two protocols, or two tasks, is that the first\nhas to get it right first time, or if you prefer, with probability one. The\nsecond protocol is allowed to make mistakes, as long as the mistakes are\nalso \"distributed\". Another way to say this, is that we allow \"distributed\n\n\fOctober 30, 2018\n\n3:6\n\nProceedings Trim Size: 9in x 6in\n\nchaoticcham3b\n\n4\n\nrejection sampling\". Moreover, we allow the second protocol not to be\ncompletely accurate. It might be, that the second protocol can be made\nmore and more accurate at the expense of a smaller and smaller acceptance\n(success) probability. This is precisely what we want to study. Success\nprobability and accuracy can both depend on the parameters a and b so\none will probably demand uniformly high success probability, and uniformly\ngood accuracy.\nTask 1 Perfect Distributed Monte-Carlo. Construct a probability distribution of a random variable Z, and two transformations f and g of Z,\neach depending on one of the two parameters a and b, such that\nf (Z; a), g(Z; b) \u223c X, Y\n\nfor all a, b.\n\n(2)\n\nThe symbol '\u223c' means 'is jointly distributed as', and X, Y on the right\nhand side come from the prespecified (or target) joint law with the given\nvalues of the parameters a and b.\nTask 2 Imperfect Distributed Rejection Sampling. As before, but\nthere are two further transformations, let me call them D = \u03b4(Z, a) and\nE = \u01eb(Z; b), such that \u03b4 and \u01eb take values 1 and 0 or if you like, ACCEPT\nand REJECT, and such that\nf (Z; a), g(Z; b) | D = 1 = E\n\n\u223c\n \u0307\n\nX, Y.\n\n(3)\n\nThe symbol '|' stands for 'conditional on', and '\u223c'\n \u0307 means 'is approximately\ndistributed as'. The quality of the approximation needs to be quantified;\nin our case, the supremum over a and b of the variation distance between\nthe two probability laws could be convenient (a low score means high quality). Moreover, one would like to have a uniformly large chance of acceptance. Thus a further interesting score (high score means high quality) is\ninf a,b Pr{D = 1 = E}.\n3. The Solutions\nBy Bell (1964) there is no way to succeed in Task 1 for Case 1. Moreover,\nthere is no way to succeed in Task 1 for Case 2 either, for certain suitably\nchosen two-point sets of values for a and b.\nConsider now Task 2, and suppose first of all that there are only two\npossible different values of a and b each (Case 2). Let the random variable Z consist of independent coin tosses coding guesses for a and b, and\n\n\fOctober 30, 2018\n\n3:6\n\nProceedings Trim Size: 9in x 6in\n\nchaoticcham3b\n\n5\n\na realization of the pair X, Y drawn from the guessed joint distribution.\nThe transformations \u03b4 and \u01eb check if each guess is correct. The transformations f and g simply deliver the already generated X, Y . One obtains\nperfect accuracy with success probability 1/4. It is known that a much\nhigher success probability is achievable at the expense of more complicated\ntransformations.\nNow consider Task 2 for Case 1. So there is a continuum of possible\nvalues of a and b. Note that the joint law of X, Y depends on the parameters\na, b continuously, and the parameters vary in compact sets. So one can\npartition each of their ranges into a finite number of cells in such a way\nthat the joint law of X, Y does not change much while each parameter\nvaries within one cell of their respective partitions. Moreover, one can get\nless and less variation at the expense of more and more cells. Pick one\nrepresentative parameter value in each cell.\nNow, fix one of these pairs of partitions, and just play the obvious\ngeneralization of our guessing game, using the representative parameter\nvalues for the guessed cells. If each partition has k cells and the guesses\nare uniform and independent, our success probability is 1/k 2 , uniformly in\na and b. We can achieve arbitrarily high accuracy, uniformly in a and b, at\nthe cost of arbitrarily low success probability.\nHowever, Gisin and Gisin (1999) show we can do much better in the\ncase of the singlet correlations:\nTheorem 1 Perfect conditional simulation of the singlet correlations. For Case 1 and Task 2, there exists a perfect simulation with success\nprobability uniformly equal to 1/2.\nSee Gisin and Gisin (1999) for the very pretty details. Can we do better\nstill? What is the maximum uniformly achievable success probability?\nThe joint laws coming from quantum mechanics always satisfy no action\nat a distance (\"no Bell telephone\"), i.e., the marginal of X does not depend\non b nor that of Y on a. This should obviously be favourable to finding\nsolutions to our tasks. Does it indeed play a role in making these simulations\nspectacularly more easy for quantum mechanics, than in general? Does \"no\naction at a distance\" ensure that we can find a perfect solution to Task 2\nwith success probability uniformly bounded away from 0? Am I indeed\ncorrect in thinking that one find probability distributions p with action at\na distance, depending smoothly on parameters a, b, for which one can only\nachieve perfection in the limit of zero success probability?\n\n\fOctober 30, 2018\n\n3:6\n\nProceedings Trim Size: 9in x 6in\n\nchaoticcham3b\n\n6\n\nIt would be interesting to study these problems in a wider context:\narbitrary biparameterized joint laws p; extend from pairs to triples; . . .\n4. Variant 1: Coincidences\nInstead of demanding that \u03b4 and \u01eb in Task 2 are binary, one might allow\nthem to take on arbitrary real values, and correspondingly allow a more\nrich acceptance rule. Suggestively changing the notation to suggest times,\ndefine now S = \u03b4(Z; a) and T = \u01eb(Z; b). Instead of conditioning on the\nseparate events D = 1 and E = 1 condition on the event |S \u2212 T | < c where\nc is some constant. Obviously the new variant contains the original, so\nVariant Task 2 is at least as easy as the original. Accardi, Imafuku and\nRegoli (2002) suggest that they tackle this variant task claiming that it has\nnothing to do with detector efficiency, but on the contrary is intrinsic to\nquantum optics, that one must post-select on coincidences in arrival times\nof entangled photons. By Heisenberg uncertainty, photons will always have\na chance to arrive (or to be measured) at different times. In those cases\ntheir joint state is not the singlet state. Therefore, if we were to collect\ndata on all pairs (supposing 100% detector efficiency) we would not recover\nthe singlet correlations.\nIn actual fact the mathematical model of Accardi et al. (2002, 2003)\napplies to the original task, not the variant. Still, in many experiments\nthis kind of coincidence post-selection is done. Its effects (in terms of the\nloophole issue) has never yet been analysed. The common consensus is that\nit is no worse than the usual detection loophole. I convert this consensus\ninto a conjecture:\nConjecture 1 No improvement from coincidences. There is no gain\nfrom Variant Task 2 over the original.\nAmazingly, this conjecture turns out to be false. In quantitative terms the\n\"coincidence loophole\" is about twice as serious as the detection loophole;\nsee Larsson and Gill (2003). Fortunately, modern experimenters are moving\n(as Bell, 1981, stipulated) toward pulsed experiments and/or to event-ready\ndetectors. In such an experment the detection time windows are fixed in\nadvance, not determined by the arrival times of the photons themselves.\nThere seems to be a connection with the work of Massar, Bacon, Cerf\nand Cleve (2001) on classical simulation of quantum entanglement using\nclassical communication. After all, checking the inequality |S \u2212 T | < c is a\ntask which requires communication between the two observers.\n\n\fOctober 30, 2018\n\n3:6\n\nProceedings Trim Size: 9in x 6in\n\nchaoticcham3b\n\n7\n\n5. Variant 2: Demanding More\nInstead of making Task 2 easier, as in the previous section, we can try to\nmake it harder by demanding further attractive properties of the simulated\njoint probability distribution of D, X, E, Y . For instance, Gisin and Gisin\n(1999) show how one can achieve nice symmetry and stochastic independence properties at the cost of an only slightly smaller success probability\n4/9 = (2/3)2 . In fact, this solution has even more nice properties, as follows.\nOne might like the simulated X to behave well, when D = 1, whether\nor not E = 1, and similarly for Y .\nSuppose we start with a joint law of X, Y depending on a, b as before.\nLet \u03b7 be a fixed probability. Modify Task 2 as follows: we require not\nonly that given D = 1 = E, the simulated X, Y have the prespecified joint\ndistribution, but also that conditional on D = 1 and E = 0, the simulated\nX has the prespecified marginal distribution, and also that, conditional\non D = 0 and E = 1, the simulated Y has the prespecified marginal\ndistribution, and also that D and E are independent Bernoulli(\u03b7). Another\nway to describe this is by saying that under the simulated joint probability\ndistribution of X, D, Y, E, we have statistical independence between D, E,\nand (X, Y ), with (X, Y ) distributed according to our target distribution\nand D and E Bernoulli(\u03b7), except that we don't care about X on {D = 0}\nnor about Y on {E = 0}\nGisin and Gisin (1999) show that this Variant Task 2 can be achieved for\nour main example Case 1, with \u03b7 = 2/3. It is known from considerations\nof the Clauser\n\u221a and Horne (1974) inequality that it cannot be done with\n\u03b7 > 2/(1 + 2) \u2248 0.828. It seems that the precise boundary is unknown.\nIn fact, for some practical applications, achieving this task is more than\nnecessary. A slightly more modest task is to simulate the joint probability\ndistribution just described, conditionally on the complement of the event\n{D = 0 = E}, i.e. conditional on D = 1 or E = 1. This means to say\nthat we also don't care what is the simulated probability of {D = 0 = E}.\nGisin and Gisin (1999) show that this can be achieved with a variant of the\nsame model, and with success probability 100% (i.e., the simulation never\ngenerates an event {D = 0 = E}), and \u03b7 = 2/3.\nAcknowledgments\nI am grateful for the warm hospitality and support of the Quantum Probability group at the department of mathematics of the University of Greif-\n\n\fOctober 30, 2018\n\n8\n\n3:6\n\nProceedings Trim Size: 9in x 6in\n\nchaoticcham3b\n\nREFERENCES\n\nswald, Germany, during my sabbatical there, Spring 2003. My research\nthere was supported by European Commission grant HPRN-CT-200200279, RTN QP-Applications. This research has also been supported by\nproject RESQ (IST-2001-37559) of the IST-FET programme of the European Commission.\n\nReferences\nL. Accardi, K. Imafuku, and M. Regoli (2002). On the EPR-chameleon\nexperiment. Infinite Dimensional Analysis, Quantum Probability and\nRelated Fields 5, 1\u201320. quant-ph/0112067.\nL. Accardi, K. Imafuku, and M. Regoli (2003). Adaptive dynamical systems\nand the EPR-chameleon experiment. pp. 11\u201336 in: Proc. of \"Foundations\nof Probability and Physics - 2\", Ser. Math. Modelling in Phys., Engin.,\nand Cogn. Sc., vol. 5/2002, V\u00e4xj\u00f6 Univ. Press.\nJ. S. Bell (1964). On the Einstein Podolsky Rosen paradox. Physics 1,\n195\u2013200.\nJ. S. Bell (1981). Bertlmann's socks and the nature of reality. Journal de\nPhysique 42, C2 41\u201361.\nJ. S. Bell (1987). Speakable and Unspeakable in Quantum Theory. Cambridge: Cambridge University Press.\nJ. F. Clauser and M. A. Horne (1974). Experimental consequences of objective local theories. Phys. Rev. D 10, 526\u2013535.\nR. D. Gill (2003). Time, Finite Statistics, and Bell's Fifth Position pp.\n179\u2013206 in: Proc. of \"Foundations of Probability and Physics - 2\", Ser.\nMath. Modelling in Phys., Engin., and Cogn. Sc., vol. 5/2002, V\u00e4xj\u00f6\nUniv. Press. quant-ph/0301059\nN. Gisin and B. Gisin (1999). A local hidden variable model of quantum\ncorrelation exploiting the detection loophole. Phys. Lett. A 260, 323\u2013327.\nquant-ph/09905158.\nK. Hess and W. Philipp (2001a). A possible loophole in the theorem of\nBell. Proc. Nat. Acad. Sci. USA 98, 14224\u201314227. quant-ph/0103028.\nK. Hess and W. Philipp (2001b). Bell's theorem and the problem of decidability between the views of Einstein and Bohr. Proc. Nat. Acad. Sci.\nUSA 98, 14228\u201314233. quant-ph/0103028.\nK. Hess and W. Philipp (2004). Breakdown of Bell's theorem for certain\nobjective local parameter spaces. Proc. Nat. Acad. Sci. USA 101, 1799\u2013\n1805. quant-ph/0103028.\nA. F. Kracklauer (2002). Is 'entanglement' always entangled? J. Opt. B:\n\n\fOctober 30, 2018\n\n3:6\n\nProceedings Trim Size: 9in x 6in\n\nchaoticcham3b\n\nREFERENCES\n\n9\n\nQuantum Semiclass. Opt. 4, S121\u2013S126. quant-ph/0108057.\nJ.-\u00c5.-Larsson and R.D. Gill (2003). Bell's inequality and the coincidencetime loophole. To appear in Europhysics Letters. quant-ph/0312035.\nS. Massar, D. Bacon, N. Cerf and R. Cleve (2001). Classical simulation of\nquantum entanglement without local hidden variables. Phys. Rev. A 63,\n052305 (9pp.). quant-ph/0009088.\nP. Pearle (1970). Hidden-variable example based upon data rejection. Phys.\nRev. D 2, 1418\u20131425.\nB. C. Sanctuary (2003). Quantum correlations between separated particles.\nquant-ph/0304186.\nC. H. Thompson and H. Holstein (2002). The \"Chaotic Ball\" model: local\nrealism and the Bell test \"detection loophole\". quant-ph/0210150.\n\n\f"}