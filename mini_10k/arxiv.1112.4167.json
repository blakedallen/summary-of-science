{"id": "http://arxiv.org/abs/1112.4167v1", "guidislink": true, "updated": "2011-12-18T16:14:15Z", "updated_parsed": [2011, 12, 18, 16, 14, 15, 6, 352, 0], "published": "2011-12-18T16:14:15Z", "published_parsed": [2011, 12, 18, 16, 14, 15, 6, 352, 0], "title": "Iterative Deterministic Equivalents for the Performance Analysis of\n  Communication Systems", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1112.0551%2C1112.5652%2C1112.5834%2C1112.0511%2C1112.0242%2C1112.2147%2C1112.2459%2C1112.1755%2C1112.2486%2C1112.0046%2C1112.1405%2C1112.5330%2C1112.0445%2C1112.1225%2C1112.1157%2C1112.4127%2C1112.0140%2C1112.1531%2C1112.2084%2C1112.4925%2C1112.0240%2C1112.1957%2C1112.1517%2C1112.2136%2C1112.3218%2C1112.0762%2C1112.4336%2C1112.5209%2C1112.5877%2C1112.5884%2C1112.2644%2C1112.3092%2C1112.3999%2C1112.3396%2C1112.6063%2C1112.4806%2C1112.3279%2C1112.5362%2C1112.0842%2C1112.1784%2C1112.0355%2C1112.5990%2C1112.1871%2C1112.3155%2C1112.1879%2C1112.4081%2C1112.1195%2C1112.2091%2C1112.1996%2C1112.4767%2C1112.4396%2C1112.3445%2C1112.0481%2C1112.0550%2C1112.5005%2C1112.1473%2C1112.4574%2C1112.6038%2C1112.3736%2C1112.1741%2C1112.1305%2C1112.6009%2C1112.2986%2C1112.1448%2C1112.0314%2C1112.3183%2C1112.5481%2C1112.0847%2C1112.6015%2C1112.3896%2C1112.3648%2C1112.3667%2C1112.6222%2C1112.4736%2C1112.0144%2C1112.4133%2C1112.4167%2C1112.2098%2C1112.1699%2C1112.2747%2C1112.0250%2C1112.2184%2C1112.6189%2C1112.2674%2C1112.3345%2C1112.0066%2C1112.0764%2C1112.5497%2C1112.0761%2C1112.3675%2C1112.4202%2C1112.0121%2C1112.5798%2C1112.3217%2C1112.5255%2C1112.5777%2C1112.5729%2C1112.4416%2C1112.4295%2C1112.3465%2C1112.0071&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Iterative Deterministic Equivalents for the Performance Analysis of\n  Communication Systems"}, "summary": "In this article, we introduce iterative deterministic equivalents as a novel\ntechnique for the performance analysis of communication systems whose channels\nare modeled by complex combinations of independent random matrices. This\ntechnique extends the deterministic equivalent approach for the study of\nfunctionals of large random matrices to a broader class of random matrix models\nwhich naturally arise as channel models in wireless communications. We present\ntwo specific applications: First, we consider a multi-hop amplify-and-forward\n(AF) MIMO relay channel with noise at each stage and derive deterministic\napproximations of the mutual information after the Kth hop. Second, we study a\nMIMO multiple access channel (MAC) where the channel between each transmitter\nand the receiver is represented by the double-scattering channel model. We\nprovide deterministic approximations of the mutual information, the\nsignal-to-interference-plus-noise ratio (SINR) and sum-rate with\nminimum-mean-square-error (MMSE) detection and derive the asymptotically\noptimal precoding matrices. In both scenarios, the approximations can be\ncomputed by simple and provably converging fixed-point algorithms and are shown\nto be almost surely tight in the limit when the number of antennas at each node\ngrows infinitely large. Simulations suggest that the approximations are\naccurate for realistic system dimensions. The technique of iterative\ndeterministic equivalents can be easily extended to other channel models of\ninterest and is, therefore, also a new contribution to the field of random\nmatrix theory.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1112.0551%2C1112.5652%2C1112.5834%2C1112.0511%2C1112.0242%2C1112.2147%2C1112.2459%2C1112.1755%2C1112.2486%2C1112.0046%2C1112.1405%2C1112.5330%2C1112.0445%2C1112.1225%2C1112.1157%2C1112.4127%2C1112.0140%2C1112.1531%2C1112.2084%2C1112.4925%2C1112.0240%2C1112.1957%2C1112.1517%2C1112.2136%2C1112.3218%2C1112.0762%2C1112.4336%2C1112.5209%2C1112.5877%2C1112.5884%2C1112.2644%2C1112.3092%2C1112.3999%2C1112.3396%2C1112.6063%2C1112.4806%2C1112.3279%2C1112.5362%2C1112.0842%2C1112.1784%2C1112.0355%2C1112.5990%2C1112.1871%2C1112.3155%2C1112.1879%2C1112.4081%2C1112.1195%2C1112.2091%2C1112.1996%2C1112.4767%2C1112.4396%2C1112.3445%2C1112.0481%2C1112.0550%2C1112.5005%2C1112.1473%2C1112.4574%2C1112.6038%2C1112.3736%2C1112.1741%2C1112.1305%2C1112.6009%2C1112.2986%2C1112.1448%2C1112.0314%2C1112.3183%2C1112.5481%2C1112.0847%2C1112.6015%2C1112.3896%2C1112.3648%2C1112.3667%2C1112.6222%2C1112.4736%2C1112.0144%2C1112.4133%2C1112.4167%2C1112.2098%2C1112.1699%2C1112.2747%2C1112.0250%2C1112.2184%2C1112.6189%2C1112.2674%2C1112.3345%2C1112.0066%2C1112.0764%2C1112.5497%2C1112.0761%2C1112.3675%2C1112.4202%2C1112.0121%2C1112.5798%2C1112.3217%2C1112.5255%2C1112.5777%2C1112.5729%2C1112.4416%2C1112.4295%2C1112.3465%2C1112.0071&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this article, we introduce iterative deterministic equivalents as a novel\ntechnique for the performance analysis of communication systems whose channels\nare modeled by complex combinations of independent random matrices. This\ntechnique extends the deterministic equivalent approach for the study of\nfunctionals of large random matrices to a broader class of random matrix models\nwhich naturally arise as channel models in wireless communications. We present\ntwo specific applications: First, we consider a multi-hop amplify-and-forward\n(AF) MIMO relay channel with noise at each stage and derive deterministic\napproximations of the mutual information after the Kth hop. Second, we study a\nMIMO multiple access channel (MAC) where the channel between each transmitter\nand the receiver is represented by the double-scattering channel model. We\nprovide deterministic approximations of the mutual information, the\nsignal-to-interference-plus-noise ratio (SINR) and sum-rate with\nminimum-mean-square-error (MMSE) detection and derive the asymptotically\noptimal precoding matrices. In both scenarios, the approximations can be\ncomputed by simple and provably converging fixed-point algorithms and are shown\nto be almost surely tight in the limit when the number of antennas at each node\ngrows infinitely large. Simulations suggest that the approximations are\naccurate for realistic system dimensions. The technique of iterative\ndeterministic equivalents can be easily extended to other channel models of\ninterest and is, therefore, also a new contribution to the field of random\nmatrix theory."}, "authors": ["Jakob Hoydis", "Romain Couillet", "Merouane Debbah"], "author_detail": {"name": "Merouane Debbah"}, "author": "Merouane Debbah", "arxiv_comment": "submitted to the IEEE Transactions on Information Theory, 43 pages, 4\n  figures", "links": [{"href": "http://arxiv.org/abs/1112.4167v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1112.4167v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1112.4167v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1112.4167v1", "journal_reference": null, "doi": null, "fulltext": "1\n\nIterative Deterministic Equivalents for the\nPerformance Analysis of Communication\nSystems\narXiv:1112.4167v1 [cs.IT] 18 Dec 2011\n\nJakob Hoydis?,\u00a7 , Romain Couillet? and M\u00e9rouane Debbah?\n\nAbstract\nIn this article, we introduce iterative deterministic equivalents as a novel technique for the performance analysis of communication systems whose channels are modeled by complex combinations of\nindependent random matrices. This technique extends the deterministic equivalent approach for the study\nof functionals of large random matrices to a broader class of random matrix models which naturally\narise as channel models in wireless communications. We present two specific applications: First, we\nconsider a multi-hop amplify-and-forward (AF) MIMO relay channel with noise at each stage and\nderive deterministic approximations of the mutual information after the Kth hop. Second, we study a\nMIMO multiple access channel (MAC) where the channel between each transmitter and the receiver\nis represented by the double-scattering channel model. We provide deterministic approximations of\nthe mutual information, the signal-to-interference-plus-noise ratio (SINR) and sum-rate with minimummean-square-error (MMSE) detection and derive the asymptotically optimal precoding matrices. In both\nscenarios, the approximations can be computed by simple and provably converging fixed-point algorithms\nand are shown to be almost surely tight in the limit when the number of antennas at each node grows\ninfinitely large. Simulations suggest that the approximations are accurate for realistic system dimensions.\nThe technique of iterative deterministic equivalents can be easily extended to other channel models of\ninterest and is, therefore, also a new contribution to the field of random matrix theory.\n\nParts of this work have been presented at the Asilomar Conference on Signals, Systems, and Computers, CA, US, Nov. 2011.\n?\n\nAlcatel Lucent Chair on Flexible Radio, Sup\u00e9lec, 3 rue Joliot Curie, 91192 Gif sur Yvette, France.\n\n\u00a7\n\nDepartment of Telecommunications, Sup\u00e9lec, 3 rue Joliot Curie, 91192 Gif sur Yvette, France.\n\n{jakob.hoydis,romain.couillet,merouane.debbah}@supelec.fr\n\n\f2\n\nI. I NTRODUCTION\nSince the pioneering work of Tse and Hanly [1] on the capacity of code division multiple access\n(CDMA) technologies assuming long spreading sequences, the theory of large dimensional random\nmatrices (RMT) has drawn an increasing interest from researchers in wireless communications and related\nfields [2], [3]. RMT is in particular convenient for the study of multiple-input multiple-output (MIMO)\nchannels [4], [5], (random) linear precoders [1], [6], [7], multi-user systems [8], [9], multi-cellular systems\n[10], [11], [12], etc. In the early contributions, it was systematically assumed that the dimensions of the\nsystem under study could grow infinitely large and that the system performance admitted a deterministic\nlimit that RMT can provide [1], [4], [13]. It then became rapidly clear that, for most systems of practical\ninterest, either the former assumption is not natural or the latter condition is not met. However, even for\nsystems of large but finite size, the inherently random performance (e.g. instantaneous mutual information,\nsignal-to-interference-plus-noise ratio (SINR)), can often be well approximated by deterministic quantities.\nSuch quantities are called deterministic equivalents, and can be derived by various techniques, such as\nthe Stieltjes transform method [5], [14], the Gaussian method [15], [16], or the replica method [17], [18].\nDeterministic equivalents are convenient to study the performance of wireless communication systems\nwhen a single system parameter can be modeled by a random matrix, e.g. the fading channel or the\nspreading codes. In order to tackle the performance analysis of more complex systems, such as multihop communications, random beamforming over random fading channels, or double-scattering channels,\nit is necessary to extend the notion of deterministic equivalents. In the present article, which is inspired\nby the original idea of [7], where the performance of random isometric precoders over random fading\nchannels is analyzed, we develop a systematic approach to generalize deterministic equivalents to iterative\ndeterministic equivalents. To this end, we introduce a generic definition of deterministic equivalents of\nfunctionals of random matrices, which we extend, based on the Fubini theorem [19], to a definition of\niterative deterministic equivalents.\nAs application examples, we then provide deterministic equivalents of the mutual information of the\nmulti-hop amplify-and-forward (AF) MIMO relay channel [20], [21], [22] (Section III-A) and of the\nergodic capacity as well as the sum-rate with minimum-mean-square-error (MMSE) detection of doublescattering multiple access channels (MACs) [23], [24] (Section III-B). An overview of related research\nto both topics is provided in the respective sections. Our analysis is based on the Stieltjes transform\nmethod, documented in detail in [3].\nThe remainder of this article is structured as follows. In Section II, we recall the fundamentals\n\n\f3\n\nof deterministic equivalents in RMT and develop the notion of iterative deterministic equivalents. In\nSection III, we study applications of iterative deterministic equivalents to the performance analysis of\nmulti-hop relay channels and double-scattering MACs. The paper is concluded with Section IV. All\nproofs, related results, and some exemplary Matlab codes are provided in the appendices.\nNotations: Boldface lower and upper case symbols represent vectors and matrices, respectively. IN\nis the size-N identity matrix and diag(x1 , . . . , xN ) is a diagonal matrix with elements xi . The trace,\ntranspose, and Hermitian transpose operators are denoted by tr (*), (*)T , and (*)H , respectively. The\nspectral norm of a matrix A is denoted by kAk, and, for two matrices A and B, the notation A \u001f B\nmeans that A \u2212 B is positive-definite. For a vector x = [x1 . . . xN ]T , x \u2265 0 denotes xi \u2265 0 for all i.\na.s.\n\nThe notations \u21d2 and \u2212\u2192 denote weak and almost sure convergence, respectively. We use CN (m, R)\nto denote the circular symmetric complex Gaussian distribution with mean m and covariance matrix R.\n\u221a\nWe denote by R+ the set [0, \u221e), by R\u2212 the set (\u2212\u221e, 0], and by i = \u22121. 1A (x) is the indicator\nfunction, i.e.,\n\n1A (x) = 1 iff x \u2208 A and 1A (x) = 0 otherwise. E [*] denotes the expectation operator. For\n\n(an )n\u22651 and (bn )n\u22651 two sequences of random variables, we denote an \u0010 bn the equivalence relation\na.s.\n\nan \u2212 bn \u2212\u2192 0 for n \u2192 \u221e.\n\nII. I TERATIVE DETERMINISTIC EQUIVALENTS\nIn this section, we will first recall the notion of deterministic equivalents in probability theory before we\nexplain their connections to RMT and the performance analysis of communication systems. We will then\nintroduce the Fubini theorem, which is the key ingredient to extend classical deterministic equivalents to\niterative deterministic equivalents.\nA. Deterministic equivalents and random matrices\nDefinition 1: Consider the probability space (\u03a9, F, P ). Let (fn )n\u22651 be a series of measurable complexvalued functions, fn : \u03a9 \u00d7 C \u2192 C, and let (gn )n\u22651 be a series of complex-valued functions, gn : C \u2192 C.\nThen (gn )n\u22651 is a deterministic equivalent of (fn )n\u22651 on D \u2282 C, if there exists a set A \u2282 \u03a9 with\nP (A) = 1, such that\nfn (\u03c9, z) \u2212 gn (z) \u2212\u2212\u2212\u2192 0\nn\u2192\u221e\n\nfor all \u03c9 \u2208 A and for all z \u2208 D.\nOtherwise stated, a deterministic equivalent for (fn )n\u22651 is a series (gn )n\u22651 such that gn (z) approximates fn (\u03c9, z) arbitrarily closely as n grows, for every z \u2208 D and almost every \u03c9 . In particular, if\n\n\f4\n\n(fn )n\u22651 converges almost surely to a limiting function f , i.e., for all (\u03c9, z) \u2208 A \u00d7 D with A \u2282 \u03a9,\nP (A) = 1 and D \u2282 C, we have\nfn (\u03c9, z) \u2212\u2212\u2212\u2192 f (z)\nn\u2192\u221e\n\n(1)\n\nthen (gn )n\u22651 defined by gn = f , for all n, is also a deterministic equivalent of (fn )n\u22651 . In many cases,\nR\none can further show that \u03a9 fn (\u03c9, z)dP (\u03c9) \u2212 gn (z) \u2212\u2212\u2212\u2192 0. Thus gn is also an approximation of the\nn\u2192\u221e\n\nexpected value of fn .\nIn the context of large dimensional random matrix theory, one often considers random matrices Hn \u2208\nC\n\nN \u00d7n\n\nof growing dimensions N, n \u2192 \u221e, where in general N/n = cn is such that\n0 < lim inf cn \u2264 lim sup cn < \u221e.\nn\n\n(2)\n\nn\n\nThis simply states that cn is bounded so that the ratio N/n of the matrix dimensions is never too close\nto zero or infinity. Formally, to be in line with Definition 1, we will define random matrices in the\nfollowing as series (Hn )n\u22651 = (Hn (\u03c9))n\u22651 of matrices with growing dimensions which are defined on\na probability space (\u03a9, F, P ), where every \u03c9 \u2208 \u03a9 generates the whole sequence (Hn (\u03c9))n\u22651 and not\nonly a single matrix Hn (\u03c9).\nIn wireless communications, one is often interested in the behavior of functionals fn (Hn , z), where\nHn \u2208 CN \u00d7n is a matrix describing the input-output relation of a wireless channel. In particular,\nfn (Hn , z) =\n\n1\nN\n\n+\nlog det(IN + zHn HH\nn ), z \u2208 R , is the (normalized) mutual information of the MIMO\n\nchannel Hn between an n-antenna transmitter and an N -antenna receiver at signal-to-noise ratio (SNR)\nz . Other quantities of interest are the SINR with linear detectors or precoders and the associated rates.\n\nThe goal of a large system analysis based on RMT is to provide deterministic approximations of these\nrandom quantities, which become arbitrarily tight as the system dimensions grow. Thus, deterministic\nequivalents provide a deterministic abstraction of the physical layer. This is particularly interesting for\ncomplex channel models which are intractable by exact analysis.\nDeterministic equivalents for functionals of large dimensional random matrices have been considered\nfor a wide range of communication channel models. For instance, in [5], a deterministic equivalent for\nthe ergodic mutual information of the Rician fading channel model Hn = Xn + An is provided, where\n2 , and\nXn \u2208 CN \u00d7n has independent entries with zero mean and a variance profile E[|(Xn )ij |2 ] = \u03c3n,ij\n\nAn \u2208 CN \u00d7n is a deterministic matrix. In [25], the deterministic equivalent of [5] is used to determine\n\nan asymptotically tight approximation of the ergodic capacity achieving input covariance matrix for the\nMIMO Rician fading channel. Deterministic equivalents were then extended to broader classes of wireless\nchannel models, such as the capacity of the frequency-selective MIMO channel [15], the MIMO MAC\n\n\f5\n\nwith Kronecker correlation [14] and the sum rate capacity of linearly precoded broadcast channels under\nimperfect channel state information [9]. The application of such techniques is therefore very broad as it\ncan simplify the difficult study of communication channels with a various number of random parameters\n(random channels, unitary precoders, path loss, etc.). Moreover, deterministic equivalents can be used to\ncompute approximate solutions of otherwise intractable optimization problems [12], [9], [25].\nAll of the works mentioned above consider deterministic equivalents for random matrix models created\nfrom sums of independent random matrices. In many cases of practical interest, it is however necessary\nto consider more complex combinations of matrices, such as products or sums of products. These include\nfor example the multi-hop relay channel (Section III-A) as well as the double-scattering channel model\n[23] (Section III-B). Another recent example is [7], which considers random beamforming over fading\nchannels, i.e., both the precoding and the channel matrices are assumed to be random. In this work,\nthe authors derive deterministic equivalents of the mutual information and of the SINR with MMSE\ndetection with respect to the random precoding matrices for quasi-static channels. Then, a second set of\ndeterministic equivalents is found, treating both precoders and channel matrices as random. This technique\nrelies on a fundamental result of probability theory, the Fubini theorem. In this article, we explain this\napproach in detail and generalize it to the new notion of iterative deterministic equivalents.\nB. The Fubini theorem\nTheorem 1 ([19]): Let (\u03a9, F, P ) and (\u03a90 , F 0 , P 0 ) be two probability spaces. Denote (\u03a9\u00d7\u03a90 , F \u00d7F 0 , Q)\ntheir product space. Let f : \u03a9 \u00d7 \u03a90 \u2192 R be (F \u00d7 F 0 )-integrable. Then\n\u0015\nZ\nZ \u0014Z\n0\n0\n0\n0 0\nf (\u03c9, \u03c9 )dQ(\u03c9, \u03c9 ) =\nf (\u03c9, \u03c9 )dP (\u03c9 ) dP (\u03c9)\n\u03a9\u00d7\u03a90\n\u03a9\n\u03a90\n\u0015\nZ \u0014Z\n0\n=\nf (\u03c9, \u03c9 )dP (\u03c9) dP 0 (\u03c9 0 ).\n\u03a90\n\n\u03a9\n\nIn particular, consider a set A \u2208 F \u00d7 F 0 . Then, we have from Theorem 1 that\nZ\nQ(A) =\n1A (\u03c9, \u03c9 0 )dQ(\u03c9, \u03c9 0 )\n0\n\u03a9\u00d7\u03a9\n\u0015\nZ \u0014Z\n=\n1A (\u03c9, \u03c9 0 )dP (\u03c9) dP 0 (\u03c90 ).\n\u03a90\n\n(3)\n\n\u03a9\n\nEquation (3) is the core ingredient for the definition of iterative deterministic equivalents: Let (Hn (\u03c9))n\u22651\nand (H0n (\u03c9 0 ))n\u22651 be two series of random matrices generated by the spaces (\u03a9, F, P ) and (\u03a90 , F 0 , P 0 ),\nrespectively. As in Theorem 1, call Q the product-space measure. Let fn ((Hn (\u03c9), H0n (\u03c9 0 )), z) be a\n\n\f6\n\nfunctional of the matrices Hn (\u03c9) and H0n (\u03c9 0 ). Assume that there is a function g\u0303n (Hn (\u03c9), z), such that,\nfor each \u03c9 \u2208 A \u2282 \u03a9 with P (A) = 1, there exists a subset B(\u03c9) \u2282 \u03a90 with P 0 (B(\u03c9)) = 1, on which\nfn ((Hn (\u03c9), H0n (\u03c9 0 )), z) \u2212 g\u0303n (Hn (\u03c9), z) \u2192 0.\n\n(4)\n\nAlthough g\u0303n (Hn (\u03c9), z) is a random function (as it depends on \u03c9 ), it is independent of H0n (\u03c9 0 ). Thus, we\ncan see g\u0303n (Hn (\u03c9), z) as a deterministic equivalent of fn ((Hn (\u03c9), H0n (\u03c9 0 )), z) with respect to (H0n (\u03c9 0 ))n\u22651 .\nNow, let us assume that there is a second function gn (z), such that for \u03c9 \u2208 C \u2282 \u03a9 with P (C) = 1,\ng\u0303n (Hn (\u03c9), z) \u2212 gn (z) \u2192 0.\n\n(5)\n\nCall D = {(\u03c9, \u03c9 0 ) : \u03c9 \u2208 A\u2229C , \u03c9 0 \u2208 B(\u03c9)} \u2282 \u03a9\u00d7\u03a90 , the space on which fn ((Hn , H0n ), z)\u2212gn (z) \u2192 0.\nThen, from (3), this space has probability\nZ \u0014Z\nQ(D) =\n\u03a9\n\nZ\n(a)\n\u2265\n\n\u0015\n1D (\u03c9, \u03c9 )dP (\u03c9 ) dP (\u03c9)\n\u03a90\n\"Z\n#\n\nA\u2229C\n(b)\n\n0\n\nB(\u03c9)\n\n0\n\n0\n\n1D (\u03c9, \u03c9 0 )dP 0 (\u03c90 ) dP (\u03c9)\n\nZ\n\n=\n\ndP (\u03c9)\nA\u2229C\n\n(c)\n\n=1\n\n(6)\n\nwhere (a) is due to A \u2229 B \u2282 \u03a9 and B(\u03c9) \u2282 \u03a90 , (b) follows since P 0 (B(\u03c9)) = 1 for \u03c9 \u2208 A and (c)\nholds since P (A \u2229 C) = P (A) + P (C) \u2212 P (A \u222a C) = 1.\nTo summarize, if a deterministic equivalent gn exists for a functional fn of a random series (H0n )n\u22651\nand a deterministic series (Hn )n\u22651 of matrices, and if additionally it can be proved that this deterministic\nequivalent holds true for almost every such (Hn )n\u22651 generated by a space \u03a9, then the latter is also a\ndeterministic equivalent for the random series ((Hn , H0n ))n\u22651 .\nThis is the mathematical key idea behind our method to derive iterative deterministic equivalents of\nfunctionals fn ((Hn (\u03c9), H0n (\u03c9 0 )), z), of two (or more) random matrices. First, one considers one of the\nsequences of random matrices, e.g. (Hn (\u03c9))n\u22651 , to be deterministic and derives a deterministic equivalent\nwith respect to (H0n (\u03c9 0 ))n\u22651 . In the example above, this was the role of the functional g\u0303n (Hn (\u03c9), z)\nwhich is independent of H0n (\u03c9 0 ). In a second step, one assumes the matrices (Hn (\u03c9))n\u22651 to be random\nand derives an iterative deterministic equivalent gn (z) of g\u0303n (Hn (\u03c9), z). Of course, this procedure can be\ncarried out for any finite number of random matrices where in each step the \"randomness\" related to one\nof the matrices is removed. From the above construction, we will call (gn )n\u22651 an iterative deterministic\nequivalent.\n\n\f7\n\nFig. 1.\n\nMulti-hop amplify-and-forward MIMO relay channel.\n\nIn the next section, we present two specific examples of iterative deterministic equivalents with\napplications to the capacity of multi-hop MIMO relay and double-scattering channels. From now on, all\nmatrices and vectors should be understood as sequences of matrices and vectors with growing dimensions.\nFor notational convenience, we drop the index n, e.g. we write H instead of (Hn )n\u22651 .\nIII. A PPLICATIONS\nA. Multi-hop relay channel\nConsider a multi-hop AF MIMO relay channel where a source node communicates via K \u2212 1 relays\nwith a destination node. There is no direct link between the source and the destination and each relay can\nonly receive data from the preceding hop. This is for example the case if the nodes follow a time-division\nmultiple-access (TDMA) protocol where only one node is transmitting at any given time and the path\nloss between relay k and k \u2212 2 is large. Thus each data symbol reaches the destination after K channel\nuses. The source and destination are respectively equipped with n and nK antennas while the k th relay\nhas nk antennas. The relays operate an AF-protocol where each node simply transmits a scaled version\nof its received signal to the next hop. We will consider a large system limit where n, n1 , . . . , nK grow\ninfinitely large at the same speed. Define the following quantities:\nn\nn1\nnk\u22121\nck =\n,\nnk\nc1 =\n\nk = 2, . . . , K.\n\n(7)\n\nThe notation \"n \u2192 \u221e\" must be understood from now on as n \u2192 \u221e, such that 0 < lim inf n ck \u2264\nlim supn ck < \u221e for all k . We denote yk \u2208 Cnk the received base-band signal vector at the k th hop,\n\n\f8\n\ngiven by\ny1 =\nyk =\n\n\u221a\n\u221a\n\nr\n\n\u03b20\nx + n1\nn\n\ns\n\n\u03b2k\u22121\nyk\u22121 + nk ,\nnk\u22121\n\n\u03b11 H1\n\u03b1k Hk\n\n(8)\n\nk = 2, . . . , K\n\nwhere Hk \u2208 Cnk \u00d7nk\u22121 is a standard complex Gaussian matrix1 (let n0 = n), x \u223c CN (0, In ) is the\n4\n\nchannel input vector, nk \u223c CN (0, Ink ) is a noise vector, \u03b1k is a path loss factor, and the parameter \u03b2k\nis chosen to normalize the transmit power of the k th node according to its power budget \u03c1k > 0, i.e.,\n\u03b20 =\n\u03b2k =\n\n\u03c10\n1\nH\nn tr E [xx ]\n\n= \u03c10\n\n\u03c1k\n\u0002\n\u0003,\nyk ykH\n\n1\nnk tr E\n\n(9)\n\nk = 1, . . . , K \u2212 1.\n\nThe expectation in the last equation is with respect to the transmit and noise vectors only.2 The channel\nmatrices Hk and path loss factors \u03b1k are assumed to be known to the relays and the destination. Since the\nreceived signal at each relay is corrupted by noise, the system suffers from noise accumulation. This is\nin addition to the linear rate loss\n\n1\nK\n\nrelated to the TDMA protocol. Thus, the capacity decreases quickly\n\nwith the number of hops K . Note that our system model is different from existing works which consider\neither no noise [26], or noise only at the destination [22]. An exception is [27], in which the authors\nconsider a similar system model, but do not provide closed-form expressions of the asymptotic mutual\ninformation. Several other works deal with the asymptotic capacity of the dual-hop relay channel [28],\n[29]. Recently, an exact expression of the mutual information of the dual-hop channel for finite channel\ndimensions was derived in [30]. Here, we will provide an explicit deterministic equivalent of the mutual\ninformation at each relay for the general model (8).\n\u0001\nLet us introduce the following, recursively defined matrices Rk \u03b2 k\u22121 :\nh\ni\nR0 = E xxH = In\nh\ni\n\u0001\n\u0001\n\u03b1k \u03b2k\u22121\nRk \u03b2 k\u22121 = E yk ykH = Ink +\nHk Rk\u22121 \u03b2 k\u22122 HH\nk,\nnk\u22121\n\u0001\nand the functionals Jk x, \u03b2 k\u22121 , x > 0, which are defined as\n\u0012\n\u0013\n\u0001\n\u0001\n\u03b1k \u03b2k\u22121\n1\nJk x, \u03b2 k\u22121 =\nlog det Ink + x\nHk Rk\u22121 \u03b2 k\u22122 HH\nk ,\nnk\nnk\u22121\n1\n2\n\nk = 1, . . . , K\n\nk = 1, . . . , K\n\n(10)\n\n(11)\n\nA standard complex Gaussian matrix X has i.i.d. elements Xij \u223c CN (0, 1).\nUnder a long-term power constraint, the expectation could be taken also with respect to the matrices Hk . Asymptotically,\n\nboth constraints are equivalent (see Lemma 1).\n\n\f9\n\nwhere \u03b2 k = [\u03b20 , * * * , \u03b2k ]. With these definitions, we can express the normalized mutual information\nIk (\u03b2 k\u22121 ) between yk and x as\nIk (\u03b2 k\u22121 ) =\n\n\u0001\n1\nJk (1, \u03b2 k\u22121 ) \u2212 Jk (1, \u03b2 0k\u22121 )\nK\n\n(12)\n\nwhere \u03b2 0k = [0, \u03b21 , * * * , \u03b2k ]. Next, we demonstrate by a simple example that (12) holds.\nExample 1 (2-hop Relay-channel): The normalized mutual information I2 (\u03b2 1 ) between x and the\nchannel output after the second hop y2 is given as\n!\n\u0012\n\u0013\u22121\n1\n\u03b12 \u03b21\n\u03b12 \u03b21 \u03b11 \u03b20\nH\nH H\nI2 (\u03b2 1 ) =\nlog det In2 + In2 +\nH2 H2\nH2 H1 H1 H2\nKn2\nn1\nn1 n\n\u0012\n\u0012\n\u0013\n\u0013\n\u0012\n\u0013\n\u03b12 \u03b21\n\u03b11 \u03b2 0\n\u03b12 \u03b21\n1\n1\nH\nH\nH\nlog det In2 +\nH2 In +\nH1 H1 H2 \u2212\nlog det In2 +\nH2 H2\n=\nKn2\nn1\nn\nKn2\nn1\n\u0012\n\u0013\n\u0012\n\u0013\n1\n\u03b12 \u03b21\n1\n\u03b12 \u03b2 1\nH\nH\nlog det In2 +\nH2 R1 (\u03b20 )H2 \u2212\nlog det In2 +\nH2 R1 (0)H2\n=\nKn2\nn1\nKn2\nn1\n\u0001\n1\n(13)\n=\nJ2 (1, \u03b2 1 ) \u2212 J2 (1, \u03b2 01 ) .\nK\nIn the following, we will derive deterministic equivalents \u012ak (\u03b2\u0304 k\u22121 ) of Ik (\u03b2 k\u22121 ). It will turn out that\nthe recursive definition of the matrices Rk (\u03b2 k\u22121 ) in (10) allows us to calculate iterative deterministic\nequivalents of the mutual information after each hop. This is achieved by treating the matrix Rk\u22121 (\u03b2 k\u22122 )\nas deterministic and deriving a deterministic equivalent of JK (x, \u03b2 k\u22121 ) with respect to the matrix Hk .\nThis process can be iterated for Rk\u22122 (\u03b2 k\u22123 ), Rk\u22123 (\u03b2 k\u22124 ), . . . and Hk\u22121 , Hk\u22122 , . . . until the deterministic matrix R0 is reached. Before we address this problem, we will derive deterministic equivalents \u03b2\u0304k\nof the power normalization factors \u03b2k :\nLemma 1 (Asymptotic power normalization): Let \u03b20 = \u03b2\u03040 = \u03c10 . Then,\na.s.\n\n\u03b2k \u2212\u2212\u2212\u2192 \u03b2\u0304k =\nn\u2192\u221e\n\nProof: Recall the definition of \u03b2k =\n\n\u03c1k\n,\n1 + \u03b1k \u03c1k\u22121\n\nk = 1, . . . , K \u2212 1.\n\n\u03c1k\n1\nnk\n\n\u0001\n,\nwhere\nR\n=\nR\n\u03b2\n. For k \u2265 1, we have\nk\nk\nk\u22121\ntr Rk\n\n1\n\u03b1k \u03b2k\u22121\ntr Rk = 1 +\ntr Hk Rk\u22121 HH\nk\nnk\nnk nk\u22121\nnk\n1 X\n1\n(a)\nh\u0303H Rk\u22121 h\u0303k,j\n= 1 + \u03b1k \u03b2k\u22121\nnk\nnk\u22121 k,j\nj=1\n\n(b)\n\n\u0010 1 + \u03b1k\n\n\u03c1k\u22121\n1\ntr Rk\u22121\nn\nnk\u22121 tr Rk\u22121 k\u22121\n1\n\n= 1 + \u03b1k \u03c1k\u22121\n\n(14)\n\n\f10\n\nwhere (a) is obtained by denoting h\u0303k,j \u2208 Cnk\u22121 the j th row vector of Hk and (b) is due to Lemma 2\nand Lemma 6 in Appendix A and the definition of \u03b2k\u22121 . By the continuous mapping theorem [31], we\nfinally have\n\u03b2k =\n\n\u03c1k\na.s.\n\u2212\u2212\u2212\u2192\n1\nn\u2192\u221e\nnk tr Rk\n\n\u03c1k\n.\n1 + \u03b1k \u03c1k\u22121\n\n(15)\n\nIn the next theorem, we will build upon Lemma 1, and provide deterministic equivalents of Jk (x, \u03b2 k ).\nTheorem 2: For k \u2208 {1, . . . , K}, let \u03b2 k\u22121 = [\u03b20 * * * \u03b2k\u22121 ] \u2265 0 be a sequence of random vectors,\na.s.\n\nindexed by n, and \u03b2\u0304 k\u22121 = [\u03b2\u03040 * * * \u03b2\u0304k\u22121 ] \u2265 0 be deterministic, such that \u03b2i \u2212\u2212\u2212\u2192 \u03b2\u0304i for i = 0, . . . , k \u2212 1.\nn\u2192\u221e\n\nThen,\n\u0001\n\u0001 a.s.\nJk x, \u03b2 k\u22121 \u2212 J \u0304k x, \u03b2\u0304 k\u22121 \u2212\u2212\u2212\u2192 0\nn\u2192\u221e\n\nwhere J \u0304k x, \u03b2\u0304 k\u22121 is recursively defined for k \u2265 2 as\n\u0001\n\n!\n!\nx\u03b1\n\u03b2\u0304\nx\u03b1\n\u03b2\nk\nk\u22121\nk\nk\u22121\n\u0001 , \u03b2\u0304 k\u22121 + ck log 1 +\n\u0001\nJ \u0304k x, \u03b2\u0304 k\u22121 = ck J \u0304k\u22121\nck + x\u03b1k \u03b2\u0304k\u22121 + \u0113k\u22121 x, \u03b2\u0304 k\u22121\nck + \u0113k\u22121 x, \u03b2\u0304 k\u22121\n\u0001!\n\u0001\n\u0113k\u22121 x, \u03b2\u0304 k\u22121\n\u0113k\u22121 x, \u03b2\u0304 k\u22121\n\u0001\n\u2212\n+ log 1 +\nck\nck + \u0113k\u22121 x, \u03b2\u0304 k\u22121\n\u0001\n\u0001\nand \u0113k x, \u03b2\u0304 k for k \u2265 0 is given by Theorem 3. The initial value J \u03041 x, \u03b2\u03040 is given in closed form:\n!\n\u0001!\n\u0001\n\u0001\n\u0113\nx,\n\u03b2\u0304\n\u0113\nx,\n\u03b2\u0304\nx\u03b1\n\u03b2\u0304\n0\n0\n0\n0\n1\n0\n\u0001 + log 1 +\n\u0001.\nJ \u03041 x, \u03b2\u03040 = c1 log 1 +\n\u2212\nc1\nc1 + \u01130 x, \u03b2\u03040\nc1 + \u01130 x, \u03b2\u03040\n\u0001\n\nProof: The proof is provided in Appendix B.\nTheorem 2 allows us to compute the quantities J \u0304k (x, \u03b2\u0304 k\u22121 ) recursively for any desired relay node\n\u0001\nk . The values of \u0113k\u22121 x, \u03b2\u0304 k\u22121 , needed at each stage, can also be calculated in a recursive manner as\nshown in the next theorem.\nTheorem 3: For k \u2208 {1, . . . , K \u2212 1}, let \u03b2 k = [\u03b20 * * * \u03b2k ] \u2265 0 be a sequence of random vectors,\na.s.\n\nindexed by n, and \u03b2\u0304 k = [\u03b2\u03040 * * * \u03b2\u0304k ] \u2265 0 be deterministic, such that \u03b2i \u2212\u2212\u2212\u2192 \u03b2\u0304i for i = 0, . . . , k . Let\nn\u2192\u221e\n\u0010\n\u0011\u22121\n\u0001 H\n1\n1\n. Then,\nx > 0 and denote by mk (x, \u03b2 k ) = nk+1 tr \u03b1k+1 \u03b2k nk Hk+1 Rk \u03b2 k\u22121 Hk+1 + x1 Ink+1\n\u0001 a.s.\nmk (x, \u03b2 k ) \u2212 m\u0304k x, \u03b2\u0304 k \u2212\u2212\u2212\u2192 0\nn\u2192\u221e\n\n\f11\n\n\u0001\nwhere m\u0304k x, \u03b2\u0304 k is recursively defined for k \u2265 1 as\n\u0001\nm\u0304k x, \u03b2\u0304 k =\n\nxck+1\n\u0001\nck+1 + \u0113k x, \u03b2\u0304 k\n\n\u0001\nand \u0113k x, \u03b2\u0304 k is given as the unique positive solution to the following fixed point equation\n\u0001\n\u0001\u0001\n\u0113k x, \u03b2\u0304 k = ck+1 ck+1 + \u0113k x, \u03b2\u0304 k\nck+1 ck+1 + \u0113k x, \u03b2\u0304 k\n\u2212\nx\u03b1k+1 \u03b2\u0304k\n\n\u0001\u00012\nm\u0304k\u22121\n\nx\u03b1k+1 \u03b2\u0304k\n\u0001 , \u03b2\u0304 k\u22121\nck+1 + x\u03b1k+1 \u03b2\u0304k + \u0113k x, \u03b2\u0304 k\n\n!\n.\n\nThe initial values m\u03040 (x, \u03b2\u03040 ) and \u01130 (x, \u03b2\u03040 ) are given in closed form:\nm\u03040 (x, \u03b2\u03040 ) =\n\nc1\n\u03b11 \u03b2\u03040\nc1 +\u01130 (x,\u03b2\u03040 )\n\n+\n\n1\nx\n\n+ (1 \u2212 c1 )x\n\nq\n\u01130 x, \u03b2\u03040\n\n\u0001\n\nx\u03b11 \u03b2\u03040 (1 \u2212 c1 ) + c1\n+\n=\u2212\n2\n\nx\u03b11 \u03b2\u03040 (1 \u2212 c1 ) + c1\n\n\u00012\n\n+ 4x\u03b11 \u03b2\u03040 c21\n\n2\n\n.\n\nProof: The proof is provided in Appendix C.\nRemark 3.1: The quantity mk (x, \u03b2 k ) can be seen as the Stieltjes transform [3] of the empirical\n1\nspectral distribution (e.s.d.) of the matrix \u03b1k+1 \u03b2k n1k Hk+1 Rk (\u03b2 k\u22121 )HH\nk+1 evaluated at \u2212 x . One can\n\nfurther show that Theorem 3 implies the weak convergence of the e.s.d. \u03b1k+1 \u03b2k n1k Hk+1 Rk (\u03b2 k\u22121 )HH\nk+1\nto a distribution function, whose Stieltjes transform is given by m\u0304k , for almost every H1 , . . . , HK .\nApplying Theorem 2 and Lemma 1 to (12) yields the following corollary which provides a deterministic\nequivalent of the mutual information Ik (\u03b2 k\u22121 ):\nCorollary 1 (Asymptotic mutual information of the K -hop AF MIMO Relay channel):\n\u0001\n\u0001 a.s\nIk \u03b2 k\u22121 \u2212 \u012ak \u03b2\u0304 k\u22121 \u2212\u2212\u2212\u2192 0\nn\u2192\u221e\n\nk = 1, . . . , K\n\nwhere\n\u0011\n\u0001\n1 \u0010 \u0304\n0\n\u012ak \u03b2\u0304 k\u22121 =\nJk (1, \u03b2\u0304 k\u22121 ) \u2212 J \u0304k (1, \u03b2\u0304 k\u22121 )\nK\n0\n\n0\n\nwith \u03b2\u0304 k\u22121 = [\u03b2\u03040 * * * \u03b2\u0304k\u22121 ], \u03b2\u0304 k\u22121 = [0 \u03b2\u03041 * * * \u03b2\u0304k\u22121 ] as given by Lemma 1, and J \u0304k (x, \u03b2\u0304 k\u22121 ) and J \u0304k (x, \u03b2\u0304 k\u22121 )\nas given by Theorem 2.\nRemark 3.2: The values of \u012ak (\u03b2\u0304 k\u22121 ) can be very easily numerically computed. We provide the Matlab\ncode which was used to generate the numerical results in this section in Appendix J. Due to the recursive\n\n\f12\n\nimplementation, the computational complexity grows quickly with k . Calculating J \u0304k (x, \u03b2\u0304 k\u22121 ) with high\nprecision for large values of k (> 10) seems therefore impractical.\nWe would now like to verify our analysis by some numerical results. To this end, we consider a system\nwith three relays, i.e., K = 4. We assume n = n4 = 4, n1 = n3 = 8, n2 = 12, \u03c11 = \u03c13 = 0.7\u03c10 and\n\u03c12 = 0.5\u03c10 . The last assumption allows us to control the transmit power of all nodes by the transmit\n\nSNR \u03c10 of the source node. We further assume the path loss factors \u03b11 = 1, \u03b12 = \u03b14 = 0.7, \u03b13 = 0.5.\n\u0002\n\u0001\u0003\nFig. 2 shows the average normalized mutual information E nnk Ik \u03b2 k\u22121 after each hop (k = 1, . . . , 4)\nversus the transmit power \u03c10 of the source node. Note that we have re-normalized all results by nnk to\n\u0001\nput them on a common ground for comparison. The deterministic equivalents nnk \u012ak \u03b2\u0304 k\u22121 as provided\nby Corollary 1 are drawn by solid lines, simulation results are represented by markers. The error bars\nrepresent one standard deviation of the simulation results in each direction. We can observe a very good\nfit between the asymptotic approximations and the simulation results for all k and the entire range of \u03c10 .\nAs expected, the performance decreases rapidly with each hop.\nFinally, we would like to remark that, although we have considered a rather simple channel model\nwith neither antenna correlation nor precoding at the nodes, more involved channel models can be treated\nin a straightforward fashion with the same techniques.\nB. Double-scattering MAC\nConsider a discrete-time MIMO MAC from K transmitters, equipped with nk , k = 1, . . . , K, antennas,\nrespectively, to a receiver with N antennas. The channel output vector y \u2208 CN reads\ny=\n\nK\nX\n\nH k xk + n\n\n(16)\n\nk=1\n\nwhere Hk \u2208 CN \u00d7nk and xk \u2208 Cnk are the channel matrix and the transmit vector associated with the\nk th transmitter, n \u223c CN (0, \u03c11 IN ) is a noise vector and \u03c1 > 0 denotes the SNR. We assume Gaussian\n\nsignaling, i.e., xk = [xk,1 , . . . , xk,nk ]T \u223c CN (0, Qk ), where Qk \u2208 Cnk \u00d7nk . The channel matrices Hk\nare modeled by the double-scattering model [23]\nHk = \u221a\n\n1\n1\n1\n1\nRk2 W1,k Sk2 W2,k Tk2\nNk nk\n\n(17)\n\nwhere Rk \u2208 CN \u00d7N , Sk \u2208 CNk \u00d7Nk and Tk \u2208 Cnk \u00d7nk are deterministic correlation matrices, while\nW1,k \u2208 CN \u00d7Nk and W2,k \u2208 CNk \u00d7nk are independent standard complex Gaussian matrices. Since the\n\ndistributions of W1,k and W2,k are unitarily invariant, we can assume Sk = diag(sk,1 , . . . , sk,Nk ) to be\ndiagonal matrices, without loss of generality for the statistics of y.\n\n\f13\n\nn = n4 = 4, n1 = n3 = 8, n2 = 12\n\n1.5\n\nk\nk\nk\nk\n\n=1\n=2\n=3\n=4\n\n1\n\n0.5\n\nE\n\nn\n\n\u0002 nk\n\nIk \u03b2 k\u22121\n\n\u0001\u0003\n\n(nats/s/Hz)\n\n2\n\n0\n\u221210\n\n0\n\n10\n\u03c10 (dB)\n\n20\n\n30\n\n\u0002\n\u0003\nAverage normalized mutual information E nnk Ik (\u03b2 k\u22121 ) after the kth hop versus the transmit SNR \u03c10 of the source\n\u0001\nnode. The deterministic equivalents nnk \u012ak \u03b2\u0304 k\u22121 are drawn by solid lines, the simulation results by markers. The error bars\nFig. 2.\n\ncorrespond to one standard deviation of the simulation results in each direction.\n\nThe double-scattering model [23] was motivated by the observation of low-rank channel matrices,\ndespite low antenna correlation at the transmitter and receiver, see e.g. [24], [32]. A special case of the\ndouble-scattering model is the keyhole channel [33], [34], which exhibits null antenna correlation, i.e.,\nRk = IN and Tk = nk for all k , but only a single degree of freedom. The existence of such channels\n\n(under laboratory conditions) was confirmed by measurements in [34]. Several theoretical works have\nstudied the double-scattering model so far. The authors of [35] derive capacity upper-bounds for the\ngeneral model and a closed-form expression for the keyhole channel. An asymptotic study of the outage\ncapacity of the multi-keyhole channel was presented in [36]. The diversity order of the double-scattering\nmodel was considered in [37] and it was shown that a MIMO system with t transmit antennas, r receive\nantennas and s scatterers achieves the diversity of order trs/ max(t, r, s). A closed-from expression of the\ndiversity-multiplexing trade-off (DMT) was derived in [38]. Beamforming along the strongest eigenmode\nover Rayleigh product MIMO channels, i.e., the double-scattering model without any form of correlation,\nwas considered in [39]. Here, the authors derive exact expressions of the cumulative distribution function\n(cdf) and the probability density function (pdf) of the largest eigenvalue of the Gramian of the channel\n\n\f14\n\nmatrix and compute closed-form results for the ergodic capacity, outage probability and SINR distribution.\nIn a later paper [40], the MIMO MAC with double-scattering fading is analyzed. The authors obtain\nclosed-form upper-bounds on the sum-capacity and prove that the transmitters should send their signals\nalong the eigenvectors of the transmit correlation matrices in order to achieve capacity. Despite the\nsignificant interest in the double-scattering channel model, little work has been done to study its asymptotic\nperformance when the channel dimensions grow large. We are only aware of [32], in which a model\nwithout transmit and receive correlation is studied relying on tools from free probability theory. Implicit\nexpressions of the asymptotic mutual information and the SINR with MMSE detection are found therein.\nIn the following, we provide deterministic equivalents of the mutual information, the SINR with MMSEdetection and the associated sum-rate. In addition, we derive the precoders which maximize the deterministic equivalent of the mutual information and provide a simple algorithm for their computation. The key\nidea behind the following proofs is that the double-scattering channel can be interpreted as a Kronecker\nchannel [14] with a random receive correlation matrix, which itself is modeled by the Kronecker model.\nThis observation allows us to build upon [14] which provides an asymptotic analysis of the performance\nof Kronecker channels with deterministic correlation matrices (Theorem 9 in Appendix A). Based on\nthe Fubini theorem, we extend this work by allowing the correlation matrices to be random. A similar\ntechnique can be applied to more involved channel models, such as channels with line-of-sight components\nor MIMO product channels with an arbitrary number of matrices.\nDenote IN (\u03c1) the instantaneous normalized mutual information of the channel (16), defined as [41]\n!\nK\nX\n1\nH\nIN (\u03c1) =\nlog det IN + \u03c1\n(18)\nHk Qk Hk .\nN\nk=1\n\nMoreover, denote\n\nN\n\u03b3k,j\n\n(\u03c1) the SINR at the output of the MMSE detector related to the transmit symbol\n\nxk,j , given by [42]\nN\n\u03b3k,j\n\n(\u03c1) =\n\nhH\nk,j\n\nK\nX\n\nHi HH\ni\n\n\u2212\n\nhk,j hH\nk,j\n\ni=1\n\n1\n+ IN\n\u03c1\n\n!\u22121\nhk,j .\n\n(19)\n\nWe define the normalized sum-rate RN (\u03c1) with MMSE detection as\nK nk\n\u0001\n1 XX\nN\nRN (\u03c1) =\nlog 1 + \u03b3k,j\n(\u03c1) .\nN\n\n(20)\n\nk=1 j=1\n\nThe notation \"N \u2192 \u221e\" will be used to denote that N and all Nk , nk grow infinitely large, satisfying\n0 < lim inf\n\nNk\nN\n\n\u2264 lim sup NNk < \u221e and 0 < lim inf\n\nfollowing technical assumption:\n\nnk\nN\n\n\u2264 lim sup nNk < \u221e. Additionally, we need the\n\n\f15\n\nA 1: For all k , lim supN kRk k < \u221e, lim supN kSk k < \u221e and lim supN kTk Qk k < \u221e.\nRemark 3.3: This assumption implies in particular that the antenna correlation at the transmitter and\nreceiver side cannot grow with the system size, as it would be the case for very dense antenna arrays\n[43]. Amendments to relax this assumption can be made, following the work in [14]. Moreover, the last\nconstraint, lim supN kTk Qk k < \u221e, implies that no transmitter is allowed to focus an increasing amount\nof transmit power in a single direction.\nOur first theorem introduces a set of 3K implicit equations which uniquely determines some quantities\n(gk , \u1e21k , \u03b4k ) (1 \u2264 k \u2264 K ). These will be needed later on to provide deterministic equivalents of IN (\u03c1),\n\u0001\nN \u03c3 2 , and R (\u03c1).\n\u03b3k,j\nN\n\nTheorem 4 (Fundamental equations): The following system of 3K implicit equations in \u1e21k , gk , and\n\u03b4k (1 \u2264 k \u2264 K ):\n\u1e21k =\n\n\u0011\u22121\n1 \u0010\n1\n1\n1\n1\ntr Tk2 Qk Tk2 gk Tk2 Qk Tk2 + Ink\nnk\n\ngk =\n\nNk\nsk,j \u03b4k\n1 X\nnk\n1 + \u1e21k sk,j \u03b4k\n\n(21)\n\nj=1\n\n1\ntr Rk\n\u03b4k =\nNk\n\nK\nX\nni \u1e21i gi\n1\nRi + IN\nNi \u03b4i\n\u03c1\n\n!\u22121\n\ni=1\n\nhas a unique solution satisfying \u1e21k , gk , \u03b4k > 0 for all k and \u03c1 > 0.\nProof: The proof is provided in Appendix D.\nRemark 3.4: The values of \u1e21k , gk , and \u03b4k can be computed by a standard fixed-point algorithm which\n(0)\n\n(0)\n\n(0)\n\niteratively computes (21), starting from some arbitrary initialization \u1e21k , gk , \u03b4k > 0. This algorithm is\nproved to converge, generally terminates within a few iterations (depending on the system size and the\ndesired accuracy), and does not pose any computational challenge.\nThe next theorem provides a deterministic equivalent of the (ergodic) mutual information based on the\nquantities (gk , \u1e21k , \u03b4k ) as provided by Theorem 4.\nTheorem 5 (Mutual information): Assume that A 1 holds. Then,\n(i)\n(ii)\n\na.s.\nIN (\u03c1) \u2212 I \u0304N (\u03c1) \u2212\u2212\u2212\u2212\u2192 0\n\nN \u2192\u221e\n\nE [IN (\u03c1)] \u2212 I \u0304N (\u03c1) \u2212\u2212\u2212\u2212\u2192 0\nN \u2192\u221e\n\n\f16\n\nwhere\nK\n\nX nk \u1e21k gk\n1\nI \u0304N (\u03c1) =\nlog det IN + \u03c1\nRk\nN\nNk \u03b4k\n\n!\n\nk=1\n\n+\n\n1\nN\n\nK h\nX\n\n\u0010\ni\n1\n1\u0011\nlog det (INk + \u1e21k \u03b4k Sk ) + log det Ink + gk Tk2 Qk Tk2 \u2212 2nk gk \u1e21k\n\n(22)\n\nk=1\n\nand gk , \u1e21k , \u03b4k are the unique positive solutions to (21).\nProof: The proof is provided in Appendix E.\nThe following result allows us to compute the asymptotically optimal precoding matrices Qk which\nmaximize I \u0304N (\u03c1) under individual transmit power constraints.\nTheorem 6 (Optimal power allocation): The solution to the following optimization problem:\nQ\u0304?1 , . . . , Q\u0304?K\n\n\u0001\n\n= arg max I \u0304N (\u03c1)\nQ1 ,...,Qk\n\ns.t.\n\n1\ntr Qk \u2264 Pk \u2200k\nnk\n\nnk \u00d7nk\nwhere I \u0304N (\u03c1) is defined in Theorem 5, is given as Q\u0304?k = Uk P\u0304?k UH\nis defined by\nk , where Uk \u2208 C\n?\n?\n?\nthe spectral decomposition of Tk = Uk diag(tk,1 , . . . , tk,nk )UH\nk and P\u0304k = diag(p\u0304k,1 , . . . , p\u0304k,nk ) is given\n\nby the water-filling solution:\np\u0304?k,j\n\nwhere \u03bck is chosen to satisfy\n\n1\n?\nnk tr P\u0304k\n\n\u0012\n=\n\n1\n\u03bck \u2212 ?\ngk tk,j\n\n\u0013+\n\n(23)\n\n= Pk and gk? is given by Theorem 4 for Qk = Q\u0304?k .\n\nProof: The proof is provided in Appendix F.\nRemark 3.5: The optimal power allocation matrices P\u0304?k can be calculated by the iterative water-filling\nAlgorithm 1 (see [14, Remark 2] and [7, Remark 3] for a discussion on the convergence of this algorithm).\nRemark 3.6: Denote by (Q?1 , . . . , Q?K ) the set of precoding matrices which maximize E [IN (\u03c1)] for a\ngiven set of power constraints. If the condition lim supkTk Q?k k < \u221e holds for all k , then E [IN (\u03c1, Q?1 , . . . , Q?K )]\u2212\nI \u0304N (\u03c1, Q\u0304?1 , . . . , Q\u0304?K ) \u2212\u2212\u2212\u2212\u2192 0, by Theorem 5 and the strict concavity of I \u0304N (\u03c1) and IN (\u03c1) in the matrices\nN \u2192\u221e\n\nQk . However, this condition is difficult to verify and is outside the scope of this paper. See [25] for such\n\na technical discussion in the case of Rician fading channels.\nN (\u03c1) at the output of the MMSE detector\nNext, we provide deterministic equivalents of the SINR \u03b3k,j\n\nand the associated sum-rate RN (\u03c1).\n\n\f17\n\nAlgorithm 1 Iterative water-filling algorithm\n1:\n\nLet \u000f > 0, n = 0 and p\u0304?,0\nk,j = Pk for all k, j .\n\n2:\n\nrepeat\n\n4:\n\n\u0010\n\u0011\nH\nFor all k , compute gk?,n according to Theorem 4 with matrices Qk = Uk diag p\u0304?,n\nk,j Uk .\n\u0011+\n\u0010\nP k ?,n+1\n1\n, with \u03bck such that n1k nj=1\np\u0304k,j = Pk .\nFor all k, j , calculate p\u0304?,n+1\n=\n\u03bc\n\u2212\n?,n\nk\nk,j\ng tk,j\n\n5:\n\nn=n+1\n\n3:\n\n6:\n\nk\n\n?,n\u22121\nuntil maxk,j |p\u0304?,n\n|\u2264\u000f\nk,j \u2212 p\u0304k,j\n\nTheorem 7 (SINR of the MMSE detector): Let Qk = diag (pk,1 , . . . , pk,nk ) and Tk = diag(tk,1 , . . . , tk,nk )\nfor all k . Assume that A 1 holds. Then,\na.s.\n\nN\nN\n\u03b3k,j\n(\u03c1) \u2212 \u03b3\u0304k,j\n(\u03c1) \u2212\u2212\u2212\u2212\u2192 0\nN \u2192\u221e\n\nN (\u03c1) = p t g and g is by given by Theorem 4.\nwhere \u03b3\u0304k,j\nk,j k,j k\nk\n\nProof: The proof is provided in Appendix G.\nRemark 3.7: It is easy to see that the theorem is also valid under the more general assumption Tk =\nH\nUk diag(tk,1 , . . . , tk,nk )UH\nk and Qk = Uk diag(pk,1 , . . . , pk,nk )Uk .\n\nCorollary 2 (Sum-rate with MMSE decoding): Let Qk = diag (pk,1 , . . . , pk,nk ) and Tk = diag(tk,1 , . . . , tk,nk )\nfor all k . Assume that A 1 holds. Then,\n(i)\n(ii)\n\na.s.\n\nRN (\u03c1) \u2212 R\u0304N (\u03c1) \u2212\u2212\u2212\u2212\u2192 0\nN \u2192\u221e\n\na.s.\n\nE [RN (\u03c1)] \u2212 R\u0304N (\u03c1) \u2212\u2212\u2212\u2212\u2192 0\nN \u2192\u221e\n\nwhere\nR\u0304N (\u03c1) =\n\nK nk\n\u0001\n1 XX\nN\nlog 1 + \u03b3\u0304k,j\n(\u03c1)\nN\nk=1 j=1\n\nN (\u03c1) are given by Theorem 7.\nand the \u03b3\u0304k,j\n\nProof: The proof is provided in Appendix H.\nRemark 3.8: Careful inspection of (22) reveals that the third term of I \u0304N (\u03c1) equals R\u0304N (\u03c1) since\nK\nK nk\n\u0010\n1\n1\u0011\n1 X\n1 XX\n2\n2\nlog det Ink + gk Tk Qk Tk =\nlog (1 + pk,j tk,j gk ) .\nN\nN\nk=1\n\nk=1 j=1\n\n(24)\n\n\f18\n\nThus, all other terms in (22) correspond to the gains of successive interference cancellation [44] over\nsimple MMSE detection.\nA special case of the double-scattering channel is the Rayleigh product MIMO channel [39] which\ndoes not exhibit any form of correlation between the transmit and receive antennas or the scatterers. For\nthis model, Theorems 4, 5 and 7 can be given in closed form as shown in the next corollary.\nCorollary 3 (Rayleigh product channel): For all k , let Nk = S , nk = N and assume Tk = IN ,\nN (\u03c1) as defined in Theorems 5 and 7 can be\nSk = IS , Rk = IN , and Qk = IN . Then I \u0304N (\u03c1) and \u03b3\u0304k,j\n\ngiven in closed form as\n\u0012\n\u0012\n\u0013\u0013\n\u0012\n\u0013\nNK\nS\nKS\nN\n \u0304\nIN (\u03c1) = log 1 + \u03c1\n\u1e21 \u1e21 +\n\u22121\n\u2212\nlog 1 +\n(\u1e21 \u2212 1) \u2212 K log (\u1e21) \u2212 2K (1 \u2212 \u1e21)\nS\nN\nN\nS\nand\nN\n\u03b3\u0304k,j\n(\u03c1) =\n\n1 \u2212 \u1e21\n\u1e21\n\nwhere \u1e21 is the unique root to\n\u0012\n\u0013\n\u0012\n\u0012\n\u0013\u0013\nS\n1\nS\n1\nS\n1\nS 1\n3\n2\n\u1e21 \u2212 \u1e21 2 \u2212\n\u2212\n+ \u1e21 1 \u2212\n\u2212\n+\n1+\n\u2212\n=0\nN\nK\nN\nK\nNK\n\u03c1\nNK \u03c1\n\u0002\n\u0003 \u0001\nS\nsuch that \u1e21 \u2208 1 \u2212 min K1 , N\n,1 .\n\n(25)\n\nProof: The proof is provided in Appendix I.\nNote that similar expressions for the asymptotic mutual information and MMSE-SINR have been\nobtained in [32] by means of free probability theory. However, these results require the numerical solution\nof a third order differential equation.\nAs a first numerical example, we consider the \"multi-keyhole channel\", i.e., K = 1, S1 = IN1 ,\nR1 = IN , T1 = Q1 = In1 , for N = n1 = 4. Fig. 3 depicts the normalized ergodic mutual information\n\nE [IN (\u03c1)] and its asymptotic approximation I \u0304N (\u03c1) versus SNR for different numbers of \"keyholes\" N1 \u2208\n{1, 2, 3, 4, 100}. Surprisingly, the match between both results is almost perfect although the channel\n\ndimensions are very small. As one expects, the multiplexing gain increases linearly with N1 until N1 \u2265\nN = 4. Larger values of N1 only change the statistical distribution of the channel matrix while the degrees\n\nof freedom are limited by the number of antennas (for N1 \u2192 \u221e, H1 becomes a standard Rayleigh fading\nchannel [23]).\nAs a second example, we consider a MAC from K = 3 transmitters, assuming the double-scattering\nmodel in [23]. Under this model, the correlation matrices are given as Rk = G(\u03c6r,k , dr,k , Nk ), Sk =\n\n\f19\n\n5\n\nApproximation\nSimulation\n\nE [IN (\u03c1)] (nats/s/Hz)\n\n4\n\n3\nN1 = 1, 2, 3, 4, 100 \u2191\n2\n\n1\n\n0\n\u221210\n\nFig. 3.\n\n\u22125\n\n0\n\n5\n10\n\u03c1 (dB)\n\n15\n\n20\n\n25\n\nErgodic mutual information E [IN (\u03c1)] of the multi-keyhole channel and its deterministic equivalent I \u0304N (\u03c1) versus \u03c1.\n\nG(\u03c6s,k , ds,k , Nk ) and Tk = G(\u03c6t,k , dt,k , Nk ), where G(\u03c6, d, n) is defined as\nn\u22121\n\n[G(\u03c6, d, n)]k,l\n\n\u0012\n\u0012\n\u0013\u0013\n2\nj\u03c6\n1 X\nexp i2\u03c0d(k \u2212 l) sin\n=\n.\nn 1\u2212n\n1\u2212n\nj=\n\n(26)\n\n2\n\nThe values \u03c6t,k and \u03c6r,k determine the angular spread of the radiated and received signals, dt,k and\ndr,k are the antenna spacings at the k th transmitter and receiver in multiples of the signal wavelength,\nNk can be seen as the number of scatterers and ds,k as the spacing of the scatterers. For simplicity,\n\nwe assume N = 4, Pk = 1/nk , Nk = 11, nk = 3, dt,k = dr,k = 0.25 and ds,k = 50 for all k . We\nfurther assume \u03c6r,k = \u03c6t,k for all k , with \u03c6r,k \u2208 {\u03c0/4, \u03c0/2, \u03c0} and \u03c6s,k = \u03c0/8. Fig. 4 shows E [IN (\u03c1)]\nand I \u0304N (\u03c1) with uniform and optimal power allocation versus SNR. Again, our asymptotic results yield\nvery tight approximations, even for small system dimensions. Note that we have used the precoding\nmatrices provided by Theorem 6 for the simulations as the optimal precoding matrices are unknown.\nFor comparison, we also provide the sum-rate with MMSE detection E [RN (\u03c1)] and its deterministic\napproximation R\u0304N (\u03c1). We observe a good fit between both results at low SNR values, but a slight\nN (\u03c1) to its deterministic\nmismatch for higher values. This is due to a slower convergence of the SINR \u03b3k,j\nN (\u03c1), well documented in the RMT literature, e.g. [45].\napproximation \u03b3\u0304k,j\n\n\f20\n\nE [IN (\u03c1)] or E [RN (\u03c1)] (nats/s/Hz)\n\n5\n\n4\n\nUniform power (Approximation)\nOptimal power (Approximation)\nSimulation\n\n3\nIN (\u03c1)\n2\n\n1\nRN (\u03c1)\n0\n\u221210\n\n\u22125\n\n0\n\n5\n10\n\u03c1 (dB)\n\n15\n\n20\n\n25\n\nFig. 4.\n\nErgodic mutual information E [IN (\u03c1)] and sum-rate E [RN (\u03c1)] of the multiple access channel and their asymptotic\napproximations I \u0304N (\u03c1) and R\u0304N (\u03c1) versus \u03c1.\n\nIV. C ONCLUSION\nIn this paper, we have presented a novel tool for the large system analysis of communication systems,\ncalled iterative deterministic equivalents. This tool is particularly suited for the analysis of channel models\ncomposed of complex combinations of independent random matrices, e.g. products or sums of products\nof matrices. We have demonstrated the usefulness of this approach with the help of two examples which\nhad not been solved in the literature before. These are the multi-hop AF MIMO relay channel with\nnoise at each stage and the MIMO MAC under the double-scattering channel model. For these channel\nmodels, we have provided asymptotically tight deterministic approximations of information theoretic\nquantities of interest, such as the mutual information and the sum-rate with MMSE detection. These\napproximations can be easily computed by provably converging fixed-point algorithms and do not require\nany numerical integration. Our simulation results suggest that the asymptotic performance approximations\nare very accurate for finite system dimensions with only a few antennas at each node. Finally, the method\nof iterative deterministic equivalents is applicable to a wide range of channel models of interest (e.g.\ncombinations of correlated i.i.d. and random unitary matrices [7]) which cannot be easily treated so far\nwith other techniques.\n\n\f21\n\nA PPENDIX A\nR ELATED RESULTS\nLemma 2 ([46, Lemma 2.7], [9, Lemma 4]): Let (AN )N \u22651 be a sequence of random N \u00d7N matrices,\nsatisfying lim supN kAN k < \u221e, almost surely. Let (xN )N \u22651 be a sequence of random N -dimensional\n\u0001\nvectors of i.i.d. entries with zero mean, variance 1/N and 8th order moment of order O 1/N 4 ,\nindependent of AN . Then,\nxH\nN A N xN \u2212\n\n1\na.s.\ntr AN \u2212\u2212\u2212\u2212\u2192 0.\nN \u2192\u221e\nN\n\nLemma 3 (Matrix inversion lemma [47, Eq. (2.2)]): Let A \u2208 CN \u00d7N be Hermitian invertible. Then,\nfor any vector x \u2208 CN and any scalar \u03c4 \u2208 C such that A + \u03c4 xxH is invertible,\n\u0011\u22121\n\u0010\nxH A\u22121\n=\nxH A + \u03c4 xxH\n.\n1 + \u03c4 xH A\u22121 x\nLemma 4 (Rank-1 perturbation lemma [47]): Let z < 0, A \u2208 CN \u00d7N , B \u2208 CN \u00d7N with B Hermitian\nnonnegative definite, and v \u2208 CN . Then,\n\u0011\n\u0010\nkAk\n.\ntr (B \u2212 zIN )\u22121 \u2212 (B + vvH \u2212 zIN )\u22121 A \u2264\n|z|\nLemma 5: Let R \u2208 CN \u00d7N be Hermitian with smallest eigenvalue \u03bbmin \u2265 1 and a, b, c, d > 0. Then\n1\n1\ntr R (aR + bIN )\u22121 R (cR + dIN )\u22121 \u2265\n.\nN\n(a + b)(c + d)\n\nProof: Let R = U\u2206UH , where U \u2208 CN \u00d7N is unitary and \u2206 = diag (\u03b41 , . . . , \u03b4N ) \u2265 1. Thus,\n1\n1\ntr R (aR + bIN )\u22121 R (cR + dIN )\u22121 = tr \u22062 (a\u2206 + bIN )\u22121 (c\u2206 + dIN )\u22121\nN\nN\nN\n1\n1 X \u03b4i2 (a + b)(c + d)\n=\n(a + b)(c + d) N\n(a\u03b4i + b)(c\u03b4i + d)\ni=1\n\n1\n\u2265\n.\n(a + b)(c + d)\n\nLemma 6: Let the matrices Rk (\u03b2 k\u22121 ), be defined as in (10). Then, almost surely:\nlim supkRk (\u03b2 k\u22121 )k < \u221e,\nn\n\nk = 0, . . . , K.\n\n(27)\n\n\f22\n\nProof: For k \u2208 {1, . . . , K}, denote by (\u03a9k , Fk , Pk ) the probability space generating the sequences\nof random matrices Hk . By [46], we have on a space Bk \u2282 \u03a9k with Pk (Bk ) = 1,\n\u0013\n\u0012\n1 2\n1\nH\n\u2212\u2212\u2212\u2192 0.\nHk Hk \u2212 1 + \u221a\nn\u2192\u221e\nnk\u22121\nck\n\n(28)\n\nObviously, we have kR0 k = kIn k = 1. Thus, almost surely,\n\u0013\n\u0012\n\u03b11 \u03b20\n1 2\nH\nlim sup kR1 (\u03b20 )k \u2264 1 + lim sup\n< \u221e.\nH1 H1 = 1 + \u03b11 \u03b20 lim sup 1 + \u221a\nn\nc1\nn\nn\nn\n\n(29)\n\nConsider now the product space (\u03a91 \u00d7 \u03a92 , F1 \u00d7 F2 , Q2 ). By the Fubini theorem, we have on a subspace\nC2 \u2282 \u03a91 \u00d7 \u03a92 with Q2 (C2 ) = 1,\n\u03b12 \u03b21\nH2 R1 (\u03b20 )HH\n2\nn\nn\n1\n1\nH2 HH\n\u2264 1 + lim sup \u03b12 \u03b21 kR1 (\u03b20 )k\n2\nn1\nn\n\u0013 !\u0012\n\u0013\n\u0012\n1 2\n1 2\n1+ \u221a\n= 1 + \u03b12 \u03b21 lim sup 1 + \u03b11 \u03b20 1 + \u221a\nc1\nc2\nn\n\nlim supkR2 (\u03b2 1 )k \u2264 1 + lim sup\nn\n\n(30)\n\n< \u221e.\n\nRepeating the last step k \u2212 2 times concludes the proof.\nDefinition 2 (Standard interference function [48]): A function h(x1 , . . . , xK ) = [h1 (x1 , . . . , xK ), . . . ,\nhK (x1 , . . . , xK )]T \u2208 RK is said to be standard if it fulfills the following conditions:\n\n1) Positivity: for each j , if x1 , . . . , xK \u2265 0, then hj (x1 , . . . , xK ) > 0.\n2) Monotonicity: if x1 > x01 , . . . , xK > x0K , then for all j , hj (x1 , . . . , xK ) > hj (x01 , . . . , x0K ).\n3) Scalability: for all \u03b1 > 1 and for all j , \u03b1hj (x1 , . . . , xK ) > hj (\u03b1x1 , . . . , \u03b1xK ).\nTheorem 8 (Fixed-point theorem [48, Theorem 2]): If a K -variate function h(x1 , . . . , xK ) is standard\nand there exists (x1 , . . . , xK ) such that for all j , xj \u2265 hj (x1 , . . . , xK ), then the fixed-point algorithm\nthat consists in setting\n(t+1)\n\nxj\n(0)\n\n(t)\n\n(t)\n\n= hj (x1 , . . . , xK )\n(0)\n\nfor t \u2265 1 and for any initial values x1 , . . . , xK > 0 converges to the unique jointly positive solution\nof the system of K equations\nxj = hj (x1 , . . . , xK ),\n\nj \u2208 {1, . . . , K}.\n\n\f23\n\nTheorem 9 ([14, Corollary 1, Theorem 2]): For k \u2208 {1, . . . , K}, let (nk )N \u22651 = (nk (N ))N \u22651 be\na sequence of positive integers and let (Rk,N )N \u22651 , Rk,N \u2208 CN \u00d7N , (Tk,N )N \u22651 ,Tk,N \u2208 Cnk \u00d7nk ,\nand (DN )N \u22651 , DN \u2208 CN \u00d7N , be three sequences of nonnegative definite Hermitian matrices, satisfying lim supN kRk,N k < \u221e, lim supN kTk,N k < \u221e, and lim supN kDN k < \u221e. Let (Xk,N )N \u22651 ,\nXk,N \u2208 CN \u00d7nk , be a sequence of random matrices with i.i.d. complex Gaussian entries with zero mean\n1\n1\nP\nH R2\n2\nand variance 1/nk . Denote BN =\nR\nX\nT\nX\nk,N\nk,N\nk k,N\nk,N k,N and define the function VN (x) =\n1\nN\n\nlog det (IN + xBN ) for x > 0. Let ck = nk /N and assume that 0 < lim inf N ck \u2264 lim supN ck < \u221e\n\nfor all k . Then,\n(i)\n(ii)\n\n1\ntr DN\nN\n\n\u0012\n\n1\nBN + I N\nx\n\n\u0013\u22121\n\n1\n\u2212 tr DN\nN\n\nK\nX\n\n\u0113i Ri,N\n\ni=1\n\n1\n+ IN\nx\n\n!\u22121\n\na.s.\n\n\u2212\u2212\u2212\u2212\u2192 0\nN \u2192\u221e\n\na.s.\n\nVN (x) \u2212 V\u0304N (x) \u2212\u2212\u2212\u2212\u2192 0\nN \u2192\u221e\n\nwhere\nK\n\nX\n1\nV\u0304N (x) =\nlog det IN + x\n\u0113k,N Rk,N\nN\n\n!\n\nk=1\n\nK\nK\nX\n1\n1 X\n+\nlog det (Ink + ek,N Tk,N ) \u2212\nnk ek,N \u0113k,N\nN\nN\nk=1\n\nk=1\n\nand where \u0113k,N , ek,N , k = 1, . . . , K , are given as the unique solution to the equations\n\u0113k,N =\nek,N\n\n1\ntr Tk,N (ek,N Tk,N + Ink )\u22121\nnk\n\n1\ntr Rk,N\n=\nnK\n\nK\nX\n\n\u0113i Ri,N\n\ni=1\n\n1\n+ IN\nx\n\n!\u22121\n\nsuch that \u0113k,N , ek,N > 0 for all k .\nCorollary 4 (Special case of Theorem 9, see also [47]): Let (n)N \u22651 = (n(N ))N \u22651 be a sequence of\npositive integers. Let (RN )N \u22651 , RN \u2208 Cn\u00d7n , be a sequence of nonnegative definite Hermitian matrices,\nsatisfying lim supN kRN k < \u221e and let (XN )N \u22651 , XN \u2208 CN \u00d7n , be a sequence of random matrices\nwith i.i.d. complex Gaussian entries with zero mean and variance 1/n. For x > 0, define the following\n\u0001\u22121\n\u0001\n1\nand JN (x) = N1 log det IN + xXN RN XH\nfunctions mN (x) = N1 tr XN RN XH\nN + x IN\nN . Denote\nc=\n\nn\nN\n\nand assume that 0 < lim inf N c \u2264 lim supN c < \u221e. Then,\n(i)\n\na.s.\n\nmN (x) \u2212 m\u0304N (x) \u2212\u2212\u2212\u2212\u2192 0,\nN \u2192\u221e\n\n(ii)\n\na.s.\nJN (x) \u2212 J \u0304N (x) \u2212\u2212\u2212\u2212\u2192 0\n\nN \u2192\u221e\n\nwhere\n\u0012\n\u0013\u22121\n1\nRN\n1\n+ In\nm\u0304N (x) = tr\n+ (1 \u2212 c)x\nN\nc + \u0113N\nx\n1\n\u0113N\nJ \u0304N (x) =\nlog det ([c + \u0113N ] In + xRN ) + (1 \u2212 c) log (c + \u0113N ) \u2212\n\u2212 log(c)\nN\nc + \u0113N\n\n\f24\n\nand \u0113N is defined as the unique positive solution to the implicit equation\n\u0012\n\u0013\u22121\nRN\n1\n1\n+ In\n.\n\u0113N = tr RN\nN\nc + \u0113N\nx\n\n(31)\n\nA PPENDIX B\nP ROOF OF T HEOREM 2:\nFirst, notice that\n4\n\n\u03b7k =\n=\n\nRk (\u03b2 k\u22121 ) \u2212 Rk (\u03b2\u0304 k\u22121 )\n\u03b1k \u03b2k\u22121\n\u03b1k \u03b2\u0304k\u22121\nHk Rk\u22121 (\u03b2 k\u22122 )HH\nHk Rk\u22121 (\u03b2\u0304 k\u22122 )HH\nk \u2212\nk\nnk\u22121\nnk\u22121\n\n\u2264 \u03b1k\n\nHk HH\nk\nnk\u22121\n\n\u2264 \u03b1k\n\n\u0003\n\u0002\nHk HH\nk\n|\u03b2k\u22121 \u2212 \u03b2\u0304k\u22121 | Rk\u22121 (\u03b2 k\u22122 ) + \u03b2\u0304k\u22121 Rk\u22121 (\u03b2 k\u22122 ) \u2212 Rk\u22121 (\u03b2\u0304 k\u22122 ) .\nnk\u22121\n\n\u03b2k\u22121 Rk\u22121 (\u03b2 k\u22122 ) \u2212 \u03b2\u0304k\u22121 Rk\u22121 (\u03b2\u0304 k\u22122 )\n\nSince, almost surely, lim sup R1 (\u03b2 0 ) \u2212 R1 (\u03b2\u0304 0 ) \u2264 lim sup \u03b11 |\u03b20 \u2212\u03b2\u03040 |\n\nH1 HH1\nn\n\n(32)\n\n= 0 and lim sup Rk\u22121 (\u03b2 k\u22122 ) <\n\n\u221e (see proof of Lemma 6), one can iteratively show that \u03b7k \u2192 0, almost surely. Thus,\n\n\u0001\n\u0001 a.s.\nJk x, \u03b2 k\u22121 \u2212 Jk x, \u03b2\u0304 k\u22121 \u2212\u2212\u2212\u2192 0.\nn\u2192\u221e\n\n(33)\n\n\u0001\nThis means that we can from now on replace \u03b2 k by \u03b2\u0304 k and focus on Jk x, \u03b2\u0304 k\u22121 .\nAs a consequence of Corollary 4, Lemma 6, and the Fubini theorem, we obtain the following relation\na.s.\n\nJk (x, \u03b2\u0304 k\u22121 ) \u2212 J \u0303k (x, \u03b2\u0304 k\u22121 ) \u2212\u2212\u2212\u2192 0,\nn\u2192\u221e\n\nk\u22651\n\n(34)\n\nwhere\n\u0001\n\u0002\n\u0001\u0003\n\u0001\u0001\n1\nlog det ck + ek\u22121 x, \u03b2\u0304 k\u22121 Ink\u22121 + x\u03b1k \u03b2\u0304k\u22121 Rk\u22121 \u03b2\u0304 k\u22122\nJ \u0303k x, \u03b2\u0304 k\u22121 =\nnk\n\u0001\n\u0001\u0001\nek\u22121 x, \u03b2\u0304 k\u22121\n\u0001 \u2212 log (ck )\n+ (1 \u2212 ck ) log ck + ek\u22121 x, \u03b2\u0304 k\u22121 \u2212\nck + ek\u22121 x, \u03b2\u0304 k\u22121\n\u0001\nand ek\u22121 x, \u03b2\u0304 k\u22121 is given as the unique positive solution to\n!\u22121\n\u0001\n\u0001\n\u0001 \u03b1k \u03b2\u0304k\u22121 Rk\u22121 \u03b2\u0304 k\u22122\n1\n1\n\u0001 + Ink\u22121\nek\u22121 x, \u03b2\u0304 k\u22121 =\ntr \u03b1k \u03b2\u0304k\u22121 Rk\u22121 \u03b2\u0304 k\u22122\n.\nnk\nx\nck + ek\u22121 x, \u03b2\u0304 k\u22121\n\n(35)\n\n(36)\n\nIn particular, for k = 1, we have\n\u0001\n\u0001\nJ \u03031 x, \u03b2\u03040 = J \u03041 x, \u03b2\u03040\n\n(37)\n\n\f25\n\nwhere\n!\n\u0001\n\u0001!\n\u0113\nx,\n\u03b2\u0304\n\u0113\nx,\n\u03b2\u0304\nx\u03b1\n\u03b2\u0304\n0\n0\n0\n0\n1\n0\n\u0001 + log 1 +\n\u0001\n\u2212\nJ \u03041 x, \u03b2\u03040 = c1 log 1 +\nc1\nc1 + \u01130 x, \u03b2\u03040\nc1 + \u01130 x, \u03b2\u03040\nq\n\u00012\nx\u03b11 \u03b2\u03040 (1 \u2212 c1 ) + c1 + 4x\u03b11 \u03b2\u03040 c21\n\u0001\nx\u03b11 \u03b2\u03040 (1 \u2212 c1 ) + c1\n+\n\u01130 x, \u03b2\u03040 = \u2212\n2\n2\n\u0001\n\n(38)\n\n(39)\n\naccording to Corollary 4. Note that (31) permits a closed-form solution (39) in this case.\n\u0001\n\u0001 H\n\u03b2\u0304k\u22122\nNow, using the recursion Rk\u22121 \u03b2\u0304 k\u22122 = Ink\u22121 + \u03b1k\u22121\nnk\u22122 Hk\u22121 Rk\u22122 \u03b2\u0304 k\u22123 Hk\u22121 (10) in (35), we\nobtain\n!\n!\nx\u03b1\n\u03b2\u0304\nx\u03b1\n\u03b2\u0304\nk k\u22121\nk k\u22121\n\u0001\n\u0001 , \u03b2\u0304 k\u22122 + ck log 1 +\nJ \u0303k (x, \u03b2\u0304 k\u22121 ) = ck Jk\u22121\nck + x\u03b1k \u03b2\u0304k\u22121 + ek\u22121 x, \u03b2\u0304 k\u22121\nck + ek\u22121 x, \u03b2\u0304 k\u22121\n\u0001\n\u0001!\nek\u22121 x, \u03b2\u0304 k\u22121\nek\u22121 x, \u03b2\u0304 k\u22121\n\u0001.\n(40)\n\u2212\n+ log 1 +\nck\nck + ek\u22121 x, \u03b2\u0304 k\u22121\nIn the proof of Theorem 3, it is shown that\n\u0001\n\u0001 a.s.\nek\u22121 x, \u03b2\u0304 k\u22121 \u2212 \u0113k\u22121 x, \u03b2\u0304 k\u22121 \u2212\u2212\u2212\u2192 0.\n\n(41)\n\nn\u2192\u221e\n\nBy the continuous mapping theorem [31], we therefore have\nJk\u22121\n\nx\u03b1k \u03b2\u0304k\u22121\n\u0001 , \u03b2\u0304 k\u22122\n1 + x\u03b1k \u03b2\u0304k\u22121 + ek\u22121 x, \u03b2\u0304 k\u22121\n\u2212 Jk\u22121\n\n!\n\nx\u03b1k \u03b2\u0304k\u22121\n\u0001 , \u03b2\u0304 k\u22122\n1 + x\u03b1k \u03b2\u0304k\u22121 + \u0113k\u22121 x, \u03b2\u0304 k\u22121\n\n!\n\na.s.\n\n(42)\n\n\u2212\u2212\u2212\u2192 0.\nn\u2192\u221e\n\nApplying the last result together with Corollary 4, Lemma 6, the continuous mapping theorem and the\n\u0001\n\u0001\nFubini theorem to (40) concludes the proof for k = 2 since J \u03031 x, \u03b2\u03040 = J \u03041 x, \u03b2\u03040 by (37). The\nconvergence for k > 2 is shown by successive iterations of the last steps.\nA PPENDIX C\nP ROOF OF T HEOREM 3\nFrom standard matrix inequalities and (32), it follows that\nmk (x, \u03b2 k ) \u2212 mk x, \u03b2\u0304 k\n\n\u0001\n\n\u2264 x2 \u03b1k+1\n\nHk+1 HH\nk+1\nnk\n\n\u0001\n\u0001\na.s.\n\u03b2k Rk \u03b2 k\u22121 \u2212 \u03b2\u0304k Rk \u03b2\u0304 k\u22121 \u2212\u2212\u2212\u2192 0. (43)\nn\u2192\u221e\n\nThus, we can replace from now on \u03b2k by \u03b2\u0304k , for almost every (H1 , . . . , HK ).\nFrom Corollary 4, Lemma 6 and the Fubini theorem, it follows that\n\u0001\n\u0001 a.s.\nmk x, \u03b2\u0304 k \u2212 m\u0303k x, \u03b2\u0304 k \u2212\u2212\u2212\u2192 0\nn\u2192\u221e\n\n(44)\n\n\f26\n\nwhere\nm\u0303k (x, \u03b2\u0304 k ) =\n\n1\nnk+1\n\n!\u22121\n\u0001\n\u03b1k+1 \u03b2\u0304k Rk \u03b2\u0304 k\u22121\n1\n\u0001 + In\n+ (1 \u2212 ck+1 )x\nx\nck+1 + ek x, \u03b2\u0304 k\n\ntr\n\n(45)\n\n\u0001\nand ek x, \u03b2\u0304 k is given as the unique positive solution to\n\u0001\n\nek x, \u03b2\u0304 k =\n\n1\nnk+1\n\ntr \u03b1k+1 \u03b2\u0304k Rk \u03b2\u0304 k\u22121\n\n\u0001\n\n!\u22121\n\u0001\n\u03b1k+1 \u03b2\u0304k Rk \u03b2\u0304 k\u22121\n1\n\u0001 + Ink\n.\nx\nck+1 + ek x, \u03b2\u0304 k\n\n(46)\n\nIn particular, we have m\u03030 (x, \u03b2\u0304 k ) = m\u03040 (x, \u03b2\u0304 k ), where\nm\u03040 (x, \u03b2\u03040 ) =\n\nc1\n\u03b11 \u03b2\u03040\nc1 +\u01130 (x,\u03b2\u03040 )\n\n1\nx\n\n+\n\n(47)\n\n+ (1 \u2212 c1 )x\n\nq\n\n\u00012\nx\u03b11 \u03b2\u03040 (1 \u2212 c1 ) + c1 + 4x\u03b11 \u03b2\u03040 c21\nx\u03b11 \u03b2\u03040 (1 \u2212 c1 ) + c1\n\u01130 x, \u03b2\u03040 = \u2212\n+\n.\n(48)\n2\n2\n\u0001\n\u0001\n\u0001\nk\u22121\nHk Rk\u22121 \u03b2\u0304 k\u22122 HH\nReplacing Rk \u03b2\u0304 k\u22121 in (46) by its recursive definition Rk \u03b2\u0304 k\u22121 = Ink + \u03b1nk \u03b2\u0304k\u22121\nk\n\u0001\n\n(10) yields after straightforward calculus\n\u0001\u0001\n\u0001\nek x, \u03b2\u0304 k = ck+1 ck+1 + ek x, \u03b2\u0304 k\nck+1 ck+1 + ek x, \u03b2\u0304 k\n\u2212\nx\u03b1k+1 \u03b2\u0304k\n\n\u0001\u00012\nmk\u22121\n\nx\u03b1k+1 \u03b2\u0304k\n\u0001 , \u03b2\u0304 k\u22121\nck+1 + x\u03b1k+1 \u03b2\u0304k + ek x, \u03b2\u0304 k\n\n!\n.\n\n(49)\n\nSimilarly, one obtains\nck+1 ck+1 + ek x, \u03b2\u0304 k\nm\u0303k (x, \u03b2\u0304 k ) =\n\u03b1k+1 \u03b2\u0304k\n\n\u0001\u0001\n\nx\u03b1k+1 \u03b2\u0304k\n\u0001 , \u03b2\u0304 k\u22121\nck+1 + x\u03b1k+1 \u03b2\u0304k + ek x, \u03b2\u0304 k\n\nmk\u22121\n\n!\n+ (1 \u2212 ck+1 )x.\n\n(50)\nCombining the last two equations leads to\nm\u0303k (x, \u03b2\u0304 k ) =\n\nxck+1\n\u0001.\nck+1 + ek x, \u03b2\u0304 k\n\n(51)\n\n\u0001\nConsider now the quantity \u0113k x, \u03b2\u0304 k , k \u2265 1, defined as a positive solution to\n\u0001\n\u0001\u0001\n\u0113k x, \u03b2\u0304 k = ck+1 ck+1 + \u0113k x, \u03b2\u0304 k\nck+1 ck+1 + \u0113k x, \u03b2\u0304 k\n\u2212\nx\u03b1k+1 \u03b2\u0304k\n\n\u0001\u00012\nm\u0304k\u22121\n\nx\u03b1k+1 \u03b2\u0304k\n\u0001 , \u03b2\u0304 k\u22121\nck+1 + x\u03b1k+1 \u03b2\u0304k + \u0113k x, \u03b2\u0304 k\n\n!\n(52)\n\n\u0001\nwhere m\u0304k x, \u03b2\u0304 k is recursively defined for k \u2265 1 as\n\u0001\nm\u0304k x, \u03b2\u0304 k =\n\nxck+1\n\u0001.\nck+1 + \u0113k x, \u03b2\u0304 k\n\n(53)\n\n\f27\n\n\u0001\n\u0001 a.s.\nIt remains to show that a unique solution to (52) exists and that ek x, \u03b2\u0304 k \u2212 \u0113k x, \u03b2\u0304 k \u2212\u2212\u2212\u2192 0. Let us\nn\u2192\u221e\n\nfirst define the following functions for k \u2265 1:\nck+1 (ck+1 + z)2\nfk (z) = ck+1 (ck+1 + z) \u2212\nmk\u22121\nx\u03b1k+1 \u03b2\u0304k\n\n\u0012\n\nx\u03b1k+1 \u03b2\u0304k\n, \u03b2\u0304\nck+1 + x\u03b1k+1 \u03b2\u0304k + z k\u22121\n\nck+1 (ck+1 + z)2\nf \u0304k (z) = ck+1 (ck+1 + z) \u2212\nm\u0304k\u22121\nx\u03b1k+1 \u03b2\u0304k\n\n\u0012\n\n\u0013\nx\u03b1k+1 \u03b2\u0304k\n, \u03b2\u0304\n.\nck+1 + x\u03b1k+1 \u03b2\u0304k + z k\u22121\n\n\u0013\n\n(54)\n(55)\n\nFrom (46) and with the help of Lemma 5 (note that the smallest eigenvalue of Rk is greater or equal\nto 1 for all k ), one can easily verify that fk (z) satisfies the following properties for z \u2265 0:\n(i)\n\u0014\nfk (z) \u2265 ck+1 (ck+1 + z) 1 \u2212\n\n\u0015\nck+1 + z\n>0\nck+1 + z + x\u03b1k+1 \u03b2\u0304k\n\n(ii) for z > z 0 \u2265 0,\nfk (z) \u2212 fk (z 0 )\n2 \u03b2\u0304 2\n(z \u2212 z 0 )ck+1 \u03b1k+1\nk 1\ntr Rk\n\u2265\n(ck+1 + z 0 )(ck+1 + z) nk\n\n\u2265 \u0010\n\n\u0012\n\n2 \u03b2\u0304 2\n(z \u2212 z 0 )ck+1 \u03b1k+1\nk\n\u0011\nck+1 +z 0\n\u03b1k+1 \u03b2\u0304k + x\n\u03b1k+1 \u03b2\u0304k +\n\n\u03b1k+1 \u03b2\u0304k Rk\n1\n+ Ink\nck+1 + z\nx\n\n\u0013\u22121\n\n\u0012\nRk\n\n1\n\u03b1k+1 \u03b2\u0304k Rk\n+ Ink\nck+1 + z 0\nx\n\n\u0013\u22121\n\nck+1 +z \u0001\nx\n\n>0\n\n(iii) for \u03b1 > 1,\n\u03b1fk (z) \u2212 fk (\u03b1z)\n\n\u0012\n\u0013\u22121\n\u0012\n\u0013\u22121\n2 \u03b2\u0304 2\n(\u03b1 \u2212 1)c2k+1 \u03b1k+1\n1\n\u03b1k+1 \u03b2\u0304k Rk\n1\n1\n\u03b1k+1 \u03b2\u0304k Rk\nk\n\u2265\ntr Rk\n+\nIn\n+ Ink\nRk\n(ck+1 + \u03b1z)(\u03b1ck+1 + \u03b1z) nk\n\u03b1ck+1 + \u03b1z \u03b1x k\nck+1 + \u03b1z\nx\n\u0013\u22121 \u0012\n\u0013\u22121\n\u0012\n(\u03b1 \u2212 1)ck+1 \u03b1k+1 \u03b2\u0304k 1\n\u03b1k+1 \u03b2\u0304k Rk\n1\n\u03b1k+1 \u03b2\u0304k Rk\n1\ntr Rk\n+\nIn\n+ Ink\n+\n\u03b1x\nnk\n\u03b1ck+1 + \u03b1z \u03b1x k\nck+1 + \u03b1z\nx\n\u2265\n\n2 \u03b2\u0304 2\n(\u03b1 \u2212 1)c2k+1 \u03b1k+1\nk\n\u0001\nck+1 +\u03b1z\n\u03b1k+1 \u03b2\u0304k +\n\u03b1k+1 \u03b2\u0304k +\nx\n\n\u03b1ck+1 +\u03b1z \u0001\nx\n\n+\n\u03b1x\n\n\u0010\n\n(\u03b1 \u2212 1)ck+1 \u03b1k+1 \u03b2\u0304k\n\u0011\u0010\n\u0011\n\u03b1k+1 \u03b2\u0304k\n1\n1\n+ \u03b1x\n+\nck+1 \u03b1z\nx\n\n\u03b1k+1 \u03b2\u0304k\n\u03b1ck+1 +\u03b1z\n\n>0\n\n\u0001\nwhere Rk = Rk \u03b2\u0304 k\u22121 . All properties are independent of Rk and therefore hold for n \u2192 \u221e.\nAssume now k = 1. For any sequence of bounded non-negative real numbers zn , we have by (44) and\nthe continuous mapping theorem [31],\na.s.\nf1 (zn ) \u2212 f \u03041 (zn ) \u2212\u2212\u2212\u2192 0.\n\nn\u2192\u221e\n\n(56)\n\n\f28\n\nThus, properties (i) \u2212 (iii) of f1 (z) also hold for f \u03041 (z). By Definition 2 and Theorem 8, these properties\nimply the uniqueness of positive solutions to the fixed point equations z = f1 (z) and y = f \u03041 (y), and\nhence the uniqueness of solutions to (52) for k = 1. Moreover, note that\n|fk (a) \u2212 fk (b)| \u2264\n\n2 \u03b2\u0304 2 x2\n\u0001\n\u03b1k+1\nk\nkRk \u03b2\u0304 k\u22121 k2 |a \u2212 b|.\nck+1\n\n(57)\n\nHence,\n\u0001\n\u0001\n\u0001\u0001\n\u0001\u0001\n\u01131 x, \u03b2\u0304 1 \u2212 e1 x, \u03b2\u0304 1 = f \u03041 \u01131 x, \u03b2\u0304 1 \u2212 f1 e1 x, \u03b2\u0304 1\n\u0001\u0001\n\u0001\u0001\n\u0001\u0001\n\u0001\u0001\n\u2264 f \u03041 \u01131 x, \u03b2\u0304 1 \u2212 f1 \u01131 x, \u03b2\u0304 1\n+ f1 \u01131 x, \u03b2\u0304 1 \u2212 f1 e1 x, \u03b2\u0304 1\n\u2264 \u000fn +\n\n\u0001\n\u0001\n\u0001\n\u03b122 \u03b2\u030412 x2\nkR1 \u03b2\u03040 k2 \u01131 x, \u03b2\u0304 1 \u2212 e1 x, \u03b2\u0304 1\nc2\n\n(58)\n\n\u0001\na.s.\nfor some sequence of real numbers \u000fn , satisfying \u000fn \u2212\u2212\u2212\u2192 0. By Lemma 6, kR1 \u03b2\u03040 k < M , almost\nn\u2192\u221e\nq\nc2 (1\u2212\u03b4)\nsurely, for some M > 0. Thus, for x \u2264 \u03b12 \u03b2\u0304 2 M 2 and some \u03b4 > 0, we have\n2\n\n1\n\n\u0001\n\n\u01131 x, \u03b2\u0304 1 \u2212 e1 x, \u03b2\u0304 1\n\n\u0001\n\n\u2264\n\n\u000fn a.s.\n\u2212\u2212\u2212\u2192 0.\n\u03b4 n\u2192\u221e\n\n(59)\n\n\u0001\n\u0001\nSince \u01131 x, \u03b2\u0304 1 and e1 x, \u03b2\u0304 1 are (almost surely) bounded on any closed subset of R+ \\ {0} and have\nanalytic continuations for x \u2208 C \\ R\u2212 , we have by Vitali's convergence theorem [49] that the convergence\nholds for any x \u2208 R+ \\ {0}.\nThe last convergence implies by the continuous mapping theorem that,\n\u0001 a.s.\nm1 (x, \u03b2\u0304 1 ) \u2212 m\u03041 x, \u03b2\u0304 1 \u2212\u2212\u2212\u2192 0.\nn\u2192\u221e\n\n(60)\n\nWe now assume k = 2. The last convergence implies f2 (z) \u2192 f \u03042 (z), almost surely. The same steps can\n\u0001 a.s.\ntherefore be applied to show that m2 (x, \u03b2\u0304 1 ) \u2212 m\u03042 x, \u03b2\u0304 1 \u2212\u2212\u2212\u2192 0. This terminates the proof as this\nn\u2192\u221e\n\nprocess can be iterated k times.\nA PPENDIX D\nP ROOF OF T HEOREM 4: F UNDAMENTAL EQUATIONS\nThe proof follows essentially the same steps as the proof of Theorem 2 in [7] and will not be given\nin full detail here. In order to prove the uniqueness of solutions (\u1e21k , gk , \u03b4k ), it is sufficient to show by\nTheorem 8 that the K -variate function h : (x1 , . . . , xK ) 7\u2192 (h1 , . . . , hK ) as defined below, is a standard\ninterference function (see Definition 2). For k = 1, . . . , K , we define\nhk (x1 , . . . , xK ) 7\u2192\n\nNk\nsk,j \u03b4k\n1 X\nnk\n1 + \u1e21k sk,j \u03b4k\nj=1\n\n(61)\n\n\f29\n\nwhere\n\u1e21k =\n\n\u0011\u22121\n1\n1 \u0010\n1\n1\n1\ntr Tk2 Qk Tk2 xk Tk2 Qk Tk2 + Ink\nnk\n\n(62)\n\nand \u03b4k , k = 1, . . . , K, form the unique jointly positive solution to the following fixed-point equations\n!\u22121\nK\nX\n1\nnk \u1e21k xk\n1\n.\n(63)\n\u03b4k =\ntr Rk\nRk + IN\nNk\nNk \u03b4k\n\u03c1\nk=1\n\nThe only difference to [7] is the definition of \u1e21k . In our case, \u1e21k is directly defined as a function of\nxk , whereas b\u0304k in [7] (using their notations) is given as the solution of another fixed point equation.\n\nHowever, the behavior of b\u0304k and \u1e21k as seen as functions of xk is identical. In particular, let xk > x0k > 0\nand denote by \u1e21k and \u1e21k0 the corresponding values of (62), respectively. One can easily verify that the\nfollowing conditions hold:(i) \u1e21k < \u1e21k0 and (ii) xk \u1e21k > x0k \u1e21k0 . The remaining steps are identical to [7]\nand will not be repeated here. By showing h(x1 , . . . , xK ) to be a standard interference function, we have\nproved by Theorem 8 that the following fixed-point algorithm, which iteratively computes\n(t)\n\n(t)\n\nxt+1\n= hk (x1 , . . . , xK ),\nk\n(0)\n\n(64)\n\nk = 1, . . . , K\n\n(0)\n\nfor t \u2265 0 and some set of initial values x1 , . . . , xK , converges as t \u2192 \u221e to the unique fixed point\n(g1 , . . . , gK ).\n\nA PPENDIX E\nP ROOF OF T HEOREM 5: M UTUAL INFORMATION\nThe key idea is that the double-scattering model can be considered as the Kronecker channel model as\nconsidered in Theorem 9 with random correlation matrices. Assume now a Kronecker model, for which\nthe matrices Hk are given as\n1\n1\nHk = \u221a Zk W2,k Tk2\nnk\n\n(65)\n\nwhere Zk \u2208 CN \u00d7Nk is a deterministic matrix and W2,k and Tk are defined as in (17). Further assume\nthat lim supN kZk k < \u221e for all k . Thus, we can apply Theorem 9 to obtain the following deterministic\nequivalent V\u0304N (\u03c1) of IN (\u03c1):\nK\n\nX\n1\nlog det IN + \u03c1\n\u0113k Zk ZH\nV\u0304N (\u03c1) =\nk\nN\nk=1\n\n!\n\nK\nK\n\u0010\nX\n1\n1\u0011\n1\n1 X\n2\n2\n+\nlog det Ink + ek Tk Qk Tk \u2212\nnk ek \u0113k\nN\nN\nk=1\n\nk=1\n\n(66)\n\n\f30\n\nwhere \u0113k , ek , k = 1, . . . , K , are given as the unique solutions to the following equations\n\u0011\u22121\n1\n1 \u0010\n1\n1\n1\ntr Tk2 Qk Tk2 ek Tk2 Qk Tk2 + Ink\n\u0113k =\nnk\n!\u22121\nK\nX\n1\n1\nek =\ntr Zk ZH\n\u0113i Zi ZH\ni + IN\nk\nnk\n\u03c1\n\n(67)\n\ni=1\n\nsuch that \u0113k , ek > 0 for all k . Recall that the matrices Qk are the covariance matrices of the channel inputs\nxk . Thus, the channel model is equivalent to a channel Hk =\n\n1\n\n\u221a1 Zk W2,k T\u0303 2 ,\nk\nnk\n\n1\n\n1\n\n1\n\nwhere T\u0303k2 = T 2 Qk2 ,\n\nwith uncorrelated channel inputs x\u0303k \u223c CN (0, Ink ).\nFor the double-scattering channel, the matrices Zk are random and defined as\n1\n1\n1\nZk = \u221a Rk2 W1,k Sk2 .\nNk\n\n(68)\n\nLet (\u03a9, F, P ) be the probability space generating the random sequences of matrices (W1,k (\u03c9))N \u22651 . There\nexists A \u2282 \u03a9 with P (A) = 1, such that for each \u03c9 \u2208 A, we have lim supN kZk (\u03c9)Zk (\u03c9)H k < \u221e ([46]).\nThus, for each of these \u03c9 , the matrices Zk ZH\nk satisfy the criteria of the correlation matrices of Theorem 9.\nLet (\u03a90 , F 0 , P 0 ) the probability space generating the matrices W2,k . Thus, for every \u03c9 \u2208 A, there exist a\nA0 (\u03c9) \u2282 \u03a90 with P 0 (A0 ) = 1, such that for all \u03c9 0 \u2208 A0 (\u03c9), V\u0304N (\u03c1) is a deterministic equivalent of IN (\u03c1).\n\nDenote by (\u03a9 \u00d7 \u03a90 , F \u00d7 F 0 , Q) the product space generating the matrices W1,k (\u03c9) and W1,k (\u03c9 0 ) and\ndenote by B \u2282 \u03a9 \u00d7 \u03a90 the space of all tuples (\u03c9, \u03c9 0 ), such that \u03c9 \u2208 A and \u03c9 0 \u2208 A0 (\u03c9). By the Fubini\ntheorem, we have Q(B) = 1, which proves that V\u0304N (\u03c1) \u2212 In (\u03c1) \u2192 0, almost surely. However, V\u0304N (\u03c1)\nis a random quantity, which depends on the matrices Zk . Therefore, we will need to obtain an iterative\ndeterministic equivalent I \u0304N (\u03c1) of V\u0304N (\u03c1).\nThe first step is to replace the fixed-point equations (67) that depend on Zk by deterministic ones. Let\nus define the quantities \u0113k,i,j , ek,i,j , for i \u2208 {1, . . . , K}, j \u2208 {1, . . . , Nk }, which are given as the unique\nsolutions to the following set of fixed-point equations:\n\u0010\n\u0011\u22121\n1\ntr T\u0303k ek,i,j T\u0303k + Ink\n\u0113k,i,j =\nnk\nek,i,j\n\n1\n=\ntr Zk,i,j ZH\nk,i,j\nnk\n\nK\nX\n\n\u0113`,i,j Z`,i,j ZH\n`,i,j\n\n`=1\n\n1\n+ IN\n\u03c1\n\n!\u22121\n(69)\n\nwhere\nZk,i,j =\n\n\uf8f1\n\uf8f4\n\uf8f2Zk\n\n,\n\ni 6= k\n\n\uf8f4\n\uf8f3[zk,1 * * * zk,j\u22121 zk,j+1 . . . zk,N ]\nk\n\n,\n\ni=k\n\n.\n\n\f31\n\nObviously, \u0113k,i,j and ek,i,j are independent of the vector zi,j . In addition, we define\nZ = max lim supkZk ZH\nk k,\nk\n\nT = max lim supkT\u0303k k,\nk\n\nN\n\nn = min nk ,\n\nc=\n\nk\n\nN\n\nN\nn\n\nand\n\u03b1i,j = max |ek,i,j \u2212 ek | ,\n\n\u1fb1i,j = max |\u0113k,i,j \u2212 \u0113k | .\n\nk\n\nk\n\nThus, we have for N large,\n|\u0113k,i,j \u2212 \u0113k | =\n\n\u0010\n\u0011\u22121 \u0010\n\u0011\u0010\n\u0011\u22121\n1\ntr T\u0303k ek,i,j T\u0303k + Ink\n(ek \u2212 ek,i,j )T\u0303k ek T\u0303k + Ink\nnk\n(70)\n\n\u2264 \u03b1i,j T 2 .\n\nSince the right-hand side (RHS) of the last inequality is independent of k , we have\n(71)\n\n\u1fb1i,j \u2264 \u03b1i,j T 2 .\n\nOn the other hand, for i 6= k , we have for N sufficiently large,\n|ek,i,j \u2212 ek |\n1\n=\ntr Zk ZH\nk\nnk\n\nK\nX\n\n\u2264 cK\u03c12 Z 2 \u1fb1i,j +\n\u2264 cK\u03c12 Z 2 \u1fb1i,j +\n\n\u0113`,i,j Z`,i,j ZH\n`,i,j\n\n`=1\n\n\u0113i,i,j H\nzi,j\nn\n\nK\nX\n`=1\n\n1\n+ IN\n\u03c1\n\n!\u22121\n\n1\n\u0113` Z` ZH\n` + IN\n\u03c1\n\nK\nX\n\n!\n(\u0113` \u2212\n\n\u0113`,i,j )Z` ZH\n`\n\n+\n\n\u0113i,i,j zi,j zH\ni,j\n\nK\nX\n\n`=1\n\n`=1\n\n!\u22121\n\n!\u22121\n\nK\nX\n\nZk ZH\nk\n\n`=1\n\n1\n\u0113`,i,j Z`,i,j ZH\n`,i,j + IN\n\u03c1\n\n\u03c12 Z 2 T\n\n\u0113` Z` ZH\n`\n\n1\n+ IN\n\u03c1\n\nzi,j\n\n(72)\n\nn\n\n2\nwhere the last inequality is due to \u0113k,i,j \u2264 T and zH\ni,j Azi,j \u2264 kzi,j k kAk \u2264 ZkAk, for any matrix A.\n\nSimilarly, one can show that\n|ek,k,j \u2212 ek | = cK\u03c12 Z 2 \u1fb1k,j +\n\n\u03c1Z\n\u03c12 Z 2 T\n+\n.\nn\nn\n\n(73)\n\nIt follows from (72), (73) and (71), that\n\u03c12 Z 2 T\n\u03c1Z\n\u03c12 Z 2 T\n\u03c1Z\n\u03b1i,j \u2264 cK\u03c12 Z 2 \u1fb1i,j +\n+\n\u2264 cK\u03c12 Z 2 T 2 \u03b1i,j +\n+\n.\nn\nn\nn\nn\nq\n1\u2212\u000f\nNow, for any \u03c1 \u2264 cKZ\n2 T 2 and \u000f > 0, we have\n\u03b1i,j \u2264\n\n\u03c1Z\n(1 + \u03c1ZT )\n\u000fn\n\n,\n\n\u1fb1i,j \u2264\n\n\u03c1ZT 2\n(1 + \u03c1ZT ) .\n\u000fn\n\n(74)\n\n!\u22121\n\n\f32\n2\n\n\u03c1ZT\nLet \u03bc = max{ \u03c1Z\n\u000f (1 + \u03c1ZT ) , \u000f (1 + \u03c1ZT )}, then we finally have\n\n\u03b1i,j \u2264\n\n\u03bc\nn\n\n\u1fb1i,j \u2264\n\n,\n\n\u03bc\n.\nn\n\n(75)\n\nThe last result establishes that for sufficiently small \u03c1, the differences between the solutions (\u0113k,i,j , ek,i,j )\nto (69) and the solutions (\u0113k , ek ) to (67) are uniformly bounded by \u03bc and vanish as n \u2192 \u221e. Moreover,\nek and ek,i,j have an analytic continuation on z = \u2212 \u03c11 \u2208 C \\ R+ and are uniformly bounded on all\n\nclosed subsets of z \u2208 C \\ R+ . Thus, in particular for \u03c1 \u2208 R+ \\ {0} and all k, i, j , we have by the Vitali\nconvergence theorem [49]\nand hence\n\nek \u2212 ek,i,j \u2212\u2212\u2212\u2212\u2192 0\nN \u2192\u221e\n\n\u0113k \u2212 \u0113k,i,j \u2212\u2212\u2212\u2212\u2192 0.\nN \u2192\u221e\n\n(76)\n\nAs a consequence of (76), we can now write\nNk\n1 X\nek =\nzH\nk,j\nnk\nj=1\n\nK\nX\ni=1\n\n1\n\u0113i Zi ZH\ni + IN\n\u03c1\n\n!\u22121\nzk,j\n\n!\u22121\n1\n\u0113i,k,j Zi ZH\nzk,j\ni + IN\n\u03c1\nj=1\ni=1\n\u0011\u22121\n\u0010P\nK\nH\nH \u2212 \u0113\nH + 1I\nNk\nzk,j\nz\n\u0113\nZ\nZ\nz\nz\nX\ni\nN\ni,k,j\nk,k,j\nk,j\ni\ni=1\nk,j\nk,j\n\u03c1\n(b) 1\n=\n\u0010P\n\u0011\u22121\nnk\nK\nH \u2212 \u0113\nH + 1I\nj=1 1 + \u0113k,k,j zH\n\u0113\nZ\nZ\nz\nz\nzk,j\ni\nN\ni,j,k\nk,k,j\nk,j\ni=1\ni\nk,j\nk,j\n\u03c1\n\u0010P\n\u0011\u22121\nsk,j\nK\nH + 1I\nNk\ntr\nR\n\u0113\nZ\nZ\ni\nN\nk\ni,j,k\ni\n(c) 1 X\ni=1\nNk\n\u03c1\n\u0010\n\u0010P\n\u0011\u22121\nnk\nsk,j \u0113k,k,j\nK\nH + 1I\nj=1 1 +\ntr\nR\n\u0113\nZ\nZ\ni\nN\nk\ni,j,k\ni=1\ni\nNk\n\u03c1\n\u0010P\n\u0011\u22121\nsk,j\nK\n1\nH\nNk\n(d) 1 X\ni=1 \u0113i Zi Zi + \u03c1 IN\nNk tr Rk\n\u0010\n\u0010P\n\u0011\u22121\nnk\nsk,j \u0113k\nK\nH + 1I\nj=1 1 +\ntr\nR\n\u0113\nZ\nZ\ni\ni\nN\nk\ni=1\ni\nNk\n\u03c1\nNk\n1 X\n\u0010\nzH\nk,j\nnk\n\n(a)\n\nK\nX\n\nwhere (a) follows from (76) since\n!\u22121\nK\nX\n1\nH\nH\nzk,j\n\u0113i Zi Zi + IN\nzk,j \u2212 zH\nk,j\n\u03c1\ni=1\n\nK\nX\n\n\u0113i,k,j Zi ZH\ni\n\ni=1\n\n1\n+ IN\n\u03c1\n\n!\u22121\nzk,j \u2264\n\n(77)\n\n\u03bcKZ\u03c12\n\u2212\u2212\u2212\u2212\u2192 0, (78)\nN \u2192\u221e\nn\n\n(b) is due to Lemma 3, (c) is a consequence of Lemmas 2 and 4 and (d) is obtained by applying (76) a sec\u0010P\n\u0011\u22121\nK\nH + 1I\n\u0113\nZ\nZ\nond time. Next, we would like to find deterministic equivalents of the terms N1k tr Rk\n.\ni\ni\nN\ni\ni=1\n\u03c1\n\nWe cannot directly apply Theorem 9 at this point since the \u0113k are defined as functions of Zk . However,\nbased on the relations (75) and (78), Theorem 9 (see [14, Theorem 1]) can be shown to hold also for\nthe matrix model under study. Thus,\n1\ntr Rk\nNk\n\nK\nX\ni=1\n\n\u0113i Zi ZH\ni\n\n1\n+ IN\n\u03c1\n\n!\u22121\n\u0010 fk\n\n(79)\n\n\f33\n\nwhere fk for k \u2208 {1, . . . , K} are defined as the unique solution to the following fixed-point equations\nNk\nsk,j \u0113k\n1 X\nf \u0304k =\nNk\n1 + \u0113k sk,j fk\n\n(80)\n\nj=1\n\n1\nfk =\ntr Rk\nNk\n\nK\nX\ni=1\n\n1\nf \u0304i Ri + IN\n\u03c1\n\n!\u22121\n(81)\n\nsuch that fk > 0 for all k . Replacing (80) in (81) leads to\n\uf8eb\n\uf8f6\u22121\nNi\nK\nX\nX\ns\n1\n1\n\u0113\ni,j\ni\nfk =\nRi\n+ IN \uf8f8 .\ntr Rk \uf8ed\nNk\nNi\n1 + si,j \u0113i fi \u03c1\n\n(82)\n\nj=1\n\ni=1\n\nThus,\nek =\n\nNk\nsk,j fk\n1 X\n+ \u000fk\nnk\n1 + sk,j \u0113k fk\n\n(83)\n\nj=1\n\na.s.\n\nwhere \u000fk is a sequence of random variables, satisfying \u000fk \u2212\u2212\u2212\u2212\u2192 0. Consider now the following system\nN \u2192\u221e\n\nof equations\n\u0113k =\n\n\u0010\n\u0011\u22121\n1\ntr T\u0303k ek T\u0303k + Ink\nnk\n\nNk\nsk,j fk\n1 X\n+ \u000fk\nnk\n1 + sk,j \u0113k fk\nj=1\n\uf8eb\n\uf8f6\u22121\nNi\nK\nX\nX\nsi,j\n\u0113i\n1\n1\ntr Rk \uf8ed\nRi\n+ IN \uf8f8\nfk =\nNk\nNi\n1 + si,j \u0113i fi \u03c1\n\nek =\n\ni=1\n\nj=1\n\nand its deterministic counterpart\n\u0010\n\u0011\u22121\n1\n\u1e21k =\ntr T\u0303k gk T\u0303k + Ink\nnk\nNk\nsk,j \u03b4k\n1 X\nnk\n1 + sk,j \u1e21k \u03b4k\nj=1\n\uf8eb\n\uf8f6\u22121\nNi\nK\nX\nX\ns\n1\n\u1e21\n1\n1\ni,j\ni\n\u03b4k =\ntr Rk \uf8ed\nRi\n+ IN \uf8f8 =\ntr Rk\nNk\nNi\n1 + si,j \u1e21i \u03b4i \u03c1\nNk\n\ngk =\n\ni=1\n\nj=1\n\nK\nX\nni \u1e21i gi\n1\nRi + IN\nNi \u03b4i\n\u03c1\n\n!\u22121\n\ni=1\n\nDefine the quantities:\n\u03b31 = max |ek \u2212 gk | ,\nk\n\n\u03b32 = max |\u0113k \u2212 g \u0304k | ,\nk\n\n\u03b33 = max |fk \u2212 \u03b4k | ,\nk\n\n\u000f = max |\u000fk | .\nk\n\nStraight-forward calculations lead to the following bounds:\n\u03b31 \u2264 cS\u03b33 + cS 2 R2 \u03c12 \u03b32 + \u000f,\n\n\u03b32 \u2264 \u03b31 T 2 ,\n\n\u03b33 \u2264 KSR2 \u03c12 \u03b32 + KS 2 R2 T 2 \u03c12 \u03b31 .\n\n.\n\n\f34\na.s.\n\nCombining these results and using the fact that \u000f \u2212\u2212\u2212\u2212\u2192 0 yields for \u03c1 sufficiently small,\nN \u2192\u221e\n\na.s.\n\n(84)\n\n\u03b31 , \u03b32 , \u03b33 \u2212\u2212\u2212\u2212\u2192 0.\nN \u2192\u221e\n\nSince ek , gk , \u0113k , \u1e21k , fk , \u03b4k are all (almost surely) bounded for \u03c1 in any closed subset of R+ \\ {0} and\nhave analytic continuations for \u03c1 \u2208 C \\ R\u2212 , we have by Vitali's convergence theorem [49] that (84) holds\nfor any \u03c1 \u2208 R+ \\ {0}.\nComing now back to V\u0304N (\u03c1) as given in (66), we have from the continuous mapping theorem [31] that\nK\n\u0010\n\u0011\ni h\n\u0010\n\u0011\ni\n1 Xh\na.s.\nlog det Ink + ek T\u0303k \u2212 nk ek \u0113k \u2212 log det Ink + gk T\u0303k \u2212 nk gk \u1e21k \u2212\u2212\u2212\u2212\u2192 0.\nN \u2192\u221e\nN\nk=1\nP\na.s.\nH\nMoreover, since k K\n\u2212\u2212\u2212\u2192 0, we have\nk=1 (\u0113k \u2212 \u1e21k ) Zk Zk k \u2212\nN \u2192\u221e\n!\n!\nK\nK\nX\nX\n1\n1\na.s.\nH\nH\n\u0113k Zk Zk \u2212\n\u1e21k Zk Zk \u2212\u2212\u2212\u2212\u2192 0.\nlog det IN + \u03c1\nlog det IN + \u03c1\nN \u2192\u221e\nN\nN\nk=1\n\n(85)\n\n(86)\n\nk=1\n\nApplying Theorem 9 to the last term yields\n!\nK\nX\n1\nH\nlog det IN + \u03c1\n\u1e21k Zk Zk\nN\nk=1\n!\nK\nK\nX\n1\nnk \u1e21k gk\n1 X\na.s.\n\u2212\nlog det IN + \u03c1\nRk \u2212\nlog det (INk + \u1e21k \u03b4k Sk ) + nk \u1e21k gk \u2212\u2212\u2212\u2212\u2192 0. (87)\nN \u2192\u221e\nN\nNk \u03b4k\nN\nk=1\n\nk=1\n\nCombining (85) and (87) finally leads to\na.s.\nV\u0304N (\u03c1) \u2212 I \u0304N (\u03c1) \u2212\u2212\u2212\u2212\u2192 0\n\n(88)\n\nN \u2192\u221e\n\nwhere\nK\n\nX nk \u1e21k gk\n1\nI \u0304N (\u03c1) =\nlog det IN + \u03c1\nRk\nN\nNk \u03b4k\nk=1\n\n+\n\n!\n+\n\nK\n1 X\nlog det (INk + \u1e21k \u03b4k Sk ) \u2212 nk \u1e21k gk\nN\nk=1\n\nK\n\u0010\n\u0011\n1 X\nlog det Ink + gk T\u0303k \u2212 nk gk \u1e21k .\nN\n\n(89)\n\nk=1\n\nThis concludes the proof of part (i).\nIn order to show the convergence in the mean (part (ii)), we will pursue the same approach as in [5],\n[7]. Define the following functions:\n1\nmN (z) = tr\nN\n\nK\nX\n\n!\u22121\nHk HH\nk \u2212 zIN\n\nk=1\n\n,\n\n1\nm\u0304N (z) = tr\nN\n\nK\nX\nnk \u1e21k gk\nRk \u2212 zIN\nNk \u03b4k\n\n!\u22121\n.\n\nk=1\n\nOne can show that\nE [IN (\u03c1)] \u2212 I \u0304N (\u03c1) =\n\n\u221e \u0012\u0014\n\nZ\n1\n\u03c1\n\n\u0015 \u0014\n\u0015\u0013\n1\n1\n\u2212 E [mN (\u2212\u03c9)] \u2212\n\u2212 m\u0304N (\u2212\u03c9) d\u03c9.\n\u03c9\n\u03c9\n\n(90)\n\n\f35\n\nSince both mN (\u03c9) and m\u0304N (\u03c9) are uniformly bounded by\n\n1\n\u03c9,\n\nit follows from dominated convergence\n\narguments, Theorem 9 and (84) that, for all \u03c9 > 0,\n\u0014\n\u0015 \u0014\n\u0015\n1\n1\n\u2212 E [mN (\u2212\u03c9)] \u2212\n\u2212 m\u0304N (\u2212\u03c9) \u2192 0.\n\u03c9\n\u03c9\n\n(91)\n\nMoreover,\n\u0015 \u0014\n\u0015\n\u0015\n\u0015\n\u0014\n\u0014\n\u0014\n1\n1\n1\n1\n\u2212 E [mN (\u2212\u03c9)] \u2212\n\u2212 m\u0304N (\u2212\u03c9) \u2264\n\u2212 E [mN (\u2212\u03c9)] +\n\u2212 m\u0304N (\u2212\u03c9)\n\u03c9\n\u03c9\n\u03c9\n\u03c9\n\"K\n#\n!!\nK\nX\nX\n1\n1\nnk \u1e21k gk\n1\nH\ntr E\nHk Hk + tr\nRk\n\u2264 2\n\u03c9\nN\nN\nNk \u03b4k\nk=1\n\nk=1\n\n2KRST\n\u2264\n\u03c92\n\n(92)\n\nwhere R = maxk lim supkRk k, S = maxk lim supkSk k, T = maxk lim supkTk Qk k. Since\n\n2KRST\n\u03c92\n\nis\n\nfinite and integrable over [ \u03c11 , \u221e), it follows from the dominated convergence theorem that\nE [IN (\u03c1)] \u2212 I \u0304N (\u03c1) \u2212\u2212\u2212\u2212\u2192 0.\n\n(93)\n\nN \u2192\u221e\n\nA PPENDIX F\nP ROOF OF T HEOREM 6: O PTIMAL POWER ALLOCATION\nThe proof follows closely those of [25, Proposition 5] and [14, Proposition 3].\nWe first recall the following property of concave functions (see e.g. [50]):\nProperty 1: A function f (Q1 , . . . , QK ) is strictly concave in the Hermitian nonnegative matrices\nQ1 , . . . , QK , if and only if, for any couples (Q1a , Q1b ) , . . . , (QKa , QKb ) of Hermitian nonnegative\n\nmatrices, the function\n\u03c6(\u03bb) = f (\u03bbQ1a + (1 \u2212 \u03bb)Q1b , . . . , \u03bbQKa + (1 \u2212 \u03bb)QKb ) ,\n\n\u03bb \u2208 [0, 1]\n\nis strictly concave.\nConsider now I \u0304N (\u03c1) seen as a function of \u03bb for Qk = \u03bbQka \u2212 (1 \u2212 \u03bb)Qkb , where Qka , Qkb are\nHermitian nonnegative definite matrices, for k = 1, . . . , K . Thus, by the chain rule of differentiation,\nK\ndI \u0304N (\u03c1)\n\u2202 I \u0304N (\u03c1) X \u2202 I \u0304N (\u03c1) \u2202\u1e21k\n\u2202 I \u0304N (\u03c1) \u2202gk\n\u2202 I \u0304N (\u03c1) \u2202\u03b4\n=\n+\n+\n+\n.\nd\u03bb\n\u2202\u03bb\n\u2202\u1e21k \u2202\u03bb\n\u2202gk \u2202\u03bb\n\u2202\u03b4k \u2202\u03bb\n\n(94)\n\nk=1\n\nOne can verify that the partial derivatives of I \u0304N (\u03c1) with respect to gk , \u1e21k , \u03b4k , respectively, satisfy\n\u2202 I \u0304N (\u03c1)\n\u2202 I \u0304N (\u03c1)\n\u2202 I \u0304N (\u03c1)\n=\n=\n= 0,\n\u2202gk\n\u2202\u1e21k\n\u2202\u03b4k\n\n(95)\n\n\f36\n\ndue to the defining relation (21). Thus,\nK\n1 \u0010\n1\n1 \u0011\u22121\n1\n\u2202 I \u0304N (\u03c1) X 1\ndI \u0304N (\u03c1)\n=\n=\ntr Tk2 Ink + gk Tk2 (\u03bbQka + (1 \u2212 \u03bb)Qkb ) Tk2\nTk2 (Qka \u2212 Qkb ) . (96)\nd\u03bb\n\u2202\u03bb\nN\nk=1\n\nThe second derivative therefore reads\n\uf8ee\nK\n\nX 1\nd2 I \u0304N (\u03c1)\n=\u2212\ntr\n2\nd\u03bb\nN\nk=1\n\n\uf8f92\n\n\uf8fa\n\uf8ef 1\u0010\n1\n1 \u0011\u22121\n1\n\uf8ef 2\n\uf8fa\nTk2 (Qka \u2212 Qkb )\uf8fa\n\uf8efTk Ink + gk Tk2 (\u03bbQka + (1 \u2212 \u03bb)Qkb ) Tk2\n|\n{z\n}\n\uf8fb\n\uf8f0|\n{z\n}\n4\n\n(97)\n\n= Bk\n\n4\n\n= Ak\n\nwhere Ak are Hermitian nonnegative definite and Bk are Hermitian. Let Ak = Uk Dk UH\nk be the eigenvalue decomposition of Ak , where Uk \u2208 Cnk \u00d7nk are unitary matrices and Dk = diag (dk,1 , . . . , dk,nk ) \u0017\n0. Moreover, denote Zk = Bk Uk = [zk,1 . . . zk,nk ]. Then,\nnk\n1\n1\n1\n1 X\n2\nH\nH\ndk,j zH\ntr [Ak Bk ] = tr Dk U Bk Ak Bk U = tr Dk Zk Ak Zk =\nk,j Ak zk,j \u2265 0.\nN\nN\nN\nN\n\n(98)\n\nj=1\n\nIf Tk \u001f 0, or equivalently, if Tk is invertible, we have Ak \u001f 0 and (98) holds with strict inequality for\nQka 6= Qkb . Thus, if any of the matrices Tk is invertible and Qka 6= Qkb , we have\nK\nX\n1\ntr [Ak Bk ]2 > 0\nN\n\n(99)\n\nk=1\n\nand hence\n\nd2 I \u0304N (\u03c1)\nd\u03bb2\n\n< 0. Thus, I \u0304N (\u03c1) is strictly concave in the matrices Qk . Due to (95) it is then sufficient\n\nto maximize\n\u0010\n1\u0011\n1\nlog det Ink + gk Tk2 Qk Tk2\nwith respect to Qk and with the constraint\n\n1\nnk tr Qk\n\n(100)\n\n\u2264 Pk . The solution to this problem is well-known\n\n[41] and given by the water-filling solution stated in the theorem. However, since gk depends on Qk ,\nthis solution must be computed iteratively by Algorithm 1.\nA PPENDIX G\nP ROOF OF T HEOREM 7: SINR OF THE MMSE DETECTOR\nSimilar to the proof of Theorem 5, let us consider the matrix model\n1\n1\n1\nHk = \u221a Zk W2,k Tk2 Qk2\nnk\n\n(101)\n\n1\n1\n1\nZk = \u221a Rk2 Wk,1 Sk2 .\nNk\n\n(102)\n\nwhere\n\n\f37\n\nThen,\nN\n\u03b3k,j\n\n1 H\n= pk,j tk,j w2,k,j\nZH\nk\nnk\n\nK\nX\ni=1\n\n1\n1\nZk w2,k,j w2,k,j ZH\nHi HH\ni \u2212 pk,j tk,j\nk + IN\nnk\n\u03c1\n\n!\u22121\nZk w2,k,j .\n\n(103)\n\nIt was shown in the proof of Theorem 5 that, almost surely, lim supN kZk ZH\nk k < 0. From the Fubini\ntheorem, Lemma 2 and Lemma 4, we therefore have\n!\nK\nX\n1\na.s\nN\n\u03b3k,j\n\u2212 pk,j tk,j tr Zk ZH\n\u2212\u2212\u2212\u2212\u2192 0.\nHi HH\ni + \u03c1Ink\nk\nN \u2192\u221e\nnk\n\n(104)\n\ni=1\n\nApplying Theorem 9 (i) leads to\nN\n\u03b3k,j\n\n1\n\u2212 pk,j tk,j tr Zk ZH\nk\nnk\n\nK\nX\n\n!\u22121\n\u0113i Zi ZH\ni\n\n+ \u03c1Ink\n\ni=1\n\na.s\n\n\u2212\u2212\u2212\u2212\u2192 0\nN \u2192\u221e\n\nwhere \u0113i are given as the unique solutions to (67). Notice now from (67) that\n!\u22121\nK\nX\n1\nH\nH\nek =\ntr Zk Zk\n\u0113i Zi Zi + \u03c1Ink\nnk\n\n(105)\n\n(106)\n\ni=1\n\na.s\n\nand that maxk |ek \u2212 gk | \u2212\u2212\u2212\u2212\u2192 0 by (84). This finally implies\nN \u2192\u221e\n\na.s\n\nN\n\u03b3k,j\n\u2212 pk,j tk,j gk \u2212\u2212\u2212\u2212\u2192 0.\nN \u2192\u221e\n\n(107)\n\nA PPENDIX H\nP ROOF OF C OROLLARY 2: S UM - RATE WITH MMSE DECODING\nPart (i) is a simple consequence of Theorem 7 and the continuous mapping theorem.\nFor Part (ii), first notice that RN (\u03c1) \u2264 IN (\u03c1) and R\u0304N (\u03c1) \u2264 I \u0304N (\u03c1). Thus,\nK nk\n1 XX\n4\nlog (1 + pk,j tk,j gk ) \u2264 IN (\u03c1) + I \u0304N (\u03c1) = \u03c6N (\u03c1).\nRN (\u03c1) \u2212\nN\n\n(108)\n\nk=1 j=1\n\nSince E [\u03c6N (\u03c1)] < \u221e by Theorem 5 (ii), it follows from dominated convergence arguments that\nE [RN (\u03c1)] \u2212 R\u0304N (\u03c1) \u2212\u2212\u2212\u2212\u2192 0.\nN \u2192\u221e\n\n(109)\n\nA PPENDIX I\nP ROOF OF C OROLLARY 3: R AYLEIGH PRODUCT CHANNEL\nUnder the assumptions of the corollary, the fundamental equations in Theorem 4 reduce to\n1\n1+g\n\u03b4\nS\ng=\nN 1 + \u1e21\u03b4\n1\n\u03b4 = \u1e21g\nS 1\nK\u03b4 +N\n\u03c1\n\n\u1e21 =\n\n(110)\n(111)\n(112)\n\n\f38\n\nFrom (110), we have\ng=\n\n1 \u2212 \u1e21\n.\n\u1e21\n\n(113)\n\nSolving (111) for \u03b4 and replacing g by (113) yields\n\u03b4=\n\n1 \u2212 \u1e21\n\u0001.\nS\n\u1e21 \u1e21 + N\n\u22121\n\n(114)\n\nSolving (112) for \u03b4 and replacing g by (113) leads to\n\u03b4=\n\n1 \u2212 K(1 \u2212 \u1e21)\nS 1\nN \u03c1\n\n(115)\n\n.\n\nEquating (114) and (115) and rearranging the terms as a polynomial in \u1e21 finally yields\n\u0012\n\u0013\n\u0012\n\u0012\n\u0013\u0013\n1\n1\nS\nS\n1\nS 1\nS\n3\n2\n\u1e21 \u2212 \u1e21 2 \u2212\n\u2212\n\u2212\n+\n= 0.\n+ \u1e21 1 \u2212\n1+\n\u2212\nN\nK\nN\nK\nNK\n\u03c1\nNK \u03c1\n\n(116)\n\nBy Theorem 4, only one of the roots of this polynomial satisfies \u1e21, g, \u03b4 > 0. Now, (113) implies \u1e21 < 1,\n\u0002\n\u0003 \u0001\nS\nS\n(115) implies \u1e21 > 1 \u2212 K1 . Hence \u1e21 \u2208 1 \u2212 min K1 , N\n(114) implies \u1e21 > 1 \u2212 N\n,1 .\nSimilarly, I \u0304N (\u03c1) reduces under the assumptions of the corollary to\n\u0012\n\u0013\nN K \u1e21g\nKS\n \u0304\nIN (\u03c1) = log 1 + \u03c1\n+\nlog (1 + \u1e21\u03b4) + K log (1 + g) \u2212 2K \u1e21g.\nS \u03b4\nN\nReplacing\n\ng\n\u03b4\n\nby \u1e21 +\n\nS\nN\n\n(117)\n\n\u2212 1 in the first term, \u03b4 by (114) in the second term, g by (113) in the third term\n\nand \u1e21g by (1 \u2212 \u1e21) in the last term leads to the desired result.\nN =p t g =\nThe simplification of Theorem 7 is immediate since \u03b3\u0304kj\nk,j k,j k\n\n1\u2212\u1e21\n\u1e21\n\nby (113).\n\n\f39\n\nA PPENDIX J\nM ATLAB CODE RELATED TO THE MULTIHOP AF MIMO RELAY CHANNEL\nA. Code for Corollary 1: corollary1.m\nfunction I_k = corollary1(k,K,a,rho,c)\n% Compute deterministic equivalent I_k of the asymptotic mutual information\n% Input parameters :\n% k\n\n: denotes which function I_k to compute\n\n% K\n\n: total number number of hops\n\n% a\n\n= [alpha_1,...,alpha_{K}] : vector containing the path loss factors\n\n% rho = [rho_0,...,rho_{K-1}]\n\n: vector containing the power budgets rho_k\n\n% c\n\n: vector containing the matrix dimension ratios\n\n= [c_1,...,c_K]\n\n% Calculate asymptotic power normalization factors (Lemma 1)\nb\n\n= zeros(1,k);\n\nb(1) = rho(1);\nfor i=2:k\nb(i) = rho(i) / (1+a(i-1)*rho(i-1));\nend\n% Calculate capacity\nI_k = 1/K*(theorem2(k,1,a,b,c) - theorem2(k,1,a,[0,b(2:end)],c));\nend\n\nB. Code for Theorem 2: theorem2.m\nfunction J = theorem2(k,x,a,b,c)\n% Recursively computes deterministic equivalent of J_k\n% Input parameters :\n% k\n\n: denotes which function J_k to compute\n\n% x\n\n: argument of J_k\n\n% a = [alpha_1,...,alpha_{k}] : vector containing the path loss factors\n% b = [beta_0,...,beta_{k-1}] : power normalization factors\n% c = [c_1,...,c_K]\n\n: vector containing the matrix dimension ratios\n\nif (k==1) % J_1 is given in closed form\n[ \u0303,e] = theorem3(k-1,x,a,b,c);\nJ\nelse\n\n= c(k)*log(1 + x*a(k)*b(k)/(c(k)+e)) + log(1+e/c(k)) - e/(c(k)+e);\n% J_k, k>1, must be computed recursively\n\n[ \u0303,e] = theorem3(k-1,x,a,b,c);\nJ\n\n= c(k)*theorem2(k-1,x*a(k)*b(k)/(c(k)+x*a(k)*b(k) + e),a,b,c)...\n+ c(k)*log(1 + x*a(k)*b(k)/(c(k)+e)) + log(1 + e/c(k)) - e/(c(k)+e);\n\nend\nend\n\n\f40\n\nC. Code for Theorem 3: theorem3.m\nfunction [m,e] = theorem3(k,x,a,b,c)\n% Recursively computes the quantities e_k\n% Input parameters :\n% k\n\n: denotes which function e_k to compute\n\n% x\n\n: argument of e_k\n\n% a = [alpha_1,...,alpha_{k}] : vector containing the path loss factors\n% b = [beta_0,...,beta_{k}]\n\n: power normalization factors\n\n% c = [c_1,...,c_K]\n\n: vector containing the matrix dimension ratios\n\nif (k==0) % For k=0, e_o and m_0 are given in closed form\ne = -(x*a(1)*b(1)*(1-c(1))+c(1))/2 + sqrt((x*a(1)*b(1)*(1-c(1))+c(1))\u02c62...\n+ 4*x*a(1)*b(1)*c(1)\u02c62)/2;\nm = c(1) / (a(1)*b(1)/(c(1)+e)+1/x) + (1-c(1))*x;\nelse\n\n% For k>0, e_k is given as the solution to a fixed point equation\ne\n\n= 0;\n\neold = 1;\nwhile abs(e-eold)>1e-6\n\n% the error tolerance 1e-6 can be changed\n\neold = e;\ne = c(k+1)*(c(k+1)+eold) - c(k+1)*(c(k+1)+eold)\u02c62/(x*a(k+1)*b(k+1))...\n* theorem3(k-1,x*a(k+1)*b(k+1)/(c(k+1)+x*a(k+1)*b(k+1)+eold),a,b,c);\nend\nm = x*c(k+1)/(c(k+1)+e);\nend\nend\n\nR EFERENCES\n[1] D. N. C. Tse and S. V. Hanly, \"Linear multiuser receivers: effective interference, effective bandwidth and user capacity,\"\nIEEE Trans. Inf. Theory, vol. 45, no. 2, pp. 641\u2013657, Feb. 1999.\n[2] A. M. Tulino and S. Verd\u00fa, \"Random matrix theory and wireless communications,\" Foundations and Trends in\nCommunications and Information Theory, vol. 1, no. 1, 2004.\n[3] R. Couillet and M. Debbah, Random matrix methods for wireless communications, 1st ed. New York, NY, USA: Cambridge\nUniversity Press, 2011.\n[4] I. E. Telatar, \"Capacity of multi-antenna Gaussian channels,\" European Transactions on Telecommunications, vol. 10, no. 6,\npp. 585\u2013595, Feb. 1999.\n[5] W. Hachem, P. Loubaton, and J. Najim, \"Deterministic equivalents for certain functionals of large random matrices,\" Annals\nof Applied Probability, vol. 17, no. 3, pp. 875\u2013930, 2007.\n[6] M. Debbah, P. Loubaton, and M. de Courville, \"The spectral efficiency of linear precoders,\" in (ITW'03), Paris, France,\nMar. 2003, pp. 90\u201393.\n[7] R. Couillet, J. Hoydis, and M. Debbah, \"Random beamforming over quasi-static and fading channels: A deterministic\nequivalent approach,\" IEEE Trans. Inf. Theory, 2011, submitted. [Online]. Available: http://arxiv.org/pdf/1011.3717v2\n\n\f41\n\n[8] V. K. Nguyen and J. S. Evans, \"Multiuser transmit beamforming via regularized channel inversion: A large system analysis,\"\nin Proc. IEEE Global Communications Conference (Globecom08), New Orleans, LO, US, Dec. 2008, pp. 1\u20134.\n[9] S. Wagner, R. Couillet, M. Debbah, and D. T. M. Slock, \"Large system analysis of linear precoding in MISO broadcast\nchannels with limited feedback,\" IEEE Trans. Inf. Theory, 2011. [Online]. Available: http://arxiv.org/abs/0906.3682\n[10] R. Zakhour and S. Hanly, \"Large system analysis of base station cooperation on the downlink,\" in Proc. 48th Annual\nAllerton Conference on Communication, Control, and Computing, Urbana-Champaign, IL, US, Oct. 2010, pp. 270 \u2013277.\n[11] H. Huh, G. Caire, S.-H. Moon, and I. Lee, \"Multi-cell MIMO downlink with fairness criteria: The large system limit,\" in\nProc. International Symposium on Information Theory Proceedings (ISIT'2010), Jun. 2010, pp. 2058\u20132062.\n[12] J. Hoydis, M. Kobayashi, and M. Debbah, \"Optimal channel training in uplink network MIMO systems,\" IEEE Trans.\nSignal Process., vol. 59, no. 6, Jun. 2011.\n[13] L. Li, A. M. Tulino, and S. Verd\u00fa, \"Design of reduced-rank MMSE multiuser detectors using random matrix methods,\"\nIEEE Trans. Inf. Theory, vol. 50, no. 6, pp. 986\u20131008, Jun. 2004.\n[14] R. Couillet, M. Debbah, and J. W. Silverstein, \"A deterministic equivalent for the analysis of correlated MIMO multiple\naccess channels,\" IEEE Trans. Inf. Theory, vol. 57, no. 6, pp. 3493\u20133514, Jun. 2011.\n[15] F. Dupuy and P. Loubaton, \"On the capacity achieving covariance matrix for frequency selective MIMO channels using\nthe asymptotic approach,\" IEEE Trans. Inf. Theory, 2010. [Online]. Available: http://arxiv.org/abs/1001.3102\n[16] W. Hachem, O. Khorunzhy, P. Loubaton, J. Najim, and L. A. Pastur, \"A new approach for capacity analysis of large\ndimensional multi-antenna channels,\" IEEE Trans. Inf. Theory, vol. 54, no. 9, 2008.\n[17] A. L. Moustakas and S. H. Simon, \"Random matrix theory of multi-antenna communications: the Rician channel,\" Journal\nof Physics A: Mathematical and General, vol. 38, no. 49, pp. 10 859\u201310 872, Nov. 2005.\n[18] --, \"On the outage capacity of correlated multiple-path MIMO channels,\" IEEE Trans. Inf. Theory, vol. 53, no. 11, pp.\n3887\u20133903, 2007.\n[19] P. Billingsley, Probability and Measure, 3rd ed.\n\nHoboken, NJ: John Wiley and Sons, Inc., 1995.\n\n[20] S. Borade, L. Zheng, and R. Gallager, \"Amplify-and-forward in wireless relay networks: rate, diversity, and network size,\"\nIEEE Trans. Inf. Theory, vol. 53, no. 10, pp. 3302\u20133318, 2007.\n[21] I. Maric, A. Goldsmith, and M. M\u00e9dard, \"Analog network coding in the high-SNR regime,\" in IEEE Wireless Network\nCoding Conference (WiNC'10), Boston, MA, USA, 2010, pp. 1\u20136.\n[22] N. Fawaz, K. Zarifi, M. Debbah, and D. Gesbert, \"Asymptotic capacity and optimal precoding in MIMO multi-hop relay\nnetworks,\" IEEE Trans. Inf. Theory, vol. 57, no. 4, pp. 2050\u20132069, 2011.\n[23] D. Gesbert, H. Bolcskei, D. A. Gore, and A. J. Paulraj, \"Outdoor MIMO wireless channels: models and performance\nprediction,\" IEEE Trans. Commun., vol. 50, no. 12, pp. 1926\u20131934, Dec. 2002.\n[24] R. R. M\u00fcller and H. Hofstetter, \"Confirmation of random matrix model for the antenna array channel by indoor\nmeasurements,\" in Proc. IEEE Int. Symp. Antennas and Propagation Society, vol. 1, 2001, pp. 472\u2013475.\n[25] J. Dumont, W. Hachem, S. Lasaulce, P. Loubaton, and J. Najim, \"On the capacity achieving covariance matrix for Rician\nMIMO channels: an asymptotic approach,\" IEEE Trans. Inf. Theory, vol. 56, no. 3, pp. 1048\u20131069, 2010.\n[26] G. H. Tucci, \"Spectral analysis of the amplify and forward relay network as the number of relay layers increases,\" in Proc.\n8th International Symposium on Wireless Communication Systems (ISWCS'11), Aachen, Germany, Nov. 2011.\n[27] S.-P. Yeh and O. Leveque, \"Asymptotic capacity of multi-level amplify-and-forward relay networks,\" in Proc. IEEE\nInternational Symposium on Information Theory (ISIT'07), Jun. 2007, pp. 1436\u20131440.\n\n\f42\n\n[28] V. I. Morgenshtern and H. Blcskei, \"Random matrix analysis of large relay networks,\" in Proc. 44th Allerton Annual\nConference on Communications, Control and Computing, Urbana-Champaign, IL, US, Sep. 2006, pp. 106\u2013112.\n[29] J. Wagner, B. Rankov, and A. Wittneben, \"Large n analysis of amplify-and-forward MIMO relay channels with correlated\nRayleigh fading,\" IEEE Trans. Inf. Theory, vol. 54, no. 12, pp. 5735\u20135746, Dec. 2008.\n[30] S. Jin, M. R. McKay, C. Zhong, and K.-K. Wong, \"Ergodic capacity analysis of amplify-and-forward MIMO dual-hop\nsystems,\" IEEE Trans. Inf. Theory, vol. 56, no. 5, pp. 2204\u20132224, May 2010.\n[31] A. W. van der Vaart, Asymptotic Statistics (Cambridge Series in Statistical and Probabilistic Mathematics).\n\nCambridge\n\nUniversity Press, New York, 1998.\n[32] R. R. M\u00fcller, \"A random matrix model of communication via antenna arrays,\" IEEE Trans. Inf. Theory, vol. 48, no. 9, pp.\n2495\u20132506, Sep. 2002.\n[33] D. Chizhik, G. J. Foschini, M. J. Gans, and R. A. Valenzuela, \"Keyholes, correlations, and capacities of multielement\ntransmit and receive antennas,\" IEEE Trans. Wireless Commun., vol. 1, no. 2, pp. 361\u2013368, Apr. 2002.\n[34] P. Almers, F. Tufvesson, and A. F. Molisch, \"Keyhole effect in MIMO wireless channels: Measurements and theory,\" IEEE\nTrans. Wireless Commun., vol. 5, no. 12, pp. 3596\u20133604, Dec. 2006.\n[35] H. Shin and J. H. Lee, \"Capacity of multiple-antenna fading channels: spatial fading correlation, double scattering, and\nkeyhole,\" IEEE Trans. Inf. Theory, vol. 49, no. 10, pp. 2636\u20132647, Oct. 2003.\n[36] G. Levin and S. Loyka, \"Multi-keyhole MIMO channels: asymptotic analysis of outage capacity,\" in Proc. IEEE\nInternational Symposium on Information Theory (ISIT'06), Seattle, Washington, US, Jul. 2006, pp. 1305\u20131309.\n[37] H. Shin and M. Z. Win, \"MIMO diversity in the presence of double scattering,\" IEEE Trans. Inf. Theory, vol. 54, no. 7,\npp. 2976\u20132996, Jul. 2008.\n[38] S. Yang and J.-C. Belfiore, \"Diversity-multiplexing tradeoff of double scattering MIMO channels,\" IEEE Trans. Inf. Theory,\nvol. 57, no. 4, pp. 2027\u20132034, Apr. 2011.\n[39] S. Jin, M. R. McKay, K.-K. Wong, and X. Gao, \"Transmit beamforming in Rayleigh product MIMO channels: capacity\nand performance analysis,\" IEEE Trans. Signal Process., vol. 56, no. 10, pp. 5204\u20135221, Oct. 2008.\n[40] X. Li, S. Jin, X. Gao, and M. R. McKay, \"Capacity bounds and low complexity transceiver design for double-scattering\nMIMO multiple access channels,\" IEEE Trans. Signal Process., vol. 58, no. 5, pp. 2809\u20132822, May 2010.\n[41] T. Cover and J. A. Thomas, Elements of Information Theory, 2nd ed. New York, NY, USA: John Wiley and Sons, Inc.,\n2006.\n[42] S. M. Kay, Fundamentals of Statistical Signal Processing: Estimation Theory.\n\nPrentice-Hall, Inc. Upper Saddle River,\n\nNJ, USA, 1993.\n[43] D. Gesbert, T. Ekman, and N. Christophersen, \"Capacity limits of dense palm-sized MIMO arrays,\" in Proc. Global\nTelecommunications Conference (GLOBECOM '02), vol. 2, Taipei, Taiwan, Nov. 2002, pp. 1187\u20131191.\n[44] D. Tse and P. Viswanath, Fundamentals of Wireless Communications. New York, NY, USA: Cambridge University Press,\n2005.\n[45] W. H. A. Kammoun, M. Kharouf and J. Najim, \"A central limit theorem for the SINR at the LMMSE estimator output\nfor large dimensional systems,\" IEEE Trans. Inf. Theory, vol. 55, pp. 5048\u20135063, Nov. 2009.\n[46] Z. D. Bai and J. W. Silverstein, \"No eigenvalues outside the support of the limiting spectral distribution of large dimensional\nsample covariance matrices,\" The Annals of Probability, vol. 26, no. 1, pp. 316\u2013345, Jan. 1998.\n[47] J. W. Silverstein and Z. D. Bai, \"On the empirical distribution of eigenvalues of a class of large dimensional random\nmatrices,\" Journal of Multivariate Analysis, vol. 54, no. 2, pp. 175\u2013192, 1995.\n\n\f43\n\n[48] R. Yates, \"A framework for uplink power control in cellular radio systems,\" IEEE J. Sel. Areas Commun., vol. 13, no. 7,\npp. 1341\u20131347, Sep. 1995.\n[49] E. C. Titchmarsh, The Theory of Functions.\n\nOxford University Press, London, Aug. 1939.\n\n[50] S. Boyd and L. Vandenberghe, Convex Optimization.\n\nCambridge University Press, 2004.\n\n\f"}