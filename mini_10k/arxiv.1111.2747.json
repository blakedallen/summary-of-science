{"id": "http://arxiv.org/abs/1111.2747v4", "guidislink": true, "updated": "2012-07-07T02:44:19Z", "updated_parsed": [2012, 7, 7, 2, 44, 19, 5, 189, 0], "published": "2011-11-11T14:05:33Z", "published_parsed": [2011, 11, 11, 14, 5, 33, 4, 315, 0], "title": "Phase-random states: ensembles of states with fixed amplitudes and\n  uniformly distributed phases in a fixed basis", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1111.2653%2C1111.0727%2C1111.5226%2C1111.2621%2C1111.3583%2C1111.4320%2C1111.1255%2C1111.6902%2C1111.1624%2C1111.0151%2C1111.5434%2C1111.2789%2C1111.6622%2C1111.4470%2C1111.4532%2C1111.1610%2C1111.0326%2C1111.4433%2C1111.2028%2C1111.0729%2C1111.6759%2C1111.3650%2C1111.2525%2C1111.5728%2C1111.1003%2C1111.6048%2C1111.5871%2C1111.6245%2C1111.7303%2C1111.3696%2C1111.6359%2C1111.5869%2C1111.4981%2C1111.3395%2C1111.6101%2C1111.4046%2C1111.7027%2C1111.2562%2C1111.2733%2C1111.5401%2C1111.6172%2C1111.4107%2C1111.3979%2C1111.2891%2C1111.5806%2C1111.4232%2C1111.0642%2C1111.3372%2C1111.6686%2C1111.5951%2C1111.5633%2C1111.6712%2C1111.2509%2C1111.5059%2C1111.1345%2C1111.6005%2C1111.3010%2C1111.5178%2C1111.2890%2C1111.5919%2C1111.7251%2C1111.3841%2C1111.5093%2C1111.5264%2C1111.1149%2C1111.0997%2C1111.0284%2C1111.1412%2C1111.2215%2C1111.1210%2C1111.1364%2C1111.0619%2C1111.6506%2C1111.7315%2C1111.3470%2C1111.1299%2C1111.5915%2C1111.6608%2C1111.0594%2C1111.2747%2C1111.5768%2C1111.5393%2C1111.1206%2C1111.4733%2C1111.1758%2C1111.4741%2C1111.6525%2C1111.6790%2C1111.7201%2C1111.6794%2C1111.1703%2C1111.2130%2C1111.0013%2C1111.4995%2C1111.4661%2C1111.3081%2C1111.4264%2C1111.1987%2C1111.4912%2C1111.5307%2C1111.6849&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Phase-random states: ensembles of states with fixed amplitudes and\n  uniformly distributed phases in a fixed basis"}, "summary": "Motivated by studies of typical properties of quantum states in statistical\nmechanics, we introduce phase-random states, an ensemble of pure states with\nfixed amplitudes and uniformly distributed phases in a fixed basis. We first\nshow that canonical states typically appear in subsystems of phase-random\nstates. We then investigate the simulatability of phase-random states, which is\ndirectly related to that of time evolution in closed systems, by studying their\nentanglement properties. We find that starting from a separable state, time\nevolutions under Hamiltonians composed of only separable eigenstates generate\nextremely high entanglement and are difficult to simulate with matrix product\nstates. We also show that random quantum circuits consisting of only two-qubit\ndiagonal unitaries can generate an ensemble with the same average entanglement\nas phase-random states.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1111.2653%2C1111.0727%2C1111.5226%2C1111.2621%2C1111.3583%2C1111.4320%2C1111.1255%2C1111.6902%2C1111.1624%2C1111.0151%2C1111.5434%2C1111.2789%2C1111.6622%2C1111.4470%2C1111.4532%2C1111.1610%2C1111.0326%2C1111.4433%2C1111.2028%2C1111.0729%2C1111.6759%2C1111.3650%2C1111.2525%2C1111.5728%2C1111.1003%2C1111.6048%2C1111.5871%2C1111.6245%2C1111.7303%2C1111.3696%2C1111.6359%2C1111.5869%2C1111.4981%2C1111.3395%2C1111.6101%2C1111.4046%2C1111.7027%2C1111.2562%2C1111.2733%2C1111.5401%2C1111.6172%2C1111.4107%2C1111.3979%2C1111.2891%2C1111.5806%2C1111.4232%2C1111.0642%2C1111.3372%2C1111.6686%2C1111.5951%2C1111.5633%2C1111.6712%2C1111.2509%2C1111.5059%2C1111.1345%2C1111.6005%2C1111.3010%2C1111.5178%2C1111.2890%2C1111.5919%2C1111.7251%2C1111.3841%2C1111.5093%2C1111.5264%2C1111.1149%2C1111.0997%2C1111.0284%2C1111.1412%2C1111.2215%2C1111.1210%2C1111.1364%2C1111.0619%2C1111.6506%2C1111.7315%2C1111.3470%2C1111.1299%2C1111.5915%2C1111.6608%2C1111.0594%2C1111.2747%2C1111.5768%2C1111.5393%2C1111.1206%2C1111.4733%2C1111.1758%2C1111.4741%2C1111.6525%2C1111.6790%2C1111.7201%2C1111.6794%2C1111.1703%2C1111.2130%2C1111.0013%2C1111.4995%2C1111.4661%2C1111.3081%2C1111.4264%2C1111.1987%2C1111.4912%2C1111.5307%2C1111.6849&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Motivated by studies of typical properties of quantum states in statistical\nmechanics, we introduce phase-random states, an ensemble of pure states with\nfixed amplitudes and uniformly distributed phases in a fixed basis. We first\nshow that canonical states typically appear in subsystems of phase-random\nstates. We then investigate the simulatability of phase-random states, which is\ndirectly related to that of time evolution in closed systems, by studying their\nentanglement properties. We find that starting from a separable state, time\nevolutions under Hamiltonians composed of only separable eigenstates generate\nextremely high entanglement and are difficult to simulate with matrix product\nstates. We also show that random quantum circuits consisting of only two-qubit\ndiagonal unitaries can generate an ensemble with the same average entanglement\nas phase-random states."}, "authors": ["Yoshifumi Nakata", "Peter S. Turner", "Mio Murao"], "author_detail": {"name": "Mio Murao"}, "author": "Mio Murao", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1103/PhysRevA.86.012301", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1111.2747v4", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1111.2747v4", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Revised, 12 pages, 4 figure", "arxiv_primary_category": {"term": "quant-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "quant-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1111.2747v4", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1111.2747v4", "journal_reference": "Phys. Rev. A 86, 012301 (2012)", "doi": "10.1103/PhysRevA.86.012301", "fulltext": "Phase-random states: ensembles of states with fixed amplitudes and uniformly\ndistributed phases in a fixed basis\nYoshifumi Nakata,1 Peter S. Turner,1 and Mio Murao1,2\n\n1\n\narXiv:1111.2747v4 [quant-ph] 7 Jul 2012\n\nDepartment of Physics, Graduate School of Science, University of Tokyo, Tokyo 113-0033, Japan\n2\nInstitute for Nano Quantum Information Electronics, University of Tokyo, Tokyo 153-8505, Japan\n(Dated: January 1, 2018)\nMotivated by studies of typical properties of quantum states in statistical mechanics, we introduce\nphase-random states, an ensemble of pure states with fixed amplitudes and uniformly distributed\nphases in a fixed basis. We first give a sufficient condition for canonical states to typically appear in\nsubsystems of phase-random states, which reveals a trade-off relation between the initial state in the\nbounded energy subspace and the energy eigenstates that define that subspace. We then investigate\nthe simulatability of phase-random states, which is directly related to that of time evolution in closed\nsystems, by studying their entanglement properties. We find that starting from a separable state,\ntime evolutions under Hamiltonians composed of only separable eigenstates generate extremely high\nentanglement and are difficult to simulate with matrix product states. We also show that random\nquantum circuits consisting of only two-qubit diagonal unitaries can generate an ensemble with the\nsame average entanglement as phase-random states.\nPACS numbers: 03.67.Mn, 03.67.Bg, 05.70.-a\n\nI.\n\nINTRODUCTION\n\nOne of the goals of quantum many-body physics is to\nbe able to compute properties such as expectation values of observables, entanglement and explicit state descriptions for physical systems composed of many particles. These properties depend upon the parameters of\nthe quantum states involved, and calculations are made\ndifficult by the fact that the number of these parameters grows exponentially with the number of particles.\nOne way around this problem is to consider ensembles of\nstates as opposed to individual states, as many of those\nparameters are then averaged out.\nThe most natural and well-studied ensemble of states\nis that of random states, the set of pure states in Hilbert\nspace selected randomly from the unitarily invariant distribution, used in many areas of quantum physics and\nquantum information science [1\u20133]. The entanglement\nof random states is an area of particular recent interest,\nwhere it has been shown that in large systems, the average amount of entanglement is nearly maximal according\nto several measures [5]. In the context of quantum statistical mechanics, the high entanglement of random states\nhas been shown to lead to reduced states that are thermal, under their restriction to a subspace constrained by\nthe amount of total energy [6].\nSymmetry is often used as a constraint, however there\nare other ways to place useful restrictions on an ensemble.\nIf states are restricted to a certain subspace of Hilbert\nspace, an ensemble of states could be described by random states in that subspace. In this paper, we address\nanother type of restriction, which leads to ensembles of\nstates in a subset of a Hilbert space. A simple example of\na subset of states that is not a subspace is the set of product states, as they are not closed under superpositions.\nA more interesting example is a state evolving under a\ntime-independent Hamiltonian. Since the time evolution\n\nchanges only the phases of the expansion coefficients in\nthe Hamiltonian's eigenbasis, states reached during the\ntime evolution form a subset rather than a subspace. Our\naim is to study random states in such a subset, namely,\nan ensemble of states where the randomness is restricted\nto the phase of the complex expansion coefficients in a\ngiven basis, which we call phase-random states.\nPhase-random states are closely connected to studies\nof typical properties in statistical mechanics [1, 7]. States\nin which the phases are the pertinent degree of freedom\nappear in quantum information theory such as in instantaneously quantum polynomial time (IQP) circuits\n[8], and locally maximally entanglable (LME) states [9].\nPhase-random states also describe situations where the\naccessible information is limited to the amplitudes in a\ncertain basis, for instance, those where a unique rank-1\nmeasurement is allowed.\nMotivated by these considerations, we investigate statistical properties of phase-random states, which clearly\ndepend on the amplitudes of the coefficients as well as\nthe expansion basis. We first demonstrate the thermalization of their reduced states, which implies potential\nuses of phase-random ensembles to realize thermal states\nin subsystems. Then, regarding phase-random states as\ntypical states during a Hamiltonian dynamics, we discuss simulating them with matrix product states (MPSs)\n[10] by deriving the average amount of entanglement of\nphase-random states. Moreover, applications of phaserandom states in IQP circuits and as LME states lead us\nto develop a scheme for generating an ensemble of states\nsimulating the entanglement of phase-random states by\na quantum circuit composed of only diagonal two qubit\nunitaries, which we call a phase-random circuit.\nThe paper is organized as follows. In Sec. II, we define\nphase-random states and show how they can be used to\nstudy thermalization in statistical mechanics. In Sec. III,\nwe derive explicit formula for the average amount of en-\n\n\f2\ntanglement of phase-random states. Using the formula,\nwe investigate the simulatability of Hamiltonian dynamics by MPSs in Sec. IV. Finally, we introduce and analyze\nphase-random circuits in Sec. V.\n\nThen, if an initial state lies in HR , the reduced density matrix on the system TrE |\u03c6(t)ih\u03c6(t)| should be in a\nneighborhood of \u03c1\u0302S given by\n\u03c1\u0302S =\n\nII.\n\nPHASE-RANDOM STATES AND\nTHERMALIZATION\n\nGiven a Hilbert space H, we denote an ensemble of\npure states |\u03c8i \u2208 H distributed according to some measure d\u03bc by \u03a5 = {|\u03c8i}d\u03bc . The ensemble of random states\nis written \u03a5rand = {|\u03c8i}d\u03c8 , where |\u03c8i is an arbitrary\nstate and d\u03c8 is the unitarily invariant normalized Haar\nmeasure. For a Hilbert space of N qubits, consider states\nof the form\n\ndR\nX\n\n\u03b1=1\n\nr\u03b12 TrE |e\u03b1 ihe\u03b1 | ,\n\nfor most of the time t, where r\u03b1 = Rehe\u03b1 |\u03c60 i, \u2200 |e\u03b1 i \u2208 HR\nand dR = dimHR . We say that for most of the phaserandom states \u03a5phase ({r\u0303n , |en i}n ), where r\u0303n is determined by |\u03c6(0)i and HR , a reduced density matrix on\nthe system is close to \u03c1\u0302S .\nBy evaluating the trace distance between the state \u03c1\u0302S\nand a canonical state TrE IR /dR where IR is the identity\nmatrix on HR , one can obtain the following condition for\n\u03c1\u0302S to be a canonical state,\n\nN\n\n|\u03c6i =\n\n2\nX\n\nn=1\n\nrn ei\u03c6n |un i ,\n\nP\nwith both the amplitudes {rn | n rn2 = 1, 0 \u2264 rn \u2264 1}\nand orthonormal basis {|un i} fixed. By phase-random\nstates, we mean the ensemble \u03a5phase = {|\u03c6i}d\u03c6 , where\nthe phases \u03c6n are distributed according to the normalized\nLebesgue measure given by\nd\u03c6 =\n\nd\u03c61\nd\u03c6 N\n*** 2 ,\n2\u03c0\n2\u03c0\n\nN\n\non [0, 2\u03c0]2 .\nThis ensemble clearly depends on\nthe choice of amplitudes and basis, which we write\n\u03a5phase ({rn , |un i}n ) when there is need to be explicit.\nNote that the ensemble of phase-random ensembles with\nappropriately distributed amplitudes is the ensemble of\nrandom states.\nWe first point out that studies of thermalization in\nclosed systems [1, 7] are special instances of the study\nof phase-random states. To see this, consider a Hilbert\nspace H with dimension d, and a Hamiltonian H =\nPd\nn=1 en |en ihen |. The state at time t is given by\nX\n|\u03c6(t)i =\nrn e\u2212ien t/~+i\u03c6n |en i ,\nn\n\ni\u03c6n\n\n= hen |\u03c60 i with rn \u2265 0 and |\u03c60 i is an initial\nwhere rn e\nstate. Then, a time averaged thermodynamical quantity is often considered by assuming phase ergodicity in\nthe sense that the distribution of phases e\u2212ien t/~+i\u03c6n are\nuniform in [0, 2\u03c0] in the long-time limit. Due to this\nidentification, all studies addressing the time average are\nequivalent to investigations of statistical properties of the\ncorresponding phase-random states \u03a5phase ({rn , |en i}n ).\nFor example, in [1] it was proven that time evolution\ntypically gives rise to canonical distributions in subsystems. In this case, we consider a Hilbert space HS \u2297 HE\nwhere HS (HE ) represents a system (environment) with\ndimension dS (dE ), and HR is a restricted subspace constrained by the energy defined by\nHR = span{|e\u03b1 i |e \u2212 \u03b4e < e\u03b1 < e + \u03b4e} \u2282 HS \u2297 HE .\n\ndR\nX\n\n(r\u0303\u03b12 \u2212\n\n\u03b1,\u03b2=1\n\n1\n1\n\u03b2\n)(r\u03032 \u2212\n)Tr[\u00ea\u03b1\nS \u00eaS ] = 0,\ndR \u03b2 dR\n\n(1)\n\nwhere \u00eakS = TrE |ek ihek |. This provides a trade-off relation between the initial state and the restricted Hilbert\nspace HR for thermalization. In order to see this, consider the following two extreme cases for Eq. (1) to hold,\nwhich trivially lead to thermalization in subsystems.\nFirstly, if the conditions are imposed only on the amplitudes, the amplitudes must be equal, i.e. r\u0303\u03b1 = 1/dR\nfor all \u03b1. Since the amplitudes are defined by the initial\nstate, this is a condition for the initial state to exhibit\nthermalization. On the other hand, if the conditions are\nimposed only on the restricted Hilbert space HR , the\n\u2032\n\u03b2\n\u03b1\u2032 \u03b2\neigenstates in HR should satisfy Tr[\u00ea\u03b1\nS \u00eaS ] = Tr[\u00eaS \u00eaS ],\n\u2200 |e\u03b1 i , |e\u03b2 i , |e\u03b1\u2032 i , |e\u03b2 \u2032 i \u2208 HR . By choosing \u03b1 = \u03b2 = \u03b2 \u2032 ,\n2\n\u03b1 \u03b1\u2032\nwe obtain Tr[(\u00ea\u03b1\nS ) ] = Tr[\u00eaS \u00eaS ]. Since the left-hand side\nis a norm of \u00ea\u03b1\nS and the right-hand side is the Hilbert\u03b1\u2032\nSchmidt inner product of \u00ea\u03b1\nS and \u00eaS , it implies that all\nreduced density matrices should be identical. Thus, this\ncondition on the eigenstates in HR trivially results in\nthermalization.\nEquation (1) gives conditions applicable in intermediate situations between these two extreme cases. It\ntherefore provides grounds for the study of the way thermalization depends on a system's initial state and on its\nHamiltonian [4].\nIII.\n\nENTANGLEMENT\n\nWe investigate the entanglement properties of phaserandom states using entropic measures of entanglement\nsince they can reveal if the state is simulatable by MPSs.\nConsider divisions into two subsystems A and \u0100, composed of NA and N\u0100 = N \u2212 NA qubits respectively.\nWe denote the density matrix of |\u03c6i by \u03c6\u0302 = |\u03c6ih\u03c6|\nand its reduced density matrix on the subsystem A by\n\u03c6\u0302A = Tr\u0100 \u03c6\u0302 = Tr\u0100 |\u03c6ih\u03c6|. For a given pure state |\u03c6i\nand subsystem A, the amount of entanglement in terms\n\n\f(a) random states\n0.9883\u00b10.0035\n\nPopulation [%]\n\nPopulation [%]\n\n3\n0.9921\u00b10.0028\n(b) phase-random\nstates\n\nThus we have\n(A)\nhEL i\u03a5phase\n\nFIG. 1: (Color online) The distributions for N = 8 of the\namount of entanglement for two ensembles, (a) random states\nand (b) phase-random states with equal amplitudes and a\nseparable basis, using the Meyer-Wallach measure of entanglePN\n({k})\nment EMW (|\u03c6i) := N2\n(|\u03c6i), where k labels singlek=1 EL\nqubit subsystems [11]. The number of samples is 104 , binned\nin intervals of 0.002.\n\n=\n\nX\u0014 X\na,b\n\nn,m\n\n2\n(a) (b)\nrn2 rm\n(h\u0169n(b) |\u0169(a)\nn ih\u0169m |\u0169m i\n\n(a) 2\n+ |h\u0169(b)\nm |\u0169n i| ) \u2212\n\nX\nl\n\n\u0015\n(b) (a)\nrl4 |h\u0169l |\u0169l i|2 . (3)\n\nDenoting the mutual information of \u03a6\u0302 between A and \u0100\n(A)\nin terms of the linear entropy by IL (\u03a6\u0302) = SL (Tr\u0100 \u03a6\u0302) +\nSL (TrA \u03a6\u0302) \u2212 SL (\u03a6\u0302), Eq. (3) reduces to\nN\n\n(A)\n\nof the linear entropy is given by EL (|\u03c6i) = SL (\u03c6\u0302A )\nwhere SL (\u03c1\u0302) = 1 \u2212 Tr\u03c1\u03022 , and in terms of the von Neumann entropy is given by E (A) (|\u03c6i) = S(\u03c6\u0302A ) where\n(A)\nS(\u03c1\u0302) = \u2212Tr\u03c1\u0302 log \u03c1\u0302. We have 0 \u2264 EL (|\u03c6i) \u2264 1 \u2212 2\u2212NA .\nThe linear entropy gives a lower bound on the von Neu(A)\nmann entropy, \u2212 log[1 \u2212 EL (|\u03c6i)] \u2264 E (A) (|\u03c6i). Hence,\nwe will use the linear entropy to measure entanglement\nin this paper unless otherwise specified.\nFor the ensemble of random states \u03a5rand on N qubits,\nthe average amount of entanglement is\nZ\n(A)\n(A)\nhEL i\u03a5rand = d\u03c8EL (|\u03c8i)\n=1\u2212\n\n2NA + 2N\u0100\n,\n2N + 1\n\n(2)\n\nindicating that random states of large systems are nearly\nmaximally entangled on average [5]. For an ensemble of\nphase random states \u03a5phase and a choice of subsystem A,\nthe average amount of entanglement is defined by\nZ\n(A)\n(A)\nhEL i\u03a5phase = d\u03c6EL (|\u03c6i),\nwhich, recall, is a function of {rn , |un i}. Note that in\n(A)\n(A)\ngeneral hEL i\u03a5phase 6= EL (\u03a6\u0302), where \u03a6\u0302 is the density\nmatrix defined by the phase-random ensemble, namely,\nZ\nX\n\u03a6\u0302 = d\u03c6\u03c6\u0302 =\nrn2 |un ihun | .\nn\n\nIn order to calculate the average amount of entanglement, we expand the basis elements such that |un i =\nP2NA\n(a)\na=1 |\u0101iA \u2297 |\u0169n i\u0100 , where {|\u0101iA }a=1,*** ,2NA is a computational basis for subsystem A, \u0101 is binary for a \u2212 1, and\n(A)\ntildes indicate unnormalized kets. Defining \u03c6aa\u2032 by\nX\n(A)\n(a\u2032 ) (a)\n\u03c6aa\u2032 :=\nrn rm ei(\u03c6n \u2212\u03c6m ) h\u0169m\n|\u0169n i,\nnm\n\nP\n(A)\nTr(\u03c6\u0302A )2 is given by a,a\u2032 |\u03c6aa\u2032 |2 . This is quadratic, so\nwill involve a sum over four basis labels n, m, l, k, and\nwhere the only phase integral that occurs is\nZ\nd\u03c6ei(\u03c6n \u2212\u03c6m +\u03c6k \u2212\u03c6l ) = \u03b4nm \u03b4kl + \u03b4nl \u03b4mk \u2212 \u03b4nm \u03b4nk \u03b4nl .\n\n(A)\nhEL i\u03a5phase\n\n=\n\n(A)\nIL (\u03a6\u0302)\n\n\u2212\n\n2\nX\n\nn=1\n\n(A)\n\nrn4 EL (|un i). (4)\n\nEquation (4) simplifies the investigation of the depen(A)\ndence of hEL i\u03a5phase on the amplitudes and the basis,\n{rn , |un i}.\nWe consider two cases in particular.\nFirst,\nwe analyze equal-amplitudes ensembles \u03a5eq\n=\nphase\n\u03a5phase ({2\u2212N/2 , |un i}). In this case, the average amount\nof entanglement over phases is given by\n2N\n\n(A)\nhEL i\u03a5eq\nphase\n\n(A)\n\n2NA + 2N\u0100 \u2212 1 X EL (|un i)\n\u2212\n.\n= 1\u2212\n2N\n22N\nn=1\n(5)\n(A)\n\nis a decreasing function of\nThis shows that hEL i\u03a5eq\nphase\n(A)\n\nthe basis entanglement, EL (|un i). Hence ensembles\nthat also have a separable basis {|usep\nn i}, denoted by\neq,sep\n\u03a5phase\n= \u03a5phase ({2\u2212N/2 , |usep\ni}),\ngive\nthe maximum,\nn\n(A)\n\nhEL i\u03a5eq,sep\n=1\u2212\nphase\n\n2NA + 2N\u0100 \u2212 1\n.\n2N\n\nThis value is greater than that of random states\ngiven P\nby Eq. (2), see also Fig. 1. For |\u03c6eq,sep i =\n2\u2212N/2 n ei\u03c6n |usep\nn i, applying the concentration of\n(A)\n(A)\nmeasure to \u2206EL (|\u03c6eq,sep i) = |EL (|\u03c6eq,sep i) \u2212\n(A)\neq,sep |, we find\nhEL i\u03a5phase\n\u0014\n\u0015\n4 N\n(A)\nProb \u2206EL (|\u03c6eq,sep i) > 2/2N + \u01eb \u2264 e\u2212c\u01eb 2 ,\n\n(6)\n\nwhere c = 1/(211 \u03c0 2 ). The proof is similar to that in\nRef. [1] (see Appendix A for details). Thus the entaneq,sep\nglement of phase-random states \u03a5phase\nis highly concentrated around the average, demonstrated in Fig. 1.\nStates with equal amplitudes in a separable basis are\nalso known as LME states [9]. These are the class of\nmultipartite states that are maximally entanglable with\nlocal auxiliary systems by only local operations. In Ref.\n[9], it is mentioned that the LME states should exhibit\nhigh entanglement. Our result proves this statement is\ntrue in the sense that the uniform ensemble of LME states\n\n\f4\nachieves a higher average amount of entanglement, in\nterms of linear entropy, than that of random states.\nOn the other hand, for separable-basis ensembles desep\nfined by \u03a5sep\nphase = \u03a5phase ({rn , |un i}), an upper bound\nof the average amount of entanglement is given by\n(A)\n\n\u2264 SL (\u03a6\u0302sep ),\n0 \u2264 hEL i\u03a5sep\nphase\nP\nsep\nwhere \u03a6\u0302sep = n rn2 |usep\nn ihun |. When the number of\nsep\nnon-zero rn is R, SL (\u03a6\u0302 ) is bounded by 1 \u2212 1/R from\nabove. If R is small, (for instance, if R = poly(N )), the\naverage amount of entanglement cannot be as large as\nthat of random states. It is therefore necessary for the\nbasis to be entangled in order to generate a large amount\nof entanglement on average when R is small.\nIV.\n\nSIMULATABILITY OF HAMILTONIAN\nDYNAMICS\n\nWe now interpret our results in the context of timeindependent Hamiltonian dynamics and consider the simulatability of the state during the time evolution by assuming phase ergodicity. We consider the area law of\nentanglement, which states that the von Neumann entropy of entanglement of a large subsystem is at most\nproportional to its boundary. Since the breakdown of\nthe area law indicates that the states cannot be simulated by MPSs with a constant matrix size [10], the area\nlaw gives insight into the simulatability of the state. The\narea law is often studied for ground states of spin systems. It is also known that, initial states that do not\nviolate the area law will not do so over a certain time\nscale evolving under a local Hamiltonian [12].\nApplying our results to a lattice of qubits, we consider\nthe long-time average of the von Neumann entropy of\nentanglement generated by a time-independent Hamiltonian dynamics hE (A) iT ;\u221e . Using the facts that the\nvon Neumann entropy is lower bounded by the linear\nentropy and the concavity of the logarithm, we obtain\na lower bound on hE (A) i\u03a5phase , which can be identified\nwith hE (A) iT ;\u221e under phase ergodicity. Thus, we have\n(A)\nhE (A) iT ;\u221e \u2265 \u2212 log[1\u2212hEL i\u03a5phase ]. By applying Eq. (4),\nwe can check the area law in the long-time average.\nIn particular, we consider Hamiltonians composed of\nseparable eigenstates, which are often referred to as semiclassical. When the initial state is a superposition of separable eigenstates with equal amplitudes, the initial state\nis also separable, and the corresponding phase-random\nstates are \u03a5eq,sep\nphase which obtains the maximum of Eq. (5).\nThus we obtain\nhE (A) iT ;\u221e \u2265 NA \u2212 log(1 + 22NA \u2212N \u2212 2NA \u2212N ),\nwhich grows in proportion to the volume NA of the subsystem A when NA \u226a N , and not with any boundary\nsize, and the area law is broken. Since entanglement concentrates around its average during the time evolution as\n\nFIG. 2: Phase-random circuit composed of two-qubit untiaries Wt (it , jt ) acting on randomly selected pairs of qubits\n(it , jt ).\n\nin Eq. (6), the states are not simulatable by MPSs with\na constant matrix size for most times. This is surprising\nat first because all eigenstates as well as the initial state\nare separable, however the dynamics generate extremely\nhigh entanglement and, thus, is difficult to simulate.\nIn Ref. [12], timescales necessary for breaking the area\nlaw by time evolutions with local Hamiltonians have been\nstudied. Combined with our result, we can explicitly estimate the timescale necessary for satisfying phase ergodicity when the Hamiltonian is composed of separable\neigenstates.\n\nV.\n\nPHASE-RANDOM CIRCUIT\n\nWe present a phase-random circuit generating an ensemble of states \u03a5pseudo\nphase that provides the same average\nentanglement as the phase-random ensemble \u03a5comp\nphase =\nP\n\u03a5phase ({ra , |\u0101i}a ), where |\u03c60 i = ra ei\u03c6a |\u0101i is the input\nN\nto the circuit and {|\u0101i}2a=1 is the computational basis.\nA phase-random circuit is similar to those considered\nin [13, 14]. We consider a circuit composed of T iterations\nof two-qubit unitaries diagonal in the computational basis denoted by Wt , where the subscript t denotes the\nt-th iteration (t = 1, 2, . . . , T ). For each iteration t, the\ntwo-qubit unitary Wt acts on a pair of qubits i, j(j 6= i)\nrandomly chosen uniformly from {1, 2, * * * , N }, and is\nwritten\nWt = CZit jt Pit (\u03b1t )Pjt (\u03b2t ),\n\n(7)\n\nwhere CZij = diag(1, 1, 1, \u22121) is a controlled-Z operation on qubits i and j, Pk (\u03b8) = diag(1, ei\u03b8 ) denotes a phase gate on the qubit k, and the two angles \u03b1, \u03b2 are randomly chosen uniformly from the interval [0, 2\u03c0]. A specific instance of the circuit is described by the set {it , jt , \u03b1t , \u03b2t }Tt=1 , and the corresponding output state after T iterations of Wt P\nis given by\n|\u03c6T i = WT WT \u22121 * * * W1 |\u03c60 i, where |\u03c60 i =\nra ei\u03c6a |\u0101i\nis an input state in the computational basis {|\u0101i}, defining the ensemble \u03a5comp\nphase .\n\n\f5\nA.\n\nSummary of results\n\nHere we state the main results, with the details of the\n(A)\nproof to follow. Denote by E[EL (|\u03c6T i)] the expectation\n(A)\nvalue of EL (|\u03c6T i) taken over the uniform distribution\nof {it , jt , \u03b1t , \u03b2t }Tt=1 . We will prove the following two the(A)\norems regarding the ability of E[EL (|\u03c6T i)] to equal the\n(A)\nafter suffiaverage of phase random states hEL i\u03a5comp\nphase\nciently many iterations, and about the required number\nof iterations.\nTheorem 1 With the preceding definitions and notations,\n(A)\n\n(A)\n\nlim E[SL (|\u03c6T i)] = hEL i\u03a5comp\n,\nphase\n\ncase. In this method, the key technique is to map the\nevolution of the states in the phase-random circuit to a\nMarkov chain, and so we first briefly review Markov processes in Subsection V B. In Subsection V C, we present\nthe map to a Markov chain, and then investigate its stationary distribution. As, contrary to [13, 14], the Markov\nchain is not irreducible in our case, we first decompose\nit into irreducible Markov chains in Subsection V D. In\norder to calculate the average amount of entanglement, it\nis sufficient to consider reduced Markov chains, which are\npresented in Subsection V E. By investigating the stationary distribution of the reduced Markov chain, we finally\nobtain the average amount of entanglement after T steps\nin Subsection V F. The mixing time Tmix(\u01eb) for achieving\nEq. (8) is treated in Subsection V G.\n\n(8)\n\nT \u2192\u221e\n\nB.\n\nwith\n(A)\n\n=1\u2212\nhEL i\u03a5comp\nphase\n\nX\n\nra2 rb2 (\n\na,b\n\nY\n\n\u03b4ai bi +\n\ni\u2208A\n\nY\n\n\u03b4ai bi )\n\ni\u2208\u0100\n\n+\n\nX\n\nra4 , (9)\n\na\n\nwhere a1 a2 * * * aN (b1 b2 * * * bN ) \u2208 {0, 1}N is a binary representation of a \u2212 1 (b \u2212 1).\nTheorem 2 Let Tmix (\u01eb) be the number of iterations required to achieve Eq. (8) with error \u01eb, namely,\n(A)\n\n(A)\n\n< \u01eb.\n\u2200T > Tmix (\u01eb), E[SL (|\u03c6T i)] \u2212 hEL i\u03a5comp\nphase\nFor \u0393 \u2282 {1, * * * , N }, define \u03ba(\u0393) (|\u03c60 i) such that\nY\nY\nX\n\u03b4ai bi .\nra2 rb2\n(1 \u2212 \u03b4ai bi )\n\u03ba(\u0393) (|\u03c60 i) :=\na6=b\n\ni\u2208\u0393\n\ni\u2208\u0393\n/\n\nThen, if max\u0393 \u03ba(\u0393) (|\u03c60 i) = O(2\u2212N ), Tmix (\u01eb) is polynomial in the system size N for any A. In particular, for\nra \u223c pa (N )2\u2212N/2 where {pa (N )}a are polynomial functions of N , Tmix (\u01eb) is poly(N ).\nThese results are especially interesting if we consider\nan ensemble \u03a5pseudo\nphase simulating the average amount of\nentanglement of \u03a5eq,sep\nphase . Since the average entanglement\npseudo\nof \u03a5eq,sep\nphase violates the area law, most states in \u03a5phase\n\ndo also. Hence, \u03a5pseudo\nphase are not simulatable by MPSs\nalthough they are generated by a quantum circuit with\na polynomial number of elementary gates.\nHere, we have focused on the generation of the average amount of entanglement of phase-random states. In\na separate paper [15], it is shown that phase-random circuits can approximately generate an ensemble simulating\nthe states themselves.\nIn the following, we prove Theorems 1 and 2 by adapting the method developed in [13, 14] to the phase-random\n\nIntroduction of a Markov chain\n\nA Markov chain is a sequence of random variables that\ntake values in a set of states S = {s}, indexed in our case\nby discrete steps t. The Markov property is that the\nprobability of st+1 occurring depends only on st , and is\nindependent of previous states. We can define at any step\nt a probability distribution \u03a0t over the states space S.\nThe Markov property then ensures that subsequent distributions are related only to the previous distribution,\nand that this dependence can be given in the form of\na step-independent, stochastic transition matrix P, with\nmatrix elements denoted by P(s, s\u2032 ). Thus, the probability distribution at step t is given by \u03a0t = P t \u03a00 , where\n\u03a00 is an initial distribution.\nWhen a Markov chain is irreducible and aperiodic, the\nprobability distribution on each state converges after sufficiently many steps. That is, for all s, there exists a\nunique \u03a0\u221e (s) = limt\u2192\u221e \u03a0t (s) that is independent of the\ninitial probability distribution. Irreducibility is a property of the transition matrix implying that any state s\ncan transition to any other state in a finite number of\nsteps, that is, for all s and s\u2032 , there exists a t such that\nP t (s, s\u2032 ) > 0. Aperiodicity implies that, for all states\ns, there exists a non-zero probability to remain in that\nstate, namely, P(s, s) > 0 for all s. A sufficient condition\nfor a distribution to be stationary is given by the detailed\nbalance condition\n\u03a0(s)P(s, s\u2032 ) = \u03a0(s\u2032 )P(s\u2032 , s), for all s, s\u2032 \u2208 S.\nWhen a Markov chain satisfies the detailed balance equations, it is referred to as reversible.\nNext, we define the mixing time, which is the number\nof Markov chain steps required for the distance between\nthe actual distribution and the stationary distribution\nto be small, where we define the distance between two\nprobability distributions as follows. Let \u03b4(s0 ) be an initial probability distribution of a Markov chain with value\n1 at s0 and zero elsewhere on the state space S. Let us\ndenote the sum of the probabilities of\nPa distribution over\na subset of states S \u2032 by \u03a0(S \u2032 ) =\ns\u2208S \u2032 \u03a0(s), and by\n\n\f6\n\u03a0t (S \u2032 |\u03b4(s0 )) such a sum at step t of a Markov chain that\ninitialized with the distribution \u03b4(s0 ). The variation distance after t-steps is defined by\n|\u03a0t (S \u2032 |\u03b4(s0 )) \u2212 \u03a0\u221e (S \u2032 )|.\n\u2206s0 (t) := max\n\u2032\nS \u2286S\n\nThe mixing time Tmix (\u01eb) is then defined for any \u01eb > 0 by\nTmix(\u01eb) := min{t| max \u2206s0 (t\u2032 ) \u2264 \u01eb for all t\u2032 \u2265 t}.\ns0 \u2208S\n\nThis is the number of steps it would take to get \u01eb-close\nto the stationary distribution in the worst case. In practice, we do not actually use this definition of the mixing\ntime, but rather the following Theorem 3 and Corollary 1\nregarding the transition matrix.\nFor a transition matrix P of a reversible Markov chain,\nlet us label the eigenvalues of P in decreasing order such\nthat\n1 = \u03bb1 > \u03bb2 > * * * .\nThen, \u03b7 := 1 \u2212 \u03bb2 is called its absolute spectral gap. The\nabsolute spectral gap \u03b7 gives an upper bound on the mixing time as stated in the following theorem.\nTheorem 3 (Theorem 12.3 in [16]) Let P be the\ntransition matrix of a reversible Markov chain on S, and\nlet \u03a0(min) := mins\u2208S \u03a0(s). Then\nTmix (\u01eb) \u2264 log(\n\n|\u03c6t ih\u03c6t | =\n\n1\n2N/2\n\nX\n\nq1 ,*** ,qN\n\n\u03bet (q1 , * * * , qN )\u03c3q1 \u2297 * * * \u2297 \u03c3qN ,\n\nwhere qi \u2208 {0, x, y, z} and \u03c3qi are Pauli operators. We\ndenote (q1 , * * * , qN ) by the vector q. We construct a\nMarkov chain defined on {q} in which the probability\ndistribution is given by the expectation value of \u03bet2 (q)\nover \u03b1t and \u03b2t , which is denoted by E[\u03bet2 (q)]. For this\npurpose, we first examine E[\u03bet2 (q)], and then construct\nthe Markov chain. For simplicity, hereafter we omit the\nstep indices on qubits and write (i, j).\nBy applying Wt+1 on a randomly chosen pair of qubits\n(i, j), the coefficients {\u03bet+1 (q)} of the state |\u03c6t+1 ih\u03c6t+1 |\nbecome\n1X\n\u03bet (ppi \u2192qi ,pj \u2192qj )\u00d7\n4 q ,q\ni\n\nj\n\n\u2020\n],\nTr[\u03c3pi \u2297 \u03c3pj Wt+1 \u03c3qi \u2297 \u03c3qj Wt+1\n\nCorollary 1 (Corollary 4 in [17]) For a given transition matrix P, let Q(s, s\u2032 ) := \u03a0\u221e (s)P(s, s\u2032 ) and\ne\u2208E\n\nWe will now show that the change in the state |\u03c6t i \u2192\n|\u03c6t+1 i upon the application of the two-qubit unitary\nWt+1 defined by Eq. (7) can be formulated in terms of a\ntransition matrix action on the indices of expansion coefficients of the state in the basis of local Pauli operators.\nThe hermiticity of this basis ensures that the coefficients\nare real, and hence their square gives a valid probability\ndistribution, while its locality ensures that we can focus\non the qubits i and j where Wt+1 acts, eventually simplifying the calculation of the linear entropy.\nLet us consider the expansion of |\u03c6t ih\u03c6t | given by\n\n1\n1\n) .\n\u01eb\u03a0(min) \u03b7\n\n1 X\n\u03a0\u221e (s)\u03a0\u221e (s\u2032 ).\nQ(e)\n\u2032\n\nMap to a Markov chain\n\n\u03bet+1 (p) =\n\nMoreover, a lower bound on the absolute spectral gap \u03b7\nis obtained by the canonical path method. Viewing a reversible transition matrix P as a graph with vertex set S,\ndefine the edge set E = {(s, s\u2032 )|P(s, s\u2032 ) > 0}. A canonical path from s to s\u2032 is a sequence Ess\u2032 = (e1 , * * * , em )\nof edges in E such that e1 = (s, s1 ), e2 = (s1 , s2 ), * * * ,\nem = (sm\u22121 , s\u2032 ) for vertices si , i = 1, 2, * * * , m. We have\nthe following Corollary 1.\n\n\u03c1 := max\n\nC.\n\n(10)\n\ns,s\nEss\u2032 \u220be\n\nwhere ppi \u2192qi ,pj \u2192qj is p but with components (pi , pj ) replaced by (qi , qj ). Squaring this to arrive at a probability\ndistribution, we have\n2\n\u03bet+1\n(p) =\n\n1 X\n\u03bet (ppi \u2192qi ,pj \u2192qj )\n4 qi ,qj ,\nqi\u2032 ,qj\u2032\n\n\u00d7 \u03bet (ppi \u2192qi\u2032 ,pj \u2192qj\u2032 )Gt+1 (p, q, q\u2032 ),\n(11)\nwhere\nGt+1 (p, q, q\u2032 ) :=\n\u2020\n]\nTr[\u03c3pi \u2297 \u03c3pj Wt+1 \u03c3qi \u2297 \u03c3qj Wt+1\n\n\u2020\n].\n\u00d7 Tr[\u03c3pi \u2297 \u03c3pj Wt+1 \u03c3qi\u2032 \u2297 \u03c3qj\u2032 Wt+1\n\nThen\n1\n\u2264 \u03b7.\n8\u03c12\nBy combining Theorem 3 and Corollary 1, an upper\nbound on the mixing time can be obtained.\n\nIn order to see that Gt+1 defines a transition matrix, it\nis important to recognize that it treats the sets of Pauli\nindices {0, z} and {x, y} equivalently. We write w0z and\nwxy for arbitrary elements of each set respectively, and we\ndefine an involution \u00ac as \u00ac0 = z and \u00acx = y. Averaging\n\n\f7\n2\nE[\u03bet+1\n]\n\npj\n\n0\nx\ny\nz\n\npi\n0\nx\ny\nz\nAt Ct (0) Ct (0) At\nBt (0) Dt\nDt Bt (z)\nBt (0) Dt\nDt Bt (z)\nAt Ct (z) Ct (z) At\n\n(qi , qj )\n\n(w0z , w0z ) (qi , qj )\n(w0z , wxy ) (\u00acqi , x)\n(\u00acqi , y)\n(wxy , w0z ) (x, \u00acqj )\n(y, \u00acqj )\n(wxy , wxy ) (x, x)\n(x, y)\n(y, x)\n(y, y)\n\n2\nTABLE I: Table of E[\u03bet+1\n(p)| |\u03c6t i] as a function of pi and pj .\n\nover \u03b1t , \u03b2t , we obtain\n\nE[Gt+1 (p, q, q\u2032 )] = \u03b4qq\u2032\n\n\uf8f1\n\uf8f4\n\uf8f416\n\uf8f4\n\uf8f28\n\u00d7\n\uf8f44\n\uf8f4\n\uf8f4\n\uf8f3\n0\n\ncase I\ncase II\ncase III\notherwise,\n\n1\n1/2\n1/2\n1/2\n1/2\n1/4\n1/4\n1/4\n1/4\n\nTABLE II: Transition probabilities.\n\n(12)\n\ngiven by \u03be02 (p),\n\u03a01 (p) =\n\ncase I \u21d4 (pi = qi = w0z ) \u2227 (pj = qj = w0z )\ncase II \u21d4 (\u00acpi = qi = w0z ) \u2227 (pj , qj = wxy )\n\u2228 (pi , qi = wxy ) \u2227 (\u00acpj = qj = w0z )\ncase III \u21d4 pi , qi , pj , qj = wxy .\nBy substituting E[Gt+1 (p, q, q\u2032 )] into Eq. (11), we ob2\ntain E[\u03bet+1\n(p)| |\u03c6t i], the expectation value conditional on\nstate |\u03c6t i, with values as shown in Table I where\n\n=\n\n1 X X\n\u03bet (ppi \u2192w,pj \u2192w\u2032 ).\n4 w=x,y \u2032\nw =x,y\n\nWe are now prepared to define a Markov chain:\nDefinition 1 (Markov chain M) Let M be a\nMarkov chain on a set S = {0, x, y, z}N = {q}. The\ntransition process is described as follows. In each step,\ni and j are randomly chosen from {1, * * * , N } and the\ntransition from q \u2208 S to p \u2208 S occurs probabilistically\naccording to Table II. The transition probability from q\nto p and the probability distribution over p after t steps\nare denoted by P(q, p) and \u03a0t (p), respectively. The\ninitial distribution \u03a00 (p) is identified with \u03be02 (p).\nProposition 1 The probability distribution \u03a0t (p) of\nthe Markov chain M coincides with E[\u03bet2 (p)| |\u03c60 i].\nSince the initial distribution of the Markov chain M is\n\nP(p, r)\u03a00 (r)\nP(p, r)\u03be02 (r)\n\n= E[\u03be12 (p)| |\u03c60 i],\nwhere the last equation is obtained using Table I with\nthe definition of the Markov chain M. By induction on\nt, Proposition 1 is proven. For example\nX\n\u03a02 (p) =\nP(p, r)\u03a01 (r)\nr\n\n=\n\nX\nr\n\n= E[\n=\n\nw =x,y\n\nw =x,y\n\nX\nr\n\nAt = \u03bet (p),\n1 X\n\u03bet (ppi \u2192\u00acw,pj \u2192w\u2032 ),\nBt (w) =\n2 \u2032\n\n1 X\nCt (w) =\n\u03bet (ppi \u2192w\u2032 ,pj \u2192\u00acw ),\n2 \u2032\n\nX\nr\n\nwhere each case is defined by\n\nDt =\n\n(pi , pj ) Probability\n\nP(p, r)E[\u03be12 (r)| |\u03c60 i]\n\nX\n\nP(p, r)\u03be12 (r)| |\u03c60 i]\n\nr\n2\nE[\u03be2 (p)| |\u03c60 i].\n\nWe recall that a probability distribution \u03a0 can be\nviewed as a vector in a 4N -dimensional space, which we'll\ncall VS , where S = {0, x, y, z}N . For a given t, the set\nof all possible\nP \u03a0t comprise the probability simplex in VS\ndefined by\np \u03a0t (p) = 1. The transition rules given\nin Tables I,II define a transition matrix P on VS with\nmatrix elements written as P(q, p).\nD.\n\nIrreducible decomposition of the Markov chain\n\nIn this subsection, we give the irreducible decomposition of VS . By the definition of the Markov chain M,\nit is obvious that the number of x and y in q is invariant under the action of the transition matrix P. Thus\nwe obtain the irreducible decomposition of VS given by\nProposition 2 (see also Fig. 3).\nProposition 2 (Irreducible decomposition of S)\nFor q = q1 q2 * * * qN \u2208 S = {0, x, y, z}N , let X(q) be the\nsequence {i \u2208 [1, * * * , N ]|qi \u2208 {x, y}} and let S(\u0393) be the\nset defined by\nS(\u0393) := {q|X(q) = \u0393},\n\n\f8\n\nFIG. 4: (Color online) Graph of the Markov chain M\u0303\u0393 . Directed colored lines imply transition occurs with a fixed probability. Transition probabilities are given in Proposition 3.\nFIG. 3: (Color online) An example of some irreducible sets of\nM when N = 3. Directed lines imply the transition occurs\nwith a fixed probability. The probability of blue (dotted),\nred (solid), green (dashed) and purple (dashed-dotted) lines\nis 1/6, 1/12, 1/3 and 1, respectively. Elements such as 000,\nz00 and so on are invariant under the Markov process.\n\nHence, its expectation value is\n(t)\n\nE[Tr(\u03c6\u0302A )2 | |\u03c60 i] = 2N\u0100\n= 2N\u0100\n\nwhere \u0393 is any subset of {1, 2, * * * , N }. Then, for the\nMarkov chain M, the irreducible decomposition of VS is\ngiven by\nVS =\n\n\u2295 V{q} \u2295 VS(\u0393) ,\n\nq\u2208S(\u2205)\n\n\u03936=\u2205\n\nwhere VS \u2032 is the vector space defined by the subset S \u2032 .\nSince V{q} is always one dimensional by definition, we\nhave that \u03a0t (q) = \u03a00 (q) for all q \u2208 S(\u2205) and for all t.\nThus \u03a0t (q \u2208 S(\u2205)) is given by\n\u03a0t (q) = \u03a00 (q) = \u03be0 (q)2\n= 2\u2212N h\u03c60 | \u03c3q |\u03c60 i2\n=2\n\n\u2212N\n\nX\n\nra2 rb2\n\na,b\n\nN\nY\n\ni=1\n\n[\u03b4qi 0 + \u03b4qi z (1 \u2212 2ai )(1 \u2212 2bi )],\n(13)\n\nReduction of the Markov chain\n(A)\n\nIn order to describe the evolution of EL (|\u03c6t i), a full\ninvestigation of the Markov chain M is not necessary due\nto the definition of the linear entropy SL (\u03c1\u0302) = 1 \u2212 Tr\u03c1\u03022 .\nThis can be seen by considering the reduced density matrix of |\u03c6t i on a subsystem A.\n(t)\n\n\u03c6\u0302A = Tr\u0100 |\u03c6t ih\u03c6t |\n1 X\n= N/2\n\u03bet (q)Tr\u0100 \u03c3q ,\n2\nq\n(t)\n\nand Tr(\u03c6\u0302A )2 is given by\n(t)\n\nTr(\u03c6\u0302A )2 = 2N\u0100\n\nE[\u03bet (q)2 | |\u03c60 i]\n\nX\n\n\u03a0t (q).\n\nq s.t.\nqi =0,i\u2208\u0100\n\nq s.t.\nqi =0,i\u2208\u0100\n\nThus, it is sufficient to investigate \u03a0t (q) for q such that\nqi = 0 for i \u2208 \u0100. The only important property is the\nnumber of non-zero terms in q. For this reason, let us\ndefine the set \u03c7(\u0393) (q) as\n\u03c7(\u0393) (q) := {i \u2208 [1, * * * , N ]|qi 6= 0, q \u2208 S(\u0393)},\nwhich indicates the positions of non-zero terms in q \u2208\nS(\u0393). Using this notation, the expectation value is written by\nX X\n(t)\nE[Tr(\u03c1A )2 | |\u03c60 i] = 2N\u0100\n\u03a0t (q).\n(14)\n\u0393\u2282A\n\nwhere we have used the fact that, for q \u2208 S(\u2205), qi \u2208 {0, z}\nfor all i and \u03c3q := \u03c3q1 \u2297 * * * \u2297 \u03c3qN .\nE.\n\nX\n\nX\n\nq s.t.\nqi =0,i\u2208\u0100\n\n\u03bet (q)2 .\n\nq s.t.\n\u03c7(\u0393) (q)=A\n\nSince \u03a0t (q) for q \u2208 S(\u2205) is already given by Eq. (13), we\nconsider only q \u2208 S(\u0393) for \u0393 6= \u2205.\nFor this reason, we can reduce the Markov chain M\nto a simpler Markov chain M\u0303\u0393 . For a given number of\nx or y entries \u03b3 := |\u0393| in q, the number of non-zero elements |\u03c7(\u0393) (q)| can take values {\u03b3, \u03b3 + 1, * * * , N }. The\nnew Markov chain is a drunkard's walk on this set (see\nFig, 4), with transition probabilities given by the following proposition.\nProposition 3 For the Markov chain M\u0303\u0393 defined on\n{i \u2208 {\u03b3, * * * N }}, a transition from i to j occurs with\nprobability,\n2\u03b3(N \u2212 i)\n,\nN (N \u2212 1)\n2\u03b3(i \u2212 \u03b3)\nP (\u0393) (i, j = i \u2212 1) =\n,\nN (N \u2212 1)\n\u03b3(\u03b3 \u2212 1) + (N \u2212 \u03b3)(N \u2212 \u03b3 \u2212 1)\n.\nP (\u0393) (i, j = i) =\nN (N \u2212 1)\n\nP (\u0393) (i, j = i + 1) =\n\nThis is directly induced from the definitions of the\nMarkov chain M and M\u0303. For instance, the transition\ni \u2192 i + 1 in M\u0303\u0393 occurs if and only if (qi , qj ) = (wxy , 0)\n\n\f9\nor (qi , qj ) = (0, wxy ) in M. As the number of zeroes is\nN \u2212 i and the number of wxy = \u03b3, its probability is given\n\u2212i)\nby N\u03b3(N\n(N \u22121)/2 .\nAs stated in the introductory subsection, since the\nMarkov chain M\u0303\u0393 is irreducible and aperiodic, it has a\n(\u0393)\nunique stationary distribution \u03a0\u221e , which is determined\nby the detailed balance condition and the normalization.\nThe detailed balance condition gives the equation\n(\u0393)\n(\u0393)\n\u03a0(\u0393)\n(i, i + 1) = \u03a0(\u0393)\n(i + 1, i).\n\u221e (i)P\n\u221e (i + 1)P\n\nN \u2212\u03b3\ni\u2212\u03b3\n\n\u03a0(\u0393)\n\u221e (i) =\n\nX\n\nX\n\n=\n\n\u03a0(\u0393)\n\u221e (i) =\n\ni=\u03b3\n\nX\n\n\u03a00 (q) =\n\n\u03a0(\u0393)\n\u221e (\u03b3).\n\n(15)\n\nX\n\n\u03be02 (q).\n\ni\u2208\u0393\n\ni\u2208\u0393\n/\n\nThus the stationary distribution for a given subset \u0393 is\n!\nY\n1\nN \u2212\u03b3 X 2 2Y\n(\u0393)\n\u03b4ai bi .\nra rb\n(1 \u2212 \u03b4ai bi )\n\u03a0\u221e (i) = N \u2212\u03b3\n2\ni \u2212 \u03b3 a6=b\ni\u2208\u0393\ni\u2208\u0393\n/\n\n(17)\n\nq s.t.\n\u03c7(\u2205) (q)\u2282A\n\n+\n\n= 2NA\n\nY\n\n\u03b4ai bi .\n\nq s.t.\n\u03c7(\u0393) (q)\u2282A\n\nNA NA \u2212\u03b3\nX X\n( i\u2212\u03b3 )\n\n\u03a0(\u0393)\n\u221e (i)\nN \u2212\u03b3\n(\n)\ni\u2212\u03b3\nA\u2283\u03936=\u2205 i=1\nY\nY\nX X\nX\nA \u2212\u03b3\n(1 \u2212 \u03b4ai bi )\n\u03b4ai bi\nNA (Ni\u2212\u03b3\n)\n=\nra2 rb2\n\n=\n\ni=\u03b3\n\nA\u2283\u03936=\u2205 a6=b\n\n=2\n\n\u2212N\u0100\n\nX\n\nra2 rb2\n\na6=b\n\nY\n\n\u03b4ai bi ,\n\nwhere we have used the relation\nY\nY\nX Y\n(1 \u2212 \u03b4ai bi ) = \u2212\u03b4ab +\n\u03b4ai bi\n\u03b4ai bi .\ni\u2208\u0393\n\ni\u2208\u0100\n\n(T )\n\nlim E[Tr(\u03c6\u0302A )2 | |\u03c60 i]\nX\nX\nY\nY\n\u03b4ai bi ) \u2212\nra4 ,\n=\nra2 rb2 (\n\u03b4ai bi +\n\nT \u2192\u221e\n\ni\u2208A\n\n(A)\n\nA\u2283\u03936=\u2205\n\ni\u2208\u0393\n\ni\u2208\u0100\n\na\n\n(T )\n\nand since EL (|\u03c6T i) = 1\u2212Tr(\u03c6\u0302A )2 , Eq. (9) is obtained.\n\n\u03a0T (q)\n\nX\n\ni\u2208\u0393\n/\n\ni\u2208\u0100\n\na,b\n\nq s.t.\n\u03c7(\u0393) (q)\u2282A\n\nX\n\n[\u03b4qi 0 + \u03b4qi z (1 \u2212 2ai )(1 \u2212 2bi )]\n\nq s.t.\ni=1\n\u03c7(\u2205) (q)\u2282A\n\nCombining the two we arrive at the final expression\n\n(T )\n\n\u0014\n\nN\nY\n\nA\u2283\u03936=\u2205 i\u2208\u0393\n/\n\n(A)\n\nCalculation of limT \u2192\u221e E[SL (|\u03c6T i)]\n\nWe will now calculate the large time limit of\nthe expectation value of the amount of entanglement\n(A)\nlimT \u2192\u221e E[EL (|\u03c6T i)] using the results of the previous\ntwo subsections. From Eq. (14) we have\n\n= 2N\u0100\n\nX\n\nA\u2283\u03936=\u2205\n\n2\nRecalling\nP that \u03be0 (q) = h\u03c60 | \u03c3q |\u03c60 i, it is not difficult to\ncompute q\u2208S(\u0393) \u03be02 (q), which gives\nX\nY\nY\nX\n\u03b4ai bi .\n\u03be02 (q) =\nra2 rb2\n(1 \u2212 \u03b4ai bi )\n\n\u0393\u2282A\n\ni\u2208A\n\nThe second term in Eq. (18) is obtained from the sta(\u0393)\ntionary distributions \u03a0\u221e (i) given by Eq. (17). From the\ndefinition of the Markov chain M, for q, q\u2032 \u2208 S(\u0393), if the\nnumber of z in q is equal to that in q\u2032 , \u03a0\u221e (q) = \u03a0\u221e (q\u2032 ),\nso that\nX\nX\n\u03a0\u221e (q)\n\nHence, the stationary distribution is given by\n!\nX\n1\nN \u2212\u03b3\n(\u0393)\n\u03a0\u221e (i) = N \u2212\u03b3\n\u03be02 (q).\n2\ni \u2212 \u03b3 q\u2208S(\u0393)\n\nE[Tr(\u03c6\u0302A )2 | |\u03c60 i]\nX\nX\n= 2N\u0100\n\n\u03b4ai bi ,\n\nra2 rb2\n\n[\u03b4qi 0 + \u03b4qi z (1 \u2212 2ai )(1 \u2212 2bi )]\n\ni\u2208A\n\ni=\u03b3\n\nF.\n\nY\n\ni=1\n\nwhere the last expression is derived from the relation\n\n(16)\n\nN \u2212\u03b3 (\u0393)\n\u03a0\u221e (\u03b3).\n\u03a0(\u0393)\n\u221e (i) = 2\n\na6=b\n\nra2 rb2\n\na,b\n\nOn the other hand, Eq. (15) gives\n\nq\u2208S(\u0393)\n\nX\n\nN\nY\n\nX\na,b\n\nq\u2208S(\u0393)\n\nq\u2208S(\u0393)\n\nN\nX\n\n2\n\n\u2212N\n\nq s.t.\n\u03c7(\u2205) (q)\u2282A\n\nThe normalization in S(\u0393) depends on the input state\n|\u03c60 i as\nN\nX\n\n\u03a0T (q)\n\nq s.t.\n\u03c7(\u2205) (q)\u2282A\n\n= 2\u2212N\u0100\n\nUsing this equation, we obtain\n!\n\nThe first term in Eq. (18) is calculated from Eq. (13)\nas\n\nX\n\nq s.t.\n\u03c7(\u0393) (q)\u2282A\n\n\u0015\n\u03a0T (q).\n\nG.\n\nMixing time\n\n(18)\nIn this final subsection we bound the mixing time of\nthe Markov chain M\u0303\u0393 using Theorem 3 and Corollary 1.\n\n\f10\nFrom Eq. (17), the stationary distribution in S(\u0393) is\ngiven by\n!\n1\nN \u2212\u03b3\n(\u0393)\n\u03ba(\u0393) (|\u03c60 i),\n\u03a0\u221e (i) = N \u2212\u03b3\n2\ni\u2212\u03b3\n\nfor all A, it is sufficient for each Markov chain M\u0303\u0393 to\nconverge with error \u01eb\u2032 := \u01eb/2N since the linear entropy is\nthe sum of the stationary distributions in M\u0303\u0393 as shown\nby Eq. (18). Therefore, from Theorem 3 and Corollary\n1, we obtain an upper bound on Tmix (\u01eb) given by\n\nwhere we have introduced the notation \u03ba(\u0393) (|\u03c60 i) :=\nQ\nQ\nP\n(\u0393)\n2 2\ni\u2208\u0393\n/ \u03b4ai bi . Thus \u03a0\u221e (min) is\ni\u2208\u0393 (1 \u2212 \u03b4ai bi )\na6=b ra rb\ngiven by\n!\n1\nN \u2212\u03b3\n(\u0393)\n\u03a0\u221e (min) =\nmin\n\u03ba(\u0393) (|\u03c60 i)\ni\u2208{\u03b3,*** ,N } 2N \u2212\u03b3\ni\u2212\u03b3\n\n\u0014\n\u00152\nN (N \u2212 1) N \u2212\u03b3 (\u0393)\nTmix (\u01eb) \u2264 max\n2\n\u03ba (|\u03c60 i)\n\u0393\n2\u03b3(N \u2212 \u03b3)\n\u0014\n\u0015\n\u0001\n\u01eb\n(\u0393)\n\u00d7 N \u2212 \u03b3 \u2212 log N * \u03ba (|\u03c60 i) .\n2\n\n=\n\n1\n\u03ba(\u0393) (|\u03c60 i).\n2N \u2212\u03b3\n\nLet \u03c1(\u0393) be the expression defined by Eq. (10) for the\nMarkov chain M\u0303\u0393 . An upper bound of \u03c1(\u0393) for M\u0303\u0393 is\nthen given by\nmaxe\u2208E\n\u03c1\n\n(\u0393)\n\n\u2264\n\nP\n\ni,j\nEij \u220be\n\n(\u0393)\n\n(\u0393)\n\n\u03a0\u221e (i)\u03a0\u221e (j)\n.\n\nmine\u2208E Q(\u0393) (e)\n\nSince the graph of the Markov chain M\u0303\u0393 is linear, as\nshown in Fig. 4, an upper bound on the maximum of\nP\n(\u0393)\n(\u0393)\ni,j \u03a0\u221e (i)\u03a0\u221e (j) is given by\nEij \u220be\n\nX\n\n(\u0393)\n\u03a0(\u0393)\n\u221e (i)\u03a0\u221e (j)\n\ni,j\nEij \u220be\n\n=\n\n\u0012\n\n\u03ba(\u0393) (|\u03c60 i)\n2N \u2212\u03b3\n\n\u00132\n\n\u2264\n\n\u0012\n\n\u03ba(\u0393) (|\u03c60 i)\n2N \u2212\u03b3\n\n\u00132\n\n= (\u03ba\n\n(\u0393)\n\ni\nX\n\nN\nX\n\u2212\u03b3\nN \u2212\u03b3\n(Ny\u2212\u03b3\n)\nmax\n( x\u2212\u03b3 )\ni\u2208{1,***N }\nx=1\ny=i+1\n\nmax\n\ni\u2208{1,***N }\n\n2\n\n(|\u03c60 i)) .\n\nN\n\u2212\u03b3\nX\n\n(N x\u2212\u03b3 )\n\nx=0\n\nN\n\u2212\u03b3\nX\n\n(N y\u2212\u03b3 )\n\ny=0\n\nOn the other hand, the mine\u2208E Q(\u0393) (e) factor can be\ncomputed as follows. In the Markov chain M\u0303\u0393 , edges are\nof the form (i, i + 1) or (i, i \u2212 1). By the symmetry of the\nlinear graph, one sees that Q(\u0393) (N +\u03b3 \u2212i, N +\u03b3 \u2212i\u22121) =\nQ(\u0393) (i, i + 1), and it is sufficient to consider the minimum\nof Q(\u0393) (i, i + 1), which is given by\nmin Q(\u0393) (i, i + 1) =\ni\n\n2\u03b3(N \u2212 \u03b3)\n\u03ba(\u0393) (|\u03c60 i).\n2N \u2212\u03b3 N (N \u2212 1)\n\nThus \u03c1(\u0393) is bounded from above as\n\u03c1(\u0393) \u2264\n\n2N \u2212\u03b3 N (N \u2212 1) (\u0393)\n\u03ba (|\u03c60 i).\n2\u03b3(N \u2212 \u03b3)\n\nIn order to achieve\n\u2200T > Tmix (\u01eb),\n\n(A)\nE[EL (|\u03c6T i)]\n\n\u2212\n\n(A)\nhEL i\u03a5comp\nphase\n\n<\u01eb\n\nThis is dominated by the factor [2N \u2212\u03b3 \u03ba(\u0393) (|\u03c60 i)]2 . Thus,\nmax\u0393 \u03ba(\u0393) (|\u03c60 i) = O(2\u2212N ) is sufficient for Tmix (\u01eb) to be\na polynomial in N .\nThis concludes the proof.\nVI.\n\nSUMMARY\n\nWe have defined phase-random states as an ensemble\nof states with fixed amplitudes and with uniformly distributed phases in a fixed basis. We have discussed their\nuse for the realization of canonical distributions in statistical mechanics. We then derived a general formula\nfor the average amount of entanglement of phase-random\nstates. Applying these results, we have argued for the\nsimulatability of time evolving states by a Hamiltonian\ndynamics, and have shown the difficulty of their simulation for semi-classical Hamiltonian systems by MPSs.\nFinally, we have proven that an ensemble of states that\nprovides the same average entanglement of phase-random\nstates can be generated efficiently by a phase-random circuit composed of relatively simple gates.\nWe acknowledge V. Vedral for useful comments. This\nwork is supported by Project for Developing Innovation Systems of MEXT, Japan and JSPS by KAKENHI\n(Grant No. 222812, No. 23540463 and 23240001).\nAppendix A: Concentration of measure\n\nIn this appendix, we show that for the ensemble of\nphase-random states with equal-amplitudes in a separable basis, \u03a5eq,sep\nphase , the amount of entanglement is highly\nconcentrated around the average. Formally, by defin(A)\n(A)\n(A)\n|\ning \u2206EL (|\u03c6eq,sep i) := |EL (|\u03c6eq,sep i) \u2212 hEL i\u03a5eq,sep\nphase\nN\nP\n2\nwhere |\u03c6eq,sep i = 2\u2212N/2 n=1 ei\u03c6n |usep\nn i, we prove that\n(A)\nProb[\u2206EL (|\u03c6eq,sep i) > 2/2N + \u01eb] \u2264 exp[\u2212c\u01eb4 2N ] where\nc = 1/(211 \u03c0 2 ).\nFirst, for two states in the ensemble \u03a5eq,sep\nphase deP\ni\nand\n|\u03c6\u2032 i =\nnoted by |\u03c6i = 2\u2212N/2 a ei\u03c6a |usep\na\nP\n\u2032\n\u2032\n2\u2212N/2 a ei\u03c6a |usep\na i, let us define the distance d(\u03c6, \u03c6 )\n2N\nbetween them in the parameter space [0, 2\u03c0) by\nd(\u03c6, \u03c6\u2032 ) =\n\n1 X |\u03c6a \u2212 \u03c6\u2032a |\n.\n2\u03c0 a\n2N\n\n\f11\nThen, using the theorems in Appendix C of Ref. [1], we\nobtain the upper bound of the concentration function\n\u03b1d (r) by\n\u03b1d (r) \u2264 exp[\u2212\n\nr2 N\n2 ],\n8\n\n(A1)\n\n(A)\n\nwhere the concentration function \u03b1d (r) implies that,\nN\nfor any subset A \u2208 [0, 2\u03c0)2 with measure 1/2, its rneighborhood Ar with respect to the metric d has measure at least 1 \u2212 \u03b1d (r) [18].\nNow, we evaluate the amount of the change in the pa(A)\nrameter space necessary to change \u2206EL (|\u03c6eq,sep i) more\nthan \u01eb, which is obtained from the following proposition;\n\u2032\n\nProposition 4 For |\u03c6i and |\u03c6 i \u2208\n\nHence, in order to change \u2206EL (|\u03c6eq,sep i) more than\n\u01eb2\n. Combining\n\u01eb, d(\u03c6, \u03c6\u2032 ) must be changed more than 16\u03c0\nthis with the concentration of measure given by (A1), we\nobtain\n(A)\n\n(A2)\n\nProof 1 Using the notation \u03c6\u0302A = Tr\u0100 |\u03c6ih\u03c6|, we calculate\n\n\u2264 exp[\u2212c\u01eb4 2N ], (A5)\n\n\u03a5eq,sep\nphase\n\nq\n(A)\n\u2264 2 h(\u2206EL )2 i\u03a5eq,sep\nphase\n\n|\u2206EL (|\u03c6i) \u2212 \u2206EL (|\u03c6\u2032 i)|\n(A)\n\n(A)\n\n\u2264 |EL (|\u03c6i) \u2212 EL (|\u03c6\u2032 i)|\n=\n\n|Tr\u03c6\u03022A\n\n\u2212\n\n= 2\u03c3E (A) ,\nL\n\n2\nTr\u03c6\u0302\u2032 A |\n\n(A)\n\nwhere \u03c3E (A) is the standard deviation of EL . Since\nL\n\nthe standard deviation \u03c3E (A) for \u03a5eq,sep\nphase can be directly\n\n= |Tr(\u03c6\u0302A \u2212 \u03c6\u0302\u2032 A )(\u03c6\u0302A + \u03c6\u0302\u2032 A )|\n\u2264 ||\u03c6\u0302A \u2212 \u03c6\u0302\u2032 A ||2 ||\u03c6\u0302A + \u03c6\u0302\u2032 A ||2\n\u2264 2DHS (\u03c6\u0302A , \u03c6\u0302\u2032 A )\n\u2264 2DHS (|\u03c6ih\u03c6| , |\u03c6\u2032 ih\u03c6\u2032 |)\n\u2264 2| |\u03c6i \u2212 |\u03c6\u2032 i |,\n\n(A)\n\n(A)\n\n\u03bcM (\u2206EL (|\u03c6eq,sep i)) \u2264 2h\u2206EL i\u03a5eq,sep\nphase\n\u001d\n\u001cq\n(A)\n(\u2206EL )2\n=2\n\n(A)\n\n(A)\n\n(A)\n\nProb[\u2206EL (|\u03c6eq,sep i) > \u03bcM (\u2206EL (|\u03c6eq,sep i)) + \u01eb]\n\nwhere \u03bcM represents the median and c = 1/(211\u221a\n\u03c0 2 ). By\nusing Markov's inequality and the convexity of x, the\nmedian is bounded from above such that\n\n\u03a5eq,sep\nphase ,\n\n\u221a p\n(A)\n(A)\n|\u2206EL (|\u03c6i) \u2212 \u2206EL (|\u03c6\u2032 i)| \u2264 4 \u03c0 d(\u03c6, \u03c6\u2032 ).\n\n\u221a\nwhere ||A||2 := TrAA\u2020 is the Hilbert-Schmidt norm and\nDHS (A, B) = ||A \u2212 B||2 . Inequalities (A3) and (A4) are\nobtained using Cauchy-Schwartz and Kadison's\np inequalities [19], respectively. Since | |\u03c6i \u2212 |\u03c6\u2032 i | \u2264 4\u03c0d(\u03c6, \u03c6\u2032 )\n[1], we obtain Eq. (A2).\n\nL\n\n(A3)\n(A4)\n\n[1] N. Linden, S. Popescu, A. J. Short and A. Winter, Phys.\nRev. E 79, 061103 (2009).\n[2] P. Hayden and J. Preskill, JHEP 0709:120 (2007).\n[3] C. H. Bennett, P. Hayden, D. W. Leung, P. W. Shor and\nA. Winter, IEEE Trans. Inform. Theory, vol. 51, no. 1,\npp 56-74 (2005); B. M. Terhal, David P. DiVincenzo and\nD. W. Leung, Phys. Rev. Lett. 86, 5807-5810 (2001); P.\nHayden, D. Leung, P. W. Shor and A. Winter Commun.\nMath. Phys. 250(2):371-391(20040).\n[4] T. N. Ikeda, Y. Watanabe and M. Ueda, Phys. Rev. E\n84, 021130 (2011).\n[5] E. Lubkin, J. Math. Phys. 19 1028 (1978); D. N. Page,\nPhys. Rev. Lett., 71:1291, (1993); S. K. Foong and S.\nKanno, Phys. Rev. Lett. 72, 1148 (1994); P. Hayden, D.\nW. Leung and A. Winter, Comm. Math. Phys. Vol. 265,\nNo. 1, pp. 95-117 (2006).\n[6] S. Goldstein, J. L. Lebowitz, R. Tumulka and N. Zanghi\nPhys. Rev. Lett. 96, 050403 (2006); S. Popescu, A. J.\nShort and A. Winter, Nature Physics, 2:754-758 (2006).\n[7] S. Goldstein, J. L. Lebowitz, R. Tumulka and N. Zanghi,\nEuropean Phys. J. H 35: 173-200 (2010).\n[8] D. Shepherd and M. J. Bremner, Proc. R. Soc. A 465,\n1413-1439 (2009); M. J. Bremner, R. Jozsa and D. J.\n\ncalculated and is upper bounded by 2\u2212N , we obtain\n\u0015\n\u0014\n2\n(A)\nProb \u2206EL (|\u03c6eq,sep i) > N + \u01eb \u2264 exp[\u2212c\u01eb4 2N ].\n2\n\nShepherd, Proc. R. Soc. A, 467, 459 (2011).\n[9] C. Kruszynska and B. Kraus, Phys. Rev. A 79, 052304\n(2009).\n[10] J. Eisert, M. Cramer and M.B. Plenio, Rev. Mod. Phys.\n82, 277 (2010).\n[11] D. A. Meyer and N. R. Wallach, J. Math. Phys. 43 4273\n(2002).\n[12] S. Bravyi, M. B. Hastings and F. Verstraete, Phys. Rev.\nLett. 97, 050401 (2006).\n[13] R. Oliveira, O. C. O. Dahlsten and M. B. Plenio, Phys.\nRev. Lett. 98, 130502 (2007).\n[14] O. C. O. Dahlsten, R. Oliveira and M. B. Plenio, J. Phys.\nA: Math. Theor. 40 8081-8108 (2007).\n[15] Y. Nakata and M. Murao, arXiv:1206.4451 (2012).\n[16] D. A. Levin, Y. Peres and E. L. Wilmer, Markov\nChains and Mixing Times, American Mathematical Society, Providence (2009).\n[17] A. Sinclair, Comb. Prob. Comp. 1, 351-370 (1992).\n[18] M. Leudox, The Concentration of Measure Phenomenon,\nAMS Monographs, Providence, RI, Vol. 89 (2001).\n[19] R. V. Kadison, Ann. of Math. 56 (1952) 494.\n\n\f"}