{"id": "http://arxiv.org/abs/nlin/0507006v2", "guidislink": true, "updated": "2006-08-14T08:41:21Z", "updated_parsed": [2006, 8, 14, 8, 41, 21, 0, 226, 0], "published": "2005-07-04T07:28:10Z", "published_parsed": [2005, 7, 4, 7, 28, 10, 0, 185, 0], "title": "Detecting Generalized Synchronization Between Chaotic Signals: A\n  Kernel-based Approach", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=nlin%2F0507057%2Cnlin%2F0507031%2Cnlin%2F0507047%2Cnlin%2F0507028%2Cnlin%2F0507067%2Cnlin%2F0507053%2Cnlin%2F0507004%2Cnlin%2F0507011%2Cnlin%2F0507056%2Cnlin%2F0507055%2Cnlin%2F0507060%2Cnlin%2F0507009%2Cnlin%2F0507037%2Cnlin%2F0507064%2Cnlin%2F0507051%2Cnlin%2F0507041%2Cnlin%2F0507052%2Cnlin%2F0507066%2Cnlin%2F0507029%2Cnlin%2F0507045%2Cnlin%2F0507002%2Cnlin%2F0507020%2Cnlin%2F0507018%2Cnlin%2F0507034%2Cnlin%2F0507015%2Cnlin%2F0507012%2Cnlin%2F0507050%2Cnlin%2F0507025%2Cnlin%2F0507043%2Cnlin%2F0507008%2Cnlin%2F0507013%2Cnlin%2F0507036%2Cnlin%2F0507023%2Cnlin%2F0507063%2Cnlin%2F0507059%2Cnlin%2F0507042%2Cnlin%2F0507014%2Cnlin%2F0507022%2Cnlin%2F0507030%2Cnlin%2F0507048%2Cnlin%2F0507035%2Cnlin%2F0507065%2Cnlin%2F0507007%2Cnlin%2F0507040%2Cnlin%2F0507016%2Cnlin%2F0507005%2Cnlin%2F0507061%2Cnlin%2F0507033%2Cnlin%2F0507046%2Cnlin%2F0507044%2Cnlin%2F0507026%2Cnlin%2F0507010%2Cnlin%2F0507024%2Cnlin%2F0507017%2Cnlin%2F0507058%2Cnlin%2F0507027%2Cnlin%2F0507006%2Cnlin%2F0008021%2Cnlin%2F0008013%2Cnlin%2F0008018%2Cnlin%2F0008022%2Cnlin%2F0008034%2Cnlin%2F0008017%2Cnlin%2F0008024%2Cnlin%2F0008031%2Cnlin%2F0008020%2Cnlin%2F0008042%2Cnlin%2F0008037%2Cnlin%2F0008016%2Cnlin%2F0008012%2Cnlin%2F0008019%2Cnlin%2F0008005%2Cnlin%2F0008002%2Cnlin%2F0008025%2Cnlin%2F0008007%2Cnlin%2F0008027%2Cnlin%2F0008039%2Cnlin%2F0008003%2Cnlin%2F0008009%2Cnlin%2F0008038%2Cnlin%2F0008029%2Cnlin%2F0008006%2Cnlin%2F0008036%2Cnlin%2F0008028%2Cnlin%2F0008032%2Cnlin%2F0008033%2Cnlin%2F0008026%2Cnlin%2F0008035%2Cnlin%2F0008014%2Cnlin%2F0008040%2Cnlin%2F0008004%2Cnlin%2F0008011%2Cnlin%2F0008010%2Cnlin%2F0008023%2Cnlin%2F0008001%2Cnlin%2F0008015%2Cnlin%2F0008030%2Cnlin%2F0008008%2Cnlin%2F0508001%2Cnlin%2F0508008%2Cnlin%2F0508013&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Detecting Generalized Synchronization Between Chaotic Signals: A\n  Kernel-based Approach"}, "summary": "A unified framework for analyzing generalized synchronization in coupled\nchaotic systems from data is proposed. The key of the proposed approach is the\nuse of the kernel methods recently developed in the field of machine learning.\nSeveral successful applications are presented, which show the capability of the\nkernel-based approach for detecting generalized synchronization. It is also\nshown that the dynamical change of the coupling coefficient between two chaotic\nsystems can be captured by the proposed approach.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=nlin%2F0507057%2Cnlin%2F0507031%2Cnlin%2F0507047%2Cnlin%2F0507028%2Cnlin%2F0507067%2Cnlin%2F0507053%2Cnlin%2F0507004%2Cnlin%2F0507011%2Cnlin%2F0507056%2Cnlin%2F0507055%2Cnlin%2F0507060%2Cnlin%2F0507009%2Cnlin%2F0507037%2Cnlin%2F0507064%2Cnlin%2F0507051%2Cnlin%2F0507041%2Cnlin%2F0507052%2Cnlin%2F0507066%2Cnlin%2F0507029%2Cnlin%2F0507045%2Cnlin%2F0507002%2Cnlin%2F0507020%2Cnlin%2F0507018%2Cnlin%2F0507034%2Cnlin%2F0507015%2Cnlin%2F0507012%2Cnlin%2F0507050%2Cnlin%2F0507025%2Cnlin%2F0507043%2Cnlin%2F0507008%2Cnlin%2F0507013%2Cnlin%2F0507036%2Cnlin%2F0507023%2Cnlin%2F0507063%2Cnlin%2F0507059%2Cnlin%2F0507042%2Cnlin%2F0507014%2Cnlin%2F0507022%2Cnlin%2F0507030%2Cnlin%2F0507048%2Cnlin%2F0507035%2Cnlin%2F0507065%2Cnlin%2F0507007%2Cnlin%2F0507040%2Cnlin%2F0507016%2Cnlin%2F0507005%2Cnlin%2F0507061%2Cnlin%2F0507033%2Cnlin%2F0507046%2Cnlin%2F0507044%2Cnlin%2F0507026%2Cnlin%2F0507010%2Cnlin%2F0507024%2Cnlin%2F0507017%2Cnlin%2F0507058%2Cnlin%2F0507027%2Cnlin%2F0507006%2Cnlin%2F0008021%2Cnlin%2F0008013%2Cnlin%2F0008018%2Cnlin%2F0008022%2Cnlin%2F0008034%2Cnlin%2F0008017%2Cnlin%2F0008024%2Cnlin%2F0008031%2Cnlin%2F0008020%2Cnlin%2F0008042%2Cnlin%2F0008037%2Cnlin%2F0008016%2Cnlin%2F0008012%2Cnlin%2F0008019%2Cnlin%2F0008005%2Cnlin%2F0008002%2Cnlin%2F0008025%2Cnlin%2F0008007%2Cnlin%2F0008027%2Cnlin%2F0008039%2Cnlin%2F0008003%2Cnlin%2F0008009%2Cnlin%2F0008038%2Cnlin%2F0008029%2Cnlin%2F0008006%2Cnlin%2F0008036%2Cnlin%2F0008028%2Cnlin%2F0008032%2Cnlin%2F0008033%2Cnlin%2F0008026%2Cnlin%2F0008035%2Cnlin%2F0008014%2Cnlin%2F0008040%2Cnlin%2F0008004%2Cnlin%2F0008011%2Cnlin%2F0008010%2Cnlin%2F0008023%2Cnlin%2F0008001%2Cnlin%2F0008015%2Cnlin%2F0008030%2Cnlin%2F0008008%2Cnlin%2F0508001%2Cnlin%2F0508008%2Cnlin%2F0508013&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A unified framework for analyzing generalized synchronization in coupled\nchaotic systems from data is proposed. The key of the proposed approach is the\nuse of the kernel methods recently developed in the field of machine learning.\nSeveral successful applications are presented, which show the capability of the\nkernel-based approach for detecting generalized synchronization. It is also\nshown that the dynamical change of the coupling coefficient between two chaotic\nsystems can be captured by the proposed approach."}, "authors": ["Hiromichi Suetani", "Yukito Iba", "Kazuyuki Aihara"], "author_detail": {"name": "Kazuyuki Aihara"}, "author": "Kazuyuki Aihara", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1088/0305-4470/39/34/009", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/nlin/0507006v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/nlin/0507006v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "20 pages, 15 figures. massively revised as a full paper; issues on\n  the choice of parameters by cross validation, tests by surrogated data, etc.\n  are added as well as additional examples and figures", "arxiv_primary_category": {"term": "nlin.CD", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "nlin.CD", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "physics.data-an", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/nlin/0507006v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/nlin/0507006v2", "journal_reference": "J. Phys. A: Math. Gen. 39 (2006) 10723-10742", "doi": "10.1088/0305-4470/39/34/009", "fulltext": "arXiv:nlin/0507006v2 [nlin.CD] 14 Aug 2006\n\nDetecting Generalized Synchronization Between\nChaotic Signals: A Kernel-based Approach\nHiromichi Suetani1,3 , Yukito Iba2 and Kazuyuki Aihara3,1\nE-mail: 1 suetani@aihara.jst.go.jp\nComplexity Modelling Project, ERATO, JST, 3-23-5 Uehara,\nShibuya-ku, Tokyo 151-0064, Japan\n2 The Institute of Statistical Mathematics, 4-6-7 Minami-Azabu, Minato-ku,\nTokyo 106-8569, Japan\n3 Institute of Industrial Science, The University of Tokyo, 4-6-1 Komaba,\nMeguro-ku, Tokyo 153-8505, Japan\n1 Aihara\n\nAbstract. A unified framework for analyzing generalized synchronization in\ncoupled chaotic systems from data is proposed. The key of the proposed approach\nis the use of the kernel methods recently developed in the field of machine learning.\nSeveral successful applications are presented, which show the capability of the\nkernel-based approach for detecting generalized synchronization, and dynamical\nchange of the coupling strength between two chaotic systems can be captured by\nthe proposed approach. It is also discussed how the kernel parameter is suitably\nchosen from data.\n\nPACS numbers: 05.45.Xt,05.45.Tp,02.50.Sk,05.10.-a\n\nSubmitted to: J. Phys. A: Math. Gen.\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n2\n\n1. Introduction\nSynchronization of chaotic systems has been an active research area in recent years [1].\nNow the notion of synchronization of chaotic systems is extended far beyond complete\nsynchronization between identical systems[2, 3, 4], and various kinds of nonlinear\nsynchronization have been proposed [1]. A significant extension is generalized\nsynchronization (GS) [5], which is defined by a time-independent nonlinear functional\nrelation y = \u03a8(x) between the states x and y of two systems X and Y .\nExperimental detection and characterization of GS from observed data is a\nchallenging problem, especially in biology; e.g., for study on nonlinear interdependence\nobserved in binding of different features in cognitive process [6] and epilepsies in the\nbrain [7, 8].\nIn unidirectionally coupled systems, a way to detect GS is to make an identical\ncopy Y \u2032 of the response system Y driven by the common signal from the driver system\nX, then investigate whether orbits of both Y and Y \u2032 coincide after transient [9, 10].\nHowever, it is very difficult to prepare an identical copy of the response system, and\nthis approach does not give any information on the structure of the synchronization\nmanifold M = {(x, y) : y = \u03a8(x)} in the state space.\nOn the other hand, several indices have been proposed [5, 7, 8, 11, 12, 13], to\nquantify nonlinear dependence between X and Y based on a local relation between\nthem. While the usefulness of these indices were shown in some examples [7, 8, 11],\nthose approaches are still ad-hoc, lacking systematic methods for unifying the local\nrelation of different regions in the state space.\nRecently, kernel methods have been attracting much attention in the machine\nlearning community as powerful tools for analyzing data with high nonlinearity\n[14, 15, 16, 17]. In this paper, we propose a novel approach for analyzing GS based\non Kernel Canonical Correlation Analysis (Kernel CCA) [18, 19, 20, 21] which is\na version of the kernel methods [22]\u2021. We will demonstrate that the Kernel CCA\nprovides a suitable index for measuring the nonlinear interdependence, and gives global\ncoordinates characterizing the synchronization manifold M of GS. Note that the latter\nhas not been addressed in conventional studies on the analysis of GS. The proposed\nmethod does not require explicit knowledge on the underlying equations behind time\nseries. Although we restrict our attention to the analysis of numerical experiments\nhere, it is also applicable to experimental data.\nThe present paper is organized as follows. In section 2, we introduce a formulation\nof the Kernel CCA. Sections 3 and 4 provide several successful applications of the\nKernel CCA for treating GS. In section 5, it is demonstrated that the nonstationary\nchange of the coupling strength between two chaotic systems can be captured by the\nproposed approach. In section 6, we discuss an issue on the choice of kernel parameters.\nOur conclusion is given in section 7.\n2. Kernel Canonical Correlation Analysis\nCanonical Correlation Analysis (CCA) is a multivariate analysis method to find a\npair of vectors that maximize the correlation coefficient between projections of signals\nonto them [23]. CCA is useful for detecting a linear relation between a pair of\nmultidimensional data sets, but cannot deal with the case like GS where there is\n\u2021 Preliminary results are reported in a conference proceedings [22] with a simpler example of detection\nof GS. Here, we give comprehensive treatments with examples of practical interests\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n3\n\na high nonlinear relation between two data sets. Extending the ability of CCA for\nanalyzing data with nonlinearity, kernelization of CCA has been proposed by several\nresearchers [18, 19, 20, 21]. An intuitive formulation of the Kernel CCA is as follows.\nFor a pair of multivariate variables (x, y) with x \u2208 Rp and y \u2208 Rq , the Kernel\nCCA seeks a pair of nonlinear scalar functions f : Rp \u2192 R and g : Rq \u2192 R such that\nan estimator of the correlation coefficient\ncov(f (x), g(y))\np\n\u03c1F = p\n(1)\nvar(f (x)) var(g(y))\n\nbetween f (x) and g(y) is maximized.\nMethods based on the expression (1) of the generalized correlation coefficient have\na long history [24, 25]. However the use of the kernel approach gives a notable progress\nin the subject, with a remarkably simple and flexible way of treating (1).\nThe essence of the kernel methods is an assumption that nonlinear functions f\nand g are well approximated by linear combinations of kernels on data points (xn , yn ),\nf (x) =\n\nN\nX\n\nn=1\n\n\u03b1n k(xn , x),\n\ng(y) =\n\nN\nX\n\n\u03b2n k(yn , y),\n\n(2)\n\nn=1\n\nwhere {(xn , yn )}N\nn=1 denotes a training data set of (x, y).\n\u2212kx\u2212x\u2032 k2\n\n(Gaussian), ((x * x\u2032 ) +\nExamples of kernels are k(x, x\u2032 ) = e 2\u03c32\nd\n\u2032\n\u03b8) ) (Polynomial), and tanh(\u03b7(x*x )+\u03b8) (Sigmoidal) [15, 16, 17]. A rich representation\nof nonlinear functions is allowed by suitably chosen weight coefficients {\u03b1n }N\nn=1 ,\n{\u03b2n }N\nn=1 and kernel parameters. At first sight, the dependence of the expressions for f\nand g on the given data {(xn , yn )}N\nn=1 brings some ad-hoc nature to the method. The\nassumption is, however, equivalent to the assumption that f and g are minimum norm\nfunctions in a Reproducing Kernel Hilbert Space (RKHS). It is proved by invoking\nrepresenter theorem in the theory of RKHS [15, 16, 17].\nSubstituting (2) into (1), and replacing covariance cov(*, *) and variances var(*)\nwith empirical averages over the data set {(xn , yn )}N\nn=1 , the Kernel CCA reduces to\nthe maximization of\nt\n\u03b1KX KY \u03b2\np\n\u03c1F = p\n,\n(3)\nt \u03b1K 2 \u03b1 t \u03b2K 2 \u03b2\nX\nY\n\nwhere \u03b1 = t (\u03b11 , \u03b12 , ..., \u03b1N ), \u03b2 = t (\u03b21 , \u03b22 , ..., \u03b2N ), and KX , KY are the Gram matrices\n(KX )i,j = k(xi , xj ) and (KY )i,j = k(yi , yj ) defined with the given sample. The Gram\nmatrix contains relevant topological information of data points in the state space. For\nN\nsimplicity, we tentatively assume that the averages of {f (xn )}N\nn=1 and {g(yn )}n=1 are\nzero. Later we will show that subtraction of the averages from data can be done in\nan implicit way and does not cause any technical difficulty.\nA naive generalization of CCA leads to the maximization of t \u03b1KX KY \u03b2 subject\nt\n2\nto \u03b1KX\n\u03b1 = t \u03b2KY2 \u03b2 = 1. The corresponding Lagrangian is\n\u03c1Y t\n\u03c1X t\n2\n( \u03b1KX\n\u03b1 \u2212 1) \u2212\n( \u03b2KY2 \u03b2 \u2212 1),\n(4)\nL0 = t \u03b1KX KY \u03b2 \u2212\n2\n2\nwhere \u03c1X and \u03c1Y are Lagrange multipliers. Taking derivatives of L0 with respect to\n\u03b1 and \u03b2, and \u03c1X = \u03c1Y = \u03c1 from the constraint, the Kernel CCA is formulated as the\nfollowing generalized eigenvalue problem:\n\u0012\n\u0013\u0012\n\u0013\u0012\n\u0013\n\u0012 2\n\u0013\n0\nKX KY\n\u03b1\n\u03b1\nKX\n0\n=\u03c1\n.\n(5)\nKY KX\n0\n\u03b2\n\u03b2\n0\nKY2\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n4\n\nThere is, however, a difficulty when the Gram matrices KX and KY are invertible.\n\u22121 \u22121\nBy multiplying both sides of (5) by (KX\nKX , KY\u22121 KY\u22121 ) from the left hand side, we\nhave\n1 \u22121\nKY \u03b2,\n(6)\n\u03b1 = KX\n\u03c1\n1\n\u03b2 = KY\u22121 KX \u03b1.\n(7)\n\u03c1\nSubstituting (7) into (6), we obtain\nI\u03b1 = \u03c12 \u03b1,\n\n(8)\n\nwhich gives a trivial solution \u03c1 = \u00b11. Such a situation is not uncommon, because\nthe Gram matrix is invertible when a Gaussian kernel is used and data points are\ndistinct each other. Thus the naive kernelization (5) of CCA does not provide useful\ninformation on the nonlinear dependence.\nTo overcome this problem we introduce small regularization terms in the\ndenominator of the right hand side of (3) as\nt\n\n\u03c1F = p\n\nt \u03b1K 2 \u03b1\nX\n\n\u03b1KX KY \u03b2\np\n,\n+ \u03bakf k2F t \u03b2KY2 \u03b2 + \u03bakgk2F\n\n(9)\n\nwhere kf k2F and kgk2F are quadratic norms of f and g on the RKHS defined as\nkf k2F =\n=\nkgk2F =\n=\n\nN\nX\n\n\u03b1n\u2032 f (xn\u2032 ) =\n\nn\u2032 =1\nt\n\u03b1KX \u03b1,\nN\nX\n\n\u03b2n\u2032 g(yn\u2032 ) =\n\nn\u2032 =1\nt\n\u03b2KY\n\nN X\nN\nX\n\n\u03b1n\u2032 \u03b1n k(xn , xn\u2032 )\n\nn\u2032 =1 n=1\n\n(10)\nN\nX\n\nN\nX\n\n\u03b2n\u2032 \u03b2n k(yn , yn\u2032 )\n\nn\u2032 =1 n=1\n\n\u03b2,\n\n(11)\n\nand \u03ba is its parameter. Note that although the parameter \u03ba 6= 0 is required for\na nontrivial result, the precise value of \u03ba is not important\u00a7 This insensitivity to\nthe value of \u03ba will be confirmed by a numerical experiment in the next section.\nAs well as (5), the maximization of the numerator t \u03b1KX KY \u03b2 in (9) subject to\nt\n2\n\u03b1KX\n\u03b1 + \u03bat \u03b1KX \u03b1 = t \u03b2KY2 \u03b2 + \u03bat \u03b2KY \u03b2 = 1 reduces to the following generalized\neigenvalue problem\n\u0012\n\u0013\u0012\n\u0013\n0\nKX KY\n\u03b1\nKY KX\n0\n\u03b2\n\u0012\n\u0013\u0012\n\u0013\nKX (KX + \u03baI)\n0\n\u03b1\n=\u03c1\n.\n(12)\n0\nKY (KY + \u03baI)\n\u03b2\nThe first eigenvalue of (12) gives the maximal value \u03c1max\nof \u03c1F in (9). \u03c1max\nis called the\nF\nF\ncanonical correlation coefficient, and the variables u = f (x) and v = g(y) transformed\nby f and g are called the canonical variates of the Kernel CCA.\n\u00a7 Recently, statistical consistency of the Kernel CCA, i.e., convergence of the estimators of f\nand g to the optimal ones is proved when f and g belong to a RKHS, under the condition that\n\u03ba/N \u223c N \u22121/3+\u03b4 (0 < \u03b4 < 1/3) with N \u2192 \u221e. Fukumizu K, Bach F R, and Gretton A 2005\nConsistency of kernel canonical correlation analysis, ISM Research Memorandum No.942\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n5\n\nN\nSo far, the averages of {f (xn )}N\nn=1 and {g(yn )}n=1 are set to zero. In fact, it is\nnot necessary to subtract the averages explicitly, because the subtraction of the means\nis equivalent to the replacement of the Gram matrices K with\n1\n1\n1\nK\u0303 = K \u2212 (j t j)K \u2212 K(j t j) + 2 (j t j)K(j t j),\n(13)\nN\nN\nN\nwhere j is a N -dimensional vector such that each component equals to the unity [15,\n16, 17].\nN\nIn the examples of this paper, the data {xn }N\nn=1 and {yn }n=1 are normalized\nwithin an unit interval [0, 1] before applying the Kernel CCA.\n\n3. Detecting Generalized Synchronization by Kernel CCA\nThe kernel methods such as the Kernel CCA have been mainly applied to problems\nof pattern recognition [17] and bioinformatics [27]. In this paper, we propose that the\nKernel CCA can also be a powerful tool for analyzing nonlinear dynamics.\nVoss et al. [26] proposed a method for analyzing dynamical system by the\nmaximization the expression (1). It is based on the Alternating Conditional\nExpectation (ACE) algorithm [25], where the transformations f and g in (1) are\nrestricted\nto a linear combination of univariate functions such as f (x1 , x2 , . . . , xp ) =\nP\n\u03a6\n(x\n)\nwhile the Kernel CCA allows any nonlinear function f (x1 , x2 , . . . , xp ) of p\ni\ni\n,\ni\nvariables in a RKHS. This difference makes the proposed method much more powerful\nthan the one based on ACE, especially in the cases where nonlinear dependence\nbetween variables x1 , x2 , . . . is essential. Unlike ACE, the Kernel CCA does not need\nany iterative procedure and it is enough to solve a generalized eigenvalue problem by\nstandard numerical algebra, only once for each set of data and parameters.\nIn this section, we study two unidirectionally coupled H\u00e9non maps [11] as an illustrative example and demonstrate the ability of the proposed approach.\n\n3.1. Quantitative Characterization of Generalized Synchronization\nTwo unidirectionally coupled H\u00e9non maps are described by the following difference\nequations:\n\u001a\nx1 (t + 1) = 1.4 \u2212 x1 (t)2 + 0.3x2 (t)\nX:\n(14)\nx2 (t + 1) = x1 (t),\n\u001a\ny1 (t + 1) = 1.4 \u2212 {\u03b3x1 (t)y1 (t) + (1 \u2212 \u03b3)y1 (t)2 } + 0.1y2 (t)\nY :\n(15)\ny2 (t + 1) = y1 (t),\nwhere x(t) = (x1 (t), x2 (t)) and y(t) = (y1 (t), y2 (t)) are state variables at time t, and\n\u03b3 denotes the coupling strength between two systems X and Y .\nFigures 1 (a) and (b) show the projections of the strange attractors of (14) and\n(15) with \u03b3 = 0.0 and 0.25 onto the (x1 , y1 ) plane, respectively. When the coupling\nstrength \u03b3 is large, a complicated driver-response relation with high nonlinearity is\nformed between two different chaotic dynamics. It can be identified in figure 1 (b)\nwith a visual inspection, but it is not easy to represent it by naive statistical tools\nsuch as correlation coefficients.\nWe apply the Kernel CCA to the cases shown in figures 1 (a) and (b). Here, we\nemploy a Gaussian kernel with \u03c3 = 0.1 and \u03ba is set to 0.3. We prepare an orbit with\nlength N = 2 \u00d7 103 as training data. As already remarked, each of variables x1 , x2 ,\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n6\n\nFigure 1. (a, b) Projections of strange attractors of the coupled H\u00e9non maps\nonto the (x1 , y1 ) plane with \u03b3 = 0.0 in (a) and \u03b3 = 0.25 in (b). For both of (a)\nand (b), an orbit with length 5 \u00d7 104 is used for plotting. (c, d) Scatter plots of\nthe canonical variates of the Kernel CCA with \u03b3 = 0.0 in (c) and \u03b3 = 0.25 in (d).\n\ny1 , and y2 is normalized within the unit interval [0, 1]. Figures 1 (c) and (d) illustrate\nresults of the Kernel CCA. Figure 1 (d) shows that GS is clearly identified as a cloud\nof points along the diagonal on the plane of the canonical variates u and v. On the\nother hand, when X and Y are independent, the correlation between the canonical\nvariates is very weak as shown in figure 1 (c). Figure 2 (a) shows the dependence\nof the canonical correlation coefficient \u03c1max\non the coupling strength \u03b3. The rapid\nF\nincrease of \u03c1max\nagainst\n\u03b3\nin\nan\ninterval\n0\n<\n\u03b3\n< 0.17 is indicated.\nF\nWe will show that the Kernel CCA can be used with time-delay embedding scheme\nfor time series. In time-delay embedding scheme, a pair of d-dimensional vectors\n(x1 (t), x1 (t \u2212 l), ..., x1 (t \u2212 (d \u2212 1)l) and (y1 (t), y1 (t \u2212 l), ..., y1 (t \u2212 (d \u2212 1)l), where l\ndenotes the delay time, is used as a sample of training data. Figure 2 (b) shows the\ngraph of \u03c1max\nvs. \u03b3 for two different values of the embedding dimension d. Shapes of\nF\nthe graphs shown in figure 2 (b) does not change significantly compared to those shown\nin figure 2 (a). This result indicates that the Kernel CCA works for data obtained by\nusing the time-delay embedding scheme.\n3.2. Comparison with A Conventional Method\nIn [9, 10], an identification of GS based on the occurrence of the complete\nsynchronization between the response system and its identical copy is proposed. For\nthe coupled H\u00e9non maps (14) and (15), we investigate the synchronization errors\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n7\n\nFigure 2. (a) The canonical correlation coefficient \u03c1max\nof the Kernel CCA as\nF\na function of the coupling strength \u03b3 for three different values of \u03c3 with \u03ba = 0.1\nvs. \u03b3\nand N = 2 \u00d7 103 . Inset An enlargement of (a). (b) The index \u03c1max\nF\nfor the embedding dimension d = 4 and d = 6 with \u03c3 = 1.0, \u03ba = 0.1, and\nN = 2 \u00d7 103 . The delay time l for embedding is set to 1. (c) The time average of\nthe synchronization error between the response system and its identical copy as\na function of \u03b3. (d) The maximal Lyapunov exponent \u03bbR of the response system\nas a function of \u03b3.\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n8\n\nhky \u2212 y copy k2 it between the system Y and its identical copy Y \u2032 with variables y copy =\n(y1copy , y2copy ). The result is shown in figure 2 (c). Here, the index hky \u2212 y copy k2 it\nbetween Y and Y \u2032 is measured by the average of 106 time steps and plotted as a\nfunction of \u03b3. The index hky \u2212 y copy k2 it decreases with increasing \u03b3 and becomes zero\nat \u03b3 \u223c 0.17. Our results shown in figures 2 (a) and (b) are consistent with this result.\nWe also investigate the maximal Lyapunov exponent \u03bbR of the state y(t) =\ny copy (t). The result is shown in figure 2 (d). The index \u03bbR is determined from\nthe first eigenvalue of the product of the Jacobian matrix of (15) with respect to the\nvariables y , and an orbit with length 106 is used for its numerical evaluation. There is\nan interval where \u03bbR changes nonmonotonically against \u03b3. Such nonmonotonic change\nis also observed in the graph of \u03c1max\nvs. \u03b3 as shown in the inset of figure 2 (a). These\nF\nresults tell us that \u03c1max\ndefined\nby\nthe\nKernel CCA can characterize subtle change as\nF\nwell as global tendency of GS.\n3.3. Influence of Noise and Sample Size\nWe consider how the performance of the Kernel CCA is influenced by the introduction\nof the observational noise and the change of the size of training data. First we consider\nthe influence of noise. In numerical simulation, for each variable of (14) and (15)\nnormalized within the interval [0, 1], Gaussian random numbers with the mean zero\nand the standard deviation g are added as the observational noise. Results are shown\nin figure 3. For a low noise level (g = 0.01), the graph of \u03c1max\nvs. \u03b3 is almost same\nF\nas that for the noise free case. For higher noise levels (g = 0.05), there is a moderate\ndecrease of \u03c1max\nin the whole interval of \u03b3, however, the global tendency of the graph\nF\nof \u03c1max\nvs.\n\u03b3\nis\nnot\nlost. The proposed approach is fairly robust against noise except\nF\nfor extremely high noise level (g = 0.3).\nSecond, we study the influence of the size of training data. Figure 4 (a) shows\nthe average of \u03c1max\nover 20 realizations as a function of \u03b3 for several different values\nF\nvs. \u03b3 does not depend\nof the size N . With the exception of \u03b3 = 0, the graph of \u03c1max\nF\nmuch on N . The result shows that the Kernel CCA works even with relatively small\nvs. N\nsize of training data. For the cases of \u03b3 = 0 and \u03b3 = 0.25, the graphs of \u03c1max\nF\nare shown in figure 4 (b). Here, the vertical bars denote the corresponding standard\nfor \u03b3 = 0 increases monotonically with decreasing N\ndeviation. The average of \u03c1max\nF\nwhereas the one for \u03b3 = 0.25 does not almost change against N . The result with \u03b3 = 0\nsuggests that a proper choice of the kernel parameter for a given data is important\nfor obtaining correct results. This issue is discussed in Section 6.\n3.4. Assessing Sensitivity of Kernel CCA to Nonlinear Structure: Surrogate Data\nAnalysis\nIn order to investigate the ability of the Kernel CCA to nonlinear dependence between\ntwo systems (14) and (15) , we use a method of surrogation[28]. Multivariate surrogate\ndata are generated as follows: first, the Fourier transform of the time series is\ncalculated for each of variables, then the common random numbers are added to\nthe phase variables, and finally the inverse Fourier transform is applied. The resulting\nmultivariate time series have the same power spectra and cross spectra as those of the\noriginal time series. By changing random numbers added to the phases, an arbitrary\nnumber of different time series which preserve the linear properties of the original is\nobtained. See papers [29, 30, 28] for technical details.\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n9\n\nas a function\nFigure 3. (a) Influence of the observational noise on the index \u03c1max\nF\nof \u03b3 with \u03c3 = 0.4, \u03ba = 0.1, and N = 103 . The average and the standard deviation\nof \u03c1max\nover 20 realizations are plotted as symbols and vertical bars, respectively.\nF\n\nIn numerical simulation, 19 realizations of the surrogate data for the time series\n{(x1 (t), y1 (t))} of (14) and (15) are prepared by using the TISEAN package[31, 28].\nWe take d = 4 and l = 1 for time-delay embedding.\nIn figure 5 (a), the index \u03c1max\ndefined by the Kernel CCA for the original data\nF\nand that for the surrogate data as functions of \u03b3 are shown. For the surrogate data,\nthe average over 19 realizations is plotted as a function of \u03b3, and the corresponding\nmaximal and minimal values are also shown as the both edges of vertical bars. For\nboth of the original and the surrogate data, the index \u03c1max\nincreases with increasing\nF\n\u03b3. Except for \u03b3 = 0 and \u03b3 \u223c 1, however, the value of \u03c1max\nfor the original data is\nF\nsignificantly higher than that for the surrogate data. For larger values of \u03b3, \u03c1max\nfor\nF\nthe surrogate data increases monotonically, and \u03c1max\n\u2192\n1\nas\n\u03b3\n\u2192\n1.\nThis\ncoincides\nF\nwith the fact that the attractor of the systems (14) and (15) is located around the\nplane x1 = y1 and x2 = y2 and the relation between two systems becomes almost\nlinear one. The results suggest that the Kernel CCA is sensitive to nonlinearity of the\ndependence between two systems.\nWe also investigate the performance of the linear CCA in the same way and results\nare shown in figure 5 (b). In this case, the difference between the maximal canonical\ncorrelation coefficients \u03c1max of the linear CCA for the original data and the one for\nthe surrogate data is not significant for any value of \u03b3. This indicates that the linear\nCCA can detect only the linear dependence between two systems.\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n10\n\nFigure 4. (a) Dependence of the index \u03c1max\non \u03b3 for three different values of\nF\nthe size N of training data with \u03c3 = 0.4, \u03ba = 0.1. (b) Dependence of the index\n\u03c1max\non N for \u03b3 = 0 and \u03b3 = 0.25 with \u03c3 = 0.4, \u03ba = 0.1. The average of \u03c1max\nF\nF\nover 20 realizations are plotted as symbols in (a), and in addition to the average,\nthe standard deviation is also plotted as vertical bars in (b).\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n11\n\nof the Kernel CCA (a) and\nFigure 5. The canonical correlation coefficients \u03c1max\nF\n\u03c1max of the linear CCA (b) as functions of \u03b3 for the original data and the surrogate\ndata. For the surrogate data, the average, and the maximal and minival values of\n\u03c1max\nover 19 realizations are plotted as symbols, and both edges of vertical bars,\nF\nrespectively. Parameters are d = 4, l = 1, \u03c3 = 1.0, \u03ba = 0.1, and N = 103 in (a)\nand d = 4, l = 1 and N = 103 in (b).\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n12\n\n3.5. The Regularization Parameter \u03ba\nAs mentioned in the preceding section, the regularization terms are required for\nnontrivial results. Figure 6 shows the dependence of \u03c1max\non the regularization\nF\nparameter \u03ba for three different values of \u03c3. Although \u03c1max\n\u2192 1 for too small \u03ba,\nF\nthe value of \u03c1max\ndecreases gradually and does not depend on the precise value of \u03ba.\nF\n\nFigure 6. The index \u03c1max\nas a function of the regularization parameter \u03ba for\nF\nthree different values of \u03c3. \u03b3 = 0.3 and N = 3 \u00d7 102 .\n\n4. Other Examples\nIn order to illustrate the capability of the Kernel CCA in more complicated situations,\nwe add the following three examples.\n4.1. Coupled R\u00f6ssler-Lorenz Systems\nFirst, we consider GS in a\n\uf8f1\n\uf8f2 x \u03071\nx \u03072\nX:\n\uf8f3\nx \u03073\n\uf8f1\n\uf8f2 y \u03071\ny \u03072\nY :\n\uf8f3\ny \u03073\n\nLorenz system driven by a R\u00f6ssler system[10]:\n= \u2212(x2 + x3 )\n= x1 + 0.2x2\n= 0.2 + x3 (x1 \u2212 5.7),\n\n(16)\n\n= 16(y2 \u2212 y1 ) \u2212 \u03b3(y1 \u2212 x1 )\n= \u2212y1 y3 + 45.92y1 \u2212 y2\n= y1 y2 \u2212 4y3 .\n\n(17)\n\nThe coupling term is introduced in the first equation of (17), and \u03b3 is its strength.\nWe confirm that there is a sharp transition of GS at \u03b3 \u223c 4.8 by investigating\nthe long time average of the synchronization error between the system (17) and its\nidentical copy driven by the common signal x1 (t) of the system (16). There coexist\ntwo attractors in the state space after the transition of GS and we choose one of them.\nFigures 7 (a) \u2013 (c) show the projections of the strange attractor of the system (16)\nand (17) with \u03b3 = 10 onto the planes of (x1 , y1 ), (x2 , y2 ), and (x3 , y3 ) respectively.\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n13\n\nFor each of pairs shown in figures 7 (a) \u2013 (c), the time series is embedded as points\nin a d-dimensional state space, and we apply the Kernel CCA. We set the embedding\ndimension d = 6 and the delay time l = 2.5. The size of training data is N = 103 .\nResults are shown in figure 8 (a). All indices \u03c1max\nshown in figure 8 (a) take large\nF\nvalues for \u03b3 & 4.8. The value \u03b3 \u223c 4.8 agrees with the transition point of GS. In figure 8\n(b), results of the linear CCA applied to the same data are also shown. The indices\n\u03c1max of the linear CCA for the cases of (x1 vs. y1 ) and (x2 vs. y2 ) take large values\nafter the GS transition as well as the indices \u03c1max\nobtained by the Kernel CCA. For\nF\nthe case of (x3 vs. y3 ), however, \u03c1max of the linear CCA is smaller than \u03c1max\nof the\nF\nKernel CCA. This result suggests that the Kernel CCA outperforms the linear CCA\nwhen the relation between two observed time series has high nonlinearity.\n\nFigure 7. Projections of the strange attractor of the coupled R\u00f6ssler and Lorenz\nsystems with \u03b3 = 10 onto the planes of (x1 , y1 ) in (a), (x2 , y2 ) in (b), and (x3 , y3 )\nin (c).\n\n4.2. Neural Spike Trains Modulated by Chaotic Inputs\nSecond, we analyze the following FitzHugh-Nagumo (FHN) neuron model modulated\nby chaotic dynamics of the R\u00f6ssler model:\n\uf8f1\n\uf8f2 x \u03071 = \u2212\u03c4 (x2 + x3 )\nx \u03072 = \u03c4 (x1 + 0.36x2 )\nX:\n(18)\n\uf8f3\nx \u03073 = \u03c4 (0.4 + x3 (x1 \u2212 4.5)),\n\u001a\ny \u03071 = {\u2212y1 (y1 \u2212 0.5)(y1 \u2212 1) \u2212 y2 + S(t)}/0.02\nY :\n(19)\ny \u03072 = y1 \u2212 y2 \u2212 0.15,\nwhere the term\nS(t) = 0.23 + 0.0075x1(t)\n\n(20)\n\ndefines a chaotic inputs to the neuron, and \u03c4 is a parameter that controls the dominant\ntime scale of the R\u00f6ssler dynamics. The system composed of (18) and (19) has been\ninvestigated from the viewpoint of the problem whether the information on the input\nsignal can be decoded from the output interspike intervals (ISIs) generated by a neuron\nor not[32, 33, 34]. Here, we focus on the relation between the input chaotic stimulus\nand the output ISIs from the viewpoint of GS between two oscillators with different\ndynamics.\nWe define the i-th ISI as si = ti \u2212 ti\u22121 where ti is onset time of the i-th spike\ndefined as the time when the variable y1 makes upward crossing over some fixed\nthreshold y\u03b8 . The value of y\u03b8 is set to 0.7 here. We also define the chaotic stimulus\nassociated with the i-th ISI as ri \u2261 x1 (ti ), which is the value of x1 in (18) at ti .\nBy using the delay embedding scheme, we transform the time series {ri } and {si }\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n14\n\nof the Kernel CCA\nFigure 8. (a) The canonical correlation coefficient \u03c1max\nF\nas a function of the coupling strength \u03b3 for different pairs of variables with\nN = 103 , d = 6, l = 2.5, \u03c3 = 1.5 and \u03ba = 0.1. (b) The canonical correlation\ncoefficient \u03c1max of the linear CCA as a function of the coupling strength \u03b3 for\ndifferent pairs of variables with N = 103 , d = 6, and l = 2.5. The results for\nthe case where the original state variables (x1 , x2 , x3 ) and (y1 , y2 , y3 ) are used as\ntraining data are also shown.\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n15\n\ninto the state points {(ri , ri\u22121 , ..., ri\u2212dX +1 )} and {(si , si\u22121 , ..., si\u2212dY +1 )} in dX and\ndY -dimensional state spaces, respectively. We set dX = dY = 3 here and apply the\nKernel CCA to these data sets.\nIn figures 9 (a1)\u2013(a3), significant nonlinear dependences between the input chaos\nand the output ISI are observed in scatter plots of (ri , si ). Figures 9 (b1)\u2013(b3) also\nshow scatter plots of the canonical variates of the Kernel CCA associated with figures 9\n(a1)\u2013(a3). It is easy to see that the correlation between canonical variates u and v\nshown in figures 9 (b1)\u2013(b3) correspond to the complexity of nonlinear dependence\nbetween ri and xi shown in figures 9 (a1)\u2013(a3).\nThe relation between ri and si changes according to the value of the control\nparameter \u03c4 . In figure 9 (c), the canonical correlation coefficient \u03c1max\nis plotted as a\nF\nfunction of \u03c4 , which visualizes the change of the input-output relation between two\nsystems of (18) and (19). The index \u03c1max\nchanges nonmonotonically with the increase\nF\nof \u03c4 , and there is a regime around \u03c4 \u223c 4 where the value of \u03c1max\nis large. In addition\nF\nto GS, chaotic phase synchronization (CPS) [35] occurs between two systems in this\nregime [34]. The increase of \u03c1max\nin this regime can be attributed to the occurrence\nF\nof CPS.\n4.3. Bidirectionally Coupled Systems\nThe notion of GS is not resricted to unidirectinally coupled systems. In [36, 37],\nthe occurrence of GS for bidirectionally coupled systems is also discussed. As an\nexample of GS in bidirectinally coupled systems, we consider the following coupled\nLorenz-R\u00f6ssler systems [36]:\n\uf8f1\n\uf8f2 x \u03071 = 10(x2 \u2212 x1 ) + \u03b3(y1 \u2212 x1 )\nx \u03072 = 35x1 \u2212 x2 \u2212 x1 x3\nX:\n(21)\n\uf8f3\nx \u03073 = \u2212(8/3)x3 + x1 x2 ,\n\uf8f1\n\uf8f2 y \u03071 = 5.5y2 \u2212 y3 + \u03b3(x1 \u2212 y1 )\ny \u03072 = 5.5y1 + 0.165y2\nY :\n(22)\n\uf8f3\ny \u03073 = 0.2 + y3 (y1 \u2212 10).\n\nA mutual interaction between a Lorenz system (21) and a R\u00f6ssler system (22) is\nintroduced as diffusion terms in the first equations of both (21) and (22), and \u03b3 is its\nstrength. In [36], Zheng et al. try to define GS in bidirectionally coupled systems by\nconsidering identical copies X \u2032 and Y \u2032 of the systems X and Y . Using the approach\nin [36], two transitions of GS are found in the systems (21) and (22). At \u03b3 \u223c 1.2,\nthe R\u00f6ssler system Y is entrained by the Lorenz system X in the sense that orbits of\nthe systems Y and Y \u2032 completely coincide with each other by receiving the common\nsignal of the system X. With the further increase of \u03b3, the system X is also entrained\nby the system Y at \u03b3 \u223c 12.3 which means that the complete synchronization between\nX and X \u2032 also occurs.\nWe apply the Kernel CCA to the systems (21) and (22) and results are shown in\nfigures 10 and 11. Figure 10 (a1), (b1), and (c1) show the projections of attractors\nof the systems (21) and (22) with \u03b3 = 0.4, 4.0, and 13.0 onto the (x1 , y1 ) planes,\nrespectively. Figures 10 (a2), (b2) and (c2) also show the corresponding results of the\nKernel CCA. Here, we use a Gaussian kernel with \u03c3 = 1.0. The state variables\n{(x1 (ti ), x2 (ti ), x3 (ti )), (y1 (ti ), y2 (ti ), y3 (ti ))} where ti = i\u2206t, i = 1, ..., N, \u2206t =\n5.0, N = 2 \u00d7 103 are used as the training data set. It is observed that the state\nof GS is clearly identified as the high linear correlation between canonical variates\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n16\n\nFigure 9. (a1 \u2013 a3) Scatter plots of ri and si of (18) and (19) with \u03c4 = 2.7 in\n(a1), \u03c4 = 4.0 in (a2), and \u03c4 = 7.5 in (a3). (b1 \u2013 b3) Scatter plots of canonical\nvariates u and v of the Kernel CCA with \u03c4 = 2.7 in (b1), \u03c4 = 4.0 in (b2), and\n\u03c4 = 7.5 in (b3). \u03c3 = 0.5, \u03ba = 0.1, and N = 2 \u00d7 103 . (c) The canonical correlation\ncoefficient \u03c1max\nof the Kernel CCA as a function of \u03c4 with \u03c3 = 0.5, \u03ba = 0.1, and\nF\nN = 2 \u00d7 103 .\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n17\n\nFigure 10. (a1, b1, c1) Projections of attractors of the bidirectionally coupled\nLorenz and R\u00f6ssler systems onto the plane of (x1 , y1 ) with \u03b3 = 0.4 in (a1), \u03b3 = 4.0\nin (b1) \u03b3 = 13.0 in (c1). (a2, b2, c2) Scatter plots of the canonical covariates of\nthe Kernel CCA with \u03b3 = 0.4 in (a1), \u03b3 = 4.0 in (b1) \u03b3 = 13.0 in (c1). Parameters\nare \u03c3 = 1.0, \u03ba = 0.1, and N = 2 \u00d7 103 .\n\nu and v of the Kernel CCA. Application of the Kernel CCA to the bidirectionally\ncoupled systems is straightforward while the approach of [36] requires rather subtle\nprocedures. Figure 11 shows the index \u03c1max\nas a function of the coupling strength \u03b3.\nF\nThere is a rapid increase of \u03c1max\nagainst\n\u03b3\nin an interval 0 < \u03b3 < 1.2. This result\nF\nis consistent with the first transition of GS defined in [36]. The second transntion of\nGS at \u03b3 \u223c 12.3 defined in [36] is not seen in the graph of \u03c1max\nvs. \u03b3. A reason is\nF\nthat the value of \u03c1max\nalready\nbecomes\nnearly\none\nat\n\u03b3\n\u223c\n5.\nAnother\nreason is that\nF\nby definition, the proposed approach based on the Kernel CCA is insensitive to the\ndirectionality of synchronization. It will be interesting to study modifications of the\napproach which can deal with the directionality of synchronization.\n5. Nonstationary Change of Coupling Strength\nSo far, we have focused on the dependence of the first eigenvalue \u03c1max\non the coupling\nF\nstrength \u03b3. We turn our attention to the eigenvector t (\u03b1, \u03b2) in (12) and investigate\nchanges of the structure of the dynamical system with the Kernel CCA.\nAs an illustration, let us consider the problem of extracting nonstationary changes\nof the coupling strength \u03b3 from time series data generated by the coupled H\u00e9non maps.\nAn example of such changes is shown in figure 12 (b). When the value of \u03b3 varies\nfrom \u03b30 , an orbit leaves from the synchronization manifold M with \u03b30 , and is attracted\nagain to it when the value of \u03b3 is restored to \u03b30 . As shown in figure 12 (a), the time\nseries of the original variables (x1 , y1 ) does not tell us whether the orbit is lying on\nM or not at a given time t. By using the Kernel CCA, a deviation of the orbit from\nM will be detected as a large value of |f (x) \u2212 g(y)|, where f (*) and g(*) are nonlinear\ntransformations determined by the first eigenvector t (\u03b1, \u03b2).\nNumerical experiments are performed with \u03b30 = 0.6 in two different conditions,\nand results are shown in figures 12 (c) and (d), respectively. Figure 12 (c) shows the\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n18\n\nFigure 11. The index \u03c1max\nof the Kernel CCA as a function of the coupling\nF\nstrength \u03b3 with \u03c3 = 1.0, \u03ba = 0.1, and N = 2 \u00d7 103 .\n\ncase where f (*) and g(*) are estimated from an orbit with \u03b3 = \u03b30 , which is prepared\nseparately from the orbit to be analyzed. In figure 12 (c), time intervals where the\nvalues of \u03b3 are different from \u03b30 is clearly detected as successive bursts in the time\nseries of |f (x) \u2212 g(y)|.\nIn figure 12 (d), we show the case where the orbit to be analyzed is also\nused for estimating f (*) and g(*). We see that even when estimation of nonlinear\ntransformations is affected by \"noise\" from the points not lying on M, successive\nbursts are still observed in the time series of |f (x) \u2212 g(y)| except for the one in a time\ninterval 1600 < t < 1800.\n6. Choice of Kernel Parameters\nIn the preceding section, we set the value of the kernel parameter such as the width \u03c3 of\na Gaussian kernel in an ad-hoc manner. If \u03c3 is too small, the nonlinear transformations\nf (*) and g(*) in (2) cannot interpolate between data points of the training sample.\nContrary, if \u03c3 is too large, (2) cannot represent a highly nonlinear structure such as\nthe synchronization manifold M of GS. Thus a proper choice of the kernel parameter\nis crucial to obtain the good performance of the method. In this section, we discuss\nhow the kernel parameter can be suitably chosen from a given data set.\nA naive way of choosing \u03c3 is to find the value of \u03c3 that maximizes \u03c1max\nF . The\ndotted line with open circles in figure 13 shows the graph of an index \u03c1max\nas\na\nfunction\nF\nof \u03c3 when two H\u00e9non maps (14) and (15) are uncoupled (\u03b3 = 0). Here, an orbit of\n(14) and (15) with length N = 103 is used as a set of training data, and the average\nand the standard deviation over 20 realizations are plotted as symbols and vertical\n\n\f19\n\nDetecting Generalized Synchronization by A Kernel-based Approach\n\n0.5\n\n0\n\n500\n\n1000\n\n1500\n\n2000\n\n0\n\n500\n\n1000\n\n1500\n\n2000\n\n0\n\n500\n\n1000\n\n1500\n\n2000\n\n0\n\n500\n\n1000\n\n1500\n\n2000\n\n1000\n\n1500\n\n2000\n\n0.5\n0.0\n\ny1\n\n1.0\n\n1.5\n\n2.0\n\nx1\n\n1.0\n\n1.5\n\n(a)\n\n0.6\n0.4\n0.04\n0.00\n0.04\n\n(d)\nPSfrag replacements\n\nu\u2212v\n\n(c)\n\nu\u2212v\n\n0.2\n\n\u03b3(t)\n\n0.8\n\n(b)\n\n0\n\n0\n\n500\n\ntime\nFigure 12. (a) Time series of the variables x1 and y1 of the coupled H\u00e9non maps\nwhen the value of \u03b3 changes temporally as shown in (b). (c, d) Time series of the\ndifference of the canonical variates of the Kernel CCA with \u03c3 = 0.1 and \u03ba = 0.1.\n\nbars, respectively. The index \u03c1max\nincreases monotonically with the decrease of \u03c3, and\nF\n\u03c1max\n\u223c\n1\nis\nattained\nin\nthe\nlimit\nof\n\u03c3 \u2192 0, while there is no interaction between two\nF\nsystems X and Y . This monotonic tendency of \u03c1max\ndoes not determine an optimal\nF\nvalue of the kernel parameter \u03c3.\nAs a way to overcome this difficulty, the following procedure is proposed. First,\nwe set aside the data {(x\u0303n , \u1ef9n )}\u00d1\nn=1 for assessing the performance of the Kernel CCA\n(we call this \"test\" data) separately from the data used for training the Kernel CCA.\nThen, we estimate the nonlinear transformations f (*) and g(*) from the training data,\nand calculate the correlation coefficient \u03c1CV\nbetween the variables \u0169n = f (x\u0303n ) and\nF\n\u1e7dn = g(\u1ef9n ), n = 1, 2, ..., \u00d1 defined as\nh(\u0169n \u2212 h\u0169n i) * (\u1e7dn \u2212 h\u1e7dn i)i\np\n,\n\u03c1CV\nF = p\nh(\u0169n \u2212 h\u0169n i)2 * h(\u1e7dn \u2212 h\u1e7dn i)2\n\n(23)\n\nwhere h***i is the empirical average over \u00d1 samples. This strategy for assessing the\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n20\n\nperformance of the estimated model with new data is regarded as a version of crossvalidation (CV) [38, 39, 40].\nFirst we check that spurious detection of synchronization can be avoided by the\nprocedure based on CV. The solid line with filled squares in figure 13 shows the\ndependence of an index \u03c1CV\nF on \u03c3 with \u03b3 = 0. When there is no interaction between\ntwo systems, the value of \u03c1CV\nF is nearly equal to zero for any \u03c3. Corresponding results\nusing time-delay embedding are shown in figure 14. In figure 14, the dependencies of\n\u03c1max\nand \u03c1CV\nF\nF on \u03c3 with \u03b3 = 0 are plotted for several different values of the embedding\ndimension d. Again, the value of \u03c1CV\nF is almost equal to zero for any \u03c3 and d, whereas\nthe value of \u03c1max\nas\na\nfunction\nof\n\u03c3\nincreases monotonically with the increase of d. This\nF\nresult suggests that the procedure based on CV effectively erases spurious detection\neven when data is embedded in a high-dimensional state space.\n\nFigure 13. Result of cross-validation for two uncoupled H\u00e9non maps (\u03b3 = 0.0).\nvs. \u03c3, and the solid line with filled\nThe dotted line with open circles shows \u03c1max\nF\n3\nsquares shows \u03c1CV\nF vs \u03c3. We prepare 20 data sets with size N = 10 for training\nthe Kernel CCA, and a test data with size \u00d1 = 2 \u00d7 103 for cross-validation. The\naverage over 20 realizations are plotted as symbols. The standard deviation is\nalso plotted as vertical bars, but the ones with small values of errors are hidden\nby symbols. \u03ba is set to 0.01.\n\nNext we show that the cross validation procedure is useful for choosing optimal\nvalues of \u03c3. Figures 15 shows the values of \u03c1max\nand \u03c1CV\nF\nF as functions of \u03c3 for the\ncoupled H\u00e9non maps (14) and (15) with \u03b3 = 0.25. The condition for the numerical\nexperiment is the same as \u03b3 = 0. For all of graphs, the value of \u03c1CV\nF with the dotted\nline takes its maximum at a nonzero value of \u03c3, whereas \u03c1max\nincreases\nmonotonically\nF\nwith the decrease of \u03c3. This result indicates that we can choose this value as an\noptimal width of a Gaussian kernel.\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n21\n\nFigure 14. Results of cross-validation with \u03b3 = 0 for four different values of\nthe embedding dimension d. We take the delay time l = 1. The condition for\nnumerical experiments is the same as figure 13.\n\nFigure 15. Results of cross-validation for two coupled H\u00e9non maps with \u03b3 = 0.25.\nThe embedding dimension d = 2 in (a), d = 4 in (b), d = 6 in (c), and d = 8\nin (d), and the delay time l = 1. The condition for numerical experiments is the\nsame as figure 13.\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n22\n\n7. Conclusion\nIn conclusion, we have proposed a new approach for analyzing GS in a unified\nframework of a kernel method. We have tested the proposed approach by applying it\nto several examples exhibiting GS, and demonstrated that the canonical correlation\ncoefficient of the Kernel CCA is a suitable index for the characterization of GS. In\naddition, it has been shown that nonstationary changes of the coupling are detected\nfrom the time series by the difference between canonical variates of the Kernel CCA.\nIt has been also discussed how the parameter of the kernel function can be suitably\nchosen from data by the procedure of cross-validation. Our experiments show that\na method based on CV gives promising results in optimizing the parameter \u03c3. The\ncross-validation procedure is also useful to circumvent spurious detection of GS by\noverfitting.\nThe approach based on the Kernel CCA provides not only an index for measuring\nnonlinear interdependence. It also provides global nonlinear coordinates, and these\ncoordinates allow a representation of the interaction between the dynamical systems\nunder investigation. Note that the linear CCA also provides global coordinates, but\nit cannot discriminate between linear and nonlinear relation. In this respect, it goes\nbeyond conventional methods of analyzing GS. Our attempts open a new possibility\nof the kernel methods for analyzing complex dynamics observed in nonlinear systems.\nAcknowledgments\nWe thank S. Akaho for stimulating discussions on the kernel methods, and\nK. Fukumizu for useful comments and informing us his results prior to publication.\nWe also thank Y. Hirata for useful suggestions on surrogate data analysis.\nReferences\n[1] Pikovsky A, Rosenblum M and Kurths J 2002 Synchronization, A Universal Concept in\nNonlinear Sciences (Cambridge: Cambridge University Press)\n[2] Fujisaka H and Yamada T 1983 Stability theory of synchronized motion in coupled-oscillator\nsystem Prog. Theor. Phys. 69 32\u201347\n[3] Pikovsky A S 1984 On the interaction of strange attractors Z. Phys. B 55 149\u2013154\n[4] Pecora L M and Carroll T L 1990 Synchronization in chaotic systems Phys. Rev. Lett. 64 821\u2013824\n[5] Rulkov N F, Sushchik M M, Tsimring L S and Abarbanel H D I 1995 Generalized synchronization\nof chaos in directionally coupled chaotic systems Phys. Rev. E 51 980 \u2013 994\n[6] Farmer S F 1998 Rhythmicity, synchronization and binding in human and primate motor systems\nJ. Physiology 509 3 \u2013 14\n[7] Le Van Quyen M, Martinerie J, Adam C and Varela F J 1999 Nonlinear analyses of interictal\nEEG map the brain interdependences in human focal epilepsy Physica D 127 250 \u2013266\n[8] Arnhold J, Grassberger P, Lehnertz K, and Elger C E 1999 A robust method for detecting\ninterdependences: application to intracranially recorded EEG Physica D 134 419 \u2013 430\n[9] Kocarev L and Parlitz U 1996 Generalized synchronization, predictability, and equivalence of\nunidirectionally coupled dynamical systems Phys. Rev. Lett. 76 1816\u20131819\n[10] Abarbanel H D I, Rulkov N F and Sushchik M M 1996 Generalized synchronization of chaos:\nthe auxiliary system approach Phys. Rev. E 53 4528\u20134535\n[11] Schiff S J, So P, Chang T, Burke R E and Sauer T 1996 Detecting dynamical interdependence\nand generalized synchrony through mutual prediction in a neural ensemble Phys. Rev. E 54\n6708\u20136724\n[12] Quian Quiroga R, Arnhold J and Grassberger P 2000 Learning driver-response relationships\nfrom synchronization patterns Phys. Rev. E 61 5142\u20135148\n[13] Stam C J and Van Dijk B W 2002 Synchronization likelihood: an unbiased measure of generalized\nsynchronization in multivariate data sets Physica D 163 236 \u2013 251\n\n\fDetecting Generalized Synchronization by A Kernel-based Approach\n\n23\n\n[14] Sch\u00f6lkopf B, Smola A J and M\u00fcller K-R 1998 Nonlinear component analysis as a kernel\neigenvalue problem Neural Comput. 10 1299\u20131319\n[15] M\u00fcller K-R, Mika S, R\u00e4tsch G, Tsuda K and Sch\u00f6lkopf B 2001 An introduction to kernel-based\nlearning algorithms IEEE Trans. on Neural Networks 12 181\u2013201\n[16] Sch\u00f6lkopf B and Smola A J 2002 Learning with Kernels, Support Vector Machines,\nRegularization, Optimization, and Beyond (Cambridge: The MIT Press)\n[17] Shawe-Taylor J and Cristianini N 2004 Kernel Methods for Pattern Recognition (Cambridge:\nCambridge University Press)\n[18] Lai P L and Fyfe C 2000 Kernel and nonlinear canonical correlation analysis Int. J. of Neural\nSys. 10 365\u2013377\n[19] Akaho S 2001 A kernel method for canonical correlation analysis In Proceedings of the\nInternational Meeting of the Psychometric Society (IMPS2001) 123-128\n[20] Melzer T, Reiter M, and Bischof H 2001 Nonlinear feature extraction using generalized canonical\ncorrelation analysis In Proceedings of the International Conference on Artficial Neural\nNetworks (ICANN) 353\u2013360 (London: Springer-Verlag)\n[21] Bach F R and Jordan M I 2002 Kernel independent component analysis J. of Machine Learning\nRes. 3 1\u201348\n[22] Suetani H, Iba Y and Aihara K 2006 Prog. Theor. Phys. Suppl. No.161 340\u2013343\n[23] Hotelling H 1936 Relation between two sets of variates Biometrika 28 321\u2013377\n[24] Buja A 1990 Remarks on functional canonical variates, alternating least squares methods and\nACE Ann. Statist. 18 1032 \u2013 1069\n[25] Breiman L and Friedman J H 1985 Estimating optimal transformations for multiple regression\nand correlation J. Amer. Statist. Assoc. 80 580-598\n[26] Voss H and Kurths J 1997 Reconstruction of non-linear time delay models from data by the use\nof optimal transformations Phys. Lett. A 234 336 \u2013 344\n[27] Sch\u00f6lkopf B, Tsuda K and Vert J-P (Eds.) 2004 Kernel Methods in Computational Biology\n(Cambridge: The MIT Press)\n[28] Schreiber T and Schmitz A 2000 Surrogate time series Physica D 142 346 \u2013 382\n[29] Prichard D and Theiler J 1994 Generating surrogate data for time series with several\nsimultaneously measured variables Phys. Rev. Lett. 73 951 \u2013 954\n[30] Schreiber T and Schmitz A 1996 Improved surrogate data for nonlinearity tests Phys. Rev. Lett.\n77 635 \u2013 638\n[31] Hegger R, Kantz H and Schreiber T 1999 Practical implementation of nonlinear time series\nmethods: the TISEAN package Chaos 9 413 \u2013 435\n[32] Sauer T 1994 Reconstruction of dynamical systems from interspike intervals Phys. Rev. Lett. 72\n3811\u20133814\n[33] Racicot D M and Longtin A 1997 Interspike interval attractors from chaotically driven neuron\nmodels Physica D 104 184-204\n[34] Han S K, Kim W S and Kook H 2002 Synchronization and decoding interspike intervals Int. J.\nBifur. and Chaos 12 983\u2013999\n[35] Rosenblum M G, Pikovsky A S, Kurths J 1996 Phase synchronization of chaotic oscillators Phys.\nRev. Lett. 76 1804\u20131807\n[36] Zheng Z, Wang X, and Cross M C 2002 Transitions from partial to complete generalized\nsynchronizations in bidirectionally coupled chaotic oscillators Phys. Rev. E 65 056211\n[37] Osipov G V, Hu B, Zhou C, Ivanchenko M V, and Kurths J 2003 Three types of transitions to\nphase synchronization in coupled chaotic oscillators Phys. Rev. Lett. 91 024101\n[38] Stone M 1974 Cross-validatory choice and assessment of statistical prediction J. R. Statist. Soc.\nB 36 111\u2013147\n[39] Silverman B W 1985 Some aspects of the spline smoothing approach to non-parametric regression\ncurve fitting J. R. Statist. Soc. B 47 1\u201352\n[40] Wahba G 1990 Spline Models for Observational Data (Philadelphia: SIAM)\n\n\f"}