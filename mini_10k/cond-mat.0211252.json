{"id": "http://arxiv.org/abs/cond-mat/0211252v2", "guidislink": true, "updated": "2003-04-08T08:40:34Z", "updated_parsed": [2003, 4, 8, 8, 40, 34, 1, 98, 0], "published": "2002-11-13T09:51:42Z", "published_parsed": [2002, 11, 13, 9, 51, 42, 2, 317, 0], "title": "Quantum entropy production as a measure of irreversibility", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0211405%2Ccond-mat%2F0211607%2Ccond-mat%2F0211560%2Ccond-mat%2F0211310%2Ccond-mat%2F0211101%2Ccond-mat%2F0211464%2Ccond-mat%2F0211106%2Ccond-mat%2F0211610%2Ccond-mat%2F0211120%2Ccond-mat%2F0211069%2Ccond-mat%2F0211114%2Ccond-mat%2F0211276%2Ccond-mat%2F0211545%2Ccond-mat%2F0211581%2Ccond-mat%2F0211695%2Ccond-mat%2F0211524%2Ccond-mat%2F0211049%2Ccond-mat%2F0211112%2Ccond-mat%2F0211087%2Ccond-mat%2F0211367%2Ccond-mat%2F0211206%2Ccond-mat%2F0211149%2Ccond-mat%2F0211555%2Ccond-mat%2F0211671%2Ccond-mat%2F0211577%2Ccond-mat%2F0211385%2Ccond-mat%2F0211252%2Ccond-mat%2F0211196%2Ccond-mat%2F0211571%2Ccond-mat%2F0211229%2Ccond-mat%2F0211496%2Ccond-mat%2F0211539%2Ccond-mat%2F0211244%2Ccond-mat%2F0211614%2Ccond-mat%2F0211394%2Ccond-mat%2F0211415%2Ccond-mat%2F0211591%2Ccond-mat%2F0211599%2Ccond-mat%2F0211510%2Ccond-mat%2F0211224%2Ccond-mat%2F0211513%2Ccond-mat%2F0211140%2Ccond-mat%2F0211659%2Ccond-mat%2F0211445%2Ccond-mat%2F0211099%2Ccond-mat%2F0211153%2Ccond-mat%2F0211042%2Ccond-mat%2F0211637%2Ccond-mat%2F0211347%2Ccond-mat%2F0211015%2Ccond-mat%2F0211250%2Ccond-mat%2F0211143%2Ccond-mat%2F0211395%2Ccond-mat%2F0211598%2Ccond-mat%2F0211601%2Ccond-mat%2F0211490%2Ccond-mat%2F0211013%2Ccond-mat%2F0211115%2Ccond-mat%2F0211414%2Ccond-mat%2F0211195%2Ccond-mat%2F0211246%2Ccond-mat%2F0211130%2Ccond-mat%2F0211081%2Ccond-mat%2F0211459%2Ccond-mat%2F0211648%2Ccond-mat%2F0211518%2Ccond-mat%2F0211611%2Ccond-mat%2F0211585%2Ccond-mat%2F0211262%2Ccond-mat%2F0203276%2Ccond-mat%2F0203040%2Ccond-mat%2F0203412%2Ccond-mat%2F0203254%2Ccond-mat%2F0203541%2Ccond-mat%2F0203165%2Ccond-mat%2F0203311%2Ccond-mat%2F0203126%2Ccond-mat%2F0203043%2Ccond-mat%2F0203249%2Ccond-mat%2F0203561%2Ccond-mat%2F0203038%2Ccond-mat%2F0203182%2Ccond-mat%2F0203397%2Ccond-mat%2F0203148%2Ccond-mat%2F0203088%2Ccond-mat%2F0203309%2Ccond-mat%2F0203430%2Ccond-mat%2F0203159%2Ccond-mat%2F0203373%2Ccond-mat%2F0203289%2Ccond-mat%2F0203533%2Ccond-mat%2F0203353%2Ccond-mat%2F0203282%2Ccond-mat%2F0203217%2Ccond-mat%2F0203582%2Ccond-mat%2F0203084%2Ccond-mat%2F0203330%2Ccond-mat%2F0203306%2Ccond-mat%2F0203270%2Ccond-mat%2F0203170%2Ccond-mat%2F0203613&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Quantum entropy production as a measure of irreversibility"}, "summary": "We consider conservative quantum evolutions possibly interrupted by\nmacroscopic measurements. When started in a nonequilibrium state, the resulting\npath-space measure is not time-reversal invariant and the weight of\ntime-reversal breaking equals the exponential of the entropy production. The\nmean entropy production can then be expressed via a relative entropy on the\nlevel of histories. This gives a partial extension of the result for classical\nsystems, that the entropy production is given by the source term of\ntime-reversal breaking in the path-space measure.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=cond-mat%2F0211405%2Ccond-mat%2F0211607%2Ccond-mat%2F0211560%2Ccond-mat%2F0211310%2Ccond-mat%2F0211101%2Ccond-mat%2F0211464%2Ccond-mat%2F0211106%2Ccond-mat%2F0211610%2Ccond-mat%2F0211120%2Ccond-mat%2F0211069%2Ccond-mat%2F0211114%2Ccond-mat%2F0211276%2Ccond-mat%2F0211545%2Ccond-mat%2F0211581%2Ccond-mat%2F0211695%2Ccond-mat%2F0211524%2Ccond-mat%2F0211049%2Ccond-mat%2F0211112%2Ccond-mat%2F0211087%2Ccond-mat%2F0211367%2Ccond-mat%2F0211206%2Ccond-mat%2F0211149%2Ccond-mat%2F0211555%2Ccond-mat%2F0211671%2Ccond-mat%2F0211577%2Ccond-mat%2F0211385%2Ccond-mat%2F0211252%2Ccond-mat%2F0211196%2Ccond-mat%2F0211571%2Ccond-mat%2F0211229%2Ccond-mat%2F0211496%2Ccond-mat%2F0211539%2Ccond-mat%2F0211244%2Ccond-mat%2F0211614%2Ccond-mat%2F0211394%2Ccond-mat%2F0211415%2Ccond-mat%2F0211591%2Ccond-mat%2F0211599%2Ccond-mat%2F0211510%2Ccond-mat%2F0211224%2Ccond-mat%2F0211513%2Ccond-mat%2F0211140%2Ccond-mat%2F0211659%2Ccond-mat%2F0211445%2Ccond-mat%2F0211099%2Ccond-mat%2F0211153%2Ccond-mat%2F0211042%2Ccond-mat%2F0211637%2Ccond-mat%2F0211347%2Ccond-mat%2F0211015%2Ccond-mat%2F0211250%2Ccond-mat%2F0211143%2Ccond-mat%2F0211395%2Ccond-mat%2F0211598%2Ccond-mat%2F0211601%2Ccond-mat%2F0211490%2Ccond-mat%2F0211013%2Ccond-mat%2F0211115%2Ccond-mat%2F0211414%2Ccond-mat%2F0211195%2Ccond-mat%2F0211246%2Ccond-mat%2F0211130%2Ccond-mat%2F0211081%2Ccond-mat%2F0211459%2Ccond-mat%2F0211648%2Ccond-mat%2F0211518%2Ccond-mat%2F0211611%2Ccond-mat%2F0211585%2Ccond-mat%2F0211262%2Ccond-mat%2F0203276%2Ccond-mat%2F0203040%2Ccond-mat%2F0203412%2Ccond-mat%2F0203254%2Ccond-mat%2F0203541%2Ccond-mat%2F0203165%2Ccond-mat%2F0203311%2Ccond-mat%2F0203126%2Ccond-mat%2F0203043%2Ccond-mat%2F0203249%2Ccond-mat%2F0203561%2Ccond-mat%2F0203038%2Ccond-mat%2F0203182%2Ccond-mat%2F0203397%2Ccond-mat%2F0203148%2Ccond-mat%2F0203088%2Ccond-mat%2F0203309%2Ccond-mat%2F0203430%2Ccond-mat%2F0203159%2Ccond-mat%2F0203373%2Ccond-mat%2F0203289%2Ccond-mat%2F0203533%2Ccond-mat%2F0203353%2Ccond-mat%2F0203282%2Ccond-mat%2F0203217%2Ccond-mat%2F0203582%2Ccond-mat%2F0203084%2Ccond-mat%2F0203330%2Ccond-mat%2F0203306%2Ccond-mat%2F0203270%2Ccond-mat%2F0203170%2Ccond-mat%2F0203613&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We consider conservative quantum evolutions possibly interrupted by\nmacroscopic measurements. When started in a nonequilibrium state, the resulting\npath-space measure is not time-reversal invariant and the weight of\ntime-reversal breaking equals the exponential of the entropy production. The\nmean entropy production can then be expressed via a relative entropy on the\nlevel of histories. This gives a partial extension of the result for classical\nsystems, that the entropy production is given by the source term of\ntime-reversal breaking in the path-space measure."}, "authors": ["I. Callens", "W. De Roeck", "T. Jacobs", "C. Maes", "K. Netocny"], "author_detail": {"name": "K. Netocny"}, "author": "K. Netocny", "arxiv_comment": "11 pages", "links": [{"href": "http://arxiv.org/abs/cond-mat/0211252v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/cond-mat/0211252v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cond-mat.stat-mech", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/cond-mat/0211252v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/cond-mat/0211252v2", "journal_reference": null, "doi": null, "fulltext": "arXiv:cond-mat/0211252v2 [cond-mat.stat-mech] 8 Apr 2003\n\nQuantum entropy production as a measure of\nirreversibility\nI. Callens, W. De Roeck 1, T. Jacobs, C. Maes \u2217, K. Neto\u010dn\u00fd\nInstituut voor Theoretische Fysica\nK.U.Leuven, Belgium.\n\nAbstract\nWe consider conservative quantum evolutions possibly interrupted by macroscopic\nmeasurements. When started in a nonequilibrium state, the resulting path-space\nmeasure is not time-reversal invariant and the weight of time-reversal breaking\nequals the exponential of the entropy production. The mean entropy production\ncan then be expressed via a relative entropy on the level of histories. This gives a\npartial extension of the result for classical systems, that the entropy production is\ngiven by the source term of time-reversal breaking in the path-space measure.\nKey words: quantum systems, entropy production, time-reversal\nPACS: 05.30.Ch, 05.70.Ln\n\n1\n\nQuantum entropy\n\nIn bridging the gap between classical mechanics and thermal phenomena, the\nfounding fathers of statistical mechanics realized that a statistical characterization of macrostates in terms of microstates is essential for understanding the\ntypical time evolution of thermodynamic systems. But statistical reasoning requires proper counting, starting from a set of a priori equivalent microstates.\nThat is different in quantum statistics from what is done in classical statistics.\nNevertheless the same concepts can be put in place. In this paper, we show\nfor the quantum case what has been proven useful in the classical case: that\nentropy production measures the breaking of time-reversal invariance. More\nexactly, we show that the logarithmic ratio of the probability of a trajectory\nand its time-reversal coincides with the physical entropy production.\n\u2217 Christian.Maes@fys.kuleuven.ac.be\n1 Aspirant FWO, U.Antwerpen\n\nPreprint submitted to Elsevier Science\n\n17 November 2018\n\n\fWe continue with an introduction about entropy, both classical and quantum,\nto specify what we mean by entropy production. The main message is contained in Sections 2 and 3 where the relation between entropy production and\ntime-reversal is demonstrated. Section 2 deals with a unitary evolution (one\ninitial preparation and one final measurement) and can be considered as a special case of Section 3 where the unitary evolution is further interrupted with\nmeasurements of the macrostate. The paper is based on elementary mathematical manipulations and the emphasis is on the conceptual framework.\n\n1.1 Classical set-up\n\nSuppose a classical closed and isolated system of N particles. A complete description consists in specifying its microstate, that is a point x in its phase\nspace, x = (q1 , . . . , qN , p1 , . . . , pN ) of positions and momenta. The dynamics is Hamiltonian and energy is conserved. Each microstate x determines a\nmacrostate M(x) corresponding to a much coarser division of phase space. To\nbe specific, we consider the surface \u0393 of constant energy and we suppose that\nthe macrostates induce a finite partition \u0393\u0302 of \u0393. The different macroscopic\nvalues thus specify a (finite) number of regions in phase space. We emphasize\nthat this reduced description is in terms of macroscopic variables (in contrast\nwith the partitions as used e.g in constructions of dynamical entropies), such\nas position or velocity profiles and we denote by |M| the corresponding phase\nspace volume.\nThe Boltzmann entropy (also called Boltzmann-Planck-Einstein or microcanonical or configurational entropy) is, up to multiplicative and additive\nconstants, defined by\nSB (x) \u2261 log |M(x)|\n\n(1.1)\n\nWhen the microstate belongs to the region of phase space of unconstrained\nequilibrium, then, at least in the thermodynamic limit, SB (x) equals the thermodynamic entropy defined operationally by Clausius. But also out of equilibrium, say when a constraint is lifted and the system is free to evolve, the\nBoltzmann entropy remains relevant as it will typically increase towards equilibrium. It gives in fact the microscopic foundation of the second law of thermodynamics.\nThere is another entropy that generalizes (1.1). Suppose we only specify\na distribution of macrovalues. This means that we do not know the exact\nmacrostate, perhaps not even initially. The statistics of macroscopic values\nis then given by a probability distribution \u03bd\u0302(M), M \u2208 \u0393\u0302; e.g. our best guess\nabout the position and velocity profile. In the absence of any further information, there is a natural probability density, written \u03c1\u03bd\u0302 , on \u0393 which gives equal\n2\n\n\fprobability to each microstate compatible with a macrostate M:\n\u03bd\u0302(M(x))\n|M(x)|\n\n\u03c1\u03bd\u0302 (x) =\nThe functional\nSG (\u03bd\u0302) = \u2212\n\nZ\n\n\u0393\n\ndx \u03c1\u03bd\u0302 (x) ln \u03c1\u03bd\u0302 (x)\n\nis appropriately called Gibbs entropy as it is, since Gibbs, the usual statistical\nmechanical entropy for constrained equilibrium 2 . Put differently, by Gibbs'\nvariational principle,\nSG (\u03bd\u0302) = sup \u2212\np(\u03bc)=\u03bd\u0302\n\nZ\n\n\u0393\n\ndx \u03bc(x) ln \u03bc(x)\n\n(1.2)\n\nwhere the supremum is taken over all phase space densities \u03bc with the same\nmacro-statistics as \u03bd\u0302, i.e., the projection p(\u03bc) of \u03bc on \u0393\u0302 coincides with \u03bd\u0302:\n\u03bc(M) =\n\nZ\n\n\u0393\n\ndx \u03bc(x) \u03b4(M(x) \u2212 M) = \u03bd\u0302(M)\n\nand the supremum is reached for \u03bc = \u03c1\u03bd\u0302 . Equivalently, by a simple calculation,\nthe Gibbs entropy equals\nSG (\u03bd\u0302) \u2261\n\nX\n\n\u03bd\u0302(M) log |M| \u2212\n\nM\n\nX\n\n\u03bd\u0302(M) log \u03bd\u0302(M)\n\n(1.3)\n\nM\n\nObviously, if \u03bd\u0302 concentrates on just one macrostate M, \u03bd\u0302(M \u2032 ) = \u03b4M,M \u2032 , then\nSG (\u03bd\u0302) = log |M| which is the Boltzmann entropy for that macrostate. More\ngenerally, the first term in (1.3) is the expected or estimated entropy, being\nunsure as we are about the exact macrostate. The second term in (1.3) is nonnegative and is most often negligible, certainly upon dividing by the number\nof particles.\nWhen we start the system from a microstate that is randomly drawn (according to the Liouville measure) from M with probability \u03bd\u0302(M) and we record\nthe statistics \u03bd\u0302t on the macrostates after time t, then, always,\nSG (\u03bd\u0302t ) \u2265 SG (\u03bd\u0302)\n\n(1.4)\n\nThis is not the second law (e.g. it does not imply that SG (\u03bd\u0302t ) is non-decreasing\nin t, see [5] for more discussion). To bring it closer to the second law, one needs\nto explain under what conditions SG (\u03bd\u0302t ) approximates the Boltzmann entropy\nSB (xt ) with xt the time-evolved phase point. Looking back at the first term in\n(1.3), that implies understanding how and when the empirical distribution for\nR\nOften, even without a specific physical context or meaning, \u2212 \u0393 dx \u03bc(x) log \u03bc(x)\nis called the Gibbs entropy of \u03bc. There is however another name for that functional:\nthe Shannon entropy. A way out would be to call SG (\u03bd\u0302) the Boltzmann-GibbsShannon entropy as in [7] but that sounds overdone.\n2\n\n3\n\n\fthe macrovariables becomes peaked, as the number of particles increases, at a\nfixed macroscopic trajectory as described e.g. by hydrodynamic equations of\nirreversible thermodynamics.\nIn [5] we have discussed at length how these entropies relate to time-reversal.\nThe main result there was that both for closed systems and for open systems, be it in the transient regime or in the steady state regime, the entropy\nproduction equals the source term of time-reversal breaking in the action functional for the distribution of the histories (on some thermodynamic scale) of\nthe system. This representation gives the entropy production as a function\nof the trajectories and it allows simple manipulations for taking the average\n(to prove that it is positive) and for studying its fluctuations (to understand\nsymmetries under time-reversal). In the present paper we begin explaining a\nsimilar reasoning for finite quantum systems.\n\n1.2 Quantum set-up\n\nWe take the simplest mathematical set-up for describing a quantum system\nwithin conventional quantum mechanics. We denote by H the Hilbert space\nof the system, assumed finite dimensional. The system is described in terms of\na wavefunction \u03c8, or perhaps better, a normalized vector in H. The variables\ndefining the macrostate are not different from that in the classical situation.\nFor example, they specify (again to some appropriate accuracy) the particle\nnumber and the momentum profiles by associating numbers to a family of\nmacroscopically small but microscopically large regions of the volume occupied\nby the system. Therefore, the macrostate is given in terms of the values of\na set of macroscopic observables represented by commuting operators. The\nmacroscopic partition in the classical case above is replaced by the orthogonal\ndecomposition\nM\nH=\nH\u03b1\n(1.5)\n\ninto linear subspaces. The macrovariables are represented by the projections\nP\nP\u03b1 on the respective H\u03b1 , P\u03b1 P\u03b2 = \u03b4\u03b1,\u03b2 P\u03b1 , \u03b1 P\u03b1 = id. We write d\u03b1 for the\ndimension of H\u03b1 ; it is the analogue of the phase space volume |M| in the\nclassical case. We can think of the macrostates as labeled by the running\nindex \u03b1. For a given macrostate \u03b1 represented by the projection P\u03b1 above, we\nstretch the notation of (1.1) and write its Boltzmann entropy as\nd(\u03b1) \u2261 log d \u2261 log d(P )\nS\nB\n\u03b1\n\u03b1\n\n(1.6)\n\nSo far, the above does not depart essentially from the classical set-up except\nfor the important difference that (1.1) is defined on microstates and (1.6) is\ndefined on macrostates. At this moment the treatment starts to differ. Following von Neumann, page 411 in his well-known book [6], as discussed e.g.\n4\n\n\fin [3], the formula (1.1) is changed to\nSN (\u03c8) =\n\nX\n\n(\u03c8, P\u03b1 \u03c8) log d\u03b1 \u2212\n\n\u03b1\n\nX\n\n(\u03c8, P\u03b1 \u03c8) log(\u03c8, P\u03b1 \u03c8)\n\n(1.7)\n\n\u03b1\n\nwhere (\u03c8, P\u03b1 \u03c8) is the probability of finding the system described via the wavefunction \u03c8 in the macrostate \u03b1 (values corresponding to H\u03b1 ). Observe that\n(1.7) very much resembles (1.3), eventhough (1.7) is the quantum analogue\nof (1.1), both defined as they are for the microstate. The reason is of course\nquantum mechanics itself: the wavefunction can still correspond to different\n(mutually exclusive) macrostates. If not initially, still later in time, superpositions in terms of wavefunctions of different macrostates are possible. This in\ncontrast with the classical set-up where a unique macrostate is associated to\neach microstate. Just as the second term in the classical (1.3) arises from additional uncertainty as to the exact macrostate, here, even when the microstate\nis given (in terms of \u03c8), we still have a distribution on the macrostates 3 .\nInstead of taking a pure state in (1.7), we may want to consider the system in\na mixed state and described by a density matrix. In fact, as we are interested\nin the thermodynamic time-evolution, we construct a special class of density\nmatrices by specifying the macroscopic statistics just as we did for (1.3). We\nthus start from a probability distribution \u03bc\u0302 on the possible macrovalues and we\nrandomize within. More precisely, we consider density matrices \u03c1(\u03bc\u0302) defined\nby\nX \u03bc\u0302(\u03b1)\n\u03c1(\u03bc\u0302) \u2261\nP\u03b1\n(1.8)\nd\u03b1\n\u03b1\nP\nfor given \u03bc\u0302(\u03b1) \u2265 0, \u03b1 \u03bc\u0302(\u03b1) = 1. Then,\n\u03bc\u0302(\u03b1) = Tr[P\u03b1 \u03c1(\u03bc\u0302)]\n\n(1.9)\n\nis the probability to find the system in macrostate \u03b1. For the choice \u03bc\u0302(\u03b1) =\nP\nd\u03b1 /d where, for normalization, d \u2261 \u03b1 d\u03b1 is the dimension of H, \u03c1(\u03bc\u0302) = id/d.\nIn the other direction, given a general density matrix \u03c1, we can take its projection p(\u03c1) on the macroscopic states:\np(\u03c1)(\u03b1) \u2261 Tr[P\u03b1 \u03c1]\n\n(1.10)\n\nand of course, p(\u03c1(\u03bc\u0302)) = \u03bc\u0302.\nWe now apply the same principle as in (1.2) to obtain the (Gibbs - von Neumann) quantum entropy\nS(\u03bc\u0302) \u2261 sup \u2212 Tr[\u03c1 log \u03c1]\n\n(1.11)\n\np(\u03c1)=\u03bc\u0302\n3\n\nOne of us, C.M., likes to emphasize that all this does not exclude that the actual\nsystem is all the time in exactly one of the macrostates - but the wavefunction\ndoes not provide a complete description of the system.\n\n5\n\n\fwith solution (reached at \u03c1 = \u03c1(\u03bc\u0302))\nS(\u03bc\u0302) =\n\nX\n\n\u03bc\u0302(\u03b1) log d\u03b1 \u2212\n\n\u03b1\n\nX\n\n\u03bc\u0302(\u03b1) log \u03bc\u0302(\u03b1)\n\n(1.12)\n\n\u03b1\n\nd(\u03b1) when \u03bc\u0302 concentrates\nwhich looks exactly like (1.3). Again, S(\u03bc\u0302) equals S\nB\non the macrostate \u03b1 and, up to some irrelevant constants, S(\u03bc\u0302) equals the\nrelative entropy of \u03c1(\u03bc\u0302) with respect to the equilibrium density matrix id/d.\nMore generally, we call\n\nS(\u03c1) \u2261 S(p(\u03c1)) =\n\nX\n\nTr[P\u03b1 \u03c1] log d\u03b1 \u2212\n\n\u03b1\n\nX\n\nTr[P\u03b1 \u03c1] log Tr[P\u03b1 \u03c1]\n\n(1.13)\n\n\u03b1\n\nthe macroscopic quantum entropy of the (mixed) state \u03c1, reducing to (1.12)\nfor the choice (1.8) and to (1.7) for a pure state.\n\n2\n\nEntropy production for a unitary evolution\n\nThe goal of this section is to show that the total change of entropy under a\nquantum conservative evolution, that is the entropy production, can be given\nin terms of a logarithmic ratio of probabilities.\nWe suppose a quantum dynamics generated via a real Hamiltonian H. This\nmeans that the Hamiltonian is time-reversal invariant, H\u03c0 = \u03c0H where \u03c0 is an\nanti-linear involution (kinematical time-reversal) which would be just complex\nconjugation for wavefunctions. The unitary evolution U(t) \u2261 exp[\u2212itH] where\nt is time (and Planck's constant is set equal to one) then satisfies\n\u03c0U(t)\u03c0 = U(t)\u22c6 = U(t)\u22121\nan expression of dynamic reversibility. We also assume that the macrostates\nare mapped into each other via the involution \u03c0, i.e.,\n\u03c0P\u03b1 \u03c0 = P\u03b1\u2032 \u2261 P\u03c0\u03b1\n\n(2.1)\n\nfor some \u03b1\u2032 , for each \u03b1 and we write \u03c0\u03b1 = \u03b1\u2032 .\nLet the system be initially prepared with macro-statistics \u03c1(\u03bc\u0302), see (1.8). We\nnow leave the system alone, undergoing its quantum evolution. The probability to see the system at the initial time in macrostate \u03b10 and at time t in\nmacrostate \u03b1t is given by\nProb\u03bc\u0302 [\u03b10 , \u03b1t ] = Tr [U(t)P\u03b10 \u03c1(\u03bc\u0302)P\u03b10 U(t)\u22c6 P\u03b1t ]\n6\n\n(2.2)\n\n\fIts marginal at time t is\n\u03bc\u0302t (\u03b1) \u2261\n\nX\n\nProb\u03bc\u0302 [\u03b10 , \u03b1t = \u03b1] = Tr [U(t)\u03c1(\u03bc\u0302)U(t)\u22c6 P\u03b1 ]\n\n(2.3)\n\n\u03b10\n\nWe consider the logarithmic ratio of probabilities\nR\u03bc\u0302 (\u03b10 , \u03b1t ) \u2261 log\n\nProb\u03bc\u0302 [\u03b10 , \u03b1t ]\nProb\u03bc\u0302t \u03c0 [\u03c0\u03b1t , \u03c0\u03b10 ]\n\n(2.4)\n\nwhere the denominator gives the probability of the time-reversed order of\nmeasurement results starting from \u03c1(\u03bc\u0302t \u03c0) with \u03bc\u0302t \u03c0(\u03b1) \u2261 \u03bc\u0302t (\u03c0\u03b1).\nWe make two observations. First, when \u03bc\u0302(\u03b1) = d\u03b1 /d, then also at later times\n\u03bc\u0302t (\u03b1) = d\u03b1 /d and moreover\nProb\u03bc\u0302 [\u03b10 , \u03b1t ] = Prob\u03bc\u0302t [\u03c0\u03b1t , \u03c0\u03b10 ]\n\n(2.5)\n\nexpressing the time-reversal invariance when started from the time-invariant\nmacro-statistics that assigns to macrostates probabilities proportional to the\nexponential of their Boltzmann entropy, see (1.6).\nSecondly, for other choices of the initial macro-statistics, the R\u03bc\u0302 of (2.4) reproduces the change of entropy:\nR\u03bc\u0302 (\u03b10 , \u03b1t ) = log d\u03b1t \u2212 log d\u03b10 \u2212 log \u03bc\u0302t (\u03b1t ) + log \u03bc\u0302(\u03b10 )\n\n(2.6)\n\nwhere we recognize the change of Boltzmann entropies (1.6) in the first two\nterms. Upon taking the expectation\nX\n\nProb\u03bc\u0302 [\u03b10 , \u03b1t ] R\u03bc\u0302 (\u03b10 , \u03b1t ) = S(\u03bc\u0302t ) \u2212 S(\u03bc\u0302)\n\n(2.7)\n\n\u03b10 ,\u03b1t\n\nwe recover the change in entropy (1.11). Note that S(\u03bc\u0302t ) = S(\u03c1t ), S(\u03bc\u0302) =\nS(\u03c1) defined in (1.13) for \u03c1 = \u03c1(\u03bc\u0302), \u03c1t = U(t)\u03c1U(t)\u22c6 so that the right-hand\nside of (2.7) is really the change of macroscopic quantum entropy under the\nunitary evolution. The left-hand side of (2.7) is a relative entropy, hence is\nnon-negative.\n\n3\n\nPerturbations by measurement\n\nIn contrast with the classical evolution, the unitary evolution can be nontrivially interrupted by measurements that reduce the state. We follow here\nthe theory of von Neumann (or, convential quantum mechanics) that adds a\ndynamic interpretation to the projections (1.10). We extend here the results\nof the previous section to include interactions with a measurement apparatus.\n7\n\n\fSuppose that we start the system described by a density matrix \u03c1 at time 0\nand that we measure the macroscopic value \u03b1 at time \u03c4 > 0. Then, the new\ndensity matrix is\nP\u03b1 U \u03c1 U \u22c6 P\u03b1\nTr[P\u03b1 U \u03c1 U \u22c6 ]\nwhere U \u2261 U(\u03c4 ) = exp[\u2212i\u03c4 H]. This reduction takes place with probability\np(U\u03c1U \u22c6 )(\u03b1) = Tr[P\u03b1 U \u03c1 U \u22c6 ]\nWe can generalize this to a sequence of measurements.\n\n3.1 Path-space measure\nWe consider a sequence of times 0, \u03c4, 2\u03c4, . . . , n\u03c4 = t (evenly spaced for convenience). A macroscopic trajectory \u03c9 assigns to each of these times a value\nfor the macroscopic observables. In short, \u03c9 = (\u03c90 , . . . , \u03c9n ) with each \u03c9i being\nequal to some projection P\u03b1 on the linear subspace H\u03b1 of (1.5). We consider\nthe operator\nG\u03c9 \u2261 \u03c9n U\u03c9n\u22121 . . . \u03c91 U\u03c90\n(3.1)\nand, for a given density matrix \u03c1 on H, the matrix\nD\u03c1 (\u03c9, \u03c9 \u2032) \u2261 Tr[G\u03c9 \u03c1 G\u22c6\u03c9\u2032 ]\n\n(3.2)\n\nThis resembles the correlation matrix that is used in the definition of quantum\ndynamical entropy, see p. 189 in [2], but again, here our partitioning corresponds to macrostates.\nIt is easy to verify that D\u03c1 is non-negative and has trace one. We call it the\npath-space density matrix.\nD\u03c1 depends on the initial density matrix \u03c1 and it also gives the probability\nto find the system after time t = n\u03c4 of (measurement-)free evolution in the\nmacrostate \u03b1:\nX\nD\u03c1 (\u03c9, \u03c9 \u2032) = Tr[P\u03b1 \u03c1t ]\n(3.3)\n\u2032 =P\n\u03c9,\u03c9 \u2032 :\u03c9n =\u03c9n\n\u03b1\n\nn\n\nwhere \u03c1t \u2261 U \u03c1U .\nMore importantly, the probability to measure the trajectory \u03c9, i.e., to see the\nsystem at the initial time in the macrostate represented by \u03c90 , at time \u03c4 in\nmacrostate \u03c91 , and so on till time n\u03c4 = t, is given by the diagonal element\n\u2212n\n\nProb\u03c1 [\u03c9] = D\u03c1 (\u03c9, \u03c9)\n\n(3.4)\n\nX\n\n(3.5)\n\nIts marginal at time t = n\u03c4 ,\n\u03bc\u0302t (\u03b1) \u2261\n\n\u03c9:\u03c9n =P\u03b1\n\n8\n\nProb\u03c1 [\u03c9]\n\n\fis the probability of macrostate \u03b1 when the unitary evolution was interrupted\nby n measurements. It equals (2.3) in case n = 1.\n3.2 Time-reversal\nOn trajectories, the time-reversal transformation \u0398 is\n(\u0398\u03c9)m \u2261 \u03c0\u03c9n\u2212m \u03c0,\n\nm = 0, 1, . . . , n\n\nSince the microscopic dynamics is time-reversal invariant, we immediately\ndeduce that\nG\u0398\u03c9 = \u03c0G\u22c6\u03c9 \u03c0\nand it is easy to verify that for \u03c1 = id/d in (3.2)\nD(\u0398\u03c9 \u2032, \u0398\u03c9) = D(\u03c9, \u03c9 \u2032)\n\n(3.6)\n\nIn particular, for (3.4) with \u03c1 = id/d, Prob[\u03c9] = Prob[\u0398\u03c9]. This identity\nhas two related interpretations. First, it is the expression of (quantum) detailed balance or microscopic reversibility for the trajectories sampled from\nthe time-invariant density matrix id/d corresponding to equilibrium. It is the\ngeneralization of (2.5). Secondly, it generalizes the observation of [1] that measurements do not introduce a time-asymmetric element (or, the reduction of\nthe wave packet does not lead to irreversibility).\nYet, in general, the system could start in a nonequilibrium state and evolve\ntowards equilibrium. This involves a change of entropy; that is, for closed and\nthermally isolated systems, its total entropy production.\nThe time-reversal of the density matrix D\u03c1 , written D\u03c1 \u0398, is defined as\nD\u03c1 \u0398(\u03c9, \u03c9 \u2032) \u2261 D\u03c1 (\u0398\u03c9 \u2032, \u0398\u03c9)\n\n(3.7)\n\nso that by (3.6), D\u0398 = D. This last equality is broken for a general D\u03c1 and it\nseems natural to estimate this breaking via the relative entropy\nS(D\u03c11 |D\u03c12 \u0398) \u2261 Tr[D\u03c11 (log D\u03c11 \u2212 log D\u03c12 \u0398)]\n\n(3.8)\n\nIn view of the classical results of [4,5], it is to be expected that this relative\nentropy is related to the entropy production for the appropriate choices of \u03c11\n(as initial state) and of \u03c12 (as time-reversal of the final state).\n3.3 Entropy production\nWe start again from \u03bc\u0302 as initial probability distribution (i.e., \u03c1(\u03bc\u0302) is the initial\ndensity matrix) and the final probability distribution \u03bc\u0302t is defined in (3.5). The\n9\n\n\fmain result is now readily obtained starting with the analogue of (2.4): the\nlogarithmic ratio of probabilities (3.4) of a macroscopic trajectory, one started\nfrom \u03bc\u0302 and the other started from \u03bc\u0302t \u03c0, is abbreviated as\nR\u03bc\u0302 (\u03c9) \u2261 log\n\nProb\u03bc\u0302 [\u03c9]\nProb\u03bc\u0302t \u03c0 [\u0398\u03c9]\n\n(3.9)\n\nThis object will not always be well-defined for all \u03c9. We can suppose however\nthat the \u03bc\u0302(\u03b1) 6= 0 6= \u03bc\u0302t (\u03b1) so that a little calculation of (3.9) yields\nR\u03bc\u0302 (\u03c9) = log d(\u03c9n ) \u2212 log d(\u03c90 ) \u2212 log \u03bc\u0302t (\u03c9n ) + log \u03bc\u0302(\u03c90 )\n\n(3.10)\n\nIn the notation of (1.6), the first difference in the right-hand side of (3.10)\nd(\u03b1 ) \u2212 S\nd(\u03b1 ) for a trajectory that\nequals the change of Boltzmann entropy S\nB\nt\nB\n0\nstarts in macrostate \u03b10 and ends in macrostate \u03b1t . If the system is initially\nprepared in essentially one macrostate, \u03bc\u0302(\u03b10 ) \u2243 1, and if the evolution on the\nlevel of macrostates is quasi-autonomous till time t in the sense that \u03bc\u0302t (\u03b1t ) \u2243\n1, then only that change in Boltzmann entropies survives.\nTaking the expectation of (3.9), we get, similar as in (2.7),\nX\n\nProb\u03bc\u0302 [\u03c9] R\u03bc\u0302 (\u03c9) = S(\u03bc\u0302t ) \u2212 S(\u03bc\u0302) \u2265 0\n\n(3.11)\n\n\u03c9\n\nequal to the change of quantum entropy (1.11)\u2013(1.12). The non-negativity follows from Jensen's inequality applied to the left-hand side of (3.11).\nOne can easily check that this expectation (the left-hand side of (3.11)) and\nhence, the change of quantum entropy (the right-hand side of (3.11)), also\ncoincides with the relative entropy on the level of density matrices for trajectories\nS(D\u03bc\u0302 |D\u03bc\u0302t \u03c0 \u0398) = Tr [D\u03bc\u0302 (log D\u03bc\u0302 \u2212 log D\u03bc\u0302t \u03c0 \u0398)]\nas announced in (3.8).\n\n4\n\nConclusions and additional remarks\n\nEntropy production, also for the quantum situation, has been under intense\ninvestigation in recent years. A list of related references, even restricted to the\nlast 5 years would soon fill an extra couple of pages. In the classical case, there\nhave been essentially two types of approaches, dynamical versus statistical. In\nthe dynamical approach, entropy production is connected with the fractal or\nsingular nature of a class of natural stationary measures. A key-notion is the\nphase space contraction rate and with some extrapolations, nonequilibrium\nstatistical mechanics becomes a branch of the theory of smooth dynamical\nsystems. It was partially motivated by numerical work and it has given wonderful insights, guiding towards a study of fluctuations of the entropy production, possibly generalizing close to equilibrium relations. The statistical\n10\n\n\fapproach emphasizes the sharp contrast between the microscopic and macroscopic scales and stochasticity enters the dynamical evolutions because of the\nreduced description. On space-time the histories have a distribution that share\nthe essential properties of Gibbs measures. The entropy production can then\nbe identified with the source term of time-reversal breaking in the action (or\nspace-time Lagrangian) of the space-time distribution; the Gibbs formalism\nreproduces and extends the results for the fluctuations of the entropy production obtained in the purely dynamical approach. The projections on equal\ntime surfaces reproduce the time-evolved measure. In the quantum case, the\nmodern dynamical approach does not seem to have a natural generalization.\nInstead, the old machinery of operator-algebra and spectral theory, directly\napplied on infinite volume systems, has been providing encouraging results for\nrelaxation to equilibrium and the positivity of entropy production in driven\nquantum systems. Again however, the conceptual framework and the essential\ndistinction between microstates and macro-statistics is, at least to our taste,\nmost often blurred in non-intuitive dynamical assumptions and in the heavy\nmathematical formalism. The present paper offers an alternative and starts\nthe statistical approach for quantum systems. The first step indeed is to be\nquite clear as to the relation between time-reversal and entropy production.\nAs in the classical case, we consider this important for constructing nonequilibrium statistical mechanics. Specifically, we hope that the characterizations\nof (2.6) and (3.10) will prove useful for deriving general fluctuation and response identities going beyond close to equilibrium.\nWe add some general remarks.\n1. For reversible systems the entropy production is a state function. It does\nnot depend on the actual path but can be written as a difference of the same\nquantity evaluated at the initial and the final time, see (2.6) or (3.10). This\ncan be different for driven or irreversible systems. A similar treatment for\nsuch systems in the classical regime can be found in [5]. One of the main\nconsequences of the identities that correspond there to (2.6) or (3.10) is that\ncertain symmetries in the fluctuations of the entropy production rate are easily\nestablished. The quantum case is in preparation.\n2. Nothing of the previous mathematical identities depends on the assumption\nthat the system is large, of macroscopic size, containing a huge number of particles. Of course, to meaningfully discuss macroscopic variables or macrostates\nand their trajectories one has in mind a clear separation between micro and\nmacro scales but the results of Sections 2 and 3 are true without. Yet again,\ntheir interpretation as thermodynamic entropy production and the relation\nwith the second law can only be made when dealing with macroscopic systems. See also Appendix A in [5] for these considerations in the classical case.\n3. The use of the projections P\u03b1 in the construction of the path-space density\nmatrix of Section 3 refers to the so called von Neumann measurements. One\n11\n\n\fcan imagine more fuzzy measurements (and more rounded-off macrostates)\nand a corresponding decomposition of unity as\nX\n\nX\u03b1\u22c6 X\u03b1 = id\n\n\u03b1\n\nThe treatment above was restricted to the case X\u03b1 = P\u03b1 U. This extension\nis very much related to the dynamics of open systems, see e.g. [2]. The involvement of measurements interrupting the unitary evolution already points\nto the interaction with the outside world. The question of isolation, even as\nan idealization, of a quantum system is much more subtle than for a classical\nsystem.\n\nReferences\n[1] Y. Aharonov, P.G. Bergmann and J.L. Lebowitz: Time Symmetry in the\nQuantum Process of Measurement, Phys. Rev. 134 (number 6B), 1410\u20131416\n(1964).\n[2] R. Alicki and M. Fannes: Quantum dynamical systems, Oxford University Press,\nOxford, 2001.\n[3] J.L. Lebowitz, Microscopic Origins of Irreversible Macroscopic Behavior,\nPhysica A 263, 516\u2013527 (1999).\n[4] C. Maes: The Fluctuation Theorem as a Gibbs Property, J. Stat. Phys. 95,\n367\u2013392 (1999).\n[5] C. Maes and K. Neto\u010dn\u00fd: Time-reversal and Entropy, J. Stat. Phys. 110, 269\u2013\n310 (2003).\n[6] J. von Neumann: Mathematical Foundations of Quantum Mechanics, Princeton\nUniversity Press, Princeton, 1955.\n[7] A. Wehrl: General Properties of Entropy, Rev. Mod. Phys. 50, 221\u2013260 (1978).\n\n12\n\n\f"}