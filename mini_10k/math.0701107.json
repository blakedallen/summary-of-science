{"id": "http://arxiv.org/abs/math/0701107v1", "guidislink": true, "updated": "2007-01-03T20:01:27Z", "updated_parsed": [2007, 1, 3, 20, 1, 27, 2, 3, 0], "published": "2007-01-03T20:01:27Z", "published_parsed": [2007, 1, 3, 20, 1, 27, 2, 3, 0], "title": "Aggregation of Nonparametric Estimators for Volatility Matrix", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0701488%2Cmath%2F0701460%2Cmath%2F0701938%2Cmath%2F0701234%2Cmath%2F0701825%2Cmath%2F0701093%2Cmath%2F0701186%2Cmath%2F0701910%2Cmath%2F0701897%2Cmath%2F0701315%2Cmath%2F0701498%2Cmath%2F0701595%2Cmath%2F0701741%2Cmath%2F0701427%2Cmath%2F0701224%2Cmath%2F0701305%2Cmath%2F0701699%2Cmath%2F0701174%2Cmath%2F0701719%2Cmath%2F0701523%2Cmath%2F0701175%2Cmath%2F0701360%2Cmath%2F0701812%2Cmath%2F0701126%2Cmath%2F0701422%2Cmath%2F0701823%2Cmath%2F0701451%2Cmath%2F0701894%2Cmath%2F0701359%2Cmath%2F0701246%2Cmath%2F0701071%2Cmath%2F0701776%2Cmath%2F0701008%2Cmath%2F0701318%2Cmath%2F0701828%2Cmath%2F0701276%2Cmath%2F0701114%2Cmath%2F0701363%2Cmath%2F0701837%2Cmath%2F0701138%2Cmath%2F0701613%2Cmath%2F0701824%2Cmath%2F0701051%2Cmath%2F0701927%2Cmath%2F0701446%2Cmath%2F0701395%2Cmath%2F0701137%2Cmath%2F0701206%2Cmath%2F0701457%2Cmath%2F0701033%2Cmath%2F0701070%2Cmath%2F0701801%2Cmath%2F0701064%2Cmath%2F0701369%2Cmath%2F0701646%2Cmath%2F0701401%2Cmath%2F0701790%2Cmath%2F0701854%2Cmath%2F0701653%2Cmath%2F0701534%2Cmath%2F0701072%2Cmath%2F0701735%2Cmath%2F0701803%2Cmath%2F0701628%2Cmath%2F0701793%2Cmath%2F0701337%2Cmath%2F0701431%2Cmath%2F0701086%2Cmath%2F0701556%2Cmath%2F0701583%2Cmath%2F0701275%2Cmath%2F0701277%2Cmath%2F0701621%2Cmath%2F0701602%2Cmath%2F0701548%2Cmath%2F0701727%2Cmath%2F0701507%2Cmath%2F0701718%2Cmath%2F0701883%2Cmath%2F0701504%2Cmath%2F0701282%2Cmath%2F0701429%2Cmath%2F0701723%2Cmath%2F0701098%2Cmath%2F0701248%2Cmath%2F0701420%2Cmath%2F0701591%2Cmath%2F0701888%2Cmath%2F0701107%2Cmath%2F0701050%2Cmath%2F0701243%2Cmath%2F0701690%2Cmath%2F0701028%2Cmath%2F0701634%2Cmath%2F0701432%2Cmath%2F0701873%2Cmath%2F0701154%2Cmath%2F0701630%2Cmath%2F0701316%2Cmath%2F0701645%2Cmath%2F0701863&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Aggregation of Nonparametric Estimators for Volatility Matrix"}, "summary": "An aggregated method of nonparametric estimators based on time-domain and\nstate-domain estimators is proposed and studied. To attenuate the curse of\ndimensionality, we propose a factor modeling strategy. We first investigate the\nasymptotic behavior of nonparametric estimators of the volatility matrix in the\ntime domain and in the state domain. Asymptotic normality is separately\nestablished for nonparametric estimators in the time domain and state domain.\nThese two estimators are asymptotically independent. Hence, they can be\ncombined, through a dynamic weighting scheme, to improve the efficiency of\nvolatility matrix estimation. The optimal dynamic weights are derived, and it\nis shown that the aggregated estimator uniformly dominates volatility matrix\nestimators using time-domain or state-domain smoothing alone. A simulation\nstudy, based on an essentially affine model for the term structure, is\nconducted, and it demonstrates convincingly that the newly proposed procedure\noutperforms both time- and state-domain estimators. Empirical studies further\nendorse the advantages of our aggregated method.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=math%2F0701488%2Cmath%2F0701460%2Cmath%2F0701938%2Cmath%2F0701234%2Cmath%2F0701825%2Cmath%2F0701093%2Cmath%2F0701186%2Cmath%2F0701910%2Cmath%2F0701897%2Cmath%2F0701315%2Cmath%2F0701498%2Cmath%2F0701595%2Cmath%2F0701741%2Cmath%2F0701427%2Cmath%2F0701224%2Cmath%2F0701305%2Cmath%2F0701699%2Cmath%2F0701174%2Cmath%2F0701719%2Cmath%2F0701523%2Cmath%2F0701175%2Cmath%2F0701360%2Cmath%2F0701812%2Cmath%2F0701126%2Cmath%2F0701422%2Cmath%2F0701823%2Cmath%2F0701451%2Cmath%2F0701894%2Cmath%2F0701359%2Cmath%2F0701246%2Cmath%2F0701071%2Cmath%2F0701776%2Cmath%2F0701008%2Cmath%2F0701318%2Cmath%2F0701828%2Cmath%2F0701276%2Cmath%2F0701114%2Cmath%2F0701363%2Cmath%2F0701837%2Cmath%2F0701138%2Cmath%2F0701613%2Cmath%2F0701824%2Cmath%2F0701051%2Cmath%2F0701927%2Cmath%2F0701446%2Cmath%2F0701395%2Cmath%2F0701137%2Cmath%2F0701206%2Cmath%2F0701457%2Cmath%2F0701033%2Cmath%2F0701070%2Cmath%2F0701801%2Cmath%2F0701064%2Cmath%2F0701369%2Cmath%2F0701646%2Cmath%2F0701401%2Cmath%2F0701790%2Cmath%2F0701854%2Cmath%2F0701653%2Cmath%2F0701534%2Cmath%2F0701072%2Cmath%2F0701735%2Cmath%2F0701803%2Cmath%2F0701628%2Cmath%2F0701793%2Cmath%2F0701337%2Cmath%2F0701431%2Cmath%2F0701086%2Cmath%2F0701556%2Cmath%2F0701583%2Cmath%2F0701275%2Cmath%2F0701277%2Cmath%2F0701621%2Cmath%2F0701602%2Cmath%2F0701548%2Cmath%2F0701727%2Cmath%2F0701507%2Cmath%2F0701718%2Cmath%2F0701883%2Cmath%2F0701504%2Cmath%2F0701282%2Cmath%2F0701429%2Cmath%2F0701723%2Cmath%2F0701098%2Cmath%2F0701248%2Cmath%2F0701420%2Cmath%2F0701591%2Cmath%2F0701888%2Cmath%2F0701107%2Cmath%2F0701050%2Cmath%2F0701243%2Cmath%2F0701690%2Cmath%2F0701028%2Cmath%2F0701634%2Cmath%2F0701432%2Cmath%2F0701873%2Cmath%2F0701154%2Cmath%2F0701630%2Cmath%2F0701316%2Cmath%2F0701645%2Cmath%2F0701863&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "An aggregated method of nonparametric estimators based on time-domain and\nstate-domain estimators is proposed and studied. To attenuate the curse of\ndimensionality, we propose a factor modeling strategy. We first investigate the\nasymptotic behavior of nonparametric estimators of the volatility matrix in the\ntime domain and in the state domain. Asymptotic normality is separately\nestablished for nonparametric estimators in the time domain and state domain.\nThese two estimators are asymptotically independent. Hence, they can be\ncombined, through a dynamic weighting scheme, to improve the efficiency of\nvolatility matrix estimation. The optimal dynamic weights are derived, and it\nis shown that the aggregated estimator uniformly dominates volatility matrix\nestimators using time-domain or state-domain smoothing alone. A simulation\nstudy, based on an essentially affine model for the term structure, is\nconducted, and it demonstrates convincingly that the newly proposed procedure\noutperforms both time- and state-domain estimators. Empirical studies further\nendorse the advantages of our aggregated method."}, "authors": ["Jianqing Fan", "Yingying Fan", "Jinchi Lv"], "author_detail": {"name": "Jinchi Lv"}, "author": "Jinchi Lv", "arxiv_comment": "46 pages, 11 PostScript figures", "links": [{"href": "http://arxiv.org/abs/math/0701107v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/math/0701107v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.ST", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "stat.TH", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "62G05; 62G20; 62M05", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/math/0701107v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/math/0701107v1", "journal_reference": null, "doi": null, "fulltext": "arXiv:math/0701107v1 [math.ST] 3 Jan 2007\n\nAggregation of Nonparametric Estimators for\nVolatility Matrix\n\n\u2217\n\nJianqing Fan\u2020\nDepartment of Operations Research and Financial Engineering\nPrinceton University\n\nYingying Fan\n\n\u2021\n\nDepartment of Operations Research and Financial Engineering\nPrinceton University\n\nJinchi Lv\n\n\u00a7\n\nDepartment of Mathematics\nPrinceton University\n\nNovember 1, 2006\n\nAddress correspondence to Yingying Fan, Department of ORFE, Princeton University,\nPrinceton, NJ 08544. Email: yingying@princeton.edu.\n\n\u2217\n\nFinancial support from the NSF under grant DMS-0532370 is gratefully acknowledged. We are\n\ngrateful to Lars Hansen, Robert Kimmel, and conference participants of Financial Mathematics Workshop at SAMSI; the 2006 Xiamen Financial Engineering and Risk Management Workshop; the 69th\nIMS Annual Meeting for helpful comments.\n\u2020\nPrinceton, NJ 08544. Phone: (609) 258-7924. E-mail: jqfan@princeton.edu.\n\u2021\nCorresponding author. Princeton, NJ 08544.\nPhone: (609) 258-7383.\ning@princeton.edu.\n\u00a7\nPrinceton, NJ 08544. Phone: (609) 258-9433. E-mail: jlv@princeton.edu.\n\n1\n\nE-mail:\n\nyingy-\n\n\fABSTRACT\nAn aggregated method of nonparametric estimators based on time-domain and statedomain estimators is proposed and studied. To attenuate the curse of dimensionality,\nwe propose a factor modeling strategy. We first investigate the asymptotic behavior\nof nonparametric estimators of the volatility matrix in the time domain and in the\nstate domain. Asymptotic normality is separately established for nonparametric estimators in the time domain and state domain. These two estimators are asymptotically\nindependent. Hence, they can be combined, through a dynamic weighting scheme, to\nimprove the efficiency of volatility matrix estimation. The optimal dynamic weights are\nderived, and it is shown that the aggregated estimator uniformly dominates volatility\nmatrix estimators using time-domain or state-domain smoothing alone. A simulation\nstudy, based on an essentially affine model for the term structure, is conducted, and it\ndemonstrates convincingly that the newly proposed procedure outperforms both timeand state-domain estimators. Empirical studies further endorse the advantages of our\naggregated method.\nKEYWORDS: aggregation, nonparametric function estimation, diffusion, volatility\nmatrix, factor, local time, affine model.\n\nCovariance matrices are fundamental for risk management, asset pricing, proprietary\ntrading, and portfolio managements. In forecasting a future event such as the volatility\nmatrix, two pieces of information are frequently consulted. Based on the recent history,\none uses a form of local average, such as the moving average, to predict the volatility\nmatrix. This approach localizes in time and uses the smoothness of the volatility matrix\nas a function of time. It ignores completely the historical information, which is related\nto the current prediction through a stationarity1 assumption. On the other hand,\none can predict a future event by consulting the historical information with similar\nscenarios. This approach basically localizes in the state variable and depends on the\nstationarity assumption. For example, by localizing on a few key financial factors,\n1\n\nBy \"stationarity\" we do not mean that the process is strongly stationary, but has some structural\n\ninvariability over time. For example, the conditional moment functions do not vary over time.\n\n2\n\n\fone can compute the volatility matrix using the historical information. This results\nin a nonparametric estimate of the volatility matrix using state-domain smoothing.\nSee, for example, Anderson, Bollerslev and Diebold (2002) for a unified framework of\ninterpreting both parametric and nonparametric approaches for volatility measurement.\nThe aforementioned two estimators are weakly correlated, as they use data that\nare quite far apart in time. They can be combined to improve the efficiency of the\nvolatility matrix estimation. This results in an aggregated estimator of the volatility\nmatrix. Three challenges arise in the endeavor: the curse of dimensionality, the choice\nof dynamic weights, and the mathematical complexity.\nDue to the curse of dimensionality, surface smoothing techniques are not very useful\nin practice when there are more than two or three predictor variables. An efficient\ndimensionality reduction process should be imposed in state-domain estimation. An\nintroduction to some of these approaches, such as additive modeling, partially linear\nmodeling, modeling with interactions, and multiple index models, can be found in Fan\nand Yao (2003).\nIn this paper, we propose a factor modeling strategy to reduce the dimensionality\nin the state domain smoothing. Specifically, to estimate the covariance matrix among\nseveral assets, we first find a few factors that capture the main price dynamics of\nthe underlying assets. Regarding the covariance matrix as a smooth function of these\nfactors, the covariance matrix can be computed via localizing on the factors.\nFigure 1 here.\nOur approach is particularly appealing for the yields of bonds, as they are often\nhighly correlated, which makes the choice of the factors relatively easy. To elucidate our\nidea, consider the weekly data on the yields of treasury bills and bonds with maturities\n1 year, 5 years, and 10 years presented in Figure 1. We choose the 5-year yield process\nas the single factor. Suppose that the current time is January 14, 2000 and the current\ninterest rate of the 5-year treasury bond is 6.67%, corresponding to time index t = 1986.\nOne may estimate the volatility matrix based on the weighted squared differences in the\npast 104 weeks. This corresponds to time-domain smoothing, using the small vertical\nstretch of data shown in Figure 1(a). On the other hand, one may also estimate the\n\n3\n\n\fvolatility matrix using the historical data with interest rates approximately 6.67%, say,\n6.67% \u00b1 .20%. This corresponds to localizing in state domain and is indicated by the\nhorizontal bar in Figure 1(a). Figures 1(b) and 1(c) present scatter plots of the yield\n1yr\n10yr\ndifferences Xt1yr \u2212 Xt\u22121\nfor the 1-year bill against the yield differences Xt10yr \u2212 Xt\u22121\nfor\n\nthe 10-year bond, using respectively the data localizing in the time and state domains.\nThe associated regression lines of the time- and state-domain data are also presented.\nThe scatter plots give two estimates of the conditional correlation and conditional\nvariance of the volatility matrix for the week of t = 1986. They are weakly dependent\nas the two scatter plots use data that are quite far apart in time.\nb T,t and \u03a3\nb S,t be the estimated volatility matrices based on data localizing\nLet \u03a3\n\nin the time and state domains, respectively. For example, they can be the sample\ncovariance matrices for the data presented in Figures 1(b) and 1(c), respectively for\nt = 1986. To fully utilize these two estimators, we introduce a weight wt and define an\naggregated estimator2 as\nb A,t = \u03c9t \u03a3\nb S,t + (1 \u2212 \u03c9t )\u03a3\nb T,t .\n\u03a3\n\n(1)\n\nThe weight function \u03c9t is always between 0 and 1, and it can be an adaptive random\nprocess which is observable at time t. Due to the weak dependence between the original\ntwo estimators, the aggregated estimator is always more efficient than either of the timeand state-domain estimators.\nAn interesting question is the choice of the dynamic weight \u03c9t . Suppose we have a\nportfolio with allocation vector a. Then the aggregation method gives us the following\nestimate of the portfolio variance:\nb A,t a = \u03c9t aT \u03a3\nb S,t a + (1 \u2212 \u03c9t )aT \u03a3\nb T,t a.\naT \u03a3\n\n(2)\n\nb S,t and \u03a3\nb T,t are asymptotically independent3 , the optimal weight in terms of\nSince \u03a3\n2\n\nLedoit and Wolf (2003) introduce a shrinkage estimator by combining the sample covariance es-\n\ntimator with that derived from the CAPM. Their procedure intends to improve estimated covariance\nmatrix by pulling the sample covariance towards the estimate based on the CAPM. Their basic assumption is that the return vectors are i.i.d. across time. This usually holds approximately when the\ndata are localized in time. In this sense, their estimator can be regarded as a time-domain estimator.\n3\nb S,t and \u03a3\nb T,t are asymptotically independent, and thus they are close to\nWe prove in Section 4 that \u03a3\n\n4\n\n\fb A,t a is\nminimizing the variance of aT \u03a3\n\u03c9opt,t =\n\nb T,t a)\nvar(aT \u03a3\n.\nb S,t a) + var(aT \u03a3\nb T,t a)\nvar(aT \u03a3\n\n(3)\n\nIndeed, our asymptotic result in Section 3 shows that the optimal weight admits a\nsimple and explicit form, independent of a. This makes our implementation very easy.\nThe above approach is data analytic in the sense that it is always operational. To\nappreciate our idea, we will introduce a mathematical model for the data-generating\nprocess in Section 1. And then in the following several sections we formally show that\nthe aggregated estimator has the desired statistical properties.\n\n1\n\nModel and Assumptions\n\nLet Wt = (W1t , * * * , Wtm )T and W = {Wt , FtW ; 0 \u2264 t < \u221e} be an m-dimensional\nstandard Brownian motion. Consider the following d-dimensional diffusion process\ndX t = \u03bct dt + \u03c3 t dWt ,\n\n(4)\n\nwhere X t = (Xt1 , * * * , Xtd )T , \u03bct is a d \u00d7 1 predictable vector process, and \u03c3 t is a d \u00d7 m\npredictable matrix process, depending only on X t . Here, m can be different from d.\nThis is a widely used model for asset prices and the yields of bonds. This family of\nmodels includes famous ones such as multivariate generalizations of both Vasicek (1977)\nand Cox, Ingersoll and Ross (1985).\nUnder model (4), the diffusion matrix is \u03a3t = \u03c3 t \u03c3 Tt . As mentioned before, when\nd \u2265 2, the so-called curse of dimensionality makes implementation hard. To reduce\nthe dimensionality, we introduce a scalar factor ft and model the drift and diffusion\nprocesses as \u03bct = \u03bc(ft ) and \u03c3 t = \u03c3(ft ), where \u03bc(*) = {\u03bci (*)}1\u2264i\u2264d is a d \u00d7 1 Borel\nmeasurable vector and \u03c3(*) = {\u03c3ij (*)}1\u2264i\u2264d,1\u2264j\u2264m is a d \u00d7 m Borel measurable matrix.\nThen model (4) becomes\ndXti = \u03bci (ft )dt +\n\nm\nX\n\n\u03c3ij (ft )dWtj ,\n\nj=1\n\n1 \u2264 i \u2264 d.\n\n(5)\n\nbe independent in finite sample. In the following, by \"nearly independent\" and \"almost uncorrelated\",\nwe mean the same.\n\n5\n\n\fIn this model, the diffusion matrix is \u03a3(ft ) = \u03c3(ft )\u03c3(ft )T . See also Engle, Ng and\nRothchild (1990) for a similar strategy.\nWe introduce some stochastic structure on ft by assuming that ft is the solution to\nthe following stochastic differential equation (SDE):\ndft = a(ft )dt +\n\nm\nX\n\nbj (ft )dWtj ,\n\n(6)\n\nj=1\n\nwhere a(*) and b1 (*), b2 (*), * * * , bm (*) are unknown functions. In some situations like\n\nmodeling bond yields4 , the factor ft can be chosen as one of the bond yields, i.e., ft is\none of the coordinates of X t . But in general, ft may be different from any coordinate\nof X t , and the theoretical studies in this paper apply to both cases. The data are\nobserved at times ti = t0 + i\u2206, i = 0, 1, * * * , N , with sampling interval \u2206, resulting in\nvectors {X ti , i = 0, 1, * * * , N } and {fti , i = 0, 1, * * * , N }. This model is reasonable for\nthe yields of bonds with different maturities since they are highly correlated. Thus,\nlocalizing on all the yields processes in the state domain results in approximately the\nsame data set as localizing on only one of the yields processes. In addition, our study\ncan be generalized to the multi-factor case without much extra difficulty. We will focus\non the one-factor setting for simplicity of presentation.\nLet Y i = (X ti+1 \u2212 X ti )\u2206\u22121/2 , and denote by Yi1 , Yi2 , * * * , Yid the coordinates of\nY i . Then, by the Euler scheme, we have\n\u221a\nY i \u2248 \u03bc(fti ) \u2206 + \u03c3(fti )\u03b5ti ,\n\n(7)\n\nwhere \u03b5ti follows the m-dimensional standard Gaussian distribution. The conditional\ncovariance matrix of X at time ti can be approximated by \u2206\u03a3(fti ) (see Fan and Zhang,\n2003). Hence, the estimate of the conditional covariance matrix is almost equivalent to\nthe estimate of the diffusion matrix \u03a3(*). Fan and Zhang (2003) study the impact of the\norder of difference on nonparametric estimation. They found that while higher order\ncan possibly reduce approximation errors, it increases variances of data substantially.\nThey recommended the Euler scheme (7) for most practical situations.\nTo use time-domain information, it is necessary to assume that the sampling frequency \u2206 converges to zero so that the biases in time-domain approximations are\n4\n\nIn practice, one can take the yields process with median term of maturity as the driving factor, as\n\nthis bond is highly correlated to both short-term and long-term bonds.\n\n6\n\n\fnegligible. As a result, we face the challenge of developing asymptotic theory for the\ndiffusion model (5). Both nonparametric estimators in the time domain and state\ndomain need to be investigated. Pioneering efforts on nonparametric estimation of\ndrift and diffusion include Jacod (1997), Jiang and Knight (1997), Arfi (1998), Gobet\n(2002), Bandi and Philips (2003), Cai and Hong (2003), Bandi and Moloche (2004),\nand Chen and Gao(2004). Arapis and Gao (2004) investigate the mean aggregated\nsquare errors of several methods for estimating the drift and diffusion, and compare\ntheir performances. A\u0131\u0308t-Sahalia and Mykland (2003, 2004) study the effects of random\nand discrete sampling when estimating continuous-time diffusions. Bandi and Nguyen\n(1999) investigate small sample behaviors of nonparametric diffusion parameters. See\nBandi and Phillips (2002) for a survey of recently introduced techniques for identifying nonstationary continuous-time processes. As long as the time horizon is long, the\ndiffusion matrix can be estimated with low frequency data (say, finite \u2206\u22121 ). See, for\nexample, Hansen et al. (1998) for the spectral method, Kessler and S\u00f8rensen (1999)\nfor parametric models, and Gobet et al. (2004) for specific univariate nonparametric\ndiffusions.\nTo facilitate our future presentation, we make the following assumptions:\nAssumption 1. (Global Lipschitz and linear growth conditions). There exists a\nconstant k0 \u2265 0 such that\nk\u03bc(x) \u2212 \u03bc(y)k + k\u03c3(x) \u2212 \u03c3(y)k \u2264 k0 |x \u2212 y|,\n\n(8)\n\nk\u03bc(x)k2 + k\u03c3(x)k2 \u2264 k02 (1 + x2 ),\nfor any x, y \u2208 R. Also, with b(*) = (b1 (*), b2 (*), * * * , bm (*))T , assume that\n|a(x) \u2212 a(y)| + kb(x) \u2212 b(y)k \u2264 k0 |x \u2212 y|.\nAssumption 2. Given any time point t > 0, there exists a constant L > 0 such that\nE|\u03bci (rs )|4(q0 +\u03b4) \u2264 L and E|\u03c3ij (rs )|4(q0 +\u03b4) \u2264 L for any s \u2208 [t \u2212 \u03b7, t] and 1 \u2264 i, j \u2264 d,\nwhere \u03b7 is some positive constant, q0 is an integer not less than 1, and \u03b4 is some small\npositive constant.\n\n7\n\n\fAssumption 3. The solution {ft } of model (6) is a stationary Markov process and\nreal ergodic. For t \u2265 0, define the transition operator by:\n(Ht g)(a) = E(g(ft )|f0 = a), a \u2208 R,\nwhere g(*) is any Borel measurable bounded function on R. Suppose Ht satisfy the G2\ncondition of Rosenblatt (1970), i.e., there is some s > 0 such that\n|Hs |2 =\n\nE 1/2 (Hs g)2 (X)\n\u2264 \u03b1 < 1.\nE 1/2 g2 (X)\nEg(X)=0}\nsup\n\n{g,\n\nAssumption 4. The conditional density pl (y|x) of fti+l given fti is continuous in the\narguments (y, x) and is bounded by a constant independent of l. The time-invariant\ndensity function p(x) of the process ft is bounded and continuous.\nAssumption 5. The kernel K(*) is a continuously differentiable, symmetric probability\ndensity function satisfying\nZ\n\n|xj K \u2032 (x)|dx < \u221e, j = 0, 1, * * * , 5,\n\n\u03bci =\n\nZ\n\nxi K(x)dx < \u221e, i = 0, 1, * * * , 4,\n\nand\n\u03bd0 =\n\nZ\n\n(9)\n\n(10)\n\nK 2 (x)dx < \u221e.\n\nLet {Ft } be the augmented filtration defined in Lemma 2 of Appendix. Assumption\n1 ensures that there exist continuous, adapted processes X = {X t , \u2208 Ft ; 0 \u2264 t < \u221e}\nand f = {ft \u2208 Ft ; 0 \u2264 t < \u221e}, which are strong solutions to SDEs (4) and (6)\nrespectively, provided that the initial values X 0 and f0 satisfy EkX 0 k2 < \u221e and\nE|f0 |2 < \u221e, and are independent of Brownian motion W (see, e.g., Chapter 5, Theorem\n\n2.9 of Karatzas and Shreve, 1991). Assumption 2 indicates that, given any time point\nt > 0, there is a time interval [t \u2212 \u03b7, t] on which the drift and volatility functions\nhave finite 4(q0 + \u03b4)-th moments. Assumption 3 says that ft is stationary and ergodic\nand satisfies some mixing condition (see Fan, 2005), which ensures that ft is Harris\nrecurrent. For the stationarity assumption of ft to be true, see Hansen and Scheinkman\n(1995) for conditions. Assumption 4 imposes some constraints on the transition density\n8\n\n\fof ft . Assumption 5 is a regularity condition on the kernel function. For example, the\ncommonly used Gaussian kernel satisfies it.\nWith the above theoretical framework and assumptions, we will formally demonstrate that the nonparametric estimators using the data localizing in time and in state\nare asymptotically jointly normal and independent. This gives a formal theoretical\njustification and serves as the theoretical foundation for the idea that the time-domain\nand state-domain nonparametric estimators can be combined to yield a more efficient\nvolatility matrix estimator.\n\n2\n\nDIFFUSION MATRIX ESTIMATION USING RECENT\nINFORMATION\n\nThe time-domain method has been extensively studied in the literature. See, for example, Robinson (1997), H\u00e4rdle et al. (2002), Fan, Jiang, Zhang and Zhou (2003), and\nMercurio and Spokoiny (2004), among others. A popular time-domain method, the\nmoving average estimator is defined as\nn\n\nX\nb M A,t = 1\nY t\u2212i Y Tt\u2212i ,\n\u03a3\nn\n\n(11)\n\ni=1\n\nwhere n is the size of the moving window. This estimator ignores the drift component\nand utilizes n local data points. An extension of the moving average estimator is the\nexponential smoothing estimator, which is defined as\nb ES,t = (1 \u2212 \u03bb)\n\u03a3\n\n\u221e\nX\n\n\u03bbi\u22121 Y t\u2212i Y Tt\u2212i ,\n\n(12)\n\ni=1\n\nwhere \u03bb is a smoothing parameter controlling the size of the local neighborhood. RiskMetrics of J.P. Morgan (1996), which is used for measuring the risks of financial assets,\nrecommends \u03bb = 0.94 and \u03bb = 0.97 when one uses (12) to forecast the daily and\nmonthly volatility, respectively.\nThe exponential smoothing estimator (12) is one type of rolling sample variance\nestimator. See Foster and Nelson (1996) for more information about rolling sample\nvariance estimators. Estimator (12) is also related to the multivariate GARCH model\nin the literature. Note that when \u2206 is very small, the first term on the right hand side\n\n9\n\n\fof (7) can be ignored. Thus (7) and (12) can be written as\nY i \u2248 \u03c3(fti )\u03b5i ,\n\u03a3ti = (1 \u2212 \u03bb)Y i\u22121 Y Ti\u22121 + \u03bb\u03a3ti\u22121 ,\nwhere \u03a3ti = \u03c3(fti )\u03c3(fti )T , which reminisces the IGARCH model.\nThe exponential smoothing estimator in (12) is a weighted sum of squared returns\nprior to time t. Since the weight decays exponentially, it essentially uses recent data.\nTo explicitly account for this, we use a slightly modified version:\nn\n1 \u2212 \u03bb X i\u22121\nb\n\u03bb Y t\u2212i Y Tt\u2212i .\n\u03a3T,t =\n1 \u2212 \u03bbn\n\n(13)\n\ni=1\n\nHere, as in the case of the moving average estimator in (11), n is a smoothing parameter\ncontrolling explicitly the window width, and \u03bb acts like a kernel weight which may\n\u03c4\nn\n\ndepend on n. For example, when \u03bb = 1 \u2212\nnormalization factor\n\n1\u2212\u03bb\n1\u2212\u03bbn ,\n\nwith \u03c4 a positive constant, besides the\n\nthe first data point Yt\u22121 receives weight 1, while the last\n\npoint Yt\u2212n receives approximately weight e\u2212\u03c4 . In particular, when \u03bb = 1, it becomes\nthe moving average estimator (11).\nBefore going into the details, we first introduce some notations and definitions. Let\nA = (aij ) be an m \u00d7 n matrix. By vec(A) we mean the mn \u00d7 1 vector formed by\nstacking the columns of A. If A is also symmetric, we vectorize the lower half of A and\ndenote the vector by vech(A). These notations are consistent with Bandi and Moloche\n(2004). It is not difficult to verify that there exists a unique m2 \u00d7 m(m + 1)/2 matrix\nD with elements 0 and 1, such that\nPD vec(A) = vech(A),\nwhere PD = (D T D)\u22121 D T . Another useful definition is the Kronecker product of two\nmatrices A and B, which is defined as A \u2297 B = (aij B).\n\nb T,t is symmetric, we only need to consider the asymptotic\nSince the estimator \u03a3\n\nb T,t ):\nnormality of the linear combination of the vector vech(\u03a3\n\nd X\nk\nn\nX\nX\ni\u22121\nk\nl\nb T,t = 1 \u2212 \u03bb\nbT,t \u2261 cT vech\u03a3\n\u03bb\nckl Yt\u2212i\nYt\u2212i\n,\nU\n1 \u2212 \u03bbn\ni=1\n\nk=1 l=1\n\nwhere c = (c1,1 , c2,1 , c2,2 , c3,1 , * * * , cd,d )T is a constant vector.\n10\n\n(14)\n\n\fProposition 1 Under Assumptions 1 and 2, for almost every sample path, we have\nk\u03c3(rs ) \u2212 \u03c3(ru )k \u2264 K|s \u2212 u|q ,\n\ns, u \u2208 [t \u2212 \u03b7, t],\n\n(15)\n\nwhere q = (2q0 \u2212 1)/(4q0 ), q0 is the integer in Assumption 2, and the coefficient K\nsatisfies E[K 4(q0 +\u03b4) ] < \u221e with \u03b4 a positive constant.\n\nRemark 1. Proposition 1 shows the continuity of \u03c3(rs ) as a function of time s, which\nis the foundation of time-domain estimation. In the proof of Proposition 1, we only\nused Assumption 2 and the condition k\u03c3(x) \u2212 \u03c3(y)k \u2264 k0 |x \u2212 y| with k0 a positive\nconstant. Assumption 1 is made to ensure the existence of a solution to model (5).\nTheorem 1 Suppose that n \u2192 \u221e, n\u22062q/(2q+1) \u2192 0, and Assumptions 1 and 2 hold\nat time t. If the limit \u03c4 = lim n(1 \u2212 \u03bb) exists, then given ft = x, the conditional\nn\u2192\u221e\n\nb T,t ) is asymptotically normal, i.e.,\ndistribution of vech(\u03a3\n\u0012\n\u0013\n\u221a\n\u03c4 (1 + e\u03c4 )\nD\nb T,t \u2212 \u03a3(x)) \u2212\u2192\nn vech(\u03a3\nN 0, \u03c4\n\u039b(x) ,\n(e \u2212 1)\nwhere \u039b(x) = PDT {\u03a3(x) \u2297 \u03a3(x)}PD .\n\nNote that all data used in the estimator (13) is within n\u2206 away from time t. According to Proposition 1, the approximation error of (13) is at most of order O((n\u2206)q ),\nwhich together with the condition n\u22062q/(2q+1) \u2192 0 in Theorem 1 guarantees that the\n\nbias is of order o(n\u22121/2 ).\n\n3\n\nDIFFUSION MATRIX ESTIMATION USING HISTORICAL INFORMATION\n\nThe diffusion matrix in (4) can also be regarded as a nonparametric regression given\nft = x. See for example its first order approximation (7). Therefore, it can be estimated\nby using the historical information via localizing on the state variable ft , as illustrated\nin Figure 1. The local linear smoother studied in Stanton (1997) will be employed. This\ntechnique has several nice properties, such as asymptotic minimax efficiency and design\n\n11\n\n\fadaptation. Further, it automatically corrects edge effects and facilitates bandwidth\nselection (Fan and Yao, 2003).\nIn the construction of the state-domain estimator, we will use the N \u2212 1 data points\nright before the current time t, i.e., the historical data {(fti , Y i ), i = 0, 1, * * * , N \u22121}.\nIt can be shown that the diffusion matrix has the standard interpretation in terms\nof infinitesimal conditional moments, that is,\nE[Yki Ykj |ftk = x0 ] = vij (x0 ) + O(\u2206).\nFor a given kernel function5 K and a bandwidth h, the local linear estimator \u03b2\u03020ij of\nvij (x0 ) is obtained by minimizing the objective function\nN\n\u22121\nX\nk=0\n\n{Yki Ykj + \u03b20ij + (ftk \u2212 x0 )\u03b21ij }Kh (ftk \u2212 x0 )\n\n(16)\n\nover \u03b20ij and \u03b21ij . Let\nWl (x) =\n\nN\n\u22121\nX\nk=0\n\n(ftk \u2212 x)l Kh (ftk \u2212 x)\n\n(17)\n\nand\nwk (x) = Kh (ftk \u2212 x){W2 (x) \u2212 (ftk \u2212 x)W1 (x)}/{W0 (x)W2 (x) \u2212 W1 (x)2 }.\n\n(18)\n\nThen the local linear estimator in (16) can be expressed as\nb S,t (x) =\n\u03a3\n\nN\n\u22121\nX\n\nwk (x)Y k Y Tk .\n\n(19)\n\nk=0\n\nThis estimator depends only on the historical data (horizontal bar in Figure 1), and\nrelies on the structure invariability.\nThe above weight function wk (x) is called an \"equivalent kernel\" in Fan and Yao\nb S,t (x) is very much like a conven(2003). Expression (19) reveals that the estimator \u03a3\n\ntional kernel estimator except that the \"kernel\" wk (x) depends on the design points\nand locations.\nb S,t (x), we first investigate the\nBefore establishing the asymptotic normality of \u03a3\n\nasymptotic property of Wl (x).\n5\n\nThe kernel function is a probability density, and the bandwidth is its associated scale parameter.\n\nBoth of them are used to localize the linear regression around the given point x0 . The commonly used\nkernel functions are the Gaussian density and the Epanechnikov kernel K(x) = 0.75(1 \u2212 x2 )+ .\n\n12\n\n\fProposition 2 Suppose \u2206 \u2192 0, N \u2206 \u2192 \u221e, and\nsumptions 3\u20135, we have\n\n1\nh\n\np\n\n\u2206 log \u2206\u22121 = o(1). Under As-\n\nWl (x) = N hl {p(x)\u03bcl + oa.s. (1)}, l = 0, 1, 2, 3.\n\n(20)\n\nThe results of Proposition 2 are similar to those in Section 6.3.3 of Fan and Yao\n(2003, p.237), but the proofs are completely different, as we have a highly correlated\nsample {fti } here. The high correlation makes their proof fail in our case. To attack\nthis problem, we invoke the local time. The definition and some preliminary results of\nlocal time can be found in Revuz and Yor (1999, p.221). For the multifactor situation,\nthe local time generally does not exist. However, by using the occupation time of Bandi\nand Moloche (2004), our results can be generalized to the multifactor situation.\nTheorem 2 Suppose \u2206 \u2192 0, N \u2206 \u2192 \u221e, h = O(N \u22121/5 ), and\n\n1\nh\n\np\n\n\u2206 log \u2206\u22121 = o(1).\n\nMoreover, suppose that \u03a3(*) is twice differentiable. Under Assumptions6 3\u20135, the statedomain estimator has the following asymptotic normality\n\u221a\n\u0001 D\nb S,t (x) \u2212 \u03a3(x) \u2212 1 h2 \u03bc2 \u03a3\u2032\u2032 (x) \u2212\u2192\nN (0, 2\u03bd0 p(x)\u22121 \u039b(x)),\nN h vech \u03a3\n2\n\nwhere \u03a3\u2032\u2032 (x) is the matrix whose entries are the second derivatives of the corresponding\nentries of \u03a3(x).\nProposition 2 and Theorem 2 are both studied under the assumption of high frequency data over a long time horizon, i.e., \u2206 \u2192 0 and N \u2206 \u2192 \u221e. Various studies\nunder this assumption include Arfi (1998), Gobet (2002), and Fan and Zhang (2003).\n\n4\n\nDYNAMIC AGGREGATION OF TIME- AND STATEDOMAIN ESTIMATORS\n\nIn this section, we show that the nonparametric estimators in the time and state domains are asymptotically independent. This allows us to combine these two estimators\ntogether to yield a more efficient one.\n6\n\nThe stationarity condition of ft in Assumption 3 can be weakened to Harris recurrence. See Bandi\n\nand Moloche (2004) for asymptotic normality of local constant estimator under recurrence assumption.\n\n13\n\n\f4.1\n\nAsymptotic Normality\n\nThe time- and state-domain estimators defined in the previous sections are both driven\nby the factor process ft . Intuitively, with high probability, most of the data they use are\nfar apart in time. Since the Markov process ft is stationary and satisfies some mixing\ncondition (Assumption 3), it is reasonable to expect that the time- and state-domain\nnonparametric estimators are also asymptotically independent. The following theorem\nformally shows this result.\nTheorem 3 Under the conditions of Theorems 1 and 2, conditioning on ft = x, we\nhave\n(i) asymptotic independence:\n\u0010\n\uf8eb \u221a\n\u0011 \uf8f6\nb S,t \u2212 \u03a3(x) \u2212 1 h2 \u03bc2 \u03a3\u2032\u2032 (x)\nN h vech \u03a3\n2\n\uf8f8\n\uf8ed\n\u0010\n\u0011\n\u221a\nb\nn vech \u03a3T,t \u2212 \u03a3(x)\n\uf8eb \uf8eb\n2\u03bd0 p(x)\u22121 \u039b(x)\nD\n\u2212\u2192 N \uf8ed0, \uf8ed\n0\n\n0\n\u03c4 (1+e\u03c4 )\n(e\u03c4 \u22121) \u039b(x)\n\n\uf8f6\uf8f6\n\n\uf8f8\uf8f8 .\n\nb A,t (x) in (1):\n(ii) asymptotic normality of the aggregrated estimator \u03a3\n\u0011\n\u0010\n\u221a\nD\nb A,t (x) \u2212 \u03a3(x) \u2212 1 h2 \u03c9t (x)\u03bc2 \u03a3\u2032\u2032 (x) \u2212\u2192\nN (0, \u03a9(x)),\nN h vech \u03a3\n2\n\u03c4)\u0001\nwhere \u03a9(x) = 2\u03c9t2 (x)\u03bd0 p(x)\u22121 +b(1\u2212\u03c9t (x))2 \u03c4(e(1+e\n\u03c4 \u22121) \u039b(x), provided that lim N h/n = b\nfor some positive constant b and h = O(N \u22121/5 ).\n\nNote that the nonparametric estimator in the time domain uses n data points and\nthe nonparametric estimator in the state domain effectively uses the amount O(N h)\nof data. The condition lim N h/n = b ensures that both estimators effectively use the\nsame amount (order) of data, which avoids the trivial case that either the time domain\nor the state domain dominates the performance.\n\n4.2\n\nChoice of the Dynamic Weight\n\nA natural question is how to choose the dynamic wight \u03c9t (x). By Theorem 3(i) and\n(3), it is easy to see that for any allocation vector a, the asymptotic optimal weight is\n\u03c9t (x) =\n\n2\u03bd0\n\n(e\u03c4\n\nb\u03c4 (1 + e\u03c4 )p(x)\n,\n\u2212 1) + b\u03c4 (1 + e\u03c4 )p(x)\n14\n\n(21)\n\n\fwhich is independent of a. This choice7 also optimizes the performance of the agb A,t (x). Indeed, by Theorem 3(ii), the asymptotic cogregated covariance estimator \u03a3\n\nb A,t (x) is given by \u03a9(x). It depends on the weight through the\nvariance matrix of \u03a3\n\ncoefficient\n\n\u03c8t (x) \u2261 2\u03c9t2 (x)\u03bd0 p(x)\u22121 + b(1 \u2212 \u03c9t (x))2\n\n\u03c4 (1 + e\u03c4 )\n,\n(e\u03c4 \u2212 1)\n\nwhich is a quadratic function, and attains its minimum at (21).\nWhen 0 < b < \u221e, the effective sample sizes in the time and state domains are comparable. Hence, neither the time-domain nor the-state domain estimator dominates.\nTherefore, by aggregating the time- and state-domain estimators, we obtain an optimal\nreduction of asymptotic variance. The biases of the aggregated estimator are indirectly\ncontrolled, when the optimal smoothing is conducted for both time- and state-domain\nestimators so that their biases and variances are already traded off before aggregation.\nNote that at time t, the optimal weight \u03c9t (x) depends on the current value of\nthe factor process f through the density function p(x). This is consistent with our\ncommon sense. When f is low or high, p(x) and consequently, the optimal weight are\napproximately zero. In this case, the main contribution to the aggregated estimator\ncomes from the time-domain estimator. When f is well in middle of its state space, say\nnear its unconditional mathematical expectation, the state-domain estimator tends to\ndominate the aggregated estimator.\nIn practice, the density function p(x) is unknown and should be estimated. There\nare lots of existing methods to do this, such as the kernel density estimator and the local\ntime density estimator (see A\u0131\u0308t-Sahalia, 1996; and Dalalyan and Kutoyants, 2003).\n\n5\n\nNUMERICAL ANALYSIS\n\nTo evaluate the aggregated estimator, we compare it with the time-domain estimator\nand the state-domain estimator. For the time-domain estimation, we apply the expo7\n\nThe optimal choice of weight is proportional to the effective number of data points used for the\n\nstate-domain and time-domain smoothing. It always outperforms the choice with \u03c9t = 1 (state-domain\nestimator) or \u03c9t = 0 (time-domain estimator).\n\n15\n\n\fnential smoothing8 with \u03bb = 0.94. For the state-domain estimation, we choose one\nyield process as the \"factor,\" and then use it to estimate the volatility matrix. The\nEpanechnikov kernel is used with the bandwidth h chosen by generalized cross validation method (see Fan and Yao, 2003). To choose the optimal weight \u03c9t (x), we estimate\nthe density function p(x) by the kernel density estimator (see A\u0131\u0308t-Sahalia, 1996).\nThe following three measures are employed to assess the performance of different\nmethods for estimating the diffusion matrix. The first two can only be used in simulation, and the last one can be used in both simulation and real data analysis.\nMeasure 1. The entropy loss is given by\nb t ) = tr(\u03a3\u22121 \u03a3\nb t ) \u2212 log |\u03a3\u22121 \u03a3\nb t | \u2212 dim(\u03a3t ).\nl1 (\u03a3t , \u03a3\nt\nt\nMeasure 2. The quadratic loss is defined as\n\u0001\nb t ) = tr \u03a3\nb t \u2212 \u03a3t 2 .\nl2 (\u03a3t , \u03a3\nMeasure 3. The prediction error (PE) is computed as\nT +m\n\u0001\n1 X\nbt 2\nb\ntr Y i Y Ti \u2212 \u03a3\nPE(\u03a3t ) =\ni\nm\n\n(22)\n\ni=T +1\n\nfor an out-sample of size m. The expected value can be decomposed as\nb t )] =\nE[PE(\u03a3\n\nT +m\nT +m\n\u00012\n\u0001\n1 X\n1 X\nb t 2 ].\nE[tr Y i Y Ti \u2212 \u03a3ti ] +\nE[tr \u03a3ti \u2212 \u03a3\ni\nm\nm\ni=T +1\n\ni=T +1\n\nNote that the second item reflects the effectiveness of the estimated diffusion matrix,\nwhile the first term is the size of the stochastic error, independent of the estimators.\nThe first term is usually an order of magnitude larger than the second term. Thus,\na small improvement in PE means a substantial improvement in estimated volatility.\nThis will also be clearly demonstrated in our simulation study (see Figure 4).\nMeasure 4. Adaptive prediction error (APE).\n8\n\nThe choice comes from the recommendation of the RiskMetrics of J.P. Morgan. The parameter \u03bb\n\ncan also be chosen automatically by data by using the prediction error as in Fan, Jiang, Zhang and\nZhou (2003). Since we compare the relative performance between the time-domain estimator and the\naggregated estimator, we opt for this simple choice. The results do not expect to change much when\na data-driven technique is used.\n\n16\n\n\fAs seen above, the dominant part of the PE is the stochastic error; however, what\nwe really care about is the estimation error. To reduce the stochastic error in (22), we\ndefine the following adaptive prediction error:\nb t) =\nAPE(\u03a3\n\nT +m\ni+k\nX\n\u0001\n1\n1 X\nb t 2,\ntr\nY j Y Tj \u2212 \u03a3\ni\nm\n2k + 1\ni=T +1\n\n(23)\n\nj=i\u2212k\n\nwhere k is a nonnegative integer. The basic idea is to average out the stochastic errors\nfirst before computing square losses, but this creates bias when k is large. When k = 0,\nthe APE reduces to the PE defined in (22).\n\n5.1\n\nSimulation\n\nWe use an essentially affine market price of risk specifications in Duffee (2002) to simulate bond yields, and hence to obtain simulated multivariate time series. Essentially\naffine model is the multivariate extension of the square-root process. It has been proved\nuseful in forecasting future yields (see Duffee, 2002). Cheridito, Filipovi\u0107 and Kimmel\n(2005) investigate the essentially affine model with one, two, and three state variables,\nand give estimates of the parameters. We use their one state variable model to conduct\nthe simulations.\nThe one state variable affine term structure model assumes that the instantaneous\nnominal interest rate rt is given by\nrt = d0 + d1 st ,\nwhere d0 and d1 are scalars, and st is a scalar state variable. The evolution of the state\nvariable st under the the risk-neutral measure Q is assumed to be\n\u221a\nQ\nQ \u0001\ndst = aQ\n1 + b11 st dt + st dWt .\n\n(24)\n\nThis is the well-known Cox-Ingersoll-Ross (CIR) model.\nLet P (t, \u03c4 ) be the time-t price of a zero-coupon bond maturing at t + \u03c4 . Under the\naffine term structure and the assumption of no arbitrage, Duffie and Kan (1996) show\nthat the bond price admits the form\nZ\nP (t, \u03c4 ) = EtQ exp(\u2212\n\nt+\u03c4\nt\n\nru du) = exp[A(\u03c4 ) \u2212 B(\u03c4 )st ],\n17\n\n(25)\n\n\fwhere A(\u03c4 ) and B(\u03c4 ) are both scalar functions satisfying the following ordinary differential equations (ODEs)\ndB(\u03c4 )\n1 2\ndA(\u03c4 )\n= \u2212aQ\n= bQ\n1 B(\u03c4 ) \u2212 d0 and\n11 B(\u03c4 ) \u2212 B (\u03c4 ) + d1 .\nd\u03c4\nd\u03c4\n2\n\n(26)\n\nThus, the bond's yield\n1\n1\ny(st , \u03c4 ) = \u2212 log P (t, \u03c4 ) = [\u2212A(\u03c4 ) + B(\u03c4 )st ]\n\u03c4\n\u03c4\n\n(27)\n\nis affine in the state variable st .\nWe use the above model to simulate 5 zero-coupon bond yield processes with maturities 1 month, 2 years, 4 years, 6 years, and 8 years. Since there is only one state\nvariable st , the bond yields of different maturities are perfectly linearly related, as\nshown in (27), which is an unrealistic artifact of the model. To attenuate this dilemma,\nCherito et al. (2005) assume that only the 1-month yield process is observed without error, while other yields are contaminated with i.i.d. multivariate Gaussian errors\nwith mean zero and unknown covariance matrix. They estimate the unknown parameters from the yields of zero-coupon bonds extracted from the US Treasury security\nprices from January 1972 to December 2002. The estimated parameters are aQ\n1 = 0.5,\nbQ\n11 = \u22120.0137, d0 = 0.0110, and d1 = 0.0074. The standard deviations of the Gaussian errors are estimated as \u03c31 = 0.0119, \u03c32 = 0.0144, \u03c33 = 0.0155, and \u03c34 = 0.0159\nfor the yields of 2-, 4-, 6-, and 8-year bonds, respectively. The associated correlation\ncoefficients are estimated as \u03c112 = 0.9727, \u03c113 = 0.9511, \u03c114 = 0.9371, \u03c123 = 0.9950,\n\u03c124 = 0.9877, and \u03c134 = 0.9978.\nFigure 2 here.\nIn the simulation, we set the the parameter values to be the above estimated values\nfrom Cherito et al. (2005). We first generate discrete samples of the state variable st\nfrom diffusion process (24). Then we solve ODEs in (26) numerically. Figure 2 shows\nthe solution to (26). After that, we obtain the ideal yield processes by using (27) with\nmaturities 1 month, 2 years, 4 years, 6 years, and 8 years. Finally, we add the i.i.d.\n4-variate normal errors to the last 4 ideal yield processes to obtain the observed bond\nprocesses with these maturities9 .\n9\n\nHere we add normal noise to make the model more realistic. Our method performs even better\n\n18\n\n\fTo generate the sample path of st , we use the transition density property of the\nprocess. That is, given st = x, the variable 2cst+\u2206 has a noncentral chi-squared\nQ\n\nb11 \u2206 , where\ndistribution with degrees of freedom 4aQ\n11 and noncentrality parameter 2cxe\n\nc=\n\n2bQ\n11\n.\nexp(bQ\n11 \u2206)\u22121\n\nThe initial value of s0 is generated from the invariant distribution of\n\nst , which is gamma distribution with density p(y) =\n\n\u03c9 \u03bd \u03bd\u22121 \u2212\u03c9y\ne\n,\n\u0393(\u03bd) y\n\nwhere \u03bd = 2aQ\n11 and\n\n\u03c9 = \u22122bQ\n11 .\nWe simulate 500 series of 1200 observations of weekly data with \u2206 = 1/52 for the\nyields of five zero-coupon bonds with maturities 1 month, 2 years, 4 years, 6 years,\nand 8 years, respectively. For each simulated series, we set the last 150 observations as\nthe out-sample data. For time t out-sample data point, the time-domain estimator is\nbased on the past n = 104 (two years)10 observations, i.e., observations from t \u2212 104 to\nt \u2212 1; and the state-domain estimator is based on the 1050 data points right before the\ncurrent time, i.e., the data points from time t \u2212 1050 to t \u2212 1. The first yields process\n(1-month) is used as the factor for state-domain estimation.\nAs pointed out in Section 1, the conditional covariance matrix of the multivariate\ndiffusion can be approximated by the diffusion matrix times the sampling interval \u2206.\nHence, we first obtain estimates of the diffusion matrix, and then convert them into\nthe conditional covariance matrix estimates. The theoretical value of the conditional\nvariance of st is given by Duffee (2002). Since the bond yields are linear regression\nmodels of the state variable (see (27) with Gaussian errors), the true (theoretical)\nvalue of the conditional covariance matrix of the bond yields can be easily obtained.\nBy comparing the estimated conditional covariance matrix to its theoretical value, the\nperformance of our estimation procedures is evaluated.\nFigure 3 here.\nFigure 3 depicts the averages and standard deviations of the entropy and quadratic\nlosses of time-domain, state-domain, and aggregated estimators. It shows unambiguwithout noise. Since the noise vectors are i.i.d. across time and the standard deviations are small,\nadding them to the original time series does not change the whole structure. Hence, our theory can\ncarry through under contamination.\n10\nWith \u03bb = 0.94, the last data point used in the time domain has an extra weight 0.94104 \u2248 0.0016,\nwhich is very small. Hence, we essentially include all the effective data points.\n\n19\n\n\fously that the aggregated method always has the smallest averages and standard deviations across 500 simulations for both the entropy loss and quadratic loss. Figures\n4(a) and 4(b) summarize the distributions of the average losses over 150 out-samples\nforecasting across the 500 simulations. The results are consistent with those in Figure\n3. On the other hand, if the PE in (22) with m = 150 is used, the distributions look\nquite different, which is demonstrated in Figure 4(c). It shows clearly that even though\nthere are huge efficiency improvements in estimating the volatility matrix by using the\naggregated method, the improvements are masked by stochastic errors which are an\norder of magnitude larger than the estimation errors. The average prediction errors\nover 500 simulations are 1.850 \u00d7 10\u22122 , 1.825 \u00d7 10\u22122 , and 1.846 \u00d7 10\u22122 for the timedomain, the aggregated, and the state-domain estimators, respectively. This demonstrates that a small improvement in PE means a huge improvement in the estimation of\nthe volatility matrix. This effect is more illuminatingly illustrated in Figure 4(d) where\neach point represents a simulation. The x-axis represents the ratios of the averages of\n150 quadratic losses for the time-domain estimator and the state-domain estimator to\nthose for the aggregated estimator, whereas the y-axis is the ratios of the PEs for the\ntime-domain estimator and the state-domain estimator to those for the aggregated estimator. The x-coordinates are mostly greater than 1, showing the improved efficiency\nof the aggregated estimation. On the other hand, the improved efficiency is masked by\nstochastic errors, resulting in the y-coordinate spreading around the line y = 1.\nFigure 4 here.\nWe have proved theoretically that nonparametric estimators based on time-domain\nsmoothing and state-domain smoothing are asymptotically independent. To verify\nthis, we compute their correlation coefficients. Since both estimators are matrices, for\na given portfolio allocation vector a, we compute the correlation of the two estimators\nb T,t a and aT \u03a3\nb S,t a across 500 simulations at each given time t in the out-sample.\naT \u03a3\n\nFigure 5 presents the correlation coefficients for a = (0.2, 0.2, 0.2, 0.2, 0.2)T . Most of\nthe correlations are below 0.1, which strongly supports our theoretical result. We also\ninclude the 95% confidence intervals based on the Fisher transformation in the same\ngraph (the two dashed curves). A large amount of these confidence intervals contain\n\n20\n\n\f0. The two straight lines in the plot indicate the acceptance region for testing the\nnull hypothesis that the correlation coefficients are zero at the significance level 5%.\nMost of these null hypotheses are accepted or nearly accepted. In fact, we conducted\nexperiments on the same simulations with larger sample sizes, and found that as the\nsample size increases, the absolute values of the correlation coefficients decrease to 0.\nFigure 5 here.\n\n5.2\n\nEmpirical Studies\n\nIn this section, we apply the aggregated method to two sets of financial data. Our aim is\nto examine whether our approach still outperforms the time-domain and state-domain\nnonparametric estimators in real applications.\n5.2.1\n\nTreasury Bonds\n\nWe consider the weekly returns of five treasury bonds with maturities 3 months, 2 years,\n5 years, 7 years, 10 years, and 30 years. We set the last 150 observations, which run\nfrom April 9, 1999 to February 15, 2002, as the out-sample data. For each observation\nfrom the out-sample data, we use the past 104 observations (2 years) with \u03bb = 0.94\nto obtain the time-domain estimator, and the state-domain estimate is based on the\npast 900 data points. The prediction error (Measure 3) and adaptive prediction error\n(Measure 4) are used to assess the performance of the three estimators: the time-domain\nestimator, the state-domain estimator, and the aggregated estimator. The results are\nreported in Table 1. From the table, we see that the aggregated estimator outperforms\nsignificantly the other two estimators.\nFor comparison, the results from the simulated data are also reported. Even through\nthere is only a small improvement in PE for simulated data, as evidenced in Section\n4.1, there is a huge improvement in the precision of estimating \u03a3t in terms of entropy\nloss (measure 1) and quadratic loss (measure 2). Hence, with the improvement of the\nPE in the bond price by the aggregrated method, we would expect to have a huge\nimprovement on the precision of the estimation of covariance, which is of primary\ninterest in financial engineering.\n\n21\n\n\f5.2.2\n\nExchange Rate\n\nWe analyze the weekly exchange rates of five foreign currencies with US dollars from\nSeptember 6, 1985 to August 19, 2005. The five foreign currencies are the Canadian\nDollar, Australian Dollar, Europe Euro11 , UK British Pound, and Switzerland Franc.\nThe length of the time series is 1042. The exchange rates from December 6, 2002 to\nAugust 19, 2005, which are of length 142, are regarded as out-sample data, and the\nestimation procedures are the same as before, i.e., for each out-sample observation, the\nlast 104 data points with \u03bb = 0.94 are set to construct the time-domain estimator, the\n900 data points before the current time are used to construct state-domain estimator,\nand then roll over. The results, based on the PE and APE defined in Section 4, are\nalso summarized in Table 1. They demonstrate clearly that the aggregated estimator\noutperforms the time-domain and state-domain estimators.\nUsing again the simulated data for calibration, as argued at the end of Section 4.2.1,\nwe would reasonably expect that the covariance matrix estimated by the aggregated\nmethod outperforms significantly both the matrices estimated by either the time- or\nstate-domain method alone.\nTable 1 here.\n\n6\n\nDISCUSSIONS\n\nWe have proposed an aggregated method to combine the information from the time\ndomain and state domain in multivariate volatility estimation. To overcome the curse\nof dimensionality, we proposed a \"factor\" modeling strategy. The performance comparisons are studied both theoretically and empirically. We have shown that the proposed\naggregated method is more efficient than the estimators based only on recent history\nor remote history. Our simulation and empirical studies have also revealed that proper\nuse of information from both the time domain and the state domain makes volatility\n11\n\nEurope used several common currencies prior to the introduction of the Euro. The European\n\nCurrency Unit (ECU) was used from January 1, 1979 to January 1, 1999, when the Euro replaced the\nEuropean Currency Unit at par.\n\n22\n\n\fmatrix estimate more accurate. Our method exploits the continuity in the time domain\nand stationarity in the state domain. It can also be applied to situations where these\ntwo conditions hold approximately.\nOur study has also revealed another potentially important application of our method.\nIt allows us to test the stationarity of diffusion processes. When time-domain estimates\ndiffer substantially from those of the state domain, it is an indication that the processes\nis not stationary. Since the time-domain and state-domain nonparametric estimators\nare asymptotically independent and normal, formal tests can be formed. Further study\non this topic is beyond the scope of this paper.\n\nAPPENDIX: PROOFS\nA.1\n\nProof of Proposition 1\n\nIn all the proofs below, we use M to denote a generic constant.\nFirst, we show that the process {ft } is locally H\u00f6lder continuous with order q =\n4(q0 +\u03b4)\n\n(2q0 \u2212 1)/(4q0 ) and coefficient K1 satisfying E[K1\n|fs \u2212 fu | \u2264 K1 |s \u2212 u|q ,\nwhere \u03b7 is a positive constant. Note that\nZ u\n4(q0 +\u03b4)\nE|fu \u2212 fs |\n\u2264 ME\na(fv )dv\n\n4(q0 +\u03b4)\n\ns\n\n] < \u221e, i.e.\n\ns, u \u2208 [t \u2212 \u03b7, t],\n\n+ ME\n\nZ\n\ns\n\nuX\n\n(A.1)\n\nbj (fv )dWvj\n\n4(q0 +\u03b4)\n\nj\n\n\u2261 (I) + (II).\n\n(A.2)\n\nThen by Jensen's inequality and Assumption 2, we have\nZ u\n(I) \u2264 M (u \u2212 s)4(q0 +\u03b4)\u22121\nE|a(fv )|4(q0 +\u03b4) dv \u2264 M (u \u2212 s)4(q0 +\u03b4) .\n\n(A.3)\n\ns\n\nOn the other hand, applying martingale moment inequalities (see, e.g. Karatzas and\nShreve (1991), Section 3.3.D, p.163), Jensen's inequality, and Assumption 2 gives\nZ uX\nZ uX\n\u00012(q0 +\u03b4)\n2\n2(q0 +\u03b4)\u22121\nE|bj (fv )|4(q0 +\u03b4) dv\nbj (fv )dv\n\u2264 M (u \u2212 s)\n(II) \u2264M E\ns\n\ns\n\nj\n\nj\n\n(A.4)\n\u2264M (u \u2212 s)2(q0 +\u03b4) .\n23\n\n\fCombining (A.2), (A.3) and (A.4) together leads to\nE|fu \u2212 fs |4(q0 +\u03b4) \u2264 M (u \u2212 s)2(q0 +\u03b4) .\nThus by Theorem 2.1 of Revuz and Yor (1999, Page 26), we have\nE\n\n\u0002\n\n\u00014(q0 +\u03b4) \u0003\nsup{|fs \u2212 fu |/|s \u2212 u|\u03b1 }\n<\u221e\n\n0 +\u03b4)\u22121\nfor any \u03b1 \u2208 [0, 2(q\n4(q0 +\u03b4) ). Let \u03b1 =\n\n4(q0 +\u03b4)\n\nThen E[K1\n\n(A.5)\n\ns6=u\n\n2q0 \u22121\n4q0\n\nand K1 = sups6=u {|fs \u2212 fu |/|s \u2212 u|\n\n2q0 \u22121\n4q0\n\n}.\n\n< \u221e], and inequality (A.1) holds.\n\nSecond, by (8) we have\nk\u03c3(fs ) \u2212 \u03c3(fu )k \u2264 k0 |fs \u2212 fu |.\nThis together with (A.1) shows that\nk\u03c3(fs ) \u2212 \u03c3(fu )k \u2264 k0 K1 |s \u2212 u|q \u2261 K|s \u2212 u|q .\n4(q0 +\u03b4)\n\nHence, E[K 4(q0 +\u03b4) ] \u2264 M E[K1\n\nA.2\n\n] < \u221e. \u0004\n\nProof of Theorem 1\n\nk,l\nProof. At time s, for fixed k, l, and i, define Zi,s\n= (Xsk \u2212 Xtki )(Xsl \u2212 Xtli ). Applying\n\nk,l\nIto's formula to Zi,s\nresults in\n\nk,l\ndZi,s\n=(Xsk \u2212 Xtki )dXsl + (Xsl \u2212 Xtli )dXsk +\n\nm\nX\n\n\u03c3kj (fs )\u03c3lj (fs )ds\n\nj=1\n\ni\nh\n= (Xsk \u2212 Xtki )\u03bcl (fs ) + (Xsl \u2212 Xtli )\u03bck (fs ) ds\nZ s\nZ s\n+[\neTk \u03bc(fu )dueTl \u03c3(fs ) +\neTl \u03bc(fu )dueTk \u03c3(fs )]dWs\nt\nti\nZ is\nZ s\nT\nT\n+[\nek \u03c3(fu )dWu el \u03c3(fs ) +\neTl \u03c3(fu )dWu eTk \u03c3(fs )]dWs\nti\n\n+\n\nm\nX\n\nti\n\n\u03c3kj (fs )\u03c3lj (fs )ds.\n\nj=1\n\nHence, Yik Yil can be decomposed as\nk,l\nk,l\nk,l\nYik Yil = \u2206\u22121 Zi,t\n\u2261 ak,l\ni + bi + v\u0304i ,\ni+1\n\n24\n\n\fwhere\nak,l\ni\n\n=\u2206\n\n\u22121\n\nZ\n\n+\u2206\n\nbk,l\ni\n\n=\u2206\n\n\u22121\n\nti+1\nti\n\n\u22121\n\nZ\n\nZ\n\n[(Xsk \u2212 Xtki )\u03bcl (fs ) + (Xsl \u2212 Xtli )\u03bck (fs )]ds\n\nti+1\nti\n\nti+1\nti\n\nZ\n\ns\nti\n\nZ\n\ns\nti\n\n[eTk \u03bc(fu )dueTl \u03c3(fs ) + eTl \u03bc(fu )dueTk \u03c3(fs )]dWs ,\n\n[eTk \u03c3(fu )dWu eTl \u03c3(fs ) + eTl \u03c3(fu )dWu eTk \u03c3(fs )]dWs\n\nand\n\u22121\nck,l\ni =\u2206\n\nZ\n\nm\nti+1 X\n\nti\n\n\u03c3kj (fs )\u03c3lj (fs )ds.\n\nj=1\n\nCorrespondingly, (14) has the following decomposition\nn\nn\nX\nX\n1 \u2212 \u03bb X i\u22121 X\nk,l\ni\u22121\nbT,t = 1 \u2212 \u03bb\nU\nc\na\n+\nckl bk,l\n\u03bb\n\u03bb\nkl N \u2212i\nN \u2212i\n1 \u2212 \u03bbn\n1 \u2212 \u03bbn\ni=1\n\n+\n\n1\u2212\u03bb\n1 \u2212 \u03bbn\n\ni=1\n\nl\u2264k\n\nn\nX\n\n\u03bbi\u22121\n\ni=1\n\nk\nX\n\nl\u2264k\n\nk,l\nckl v\u0304N\n\u2212i\n\nl\u2264k\n\n\u2261 An,\u2206 + Bn,\u2206 + Vn,\u2206 .\n\n(A.6)\n\nTherefore, Slutsky's lemma, together with Lemmas 1\u20133 below, leads to the conclusions\nof Theorem 1 immediately. \u0004\nLemma 1 Under Assumption 1, as n \u2192 \u221e, n\u2206 \u2192 0, and n(1 \u2212 \u03bb) \u2192 \u03c4 , we have\nEA2n,\u2206 = O(\u2206),\nwhere An,\u2206 =\n\n1\u2212\u03bb\n1\u2212\u03bbn\n\nPn\n\ni=1 \u03bb\n\ni\u22121\n\nP\n\nk,l\nl\u2264k ckl aN \u2212i ,\n\n(A.7)\n\nas defined in (A.6).\n\nProof. First, note that\n2\n\u22121\nE(ak,l\ni ) \u22642E \u2206\n\nZ\n\nti+1\nti\n\n+ 2E \u2206\u22121\n\nZ\n\n[(Xsk \u2212 Xtki )\u03bcl (fs ) + (Xsl \u2212 Xtli )\u03bck (fs )]ds\n\nti+1\nti\n\nZ\n\ns\nti\n\n\u00012\n\n[eTk \u03bc(fu )dueTl \u03c3(fs ) + eTl \u03bc(fu )dueTk \u03c3(fs )]dWs\n\n\u2261I1 (\u2206) + I2 (\u2206).\n\n25\n\n(A.8)\n\u00012\n\n\fApplying Jensen's inequality and H\u00f6lder's inequality (Propostion 1), we obtain\nZ ti+1 h\ni2\n\u22121\nI1 (\u2206) \u2264M \u2206\nE (Xsk \u2212 Xtki )\u03bcl (fs ) + (Xsl \u2212 Xtli )\u03bck (fs ) ds\n(A.9)\n\u2264M \u2206\u22121\n\nZ\n\nti\nti+1\nti\n\nn\n\nE(Xsk \u2212 Xtki )4 E[\u03bcl (fs )]4\n\n\u00011/2\n\n+ E(Xsl \u2212 Xtli )4 E[\u03bck (fs )]4\n\n\u00011/2 o\nds.\n\nSince an application of Jensen's inequality, martingale moments inequalities and Assumption 2 results in\nE(Xsl\n\n\u2212\n\nXtli )4\n\n\u2264M E\n\n\u0002\n\nZ\n\ns\n\n\u03bcl (fu )du\n\nti\n3\n\n\u2264 M (s \u2212 ti )\n\nZ\n\n\u00034\n\nZ\nm\nX\n\u0002\nE\n+\nj=1\n\ns\n\n4\n\nE[\u03bcl (fu )] du +\nti\n\ns\nti\n\n\u03c3lj (fu )dWuj\n\nm\nX\nj=1\n\nM (s \u2212 ti )\n\n\u00034 \u0001\n\nZ\n\ns\n\nE[\u03c3lj (fu )]4 du\n\nti\n\n\u0001\n\n\u2264 M (s \u2212 ti )2 ,\nwe see that (A.9) can be bounded as\nI1 (\u2206) \u2264 M \u2206.\n\n(A.10)\n\nWe now consider the second term I2 (\u2206) in (A.8). By stochastic calculus and\nJensen's inequality, we have\nZ s\nZ ti+1 X\nm\n\u0010\n\u00112\n\u22121\nE \u2206\nI2 (\u2206) = 2\n[\u03bck (fu )\u03c3lj (fs ) + \u03bcl (fu )\u03c3kj (fs )]du ds\nti\n\n\u2264 M \u2206\u22121\n\nti\n\nj=1\n\nZ\n\nti+1\n\nti\n\nm Z s\nX\nj=1\n\nE[\u03bck (fu )\u03c3lj (fs ) + \u03bcl (fu )\u03c3kj (fs )]2 duds\n\nti\n\n= O(\u2206).\n2\nThis together with (A.10) leads to E(ak,l\ni ) = O(\u2206). Therefore, by the Cauchy-Schwarz\n\ninequality and the assumption that limn (1 \u2212 \u03bb) exists,\n\u0012\n\u0013 n\n1 \u2212 \u03bb 2 X 2(i\u22121) X 2\n2\n2\nEAn,\u2206 \u2264 M n\n\u03bb\nckl E(ak,l\nN \u2212i ) = O(\u2206),\n1 \u2212 \u03bbn\ni=1\n\nl\u2264k\n\nwhich concludes the proof. \u0004\nLemma 2 Under Assumptions 1 and 2, as n \u2192 \u221e, n\u2206q \u2192 0 and n(1 \u2212 \u03bb) \u2192 \u03c4 , we\nhave\n\u221a\n\nD\n\nnBn,\u2206 \u2212\u2192 Zc ,\n\nwhere Bn,\u2206 is defined in (A.6) and the random variable Zc is defined in Theorem 1.\n26\n\n\fProof. We will decompose Bn,\u2206 into two parts and prove that the first part is asymptotically negligible and the second part has some asymptotic distribution.\nNote that bk,l\ni can be decomposed as\nk,l\nk,l\nbk,l\ni = B i + Ci ,\n\n(A.11)\n\nwhere\nBik,l\n\n=\u2206\n\n\u22121\n\nX\n\n(\u03c3kj (ft0 )\u03c3lp (ft0 ) + \u03c3kp (ft0 )\u03c3lj (ft0 ))\n\nj,p\n\nZ\n\nti+1\nti\n\n(Wsj \u2212 Wtji )dWsp\n\nand\nCik,l\n\n=\u2206\n\n\u22121\n\nZ\n\nti+1\n\nti\n\nZ\n\ns\n\nti\n\n[eTk (\u03c3(fu ) \u2212 \u03c3(ft0 ))dWu eTl \u03c3(fs ) + eTk \u03c3(fu )dWu eTl (\u03c3(fs ) \u2212 \u03c3(ft0 ))]dWs ,\n\nwhere ek is the unit vector with kth entry 1 and all other entries 0. Correspondingly,\nBn,\u2206 is decomposed as\nBn,\u2206 =\n\nX\nX\n1\u2212\u03bb X\n1\u2212\u03bb X\nk,l\nk,l\nckl\n\u03bbi\u22121 BN\nckl\n\u03bbi\u22121 CN\n\u2212i +\n\u2212i \u2261 B + C.\nn\nn\n1\u2212\u03bb\n1\u2212\u03bb\nk\u2264l\n\nk\u2264l\n\n\u221a\n\nFirst, we show that\n\nnC is asymptotically negligible. To this end, note that by\n\nstochastic calculus and the triangular inequality, we have\nE(Cik,l )2 \u2264\u2206\u22122\n\nZ\n\nti\n\n+\u2206\n\u2261\u2206\n\n\u22122\n\nm\nti+1 X\n\n\u22122\n\nZ\n\nj=1\n\nZ\n\nti+1\nti\n\n\u0010Z\n\nm\nX\n\nE\n\nj=1\n\nm\nti+1 X\n\nti\n\nE\n\ns\nti\n\n\u00112\neTk (\u03c3(fu ) \u2212 \u03c3(ft0 ))dWu \u03c3lj (fs ) ds\n\n\u0010Z\n\ns\nti\n\n(j)\nI1 (\u2206)ds\n\n\u00112\neTk \u03c3(fu )dWu (\u03c3lj (fs ) \u2212 \u03c3lj (ft0 )) ds\n+\u2206\n\n\u22122\n\nZ\n\nm\nti+1 X\n\nti\n\nj=1\n\n(j)\n\nI1 (\u2206)ds.\n\nj=1\n\nApplying H\u00f6lder's inequality yields\n(j)\nI1 (\u2206)\n\n\u0010 Z\n\u2264 E\n\ns\n\nti\n\n\u00111/2\n\u00014\neTk (\u03c3(fu ) \u2212 \u03c3(ft0 ))dWu E(\u03c3lj (fs ))4\n,\n\n(A.12)\n\nand then by martingale moment inequalities and (15) we obtain\nE\n\n\u0010Z\n\ns\n\nti\n\neTk (\u03c3(fu )\n\n\u2212 \u03c3(ft0 ))dWu\n\n\u00114\n\n\u2264O(1)E\n\n\u0010Z\n\nm\nsX\n\nti j=1\n\n(\u03c3kj (fu ) \u2212 \u03c3kj (ft0 ))2 du\n\n\u0001\n\u2264O (n\u2206 + \u2206)4q \u22062 .\n27\n\n\u00112\n\n\fHence, we can bound (A.12) as\n\u0001\n(j)\nI1 (\u2206) \u2264 O (n\u2206)2q \u2206 .\n\n(j)\n\n(A.13)\n\nNext we consider I2 (\u2206). Similarly, by H\u00f6lder's inequalities, martingale moments\ninequalities, and (15) we have\n\u00111/2\n\u0010 Z s\n\u00014\n(j)\nI2 (\u2206) \u2264 E\neTk \u03c3(fu )dWu E(\u03c3lj (fs ) \u2212 \u03c3lj (ft0 ))4\nti\n\n\u0010 Z\n\u2264 O(1) E[\n\nm\nsX\n\nti j=1\n\n2\n\u03c3kj\n(fu )du]2 (n\u2206 + \u2206)4q EK 4\n\n\u00111/2\n\n\u0001\n\u2264 O (n\u2206)2q \u2206 .\nThis together with (A.13) implies that\n\u0001\nE(Cik,l )2 = O (n\u2206)2q .\nHence, it follows that\nE\nwhich means that\n\n\u221a\n\n\u221a \u00012\nnC = O((n\u2206)2q ),\n\n(A.14)\n\nnC is asymptotically negligible.\n\u221a\nNext, we consider the term nB. We first define the augmented filtration Ft . Let\n\n(\u03a9, F, P ) be the probability space in which the Brownian motion {Wt , 0 \u2264 t < \u221e} is\ndefined, and X 0 is the initial value of model (4) and independent of F\u221e . Define the\n\nleft-continuous filtration Gt = \u03c3(X 0 ) \u2228 {FtW , 0 \u2264 t < \u221e} as well as the collection of\nnull sets N = {N \u2208 \u03a9; \u2203G \u2208 G\u221e with N \u2286 G and P (G) = 0}. Then the augmented\nS\nfiltration is defined as Ft = \u03c3(Gt \u222a N ), 0 \u2264 t < \u221e; F\u221e = \u03c3( t\u22650 Ft ). First note\n\nthat by stochastic calculus we have E[Bik,l |F0 ] = 0 and for i 6= j, Bik,l and Bjk,l are\nindependent. Therefore, we only need to verify the conditions of the central limit\ntheorem for the martingale difference array (see, e.g. Hall and Heyde (1980), Corollary\n3.1, P.58); namely, we need to check\nn\n\u00112\n\u0010 \u221an(1 \u2212 \u03bb)\n\u03c4\nX\nX\nP \u03c4 (1 + e ) T T\nk,l\ni\u22121\nc\nB\n|F\n\u2212\u2192\nE\nc PD (\u03a3(ft ) \u2297 \u03a3(ft ))PD c\n\u03bb\nt\nkl i\ni\n1 \u2212 \u03bbn\ne\u03c4 \u2212 1\ni=1\n\nl\u2264k\n\n(A.15)\nand\nn\nh \u221a 1\u2212\u03bb\ni\nX\nX\nP\nk,l \u00014\ni\u22121\nE\nn\n\u03bb\nc\nB\nF\n\u2212\u2192 0.\nt\nkl\ni\ni\nn\n1\u2212\u03bb\ni=1\n\nl\u2264k\n\n28\n\n(A.16)\n\n\fExpression(A.15) gives the asymptotic conditional variance of\n\n\u221a\n\nnB and (A.16) implies\n\nthe conditional Lindeberg condition. These two conditions lead to\n\u221a\n\nD\n\nnB \u2212\u2192 Zc ,\n\n(A.17)\n\nwhere the random variable Zc is defined as in Theorem 1.\nWe first prove (A.15). From stochastic calculus we know that E[Bik,l |Fti ] = 0 and\n\nfor i 6= j, Bik,l and Bjk,l are independent. Moreover, by (15) we have\nE[Bik1 ,l1 Bik2 ,l2 |Fti ] =\u2206\u22122\n\nX\n\nk1 ,l1\nk2 ,l2\nHj,g\n(ft0 )Hj,g\n(ft0 )\n\nj,g\n\nZ\n\nti+1\nti\n\nE(Wsj \u2212 Wtji )2 ds\n\n=\n\n1X\n\nk1 ,l1\nk2 ,l2\nHj,g\n(ft0 )Hj,g\n(ft0 )\n\n=\n\n1X\n\nk1 ,l1\nk2 ,l2\nHj,g\n(ft )Hj,g\n(ft ) + og ((n\u2206 + \u2206)q ),\n\n2\n2\n\nj,g\n\nj,g\n\nk,l\nwhere Hj,g\n(x) = \u03c3kj (x)\u03c3lg (x) + \u03c3kg (x)\u03c3lj (x). It follows that\n\nX\nvar(\nclk Bil,k |Fti ) = cT PD (2\u03a3(ft0 ) \u2297 \u03a3(ft0 ))PDT c\nl\u2264k\n\nP\n\n\u2212\u2192 cT PD (2\u03a3(ft ) \u2297 \u03a3(ft ))PDT c.\nTherefore, we get the following result for the conditional variance of the left hand side\nof (A.15):\nn\n\u0010 \u221an(1 \u2212 \u03bb)\n\u00112 n(1 \u2212 \u03bb)(1 + \u03bbn )\nX\nX\nX\nk,l\ni\u22121\nvar(\n\u03bb\nE\n=\n|F\nc\nB\nclk Bil,k |Fti )\nt\nkl\ni\ni\n1 \u2212 \u03bbn\n(1 + \u03bb)(1 \u2212 \u03bbn )\ni=1\n\nl\u2264k\n\nl\u2264k\n\nP\n\n\u2212\u2192\n\ne\u03c4 )\n\n\u03c4 (1 +\ncT PDT (\u03a3(ft ) \u2297 \u03a3(ft ))PD c,\ne\u03c4 \u2212 1\n\nwhere \u03c4 = limn\u2192\u221e n(1 \u2212 \u03bb). This verifies (A.15).\nThen we show (A.5). Straightforward calculations yield\nE\n\nh X\nl\u2264k\n\nckl Bik,l\n\n\u00014\n\n=O(1)\n\nX\n\nc4kl \u2206\u22124\n\n=O(1)\n\nX\n\nX\n\nl\u2264k\n\nX\n\nk,l\n(Hj,g\n(ft0 ))4 E\n\nj,g\n\nl\u2264k\n\nl\u2264k\n\ni\nX\nFti = O(1)\nc4kl E[(Bik,l )4 |Fti ]\n\nc4kl\n\nh Z\n\nk,l\n(Hj,g\n(ft0 ))4 .\n\nj,g\n\n29\n\nti+1\nti\n\n(Wsj \u2212 Wtji )dWsg\n\n\u00014\n\nFti\u22121\n\ni\n\n\fThis together with Assumption 2 and H\u00f6lder's inequality leads to\nn\nh \u221a 1\u2212\u03bb\ni\nX\nX k,l\nX\nX\nP\nk,l \u00014\n\u22121\n4\ni\u22121\nE\nn\n(Hj,g (ft0 ))4 \u2212\u2192 0,\n=\nO(n\n)\nc\nc\nB\nF\n\u03bb\nt\nkl i\nkl\ni\n1 \u2212 \u03bbn\ni=1\n\nl\u2264k\n\nl\u2264k\n\nj,g\n\nwhich proves (A.5). (A.17) holds in consequence. Combining (A.14) and (A.17) and\napplying Slutsky's lemma, we obtain the conclusion in lemma 2. \u0004\nLemma 3 Under Assumptions 1 and 2, as n \u2192 \u221e and n\u2206q \u2192 0, the following result\nholds for Cn,\u2206 defined in (A.6)\nE Cn,\u2206 \u2212 cT vech(\u03a3(ft )) = O ((n\u2206)q ) .\n\n(A.18)\n\nProof. Note that\nE|Cn,\u2206 \u2212\n\nk\nX\nl\u2264k\n\nckl vkl,t| =\n\u2264\n\nk\nn\n\u0010\n\u0011\nX\nX\n1\u2212\u03bb\nk,l\ni\u22121\nc\nv\u0304\n\u2212\nv\nE\n\u03bb\nkl\nkl,t\nN \u2212i\n1 \u2212 \u03bbn\ni=1\n\nn\nX\n\n1\u2212\u03bb\n1 \u2212 \u03bbn\n\ni=1\n\n\u03bbi\u22121\n\nl\u2264k\n\nk\nX\nl\u2264k\n\nk,l\nckl E|v\u0304N\n\u2212i \u2212 vkl,t |.\n\nThus we only need to consider the asymptotic property of E|v\u0304ik,l \u2212 vkl,t |. By the\nCauchy-Schwarz inequality and H\u00f6lder's inequality, we have\nE\n\nv\u0304ik,l\n\n\u2212 vkl,t \u2264 \u2206\n\n\u22121\n\nm Z\nX\nj=1\n\nti+1\nti\n\n\b\n\n\u0001\nE \u03c3kj (ft ) \u03c3lj (ft ) \u2212 \u03c3lj (fs )\n\n\u0001\n+ E \u03c3kj (ft ) \u2212 \u03c3kj (fs ) \u03c3lj (fs ) ds\nm Z ti+1\nX\n\b\u0002 2\n\u00012 \u00031/2\n\u2264 \u2206\u22121\nE\u03c3kj (ft )E \u03c3lj (ft ) \u2212 \u03c3lj (fs )\nj=1\n\nti\n\n\u00031/2\n\u0002\n\u00012 2\n(fs )\nds\n+ E \u03c3kj (ft ) \u2212 \u03c3kj (fs ) E\u03c3lj\nTherefore by (15) and Assumption 2,\n\u0001\n\u0001\nE v\u0304ik,l \u2212 vkl,t = O (n\u2206 + \u2206)q = O (n\u2206)q .\nThis proves (A.18). \u0004\n\nA.3\n\nProof of Proposition 2\n\n30\n\n\fLemma 4 Since ft is a stationary real ergodic process, we have\nL (T, x) a.s.\nPf 2\n\u2212\u2192 p(x),\nbj (x)T\n\nwhere p(x) is the time-invariant density function of the process ft at x.\nProof. See Bandi and Phillips (2003) and Bosq (1998, Theorem 6.3, P150). \u0004\n\nLemma 5 Suppose \u2206 \u2192 0, N \u2206 \u2192 \u221e, and\n3\u20135, we have for l = 0, 1, 2, 3\nWl (x) =\n\n1\n\u2206\n\nZ\n\ntN\u22121\n\nt0\n\n1\nh\n\np\n\n\u2206 log \u2206\u22121 = o(1). Under Assumptions\n\n(fs \u2212 x)l Kh (fs \u2212 x)ds + N hl\u22121 Oa.s.\n\n\u0010p\n\n\u0011\n\u2206 log \u2206\u22121 .\n\nProof. First, note that for any nonnegative integer l \u2264 4, we have\nN \u22121 Z\n\u0010f \u2212 x\u0011\n1 X tk+1\ns\nWl (x) \u2212\nds\n(fs \u2212 x)l K\n\u2206\nh\nk=0 tk\nN \u22121 Z\n\u0010f \u2212 x\u0011\n\u0010f \u2212 x\u0011\n1 X tk+1\ns\ntk\n\u2264\n\u2212 (fs \u2212 x)l K\nds\n(ftk \u2212 x)l K\nh\u2206\nh\nh\ntk\n\n(A.19)\n\nk=0\n\n\u2264I1 + I2\nwith\nI1 =\n\nN \u22121 Z\n\u0010 rb \u2212 x \u0011 f \u2212 f\n1 X tk+1\ns\ntk\nks\n|ftk \u2212 x|l ds\nK\u2032\nh\u2206\nh\nh\ntk\n\n(A.20)\n\nk=0\n\nand\nN \u22121 Z\n\u0010f \u2212 x\u0011\n1 X tk+1\ns\nds,\n(rks \u2212 x)l\u22121 (fs \u2212 ftk ) K\nI2 =\nh\u2206\nh\ntk\n\n(A.21)\n\nk=0\n\nwhere rbks and rks are both values on the line segment connecting ftk to fs . Now define\n\u03baN,\u2206 = max\n\nsup\n\ni\u2264N \u22121 ti\u22121 \u2264s\u2264ti\n\n|fs \u2212 fti\u22121 |.\n\nThen, by Levy's modulus of continuity of diffusions (see, e.g. Revuz and Yor (1998,\nCh. V, Exercise 1.20)),\n\u0011\n\u0010\n\u03baN,\u2206\n= \u03b1 = 1,\nP lim sup p\n\u2206 log \u2206\u22121\n\u2206\u21920\n31\n\n(A.22)\n\n\fwhere \u03b1 is a suitable constant. In turn, (A.22) implies that\n\u0010p\n\u0011\n\u03baN,\u2206 = Oa.s.\n\u2206 log \u2206\u22121 .\nThis together with the assumption that\n\n1\nh\n\np\n\n\u2206 log \u2206\u22121 = o(1) leads to\n\n\u03baN,\u2206\n= oa.s. (1) as N \u2206 \u2192 \u221e.\nh\nIn view of (A.20) and (A.21), we have\n\u0001\nrbks \u2212 x \u0001\nfs \u2212 x\n+ oa.s. (1)\n= K\u2032\nh\nh\n\nK\u2032\nand\n\nr ks \u2212 x = h\n\n\u0001\nfs \u2212 x\n+ oa.s. (1) ,\nh\n\nuniformly over k = 0, * * * , N \u2212 1. Hence, by Lemma 4 and Revuz and Yor (1999),\nExercise 1.15 and Corollary 1.6 of Chapter 6, we obtain that (A.20) can be bounded as\nN \u22121 Z\n\u0001 fs \u2212 x\n\u03baN,\u2206 hl\u22121 X tk+1\nfs \u2212 x\nl\n+ oa.s. (1)\n+ oa.s. (1) ds\nI1 \u2264\nK\u2032\nh\n\u2206\nh\nh\nk=0 tk\nZ \u221e\n\u0001 y\u2212x\ny\u2212x\n\u03baN,\u2206\nl Lr (tN \u22121 , y)\nP\n+ oa.s. (1)\n+ oa.s. (1)\nK\u2032\ndy\n=N \u2206hl\u22121\nh\nh\nh\nN \u2206 b2j (y)\n\u2212\u221e\nZ \u221e\n\u0001\nl \u03baN,\u2206\n=N h\nK \u2032 u + oa.s. (1) |u + oa.s. (1)|l (p(uh + x) + oa.s. (1))du.\nh\n\u2212\u221e\nThis together with (9) yields\nI1 \u2264 N hl Oa.s.\n\n\u0001\n1p\n\u2206 log \u2206\u22121 .\nh\n\nSimilarly, we can show that (A.21) is also bounded by N hl Oa.s.\nproves the stated results. \u0004\n\n1\nh\n\np\n\n\u0001\n\u2206 log \u2206\u22121 . This\n\nProof of Proposition 2\nSince x2l K(x) is a positive function, by Exercise 1.15 and Corollary 1.6 of Chapter 6\nof Revuz and Yor (1999), and Lemma 4 above we have for l = 0, 1,\nZ tN\u22121\n1\nfs \u2212 x \u0001\nfs \u2212 x \u00012l\nK\nds\nN \u2206 t0\nh\nh\nZ\ny \u2212 x \u0001 Lr (tN \u22121 , y)\ny \u2212 x \u00012l\nP\ndy\nK\n=\nh\nh\nN \u2206 b2j (y)\nZ\n= h u2l K(u)(p(uh + x) + oa.s. (1))du\n\u0001\n= h p(x)\u03bc2l + oa.s. (1) ,\n32\n\n\fR\n\nx4 K(x)dx < \u221e. This together with Lemma 5 leads to\nZ tN\u22121\n1\n1\nW2l (x) =\n(fs \u2212 x)2l Kh (fs \u2212 x)ds + oa.s. (1)\n(A.23)\nN\nN \u2206 t0\n\nwhere we have used \u03bc4 =\n\n=h2l (p(x)\u03bc2l + oa.s. (1)).\nnR\nx\nLet s(dx) = exp \u03b1\n\n2a(y)\nP\ndy\nb2j (y)\n\no\n\nP2dx\nb2j (x)\n\nbe the speed measure of ft . By the Quotient\n\ntheorem (Revuz and Yor (1999), Theorem 3.12, Chapter 10, p.427),\n1\nN\u2206\n\nR tN\u22121 \u0010 fs \u2212x \u00112l+1\nh\n\nt0\n\n1\nN\u2206\n\nR tN\u22121\nt0\n\nKh (fs \u2212 x)ds\n\nKh (fs \u2212 x)ds\n\ny\u2212x \u00012l+1\nKh (y\nhR\n\n=\n\nR\n\n=\n\n\u03bc2l+1\n+ oa.s. (1)\n\u03bc0\n\n\u2212 x)s(dy)\n+ oa.s. (1)\nKh (y \u2212 x)s(dy)\n\nas N \u2206 \u2192 \u221e. In turn, this implies that\n\u221a\n\u00112l+1\n\u0010\nR\n\u2206 log \u2206\u22121 \u0001\n1 tN\u22121 fs \u2212x\n2l+1\nK\n(f\n\u2212\nx)ds\n+\nN\nO\ns\na.s.\nh\n\u2206 t0\nh\nh\nW2l+1 (x)/h\n\u221a\n=\nR\n\u22121 \u0001\nW0 (x)\n\u2206\nlog\n\u2206\nt\n1\nN\u22121\nKh (fs \u2212 x)ds + N Oa.s.\n\u2206 t0\nh\n\u03bc2l+1\n+ oa.s. (1).\n=\n\u03bc0\n\n(A.24)\n\nCombining (A.23) and (A.24), we obtain\nW2l+1 (x) = N h2l+1 (p(x)\u03bc2l+1 + oa.s. (1)).\nThis completes the proof. \u0004\n\nA.4\n\nProof of Theorem 2\n\nLet M (ftk ) = E[Y k Y Tk |ftk ]. Then the matrix function M (y) can be expanded around\na fixed point x as\nM (y) = A0 + A1 (y \u2212 x) + A2 (y \u2212 x)2 + A3 (y \u2212 x)3 + * * * ,\nwhere A0 , A1 , * * * are all matrices. To prove the asymptotic property of the statedomain estimator, let us decompose it as\n\u03a3\u0302S,t (x) \u2212 M (x) =\n\nN\n\u22121\nX\nk=0\n\nwk (x) (M (ftk ) \u2212 M (x)) +\n\n\u2261 b + t.\n\nN\n\u22121\nX\nk=0\n\n\u0001\nwk (x) Y k Y Tk \u2212 M (ftk )\n(A.25)\n\n33\n\n\fFirst, we establish the asymptotic behavior of the bias term b. Applying Taylor's\nexpansion and Proposition 2 results in\nb=\n\n=\n\nN\n\u22121\nX\n\nk=0\nN\n\u22121\nX\nk=0\n\nwk (x) (M (ftk ) \u2212 M (x))\nwk (x)A1 (ftk \u2212 x) +\n\n2\n\nN\n\u22121\nX\nk=0\n\nwk (x)A2 (ftk \u2212 x)2 + oa.s. (h3 )\n\n2\n\n= h \u03bc2 A2 + oa.s. (h ).\nSince we have the following decomposition\n\u0001\n\u0001\n\u0001\n\u03a3\u0302S,t (x) \u2212 \u03a3(x) = \u03a3\u0302S,t(x) \u2212 M (x) + M (x) \u2212 \u03a3(x) = [b + M (x) \u2212 \u03a3(x) ] + t,\nand M (x) \u2212 \u03a3(x) = op (\u2206), the asymptotic bias of the state-domain estimator is\n\u0001 1\nb + M (x) \u2212 \u03a3(x) = h2 \u03bc2 \u03a3\u2032\u2032 (x) + oa.s. (h2 ) + op (\u2206).\n2\n\n(A.26)\n\nThen, let us consider the variance term t. Since t is a matrix, we first vectorize it\nand then consider the asymptotic normality of its linear combination, i.e. we look at\nthe statistic\nT\n\nt\u0303 = a vech\n\n\u22121\n\u0010 NX\nk=0\n\n\u0001\u0011\nwk (x) Y k Y Tk \u2212 M (ftk ) ,\n\nwhere a is a constant vector. By Proposition 2,\nt\u0303 =\n\nN\n\u22121\nX\n\u0001\n1\nKh (ftk \u2212 x)aT vech Y k Y Tk \u2212 M (ftk ) {1 + oa.s. (1)}\np(x)N\n\n(A.27)\n\nk=0\n\n\u2261 AN {1 + oa.s. (1)}.\nTherefore, we only need to show the asymptotic normality of AN . To this end, first let\n\u0001\nPN \u22121\n1\n\u03b8N,k = Kh (ftk \u2212 x)aT vech Y k Y Tk \u2212 M (ftk ) . Then AN = p(x)N\nk=0 \u03b8N,k . Straightforward calculations give\n\n\u0001\u00012\nvar(\u03b8N,k ) = E Kh (ftk \u2212 x)aT vech Y k Y Tk \u2212 M (ftk )\nh\ni\n\b\n\u00012\n= E Kh2 (ftk \u2212 x)E aT vech(Y k Y Tk \u2212 M (ftk )) |ftk\n\b\n\u0001\n= 2E Kh2 (ftk \u2212 x) aT PD \u03a3(ftk ) \u2297 \u03a3(ftk )PDT a\n\n= 2h\u22121 \u03bd0 p(x)aT PD \u03a3(x) \u2297 \u03a3(x)PDT a(1 + o(1)),\n34\n\n(A.28)\n\n\fwhere the last step follows from Taylor's expansion.\nNote that Y tl only depends on the sample path of ft over time interval [tl , tl+1 ].\nThus by conditioning on Ftl , we obtain\n\u0001\n\u0001\u0003\n\u0002\ncov(\u03b8N,1 , \u03b8N,l+1 ) = E \u03b8N,1 Kh (ftl \u2212 x)E aT vech Y l Y Tl \u2212 M (ftl ) Ftl = 0, l \u2265 1.\n\n(A.29)\n\nCombining (A.28) and (A.29) entails\nvar(AN ) =\n\n2\u03bd0\naT PD \u03a3(x) \u2297 \u03a3(x)PDT a(1 + o(1)).\nN hp(x)\n\nSince a stationary Markov process satisfying the G2 condition of Rosenblatt (1970)\nis \u03c1-mixing, we can use \"big-block and small-block\" arguments similar to those used\nby Fan and Yao (2003, Theorem 2.22, p.77) to prove the asymptotic normality of AN .\nThe lengthy details are omitted here. Thus,\n\u221a\nD\nN hAN \u2212\u2192 N (0, 2\u03bd0 p(x)\u22121 aT PD \u03a3(x) \u2297 \u03a3(x)PDT a).\nThis together with (A.26) and (A.27) implies the asymptotic normality of the statedomain estimator, i.e.\n\u221a\n\n\u0011\n\u0010\n1\nD\nN haT vech \u03a3\u0302S,t (x) \u2212 \u03a3(x) \u2212 h2 \u03bc2 \u03a3\u2032\u2032 (x) \u2212\u2192 N (0, 2\u03bd0 p(x)\u22121 aT \u039b(x)a),\n2\n\nwhere a is an arbitrary constant vector. This completes the proof. \u0004\n\nA.5\n\nProof of Theorem 3\n\nWe only need to show the asymptotic normality of the linear combination\n\u0013\n\u0012\n\u0010 2\n\u0011\n\u221a\n\u221a\nb S,t \u2212 \u03a3(x) \u2212 1 h2 \u03bc2 \u03a3\u2032\u2032 (x) + n cT vech \u03a3\nb \u2212 \u03a3(x) ,\nN h aT vech \u03a3\nT,t\n2\n\nwhere aT and cT are two constant vectors. This is equivalent to showing the joint\n\u221a\n\u0001\n\u0001\nb S,t \u2212\u03a3(x)\u2212 1 h2 \u03bc2 \u03a3\u2032\u2032 (x) and \u221ancT vech \u03a3\nb2 .\nasymptotic normality of N haT vech \u03a3\nT,t\n2\n\nFrom the proof of Theorem 2, we have\n\n\u0001\nb S,t \u2212\u03a3(x)\u2212 1 h2 \u03bc2 \u03a3\u2032\u2032 (x) = aT t+op (1) = t\u0303+op (1) = AN {1+oa.s. (1)}+op (1),\naT vech \u03a3\n2\n\nwhere t, t\u0303 and AN are all defined in the proof of Theorem 2. Therefore, we need only\n\u221a\n\u0001\n\u221a\nb2 .\nto consider about the asymptotic normality of N hAN and ncT vech \u03a3\nT,t\n35\n\n\fWe truncate AN by defining\nAtN\n\nNX\n\u2212aN\n1\n\u03b8N,k ,\n=\np(x)N\nk=0\n\nwhere aN is an integer depending only on N and satisfying aN /N \u2192 0 and aN \u2206 \u2192 \u221e.\nWe are going to show that:\n(i) AtN and\n\n\u221a\n\n\u0001\nb 2 are asymptotically independent;\nncT vech \u03a3\nT,t\n\n(ii) AN \u2212 AtN is asymptotically negligible.\n\nWe first prove (i). Since a stationary Markov process satisfying the G2 condition of\nRosenblatt (1970) is \u03c1-mixing with exponentially decaying \u03c1-mixing coefficient \u03c1t (*),\nand the strong-mixing coefficient \u03b1(l) \u2264 \u03c1(l) for any integer l, it follows that\n\u0001\n\u0001\nb 2 )}\u2212E exp{i\u03be(At )}E exp{\u0131\u03becT vech \u03a3\nb 2 } \u2264 32\u03b1(aN \u2212n) \u2192 0,\nE exp{i\u03be(AtN +cT vech \u03a3\nT,t\nT,t\nN\n\nfor any \u03be \u2208 R. This proves (i).\n\nNow, we prove (ii). From the proof of Theorem 2 we know that\nvar(\u03b8N,k ) = 2h\u22121 \u03bd0 p(x)aT PD \u03a3(x) \u2297 \u03a3(x)PDT a(1 + o(1)),\nand cov(\u03b8N,1 , \u03b8N,l+1 ) = 0, \u2200l \u2265 1. Therefore,\n\u221a\n2aN\nvar( N h[AN \u2212 AtN ]) =\n\u03bd0 aT PD \u03a3(x) \u2297 \u03a3(x)PDT a(1 + o(1)) \u2192 0.\np(x)N\nThis along with E[\u03b8N,k ] = 0 gives\n\u221a\n\nP\n\nN h[AN \u2212 AtN ] \u2212\u2192 0,\n\n\u221a\nwhich completes the proof of (ii). Combining (i) and (ii) entails that N hAN and\n\u0001\n\u221a T\nb 2T,t are asymptotically independent. This together with Theorem 1 and\nnc vech \u03a3\n\u221a\nthe asymptotical normality of N hAN shown in the proof of Theorem 2 completes the\nproof of Theorem 3. \u0004\n\n36\n\n\fFIGURE LEGENDS\nFigure 1. Illustration of time- and state-domain estimation. (a) The yields of 1year, 5-year, and 10-year treasury bills from 1962 to 2005. The vertical bar indicates\nlocalization in time, and the horizontal bar represents localization in state of the 5-year\ntreasury bill process. (b) Illustration of time-domain smoothing: 1-year yield differences\nare plotted against 10-year yield differences with the regression line superimposed. (c)\nIllustration of the state-domain smoothing: 1-year yield differences are plotted against\n10-year yield differences for those periods with the corresponding 5-year yields restricted\nto the interval 6.37% \u00b1 .2%, indicated by the horizontal bar in (a).\n\nFigure 2. Functions A(\u03c4 ) (solid curve) and B(\u03c4 ) (dashed curve) for the parameters\ngiven in the simulation.\n\nFigure 3. (a) The averages of the entropy losses over 500 simulations for the timedomain estimation (dotted curve), state-domain estimation (dashed curve), and aggregated method (solid curve). (b) The standard deviations of the entropy losses over\n500 simulations for time-domain estimation (dotted curve), state-domain estimation\n(dashed curve), and the aggregated method (solid curve). (c) and (d): The same as in\n(a) and (b) except using the quadratic loss.\n\nFigure 4. (a) Box plots of the entropy losses over 500 simulations for the timedomain estimator (left), the aggregated method (middle), and the state-domain estimator (right). (b) and (c): The same as in (a) except that the quadratic loss and PE\nare used, respectively. (d) The ratios of the averages of the quadratic losses over 150\nout-sample forecastings using the time-domain and state-domain estimators to those\nbased on the aggregated estimator (x-axis) are plotted against the ratios of the PEs\nbased on the time-domain and state-domain estimators to those based on the aggregated estimator (y-axis).\n\nFigure 5. Correlation of the time-domain estimator and state-domain estimator for\nthe volatility of an equally weighted portfolio. The dashed curves are for the 95%\nconfidence intervals. The straight lines are acceptance regions for testing the null\nhypothesis that the correlation is zero at significance level 5%.\n37\n\n\fREFERENCES\nA\u0131\u0308t-Sahalia, Y. (1996). \"Nonparametric Pricing of Interest Rate Derivative Securities.\"\nEconometrica 64, 527\u2013560.\nA\u0131\u0308t-sahalia, Y., and P. Mykland. (2003). \"The Effects of Random and Discrete Sampling\nWhen Estimating Continuous-Time Diffusions.\" Econometrica 71, 483\u2013549.\n-- (2004). \"Estimating Diffusions with Discretely and Possibly Randomly Spaced\nData: A General Theory.\" Annals of Statistics 32, 2186\u20132222.\nAndersen, T. G., T. Bollerslev, and F. X. Diebold. (2002). \"Parametric and Nonparametric Volatility Measurement,\" in Handbook of Financial Econometrics (Y. A\u0131\u0308t-Sahalia\nand L. P. Hansen, eds.).\nArapis, M., and J. Gao. (2004). \"Nonparametric Kernel Estimation and Testing in\nContinuous-Time Financial Econometrics.\" Manuscript.\nArfi, M. (1998). \"Non-Parametric Variance Estimation from Ergodic Samples.\" Scandinavian Journal of Statistics 25, 225\u2013234.\nBandi, F. M., and G. Moloche. (2004). \"On the Functional Estimation of Multivariate\nDiffusion Processes.\" Manuscript.\nBandi, F. M., and T. Nguyen. (1999). \"Fully Nonparametric Estimators for Diffusions:\nA Small Sample Analysis.\" Working Paper, University of Chicago.\nBandi, F. M., and P. C. B. Phillips. (2002). \"Nonstationary Continuous-Time Processes,\"\nin Handbook of Financial Econometrics (Y. A\u0131\u0308t-Sahalia and L. P. Hansen, eds.).\n-- (2003). \"Fully Nonparametric Estimation of Scalar Diffusion Models.\" Econometrica 71, 241\u2013283.\nBanon, G. (1978). \"Nonparametric Identification for Diffusion Processes.\" SIAM J. Control Optim. 16, 380\u2013395.\nBollerslev, T., R. F. Engle, and J. M. Wolldridge. (1988). \"A Capital Asset Pricing\nModel with Time-Varying Covariance.\" Jour. of Political Economy 96, 116\u2013131.\nCai, Z., and Y. Hong. (2003). \"Nonparametric Methods in Continuous-Time Finance:\nA Selective Review.\" In Recent Advances and Trends in Nonparametric Statistics (M. G.\nAkritas and D. M. Politis, eds.), 283\u2013302.\nChen, S.X. and J. Gao. (2004). \"A Test for Model Specification of Diffusion Processes.\"\nManuscript.\nCheridito, P., D. Filipovi\u0107, and R. L. Kimmel. (2005). \"Market Price of Risk Specification\nfor Affine Models: Theory and Evidence.\" Journal of Financial Economics, Forthcoming.\nCox, J. C., J. E. Ingersoll, and S. A. Ross. (1985). \"A Theory of the Term Structure of\nInterest Rates.\" Econometrica 53, 385\u2013467.\n\n38\n\n\fDalalyan, A. S., and Y. A. Kutoyants. (2003). \"Asymptotically Efficient Estimation of\nthe Derivative of the Invariant Density.\" Statist. Inference Stochastic Process. 6, 89\u2013107.\nDuffee, G. R. (2002). \"Term Premia and Interest Rate Forecasts in Affine Models.\"\nJournal of Finance 57, 405\u2013443.\nDuffie, D., and R. Kan. (1996). \"A Yield-Factor Model of Interest Rates.\" Math. Finance\n6, 379?-406.\nEngle, R. F., V. K. Ng, and M. Rothschild. (1990). \"Asset Pricing with a Factor ARCH\nCovariance Structure: Empirical Estimates for Treasury Bills.\" Journal of Econometrics\n45, 213\u2013237.\nFan, J. (2005). \"A Selective Overview of Nonparametric Methods in Financial Econometrics (with discussion).\" Statistical Science, 20, 317\u2013357.\nFan, J., Y. Fan, and J. Jiang. (2005). \"Dynamic Integration of Time- and State-Domain\nMethods for Volatility Estimation.\" Manuscript.\nFan, J., J. Jiang, C. Zhang, and Z. Zhou. (2003). \"Time-Dependent Diffusion Models for\nTerm Structure Dynamics and the Stock Price Volatility.\" Statistica Sinica 13, 965\u2013992.\nFan, J. and Q. Yao (2003). Nonlinear Time Series: Nonparametric and Parametric\nMethods. New York: Springer-Verlag.\nFan, J., and C. Zhang. (2003). \"A Re-examination of Stanton's Diffusion Estimations\nwith Applications to Financial Model Validation.\" J. Amer. Statist. Assoc. 98, 118\u2013134.\nFoster, D. P., and D. B. Nelson. (1996). \"Continuous Record Asymptotics for Rolling\nSample Variance Estimators.\" Econometrica 64, 139\u2013174.\nGobet, E. (2002). \"LAN Property for Ergodic Diffusions with Discrete Observations.\"\nAnn. Inst. H. Poincar\u00e9 Probab. Statist. 38, 711\u2013737.\nGobet, E., M. Hoffmann, and M. Reiss. (2004). \"Nonparametric Estimation of Scalar\nDiffusions Based on Low Frequency Data Is Ill-Posed.\" Ann. Statist. 32, 2223\u20132253.\nHall, P., and C. Heyde. (1980). Martingale Limit Theorem and Its Applications. Academic Press.\nHansen, L. P., and Scheinkman, J. A. (1995). \"Back to the Future: Generating Moment\nImplications for Continuous-Time Markov processes.\" Econometrica 63, 767\u2013804.\nHansen, L. P., J. A. Scheinkman, and N. Touzi. (1998). \"Spectral Methods for Identifying\nScalar Diffusions.\" Journal of Econometrics 86, 1\u201332.\nH\u00e4rdle, W. , H. Herwartz, and V. Spokoiny. (2002). \"Time Inhomogeneous Multiple\nVolatility Modelling.\" Jour. Fin. Econometrics 1, 55-95.\nJacod, J. (1997). \"Nonparametric Kernel Estimation of the Diffusion Coefficient of a\nDiffusion.\" Pr\u00e9publication N. 405 du Laboratoire de Probabilit\u00e9s de l'Universit\u00e9 Paris\nVI.\n\n39\n\n\fJiang, G. J., and J. Knight. (1997). \"A Nonparametric Approach to the Estimation of\nDiffusion Processes, with an Application to a Short-Term Interest Rate Model.\" Econometric Theory 13, 615\u2013645.\nKessler, M., and M. S\u00f8rensen. (1999). \"Estimating Equations Based on Eigenfunctions\nfor a Discretely Observed Diffusion Process.\" Bernoulli 5, 299\u2013314.\nKaratzas, I., and S. Shreve. (1991). Brownian Motion and Stochastic Calculus (2nd ed.).\nNew York: Springer-Verlag.\nLedoit, O. and M. Wolf. (2003). \"Improved Estimation of the Covariance Matrix of\nStock Returns with an Application to Portfolio Selection.\" Journal of Empirical Finance\n10, 603\u2013621.\nMercurio, D. and V. Spokoiny. (2004). \"Statistical Inference for Time-Inhomogeneous\nVolatility Models.\" The Annals of Statistics 32, 577\u2013602.\nMorgan, J. P. (1996). RiskMetrics Technical Document (4th ed.). New York.\nRevuz, D., and M. Yor. (1999). Continuous Martingales and Brownian Motion. SpringerVerlag.\nRobinson, P. M. (1997). \"Large-sample Inference for Nonparametric Regression with\nDependent Errors.\" Ann. Statist. 25, 2054\u20132083.\nRosenblatt, M. (1970). \"Density Estimates and Markov Sequences,\" in Nonparametric\nTechniques in Statistical Inference (M. L. Puri, ed.), 199\u2013213. Cambridge University\nPress.\nStanton, R. (1997). \"A Nonparametric Models of Term Structure Dynamics and the\nMarket Price of Interest Rate Risk.\" Journal of Finance 52, 1973\u20132002.\nVasicek, O. A. (1977). \"An Equilibrium Characterisation of the Term Structure.\" Journal\nof Financial Economics 5, 177\u2013188.\n\n40\n\n\fFOOTNOTE\nFootnote 1. By \"stationarity\" we do not mean that the process is strongly stationary,\nbut has some structural invariability over time. For example, the conditional moment\nfunctions do not vary over time.\n\nFootnote 2. Ledoit and Wolf (2003) introduce a shrinkage estimator by combining\nthe sample covariance estimator with that derived from the CAPM. Their procedure intends to improve estimated covariance matrix by pulling the sample covariance towards\nthe estimate based on the CAPM. Their basic assumption is that the return vectors\nare i.i.d. across time. This usually holds approximately when the data are localized in\ntime. In this sense, their estimator can be regarded as a time-domain estimator.\nb S,t and \u03a3\nb T,t are asymptotically independent,\nFootnote 3. We prove in Section 4 that \u03a3\nand thus they are close to be independent in finite sample. In the following, by \"nearly\nindependent\" and \"almost uncorrelated\", we mean the same.\n\nFootnote 4. In practice, one can take the yields process with median term of maturity\nas the driving factor, as this bond is highly correlated to both short-term and long-term\nbonds.\n\nFootnote 5. The kernel function is a probability density, and the bandwidth is its\nassociated scale parameter. Both of them are used to localize the linear regression\naround the given point x0 . The commonly used kernel functions are the Gaussian\ndensity and the Epanechnikov kernel K(x) = 0.75(1 \u2212 x2 )+ .\n\nFootnote 6. The stationarity condition of ft in Assumption 3 can be weakened to\nHarris recurrence. See Bandi and Moloche (2004) for asymptotic normality of local\nconstant estimator under recurrence assumption.\n\nFootnote 7. The optimal choice of weight is proportional to the effective number\nof data points used for the state-domain and time-domain smoothing. It always outperforms the choice with \u03c9t = 1 (state-domain estimator) or \u03c9t = 0 (time-domain\nestimator).\n\nFootnote 8. The choice comes from the recommendation of the RiskMetrics of J.P.\nMorgan. The parameter \u03bb can also be chosen automatically by data by using the\nprediction error as in Fan, Jiang, Zhang and Zhou (2003). Since we compare the relative\n41\n\n\fperformance between the time-domain estimator and the aggregated estimator, we opt\nfor this simple choice. The results do not expect to change much when a data-driven\ntechnique is used.\n\nFootnote 9. Here we add normal noise to make the model more realistic. Our method\nperforms even better without noise. Since the noise vectors are i.i.d. across time and the\nstandard deviations are small, adding them to the original time series does not change\nthe whole structure. Hence, our theory can carry through under contamination.\n\nFootnote 10. With \u03bb = 0.94, the last data point used in the time domain has an\nextra weight 0.94104 \u2248 0.0016, which is very small. Hence, we essentially include all\nthe effective data points.\n\nFootnote 11. Europe used several common currencies prior to the introduction of the\nEuro. The European Currency Unit (ECU) was used from January 1, 1979 to January\n1, 1999, when the Euro replaced the European Currency Unit at par.\n\nTABLE\nTable 1\nAPEs of Bond Yields, Exchange Rates and Simulations\n\nTime\n\nState\n\nAggregated\n\n3.837 \u00d7 10\u22123\n\n3.767 \u00d7 10\u22123\n\n3.756 \u00d7 10\u22123\n\n1.013 \u00d7 10\u22123\n\n1.011 \u00d7 10\u22123\n\n9.933 \u00d7 10\u22124\n\nBonds\nk=0\nk=1\nk=2\n\n1.643 \u00d7 10\u22123\n\n1.557 \u00d7 10\u22123\n\n1.555 \u00d7 10\u22123\n\nCurrencies\n4.795 \u00d7 10\u22123\n\n4.913 \u00d7 10\u22123\n\n4.755 \u00d7 10\u22123\n\nk=2\n\n8.979 \u00d7 10\u22124\n\n1.184 \u00d7 10\u22123\n\n8.937 \u00d7 10\u22124\n\nSimulations (k = 0)\n\n1.850 \u00d7 10\u22122\n\nk=0\nk=1\n\n1.681 \u00d7 10\u22123\n\n42\n\n1.855 \u00d7 10\u22123\n1.846 \u00d7 10\u22122\n\n1.652 \u00d7 10\u22123\n1.825 \u00d7 10\u22122\n\n\f(a) Yields of Treasury Bonds From 1962 to 2005\n20\n1\u2212Year\n5\u2212Year\n10\u2212Year\n\n15\n10\n5\n0\n\n500\n\n1000\n\n1500\n\n(b) Correlation in the time domain\n\n2000\n\n(c) Correlation in the state domain\n\n0.6\n0.4\n\n10\u2212year diff.\n\n10\u2212year diff.\n\n0.4\n0.2\n0\n\u22120.2\n\n0.2\n0\n\u22120.2\n\u22120.4\n\n\u22120.4\n\n\u22120.6\n\u22120.5\n\nFigure 1:\n\n0\n1\u2212year diff.\n\n0.5\n\n\u22120.5\n0\n1\u2212year diff.\n\n0.5\n\nIllustration of time- and state-domain estimation. (a) The yields of 1-year, 5-year and 10-year\n\ntreasury bills from 1962 to 2005. The vertical bar indicates localization in time, and the horizontal bar represents\nlocalization in the state of the 5-year treasury bill process. (b) Illustration of time-domain smoothing: 1year yield differences are plotted against 10-year yield differences with the regression line superimposed. (c)\nIllustration of the state-domain smoothing: 1-year yield differences are plotted against 10-year yield differences\nfor those periods with the corresponding 5-year yields restricted to the interval 6.37% \u00b1 .2%, indicated by the\nhorizontal bar in (a).\n\n0.5\n\n0\n\n\u22120.5\n\n\u22121\n\n\u22121.5\n\n\u22122\n\n\u22122.5\n\nFigure 2:\n\n0\n\n5\n\n10\n\n15\n\n20\n\n25\n\n30\n\n35\n\n40\n\nFunctions A(\u03c4 ) (solid curve) and B(\u03c4 ) (dashed curve) for the parameters given in the simulation.\n\n43\n\n\f1.15\n\n1.3\n\n1.1\n\n1.2\n\n1.05\n\n1.1\n\n1\n\n1\n\n0.95\n0.9\n0.9\n0.8\n0.85\n0.7\n\n0.8\n\n0.6\n\n0.75\n\n0.5\n\n0.7\n0.65\n\n0\n\n50\n\n100\n\n0.4\n\n150\n\n0\n\n50\n\n(a)\n\n150\n\n100\n\n150\n\n(b)\n\n\u22126\n\n1.25\n\n100\n\n\u22126\n\nx 10\n\n4.5\n\n1.2\n\nx 10\n\n4\n\n1.15\n3.5\n1.1\n3\n\n1.05\n1\n\n2.5\n\n0.95\n\n2\n\n0.9\n1.5\n0.85\n1\n\n0.8\n0\n\n50\n\n100\n\n0.5\n\n150\n\n(c)\n\nFigure 3:\n\n0\n\n50\n\n(d)\n\n(a) The averages of the entropy losses over 500 simulations for the time-domain estimation (dotted\n\ncurve), state-domain estimation (dashed curve) and aggregated method (solid curve). (b) The standard deviations of the entropy losses over 500 simulations for the time-domain estimation (dotted curve), state-domain\nestimation (dashed curve) and aggregated method (solid curve). (c) and (d): The same as in (a) and (b) except\nusing the quadratic loss.\n\n44\n\n\f11\n\n1.1\n\n10.5\n1.05\n10\n1\n9.5\n0.95\n\n9\n\n0.9\n\n8.5\n\n0.85\n\n8\n\n0.8\n\n7.5\n7\n\n0.75\n\n6.5\n\n0.7\n\n6\nTime\n\nAggregation\n\nState\n\nTime\n\nAggregation\n\n(a)\n\nState\n\n(b)\n1.15\n\n0.045\n\nTime\nState\n\n0.04\n1.1\n0.035\n0.03\n\n1.05\n\n0.025\n1\n\n0.02\n0.015\n\n0.95\n0.01\n\nTime\n\nAggregation\n\n0.9\n0.6\n\nState\n\n0.8\n\n1\n\n1.2\n\n(c)\n\nFigure 4:\n\n1.4\n\n1.6\n\n1.8\n\n2\n\n2.2\n\n2.4\n\n(d)\n\n(a) Box plots of the entropy losses over 500 simulations for the time-domain estimator (left),\n\nthe aggregated method (middle), and the state-domain estimator (right). (b) and (c): The same as in (a)\nexcept that the quadratic loss and PE are used, respectively. (d) The ratios of the averages of the quadratic\nlosses over 150 out-sample forecastings using the time-domain and state-domain estimators to those based on\nthe aggregated estimator (x-axis) are plotted against the ratios of the PEs based on the time-domain and\nstate-domain estimators to those based on the aggregated estimator (y-axis).\n\n45\n\n\f0.25\n\n0.2\n\n0.15\n\n0.1\n\n0.05\n\n0\n\n\u22120.05\n\n\u22120.1\n\nFigure 5:\n\n0\n\n50\n\n100\n\n150\n\nCorrelation of the time-domain estimator and state-domain estimator for the volatility of an equally\n\nweighted portfolio. The dashed curves are for the 95% confidence intervals. The straight lines are acceptance\nregions for testing the null hypothesis that the correlation is zero at significance level 5%.\n\n46\n\n\f"}