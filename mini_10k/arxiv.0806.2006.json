{"id": "http://arxiv.org/abs/0806.2006v2", "guidislink": true, "updated": "2012-01-06T20:39:14Z", "updated_parsed": [2012, 1, 6, 20, 39, 14, 4, 6, 0], "published": "2008-06-12T06:42:07Z", "published_parsed": [2008, 6, 12, 6, 42, 7, 3, 164, 0], "title": "Fusion de classifieurs pour la classification d'images sonar", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0806.2112%2C0806.2602%2C0806.3296%2C0806.2443%2C0806.0036%2C0806.3356%2C0806.2624%2C0806.3825%2C0806.4276%2C0806.2928%2C0806.4143%2C0806.4503%2C0806.3566%2C0806.4693%2C0806.1282%2C0806.0610%2C0806.4466%2C0806.3573%2C0806.4685%2C0806.2100%2C0806.3786%2C0806.1470%2C0806.3794%2C0806.2338%2C0806.2005%2C0806.3534%2C0806.0215%2C0806.0743%2C0806.1145%2C0806.4878%2C0806.3809%2C0806.0790%2C0806.2756%2C0806.0540%2C0806.0640%2C0806.3844%2C0806.4536%2C0806.2933%2C0806.3390%2C0806.2405%2C0806.1906%2C0806.2006%2C0806.4327%2C0806.1170%2C0806.2474%2C0806.4681%2C0806.3381%2C0806.0112%2C0806.2796%2C0806.1469%2C0806.4952%2C0806.1143%2C0806.2947%2C0806.3788%2C0806.4090%2C0806.2529%2C0806.0422%2C0806.3708%2C0806.1986%2C0806.0463%2C0806.1722%2C0806.4377%2C0806.2967%2C0806.2070%2C0806.0290%2C0806.0932%2C0806.4115%2C0806.1964%2C0806.3477%2C0806.2420%2C0806.2191%2C0806.1640%2C0806.3679%2C0806.1747%2C0806.2158%2C0806.0202%2C0806.4412%2C0806.3270%2C0806.0565%2C0806.3038%2C0806.0753%2C0806.1766%2C0806.3047%2C0806.1455%2C0806.2787%2C0806.1250%2C0806.2264%2C0806.2666%2C0806.0427%2C0806.3761%2C0806.2610%2C0806.1327%2C0806.4357%2C0806.2310%2C0806.3249%2C0806.3480%2C0806.1972%2C0806.2496%2C0806.4839%2C0806.1044%2C0806.3818&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Fusion de classifieurs pour la classification d'images sonar"}, "summary": "In this paper, we present some high level information fusion approaches for\nnumeric and symbolic data. We study the interest of such method particularly\nfor classifier fusion. A comparative study is made in a context of sea bed\ncharacterization from sonar images. The classi- fication of kind of sediment is\na difficult problem because of the data complexity. We compare high level\ninformation fusion and give the obtained performance.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0806.2112%2C0806.2602%2C0806.3296%2C0806.2443%2C0806.0036%2C0806.3356%2C0806.2624%2C0806.3825%2C0806.4276%2C0806.2928%2C0806.4143%2C0806.4503%2C0806.3566%2C0806.4693%2C0806.1282%2C0806.0610%2C0806.4466%2C0806.3573%2C0806.4685%2C0806.2100%2C0806.3786%2C0806.1470%2C0806.3794%2C0806.2338%2C0806.2005%2C0806.3534%2C0806.0215%2C0806.0743%2C0806.1145%2C0806.4878%2C0806.3809%2C0806.0790%2C0806.2756%2C0806.0540%2C0806.0640%2C0806.3844%2C0806.4536%2C0806.2933%2C0806.3390%2C0806.2405%2C0806.1906%2C0806.2006%2C0806.4327%2C0806.1170%2C0806.2474%2C0806.4681%2C0806.3381%2C0806.0112%2C0806.2796%2C0806.1469%2C0806.4952%2C0806.1143%2C0806.2947%2C0806.3788%2C0806.4090%2C0806.2529%2C0806.0422%2C0806.3708%2C0806.1986%2C0806.0463%2C0806.1722%2C0806.4377%2C0806.2967%2C0806.2070%2C0806.0290%2C0806.0932%2C0806.4115%2C0806.1964%2C0806.3477%2C0806.2420%2C0806.2191%2C0806.1640%2C0806.3679%2C0806.1747%2C0806.2158%2C0806.0202%2C0806.4412%2C0806.3270%2C0806.0565%2C0806.3038%2C0806.0753%2C0806.1766%2C0806.3047%2C0806.1455%2C0806.2787%2C0806.1250%2C0806.2264%2C0806.2666%2C0806.0427%2C0806.3761%2C0806.2610%2C0806.1327%2C0806.4357%2C0806.2310%2C0806.3249%2C0806.3480%2C0806.1972%2C0806.2496%2C0806.4839%2C0806.1044%2C0806.3818&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this paper, we present some high level information fusion approaches for\nnumeric and symbolic data. We study the interest of such method particularly\nfor classifier fusion. A comparative study is made in a context of sea bed\ncharacterization from sonar images. The classi- fication of kind of sediment is\na difficult problem because of the data complexity. We compare high level\ninformation fusion and give the obtained performance."}, "authors": ["Arnaud Martin"], "author_detail": {"name": "Arnaud Martin"}, "author": "Arnaud Martin", "links": [{"href": "http://arxiv.org/abs/0806.2006v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0806.2006v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0806.2006v2", "affiliation": "E3I2", "arxiv_url": "http://arxiv.org/abs/0806.2006v2", "arxiv_comment": null, "journal_reference": "Revue Nationale des Technologies de l'Information E, 5 (2005)\n  259-268", "doi": null, "fulltext": "Fusion de classifieurs pour la classification d'images sonar\n\narXiv:0806.2006v2 [cs.CV] 6 Jan 2012\n\nArnaud MARTIN\nENSIETA / E3 I2 , EA3876\n2, rue Fran\u00e7ois Verny, 29806 Brest cedex 9\nArnaud.Martin@ensieta.fr\nhttp ://www.ensieta.fr/e3i2\nR\u00e9sum\u00e9. Nous pr\u00e9sentons dans ce papier des approches de fusion d'informations haut niveau applicables pour des donn\u00e9es num\u00e9riques ou des donn\u00e9es symboliques. Nous \u00e9tudions l'int\u00e9r\u00eat des telles approches particuli\u00e8rement pour la\nfusion de classifieurs. Une \u00e9tude comparative est pr\u00e9sent\u00e9e dans le cadre de la\ncaract\u00e9risation des fonds marins \u00e0 partir d'images sonar. Reconna\u0131\u0302tre le type de\ns\u00e9diments sur des images sonar est un probl\u00e8me difficile en soi en partie \u00e0 cause\nde la complexit\u00e9 des donn\u00e9es. Nous comparons les approches de fusion d'informations haut niveau et montrons le gain obtenu.\n\n1 Introduction\nLa fusion d'informations est apparue afin de g\u00e9rer des quantit\u00e9s tr\u00e8s importantes de donn\u00e9es\nmultisources dans le domaine militaire. Depuis quelques ann\u00e9es des m\u00e9thodes de fusion ont\n\u00e9t\u00e9 adapt\u00e9es et d\u00e9velopp\u00e9es pour des applications en traitement du signal. Plusieurs sens sont\ndonn\u00e9s \u00e0 la fusion d'informations, nous reprenons ici la d\u00e9finition propos\u00e9e par (Bloch 2003) :\nLa fusion d'informations consiste \u00e0 combiner des informations issues de plusieurs sources afin\nd'aider \u00e0 la prise de d\u00e9cision.\nNous ne cherchons pas ici \u00e0 r\u00e9duire les redondances contenues dans les informations issues\nde plusieurs sources, mais au contraire \u00e0 en tenir compte afin d'am\u00e9liorer la prise de d\u00e9cision.\nDe m\u00eame nous cherchons \u00e0 mod\u00e9liser au mieux les diff\u00e9rentes imperfections des donn\u00e9es\n(impr\u00e9cisions, incertitudes, conflit, ambigu\u0131\u0308t\u00e9, incompl\u00e9tude, fiabilit\u00e9 des sources, ...) non pas\npour les supprimer, mais encore pour l'aide \u00e0 la d\u00e9cision.\nDiff\u00e9rents niveaux de fusion ont \u00e9t\u00e9 propos\u00e9 dans la litt\u00e9rature. Ce qui est commun\u00e9ment\nretenu, est une division en trois niveaux (Dasarathy 1997), celui des donn\u00e9es (ou bas niveau),\ncelui des caract\u00e9ristiques (i.e. des param\u00e8tres extraits) (ou fusion de niveau interm\u00e9diaire) et\ncelui des d\u00e9cisions (ou fusion de haut niveau).\nLe choix du niveau de fusion doit se faire en fonction des donn\u00e9es disponibles et de l'architecture de la fusion retenue (centralis\u00e9e, distribu\u00e9e, ...) qui sont li\u00e9es \u00e0 l'application recherch\u00e9e.\nAinsi, nous pouvons chercher \u00e0 fusionner des informations issues de diff\u00e9rents capteurs tels\nque des radars de fr\u00e9quences diff\u00e9rentes afin d'estimer au mieux la r\u00e9flexion d'une cible. Dans\nce cas une approche de fusion bas niveau sera pr\u00e9f\u00e9rable.\nDans ce papier, nous consid\u00e9rons une application dans le cadre de la classification. Plusieurs classifieurs peuvent fournir une information sur la classe de l'objet observ\u00e9. Ainsi, nous\nretenons des approches de fusion haut niveau pour r\u00e9soudre un tel probl\u00e8me. Les donn\u00e9es exprimant une d\u00e9cision peuvent \u00eatre de type num\u00e9rique (tel que les sorties des classifieurs) ou\nsymbolique (tel que les classes d\u00e9cid\u00e9es par les classifieurs exprim\u00e9es sous forme de sym-\n\n\fFusion de classifieurs pour la classification d'images sonar\n\nboles). Nous pr\u00e9sentons ici une \u00e9tude comparative des m\u00e9thodes de fusion haut niveau dans le\ncadre de la classification d'images sonar.\nLes images sonar sont caract\u00e9ris\u00e9es par un grand nombre d'imperfections telles que l'incertitude du milieu, les impr\u00e9cisions des mesures et de reconstruction de l'image. C'est pourquoi,\nnous cherchons ici \u00e0 extraire des param\u00e8tres de textures sur ces images, en consid\u00e9rant que la\nphysique du probl\u00e8me a \u00e9t\u00e9 au mieux prise en compte lors de l'\u00e9tape de reconstruction. Nous\nretenons quatre jeux de param\u00e8tres extraits selon quatre m\u00e9thodes diff\u00e9rentes de traitement\nd'images. Les images sonar sont ensuite class\u00e9es par quatre perceptrons multicouche, chacun\nconsid\u00e9rant un des quatre jeux de param\u00e8tres.\nNous pr\u00e9sentons tout d'abord trois grandes classes de m\u00e9thodes de fusion haut niveau, les\napproches par vote, celles issues de la th\u00e9orie des possibilit\u00e9s et celles issues de la th\u00e9orie\ndes croyances. Nous exposons ensuite la complexit\u00e9 des images sonar pour leur classification\nautomatique, ainsi que les quatre m\u00e9thodes retenues pour l'extraction de param\u00e8tres de texture.\nEnfin nous pr\u00e9sentons une \u00e9valuation comparative des m\u00e9thodes de fusion d'informations haut\nniveau selon la configuration retenue pour la classification d'images sonar.\n\n2 M\u00e9thodes de fusion d'informations\nNous pr\u00e9sentons ici trois cadres th\u00e9oriques de fusion d'informations haut niveau, le principe du vote, la th\u00e9orie des possibilit\u00e9s et la th\u00e9orie des croyances. Nous consid\u00e9rons le probl\u00e8me\nde la fusion de m sources Sj afin de d\u00e9terminer une des n classes Ci possibles.\n\n2.1 Principe du vote\nLe principe du vote est la m\u00e9thode de fusion d'informations la plus simple \u00e0 mettre en\noeuvre. Plus qu'une approche de fusion, le principe du vote est une m\u00e9thode de combinaison\nparticuli\u00e8rement adapt\u00e9e aux d\u00e9cisions de type symbolique. Notons Sj (x) = i le fait que la\nsource Sj attribue la classe Ci \u00e0 l'observation x. Nous supposons ici que les classes Ci sont\nexclusives. A chaque source nous associons la fonction indicatrice :\nMij (x)\n\n=\n\n\u001a\n\n1 si Sj (x) = i,\n0 sinon.\n\n(1)\n\nLa combinaison des sources s'\u00e9crit par :\nMkE (x) =\n\nm\nX\n\nMkj (x),\n\n(2)\n\nj=1\n\npour tout k. L'op\u00e9rateur de combinaison est donc associatif et commutatif. La r\u00e8gle du vote\nmajoritaire consiste \u00e0 choisir la d\u00e9cision prise par le maximum de sources, c'est-\u00e0-dire le maximum de MkE . Cependant cette r\u00e8gle simple n'admet pas toujours de solutions dans l'ensemble\ndes classes D = {C1 , . . . , Cn }. En effet, par exemple si le nombre de sources m est paire\net que m/2 sources d\u00e9cident Ci1 et m/2 autres sources disent Ci2 , ou encore dans le cas o\u00f9\nchaque source affecte \u00e0 x une classe diff\u00e9rente. Nous sommes donc oblig\u00e9 d'ajouter une classe\nRNTI - 1\n\n\fArnaud MARTIN\n\nCn+1 qui repr\u00e9sente l'incertitude totale li\u00e9e au conflit des sources sous l'hypoth\u00e8se de l'exhaustivit\u00e9 des classes Cn+1 = {C1 , . . . , Cn }. La d\u00e9cision finale de l'expert prise par cette\nr\u00e8gle s'\u00e9crit donc par :\n\u001a\nk si maxk MkE (x),\nE(x) =\n(3)\nn + 1 sinon.\nCette r\u00e8gle est cependant peu satisfaisante dans les cas o\u00f9 deux sources donnent le maximum\npour des classes diff\u00e9rentes. La r\u00e8gle la plus employ\u00e9e est la r\u00e8gle du vote majoritaire absolu\nqui s'\u00e9crit :\n\u001a\nk si maxk MkE (x) > m\n2,\nE(x) =\n(4)\nn + 1 sinon.\nA partir de cette r\u00e8gle il a \u00e9t\u00e9 d\u00e9montr\u00e9 (Lam et Suen 1997) plusieurs r\u00e9sultats prouvant\nque la m\u00e9thode du vote permet d'obtenir de meilleurs performances que toutes les sources\nprises s\u00e9par\u00e9ment, sous des hypoth\u00e8ses d'ind\u00e9pendance statistique des sources et de m\u00eame\nprobabilit\u00e9, et ceci est d'autant plus vrai que m est impaire.\nIl est possible de g\u00e9n\u00e9raliser le principe du vote majoritaire afin de supprimer le conflit. Au\nlieu de combiner les r\u00e9ponses des sources par une somme simple comme dans l'\u00e9quation (2),\nl'id\u00e9e est d'employer une somme pond\u00e9r\u00e9e (Xu et al. 1992) :\nMkE (x) =\n\nm\nX\n\n\u03b1jk Mkj (x),\n\n(5)\n\nj=1\n\no\u00f9\n\nm X\nn\nX\n\n\u03b1jk = 1. Les poids \u03b1jk repr\u00e9sentent la fiabilit\u00e9 d'une source pour une d\u00e9cision\n\nj=1 k=1\n\ndonn\u00e9e, et l'estimation de ces poids peut se faire \u00e0 partir des taux normalis\u00e9s de r\u00e9ussite pour\nchaque classe et chaque classifieur. Notons qu'alors nous introduisons une connaissance a\npriori non n\u00e9cessaire pr\u00e9c\u00e9demment. Les diff\u00e9rentes r\u00e8gles de d\u00e9cision possibles peuvent se\nr\u00e9sumer par la formule suivante :\n\u001a\nk si MkE (x) = maxi MiE (x) \u2265 c m + b(x),\nE(x) =\n(6)\nn + 1 sinon,\no\u00f9 c est une constante de [0, 1] et b(x) est une fonction de MkE (x).\n\n2.2 Th\u00e9orie des possibilit\u00e9s\nLa th\u00e9orie des possibilit\u00e9s propos\u00e9e par (Zadeh 1978, Dubois et Prade 1988) permet de\ntenir compte de l'impr\u00e9cision des donn\u00e9es ainsi que de l'incertitude \u00e0 partir de deux fonctions\nde possibilit\u00e9 et de n\u00e9cessit\u00e9. Ces deux fonctions sont obtenues \u00e0 partir des distributions de\npossibilit\u00e9s d\u00e9finies sur D = {C1 , . . . , Cn } par :\n\u03c0 : D \u2192 [0, 1], sup \u03c0(x) = 1.\n\n(7)\n\nx\u2208D\n\nCes distributions donnent le degr\u00e9 d'appartenance au domaine D, qui n'est autre qu'un op\u00e9rateur\nflou. Afin d'extraire l'impr\u00e9cision et l'incertitude des donn\u00e9es, deux fonctions sp\u00e9cifiques sont\nRNTI - 1\n\n\fFusion de classifieurs pour la classification d'images sonar\n\nd\u00e9finies \u00e0 partir de ces distributions. La fonction de possibilit\u00e9 est d\u00e9finie pour tout A \u2208 2D\npar :\n\u03a0(A) = sup \u03c0(x).\n\n(8)\n\nx\u2208A\n\nLa fonction de n\u00e9cessit\u00e9 est donn\u00e9e pour tout A \u2208 2D par :\nN (A) = 1 \u2212 \u03a0(Ac ),\n\n(9)\n\no\u00f9 Ac repr\u00e9sente l'\u00e9v\u00e8nement contraire de A.\nUn des avantages de la th\u00e9orie des possibilit\u00e9s est le nombre d'op\u00e9rateurs de combinaison\ndisponibles. Il est ainsi possible de combiner l'information issue des distributions de possibilit\u00e9, \u00e0 partir d'op\u00e9rateurs de type t-norme, t-conorme, moyenne, sommes sym\u00e9triques, etc...\nLe choix du type de combinaison est un probl\u00e8me d\u00e9licat a priori dans la th\u00e9orie des possibilit\u00e9s, et doit \u00eatre fait selon l'application et l'objectif recherch\u00e9. Ce choix peut se faire selon le\ncomportement g\u00e9n\u00e9ral de l'op\u00e9rateur (conjonctif, disjonctif, ou des compromis), selon les propri\u00e9t\u00e9s d\u00e9sir\u00e9es, selon sa capacit\u00e9 \u00e0 discriminer les classes, ou encore selon son comportement\ndans des situations de conflit. En pratique de nombreux op\u00e9rateurs sont employ\u00e9s et test\u00e9s dans\nles applications, tels que max (op\u00e9rateur de type t-norme), min (op\u00e9rateur de type t-conorme),\nou la moyenne, la m\u00e9diane et les int\u00e9grales floues (op\u00e9rateurs de type moyenne).\nLa derni\u00e8re \u00e9tape de la fusion d'informations est l'\u00e9tape de d\u00e9cision. Dans le cadre de la\nth\u00e9orie des possibilit\u00e9s, elle est g\u00e9n\u00e9ralement faite selon la r\u00e8gle suivante : la classe Ck est\nd\u00e9cid\u00e9e pour l'observation x si :\nCk = argmax \u03bci (x),\n\n(10)\n\n1\u2264i\u2264n\n\no\u00f9 \u03bci (x) repr\u00e9sente le coefficient d'appartenance de x \u00e0 la classe Ci , qui sera ici donn\u00e9 par les\nsorties du classifieur.\nPar construction des op\u00e9rateurs de combinaison et de la r\u00e8gle de d\u00e9cision, la th\u00e9orie des\npossibilit\u00e9s est davantage adapt\u00e9e \u00e0 la fusion d'informations de type num\u00e9rique. Ainsi les\ncoefficients d'appartenance peuvent \u00eatre facilement obtenus dans le cadre de la classification\npar les sorties num\u00e9riques des classifieurs. Nous emploierons donc ici cette th\u00e9orie pour la\nfusion d'informations haut niveau sur des donn\u00e9es de type num\u00e9rique.\n\n2.3 Th\u00e9orie des croyances\nLa th\u00e9orie des croyances (ou th\u00e9orie de Dempster-Shafer) permet \u00e9galement de repr\u00e9senter\n\u00e0 la fois l'impr\u00e9cision et l'incertitude au travers deux fonctions : la fonction de croyance\net la fonction de plausibilit\u00e9 (Bloch 2003, Appriou 2002). Ces deux fonctions sont d\u00e9riv\u00e9es\ndes fonctions de masses. Le principe de la th\u00e9orie des croyances repose sur la manipulation\nde ces fonctions de masse d\u00e9finies sur des sous-ensembles et non sur des singletons comme\ndans la th\u00e9orie des probabilit\u00e9s. En effet, elles sont d\u00e9finies sur chaque sous-espace de l'ensemble des disjonctions du cadre de discernement D = {C1 , . . . , Cn } et \u00e0 valeurs dans [0, 1].\nG\u00e9n\u00e9ralement, il est ajout\u00e9 une condition donn\u00e9e par :\nX\nmj (A) = 1,\n(11)\nA\u22082D\n\nRNTI - 1\n\n\fArnaud MARTIN\n\no\u00f9 m(.) repr\u00e9sente la fonction de masse. Dans cette th\u00e9orie la premi\u00e8re difficult\u00e9 est le choix\nde la fonction de masse. Plusieurs approches ont \u00e9t\u00e9 propos\u00e9es, nous en retenons ici deux :\nl'une fond\u00e9e sur un mod\u00e8le probabiliste (Appriou 2002) et l'autre sur une transformation en\ndistance (Denoeux 1995).\n(Appriou 2002) propose deux mod\u00e8les r\u00e9pondant \u00e0 trois axiomes qui impliquent la consid\u00e9ration\nde n \u2217 m fonctions de masse aux seuls \u00e9l\u00e9ments focaux possibles {Ci }, {Cic } et D. Un axiome\ngarantit de plus l'\u00e9quivalence avec l'approche bay\u00e9sienne dans le cas o\u00f9 la r\u00e9alit\u00e9 est parfaitement connue (m\u00e9thode optimale dans ce cas). Ces deux mod\u00e8les sont sensiblement \u00e9quivalents\nsur nos donn\u00e9es, nous utilisons dans cet article le mod\u00e8le donn\u00e9 par :\n\uf8f1\n\u03b1ij Rj p(Sj /Ci )\n\uf8f4\n\uf8f2 mij (Ci )(x) = 1+Rj p(Sj /Ci )\n\u03b1ij Rj\n(12)\nmij (Cic )(x) = 1+Rj p(S\nj /Ci )\n\uf8f4\n\uf8f3\nmij (D)(x) = 1 \u2212 \u03b1ij\n\u22121\n\no\u00f9 p est une probabilit\u00e9, Rj = (maxi,j p(Sj /Ci )) est un facteur de normalisation, et \u03b1ij \u2208\n[0, 1] est un coefficient d'affaiblissement permettant de tenir compte de la fiabilit\u00e9 d'une source\nSj pour une classe Ci , que nous choisissons ici \u00e9gale \u00e0 1.\nLa difficult\u00e9 de ce mod\u00e8le est alors l'estimation des probabilit\u00e9s p(Sj /Ci ). Dans le cas o\u00f9\nla donn\u00e9e de la source Sj est la r\u00e9ponse d'un classifieur exprim\u00e9e sous la forme de la classe\n(donn\u00e9e symbolique), l'estimation de ces probabilit\u00e9s peut \u00eatre faite par les matrices de confusion sur une base d'apprentissage. Si la r\u00e9ponse du classifieur est une donn\u00e9e num\u00e9rique, l'estimation de telles probabilit\u00e9s peut se faire soit par une approche fond\u00e9e sur les fr\u00e9quences, soit\nsous l'hypoth\u00e8se de la distribution suivie par ces probabilit\u00e9s. Dans ce dernier cas l'estimation\nest g\u00e9n\u00e9ralement plus d\u00e9licate, nous retiendrons donc ce mod\u00e8le pour la fusion d'informations\nhaut niveau des donn\u00e9es symboliques.\nEn revanche l'approche fond\u00e9e sur une transformation en distance propos\u00e9e par (Denoeux\n1995) est plus adapt\u00e9e \u00e0 la fusion d'informations haut niveau des donn\u00e9es num\u00e9riques. En\neffet, les fonctions de masse sont d\u00e9finies par :\n\u0001\n\u001a\nmij (Ci /x(t) )(x) = \u03b1ij \u03c6i d(x, x(t) )\n\u0001\n(13)\nmij (D/x(t) )(x) = 1 \u2212 \u03b1ij \u03c6i d(x, x(t) )\n\u0001\no\u00f9 x(t) est un vecteur d'apprentissage des r\u00e9ponses des sources, \u03b1ij \u2208 [0, 1] est un coefficient\nd'affaiblissement, d est une distance \u00e0 d\u00e9terminer entre x et x(t) , Ci est la classe associ\u00e9e \u00e0\nx(t) , et \u03c6i est une fonction v\u00e9rifiant :\n(\n\u03c6i (0) = 1,\n(14)\nlim \u03c6i (d) = 0.\nd\u2192+\u221e\n\nIl existe un grand nombre de fonctions \u03c6i v\u00e9rifiant ces \u00e9galit\u00e9s, sans qu'il y ait une m\u00e9thode\npour le choix de ces fonctions. Dans le cas d'une distance euclidienne, Denoeux propose la\nfonction :\n\u03c6i (d) = exp(\u03b3i d2 ),\n\n(15)\n\no\u00f9 \u03b3i > 0 est un param\u00e8tre associ\u00e9 \u00e0 la classe Ci . \u03b3i peut \u00eatre initialis\u00e9 comme l'inverse de la\ndistance moyenne entre les vecteurs d'apprentissage v\u00e9rifiant Ci . La distance d(x, x(t) ) peut\nRNTI - 1\n\n\fFusion de classifieurs pour la classification d'images sonar\n\n\u00eatre consid\u00e9r\u00e9e uniquement pour les k-plus proches voisins de x afin de r\u00e9duire le temps de\ncalcul.\nLa diff\u00e9rence de fond avec les mod\u00e8les d'Appriou est qu'ici il faut estimer une distance\nau lieu d'une probabilit\u00e9. La distance, g\u00e9n\u00e9ralement euclidienne est plus adapt\u00e9e aux donn\u00e9es\nnum\u00e9riques, tandis que l'estimation des probabilit\u00e9s est ici plus ais\u00e9e pour des donn\u00e9es symboliques. Dans le cas d'une distance euclidienne, notons que nous obtenons une fonction de\nmasse proche de celle obtenue par un mod\u00e8le d'Appriou sous l'hypoth\u00e8se d'une distribution\ngaussienne. Nous comparons donc ces deux approches pour la fusion d'informations avec des\ndonn\u00e9es de type sym\u00e9trique pour le mod\u00e8le probabiliste et num\u00e9rique pour le mod\u00e8le des distances.\nLa combinaison des fonctions de masse est fond\u00e9e sur la r\u00e8gle orthogonale de DempsterShafer non normalis\u00e9e propos\u00e9e par (Smets 1990) d\u00e9finie pour deux fonctions de masse m1 et\nm2 et pour tout A \u2208 2D par :\nm(A) = (m1 \u2295 m2 )(A) =\n\nX\n\nm1 (B)m2 (C).\n\n(16)\n\nB\u2229C=A\n\nCette op\u00e9rateur est associatif et commutatif. La masse affect\u00e9e sur l'ensemble vide s'interpr\u00e8te\ncomme une mesure de conflit. Pour les mod\u00e8les d'Appriou et de Denoeux, nous obtenons donc\nune unique fonction de masse en combinant les fonctions mij .\nLa derni\u00e8re \u00e9tape de la fusion est la d\u00e9cision sur la classe la plus vraisemblable. La th\u00e9orie\ndes croyances offrent plusieurs r\u00e8gles de d\u00e9cision fond\u00e9es sur la maximisation d'un crit\u00e8re. En\nparticulier, nous pouvons employer le maximum des fonctions de croyance ou des fonctions\nde plausibilit\u00e9. Si les premi\u00e8res peuvent \u00eatre trop pessimistes, les secondes peuvent \u00eatre trop\noptimistes. Un compromis est le maximum des probabilit\u00e9s pignistiques propos\u00e9es par (Smets\n1990) qui est le crit\u00e8re retenu dans cet article.\n\n3 Classification d'images sonar\nLa classification des images sonar est un probl\u00e8me difficile en soi. Les m\u00e9thodes de caract\u00e9risation automatique consistent en des m\u00e9thodes d'analyse de texture, les images de fonds\nmarins pr\u00e9sentant en effet des zones de s\u00e9diments homog\u00e8nes ou non qui peuvent s'apparenter\n\u00e0 des textures. La litt\u00e9rature concernant les m\u00e9thodes d'analyse de la texture est abondante et le\nchoix de l'une ou de plusieurs d'entre elles d\u00e9pend tr\u00e8s souvent de l'image et de l'application.\nCes m\u00e9thodes fournissent g\u00e9n\u00e9ralement un ensemble assez restreint de param\u00e8tres pertinents\nqui permettent de classer l'image en un ou plusieurs type de s\u00e9diments. Nous exposons ici\ntoute la complexit\u00e9 des images sonar due aux nombreuses imperfections, puis nous pr\u00e9sentons\nles classifieurs \u00e0 base de m\u00e9thodes d'analyse de texture.\nLes images sonar sont obtenues \u00e0 partir des mesures temporelles faites en tra\u0131\u0302nant \u00e0 l'arri\u00e8re\nd'un bateau un sonar qui peut \u00eatre lat\u00e9ral, frontal, ou multifaisceaux. Chaque signal \u00e9mis est\nr\u00e9fl\u00e9chi sur le fond puis re\u00e7u sur l'antenne du sonar avec un d\u00e9calage et une intensit\u00e9 variable.\nPour la reconstruction sous forme d'images un grand nombre de donn\u00e9es physiques (g\u00e9om\u00e9trie\ndu dispositif, coordonn\u00e9es du bateau, mouvements du sonar, ...) est pris en compte, mais elles\nsont entach\u00e9es des bruits de mesures dues \u00e0 l'instrumentation. A ceci viennent s'ajouter des\ninterf\u00e9rences dues \u00e0 des trajets multiples du signal (sur le fond ou la surface), \u00e0 des bruits de\nRNTI - 1\n\n\fArnaud MARTIN\n\nchatoiement, ou encore \u00e0 la faune et \u00e0 la flore. Les images sont donc entach\u00e9es d'un grand\nnombres d'imperfections telles que l'impr\u00e9cision et l'incertitude.\n26 images fournies par le GESMA (Groupe d'Etudes Sous-Marine de l'Atlantique) ont\n\u00e9t\u00e9 obtenues \u00e0 partir d'un sonar Klein 5400 permettant une bonne r\u00e9solution. Ces images ont\n\u00e9t\u00e9 segment\u00e9es en imagettes de taille 64 \u00d7 64 pixels (voir Tab. 1) \u00e9tiquet\u00e9es selon le type de\ns\u00e9diment. Nous avons ainsi distingu\u00e9 le sable (54.52%), la roche (21.35%), les rides de sable\n\nSable\n\nRide\n\nRoche\n\nSable\net Roche\n\nCailloutis\n\nRide\net Sable\n\nTABLE 1 \u2013 Exemple d'image sonar (fournit par le GESMA) et d'imagettes extraites et\n\u00e9tiquet\u00e9es.\n(8.80%), la vase (5.50%), les cailloutis (0.77%) et l'ombre (2.40%) qui repr\u00e9sente l'absence\nd'information sur le type de s\u00e9diment. De plus, nous avons indiqu\u00e9 lorsque ces imagettes comprennent plus d'un s\u00e9diment (homog\u00e8nes ou non), ce qui repr\u00e9sente 39.70% des imagettes.\nLe type de s\u00e9diment de ces imagettes est le plus pr\u00e9sent. Notons \u00e9galement que ces bases\nde donn\u00e9es sont tr\u00e8s d\u00e9licates \u00e0 r\u00e9aliser, car elles sont entach\u00e9es des erreurs \u00e9ventuelles de\nl'expert.\nLes classifieurs sont compos\u00e9s chacun d'une m\u00e9thode d'extraction de param\u00e8tres de texture et d'un perceptron multicouche. L'approche retenue pour l'architecture de fusion est celle\npr\u00e9sent\u00e9e sur la Fig. 1. La fusion d'informations haut niveau se fait donc soit au niveau des sorties num\u00e9riques des perceptrons soit au niveau des sorties symboliques repr\u00e9sentant les classes\naffect\u00e9es.\nLes m\u00e9thodes d'extraction de param\u00e8tres de texture sont celles d\u00e9j\u00e0 pr\u00e9sent\u00e9es dans (Martin et al. 2004). Chaque m\u00e9thode permet de calculer des param\u00e8tres diff\u00e9rents, parfois redondants entre eux, mais avec des caract\u00e9ristiques propres \u00e0 la m\u00e9thode.\nLes matrices de co-occurrence sont calcul\u00e9es en comptant les occurrences identiques de\nniveaux de gris entre deux pixels contigus. Quatre directions sont consid\u00e9r\u00e9es : 0, 45, 90 et 135\ndegr\u00e9s. Dans ces quatre directions six param\u00e8tres d'Haralick sont calcul\u00e9s : l'homog\u00e9n\u00e9it\u00e9,\nle contraste, l'entropie, la corr\u00e9lation et l'uniformit\u00e9. Un des probl\u00e8mes principaux de cette\napproche est la non invariance en translation. Ainsi les imagettes de rides auront des param\u00e8tres\ndiff\u00e9rents selon la direction de celles-ci.\nLes matrices de longueurs de plages sont obtenues en comptabilisant les pixels cons\u00e9cutifs\nposs\u00e9dant le m\u00eame niveau de gris dans les quatre directions pr\u00e9c\u00e9demment consid\u00e9r\u00e9es. Dans\nchacune des directions cinq param\u00e8tres sont calcul\u00e9s : la proportion de petite longueur de plage,\nla dispersion des plages entre les niveaux de gris et entre les longueurs et le pourcentage des\nRNTI - 1\n\n\fFusion de classifieurs pour la classification d'images sonar\n\nF IGURE 1 \u2013 Architecture de fusion de classifieurs retenue.\nlongueurs de plage. Cette approche est bien adapt\u00e9e aux images optiques faiblement bruit\u00e9es.\nDans le cas des images sonar, o\u00f9 un bruit de chatoiement est fortement pr\u00e9sent, il faudrait\nsoit supprimer ce bruit soit adapter le calcul des param\u00e8tres. Nous conservons cependant cette\napproche afin d'\u00e9valuer la robustesse de la fusion aux mauvais param\u00e8tres de texture.\nLa troisi\u00e8me approche retenue est une transform\u00e9e en ondelettes. Les deux approches\npr\u00e9c\u00e9dentes ne permettent pas de tenir compte de l'invariance dans les directions. La transform\u00e9e en ondelettes discr\u00e8te invariante en translation est fond\u00e9e sur le choix de la transformation optimale pour chaque niveau de d\u00e9composition. Chaque niveau de d\u00e9composition fournit\nquatre images, sur lesquelles nous calculons trois param\u00e8tres : l'\u00e9nergie, l'entropie, et une\nmoyenne. Nous retenons un niveau de d\u00e9composition de trois ce qui fournit 63 param\u00e8tres au\nclassifieur.\nEnfin, une approche fond\u00e9e sur les filtres de Gabor permet de r\u00e9soudre le probl\u00e8me des\nrides. En effet, nous consid\u00e9rons cinq fr\u00e9quences diff\u00e9rentes pour six directions ce qui donne\ntrente filtres. Sur ces filtres, nous calculons quatre param\u00e8tres statistiques : le maximum de\nl'\u00e9cart-type d'un s\u00e9diment consid\u00e9r\u00e9, la moyenne de tous les filtres, la moyenne dans la direction horizontale (celle des pings du sonar) et l'\u00e9cart-type avant filtrage.\nCes quatre jeux de param\u00e8tres sont ensuite consid\u00e9r\u00e9s ind\u00e9pendamment \u00e0 l'entr\u00e9e de quatre\nperceptrons multicouche ayant ainsi des couches d'entr\u00e9e de 24, 63, 20 et 4 neurones et une\ncouche de sortie de 6 neurones correspondant aux six classes de s\u00e9diments consid\u00e9r\u00e9s. L'apprentissage est r\u00e9alis\u00e9 pour une fonction sigmo\u0131\u0308de de sortie donnant ainsi pour chacun des\nneurones k de la couche de sortie une valeur r\u00e9elle ok \u2208 [0, 1]. Ces valeurs ok constituent\nles donn\u00e9es num\u00e9riques sur la d\u00e9cision des classifieurs. Les d\u00e9cisions symboliques sont obtenues en consid\u00e9rant pour chaque classifieur le maximum des ok , indiquant ainsi la classe Ck\npr\u00e9f\u00e9r\u00e9e par chaque perceptron.\n\n4 R\u00e9sultats\nLa base de donn\u00e9es a \u00e9t\u00e9 divis\u00e9e al\u00e9atoirement en trois parties \u00e9gales. La premi\u00e8re sert \u00e0\nl'apprentissage des perceptrons multicouche, la deuxi\u00e8me \u00e0 l'apprentissage de la fusion et la\ntroisi\u00e8me pour les tests. Afin d'accro\u0131\u0302tre la qualit\u00e9 de l'estimation des taux de classification,\nnous avons r\u00e9p\u00e9t\u00e9 le tirage al\u00e9atoire 10 fois et moyenn\u00e9 les r\u00e9sultats. Dans l'approche par vote\nRNTI - 1\n\n\fArnaud MARTIN\n\nCoocc.\n70.0\n\nlongueur\nde plages\n50.3\n\nondel.\n\nGabor\n\nPMC\n\nvote\n\nposs.\n\n68.9\n\n66.4\n\n50.0\n\n62.0\n\n69.9\n\ncroyances\nproba. distance\n68.8\n79.5\n\nTABLE 2 \u2013 Taux de classification avant et apr\u00e8s fusion d'informations (%).\nroche\nride\ncailloutis\nhomog\u00e8nes\n\n87.3\n61.3\n0.9\n91.3\n\nsable\nvase\nombre\nnon homog\u00e8nes\n\n84.9\n4.9\n71.5\n63.1\n\nTABLE 3 \u2013 taux de classification par type de s\u00e9diment pour le mod\u00e8le de distance (%).\nmajoritaire nous avons obtenu un conflit de 18.59%, afin de supprimer ce conflit nous avons\nconsid\u00e9r\u00e9 l'approche avec les pond\u00e9rations \u03b1jk estim\u00e9es par les matrices de confusion. Dans\nle cadre de la th\u00e9orie des possibilit\u00e9s de nombreux op\u00e9rateurs de combinaison ont \u00e9t\u00e9 test\u00e9s ;\nnous pr\u00e9sentons ici celui donnant les r\u00e9sultats les plus probants donn\u00e9s par l'op\u00e9rateur max\n(t-conorme).\nLe Tab. 2 pr\u00e9sente les taux de bonne classification d\u00e9finis par le rapport du nombre d'imagettes bien class\u00e9es sur le nombre total d'imagettes de la base de test. Nous constatons que\nles quatre m\u00e9thodes de fusion pr\u00e9sent\u00e9es sont plus robustes aux donn\u00e9es erron\u00e9es fournies par\nles longueurs de plages que le PMC (perceptron global prenant en entr\u00e9e l'ensemble des param\u00e8tres extraits). Cependant la fusion par vote reste moins bonne que les trois classifieurs\nissus des matrices de co-occurence, ondelettes et Gabor, les hypoth\u00e8ses de (Lam et Suen 1997)\nne sont pas v\u00e9rifi\u00e9es. Les deux approches de fusion d'informations haut niveau \u00e0 partir des\ndonn\u00e9es num\u00e9riques sont plus performantes que les approches \u00e0 partir des donn\u00e9es symboliques. Notons de plus que la th\u00e9orie des croyances avec le mod\u00e8le de distance donne significativement les meilleurs r\u00e9sultats que nous d\u00e9taillons dans le Tab. 3. Les meilleurs taux sont\natteints pour les s\u00e9diments sable et roche, ceci est d\u00fb \u00e0 l'apprentissage du perceptron qui est\nmeilleur pour les s\u00e9diments les plus repr\u00e9sent\u00e9s num\u00e9riquement. Les cailloutis et la vase offrent\nde mauvais r\u00e9sultats car leur effectif est faible dans la base. Notons encore que les taux pour\nles imagettes homog\u00e8nes sont bien meilleurs, mais est-il raisonnable de chercher \u00e0 affecter un\ntype de s\u00e9diment \u00e0 une imagette qui en contient plusieurs. Ceci doit entra\u0131\u0302ner une remise en\ncause de la constitution m\u00eame de la base de donn\u00e9es.\n\n5 Conclusion\nNous avons \u00e9tudi\u00e9 les diff\u00e9rentes approches de fusion d'informations haut niveau, en faisant ressortir leurs avantages et inconv\u00e9nients, et notamment la facilit\u00e9 pour chacune d'entre\nelles \u00e0 \u00eatre employ\u00e9es pour des donn\u00e9es num\u00e9riques et symboliques. Ces approches ont \u00e9t\u00e9\ncompar\u00e9es dans le cadre d'une application particuli\u00e8rement d\u00e9licate : la classification d'images\nsonar. En effet, nous avons vu la complexit\u00e9 pour l'expert \u00e0 interpr\u00e9ter ces images, et la difficult\u00e9 de les classer automatiquement. La fusion d'informations apporte une solution int\u00e9ressante\nRNTI - 1\n\n\fFusion de classifieurs pour la classification d'images sonar\n\npour la r\u00e9solution de tels probl\u00e8mes particuli\u00e8rement gr\u00e2ce \u00e0 sa facilit\u00e9 de mise en oeuvre\npour des applications de classification. Nous avons ici fait ressortir de meilleures performances pour la fusion d'informations haut niveau \u00e0 partir de donn\u00e9es num\u00e9riques et plus particuli\u00e8rement dans le cadre de la th\u00e9orie des croyances. Cependant, nous devons bien nous\ngarder de g\u00e9n\u00e9raliser de tels r\u00e9sultats \u00e0 tout type de donn\u00e9es.\nPour cette application nous avons fait ressortir l'influence du sur-apprentissage du perceptron employ\u00e9 qui provient de la diff\u00e9rence d'effectifs des s\u00e9diments dans la base de donn\u00e9es.\nLa gestion des \u00e9v\u00e8nements rares peut \u00eatre r\u00e9alis\u00e9e par la fusion, mais dans ce cas avant le\nclassifieur. Une fusion d'informations bas niveau doit alors \u00eatre envisag\u00e9e. Une autre difficult\u00e9\nest issue de la constitution m\u00eame de la base. Le fait d'avoir des imagettes poss\u00e9dant plusieurs\ns\u00e9diments augmente l'incertitude, qui est dans ce cas dure \u00e0 mesurer. Nous travaillons sur la\nr\u00e9alisation d'une base de zones homog\u00e8nes o\u00f9 l'incertitude sera mesurable plus finement.\n\nR\u00e9f\u00e9rences\nAppriou, A. (2002), Discrimination multisignal par la th\u00e9orie de l'\u00e9vidence, In D\u00e9cision et\nReconnaissance des formes en signal, Hermes Science Publication, pp 219-258, 2002.\nBloch, I. (2003), Fusion d'informations en traitement du signal et des images, Lavoisier (eds),\nHermes Science Publication, 2003.\nDasarathy, B.V. (1997), Sensor Fusion Potential Exploitation - Innovative Architechtures and\nIllustrative Applications, Proceeding of the IEEE 1997, 85(1), pp 24-38.\nDenoeux, T. (1995), A k-Nearest Neighbor Classification Rule Based on Dempster-Shafer\nTheory, IEEE Transactions on Systems, Man Cybernetics 1995, 25(5), pp 804-813.\nDubois, D. et Prade, H. (1988), Possibility Theory, Plenum Press, New York, 1988.\nLam, L. et Suen, C.Y. (1997), Application of Majority Voting to Pattern Recognition : An Analysis of Its Behavior and Performance, IEEE Transactions on Systems, Man Cybernetics\n1997, 27(5), pp 553-568.\nMartin, A., S\u00e9vellec, G. et Leblond, I. (2004), Characteristics vs decision fusion for sea-bottom\ncharacterization, Caract\u00e9risation in-situ des fonds marins, Brest, France, 2004.\nSmets, Ph. (1990), The Combinaison of Evidence in the Transferable Belief Model, IEEE\nTransactions on Pattern Analysis and Machine Intelligence 1990, 12(5), pp 447-458.\nXu, B.V., Krzyzak, A. et Suen, C.Y. (1992), Methods of Combining Multiple Classifiers and\nTheir Application to Handwriting Recognition, IEEE Transactions on Systems, Man Cybernetics 1992, 22(3), pp 418-435.\nZadeh, L.A. (1978), Fuzzy Sets as a Basis For a Theory of Possibility, Fuzzy Sets and Systems\n1978, 1, pp 3-28.\n\nSummary\nIn this paper, we present some high level information fusion approaches for numeric and\nsymbolic data. We study the interest of such method particularly for classifier fusion. A comparative study is made in a context of sea bed characterization from sonar images. The classiRNTI - 1\n\n\fArnaud MARTIN\n\nfication of kind of sediment is a difficult problem because of the data complexity. We compare\nhigh level information fusion and give the obtained performance.\n\nRNTI - 1\n\n\f11\n00\n00\n11\n00\n11\n00\n11\n00\n11\n00\n11\n00\n11\n00\n11\n00\n11\n00\n11\n00\n11\n00\n11\nBas Niveau\n\nDiff\u00e9rentes Sources\nDonn\u00e9es\n\nNiveau Interm\u00e9diare\n\nHaut Niveau\n\nDiff\u00e9rentes actions\nS\u00e9lection, transformation (fouille de donn\u00e9es)\nExtraction d'informations, estimation\n\nCaract\u00e9ristiques\n\n11\n00\n00\n11\n\nD\u00e9cisions\n\nClassification, D\u00e9tection, Identification, Reconnaissance\nFUSION de donn\u00e9es, de caract\u00e9ristiques, de d\u00e9cisions\n\n11\n00\n00\n11\n00\n11\n00\n11\n11\n00\n00\n11\n00\n11\n\n\f\f"}