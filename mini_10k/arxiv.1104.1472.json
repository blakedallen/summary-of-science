{"id": "http://arxiv.org/abs/1104.1472v1", "guidislink": true, "updated": "2011-04-08T03:15:43Z", "updated_parsed": [2011, 4, 8, 3, 15, 43, 4, 98, 0], "published": "2011-04-08T03:15:43Z", "published_parsed": [2011, 4, 8, 3, 15, 43, 4, 98, 0], "title": "Gaussian Affine Feature Detector", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1104.0939%2C1104.0493%2C1104.4313%2C1104.5695%2C1104.5117%2C1104.0141%2C1104.3000%2C1104.5102%2C1104.4832%2C1104.3120%2C1104.2178%2C1104.3014%2C1104.1554%2C1104.3518%2C1104.0315%2C1104.1040%2C1104.1349%2C1104.4331%2C1104.4835%2C1104.2570%2C1104.1720%2C1104.3949%2C1104.0420%2C1104.4399%2C1104.3654%2C1104.5608%2C1104.1459%2C1104.5573%2C1104.3952%2C1104.4535%2C1104.5423%2C1104.0301%2C1104.0843%2C1104.3429%2C1104.1313%2C1104.1233%2C1104.4986%2C1104.3883%2C1104.2463%2C1104.0547%2C1104.1366%2C1104.4017%2C1104.0258%2C1104.3159%2C1104.1472%2C1104.3141%2C1104.2226%2C1104.0434%2C1104.0146%2C1104.3928%2C1104.5030%2C1104.5207%2C1104.3575%2C1104.1330%2C1104.1481%2C1104.5042%2C1104.1495%2C1104.2802%2C1104.2048%2C1104.2858%2C1104.2566%2C1104.4929%2C1104.5156%2C1104.0931%2C1104.1882%2C1104.2443%2C1104.0579%2C1104.2160%2C1104.3770%2C1104.2069%2C1104.4452%2C1104.1290%2C1104.3457%2C1104.1811%2C1104.5314%2C1104.4565%2C1104.2784%2C1104.2984%2C1104.4159%2C1104.5236%2C1104.0232%2C1104.1645%2C1104.3231%2C1104.0512%2C1104.4201%2C1104.3171%2C1104.4956%2C1104.0550%2C1104.3692%2C1104.1129%2C1104.1553%2C1104.1974%2C1104.5341%2C1104.3440%2C1104.5610%2C1104.3897%2C1104.2446%2C1104.1921%2C1104.4107%2C1104.5439%2C1104.2897&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Gaussian Affine Feature Detector"}, "summary": "A new method is proposed to get image features' geometric information. Using\nGaussian as an input signal, a theoretical optimal solution to calculate\nfeature's affine shape is proposed. Based on analytic result of a feature\nmodel, the method is different from conventional iterative approaches. From the\nmodel, feature's parameters such as position, orientation, background\nluminance, contrast, area and aspect ratio can be extracted. Tested with\nsynthesized and benchmark data, the method achieves or outperforms existing\napproaches in term of accuracy, speed and stability. The method can detect\nsmall, long or thin objects precisely, and works well under general conditions,\nsuch as for low contrast, blurred or noisy images.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1104.0939%2C1104.0493%2C1104.4313%2C1104.5695%2C1104.5117%2C1104.0141%2C1104.3000%2C1104.5102%2C1104.4832%2C1104.3120%2C1104.2178%2C1104.3014%2C1104.1554%2C1104.3518%2C1104.0315%2C1104.1040%2C1104.1349%2C1104.4331%2C1104.4835%2C1104.2570%2C1104.1720%2C1104.3949%2C1104.0420%2C1104.4399%2C1104.3654%2C1104.5608%2C1104.1459%2C1104.5573%2C1104.3952%2C1104.4535%2C1104.5423%2C1104.0301%2C1104.0843%2C1104.3429%2C1104.1313%2C1104.1233%2C1104.4986%2C1104.3883%2C1104.2463%2C1104.0547%2C1104.1366%2C1104.4017%2C1104.0258%2C1104.3159%2C1104.1472%2C1104.3141%2C1104.2226%2C1104.0434%2C1104.0146%2C1104.3928%2C1104.5030%2C1104.5207%2C1104.3575%2C1104.1330%2C1104.1481%2C1104.5042%2C1104.1495%2C1104.2802%2C1104.2048%2C1104.2858%2C1104.2566%2C1104.4929%2C1104.5156%2C1104.0931%2C1104.1882%2C1104.2443%2C1104.0579%2C1104.2160%2C1104.3770%2C1104.2069%2C1104.4452%2C1104.1290%2C1104.3457%2C1104.1811%2C1104.5314%2C1104.4565%2C1104.2784%2C1104.2984%2C1104.4159%2C1104.5236%2C1104.0232%2C1104.1645%2C1104.3231%2C1104.0512%2C1104.4201%2C1104.3171%2C1104.4956%2C1104.0550%2C1104.3692%2C1104.1129%2C1104.1553%2C1104.1974%2C1104.5341%2C1104.3440%2C1104.5610%2C1104.3897%2C1104.2446%2C1104.1921%2C1104.4107%2C1104.5439%2C1104.2897&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A new method is proposed to get image features' geometric information. Using\nGaussian as an input signal, a theoretical optimal solution to calculate\nfeature's affine shape is proposed. Based on analytic result of a feature\nmodel, the method is different from conventional iterative approaches. From the\nmodel, feature's parameters such as position, orientation, background\nluminance, contrast, area and aspect ratio can be extracted. Tested with\nsynthesized and benchmark data, the method achieves or outperforms existing\napproaches in term of accuracy, speed and stability. The method can detect\nsmall, long or thin objects precisely, and works well under general conditions,\nsuch as for low contrast, blurred or noisy images."}, "authors": ["Xiaopeng Xu", "Xiaochun Zhang"], "author_detail": {"name": "Xiaochun Zhang"}, "author": "Xiaochun Zhang", "arxiv_comment": "A paper about two dimension image signal detection, including\n  position, length, width, height, orentation", "links": [{"href": "http://arxiv.org/abs/1104.1472v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1104.1472v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1104.1472v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1104.1472v1", "journal_reference": null, "doi": null, "fulltext": "JOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007\n\n1\n\nGaussian Affine Feature Detector\nXiaopeng Xu, Xiaochun Zhang\n\narXiv:1104.1472v1 [cs.CV] 8 Apr 2011\n\nAbstract-A new method is proposed to get image features' geometric information. Using Gaussian as an input signal, a\ntheoretical optimal solution to calculate feature's affine shape is proposed. Based on analytic result of a feature model, the\nmethod is different from conventional iterative approaches. From the model, feature's parameters such as position, orientation,\nbackground luminance, contrast, area and aspect ratio can be extracted.\nTested with synthesized and benchmark data, the method achieves or outperforms existing approaches in term of accuracy,\nspeed and stability. The method can detect small, long or thin objects precisely, and works well under general conditions, such\nas for low contrast, blurred or noisy images.\nIndex Terms-LoG, DoG, differential geometry, Hessian, Harris, affine, Fourier, Laplacian.\n\n1 I NTRODUCTION\nDetecting two dimension signals is more difficult than one\ndimension ones and many heuristic algorithms are proposed\nto deal with it. However, following appearance of scale\nspace theory [12], [7], many effective feature detectors\ncome into being [5].\nOriginally, scale space theory is proposed by physicists, and developed by computer scientists. It is studied\nthoroughly from view point of vision and mathematics,\nand a consistent way to find new detector had been built\n[2]. Many successful feature detectors are built upon scale\nspace, including [3], [15].\nAn additional dimension is introduced in scale space,\nnamely scale dimension. In order to get image's information, such as affine shape parameters, some methods [9],\n[6], [4] iteratively search in scale dimension. They are based\non fix point theory: they will finally get a solution if there\nis one. In practice, however, these methods have several\ndrawbacks, including,\n\u2022 waste lots of candidate features;\n\u2022 very slow;\n\u2022 get abundant duplicated or false features.\nTo overcome these drawbacks, we propose a new method\nbased on analytic solution. It achieves or outperforms\niterative methods with much less computation resources.\nSome feature detectors [10], [8] are ideal for noise free\nimages, but are incapable of blurred or noisy images. The\nproposed detector is more robust with similar performance.\nFeatures' position, orientation, background luminance,\ncontrast, area and aspect ratio can also be extracted from\nimages. Until recently, information such as background\nluminance contrast are not commonly used in feature extraction. Others including area, orientation and aspect ratio\nare studied extensively, but with a limited accuracy.\nIn this paper, a feature model is proposed, and the above\nmentioned parameters will be calculated.\n\n\u2022 X. Xu and X. Zhang are with Nanjing University of Science and\nTechnology, China.\n\nF\n\n2\n\nG AUSSIAN A FFINE S HAPE\n\nIn this section, firstly a feature model is proposed, and then\nanalytic result is derived based on the model to get various\nparameters.\n2.1\n\nFeature Model\n\nFrom a view point of systematology, images, feature extractor and features correspond to input, system, and output. We\nneed build a system that can transform input to output. In\nanother words, image is system input and feature parameters are output. In order to study behavior of the system, we\nneed define input signals. As it is not possible to build an\nall-purpose feature extractor, we will concentrate on some\nspecific image signals. Since (two dimensional) Gaussian\nhas nice analytic properties and simple form, it is chosen as\ninput signal. As to be shown later, Gaussian based model\nwill filter out high frequency signal, hence ideal for noisy\nimages.\nBased on above mentioned idea, image surface is modeled as Gaussian function, as shown in Fig. 1. In this\nway, image feature parameters are related to Gaussian\nparameters, including orientation, long and short radii,\nbaseline height and contrast. Traditionally, baseline height\nand contrast are not considered in feature extraction, they\nare included for completeness. The signal can be defined as\nEqu. 1. Parameters and model variables are listed in Tab. 1.\n\u2212 12\n\nf (x) = c e\n\n\u0010* *\u0011T\n\u0010* *\u0011\nx\u2212\u03bc\n\u03a3\u22121 x \u2212 \u03bc\n\n+d\n\n(1)\n\nBefore continuing, it is helpful to clarify a fact, that\nis, rotating an image will not affect our discussion. This\nfact greatly simplifies our deduction. It is proved in Appendix. A.\nKnown the fact, two-dimensional axis-aligned Gaussian\nwill be used as input signal, as shown in Equ. 2. For this\nfunction, we need get value of \u03b1, \u03b2, c and d.\n\u2212 21\n\nI (x, y; \u03b1, \u03b2, c, d) = c e\n\n\u0010\n\nx2\n\u03b12\n\n2\n\ny\n+\u03b2\n2\n\n\u0011\n\n+d\n\n(2)\n\n\fJOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007\n\n2\n\nAs shown in Equ. 7, convolving I with G is another\nGaussian, which is called (Gaussian) scale space. For\nzero shifted I, its Laplacian will get extreme at origin.\nNormalizing this value will get normalized Laplacian of\nGaussian operation upon I, which is basis of some feature\nextractors.\n\u2212 12\nc\u03b1\u03b2\np\ne\nG\u2217I = \u221a\n\u03c3 2 + \u03b12 \u03c3 2 + \u03b2 2\n\n\u0012\n\nx2\n\n(\u03b12 +\u03c32 )\n\n+\n\n\u0013\n\ny2\n\n(\u03b2 2 +\u03c32 )\n\n+ d (7)\n\nApplying LoG to image to get extreme points, and with\ninformation provided by G \u2217 I, we need get radii (standard\ndeviations) of original input (Gaussian) function I.\nFig. 1. Model of input signal, whose baseline height is\n0 and contrast, is 1.\nTABLE 1\nFactors of model\nFactors\n\n2.2\n\nParameters\n\nContrast\n\nc\n\nBaseline height\n\nd\n\nLong radius\n\n\u03b2\n\nShort radius\nNominal radius\n\n\u03b1\n\u221a\n\u03b1\u03b2\n\nAspect ratio\n\n\u03b2\n\u03b1\n\nOrientation\n\n\u03b8\n\nLoG detected scale\n\n\u03c3\n\nFeature Detection\n\nBefore computing parameters, we need detect feature's\nposition. There exists many feature detectors, we need\nchoose the one that has good performance and solid mathematical foundation. It will be chosen from rotation invariant\ndifferential operator family. As defined in Equ. 3, LoG\ndetector is a good candidate, it is very stable, has fast\nimplementation, and is Gaussian based. The last one is\nthe most important reason, because input signal is also a\nGaussian, and they may have close relation.\nx2 +y 2\n\ne\u2212 2\u03c32\nLoG = \u2207 * \u2207G, G =\n2\u03c0\u03c3 2\n\n(3)\n\n\u2202x (f1 \u2217 f2 ) = f1 \u2217 \u2202x f2\n= \u2202 x f1 \u2217 f2\n\n2.3\n\nAs shown before, image I can be considered as a surface\nin three-dimensional space. From differential geometry, we\nknow its hessian matrix directly relates to principal curvatures and principal directions, and for Gaussian function,\nprincipal curvatures connect with its standard deviations.\nIn one word, eigenvalues of hessian matrix relate to radii\nand eigenvectors relate to directions. We also know that two\nprincipal directions are perpendicular to one another. Based\non these facts, we will derive formulas for parameters.\nObviously, convolving I with isotropic Gaussian will not\nchange principal direction. For extreme point, we can use\nG\u2217I's principal direction as I's principal direction. For the\ncase of axis-aligned Gaussian, we already know principal\ndirections, otherwise, compute eigenvectors.\nRemaining question is, giving information of G\u2217I , how\nto get I's radii \u03b1 and \u03b2, its contrast c and baseline height\nd.\nHere, we will exploit a fact, that LoG can detect Gaussian\nat one and only one scale. In another word, every \u03b1 and \u03b2\npair must produce one and only one \u03c3, as shown in Equ. 8.\nIf analytic form of f is determined, we can recover \u03b1 and\n\u03b2 from \u03c3.\n\u03c3 = f (\u03b1, \u03b2)\n\n(4)\n\nUsing Equ. 5, which is based on Equ. 4, we can define\nLoG operation on image function, as shown in Equ. 6.\n\u2202x,x (f1 \u2217 f2 ) = \u2202x,x f1 \u2217 f2 = f1 \u2217 \u2202x,x f2\n\u2202x,y (f1 \u2217 f2 ) = \u2202x,y f1 \u2217 f2 = f1 \u2217 \u2202x,y f2\n(5)\n\n(8)\n\n\u03b2\nis fixed. LoG will detect extreme\nFor any input image, \u03b1\n\u03b2\npoint in a fixed scale \u03c3. Let us denote k = \u03b1\n, and h = \u03b1\n\u03c3.\nApply normalized LoG operator to I, and substitute \u03b2 =\n\u03b1k and \u03b1 = \u03c3h, and let x = 0, y = 0, we get Equ. 9.\n\n2\n\n\u2202y,y (f1 \u2217 f2 ) = \u2202y,y f1 \u2217 f2 = f1 \u2217 \u2202y,y f2\n\nParameters Calculation\n\n\u03c3 \u2207 * \u2207(G \u2217 I)x=0,y=0 = \u2212\n\nch2 k 2 + h2 1 + k 2\n\n\u0001\u0001\n\n((1 + h2 ) (1 + h2 k 2 ))\n\n3/2\n\n(9)\n\nLet c be constance 1 and draw this expression in Fig. 2.\nIt is clearly shown that for k > 1, extreme of LoG \u2217 I is\nlocated on a smooth ridge.\nFor a fixed k, at extreme point, the formula's one order\nderivative will be zero. After some calculation, we can get\nEqu. 10.\n\nLoG \u2217 I = (\u2202x,x G + \u2202y,y G) \u2217 I\n= \u2202x,x G \u2217 I + \u2202y,y G \u2217 I\n= \u2207 * \u2207(G \u2217 I)\n\n(6)\n\n\u0001\n\u0001\n\u0001\n\u22124\u22122h2 1 + k 2 \u2212h4 1 \u2212 6k 2 + k 4 +2h6 k 2 + k 4 == 0\n(10)\n\n\fJOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007\n\n3\n\nH\n\n0.50\n0.49\n0.48\nratio of eigenvalue\n5\n\nFig. 2. k and h constrained\n\n10\n\n15\n\n20\n\nFig. 3. Relation of H and ratio of eigenvalues\n\nTo solve this equation, let k 2 = K and h2 = H, and we\nGot H, k, h, \u03b1 and \u03b2 will be solved directly.\nget two order equation Equ. 11.\nc and d can also be solved in analytic form. Equ. 9 is\n\u0001\n\u0001\nused\nto get c. Because d is constant component of scale\n\u22124\u22122H\u2212H 2 + \u22122H + 6H 2 + 2H 3 K+ \u2212H 2 + 2H 3 K 2\nspace, it will disappear by differential operation; therefore\n(11)\ncan only be solved in scale space itself. Let x = 0 and\nIt is easy to solve, as Equ. 12.\ny = 0 in G \u2217 I, we will get Equ. 18, so d can be solved\np\n2\nupon extreme point of scale space.\n1 \u2212 3H \u2212 H \u2212 (1 + H) \u22123 + H(6 + H)\nK1 =\nc\nH(\u22121 + 2H)\nq\n(18)\nG \u2217 Ix=0,y=0 = d + q\np\n2\n1\n1\n1 \u2212 3H \u2212 H + (1 + H) \u22123 + H(6 + H)\n1 + H 1 + HK\nK2 =\n(12)\nH(\u22121 + 2H)\nUntil now, we have calculated all parameters of the\nKnown constraint of K and H, we need more informa- zero shifted and axis aligned Gaussian. Because axis can\ntion to get their values. As mentioned above, eigenvalues of be shifted or rotated, our discussion will be applied to\nhessian matrix relate to radii closely. We calculate hessian Gaussian of any position or rotation. We will summary the\nmatrix over scale space, as shown in Equ. 13.\nsteps of our algorithm.\n\u0012\n\u0013\n\u2022 Detect extreme point in normalized LoG space, and\n\u2202x,x \u2202x,y\n(G \u2217 I)\n(13)\nget its \u03c3.\n\u2202x,y \u2202y,y\n\u2022 compute hessian matrix of extreme point in correAs before, we calculate eigenvalues of this matrix, and\nsponding scale space\nlet x = 0, y = 0. Since our discuss based Gaussian, we can\n\u2022 compute eigenvectors as principal directions of the\nget analytic solution of two eigenvalues, shown in Equ. 14.\npoint.\n\u2022 compute eigenvalues, let absolute larger one divide\nch2 k\nsmaller one, and represented as r\ne1 = \u2212\n3/2 \u221a\n\u2022 use Equ. 17 to compute H, Equ. 16 to compute K,\n(1 + h2 )\n1 + h2 k 2 \u03c3 2\n\u221a\n\u221a\nand\nuse\n\u03b1\n=\nH\u03c3,\n\u03b2\n=\nK\u03b1 to compute other\n2\nch k\n(14)\ne2 = \u2212 \u221a\nparameters, use Equ. 9 and Equ. 18 to solve for\n3/2\n1 + h2 (1 + h2 k 2 ) \u03c3 2\ncontrast and baseline height.\nThese two eigenvalues have complicated form, but their\nratio is simpler, shown in Equ. 15.\n2.4 Data Transformation\nr=\n\ne1\n1 + HK\n=\ne2\n1+H\n\n(15)\n\nFrom Equ. 15, we can solve for K, shown in Equ. 16.\n\u22121 + r + Hr\n(16)\nH\nCombined Equ. 12 and Equ. 16, we can solve for H,\nresult is Equ. 17.\nK=\n\nH=\n\n3 + r2\n2r(1 + r)\n\n(17)\n\nWe draw this relation in Fig. 3, which shows detecting\nscale tends to be constancy as shape gets elongate. Simply\nput, elongating a shape contributes little to its detecting\nscale.\n\nUntil now, signal's radii and angle are extracted. In order to\ncomparing with other methods' results, we depend on some\npublicly available tools. Therefore radii and angle need\nto be transformed to a common form, such as symmetric\npositive definite matrix, as shown in Equ. 19.\n\u0012\n\u0013\nx y\n(19)\ny z\nIf let \u03b8 be signal's orientation, and t = arctan(\u03b8), in a\nsimilar way as before, we get Equ. 20.\nx=\ny=\nz=\n\n\u03b2+t2 \u03b1\n1+t2\nt(\u03b1\u2212\u03b2)\n1+t2\n\u03b1+t2 \u03b2\n1+t2\n\n(20)\n\n\fJOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007\n\n4\n\nTABLE 2\nTest Image condition\n\nk\n25\n\n20\n\n15\n\n10\n\n5\n\n50\n\n100\n\n150\n\n200\n\nParameter\n\nRange\n\nc\n\n[\u2212255, 255]\n\nd\n\u221a\n\u03b1\u03b2\n\n[0, 255]\n\n\u03b2\n\u03b1\n\n[1, 30]\n\u0002 \u03c0 \u03c0\u0003\n\u22122, 2\n\n\u03b8\n\nr\n\n[5, 40]\n\nFig. 4. relation of k and r\n\n3\n\nOurs\n\nHessian\u2212Affine\n\nHarris\u2212Affine\n\nMser\n\nI MPLEMENTATION D ETAILS\n\nIn this section, some important implementation details are\noutlined.\n3.1\n\nApproximation and Adjustment\n\nAs shown in Equ. 21, LoG can be implemented by DoG,\nand together with pyramid algorithm, which makes proposed method ready for application. We use similar DoG\npyramid as Lowe's. Extremum of DoG should be adjusted\nby a constant multiplier, for its value is used to compute c\nand d.\nG(x, y, k\u03c3) \u2212 G(x, y, \u03c3) \u2248 (k \u2212 1)\u03c3 2 \u22072 G\n3.2\n\n(21)\n\nRemoval of False Features\n\nTested with synthesized data, we found one common problem among several (affine) feature detectors, that is, for\na single Gaussian signal, often there are several features\ndetected out. Some of them have similar radii and orientations, located around true position, as shown in Fig. 5 and\nFig. 9. Others are false features arisen from noise, as shown\nin Fig. 9 and Fig. 10.\nIn practice, we found a large part of false features coming\nfrom sampling and digitization process, that is to say, they\nare small sized, low contrast features. True features seldom\nhave such properties. Therefore features with small value\nof c, \u03b1 and \u03b2 are considered as noises.\n3.3\n\nDetector Threshold\n\nLike SIFT, we uses ratio of principal curvatures (ratio of\nhessian's eigenvalues, or r in our method) to remove points\non valley or ridge. To accept more features, the ratio needs\nto be refined. Combining Equ. 17 and Equ. 16, with K =\nk 2 , we have Equ. 22.\nr\nr + 3r3\nk=\n(22)\n3 + r2\nWe have drawn relation of k and r in Fig. 4. For aspect\nratio k to be as high as 40, r need at least to be 535\ntheoretically. The r in Equ. 23 is threshold of features.\nTr(H)2\n(e1 + e2 ) 2\n(re2 + e2 )\n(r + 1)2\n=\n=\n=\nDet(H)\ne1 e2\nre2 2\nr\n\n(23)\n\nFig. 5. Typical results for an isotropic Gaussian\n\n4\n\nE XPERIMENTS\n\nIn order to evaluate performance of our method, we firstly\ntest it with synthesized data. In this way, we will know true\nparameters and therefor can compare them with calculated\nones. We will compare results of our method and others,\nincluding Harris-Affine, Hessian-Affine and Mser. Only\ncommon parameters such as orientation, long and short\nscale can be compared, because contrast and base height\nare unique provided by our method. Nevertheless, we will\nshow the results alone.\nGaussian will be used as test image. Image size is\n256x256, and gray scale level is 256. Our method can detect\na large range of parameters, and Tab. 2 lists parameters used\nin experiments.\n4.1\n\nResults of ideal signals\n\nAs demostrated in Fig. 5, Hessian-Affine and Harris-Affine\ntend to detect duplicated features. Fig. 6 and Fig. 7 show,\nfor noise free Gaussian signal, Mser has highest accuracy for detecting position and aspect ratio. Our method\nachieves similar results as MSer. Compared with HarrisAffine, Hessian-Affine gets better results. Both Mser and\nour method can detect signals of high aspect ratio, but\nHessian-Affine and Harris-Affine are limited to low aspect\nratio signals.\nOur method is to compute original parameters from\nblurred output image. For very long and thin shapes, our\nmethod may slightly underestimate true aspect ratio, as\nshown in Fig .7.\nAs shown in Fig. 8, our method and Mser achieve highest\naccuracy for detecting short radii. However, in addition to\ntrue signals, Mser often finds small concentric signals.\n\n\f5\n\n20\n\n1.5\nMSer\nOurs\nHarris\u2212Affine\nHessian\u2212Affine\n\n15\n\n10\n\n5\n\n0\n\ndetected / true short radius\n\ndistance from detected to true position\n\nJOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007\n\n1\n\n0\n0\n\n2\n\n4\n\n6\n8\ntrue aspect ratio\n\n10\n\n12\n\nMSer\nOurs\nHarris\u2212Affine\nHessian\u2212Affine\n\n0.5\n\n0\n\n2\n\n4\n\n6\n8\ntrue aspect ratio\n\n10\n\n12\n\nFig. 6. Position inaccuracy\n\ndetected / true aspect ratio\n\nFig. 8. Short radius accuracy\nMSer\nOurs\nHarris\u2212Affine\nHessian\u2212Affine\n\n1.4\n1.3\n1.2\n1.1\n\nOurs\n\nHessian\u2212Affine\n\nHarris\u2212Affine\n\nMser\n\n1\n0.9\n0.8\n0.7\n\n2\n\n4\n\n6\n8\nreal aspect ratio\n\n10\n\n12\n\nFig. 7. Aspect ratio accuracy\nIn conclusion, for ideal noise free Gaussian, Mser get\nbest results, and ours is similar to that of Mser. HessianAffine and Harris-Affine are not as stable as Mser and ours.\nFig. 9. Typical results for noisy Gaussian\n4.2 Results of noisy signals\nFig. 9 is a typical noisy image, and Mser is the most\nsensitive to noise. Even a small amount of noise can impact\nMser seriously. Fig. 10 is distance of true and detected\npoints. It is difficult for Mser to differentiate noises from\ntrue signals. Therefore we only compare Hessian-Affine,\nHarris-Affine and ours for noisy images.\nAs shown in Fig. 10, Fig. 11, Fig. 11, our method\nperforms well when other methods reach their limits.\nUsing Mikolajczyk's evaluation images and toolbox, we\nget repeatability in Fig. 13. For these noisy free images,\nMser get highest accuracy, and Hessian-Affine, HarrisAffine and our methods have similar results. Our 1 and\n2 are results of different thresholds.\nFig. 14 is detecting results of graffiti under different view\nangle. Compared with Hessian-Affine and Harris-Affine,\nMser and ours detect fewer features. It seems that the\nformer two detect many redundant features. Compared with\nours, Mser tends to detect many small features.\n\nand quick. Tested with Gaussian, for ideal noisy free signal,\nour method produces one of the best results, and for noisy\nsignal, it outperforms others significantly. The proposed\nmethod can also extracts parameters unavailable for other\nmethods, such as contrast and baseline height.\nTest with benchmark images, the method get similar\nrepeatability as Harris-Affine and Hessian-Affine.\n\nA PPENDIX A\nP ROOF OF R OTATION I NVARIANT\nS URFACE\n\nLet F be Fourier operator, and f be an input function;\nFourier transform is shown in Equ. 24.\nZ\n\n\u221e\n\nF \u25e6 f (x) =\n\n5\n\nC ONCLUSION\n\nIn this paper, we have proposed a new feature detector.\nCompared with other methods, it is very stable, accurate\n\nFOR I MAGE\n\n\u2227\n\nf (x)e\u22122\u03c0ihx,\u03bei dx = f (\u03be)\n\n(24)\n\n\u221e\n\nIf input function rotates in x space, and let \u03be = Rx, its\nFourier transform will also rotate same angle, as shown in\n\n\f6\n\n200\n\n1.5\nMSer\nOurs\nHarris\u2212Affine\nHessian\u2212Affine\n\n150\n\ndetected / true short radius\n\ndistance from detected to true position\n\nJOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007\n\n100\n\n50\n\n0\n\n0\n\n2\n\n4\n\n6\n8\ntrue aspect ratio\n\n10\n\nOurs\nHarris\u2212Affine\nHessian\u2212Affine\n\n1\n\n0.5\n\n12\n\n0\n\n2\n\n4\n\n6\n8\ntrue aspect ratio\n\n10\n\n12\n\nFig. 10. Position inaccuracy for noisy Gaussian\nFig. 12. Short radius accuracy for noisy Gaussian\n\n100\nHarris\u2212Affine\nHessian\u2212Affine\nMSER\nOurs 1\nOurs 2\n\n90\n80\n1\n70\nrepeatebility %\n\ndetected / true aspect ratio\n\n1.5\n\n0.5\nOurs\nHarris\u2212Affine\nHessian\u2212Affine\n0\n\n2\n\n4\n\n6\n8\ntrue aspect ratio\n\n10\n\n12\n\n60\n50\n40\n30\n20\n10\n0\n10\n\nFig. 11. Aspect ratio accuracy for noisy Gaussian\n\nEqu. 25.\nZ\n\n20\n\n30\n\n40\nviewpoint angle\n\n50\n\n60\n\n70\n\nFig. 13. Repeatebility comparasion. Our 1 and 2 have\ndifferent threshold.\n\n\u221e\n\nF \u25e6 f (Rx) =\nf (Rx)e\u22122\u03c0ihx,\u03bei dx\n\u221e\nZ \u221e\nT\n=\nf (y)e\u22122\u03c0ihR y,\u03bei dy\nZ\u221e\n\u221e\nT\nT\n=\nf (y)e \u22122\u03c0i(R y) \u03be dy\n\u221e\nZ \u221e\nT\n=\nf (y)e\u22122\u03c0iy R\u03be dy\n\u221e\nZ \u221e\n=\nf (y)e\u22122\u03c0ihy,R\u03bei dy\n\noutput's geometrical property will not change on rotating\ninput and system.\n\nACKNOWLEDGMENTS\nThe authors would like to thank PhD. Andrea Vedaldi for\nhis excellent open sourced code, and professor Bart ter Haar\nRomeny for his free distributed electronic book.\n\n\u221e\n\u2227\n\n= f (R\u03be)\n\n(25)\n\nConvolution in space domain can be implemented by\nmultiplication in \u03be domain, as shown in Equ. 26.\n\u2227\n\n\u2227\n\n\u2227\n\nf (x) \u2217 g(x) \u2194 f (\u03be)g(\u03be) = h(\u03be) \u2194 h(x)\n\u2227\n\n\u2227\n\n(26)\n\n\u2227\n\nf (Rx) \u2217 g(Rx) \u2194 f (R\u03be)g(R\u03be) = h(R\u03be) \u2194 h(Rx) (27)\nUsing Equ. 24, Equ. 25 and Equ. 26, we can get Equ. 27.\nIt means if input and system are rotated with same angle,\nthe output will also rotate the same angle. In one word,\n\nR EFERENCES\n[1] J.J. Koenderink and A.J. Doorn, \"Generic Neighborhood Operators,\"\nIEEE Trans. Pattern Anal. Mach. Intell., Vol. 14, No. 6. (1992), pp.\n597-605.\n[2] B.M.H Romeny, Front-end vision and multi-scale image analysis.\nBerlin, Germany.: Springer Verlag, 2003.\n[3] D.G. Lowe, \"Distinctive Image Features from Scale-Invariant Keypoints,\" International Journal of Computer Vision, Vol. 60, No. 2. (1\nNovember 2004), pp. 91-110.\n[4] K. Mikolajczyk and C. Schmid, \"Scale and Affine Invariant Interest\nPoint Detectors,\" International Journal of Computer Vision, Vol. 60,\nNo. 1. (1 October 2004), pp. 63-86.\n[5] T. Lindeberg, \"Feature Detection with Automatic Scale Selection\"\nInternational Journal of Computer Vision, Vol. 30, No. 2. (1 November\n1998), pp. 79-116.\n\n\fJOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007\n\nOurs\n\nOurs\n\nMser\n\nMser\n\nHarris\u2212Affine\n\nHarris\u2212Affine\n\nHessian\u2212Affine\n\nHessian\u2212Affine\n\nFig. 14. Graffiti of different view angles.\n\n[6] K. Mikolajczyk and C. Schmid, \"A performance evaluation of local\ndescriptors,\" IEEE Transactions on Pattern Analysis and Machine\nIntelligence, Vol. 27, No. 10. (October 2005), pp. 1615-1630.\n[7] J.J. Koenderink \"The structure of images,\" Biological Cybernetics,\nVol. 50, No. 5, pp. 363-370-370, Aug 1984, doi:10.1007/BF00336961.\n[8] T. Tuytelaars and Luc Van Gool, \"Matching Widely Separated Views\nBased on Affine Invariant Regions,\" Int. J. Comput. Vision, Vol. 59,\nNo. 1. (August 2004), pp. 61-85.\n[9] K. Mikolajczyk, T. Tuytelaars, C. Schmid, A. Zisserman, J. Matas,\nF. Schaffalitzky, T. Kadir and L. Van Gool, \"A comparison of affine\nregion detectors,\" International Journal of Computer Vision, Vol. 65,\nNo. 1. (13 November 2005), pp. 43-72.\n[10] J. Matas, O. Chum, U. Martin and T. Pajdla, \"Robust wide baseline\nstereo from maximally stable extremal regions,\" In Proceedings of the\nBritish Machine Vision Conference, Vol. 1 (2002), pp. 384-393.\n[11] X. Xu and J. Yang, \"Directional SIFT \u2013 An Improved Method Using\nElliptical Gaussian Pyramid,\" Chinese Conference on Pattern Recognition (CCPR '10), pp. 1 - 5, 2010, doi:10.1109/CCPR.2010.5659135.\n[12] A.P. Witkin, \"Scale-Space Filtering,\" In 8th Int. Joint Conf. Artificial\nIntelligence, Vol. 2, pp. 1019-1022, Aug 1983.\n[13] A. Vedaldi and B. Fulkerson, \"VLFeat: An Open and Portable\nLibrary of Computer Vision Algorithms,\" http://www.vlfeat.org/\n[14] T. Kadir, A. Zisserman and M. Brady, \"An Affine Invariant Salient\nRegion Detector,\" In Computer Vision - ECCV 2004, pp. 228C241.\n[15] D.G. Lowe, \"Object Recognition from Local Scale-Invariant Features,\" IEEE International Conference on In Computer Vision, 1999,\nVol. 2, (06 August 1999), pp. 1150-1157.\n\n7\n\n\f"}