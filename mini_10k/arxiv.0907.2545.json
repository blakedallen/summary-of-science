{"id": "http://arxiv.org/abs/0907.2545v1", "guidislink": true, "updated": "2009-07-15T10:04:51Z", "updated_parsed": [2009, 7, 15, 10, 4, 51, 2, 196, 0], "published": "2009-07-15T10:04:51Z", "published_parsed": [2009, 7, 15, 10, 4, 51, 2, 196, 0], "title": "On backward errors of structured polynomial eigenproblems solved by\n  structure preserving linearizations", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0907.3523%2C0907.1269%2C0907.3218%2C0907.1105%2C0907.4427%2C0907.0409%2C0907.1797%2C0907.4830%2C0907.0174%2C0907.3458%2C0907.3673%2C0907.1477%2C0907.1823%2C0907.1580%2C0907.0633%2C0907.1411%2C0907.2734%2C0907.4234%2C0907.0020%2C0907.4585%2C0907.5047%2C0907.4260%2C0907.4137%2C0907.2192%2C0907.4552%2C0907.3304%2C0907.4804%2C0907.3409%2C0907.0927%2C0907.2929%2C0907.2763%2C0907.0087%2C0907.0518%2C0907.2578%2C0907.3621%2C0907.1060%2C0907.0930%2C0907.3711%2C0907.0614%2C0907.0577%2C0907.1598%2C0907.4857%2C0907.0163%2C0907.4926%2C0907.3290%2C0907.3173%2C0907.1917%2C0907.0440%2C0907.0457%2C0907.3820%2C0907.5035%2C0907.0336%2C0907.3646%2C0907.3398%2C0907.3940%2C0907.3013%2C0907.2315%2C0907.4606%2C0907.0925%2C0907.5534%2C0907.4289%2C0907.0596%2C0907.4757%2C0907.3856%2C0907.0366%2C0907.5540%2C0907.5336%2C0907.0442%2C0907.0981%2C0907.5192%2C0907.2545%2C0907.2471%2C0907.4678%2C0907.4554%2C0907.1376%2C0907.0147%2C0907.1928%2C0907.5058%2C0907.5201%2C0907.3547%2C0907.2071%2C0907.1361%2C0907.0215%2C0907.2893%2C0907.3665%2C0907.5210%2C0907.4181%2C0907.1437%2C0907.3097%2C0907.3690%2C0907.1892%2C0907.4787%2C0907.1375%2C0907.0718%2C0907.5402%2C0907.4549%2C0907.0849%2C0907.2955%2C0907.3546%2C0907.5026%2C0907.2313&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "On backward errors of structured polynomial eigenproblems solved by\n  structure preserving linearizations"}, "summary": "First, we derive explicit computable expressions of structured backward\nerrors of approximate eigenelements of structured matrix polynomials including\nsymmetric, skew-symmetric, Hermitian, skew-Hermitian, even and odd polynomials.\nWe also determine minimal structured perturbations for which approximate\neigenelements are exact eigenelements of the perturbed polynomials. Next, we\nanalyze the effect of structure preserving linearizations of structured matrix\npolynomials on the structured backward errors of approximate eigenelements. We\nidentify structure preserving linearizations which have almost no adverse\neffect on the structured backward errors of approximate eigenelements of the\npolynomials. Finally, we analyze structured pseudospectra of a structured\nmatrix polynomial and establish a partial equality between unstructured and\nstructured pseudospectra.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0907.3523%2C0907.1269%2C0907.3218%2C0907.1105%2C0907.4427%2C0907.0409%2C0907.1797%2C0907.4830%2C0907.0174%2C0907.3458%2C0907.3673%2C0907.1477%2C0907.1823%2C0907.1580%2C0907.0633%2C0907.1411%2C0907.2734%2C0907.4234%2C0907.0020%2C0907.4585%2C0907.5047%2C0907.4260%2C0907.4137%2C0907.2192%2C0907.4552%2C0907.3304%2C0907.4804%2C0907.3409%2C0907.0927%2C0907.2929%2C0907.2763%2C0907.0087%2C0907.0518%2C0907.2578%2C0907.3621%2C0907.1060%2C0907.0930%2C0907.3711%2C0907.0614%2C0907.0577%2C0907.1598%2C0907.4857%2C0907.0163%2C0907.4926%2C0907.3290%2C0907.3173%2C0907.1917%2C0907.0440%2C0907.0457%2C0907.3820%2C0907.5035%2C0907.0336%2C0907.3646%2C0907.3398%2C0907.3940%2C0907.3013%2C0907.2315%2C0907.4606%2C0907.0925%2C0907.5534%2C0907.4289%2C0907.0596%2C0907.4757%2C0907.3856%2C0907.0366%2C0907.5540%2C0907.5336%2C0907.0442%2C0907.0981%2C0907.5192%2C0907.2545%2C0907.2471%2C0907.4678%2C0907.4554%2C0907.1376%2C0907.0147%2C0907.1928%2C0907.5058%2C0907.5201%2C0907.3547%2C0907.2071%2C0907.1361%2C0907.0215%2C0907.2893%2C0907.3665%2C0907.5210%2C0907.4181%2C0907.1437%2C0907.3097%2C0907.3690%2C0907.1892%2C0907.4787%2C0907.1375%2C0907.0718%2C0907.5402%2C0907.4549%2C0907.0849%2C0907.2955%2C0907.3546%2C0907.5026%2C0907.2313&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "First, we derive explicit computable expressions of structured backward\nerrors of approximate eigenelements of structured matrix polynomials including\nsymmetric, skew-symmetric, Hermitian, skew-Hermitian, even and odd polynomials.\nWe also determine minimal structured perturbations for which approximate\neigenelements are exact eigenelements of the perturbed polynomials. Next, we\nanalyze the effect of structure preserving linearizations of structured matrix\npolynomials on the structured backward errors of approximate eigenelements. We\nidentify structure preserving linearizations which have almost no adverse\neffect on the structured backward errors of approximate eigenelements of the\npolynomials. Finally, we analyze structured pseudospectra of a structured\nmatrix polynomial and establish a partial equality between unstructured and\nstructured pseudospectra."}, "authors": ["Bibhas Adhikari", "Rafikul Alam"], "author_detail": {"name": "Rafikul Alam"}, "author": "Rafikul Alam", "arxiv_comment": "27 pages, submitted", "links": [{"href": "http://arxiv.org/abs/0907.2545v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0907.2545v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "math.NA", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "math.NA", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0907.2545v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0907.2545v1", "journal_reference": null, "doi": null, "fulltext": "On backward errors of structured polynomial\neigenproblems solved by structure preserving linearizations\n\narXiv:0907.2545v1 [math.NA] 15 Jul 2009\n\nBibhas Adhikari\u2217 and Rafikul Alam\u2020\n\nAbstract. First, we derive explicit computable expressions of structured backward errors of approximate eigenelements of structured matrix polynomials including symmetric, skew-symmetric, Hermitian, skew-Hermitian, even and odd polynomials. We also determine minimal structured perturbations for which approximate eigenelements are exact eigenelements of the perturbed polynomials.\nNext, we analyze the effect of structure preserving linearizations of structured matrix polynomials\non the structured backward errors of approximate eigenelements. We identify structure preserving\nlinearizations which have almost no adverse effect on the structured backward errors of approximate\neigenelements of the polynomials. Finally, we analyze structured pseudospectra of a structured matrix\npolynomial and establish a partial equality between unstructured and structured pseudospectra.\n\nKeywords. Structured matrix polynomial, structured backward error, pseudospectrum,\nstructured linearization.\nAMS subject classifications. 65F15, 15A57, 15A18, 65F35\n\n1\n\nIntroduction\n\nP\nj\nn\u00d7n\nConsider a matrix polynomial P(z) := m\nand Am 6= 0.\nj=0 z Aj of degree m, where Aj \u2208 C\nWe assume that P is regular, that is, det(P(z)) 6= 0 for some z \u2208 C. We say that \u03bb \u2208 C is\nan eigenvalue of P if det(P(\u03bb)) = 0. A nonzero vector x \u2208 Cn (resp., y \u2208 Cn ) that satisfies\nP(\u03bb)x = 0 (resp., y H P(\u03bb) = 0) is called a right (resp., left) eigenvector of P corresponding to\nthe eigenvalue \u03bb. The standard approach to computing eigenelements of P is to convert P into\nan equivalent linear polynomial L, called a linearization of P, and employ a numerically backward stable algorithm to compute the eigenelements of L, where L(z) := zX +Y, X \u2208 Cmn\u00d7mn\nand Y \u2208 Cmn\u00d7mn . It is well known that a matrix polynomial admits several linearizations. In\nfact, it is shown in [20, 18] that potential linearizations of a matrix polynomial form a vector\nspace. Thus choosing an optimal (in some sense) linearization of P is an important first step\ntowards computing eigenelements of P. In general, a linearization of P can have an adverse\neffect on the conditioning of the eigenvalues of P (see, [13]). Hence by analyzing the condition\nnumbers of eigenvalues of linearizations, potential linearizations of P have been identified in\n[13] whose eigenvalues are almost as sensitive to perturbations as that of P. Further, it is\nshown in [11] that these linearizations are consistent with the backward errors of approximate\neigenelements in the sense that they nearly minimize the backward errors.\nPolynomial eigenvalue problems that occur in many applications possess some distinctive\nstructures (e.g., Hermitian, even, odd and palindromic) which in turn induce certain spectral\nsymmetries on the eigenvalues of the matrix polynomials (see, [21, 25, 24, 17, 16] and the references therein). With a view to preserving spectral symmetry in the computed eigenvalues\n(and possibly improved accuracy), there has been a lot of interests in developing structured\npreserving algorithms (see, [15, 23, 25, 19] and the references therein). Since linearization is\nthe standard way to solve a polynomial eigenvalue problem, for a structured matrix polyno\u2217 Department\n\nof Mathematics, IIT Guwahati, India, E-mail: bibhas.adhikari@gmail.com\nof Mathematics, IIT Guwahati, India, E-mail: rafik@iitg.ernet.in, rafikul@yahoo.com, Fax:\n+91-361-2690762/2582649.\n\u2020 Department\n\n\fmial it is therefore necessary to choose a structured linearization and then solve the linear\nproblem by a backward stable structure preserving algorithm. For the accuracy assessment\nof computed solution, it is therefore important to understand the sensitivity of eigenvalues of\na structured matrix polynomial with respect to structure preserving perturbations. Also it is\nequally important to know the structured backward errors of approximate eigenelements of a\nstructured matrix polynomial. Moreover, for a variety of structured polynomials such as symmetric, skew-symmetric, Hermitian, skew-Hermitian, even, odd and palindromic polynomials,\nthere are infinitely many structured linearizations, see [12, 21]. This poses a genuine problem\nof choosing one linearization over the other. For computational purposes, it is highly desirable\nto know how different structured linearizations affect the accuracy of computed eigenelements.\nThus the selection of an optimal or a near optimal structured linearization is an important\nstep in the solution process of a structured polynomial eigenvalue problem. The sensitivity\nanalysis of eigenvalues of structured matrix polynomials with respect to structure preserving\nperturbation has been investigated in [4]. It also provides a recipe for choosing structured\nlinearizations whose eigenvalues are almost as sensitive to structure preserving perturbations\nas that of the structured matrix polynomials.\nTo complete the investigation, in this paper we analyze structured backward errors of\napproximate eigenelements of symmetric, skew-symmetric, Hermitian, skew-Hermitian, T even, T -odd, H-even and H-odd polynomials. These structures are defined in Table 1. The\nmain contribution of this paper is as follows.\nFirst, we derive explicit computable expressions for the structured backward errors of\napproximate eigenelements of structured matrix polynomials. We also construct a minimal\nstructured perturbation so that an approximate eigenelement is the exact eigenelement of the\nstructured perturbed polynomial. These results generalize similar results in [3] obtained for\nstructured matrix pencils.\nSecond, we consider structured linearizations that preserve spectral symmetry of a structured matrix polynomial and compare the structured backward errors of approximate eigenelements with that of the structured polynomial. For example, a T -even matrix polynomial\nadmits T -even as well as T -odd linearizations both of which preserve the spectral symmetry\nof the T -even polynomial. Based on these results we identify structured linearizations which\nare optimal in the sense that the structured backward errors of approximate eigenelements of\nthe linearizations are bounded above and below by a small constant multiple of that of the\nstructured polynomials. We show that these linearizations are consistent with the choice of\nlinearizations discussed in [4] by analyzing structured condition numbers of eigenvalues.\nThird, we show that the effect of structure preserving linearization on the structured\nbackward errors of approximate eigenelements is almost harmless for a wide class of structured\nlinearizations. We show that bad effect, if any, of a structure preserving linearization can be\nneutralized by considering a complementary structured linearization. For example, when P\nis a T -even polynomial, we show that any T -even linearization is optimal for eigenvalues \u03bb\nof P such that |\u03bb| \u2264 1, and any T -odd linearization is optimal for eigenvalues \u03bb such that\n|\u03bb| \u2265 1. In such a case, we show that the backward error of an approximate eigenelement of\nthe linearization differ from that of P by no more than a factor of 2. We show that similar\nresults hold for other structured polynomials as well. In contrast, it is shown in [4] that\nthe condition numbers of eigenvalues of these optimal linearizations differ from that of the\npolynomial by a factor of a constant whose size could of the order of the degree of the matrix\npolynomial.\nFinally, we analyze structured pseudospectra of structured matrix polynomials and establish a partial equality between structured and unstructured pseudospectra. Similar study for\npalindromic matrix polynomials has been carried out in [2], see also [1, 8].\nThe rest of the paper is organized as follows. In section 2, we review structured polynomials and their spectral symmetries. In section 3, we analyze structured backward errors\nof approximate eigenpairs of structured polynomials. In section 4, we analyze the effect of\nstructure preserving linearizations on the backward errors of approximate eigenelements of\n\n2\n\n\fstructure polynomials and provide a recipe for choosing optimal linearizations. Finally, in\nsection 5, we consider structured pseudospectra of structured matrix polynomials.\n\n2\n\nStructured matrix polynomials\n\nPm\nWe consider matrix polynomial of degree m of the form P(z) := j=0 z j Aj , where Aj \u2208 Cn\u00d7n\nand Am 6= 0. Let Pm (Cn\u00d7n ) denote the vector space of matrix polynomials of degree at most\nm. The spectrum of a regular polynomial P \u2208 Pm (Cn\u00d7n ), denoted by \u03c3(P), is given by\n\u03c3(P) := {z \u2208 C : det(P(z)) = 0}. Strictly, speaking \u03c3(P) consists of finite eigenvalues of P.\nIf the leading coefficient of P is singular then P has an infinite eigenvalue. In this paper, we\nconsider only finite eigenvalues of matrix polynomials. An infinite eigenvalue of P, if any, can\neasily be analyzed by considering the reverse polynomial of P (see [6]). We say that (\u03bb, x, y)\nis an eigentriple of P if \u03bb is an eigenvalue of P and, x and y are the corresponding nonzero\nright and left eigenvectors, that is, P(\u03bb)x = 0 and y H P(\u03bb) = 0.\nH\nWe denote the transpose and conjugate transpose of a matrix A by AT and A\nPm, respecn\u00d7n\nn\u00d7n\n\u2217\n\u2217\nj \u2217\ntively. Define the map Pm (C\n) \u2192 Pm (C\n), P 7\u2192 P given by P (z) :=\nj=0 z Aj ,\nwhere A\u2217 = AT or A\u2217 = AH . The map P 7\u2192 P\u2217 can be used to define interesting structured\nmatrix polynomials such as symmetric, skew-symmetric, Hermitian, skew-Hermitian, \u2217-even\nand \u2217-odd matrix polynomials. These structures are defined in Table 1. The table also shows\nthe eigentriples as well as the spectral symmetries of the eigenvalues, see also [21]. We denote\nthe set of structured polynomials having one of the structures given in Table 1 by S. By\nwriting a pair (\u03bb, \u03bc) in the third column of Table 1 we mean that if \u03bb is an eigenvalue of P\nthen so is \u03bc. Notice that the eigenvalues of Hermitian and skew-Hermitian polynomials have\nthe same spectral symmetry. Similarly, the eigenvalues of \u2217-even and \u2217-odd polynomials have\nthe same spectral symmetry, where \u2217 \u2208 {T, H}.\nS\nsymmetric\nskew-symmetric\nT -even\nT -odd\nHermitian\nskew-hermitian\nH-even\nH-odd\n\nCondition\n\nspectral symmetry\n\neigentriple\n\nP (z) = P(z), \u2200z \u2208 C\nPT (z) = \u2212P(z), \u2200z \u2208 C\nPT (z) = P(\u2212z), \u2200z \u2208 C\nPT (z) = \u2212P(\u2212z), \u2200z \u2208 C\n\n\u03bb\n\n(\u03bb, x, x)\n\n(\u03bb, \u2212\u03bb)\n\n(\u03bb, x, y), (\u2212\u03bb, y, x)\n\n(\u03bb, \u03bb)\n\n(\u03bb, x, y), (\u03bb, y, x)\n\n(\u03bb, \u2212\u03bb)\n\n(\u03bb, x, y), (\u2212\u03bb, y, x)\n\nT\n\nPH (z) = P(z), \u2200z \u2208 C\nPH (z) = \u2212P(z), \u2200z \u2208 C\nPH (z) = P(\u2212z), \u2200z \u2208 C\nPH (z) = \u2212P(\u2212z), \u2200z \u2208 C\n\nTable 1: Spectral symmetries of structured polynomials.\nLet P \u2208 S be regular. With a view to obtaining structured backward error of (\u03bb, x) \u2208\nC\u00d7Cn with xH x = 1 as an approximate eigenpair of P, we now show that there always exists a\npolynomial \u25b3P \u2208 S such that (\u03bb, x) is a right eigenpair of P + \u25b3P, that is, (P(\u03bb)+ \u25b3P(\u03bb))x =\n0. Recall that S denotes the set of structured polynomials having one of the structures given in\nTable 1. In short, we write S \u2208 {sym, skew-sym, Herm, skew-Herm, T -even, T -odd, H-even, H-odd}.\nTheorem 2.1 Let S \u2208 {sym,P\nskew-sym, Herm, skew-Herm, T -even, T -odd, H-even, H-odd} and\nm\nj\nn\nH\nP \u2208 S be given by P(z) =\nj=0 z Aj . Let (\u03bb, x) \u2208 C \u00d7 C be such that x x = 1. Set\n\n3\n\n\fr = \u2212P(\u03bb)x, \u039bm := [1, \u03bb, . . . , \u03bbm ]T and Px := I \u2212 xxH . Define\n\uf8f1\n\u03bbj\nT\nH\nT\nH\nT\nH\n\uf8f4\n\uf8f2 \u2212xx Aj xx + k\u039bm k22 [xr + rx \u2212 2(r x)xx ],\n\u25b3Aj :=\n\uf8f4\n\uf8f3 \u2212 \u03bbj [xrT \u2212 rxH ],\nk\u039bm k22\n\uf8f1\n1\nH\nH\nH\nj\nH\nj\n\uf8f4\n\uf8f2 \u2212xx Aj xx + k\u039bm k22 [\u03bb xr Px + \u03bb Px rx ], if\n\u25b3Aj :=\n\uf8f4\n\uf8f3 \u2212xxH Aj xxH \u2212 1 2 [\u03bbj xrH Px \u2212 \u03bbj Px rxH ], if\nk\u039bm k\n2\n\nand consider the polynomial \u25b3P(z) :=\n\nPm\n\nj=0\n\nif Aj = ATj ,\nif Aj = \u2212ATj ,\nAj = AH\nj ,\nAj = \u2212AH\nj ,\n\nz j \u25b3Aj . Then P(\u03bb)x + \u25b3P(\u03bb)x = 0 and \u25b3P \u2208 S.\n\nProof: The proof is computational and is easy to check.\u0004\n\n3\n\nStructured backward errors\n\nBackward errors of approximate eigenelements of regular matrix polynomials have been systematically analyzed and computable expressions for the backward errors have been derived\nby Tisseur in [26] . For our purpose, we require a different norm setup for matrix polynomials. We equip Pm (Cn\u00d7n ) with a norm so that the resulting normed linear space can\nbe used P\nfor perturbation analysis of matrix polynomials. Let P \u2208 Pm (Cn\u00d7n ) be given by\nm\nP(z) := j=0 Aj z j . We define\n\uf8eb\n\n|||P|||M := \uf8ed\n\nm\nX\nj=0\n\n\uf8f61/2\n\nkAj k2M \uf8f8\n\n,\n\nwhere kAkM denotes the Frobenius norm when M = F and the spectral norm when M =\n2. Accordingly, we say that |||*|||F is the Frobenius norm and |||*|||2 is the spectral norm on\nPm (Cn\u00d7n ). See [6, 5] for more on norms of matrix polynomials.\nLet (\u03bb, x) \u2208 C \u00d7 Cn be such that xH x = 1 and P \u2208 Pm (Cn\u00d7n ) be regular. We denote the\nbackward error of (\u03bb, x) as an approximate eigenelement of P by \u03b7M (\u03bb, x, P) given by\n\u03b7M (\u03bb, x, P) :=\n\ninf\n\n{|||\u25b3P|||M : P(\u03bb)x + \u25b3P(\u03bb)x = 0}.\n\n\u25b3P\u2208Pm (Cn\u00d7n )\n\nSetting r := \u2212P(\u03bb)x and \u039bm := [1, \u03bb, . . . , \u03bbm ]T , it is easily seen that\n\u03b7M (\u03bb, x, P) =\n\nkrk2\nkxk2 k\u039bm k2\n\n(1)\n\n\u03bbj rxH\n, j = 0 : m, and considering\nfor M = F as well as M = 2. Indeed, defining \u25b3Aj := H\nx xk\u039bm k22\nPm j\nthe polynomial \u25b3P(z) := j=0 z \u25b3Aj , we have |||\u25b3P|||M = krk2 /kxk2 k\u039bm k2 and P(\u03bb)x +\n\u25b3P(\u03bb)x = 0. Consequently, for simplicity of notation, we denote \u03b7M (\u03bb, x, P) by \u03b7(\u03bb, x, P).\nNow suppose that P \u2208 S. Then treating (\u03bb, x) as an approximate eigenelement of P, we\ndefine the structured backward error of (\u03bb, x) by\nS\n\u03b7M\n(\u03bb, x, P) := inf {|||\u25b3P|||M : P(\u03bb)x + \u25b3P(\u03bb)x = 0}.\n\u25b3P\u2208S\n\nS\nIn view of Theorem 2.1, it follows that \u03b7(\u03bb, x, P) \u2264 \u03b7M\n(\u03bb, x, P) < \u221e. Structured backward\nerrors of approximate eigenelements of structured matrix pencils have been systematically\nanalyzed and computable expressions of the structured backward errors have been derived\nin [3]. In this section we generalize these results to the case of structured matrix polynomials.\n\n4\n\n\fAs we shall see, determining \u03b72S (\u03bb, x, P) is much more difficult than determining \u03b7FS (\u03bb, x, P)\nand requires solution of norm preserving dilation problem for matrices. The Davis-KahanWeinberger solutions of norm preserving dilation problem given below will play an important\nrole in the subsequent development. Let A, B, C and D be matrices of appropriate sizes.\nThen the following result holds.\n\u0014 \u0015\nA\nTheorem 3.1 (Davis-Kahan-Weinberger, [10]) Let A, B, C satisfy\n= \u03bc and\nB 2\n\u0014\n\u0015\n\u0002\n\u0003\nA C\nA C 2 = \u03bc. Then there exists D such that\n= \u03bc. Indeed, those D which have\nB D 2\nthis property are exactly those of the form\nD = \u2212KAH L + \u03bc(I \u2212 KK H )1/2 Z(I \u2212 LH L)1/2 ,\nwhere K H := (\u03bc2 I\u2212AH A)\u22121/2 B H , L := (\u03bc2 I\u2212AAH )\u22121/2 C and Z is an arbitrary contraction,\nthat is, kZk2 \u2264 1. \u0004\nFor a more general version of the above result, see [10].\n\n3.1\n\nSymmetric and skew-symmetric polynomials\n\nWe now derive structured backward error of (\u03bb, x) \u2208 C \u00d7 Cn as an approximate eigenpair\nof symmetric and skew-symmetric matrix polynomials. We also derive minimal structured\nperturbations so that (\u03bb, x) is an exact eigenpair of the perturbed polynomials. First, we\nconsider symmetric matrix polynomials. Note that a matrix polynomial P \u2208 Pm (Cn\u00d7n ) is\nsymmetric if and only if all the coefficient matrices of P are symmetric. For a symmetric\nmatrix polynomial, we have the following result.\nTheorem 3.2 Let S denote the set of symmetric matrix polynomials in Pm (Cn\u00d7n ) and let\nP \u2208 S. Let (\u03bb, x) \u2208 C \u00d7 Cn be such that xH x = 1. Set r := \u2212P(\u03bb)x, Px := I \u2212 xxH and\n\u039bm := [1, \u03bb, . . . , \u03bbm ]T . Then we have\np\n\u221a\n2krk22 \u2212 |xT r|2\nS\n\u2264 2\u03b7(\u03bb, x, P) and \u03b72S (\u03bb, x, P) = \u03b7(\u03bb, x, P).\n\u03b7F (\u03bb, x, P) =\nk\u039bm k2\nj\n\nSet \u25b3Aj := k\u039b\u03bbm k2 [xrT + rxH \u2212 (rT x)xxH ], j = 0 : m, and consider the polynomial \u25b3P(z) :=\n2\nPm j\nj=0 z \u25b3Aj . Then \u25b3P is a unique polynomial such that \u25b3P \u2208 S, \u25b3P(\u03bb)x + P(\u03bb)x = 0 and\n|||\u25b3P|||F = \u03b7FS (\u03bb, x, P). Further, define\n\u03bbj\n\u03bbj xT r PxT rrT Px\n[xrT + rxH \u2212 (rT x)xxH ] \u2212\n2\nk\u039bm k2\nk\u039bm k22 (krk22 \u2212 |xT r|2 )\nPm\nand consider the polynomial \u25b3P(z) := j=0 z j \u25b3Aj . Then \u25b3P \u2208 S, \u25b3P(\u03bb)x + P(\u03bb)x = 0 and\n|||\u25b3P|||2 = \u03b72S (\u03bb, x, P).\nPm\nProof: In view of Theorem 2.1, let \u25b3P \u2208 S given by \u25b3P(z) := j=0 \u25b3Aj z j be such that\nn\u00d7(n\u22121)\nP(\u03bb)x + \u25b3P(\u03bb)x = 0. Let Q\n\u00121 \u2208 C T \u0013 be such that the matrix Q = [x Q1 ] is unitary.\najj aj\n]j := QT \u25b3Aj Q =\n, where Xj = XjT is of size n \u2212 1. Since QQT = I,\nThen \u25b3A\naj X j\nwe have\n\u0012 T \u0013\nx r\nH\nH\nT\nQ(\u25b3P(\u03bb))Q x = r \u21d2 (\u25b3P(\u03bb))Q x = Q r =\nQT1 r\n\u25b3Aj :=\n\n5\n\n\f\u0013 \u0012 T \u0013\n\u0012 Pm j\nx r\nj=0 \u03bb ajj\nP\n=\n.\nAs Q x = e1 , the first column of the identity matrix, we have\nm\nT\nj\nQ\n\u03bb\na\nj\n1r\nj=0\nH\n\n\u03bbj QT\n1 r\nk\u039bm k22\n\nHence the minimum norm solutions are aj =\nquently, we have\n\uf8eb\nT\ng =\uf8ec\n\u25b3A\n\uf8ed\nj\n\nand ajj =\n\n\u03bbj QT r\n\n\u03bbj x r\nk\u039bm k22\n\n( k\u039bm1k2 )T\n\n\u03bbj QT\n1 r\nk\u039bm k22\n\nXj\n\n2\n\n\uf8f6\n\n\u03bbj xT r\n,\nk\u039bm k22\n\nj = 0 : m. Conse-\n\n\uf8f7\n\uf8f8.\n\n(2)\n\n]j is minimized when Xj = 0. Hence we have\nThis shows that the Frobenius norm of \u25b3A\n2\n2\n2\n2\n]\nk\u25b3Aj kF = k\u25b3Aj kF = |ajj | + 2kaj k2 . Since Q1 QT1 = I \u2212 xxT , we have\ns\np\n2krk22 \u2212 |xT r|2\n|xT r|2\n2k(I \u2212 xxT )rk22\nS\n\u03b7F (\u03bb, x, P) =\n+\n=\n.\nk\u039bm k22\nk\u039bm k22\nk\u039bm k2\nNow from (2), we have\n\uf8eb\n\uf8ec\n\u25b3Aj = [x Q1 ] \uf8ed\n\n\u03bbj QT r\n\n\u03bbj xT r\nk\u039bm k22\n\n( k\u039bm1k2 )T\n\n\u03bbj QT\n1 r\nk\u039bm k22\n\n0\n\n2\n\n\uf8f6\n\uf8f7\n\uf8f8\n\n\u0012\n\nxH\nQH\n1\n\n\u0013\n\n=\n\n\u03bbj\n[xrT + rxH \u2212 (rT x)xxH ]\nk\u039bm k22\n\nwhich gives the desired polynomial \u25b3P for the Frobenius norm.\nFor the spectral norm, we employ dilation result in Theorem 3.1 to the matrix in (2).\nj\n2\nIndeed, for \u03bcj := |\u03bbk\u039b| mkrk\n, by Theorem 3.1, we have\nk2\n2\n\nXj = \u2212\nwhich gives \u03b72S (\u03bb, x, P) =\nhave\n\u25b3Aj =\n\n\u03bbj xT r QT1 r(QT1 r)T\n, j = 0 : m,\nk\u039bm k22 (krk22 \u2212 |xT r|2 )\n\nkrk2\n= \u03b7(\u03bb, x, P). Putting Xj in (2) and after simplification we\nk\u039bm k2\n\n\u03bbj\n\u03bbj xT r PxT rrT Px\nT\nH\nT\nH\n+\nrx\n\u2212\n(r\nx)xx\n]\n\u2212\n[xr\nk\u039bm k22\nk\u039bm k22 (krk22 \u2212 |xT r|2 )\n\nwhich gives the desired polynomial \u25b3P for the spectral norm. \u0004\n\nRemark 3.3 If |xT r| = krk2 , then kQT1 rk2 = 0. Hence considering Xj = 0, j = 0 : m, in\nthe above proof we obtain\n\u221a the desired results for the spectral norm. Note that in such a case\nwe have \u03b7FS (\u03bb, x, P) = 2 \u03b7(\u03bb, x, P).\nObserve that if Y is symmetric and Y x = 0 then Y = PxT ZPx for some symmetric matrix\nT\nZ. Consequently, from the proof Theorem 3.2, we have Qj Xj QH\nj = Px Zj Px , j = 0 : m, for\nsome symmetric matrices Zj . Hence we have following.\nCorollary 3.4 Let P be a symmetric matrix polynomial. For (\u03bb, x) \u2208 C \u00d7 Cn with xH x = 1,\nset r := \u2212P(\u03bb)x. Then there is a symmetric matrix polynomial Q such that P(\u03bb)x+Q(\u03bb)x = 0\nif and only if Q(z) = \u25b3P(z) + PxT R(z)Px for\nPmsome symmetric polynomial R, where \u25b3P is the\nsymmetric polynomial given by \u25b3P(z) := j=0 z j \u25b3Aj and\n\u25b3Aj :=\n\n\u03bbj\n[xrT + rxH \u2212 (rT x)xxH ], j = 0 : m.\nk\u039bm k22\n\nNext, we consider skew-symmetric matrix polynomials. Note that a matrix polynomial\nP \u2208 Pm (Cn\u00d7n ) is skew-symmetric if and only if all the coefficient matrices of P are skewsymmetric. For skew-symmetric matrix polynomials we have the following result.\n6\n\n\fTheorem 3.5 Let S denote the set of skew-symmetric matrix polynomials in Pm (Cn\u00d7n ) and\nlet P \u2208 S. For (\u03bb, x) \u2208 C \u00d7 Cn with xH x = 1, set r := \u2212P(\u03bb)x. Then we have\n\u221a\n\u03b7FS (\u03bb, x, P) = 2 \u03b7(\u03bb, x, P), \u03b72S (\u03bb, x, P) = \u03b7(\u03bb, x, P).\nFor the skew-symmetric polynomial \u25b3P given in Theorem 2.1, we have P(\u03bb)x + \u25b3P(\u03bb)x =\n0, |||\u25b3P|||F = \u03b7FS (\u03bb, x, P) and |||\u25b3P|||2 = \u03b72S (\u03bb, x, P).\nProof: The proof is the same as that of Theorem 3.2 except that \u25b3Aj is skew-symmetric for\nj = 0 : m. This gives\n\uf8f6\n\uf8eb\n]j = \uf8ed\n\u25b3A\n\n\u03bbj QT r\n\n\u2212( k\u039bm1k2 )T\n\n0\n\n2\n\n\u03bbj QT\n1 r\nk\u039bm k22\n\nXj\n\n\uf8f8.\n\n(3)\n\nSetting Xj = 0, we obtain the results for the Frobenius norm.\nSetting \u03bcj :=\n\n|\u03bbj | krk2\nk\u039bm k22\n\nand invoking Theorem 3.1, it is easily seen that the spectral norm\n\n]j in (3) is minimized when Xj = 0. Hence the desired results follow for the spectral\nof \u25b3A\nnorm. \u0004\nNote that if Y is a skew-symmetric matrix and Y x = 0 then Y = PxT ZPx for some\nskew-symmetric matrix Z. Hence we have the following result.\nCorollary 3.6 Let P \u2208 Pm (Cn\u00d7n ) be a skew-symmetric matrix polynomial. For (\u03bb, x) \u2208 C \u00d7\nCn with xH x = 1, set r := \u2212P(\u03bb)x. Then there is a skew-symmetric matrix polynomial Q such\nthat P(\u03bb)x + Q(\u03bb)x = 0 if and only if Q(z) = \u25b3P(z) + PxT R(z)Px for some skew-symmetric\nPm\npolynomial R, where \u25b3P is the skew-symmetric polynomial given by \u25b3P(z) := j=0 z i \u25b3Aj\nand\n\u03bbj\n[xrT \u2212 rxH ], j = 0 : m.\n\u25b3Aj = \u2212\nk\u039bm k22\n\n3.2\n\nT-even and T-odd matrix polynomials\n\nFor backward perturbation analysis of T -even and T -odd polynomials, we need the even index\nprojection \u03a0e : Cm+1 \u2192 Cm+1 given by\n\u001a\n[x0 , 0, x2 , 0, . . . , xm\u22122 , 0, xm ]T , if m is even,\nT\n\u03a0e ([x0 , x1 , . . . , xm\u22121 , xm ] ) :=\n[x0 , 0, x2 , 0, . . . , 0, xm\u22121 , 0]T ,\nif m is odd.\nNote that \"0\" is considered as even number. Observe that I \u2212 \u03a0e is thePodd index projection.\nm\nRecall that a matrix polynomial P \u2208 Pm (Cn\u00d7n ) given by P(z) := j=0 Aj z j is T -even if\nand only if Aj is symmetric when j is even (including j = 0) and Aj is skew-symmetric when\nj is odd. We have the following result for T -even matrix polynomials.\nTheorem 3.7 Let S denote the set of T -even matrix polynomials in Pm (Cn\u00d7n ). Let P \u2208 S\nand (\u03bb, x) \u2208 C \u00d7 Cn be such that xH x = 1. Set r := \u2212P(\u03bb)x, Px := I \u2212 xxH and \u039bm :=\n[1, \u03bb, . . . , \u03bbm ]T . Then we have\ns\ns\nkrk22 \u2212 |xT r|2 S\nkrk22 \u2212 |xT r|2\n|xT r|2\n|xT r|2\nS\n\u03b7F (\u03bb, x, P) =\n+2\n, \u03b72 (\u03bb, x, P) =\n+\n.\n2\n2\n2\nk\u03a0e (\u039bm )k2\nk\u039bm k2\nk\u03a0e (\u039bm )k2\nk\u039bm k22\n\u221a\nIn particular, if m is odd and |\u03bb| = 1 then we have \u03b7FS (\u03bb, x, P) = 2 \u03b7(\u03bb, x, P) and\n\u03b72S (\u03bb, x, P) = \u03b7(\u03bb, x, P).\nFor j = 0 : m, define\n\uf8f1\n\uf8f4\n\u03bbj\n\u03bbj\n\uf8f4\nT\nH\n\uf8f4\n(x\nr)xx\n[xrT Px + PxT rxH ], if j is even,\n+\n\uf8f2\nk\u03a0e (\u039bm )k22\nk\u039bm k22\nEj :=\n\uf8f4\n\u03bbj\n\uf8f4\n\uf8f4\n[P T rxH \u2212 xrT Px ],\nif j is odd .\n\uf8f3\nk\u039bm k22 x\n7\n\n\fPm\nThen \u25b3P(z) := j=0 z j Ej is a unique T -even polynomial in S such that P(\u03bb)x+ \u25b3P(\u03bb)x = 0\nand |||\u25b3P|||F = \u03b7FS (\u03bb, x, P). Further, for j = 0 : m, defining\n\uf8f1\n\u03bbj xT r PxT rrT Px\n\uf8f2\n, if j is even,\nEj \u2212\n\u25b3Aj :=\nk\u03a0e (\u039bm )k22 (krk22 \u2212 |xT r|2 )\n\uf8f3\nEj ,\nif j is odd,\nPm j\nwe obtain a T-even polynomial \u25b3P(z) := j=0 z \u25b3Aj in S such that P(\u03bb)x + \u25b3P(\u03bb)x = 0\nand |||\u25b3P|||2 = \u03b72S (\u03bb, x, P).\nProof: In view of Theorem 2.1, letP\u25b3P \u2208 S be such that P(\u03bb)x + \u25b3P(\u03bb)x = 0. Assuming that \u25b3P is given by \u25b3P(z) := m\n\u25b3Aj z j , and arguing similarly as in the proofs of\nj=0 \u0012\n\u0013\najj aTj\n]j =\n, XjT = Xj when j is even, and\nTheorems 3.2 and 3.5, we have \u25b3A\naj X j\n\u0013\n\u0012\n0\nbTj\n]\n, YjT = \u2212Yj when j is odd. Consequently, we have\n\u25b3Aj =\n\u2212bj Yj\nP j\n\u0013 \u0012 T \u0013\n\u0012\nx r\njj\nj\u03bb a\nP\nP\n=\n.\nj\nj\nT\n\u03bb\nb\n\u03bb\na\n\u2212\nQ\nj\nj\n1r\nj -even\nj -odd\nj\n\n\u03bb\nT\nHence the smallest norm solutions are ajj = k\u03a0e (\u039b\n2 x r, aj =\nm )k2\nTherefore, we have\n\uf8f1 \uf8eb\n\u03bbj QT r\n\u03bbj\nT\n\uf8f4\n\uf8f4\n( k\u039bm1k2 )T\n2x r\n\uf8f4\nk\u03a0\n(\u039b\n)k\ne\nm\n\uf8ec\n\uf8f4\n2\n2\n\uf8f4\n\uf8ec\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8ed\n\uf8f4\n\uf8f4\n\u03bbj QT\n\uf8f4\n1 r\nXj\n\uf8f4\n\uf8f2\nk\u039bm k22\nT\n]j = Q \u25b3Aj Q =\n\u25b3A\n\uf8f6\n\uf8eb\n\uf8f4\n\uf8f4\n\u03bbj QT\n\uf8f4\n1 r T\n\uf8f4\n0\n\u2212(\n)\n\uf8f4\nk\u039bm k22\n\uf8f4\n\uf8f7\n\uf8ec\n\uf8f4\n\uf8f4\n\uf8f7,\n\uf8ec\n\uf8f4\n\uf8f4\n\uf8f8\n\uf8ed j T\n\uf8f4\n\uf8f4\n\u03bb\nQ\nr\n\uf8f3\n1\nY\n2\nj\nk\u039bm k\n\n\u03bbj\nQT r,\nk\u039bm k22 1\n\nj\n\nbj = \u2212 k\u039b\u03bbm k2 QT1 r.\n2\n\n\uf8f6\n\n\uf8f7\n\uf8f7 , if j is even\n\uf8f8\n\n(4)\n\nif j is odd.\n\n2\n\nSetting Xj = 0 = Yj and using\nfact that Q1 QT1 = I \u2212 xxT , we obtain the desired unique\nPthe\nm\nT -even polynomial \u25b3P(z) := j=0 z j Ej such that\ns\nkrk22 \u2212 |xT r|2\n|xT r|2\n|||\u25b3P|||F = \u03b7FS (\u03bb, x, P) =\n+\n2\n.\nk\u03a0e (\u039bm )k22\nk\u039bm k22\nWhen m is odd and |\u03bb| = 1, it is easily seen that k\u03a0e (\u039bm )k22 = 21 k\u039bm k22 . Hence we have\n\u221a\n\u03b7FS (\u03bb, x, P) = 2 \u03b7(\u03bb, x, P).\nq j2 T 2\n|\u03bbj |2 (krk22 \u2212|xT r|2 )\n| |x r|\n+\nwhen j is even, and\nFor the spectral norm, setting \u03bcj := |\u03bb\nk\u03a0e (\u039bm )k42\nk\u039bm k42\nq j2\n|\u03bb | (krk22 \u2212|xT r|2 )\n\u03bcj :=\nwhen j is odd, and applying Theorem 3.1 to the matrices in (4),\nk\u039bm k42\nwe have\n\u03bbj xT r QT1 r(QT1 r)T\nand Yj = 0.\nk\u03a0e (\u039bm )k22 (krk22 \u2212 |xT r|2 )\ns\nkrk22 \u2212 |xT r|2\n|xT r|2\n+\n. From (4), we have\nConsequently, we have \u03b72S (\u03bb, x, P) =\nk\u03a0e (\u039bm )k22\nk\u039bm k22\n\uf8f1\n\u03bbj xT rxxH\n\u03bbj\n\uf8f4\nT\nT\nH\nH\n\uf8f4\n\uf8f4\n\uf8f2 k\u03a0 (\u039b )k2 + k\u03bbk2 [xr Px + Px rx ] + Q1 Xj Q1 , if j is even\ne\nm 2\n2\n\u25b3Aj =\nj\n\uf8f4\n\u03bb\n\uf8f4\n\uf8f4\n\uf8f3\n[P T rxH \u2212 xrT Px ] + Q1 Yj QH\nif j is odd.\n1 ,\nk\u03bbk22 x\nXj\n\n= \u2212\n\n8\n\n\fSubstituting Xj and Yj in \u25b3Aj we obtain the desired T -even matrix polynomial \u25b3P for the\nspectral norm. \u0004\nRemark 3.8 If |xT r| = krk2 then kQT1 rk2 = 0. Hence considering Xj = 0 = Yj in the above\nproof, we obtain\n\u221a for the spectral norm. Note that in such a case we have\n\u221a the desired result\n\u03b7FS (\u03bb, x, P) = 2 \u03b72S (\u03bb, x, P) = 2\u03b7(\u03bb, x, P).\nRecall that when A is symmetric (resp., skew-symmetric) and Ax = 0 then A = PxT ZPx for\nsome symmetric (resp., skew-symmetric) matrix Z. Consequently, from the proof Theorem 3.7\nit follows that \u25b3Aj := Ej + PxT Zj Px , where Zj = ZjT when j is even, and ZjT = \u2212Zj when j\nis odd. Hence we have the following result.\nCorollary 3.9 Let P be a T -even matrix polynomial in Pm (Cn\u00d7n ). Let (\u03bb, x) \u2208 C \u00d7 Cn be\nsuch that xH x = 1. Then there is a T -even matrix polynomial Q such that P(\u03bb)x + Q(\u03bb)x = 0\nif and only if Q(z)\n\u25b3P(z) + PxT R(z)Px for some T -even matrix polynomial R \u2208 Pm (Cn\u00d7n ),\nP=\nm\nwhere \u25b3P(z) := j=0 Ej z j and Ej 's are given in Theorem 3.7.\n\nNext, we consider backward error\nPm of T -odd polynomials. Observe that a matrix polynomial\nP \u2208 Pm (Cn\u00d7n ) given by P(z) := j=0 Aj z j is T -odd if and only if Aj is skew-symmetric when\nj is even (including j = 0) and Aj is symmetric when j is odd.\nTheorem 3.10 Let S denote the set of T -odd matrix polynomials in Pm (Cn\u00d7n ). Let P \u2208 S\nand (\u03bb, x) \u2208 C \u00d7 Cn be such that xH x = 1. Set r := \u2212P(\u03bb)x, Px := I \u2212 xxH and \u039bm :=\n[1, \u03bb, . . . , \u03bbm ]T . Then we have\n( q\nkrk22 \u2212|xT r|2\n|xT r|2\n, if \u03bb 6= 0,\n2 + 2\nS\nk\u039bm k22\n\u03b7F (\u03bb, x, P) =\n\u221a k(I\u2212\u03a0e )(\u039bm )k2\n2 \u03b7(\u03bb, x, P),\nif \u03bb = 0,\n( q\n2\nkrk2 \u2212|xT r|2\n|xT r|2\n+ k\u039b\n, if \u03bb 6= 0,\n2\nk(I\u2212\u03a0e )(\u039bm )k22\nm k2\n\u03b72S (\u03bb, x, P) =\n\u03b7(\u03bb, x, P),\nif \u03bb = 0.\n\u221a\nIn particular, if m is odd and |\u03bb| = 1 we have \u03b7FS (\u03bb, x, P) = 2 \u03b7(\u03bb, x, P) and \u03b72S (\u03bb, x, P) =\n\u03b7(\u03bb, x, P). For j = 0 : m, define\n\uf8f1\n\uf8f4\n\u03bbj\n\uf8f4\n\uf8f4\n[P T rxH \u2212 xrT Px ],\nif j is even\n\uf8f2\nk\u039bm k22 x\nFj :=\n\uf8f4\n\u03bbj xxT rxH\n\u03bbj\n\uf8f4\n\uf8f4\n+\n[xrT Px + PxT rxH ], if j is odd.\n\uf8f3\nk(I \u2212 \u03a0e )(\u039bm )k22\nk\u039bm k22\nP\nj\nThen \u25b3P(z) := m\nj=0 z Fj is a unique T -odd polynomial in S such that P(\u03bb)x + \u25b3P(\u03bb)x = 0\nand |||\u25b3P|||F = \u03b7FS (\u03bb, x, P).\nFurther, for j = 0 : m, define \u25b3Aj := Fj when j is even, and\n\u25b3Aj := Fj \u2212\n\n\u03bbj xT rPxT rrT Px\nk(I \u2212 \u03a0e )(\u039bm )k22 (krk22 \u2212 |xT r|2 )\n\nPm\nwhen j is odd. Then \u25b3P(z) := j=0 z j \u25b3Aj is a T -odd polynomial in S such that P(\u03bb)x +\n\u25b3P(\u03bb)x = 0 and |||\u25b3P|||2 = \u03b72S (\u03bb, x, P).\nProof: The desired results follow from the proof of Theorem 3.7 by interchanging the role of\n\u25b3Aj for even j and odd j. \u0004\nWe have the following results whose proof is immediate.\nCorollary 3.11 Let P be a T -odd matrix polynomial in Pm (Cn\u00d7n ). Let (\u03bb, x) \u2208 C \u00d7 Cn be\nsuch that xH x = 1. Then there is a T -odd matrix polynomial Q such that P(\u03bb)x + Q(\u03bb)x = 0\nif and only if Q(z)\n= \u25b3P(z) + PxT R(z)Px for some T -odd matrix polynomial R \u2208 Pm (Cn\u00d7n ),\nPm\nwhere \u25b3P(z) := j=0 Fj z j and Fj 's are given in Theorem 3.10.\n9\n\n\f3.3\n\nHermitian and skew-Hermitian matrix polynomials\n\nWe now consider structured backward errors of approximate eigenelements of Hermitian and\nskew-Hermitian matrix polynomials. We proceed as follows. Let S \u2282 Pm (Cn\u00d7n ) and \u03c9 \u2208 C\nbe such that |\u03c9| = 1. We set S\u03c9 := {\u03c9P : P \u2208 S}. Then for P \u2208 Pm (Cn\u00d7n ), it is easily seen\nthat\n\u03b7FS (\u03bb, x, P) = \u03b7FS\u03c9 (\u03bb, x, \u03c9P) and \u03b72S (\u03bb, x, P) = \u03b72S\u03c9 (\u03bb, x, \u03c9P).\n(5)\nNote that a matrix polynomial P \u2208 Pm (Cn\u00d7n ) is Hermitian (resp., skew-Hermitian) if and\nonly if all the coefficient matrices of P are Hermitian (resp., skew-Hermitian). Let Herm and\nskew-Herm, respectively, denote the set of Hermitian and skew-Hermitian matrix polynomials\nin Pm (Cn\u00d7n ). Then noting that a matrix X \u2208 Cn\u00d7n is Hermitian if and only if iX is skewHermitian, it easily seen that the maps\nHerm \u2212\u2192 skew-Herm, P 7\u2212\u2192 iP and skew-Herm \u2212\u2192 Herm, Q 7\u2212\u2192 iQ\n\n(6)\n\nare isometric isomorphisms. Thus, in view of (5) and (6), it follows that the structured\nbackward error of (\u03bb, x) as an approximate eigenpair of a skew-Hermitian polynomial can\nbe obtained from the structured backward error of (\u03bb, x) as an approximate eigenpair of\na Hermitian matrix polynomial and vice-versa. We therefore analyze structured backward\nperturbation of Hermitian matrix polynomials.\nFor x \u2208 Cn , we denote by Re(x) and Im(x), respectively, the real and the imaginary parts\nof x. Then we have x = Re(x) + iIm(x). We denote the real and imaginary part of a complex\nnumber z \u2208 C by re(z) and im(z), respectively. We denote the Moore-Penrose pseudo-inverse\nof A by A\u2020 and the canonical basis of Cm+1 by ej , j = 0 : m.\nTheorem 3.12 Let Herm denote the set of Hermitian matrix polynomials in Pm (Cn\u00d7n ). Let\nP \u2208 Herm and (\u03bb, x) \u2208 C \u00d7 Cn be such that xH x = 1. Set r := \u2212P(\u03bb)x, Px := I \u2212 xxH and\n\u039bm := [1, \u03bb, . . . , \u03bbm ]T . Then we have\n\uf8f1 \u221a\n\uf8f2 2krk22 \u2212|xH r|2 \u2264 \u221a2\u03b7(\u03bb, x, P), if \u03bb \u2208 R,\nHerm\nq k\u039bm k2\n\u03b7F (\u03bb, x, P) =\n2(krk22 \u2212|xH r|2 )\n\uf8f3 kb\nrk22 +\n,\nif \u03bb \u2208 C \\ R,\nk\u039bm k22\n(\n\u03b7(\u03bb, x, P),\nif \u03bb \u2208 R,\nq\n\u03b72Herm (\u03bb, x, P) =\nkrk22 \u2212|xH r|2\n2\nkb\nrk2 + k\u039bm k2 , if \u03bb \u2208 C \\ R,\n2\n\n\u0014\n\n\u0015\u2020 \u0014\n\u0015\nRe(\u039bm )T\nre(xH r)\n. For the Frobenius norm, define\nIm(\u039bm )T\nim(xH r)\n\uf8f1\n\u03bbj\n\uf8f4\nH\nH\nH\nH\n\uf8f4\n\uf8f2\nwhen \u03bb \u2208 R,\n2 (xr + rx \u2212 (r x)xx ),\nk\u039b\nk\nm\n2\n\u25b3Aj :=\n1\n\uf8f4\n\uf8f4\n[\u03bbj Px rxH + \u03bbj xrH Px ], when \u03bb \u2208 C \\ R.\n\uf8f3 eTj rbxxH +\nk\u039bm k22\nPm\nThen \u25b3P(z) := j=0 z j \u25b3Aj is a unique Hermitian polynomial in Herm such that P(\u03bb)x +\n\u25b3P(\u03bb)x = 0 and |||\u25b3P|||F = \u03b7FHerm (\u03bb, x, P).\nFor the spectral norm, define\n\uf8f1\n\u03bbj\n\u03bbj xH rPx rrH Px\n\uf8f4\nH\nH\nH\nH\n\uf8f4\n\uf8f2 k\u039b k2 (rx + xr \u2212 (r x)xx ) \u2212 k\u039b k2 (krk2 \u2212 |xH r|2 ) , when \u03bb \u2208 R,\nm 2\nm 2\n2\n\u25b3Aj :=\nT\nH\ne\nr\nb\nP\n\uf8f4\n1\nx rr Px\nj\n\uf8f4\n\uf8f3 eTj rbxxH +\n[\u03bbj Px rxH + \u03bbj xrH Px ] \u2212\n,\nwhen \u03bb \u2208 C \\ R.\n2\n2\nk\u039bm k2\nkrk2 \u2212 |xH r|2\nPm\nThen \u25b3P(z) := j=0 z j \u25b3Aj is a Hermitian polynomial in Herm such that P(\u03bb)x+\u25b3P(\u03bb)x =\n0 and |||\u25b3P|||2 = \u03b72Herm (\u03bb, x, P).\nwhere rb :=\n\n10\n\n\fPm\nProof: Again, in view of Theorem 2.1, let \u25b3P(z) = j=0 z j \u25b3Aj be a Hermitian polynomial\nsuch that \u25b3P(\u03bb)x + P(\u03bb)x = 0. Choosing a unitary matrix Q := [x, Q1 ], we have\n\u0013\n\u0012 H \u0013\n\u0012\najj aH\nx r\nH\nH\nj\n]\n, Q r=\n\u25b3Aj := Q \u25b3Aj Q =\n.\nQH\naj X j\n1 r\n\u0013 \u0012 H \u0013\n\u0012 Pm j\nx r\nj=0 \u03bb ajj\nP\n=\n. The minimum norm solution of\nNow \u25b3P(\u03bb)x + P(\u03bb)x = 0 \u21d2\nm\nH\nj\nQ\n\u03bb\na\nj\n1 r\nj=0\nPm j\n\u03bbj\nH\nH\nj=0 \u03bb aj = Q1 r is given by aj = k\u039bm k22 Q1 r.\nP\nj\nH\nNow suppose that \u03bb \u2208 R. Then the minimum norm solution of m\nj=0 \u03bb ajj = x r is given\nby ajj =\n\n\u03bbj\nxH r\nk\u039bm k22\n\n\u2208 R. Hence for \u03bb \u2208 R, we have\n\u03bbj\nxH r\nk\u039bm k22\n\u03bbj\nQH r\nk\u039bm k22 1\n\n]j =\n\u25b3A\n\nj\n\nH\n( k\u039b\u03bbm k2 QH\n1 r)\n2\n\nXj\n\n!\n\n, j = 0 : m.\n\n(7)\n\n\u221a\n2krk22 \u2212|r H x|2\nand the\nFor the Frobenius norm, setting Xj = 0 we obtain \u03b7FHerm (\u03bb, x, P) =\nk\u039bm k2\ndesired Hermitian polynomial \u25b3P.\nj\n2\nand applying Theorem 3.1 to (7), we obtain\nFor the spectral norm, setting \u03bcj := |\u03bbk\u039b| mkrk\nk2\n2\n\nXj = \u2212\n\nH H\n\u03bbj xH r(QH\n1 r)(Q1 r)\n.\n2\n2\nk\u039bm k2 (krk2 \u2212 |xH r|2 )\n\nkrk2\n= \u03b7(\u03bb, x, P). Now substituting Xj in (7) and simplifying\nThis gives \u03b7 Herm (\u03bb, x, P) = k\u039b\nm k2\nthe expression, we obtain the desired Hermitian polynomial \u25b3P.\nPm\nNext, suppose that \u03bb \u2208 C \\ R. Then the minimum norm solution of j=0 \u03bbj ajj = xH r is\nobtained by solving\n\uf8eb\n\uf8f6\na00\n\u0013 \u0012\n\u0013\n\u0012 Pm\n\u0012\n\u0013\u2020 \u0012\n\u0013\nj\nH\nre(x r)\nRe(\u039bm )T\nre(xH r)\n\uf8ec .. \uf8f7\nj=0 re(\u03bb )ajj\nPm\n=\n\u21d2\uf8ed . \uf8f8=\n=: rb.\nj\nim(xH r)\nIm(\u039bm )T\nim(xH r)\nj=0 im(\u03bb )ajj\namm\n\nTherefore we have ajj = eTj rb. Hence for \u03bb \u2208 C \\ R, we have\nH\n\nQ \u25b3Aj Q =\n\nj\n\nH\n( k\u039b\u03bbm k2 QH\n1 r)\n\neTj rb\n\n2\n\n\u03bbj\nQH r\nk\u039bm k22 1\n\nXj\n\n!\n\n, j = 0 : m.\n\n(8)\n\nThus, for the Frobenius norm, setting Xj = 0 we obtain\ns\nkrk22 \u2212 |rH x|2\n\u03b7FHerm (\u03bb, x, P) = kb\nrk22 + 2\nk\u039bm k22\nand the desired Hermitian polynomial \u25b3P.q\n|eTj rb|2 +\nFor the spectral norm, setting \u03bcj :=\nrem 3.1 to the matrix in (8), we have\nXj = \u2212\nThis gives\n\n|\u03bbj |2 (krk22 \u2212|xH r|2 )\nk\u039bm k42\n\nH H\neTj rb (QH\n1 r)(Q1 r)\n, j = 0 : m.\nkrk22 \u2212 |xH r|2\n\n\u03b72Herm (\u03bb, x, P)\n\n=\n\ns\n\nkb\nrk22 +\n11\n\nkrk22 \u2212 |xH r|2\n.\nk\u039bm k22\n\nand applying Theo-\n\n\fNow substituting Xj in (8) and simplifying the expression, we have\n\u25b3Aj = eTj rbxxH +\n\n1\n\nH\nj\nH\nj\n2 [\u03bb Px rx + \u03bb xr Px ] \u2212\n\nk\u039bm k2\n\nHence the results follow. \u0004\n\neTj rb Px rrH Px\n.\nkrk22 \u2212 |xH r|2\n\nRemark 3.13 If |xH r| = krk2 then kQH\n1 rk2 = 0. Hence considering Xj = 0, j = 0 : m, we\nobtain the desired results for the spectral norm.\nLet x \u2208 Cn be such that xH x = 1. If A \u2208 Cn\u00d7n is Hermitian and Ax = 0 then it is easily\nseen that A = (I \u2212 xxH )Z(I \u2212 xxH ) for some Hermitian matrix Z. Consequently, in view\nof Theorem 3.12, we have an analogue of the result in Corollary 3.4 for Hermitian matrix\npolynomials.\nNote that, in view of (5) and (6), structured backward error of (\u03bb, x) as an approximate\neigenpair of a skew-Hermitian matrix polynomial follows from Theorem 3.12. Indeed, let\nQ \u2208 skew-Herm \u2282 Pm (Cn\u00d7n ) be a skew-Hermitian matrix polynomial. Then P := iQ \u2208\nskew-Herm\nHerm\nHerm \u2282 Pm (Cn\u00d7n ). Hence by (5) and (6), we have \u03b7M\n(\u03bb, x, Q) = \u03b7M\n(\u03bb, x, P). Now,\nlet \u25b3P be the matrix polynomial given in Theorem 3.12 such that P(\u03bb)x + \u25b3P(\u03bb)x = 0 and\nHerm\n|||\u25b3P|||M = \u03b7M\n(\u03bb, x, P). Then setting \u25b3Q := \u2212i\u25b3P, we have \u25b3Q \u2208 skew-Herm such that\nskew-Herm\nQ(\u03bb)x + \u25b3Q(\u03bb)x = 0 and |||\u25b3Q|||M = \u03b7M\n(\u03bb, x, Q).\n\n3.4\n\nH-even and H-odd matrix polynomials\n\nWe now derive structured backward errors of approximate eigenelements of H-even and Hodd\npolynomials. Recall that a matrix polynomial P \u2208 Pm (Cn\u00d7n ) given by P(z) :=\nPm matrix\nj\nj=0 Aj z is H-even if and only if Aj is Hermitian when j is even (including j = 0) and\nAj is skew-Hermitian when j is odd. Let H-even and H-odd, respectively, denote the set\nof H-even and H-odd matrix polynomials in Pm (Cn\u00d7n ). Then, as in the case of Hermitian\nmatrix polynomials in (6), it is easily seen that the map\nH-even \u2212\u2192 H-odd, P 7\u2212\u2192 iP and H-odd \u2212\u2192 H-even, Q 7\u2212\u2192 iQ\n\n(9)\n\nare isometric isomorphisms. Consequently, we only need to prove the results either for H-even\nor for H-odd matrix polynomials. Recall that A\u2020 is the Moore-Penrose pseudo-inverse of A\nand ej , j = 0 : m, is the canonical basis of Cm+1 .\nTheorem 3.14 Set S := H-even \u2282 Pm (Cn\u00d7n ). Let P \u2208 S and (\u03bb, x) \u2208 C \u00d7 Cn be such that\nxH x = 1. Set r := \u2212P(\u03bb)x, Px := I \u2212 xxH and \u039bm := [1, \u03bb, . . . , \u03bbm ]T . Then we have\n\uf8f1 \u221a\n\u221a\n2krk22 \u2212|xH r|2\n\uf8f4\n\uf8f2\n\u2264 2\u03b7(\u03bb, x, P), if \u03bb \u2208 i R,\nk\u039b\nk\nm\n2\n\u03b7FS (\u03bb, x, P) =\nq\n\uf8f4\n2(krk22 \u2212|xH r|2 )\n\uf8f3 kb\n,\nif \u03bb \u2208 C \\ i R,\nr k22 +\nk\u039bm k22\n\uf8f1\nif \u03bb \u2208 i R,\n\uf8f2 \u03b7(\u03bb, x, P),\nq\n\u03b72S (\u03bb, x, P) =\nkrk22 \u2212|xH r|2\n\uf8f3 kb\nr k22 + k\u039b\n, if \u03bb \u2208 C \\ i R,\n2\nmk\n2\n\nwhere rb :=\n\n\u0014\n\n\u03a0e Re(\u039bm )T \u2212 (I \u2212 \u03a0e )Im(\u039bm )T\n\u03a0e Im(\u039bm )T + (I \u2212 \u03a0e )Re(\u039bm )T\n\nEj :=\n\n\u0015\u2020 \u0014\n\n\u0015\nre(xH r)\n. For j = 0 : m, set\nim(xH r)\n\n1\n1\n[\u03bbj Px rxH + \u03bbj xrH Px ] and Fj :=\n[\u03bbj Px rxH \u2212 \u03bbj xrH Px ].\nk\u039bm k22\nk\u039bm k22\n\n12\n\n\fFor the Frobenius norm, define \u25b3Aj :=\n\u001a\n\n\u03bbj\n[xrH + rxH \u2212 (rH x)xxH ] when \u03bb \u2208 i R, and\nk\u039bm k22\n\neTj rbxxH + Ej , if j is even,\nieTj rbxxH + Fj , if j is odd,\nP\nj\nwhen \u03bb \u2208 C \\ i R, for j = 0 : m. Then \u25b3P(z) := m\nj=0 z \u25b3Aj is a unique H-even polynomial\nS\nin S such that P(\u03bb)x + \u25b3P(\u03bb)x = 0 and |||\u25b3P|||F = \u03b7F (\u03bb, x, P).\nFor the spectral norm, define\n\u25b3Aj :=\n\n\u25b3Aj :=\nwhen \u03bb \u2208 i R, and\n\n\u25b3Aj :=\n\n(\u22121)j+1 \u03bbj xH rPx rrH Px\n\u03bbj\nH\nH\nH\nH\n[xr\n+\nrx\n\u2212\n(r\nx)xx\n]\n+\nk\u039bm k22\nk\u039bm k22 (krk22 \u2212 |xH r|2 )\n\uf8f1\n(\u22121)j+1 eTj rb Px rrH Px\n\uf8f4\nT\nH\n\uf8f4\ne\nr\nb\nxx\n+\nE\n+\n,\n\uf8f4\nj\n\uf8f4\n\uf8f2 j\nkrk22 \u2212 |xH r|2\n\nif j is even,\n\n\uf8f4\n\uf8f4\ni (\u22121)j+1 eTj rb Px rrH Px\n\uf8f4\n\uf8f4\n\uf8f3 ieTj rbxxH + Fj \u2212\n, if j is odd,\nkrk22 \u2212 |xH r|2\nPm j\nwhen \u03bb \u2208 C \\ i R. Then \u25b3P(z) :=\nj=0 z \u25b3Aj is an H-even polynomial in S such that\nP(\u03bb)x + \u25b3P(\u03bb)x = 0 and |||\u25b3P|||2 = \u03b72S (\u03bb, x, P).\nP\nj\nProof: By Theorem 2.1 there exists an H-even matrix polynomial \u25b3P(z) = m\nj=0 z \u25b3Aj\nsuch\nthat\n\u25b3P(\u03bb)\n=\nr.\nNow\nchoosing\na\nunitary\nmatrix\nQ\n:=\n[x,\nQ\n],\nwe\nhave\n\u25b3A\n1 \u0013\nj =\n\u0013\n\u0012\n\u0012\nH\nia\na\najj aH\njj\nj\nj\nQH , YjH = \u2212Yj\nQH , XjH = Xj if j is even, and \u25b3Aj = Q\nQ\n\u2212aj Yj\naj X j\nif j is odd. Notice that ajj is real\nfor all j.\nP\n\u0013\n\u0012 H \u0013\n\u0012 P\nj\nj\nx r\nj -even \u03bb ajj + iP j -odd \u03bb ajj\nP\n. The mini=\nThen \u25b3P(\u03bb)x = r gives\nH\nj\nj\nQ\n\u03bb\na\n\u03bb\na\n\u2212\nj\nj\n1 r\nj -even\nj -odd\nP\nP\n\u03bbj\nH\nmum norm solution of j -even \u03bbj aj \u2212 j -odd \u03bbj aj = QH\n1 r is given by aj = k\u039bm k2 Q1 r if j\n2\n\nj\n\nis even, and aj = \u2212 k\u039b\u03bbm k2 QH\n1 r if j is odd.\n2\nNow suppose that \u03bb \u2208 iR. Then the minimum norm solution\n\u03bbj\n\u03bbj\nxH r when j is even, and ajj = \u2212 k\u039bi m\nxH r when j is odd.\nk\u039bm k22\nk22\neven, and iajj \u2208 i R when j is odd. Consequently, we have\n\uf8eb\nj\n\u03bbj\nH\nxH r ( k\u039b\u03bbm k2 QH\n1 r)\nk\u039bm k22\n2\n\uf8ec\nH\nQ \u25b3Aj Q = \uf8ed\n\u03bbj\nQH r\nXj\nk\u039bm k2 1\n2\n\nwhen j is even, and\n\n\uf8eb\n\n\uf8ec\nQH \u25b3Aj Q = \uf8ed\n\n\u03bbj\nxH r\nk\u039bm k22\n\u03bbj\n\nQH r\nk\u039bm k22 1\n\nj\n\nH\n\u2212( k\u039b\u03bbm k2 QH\n1 r)\n2\n\nYj\n\nfor ajj is given by ajj =\nHence ajj \u2208 R when j is\n\uf8f6\n\uf8f7\n\uf8f8\n\uf8f6\n\uf8f7\n\uf8f8\n\n(10)\n\n(11)\n\n\u221a\n2krk22 \u2212|r H x|2\nwhen j is odd. Setting Xj = 0 = Yj in (10) and (11), we obtain \u03b7FS (\u03bb, x, P) =\nk\u039bm k2\nand the desired \u25b3Aj .\nP\nP\nNext, suppose that \u03bb \u2208 C \\ i R. Then j -even \u03bbj ajj + i j -odd \u03bbj ajj = xH r gives\nP\n\u0013 \u0012\n\u0013\n\u0012 P\nre(\u03bbj )ajj \u2212 j -odd im(\u03bbj )ajj\nre(xH r)\nP\nPj -even\n=\n.\nj\nj\nim(xH r)\nj -even im(\u03bb )ajj +\nj -odd re(\u03bb )ajj\n13\n\n\fHence we\n\uf8eb\na00\n\uf8ec a11\n\uf8ec\n\uf8ec ..\n\uf8ed .\n\namm\n\nhave\n\uf8f6\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f8\n\n=\n\n\u0012\n\n\u03a0e Re(\u039bm )T \u2212 (I \u2212 \u03a0e )Im(\u039bm )T\n\u03a0e Im(\u039bm )T + (I \u2212 \u03a0e )Re(\u039bm )T\n\n\u0013\u2020 \u0012\n\nre(xH r)\nim(xH r)\n\n\u0013\n\n= rb \u21d2 ajj = eTj rb.\n\nConsequently, we have\n\uf8eb\n\n\uf8ec\nQH \u25b3Aj Q = \uf8ed\n\nwhen j is even, and\n\n\uf8eb\n\n\uf8ec\nQH \u25b3Aj Q = \uf8ed\n\neTj rb\n\nj\n\nH\n( k\u039b\u03bbm k2 QH\n1 r)\n2\n\n\u03bbj\n\nQH r\nk\u039bm k22 1\n\nieTj rb\n\n\u03bbj\n\nQH r\nk\u039bm k22 1\n\nXj\n\nj\n\nH\n\u2212( k\u039b\u03bbm k2 QH\n1 r)\n2\n\nYj\n\n\uf8f6\n\uf8f7\n\uf8f8\n\uf8f6\n\uf8f7\n\uf8f8\n\n(12)\n\n(13)\n\nwhen j is odd. Now setting Xj =s0 = Yj in (12) and (13), we have the desired matrices\nkrk22 \u2212 |xH r|2\nr k22 + 2\n\u25b3Aj , j = 0 : m, and \u03b7FS (\u03bb, x, P) = kb\n. This completes the proof for the\nk\u039bm k22\nFrobenius norm.\nj\n2\nFor the spectral norm, consider \u03bcj := |\u03bbk\u039b| mkrk\nwhen \u03bb \u2208 iR. Then applying Theorem 3.1\nk22\nto the matrices in (10) and (11), we obtain\nXj = \u2212\n\nH H\nH H\n\u03bbj xH r(QH\n\u03bbj xH r(QH\n1 r)(Q1 r)\n1 r)(Q1 r)\nand\nY\n=\n.\nj\nk\u039bm k22 (krk22 \u2212 |xH r|2 )\nk\u039bm k22 (krk22 \u2212 |xH r|2 )\n\nkrk2\n. Now substituting Xj and Yj in (10) and (11), we obtain the\nThis gives \u03b72S (\u03bb, x, P) = k\u039b\nm k2\ndesired matrices \u25b3Aj , j = 0 : m.\nq\n|\u03bbj |2 (krk22 \u2212|xH r|2 )\nWhen \u03bb \u2208 C \\ i R, considering \u03bcj := |eTj rb|2 +\nand applying Theok\u039bm k42\nrem 3.1 to the matrices in (12) and (13), we obtain\n\nXj = \u2212\nConsequently, we have\n\nH H\nH H\neTj rb (QH\nieTj rb (QH\n1 r)(Q1 r)\n1 r)(Q1 r)\nand\nY\n=\n\u2212\n.\nj\nkrk22 \u2212 |xH r|2\nkrk22 \u2212 |xH r|2\n\n\u03b72S (\u03bb, x, P) =\n\ns\n\nkb\nrk22 +\n\nkrk22 \u2212 |xH r|2\n.\nk\u039bm k22\n\nSubstituting Xj and Yj in (12) and (13), we obtain the desired matrices \u25b3Aj , j = 0 : m. \u0004\nLet x \u2208 C be such that xH x = 1. If X \u2208 Cn\u00d7n is skew-Hermitian and Xx = 0 then it is\neasily seen that X = (I \u2212 xxH )Z(I \u2212 xxH ) for some skew-Hermitian matrix Z. Consequently,\nit follows that an analogue of the result in Corollary 3.11 holds for H-even matrix polynomials.\nObserve that, in view of (5) and (9), the structured backward error of (\u03bb, x) as an\napproximate eigenpair of an H-odd matrix polynomial follows from Theorem 3.14. Indeed, let Q be an H-odd matrix polynomial in Pm (Cn\u00d7n ). Set Se := H-even \u2282 Pm (Cn\u00d7n )\nand So := H-odd \u2282 Pm (Cn\u00d7n ). Then P := iQ \u2208 Se . Hence by (5) and (9), we have\nSo\nSe\n\u03b7M\n(\u03bb, x, Q) = \u03b7M\n(\u03bb, x, P). Now, let \u25b3P be the matrix polynomial given in Theorem 3.14 such\nSe\nthat \u25b3P \u2208 Se , P(\u03bb)x + \u25b3P(\u03bb)x = 0 and |||\u25b3P|||M = \u03b7M\n(\u03bb, x, P). Then setting \u25b3Q := \u2212i\u25b3P,\nSo\nwe have \u25b3Q \u2208 So , Q(\u03bb)x + \u25b3Q(\u03bb)x = 0 and |||\u25b3Q|||M = \u03b7M\n(\u03bb, x, P).\n14\n\n\f3.5\n\nPolynomials with coefficients in Lie and Jordan algebras\n\nWe mention that the structured backward perturbation analysis of structured matrix polynomials discussed so far can easily be extended to more general structured matrix polynomials in\nwhich the coefficient matrices are elements of appropriate Jordan and/or Lie algebras. Indeed,\nlet M be a unitary matrix such that M T = M or M T = \u2212M. Consider the Jordan algebra\nJ := {A \u2208 Cn\u00d7n : M \u22121 AT M = A} and the Lie algebra L := {A \u2208 Cn\u00d7n : M \u22121 ATP\nM = \u2212A}\nm\nassociated with the scalar product (x, y) 7\u2192 y T M x. Consider a polynomial P(z) := j=0 z j Aj .\nPm j\nThen by imposing the condition that the polynomial M P given by M P(z) = j=0 \u03bb M Aj is\neither symmetric or skew-symmetric or T -even or T -odd, we obtain various structured matrix\npolynomials. Said differently, S \u2282 Pm (Cn\u00d7n ) defines a class of structured matrix polynomials\nif M S \u2208 {sym, skew-sym, T -even, T -odd}. Hence if P \u2208 S then the results obtained in the\nprevious section are easily extended to P by replacing Aj and r := \u2212P(\u03bb)x by M Aj and M r,\nrespectively.\nSimilarly, when M is unitary and M = M H or M = \u2212M H , we consider the Jordan\nalgebra J := {A \u2208 Cn\u00d7n : M \u22121 AH M = A} and the Lie algebra L := {A \u2208 Cn\u00d7n :\nM \u22121 AH M = \u2212A} associated with the scalar product (x, y) 7\u2192 y H M x. Then a class of\nstructured matrix polynomials S \u2282 Pm (Cn\u00d7n ) is obtained by imposing the condition that\nM S \u2208 {Herm, skew-Herm, H-even, H-odd}. Hence the results obtained in the previous section\nare easily extended to P \u2208 S by replacing\u0012Aj and r \u0013\n:= \u2212P(\u03bb)x by M Aj and M r, respectively.\n0 I\nIn particular, when M := J, where J :=\n\u2208 C2n\u00d72n , the Jordan algebra J consists\n\u2212I 0\nof skew-Hamiltonian matrices and the Lie algebra\nof Hamiltonian matrices. So, for\nP L consists\nj\nexample, considering the polynomial P(z) := m\nz\nA\n,\nwhere\nAj s are Hamiltonian when j\nj\nj=0\nPm\nis even and skew-Hamiltonian when j is odd, we see that the polynomial JP(z) = j=0 z j JAj\nis H-even. Hence extending the results obtained for H-even polynomial to the case of P, we\nhave the following.\nPm j\nTheorem 3.15 Let S denote set of polynomials of the form P(z) =\nj=0 z Aj where Aj\nis Hamiltonian when j is even, and Aj is skew-Hamiltonian when j is odd. Let P \u2208 S\nand (\u03bb, x) \u2208 C \u00d7 Cn be such that xH x = 1. Set r := \u2212P(\u03bb)x, Px := I \u2212 xxH and \u039bm :=\n[1, \u03bb, . . . , \u03bbm ]T . Then we have\n\uf8f1 \u221a\n\u221a\n2krk22 \u2212|xH Jr|2\n\uf8f4\n\uf8f2\n\u2264 2\u03b7(\u03bb, x, P), if \u03bb \u2208 i R,\nk\u039b\nk\nm\n2\n\u03b7FS (\u03bb, x, P) =\nq\n\uf8f4\n2(krk22 \u2212|xH Jr|2 )\n\uf8f3 kb\n,\nif \u03bb \u2208 C \\ i R,\nrk22 +\nk\u039bm k22\n\uf8f1\nif \u03bb \u2208 i R,\n\uf8f2 \u03b7(\u03bb, x, P),\nq\n\u03b72S (\u03bb, x, P) =\nkrk22 \u2212|xH Jr|2\n\uf8f3 kb\nrk22 +\n, if \u03bb \u2208 C \\ i R,\nk\u039bm k2\n2\n\n\u0014\n\n\u0015\u2020 \u0014\n\u0015\n\u03a0e (Re(\u039bm )T ) \u2212 (I \u2212 \u03a0e )(Im(\u039bm )T )\nre(xH Jr)\nwhere rb :=\n.\n\u03a0e (Im(\u039bm )T ) + (I \u2212 \u03a0e )(Re(\u039bm )T )\nim(xH Jr)\n\n4\n\nEffect of structured linearization on backward error\n\nAs we have mentioned before, linearization is the standard approach to solving a polynomial\neigenvalue value problem. It is well known that important classes of structured matrix polynomials admit structured linearizations [18, 12, 21, 20]. However, the process of linearizing a\nmatrix polynomial (structure preserving or not) has its side effect too. It increases the sensitivity of eigenvalues of the matrix polynomial (see, [13, 1, 4]). Therefore, it is important to\nidentify linearizations whose eigenelements are almost as sensitive to perturbations as those of\nthe matrix polynomial. Obviously, condition numbers of eigenvalues and backward errors of\napproximate eigenelements have an important role to play in identifying such linearizations.\n15\n\n\fFor an unstructured polynomial P \u2208 Pm (Cn\u00d7n ), Higham et al. [13, 11] provide a recipe for\nchoosing a linearization by analyzing condition numbers of eigenvalues and backward errors\nof approximate eigenpairs. For structured matrix polynomials, a recipe for choosing a structured linearization has been provided in [4] by analyzing structured condition numbers of\neigenvalues. With a view to identifying optimal and near optimal structured linearizations\nof a structured matrix polynomials, in this section, we analyze the influence of structured\nlinearizations on the structured backward errors of approximate eigenelements. It turns out\nthat linearizations which minimize structured backward errors also minimize the structured\ncondition numbers. Therefore our results are consistent with those in [4]. We thus provide a\nrecipe for choosing structured linearizations of a structured matrix polynomial which minimize\nstructured backward errors as well as the structured condition numbers.\nFor a ready reference, we briefly review some basic results about linearizations of P \u2208\nPm (Cn\u00d7n ), for details, see [20, 18, 12, 21]. For our purpose, it is enough to consider the\nvector space L1 (P) given by [20]\nL1 (P) := {L(\u03bb) : L(\u03bb).(\u039bm\u22121 \u2297 In ) = v \u2297 P(\u03bb), v \u2208 Cm },\nwhere \u039bm\u22121 := [\u03bbm\u22121 , \u03bbm\u22122 , . . . , 1]T , \u2297 is the Kronecker product and v is called the right\nansatz vector for L. Let v := [v1 , v2 , . . . , vm ]T \u2208 Cm be a right ansatz vector. Then the\nscalar polynomial p(x; v) := v1 xm\u22121 + v2 xm\u22122 + . . . + vm\u22121 x + vm is referred to as the \"vpolynomial\" of the vector v, see [18, 20]. The convention is that p(x; v) is said to have a root\nat \u221e whenever v1 = 0. Let L(\u03bb) = \u03bbX + Y \u2208 L1 (P) be a linearization of P corresponding to\nthe right ansatz vector v \u2208 Cm . Then for x \u2208 Cn , the following holds\nkL(\u03bb)(\u039bm\u22121 \u2297 x)k2\n\n= kvk2 kP(\u03bb)xk2 ,\n\n(14)\n\nT\n\n=\n\nH\n\n=\n\n(16)\n\n|(\u039bm\u22121 \u2297 x) L(\u03bb)(\u039bm\u22121 \u2297 x)|\n\n|(\u039bm\u22121 \u2297 x) L(\u03bb)(\u039bm\u22121 \u2297 x)|\n\n|\u039bTm\u22121 v| |xT P(\u03bb)x|,\nH\n|\u039bH\nm\u22121 v| |x P(\u03bb)x|.\n\n(15)\n\nObserve from (14) that (\u03bb, x) is an eigenelement of P if and only if (\u03bb, \u039bm\u22121 \u2297 x) is an\neigenelement of L. Consequently, when (\u03bb, x) \u2208 C \u00d7 Cn is considered as an approximate\neigenelement of P, it is natural to consider (\u03bb, \u039bm\u22121 \u2297 x) \u2208 C \u00d7 Cmn as an approximate\neigenelement of L and vice-versa. We denote the (unstructured) backward error of (\u03bb, \u039bm\u22121 \u2297\nx) as an approximate eigenelement of L by \u03b7(\u03bb, \u039bm\u22121 \u2297 x, L; v) so as to show the dependence\nof the backward error on the ansatz vector v. Similarly, we denote the structured backward\nS\nby \u03b7M\n(\u03bb, \u039bm\u22121 \u2297 x, L; v), where M \u2208 {2, F }.\nNow suppose that (\u03bb, x) \u2208 C \u00d7 Cn with xH x = 1 is an approximate eigenpair of P. In\nview of (14) - (16), we only need to consider ansatz vectors v having unit norm. We use the\ninequality\nr\nm+1\nk\u039bm k2\n\u22641\n(17)\n\u2264\n2m\nk\u039bm\u22121 k2 k(\u03bb, 1)k2\nwhich is derived in (Lemma A.1, [13]).\nTheorem 4.1 Let P \u2208 Pm (Cn\u00d7n ) be regular and L \u2208 L1 (P) be a linearization of P corresponding to the normalized right ansatz vector v. Let (\u03bb, x) \u2208 C \u00d7 Cn be such that xH x = 1.\nSet \u039bm\u22121 := [\u03bbm\u22121 , . . . , \u03bb, 1]T . Then we have\nr\nm+1\n\u03b7(\u03bb, \u039bm\u22121 \u2297 x, L; v)\n\u2264\n\u2264 1.\n2m\n\u03b7(\u03bb, x, P)\n\n16\n\n\fProof: By (1) and (14), we have\n\u03b7(\u03bb, \u039bm\u22121 \u2297 x, L; v) =\n=\n=\n\nkvk2 kP(\u03bb)xk2\nkL(\u03bb)(\u039bm\u22121 \u2297 x)k2\n=\nk(\u039bm\u22121 \u2297 x)k2 k(\u03bb, 1)k2\nk(\u039bm\u22121 \u2297 x)k2 k(\u03bb, 1)k2\nkvk2 k\u039bm k2 kxk2\n\u03b7(\u03bb, x, P)\nk(\u039bm\u22121 \u2297 x)k2 k(\u03bb, 1)k2\nk\u039bm k2\n\u03b7(\u03bb, x, P).\nk\u039bm\u22121 k2 k(\u03bb, 1)k2\n\nHence by (17) the desired result follows. \u0004\nTheorem 4.1 shows that as far as the backward errors of approximate eigenelements of\nP are concerned, any linearization from L1 (P) is as good as any other provided that the\nlinearization is associated to a normalized right ansatz vector. In contrast, restricting L in\nDL(P) (see, [20]), it is shown in [4] that the\u221acondition number of an eigenvalues \u03bb of P is\nincreased at least by \u03b4(\u03bb, v) and at most by 2 \u03b4(\u03bb, v), where \u03b4(\u03bb, v) := k\u039bm\u22121 k2 /|p(x; v)|,\nsee also [13].\nFor a structured matrix polynomials, there exists infinitely many structured linearizations, see [12, 21, 18]. For the structures we consider in this paper, we consider structured\nlinearization from L1 (P). For a ready reference, we summarize in Table 2 the condition on\nansatz vector for a structured linearization, see [12, 21]. The matrix \u03a3 in Table 2 is given by\n\u03a3 = diag{(\u22121)m\u22121 , (\u22121)m\u22122 , . . . , (\u22121)0 }.\nS\nsym\nskew-sym\nT -even\nT -odd\nHerm\nskew-Herm\nH-even\nH-odd\n\nStructured Linearization\n\nansatz vector\n\nsksymm\nskew-symm\nT -even\nT -odd\nT -even\nT -odd\n\nv \u2208 Cm\nv \u2208 Cm\n\u03a3v = v\n\u03a3v = \u2212v\n\u03a3v = \u2212v\n\u03a3v = v\n\nHerm\nskew-Herm\nHerm\nskew-Herm\nH-even\nT -odd\nH-even\nH-odd\n\nv \u2208 Rm\nv \u2208 iRm\nv \u2208 iRm\nv \u2208 Rm\n\u03a3v = v\n\u03a3v = \u2212v\n\u03a3v = \u2212v\n\u03a3v = v\n\nTable 2: Admissible ansatz vectors for structured linearizations.\nS\nRecall that \u03b7(\u03bb, x, P) \u2264 \u03b7M\n(\u03bb, x, P). Similarly, for a structured linearization from L1 (P)\nS\nwe have \u03b7(\u03bb, \u039bm\u22121 \u2297 x, L; v) \u2264 \u03b7M\n(\u03bb, \u039bm\u22121 \u2297 x, L; v), where v is the ansatz vector. With a\nview to understanding the effect of structure preserving linearizations on the backward errors\nof approximate eigenelements of structured matrix polynomials, in this section we compare\nS\nS\n\u03b7(\u03bb, x, P) and \u03b7M\n(\u03bb, x, P) with \u03b7M\n(\u03bb, x, L).\n\nCorollary 4.2 Let P \u2208 S and L \u2208 L1 (P) be a structured linearization corresponding to the\nnormalized ansatz vector v. Then for M \u2208 {2, F }, we have\nr\nS\nm+1\n\u03b7M\n(\u03bb, \u039bm\u22121 \u2297 x, L; v)\n\u2265\n.\n\u03b7(\u03bb, x, P)\n2m\n17\n\n\fProof: By Theorem 4.1 we have\nS\n\u03b7M\n(\u03bb, \u039bm\u22121 \u2297 x, L; v)\n\u03b7(\u03bb, \u039bm\u22121 \u2297 x, L; v)\n\u2265\n\u2265\n\u03b7(\u03bb, x, P)\n\u03b7(\u03bb, x, P)\n\nr\n\nm+1\n.\n2m\n\nHence the proof. \u0004\n\n4.1\n\nSymmetric and skew-symmetric linearizations\n\nFor a symmetric matrix polynomial P, any ansatz vector v yields a potential symmetric\nlinearization. Recall that an ansatz vector v is always assumed to be normalized, that is,\nkvk2 = 1. We now show that structure preserving linearizations of symmetric and skewsymmetric matrix polynomials have almost no adverse effect on the backward errors of approximate eigenelements.\nTheorem 4.3 Let S be the space of symmetric matrix polynomials and P \u2208 S. Let L \u2208 L1 (P)\nbe a symmetric linearization of P with normalized ansatz vector v. Finally, let (\u03bb, x) \u2208 C \u00d7 Cn\nbe such that kxk2 = 1. Then we have\nr\n\u03b7FS (\u03bb, \u039bm\u22121 \u2297 x, L; v)\n\u03b7FS (\u03bb, \u039bm\u22121 \u2297 x, L; v) \u221a\nm+1\n\u2264\n\u2264 2,\n\u2264\n2m\n\u03b7(\u03bb, x, P)\n\u03b7FS (\u03bb, x, P)\nr\n\u03b7(\u03bb, \u039bm\u22121 \u2297 x, L; v)\nm+1\n\u03b72S (\u03bb, \u039bm\u22121 \u2297 x, L; v)\n=\n\u2264\n\u2264 1.\n2m\n\u03b7(\u03bb, x, P)\n\u03b72S (\u03bb, x, P)\nProof: For the Frobenius norm, by Theorem 3.2 we have\nr\n\u03b7FS (\u03bb, \u039bm\u22121 \u2297 x, L; v)\n\u03b7FS (\u03bb, x, P)\n\n|\u039bT\n\n=\n\nv|2\n\nT 2\n2krk22 \u2212 k\u039bm\u22121\n2 |x r|\nm\u22121 k2\nk\u039bm k2\np\n*\n,\n2\nT\n2\nk\u039b\nm\u22121 k2 k(\u03bb, 1)k2\n2krk2 \u2212 |x r|\n\nq\n\u03b7 S (\u03bb, \u039bm\u22121 \u2297 x, L; v)\nm+1\n\u2265\nwhere r := \u2212P(\u03bb)x. Hence by (17) we have F\n2m . Next, since\nS (\u03bb, x, P)\n\u03b7\nF\nr\n\u221a\n|\u039bT\nv|2 T 2\nkrk2 \u2264 2krk22 \u2212 k\u039bm\u22121\n2 krk2 , we have\n2 |x r| \u2264\nm\u22121 k\n2\n\n\u221a\nk\u039bm k2\n\u03b7FS (\u03bb, \u039bm\u22121 \u2297 x, L; v)\n\u03b7 S (\u03bb, \u039bm\u22121 \u2297 x, L; v) \u221a\n\u2264 2.\n\u2264 2\n\u2264 F\nS\n\u03b7(\u03bb, x, P)\nk\u039bm\u22121 k2 k(\u03bb, 1)k2\n\u03b7F (\u03bb, x, P)\nFinally, by Theorem 3.2, we have structured and unstructured backward errors are the\nsame for the spectral norm. Hence the desired results follow from Theorem 4.1. \u0004\nFor skew-symmetric linearizations of skew-symmetric matrix polynomials, we have the\nfollowing result.\nTheorem 4.4 Let S be the space of skew-symmetric matrix polynomials and P \u2208 S. Let\nL \u2208 L1 (P) be a skew-symmetric linearization of P with normalized ansatz vector v. Finally,\nlet (\u03bb, x) \u2208 C \u00d7 Cn be such that kxk2 = 1. Then for M \u2208 {2, F } we have\nr\nm+1\n\u03b7(\u03bb, \u039bm\u22121 \u2297 x, L; v)\n\u03b7 S (\u03bb, \u039bm\u22121 \u2297 x, L; v)\n=\n\u2264 M\n\u2264 1.\nS\n2m\n\u03b7(\u03bb, x, P)\n\u03b7M (\u03bb, x, P)\nProof: By Theorem 3.5 we have\nS\n\u03b7(\u03bb, \u039bm\u22121 \u2297 x, L; v)\n\u03b7M\n(\u03bb, \u039bm\u22121 \u2297 x, L; v)\n=\n.\nS\n\u03b7(\u03bb, x, P)\n\u03b7M (\u03bb, x, P)\n\n18\n\n\fHence desired result follows from Theorem 4.1. \u0004\nThus we conclude that for a symmetric/skew-symmetric matrix polynomial a structure\npreserving linearization automatically ensures that the backward errors of approximate eigenelements are least affected by the conversion the polynomial eigenvalue problem into a generalized\neigenvalue problem of larger dimension. Moreover, as shown in [4] this choice also ensures\nthat the linearization has a mild influence on the structured condition numbers of eigenvalues\nof the polynomial.\n\n4.2\n\nT -even and T -odd linearizations\n\nNow we analyze T -even and T -odd linearizations. Note that a T -even (resp., T -odd) polynomial admits T -even as well as T -odd linearizations which preserve the spectral symmetry of\nthe T -even (resp., T -odd) polynomial.\nTheorem 4.5 Let P \u2208 Pm (Cn\u00d7n ) be a T -even polynomial and (\u03bb, x) \u2208 C \u00d7 Cn be such that\nkxk2 = 1. Let Se \u2282 L1 (P) and So \u2282 L1 (P), respectively, denote the space of T -even and T -odd\npencils. Finally, let Le \u2208 Se (resp., Lo \u2208 So ) be T -even (resp. T -odd) linearization of P\nwith normalized ansatz vector v = \u03a3v (resp., v = \u2212\u03a3v). Then for M \u2208 {2, F } we have the\nfollowing.\nq\nSe\n\u03b7M\n(\u03bb, \u039bm\u22121 \u2297 x, Le ; v) \u221a\n\u2264 2.\n\u2264\n1. If |\u03bb| \u2264 1 then m+1\n2m\n\u03b7(\u03bb, x, P)\n2. If |\u03bb| \u2265 1 then\n\nq\n\nm+1\n2m\n\n\u2264\n\nSo\n\u03b7M\n(\u03bb, \u039bm\u22121 \u2297 x, Lo ; v) \u221a\n\u2264 2.\n\u03b7(\u03bb, x, P)\n\nProof: First consider the T -even linearization Le . Then by Theorem 3.7 we have\n!\nr\n2 krk22 +\n\n\u03b7FSe (\u03bb, \u039bm\u22121\n\n\u2297 x, Le ; v)\n=\n\u03b7(\u03bb, x, P)\n\n2\n(|\u03bb|2 \u22121)|\u039bT\nm\u22121 v|\nk\u039bm\u22121 k22\n\nNow for |\u03bb| \u2264 1, we have krk2 \u2264\n\nr\n\n2krk22 +\n\n2\n(|\u03bb|2 \u22121)|\u039bT\nm\u22121 v|\n|xT r|2\nk\u039bm\u22121 k22\n\nby (17) we obtain the desired results for the Frobenius norm.\nAgain by Theorem 3.7, we have\nr\n\nNotice that krk2 \u2264\n\n|\u039bT\n\nk\u039bm k2\n\nkrk2 k\u039bm\u22121 k2 k(\u03bb, 1)k2\n\nwhere r := \u2212P(\u03bb)x.\n\n\u03b72Se (\u03bb, \u039bm\u22121 \u2297 x, Le ; v)\n=\n\u03b7(\u03bb, x, P)\nr\n\n|xT r|2\n\nkrk22\n\n+\n\n2\n|\u03bb|2 |\u039bT\nm\u22121 v|\nk\u039bm\u22121 k22\n\n|xT r|2\n\n!\n\n\u2264\n\nv|2\n2\n\nk\u039bm k2\n\n|\u039bT\n\n\u2297 x, Lo ; v)\n=\n\u03b7(\u03bb, x, P)\n\nkrk2 \u2264\n\nv|2\n\nT 2\n2krk22 + ( |\u03bb|1 2 \u2212 1) k\u039bm\u22121\n2 |x r|\nm\u22121 k\n2\n\nkrk2 k\u039bm\u22121 k2 k(1, \u03bb)k2\n\nfor \u03bb 6= 0. Now for |\u03bb| \u2265 1, we have\ns\n\n2krk22 + (|\u03bb|\u22122 \u2212 1)\n19\n\n.\n\n(19)\n\np\n1 + |\u03bb|2 krk2 for \u03bb \u2208 C. Hence by (17)\n\nwe obtain the desired result for the spectral norm.\nNext, consider the T -odd linearization Lo . Then by Theorem 3.10 we have\n!\nr\n\u03b7FSo (\u03bb, \u039bm\u22121\n\n(18)\n\n\u221a\n2 krk2 . Hence\n\nkrk2 k\u039bm\u22121 k2 k(\u03bb, 1)k2\n\nT 2 \u2264\nkrk22 + |\u03bb|2 k\u039bm\u22121\n2 |x r|\nm\u22121 k\n\n,\n\n|\u039bTm\u22121 v|2 T 2 \u221a\n|x r| \u2264 2krk2 .\nk\u039bm\u22121 k22\n\nk\u039bm k2\n\n,\n\n(20)\n\n\fHence by (17)we obtain the desired result for the Frobenius norm.\nAgain by Theorem 3.10 we have\nr\n\u03b72So (\u03bb, \u039bm\u22121 \u2297 x, Lo ; v)\n=\n\u03b7(\u03bb, x, P)\nr\n\nfor \u03bb 6= 0. For |\u03bb| \u2265 1, we have krk2 \u2264\n\nkrk22\n\n+\n\n2\n|\u039bT\nm\u22121 v|\n|xT r|2\n|\u03bb|2 k\u039bm\u22121 k22\n\n!\n\nk\u039bm k2\n\nkrk2 k\u039bm\u22121 k2 k(1, \u03bb)k2\n|\u039bT\n\nv|2\n\nT 2\nkrk22 + |\u03bb|\u22122 k\u039bm\u22121\n2 |x r| \u2264\nm\u22121 k\n2\n\n(21)\n\n\u221a\n2krk2 . Hence by (17)\n\nwe obtain the desired result follows for the spectral norm.\u0004\n\nRemark 4.6 We mention that the bounds in Theorem 4.5 also hold when P is T -odd with\nthe role of T -even and T -odd linearizations are reversed, that is, by interchanging the role of\nLe and Lo we obtain the desired bounds.\nNext, comparing \u03b72S (\u03bb, x, P) with \u03b72S (\u03bb, x, L, v) we have the following result.\nTheorem 4.7 Suppose that the assumptions of Theorem 4.5 hold. Let S \u2282 Pm (Cn\u00d7n ) denote\nthe set of T -even polynomials. Then we have\nq\n\u03b72Se (\u03bb, \u039bm\u22121 \u2297 x, Le ; v) \u221a\n\u2264 2.\n1. If |\u03bb| \u2264 1 : m+1\n4m \u2264\n\u03b72S (\u03bb, x, P)\nq\n\u03b72So (\u03bb, \u039bm\u22121 \u2297 x, Lo ; v) \u221a\n2. If |\u03bb| \u2265 1 : m+1\n\u2264 2, when m is even and\n4m \u2264\n\u03b72S (\u03bb, x, P)\nq\n\u03b72So (\u03bb, \u039bm\u22121 \u2297 x, Lo ; v) \u221a\nm+1\n1\n\u2264 2, when m is odd.\n2m k(1, \u03bb)k2 \u2264\n\u03b72S (\u03bb, x, P)\n\nProof: Note that the upper bounds follow from Theorem 4.5. We now derive the lower\nbounds.\nFirst suppose that |\u03bb| \u2264 1. Then it is easy to see that k(I \u2212 \u03a0e )(\u039bm )k2 \u2264 k\u03a0e (\u039bm )k2 .\nHence by Theorem 3.7 we have\ns\n\u221a\nkrk2\n2krk2\nk(I \u2212 \u03a0e )(\u039bm )k22\nS\n\u03b72 (\u03bb, x, P) \u2264\n\u2264\n.\n1+\n2\nk\u039bm k2\nk\u03a0e (\u039bm )k2\nk\u039bm k2\nOn the other hand, by (19) we have \u03b72Se (\u03bb, \u039bm\u22121 \u2297 x, Le ; v) \u2265\nquently, by (17) we have\n\nkrk2\n. Consek\u039bm\u22121 k2 k(1, \u03bb)k2\n\n1\n\u03b72Se (\u03bb, \u039bm\u22121 \u2297 x, Le ; v)\nk\u039bm k2\n\u2265\n\u2265 \u221a\n2\n\u03b72S (\u03bb, x, P)\n2k\u039bm\u22121 k2 k(1.\u03bb)k2\n\nr\n\nm+1\n.\nm\n\nNext suppose that |\u03bb| \u2265 1 and consider the T -odd linearization Lo . Then it is easy to\ncheck that k(I \u2212 \u03a0e )(\u039bm )k2 \u2264 k\u03a0e (\u039bm )k2 when m is even and the desired result follows\nby similar arguments as above. Now suppose that m is odd. Then it is easy to see that\nk(I \u2212 \u03a0e )(\u039bm )k22 = |\u03bb|2 k\u03a0e (\u039bm )k22 . Hence by Theorem 3.7 we have\ns\np\n1 + |\u03bb|2 krk2\nkrk2\nk(I \u2212 \u03a0e )(\u039bm )k22\nS\n\u03b72 (\u03bb, x, P) \u2264\n1+\n\u2264\n.\n2\nk\u039bm k2\nk\u03a0e (\u039bm )k2\nk\u039bm k2\nkrk2\n. Hence by (17) we have\nk\u039bm\u22121 k2 k(1, \u03bb)k2\nr\n\u03b72So (\u03bb, \u039bm\u22121 \u2297 x, Lo ; v)\nk\u039bm k2\nm+1\n1\n\u2265\n\u2265 \u221a\n.\n2\nS\nk\u039bm\u22121 k2 k(1.\u03bb)k2\nm\n\u03b72 (\u03bb, x, P)\n2k(1, \u03bb)k2\n\nFurther by (21) we have \u03b72So (\u03bb, \u039bm\u22121 \u2297 x, Lo ; v) \u2265\n\nThis completes the proof. \u0004\nFor T -odd polynomials, we have the following result.\n20\n\n\fTheorem 4.8 Let S \u2282 Pm (Cn\u00d7n ) denote the space of T -odd matrix polynomials and P \u2208 S.\nLet Se \u2282 L1 (P) and So \u2282 L1 (P), respectively, denote the space of T -even and T -odd pencils.\nFinally, let Le \u2208 Se (resp., Lo \u2208 So ) be T -even (resp. T -odd) linearization of P with normalized\nansatz vector v = \u03a3v (resp., v = \u2212\u03a3v). Then for (\u03bb, x) \u2208 C \u00d7 Cn with kxk2 = 1, we have the\nfollowing.\n1. If |\u03bb| \u2264 1 :\n\nq\n\nm+1\n6m\n\n\u2264\n\n\u03b72So (\u03bb, \u039bm\u22121 \u2297 x, Lo ; v)\n\u2264 1.\n\u03b72S (\u03bb, x, P)\n\nq\n1\n\u03b72Se (\u03bb, \u039bm\u22121 \u2297 x, Le ; v)\nm+1\n\u221a\n\u2264 1, when m is even and\n\u2264\nm\n\u03b72S (\u03bb, x, P)\nk( 2, \u03bb)k2\nq\n\u03b72So (\u03bb, \u039bm\u22121 \u2297 x, Lo ; v)\nm+1\n\u2264\n\u2264 1, when m is odd.\n4m\n\u03b72S (\u03bb, x, P)\ns\n1\nk\u03a0e (\u039bm )k22\n|xT r|2 . It\nProof: By Theorem 3.10 we have \u03b72S (\u03bb, x; P) =\nkrk22 +\nk\u039bm k2\nk(I \u2212 \u03a0e )(\u039bm )k22\nis easy to see that\n|\u03bb|2\nk(I \u2212 \u03a0e )(\u039bm )k22\n\u2265\n(22)\n1 + |\u03bb|2\nk\u039bm k22\n2. If |\u03bb| \u2265 1 :\n\nwith equality holds for odd m. Now, by (21) we have\n\u03b72So (\u03bb, \u039bm\u22121\nSince by (22),\n\n1\n\u2297 x, Lo ; v) =\nk\u039bm\u22121 k2 k(1, \u03bb)k2\n\nk\u03a0e (\u039bm )k22\nk(I\u2212\u03a0e )(\u039bm )k22\n\ns\n\nkrk22 + |\u03bb|\u22122\n\n|\u039bTm\u22121 v|2 T 2\n|x r| .\nk\u039bm\u22121 k22\n\n\u2265 |\u03bb|\u22122 with equality holds for odd m, we have\n\n\u03b72So (\u03bb, \u039bm\u22121 \u2297 x, Lo ; v)\n\u2264 1.\n(23)\n\u03b72S (\u03bb, x; P)\n\u221a\nAlso it is easy to check that k(I \u2212 \u03a0e )(\u039bm )k2 \u2264 k\u039bm k2 \u2264 2k\u03a0e (\u039bm )k2 whenever |\u03bb| \u2264 1.\n\u221a\ne )(\u039bm )k2\nConsequently we have k(I\u2212\u03a0\n\u2264 2. This yields\nk\u03a0e (\u039bm )k2\n\u03b72So (\u03bb, \u039bm\u22121 \u2297 x, Lo ; v)\n\u2265\n\u03b72S (\u03bb, x; P)\n\nr\n\nm+1\n.\n6m\n\nNext suppose that |\u03bb| \u2265 1. If m is even then its obvious that\nby (19) and (17) we have\nr\n\u03b72Se (\u03bb, \u039bm\u22121 \u2297 x, Le ; v)\nk\u039bm k2\n\u2264\nS\nk\u039b\n\u03b72 (\u03bb, x; P)\nm\u22121 k2 k(1, \u03bb)k2\n\nFurther using the fact\n\nk\u03a0e (\u039bm )k22\nk(I\u2212\u03a0e )(\u039bm )k22\n\n|\u039bT\n\n\u2265 |\u03bb|2 . Hence\n\nv|2\n\nT 2\nkrk22 + |\u03bb|2 k\u039bm\u22121\n2 |x r|\nm\u22121 k2\np\n\u2264 1.\nkrk22 + |\u03bb|2 |xT r|2\n\nk\u03a0e (\u039bm )k22\n\u2264 1 + |\u03bb|2 we have\nk(I \u2212 \u03a0e )(\u039bm )k22\n\n\u03b72Se (\u03bb, \u039bm\u22121 \u2297 x, Le ; v)\n1\n\u2265 \u221a\n\u03b72S (\u03bb, x; P)\nk( 2, \u03bb)k2\n\nr\n\nm+1\n.\nm\n\nOn the other hand, if m is odd and |\u03bb| \u2265 1 then the lower bound follows from the fact that\nk\u03a0e (\u039bm )k22\n= |\u03bb|1 2 \u2264 1. This completes the proof. \u0004\nk(I \u2212 \u03a0e )(\u039bm )k22\n21\n\n\fThe moral of the story is that for computing eigenelements of a T -even matrix polynomial\nP, it is advisable to solve T -even as well as T -odd linearizations of P and then choose a\ncomputed eigenpair (\u03bb, x) from T -even or T -odd linearization according as |\u03bb| \u2264 1 or |\u03bb| \u2265 1.\nIn contrast, when P is T -odd it is advisable to choose (\u03bb, x) from T -even linearization only\nwhen |\u03bb| \u2265 1 and the degree of P is even, otherwise choose (\u03bb, x) from T -odd linearization of P.\nThis choice ensures that the linearizations have almost no adverse effect on the backward error\nof the computed eigenelement (\u03bb, x). We arrived at the same conclusion in [4] by analyzing the\neffect of structure preserving linearizations on the structured condition numbers of eigenvalues\nof the polynomial P.\n\n4.3\n\nHermitian and H-even linearizations\n\nFirst, we consider Hermitian matrix polynomials. Note that a Hermitian matrix polynomial\nadmits Hermitian and skew-Hermitian linearizations both preserving the spectral symmetry\nof the Hermitian polynomial.\nTheorem 4.9 Let P \u2208 Pm (Cn\u00d7n ) be Hermitian and (\u03bb, x) \u2208 C \u00d7 Cn be such that kxk2 = 1.\nLet S \u2208 {Herm, skew-Herm} and L \u2208 S be a linearization of P with normalized ansatz vector\nv. If \u03bb \u2208 R then we have\nr\nr\n\u03b7 S (\u03bb, \u039bm\u22121 \u2297 x, L; v) \u221a\n\u03b7 S (\u03bb, \u039bm\u22121 \u2297 x, L; v)\nm+1\nm+1\n\u2264 F Herm\n\u2264 2 Herm\n\u2264 1.\n\u2264 2 and\n2m\n2m\n\u03b7F (\u03bb, x, P)\n\u03b72 (\u03bb, x, P)\nThe same bounds hold when P is skew-Hermitian.\nProof: First, suppose that S = Herm so that L is a Hermitian linearization of P. For \u03bb \u2208 R,\nby Theorem 3.12, we have\nr\n\u03b7FS (\u03bb, \u039bm\u22121 \u2297 x, L; v)\n\u03b7FHerm (\u03bb, x, P)\n\n|\u039bH\n\n=\n\nv|2\n\nH r|2\n2krk22 \u2212 k\u039bm\u22121\n2 |x\nm\u22121 k2\nk\u039bm k2\np\n,\n*\nk\u039bm\u22121 k2 k(\u03bb, 1)k2\n2krk22 \u2212 |xH r|2\n\nq\n\u03b7 S (\u03bb, \u039bm\u22121 \u2297 x, L; v)\nm+1\nwhere r := \u2212P(\u03bb)x. Hence by (17) we have F Herm\n\u2265\n2m . Next, since\n\u03b7\n(\u03bb,\nx,\nP)\nF\nr\n\u221a\n|\u039bH v|2 H 2\nr| \u2264 2 krk2 , we have\nkrk2 \u2264 2krk22 \u2212 k\u039bm\u22121\n2 |x\nm\u22121 k\n2\n\n\u221a\n\u03b7FS (\u03bb, \u039bm\u22121 \u2297 x, L; v)\n\u03b7FS (\u03bb, \u039bm\u22121 \u2297 x, L; v) \u221a\nk\u039bm k2\n\u2264\n\u2264 2.\n\u2264 2\nHerm\n\u03b7(\u03bb, x, P)\nk\u039bm\u22121 k2 k(\u03bb, 1)k2\n\u03b7F (\u03bb, x, P)\nFor the spectral norm, by Theorem 3.12, structured and unstructured backward errors are\nthe same when \u03bb \u2208 R. Hence the desired results follow from Theorem 4.1.\nFinally, since the backward errors are the same for Hermitian and skew-Hermitian pencils,\nthe above hounds obviously hold for the case when S = skew-Herm. \u0004\nThis shows that a structured linearization of a Hermitian matrix polynomial does not have\nadverse effect on the backward errors of approximate eigenelements when the approximate\neigenvalues are real. On the other hand, when the approximate eigenvalues are complex,\nthe structured backward errors are not amenable to easy comparisons. Indeed, under the\nassumptions of Theorem 4.9, when \u03bb \u2208 C \\ R by Theorem 3.12 a little calculation shows that\ns\ns\nkb\nrk22\nkb\nrk22\n\u03b72S (\u03bb, \u039bm\u22121 \u2297 x, L; v)\n\u03b7FS (\u03bb, \u039bm\u22121 \u2297 x, L; v)\n1\n+\nand\n,\n\u2264 2+\n\u2264\n\u03b7(\u03bb, x, P)\nkrk22\n\u03b7(\u03bb, x, P)\nkrk22\n\n22\n\n\f\u0014\n\n\u0015\u2020 \u0014\n\u0015\nH\n1 re\u03bb\nre(\u039bH\nm\u22121 vx P(\u03bb)x)\nwhere r := \u2212P(\u03bb)x and rb = rh :=\nwhen S = Herm, and\nH\n0 im\u03bb\nim(\u039bH\nm\u22121 vx P(\u03bb)x)\n\u0014\n\u0015\u2020 \u0014\n\u0015\nH\n1 \u2212im\u03bb\nre(\u039bH\nm\u22121 vx P(\u03bb)x)\nrb = rs :=\nwhen S = skew-Herm.\nH\n0\nre\u03bb\nim(\u039bm\u22121 vxH P(\u03bb)x)\nNext we consider linearizations of H-even polynomials. Note that an H-even polynomial\nadmits H-even as well as H-odd linearizations and both have the same spectral symmetry as\nthat of the polynomial. For purely imaginary eigenvalues of an H-even or H-odd polynomial,\nwe have the following result.\nTheorem 4.10 Let P \u2208 Pm (Cn\u00d7n ) be H-even and (\u03bb, x) \u2208 C \u00d7 Cn be such that kxk2 = 1.\nLet S \u2208 {H-even, H-odd} and L \u2208 S be a linearization of P with normalized ansatz vector v.\nIf \u03bb \u2208 iR then we have\nr\nr\nm+1\nm+1\n\u03b7FS (\u03bb, \u039bm\u22121 \u2297 x, L; v) \u221a\n\u03b72S (\u03bb, \u039bm\u22121 \u2297 x, L; v)\n\u2264\n\u2264 1.\n2\nand\n\u2264\n\u2264\n2m\n2m\n\u03b7FH -even (\u03bb, x, P)\n\u03b72H -even (\u03bb, x, P)\nThe same bounds hold when P is H-odd.\nProof: The proof is exactly the same as that of Theorem 4.9 and follows from Theorem 3.14.\n\u0004\nThis shows that a structured linearization of an H-even polynomial has least influence\non the backward errors of approximate eigenelements when the approximate eigenvalues are\npurely imaginary. On the other hand, when the approximate eigenvalues are not purely\nimaginary, the structured backward errors of approximate eigenelements are not amenable\nto easy comparisons. Indeed, under the assumptions of Theorem 4.10, when \u03bb \u2208 C \\ iR by\nTheorem 3.14, we have\ns\ns\n\u03b72S (\u03bb, \u039bm\u22121 \u2297 x, L; v)\n\u03b7FS (\u03bb, \u039bm\u22121 \u2297 x, L; v)\nkb\nrk22\nkb\nrk22\nand\n,\n\u2264 2+\n\u2264 1+\n2\n\u03b7(\u03bb, x, P)\nkrk2\n\u03b7(\u03bb, x, P)\nkrk22\nwhere r := \u2212P(\u03bb)x and rb = rs when S = H-even, and rb = rh when S = H-odd.\nThe obvious conclusion that we can draw is that real eigenvalues of a Hermitian/skewHermitian matrix polynomial can be computed either by solving a Hermitian or a skewHermitian linearization. However, for non real eigenvalues it may be a good idea to solve\nHermitian as well as skew-Hermitian linearizations and choose an eigenpair (\u03bb, x) from Hermitian or skew-Hermitian linearization according as rh \u2264 rs or rs \u2264 rh . Similar conclusion\nholds for H-even/H-odd matrix polynomials. These observations are consistent with those\nmade in [4] by analyzing the structured condition numbers of eigenvalues.\n\n5\n\nStructured pseudospectra of structured polynomials\n\nLet P be a regular polynomial. For \u03bb \u2208 C, the backward error of \u03bb as an approximate eigenvalue of P is given by \u03b7(\u03bb, P) := min{\u03b7(\u03bb, x, P) : x \u2208 Cn and kxk2 = 1}. Since \u03b7(\u03bb, x, P) =\nkP(\u03bb)xk/kxk2 k\u039bm k2 , it follows that for the spectral as well as for the Frobenius norms on\nCn\u00d7n , we have\n\u03c3min (P(\u03bb))\n.\n\u03b7(\u03bb, P) :=\nk\u039bm k2\n\nSimilarly, for M \u2208 {2, F } we define structured backward error of an approximate eigenvalue\n\u03bb of P \u2208 S by\nS\nS\n\u03b7M\n(\u03bb, P) := min{\u03b7M\n(\u03bb, x, P) : x \u2208 Cn and kxk2 = 1}.\n\nS\nIn this section, we make an attempt to determine \u03b7M\n(\u03bb, P). The backward errors of approximate eigenvalues and pseudospectra of a polynomial are closely related. For \u01eb > 0, the\n\n23\n\n\funstructured \u01eb-pseudospectrum of P, denoted by \u03c3\u01eb (P), is given by (see [5, 6])\n[\n{\u03c3(P + \u25b3P) : \u25b3P \u2208 Pm (Cn\u00d7n )}.\n\u03c3\u01eb (P) =\n|||\u25b3P|||M \u2264\u01eb\n\nObviously, we have \u03c3\u01eb (P) = {z \u2208 C : \u03b7(z, P) \u2264 \u01eb}, assuming, for simplicity, that \u221e \u2208\n/ \u03c3\u01eb (P),\nsee [5, 6]. For the sake of simplicity in this section we make an implicit assumption that\n\u221e\u2208\n/ \u03c3\u01eb (P). Observe that since \u03b7(\u03bb, P) is the same for the spectral norm and the Frobenius\nnorm, we conclude that \u03c3\u01eb (P) is the same for the spectral and the Frobenius norms. Similarly,\nwhen P \u2208 S, we define the structured \u01eb-pseudospectrum of P, denoted by \u03c3\u01ebS (P), by\n[\n{\u03c3(P + \u25b3P) : \u25b3P \u2208 S}.\n\u03c3\u01ebS (P) :=\n|||\u25b3P|||M \u2264\u01eb\n\nS\nThen it follows that \u03c3\u01ebS (P) = {z \u2208 C : \u03b7M\n(\u03bb, P) \u2264 \u01eb}.\n\nTheorem 5.1 Let S \u2208 {sym, skew-sym} and P \u2208 S. Then for the spectral norm, we have\n\u03b72S (\u03bb, P) = \u03b7(\u03bb, P)\u221aand \u03c3\u01ebS (P) = \u03c3\u01eb (P). On the other hand, for the Frobenius norm, we\nhave \u03b7FS (\u03bb, P) = 2 \u03b7(\u03bb, P) and \u03c3\u01ebS (P) = \u03c3\u01eb/\u221a2 (P) when S = skew-sym, and \u03b7FS (\u03bb, P) =\n\u03b7(\u03bb, P) and \u03c3\u01ebS (P) = \u03c3\u01eb (P) when S = sym.\nProof: For the spectral norm, by Theorem 3.2, we have \u03b72S (\u03bb, x, P) = \u03b7(\u03bb, x, P) for all x.\nConsequently, we have \u03b72S (\u03bb, P) = \u03b7(\u03bb, P). Hence the result follows.\nFor the Frobenius norm, the result follows from Theorem 3.5 when P is skew-symmetric.\nSo, suppose that P is symmetric. Then P(\u03bb) \u2208 Cn\u00d7n is symmetric. Consider the Takagi\nfactorization P (\u03bb) = U \u03a3U T , where U is unitary and \u03a3 is a diagonal matrix containing\nsingular values of P(\u03bb) (appear in descending order). Set \u03c3 := \u03a3(n, n) and u := U (:, n). Then\nwe have P(\u03bb)u = \u03c3u. Now define\nj\n\n\u25b3Aj := \u2212\n\n\u03bb \u03c3 uuT\n,\nk\u039bm k22\n\nPm\nand consider the polynomial \u25b3P(z) = j=0 z j \u25b3Aj . Then \u25b3P is symmetric and P(\u03bb)u +\n\u25b3P(\u03bb)u = 0. Note that for M \u2208 {2, F } we have\n\u03c3\nS\n= \u03b7(\u03bb, P) and hence \u03c3\u01eb (P) = \u03c3\u01ebS (P).\n\u03b7M\n(\u03bb, P) \u2264 |||\u25b3P|||M =\nk\u039bm k2\nThis completes the proof. \u0004\nWhen P is symmetric, the above proof shows how to construct a symmetric polynomial\nS\n\u25b3P such that \u03bb \u2208 \u03c3(P + \u25b3P) and |||\u25b3P|||M = \u03b7M\n(\u03bb, P). When P is skew-symmetric, using\nTakagi factorization of the complex skew-symmetric matrix P(\u03bb), one can construct a skewS\nsymmetric polynomial \u25b3P such that \u03bb \u2208 \u03c3(P+\u25b3P) and |||\u25b3P|||M = \u03b7M\n(\u03bb, P). Indeed, consider\nthe Takagi factorization\nP(\u03bb) = U diag(d1 , * * * , dm )U T ,\n\u0014\n\u0015\n0\nsj\nwhere U is unitary, dj :=\n, sj \u2208 C is nonzero and |sj | are singular values of P(\u03bb).\n\u2212sj 0\nHere the blocks dj appear in descending order of magnitude of |sj |. Note that P(\u03bb)U =\nU diag(d1 , * * * , dm ). Let u := U (:, n \u2212 1 : n). Then P(\u03bb)u = udm = udm uT u. Now define\n\u25b3Aj := \u2212\nand consider the pencil \u25b3P(z) =\n\u25b3P(\u03bb)u = 0. Further, we have\n\u03b72S (\u03bb, P) = |||\u25b3P|||2 =\n\nPm\n\nj=0\n\n\u03bbj udm uT\nkv\u03bb k22\n\nz j \u25b3Aj . Then \u25b3P is skew-symmetric and P(\u03bb)u +\n\n\u221a \u03c3min (P(\u03bb)) \u221a\n\u03c3min (P(\u03bb))\n= \u03b7(\u03bb, P), \u03b7FS (\u03bb, P) = |||\u25b3P|||F = 2\n= 2 \u03b7(\u03bb, P).\nk\u039bm k2\nk\u039bm k2\n24\n\n\fWe denote the unit circle in C by T, that T := {z \u2208 C : |z| = 1}. Then for the T -even or\nT -odd polynomials we have the following result.\nTheorem 5.2 Let S \u2208 {T -even, T -odd}\n\u221a and P \u2208 S and m is odd. Then for \u03bb \u2208 T and the\nFrobenius norm we have \u03b7FS (\u03bb, P) = 2 \u03b7(\u03bb, P) and \u03c3\u01ebS (P) \u2229 T = \u03c3\u01eb/\u221a2 (P) \u2229 T.\n\n\u221a\nProof: Let \u03bb \u2208 T. Then by Theorem 3.7 and Theorem 3.10, \u03b7FS (\u03bb, x, P) = 2 kP(\u03bb)xk2 /k\u039bm k2\nfor all x such that kxk2 = 1. Hence taking minimum over kxk2 = 1, we obtain the desired\nresults. \u0004\nTheorem 5.3 Let S \u2208 {Herm, skew-Herm} and P \u2208 S. Then for M \u2208 {2, F } and \u03bb \u2208 R, we\nS\nhave \u03b7M\n(\u03bb, P) = \u03b7(\u03bb, P) and \u03c3\u01ebS (P) \u2229 R = \u03c3\u01eb (P) \u2229 R.\nProof: Note that P(\u03bb) is either Hermitian or skew-Hermitian. Let (\u03bc, u) be an eigenpair of\nthe matrix P(\u03bb) such that |\u03bc| = \u03c3min (P(\u03bb)) and uH u = 1. Then P(\u03bb)u = \u03bcu. Define\n\u25b3Aj := \u2212\n\n\u03bbj \u03bc uuH\nk\u039bm k22\n\nPm j\nand consider the polynomial \u25b3P(z) =\nj=0 z \u25b3Aj . Then \u25b3P \u2208 S and \u03bb \u2208 \u03c3(P + \u25b3P).\n\u03c3min (P(\u03bb))\n. Hence the result follows. \u0004\nFurther, we have |||\u25b3P|||M =\nk\u039bm k2\nTheorem 5.4 Let S \u2208 {H-even, H-odd} and P \u2208 S. Then for M \u2208 {2, F } and \u03bb \u2208 iR, we\nS\nhave \u03b7M\n(\u03bb, P) = \u03b7(\u03bb, P) and \u03c3\u01ebS (P) \u2229 i R = \u03c3\u01eb (P) \u2229 i R.\nProof: Note for \u03bb \u2208 i R, then the matrix P(\u03bb) is again either is Hermitian or skew-Hermitian.\nHence the result follows from the proof of Theorem 5.3. \u0004\nWe mention that the above results can be easily extended to the case of general structured\npolynomials where the coefficients matrices are elements of Jordan and/or Lie algebras.\nFinally, we mention that the partial equality \u03c3\u01ebS (L) \u2229 \u03a9 = \u03c3\u01eb (L) \u2229 \u03a9, for an appropriate\n\u03a9 \u2282 C, and the minimal perturbations constructed above as well as in section 3 are expected\nto be key tools for solution of certain structured distance problems, see [7]. For illustration,\nconsider an H-even polynomial P. We have seen that the eigenvalues of P have Hamiltonian\nspectral symmetry, that is, the spectrum of P is symmetric with respect to the imaginary axis\nin the complex plane and thus appear in the pair (\u03bb, \u2212\u03bb). Obviously the spectral symmetry\ndegenerates if there are purely imaginary eigenvalues. Often in practice the polynomial P\nis obtained by an approximation of the exact problem. Thus it may be the case that even\nthough the exact problem has no purely imaginary eigenvalues but due to approximation error\nthe polynomial P may have a few purely imaginary eigenvalues. So, the task is to construct\na minimal perturbation \u25b3P such that P + \u25b3P is H-even and that the perturbed polynomial\nP + \u25b3P has no eigenvalues on the imaginary axis. On the other hand, it may also be the\ncase that all eigenvalues of the exact problem are purely imaginary (e.g. gyroscopic system)\nbut due to approximation error the polynomial P has a few eigenvalues off the imaginary\naxis. In such a case the task is to construct a minimal perturbation \u25b3P such that P + \u25b3P is\nH-even and that all eigenvalues of P + \u25b3P are purely imaginary. The minimal perturbations\nso constructed and the partial equality of between structured and unstructured pseudospectra\nso established are expected to be key tools in solving these problems and will be investigated\nelsewhere.\nConclusion. We have derived backward errors of approximate eigenelements of structured\nmatrix polynomials. We have constructed minimal structured perturbations that induce the\napproximate eigenelements as exact eigenelements of the perturbed polynomials. The minimal\nperturbations so constructed are expected to be useful in analyzing the evolution of eigenvalues of structured polynomials under structure preserving perturbations. We have analyzed\n25\n\n\fthe influence of structure preserving linearizations on the approximate eigenelements of structured matrix polynomials. Also, we have provided a recipe for selecting structure preserving\nlinearizations so that the linearizations have almost no adverse effect on the approximate\neigenelements of the structured matrix polynomials. We have briefly analyzed structured\npseudospectra of structured matrix polynomials and have shown that partial equality between structured and unstructured pseudospectra holds for certain structured polynomials.\nThese results are expected to be useful for constructing minimal structured perturbations\nthat move eigenvalues of the structured polynomials along certain directions which in turn\nare expected to be key tools for solving certain structured distance problems.\n\nReferences\n[1] B. Adhikari, Backward perturbation and sensitivity analysis of structured polynomial\neigenvalue problem, PhD thesis, Department of Mathematics, IIT Guwahati, India.,\n2008.\n[2] B. Adhikari, Backward errors and linearizations for palindromic matrix polynomials,\npreprint: arXiv:0812. 4154v1[math.NA], submitted.\n[3] B. Adhikari and R. Alam Structured backward errors and pseudospectra of structured matrix pencils, SIAM. J. Matrix Anal. Appl., 31 (2009) pp. 331-359.\n[4] B. Adhikari, R. Alam and D. Kressner Structured eigenvalue condition numbers\nand linearizations for matrix polynomials, submitted.\n[5] S. S. Ahmad, Pseudospectra of matrix pencils and their applications in perturbation\nanalysis of eigenvalues and eigendecompositions, PhD thesis, Department of Mathematics, Indian Institute of Technology Guwahati, India, 2007.\n[6] S. S. Ahmad and R. Alam, Pseudospectra, critical points and multiple eigenvalues\nof matrix polynomials, Linear Algebra Appl., 430 (2008), pp. 1171-1195.\n[7] R. Alam, S. Bora, M. Karow, V. Mehrmann and J. Moro, Numerical methods\nfor computing the distance to bounded-realness, in preparation.\n[8] S. Bora, Structured eigenvalue conditioning and backward error of a class of polynomial eigenvalue problems, to appear in SIMAX.\n[9] E. Chu, T. Hwang, W. Lin and C. Wu, Vibration of fast trains, palindromic\neigenvalue problems and structure-preserving doubling algorithms, J. Comp. Appl.\nMath., 219(2008), pp. 237-252.\n[10] C. Davis, W. M. Kahan and H.F. Weinberger, Norm-preserving dialations and\ntheir applications to optimal error bounds, SIAM J. Numer. Anal., 19(1982) 445-469.\n[11] N. J. Higham, R. Li, and F. Tisseur, Backard error of polynomial eigenproblems\nsolved by linearization, SIAM J. Matrix Anal. Appl., 29(2007), pp. 1218 - 1241.\n[12] N. J. Higham, D. S. Mackey, N. Mackey and F. Tisseur, Symmetric linearizations for matrix polynomials, SIAM J. Matrix Anal. Appl., 29(2006), pp. 143 - 159.\n[13] N. J. Higham, D. S. Mackey, and F. Tisseur, The conditioning of linearizations\nof matrix polynomials, SIAM J. Matrix Anal. Appl., 28(2006), pp. 1005 - 1028.\n[14] N. J. Higham and F. Tisseur, More on pseudospectra for polynomial eigenvalue\nproblems and applications in control theory, Linear Algebra Appl., 351-352 (2002),\npp. 435\u2013453.\n\n26\n\n\f[15] A. Hilliges, C. Mehl, and V. Mehrmann, On the solution of palindromic eigenvalue problems, In Proceedings of ECCOMAS, Jyv\u00e4skyl\u00e4, Finland, 2004.\n[16] Xin-guo Liu and Wei-guo Wang, On a class of alternating coefficient matrices\nquadratic eigenvalue problem, Applied Mathematics and Computation, 158(2004)\npp.619-636.\n[17] Xin-guo Liu and Ze-xi Wang, A note on the backward errors for Hermite eigenvalue\nproblems, Applied Mathematics And Computation, 165(2005), pp.405-417.\n[18] D. S. Mackey, Structured linearizations for matrix polynomials, PhD thesis, School\nof Mathematics, The University of Manchester, UK, 2006.\n[19] D. S. Mackey, N. Mackey, C. Mehl and V. Mehrmann, Numerical methods for\npalindromic eigenvalue problems: computing the anti-triangular Schur form, Numer.\nLinear Algebra Appl., 16(2009) pp. 63-86.\n[20] D. S. Mackey, N. Mackey, C. Mehl and V. Mehrmann, Vector spaces of linearizations for matrix polynomials, SIAM J. Matrix Anal. Appl., 28(2006), pp.9711004.\n[21] D. S. Mackey, N. Mackey, C. Mehl and V. Mehrmann, Palindromic polynomial\neigenvalue problems: good vibrations from good linearizations, SIAM J. Matrix Anal.\nAppl., 28(2006), pp.1029-1051.\n[22] D. S. Mackey, N. Mackey and F. Tisseur, Structured factorizations in scalar\nproduct spaces, SIAM J. Matrix Anal. Appl., 27(2006), pp.821-850.\n[23] V. Mehrmann and D. Watkins, Structure-preserving methods for computing eigenpairs of large sparse skew-Hamiltonian/Hamiltonian pencils, SIAM J. Scientific Comp.,\n22(2001), pp.1905-1925.\n[24] V. Mehrmann and D. Watkins, Polynomial eigenvalue problems with Hamiltonian\nstructure, Elect. Trans. Numer. Anal., 13(2002), pp.106-113.\n[25] C. Schr\u00f6der, Palindromic and even eigenvalue problems - analysis and numerical\nmethods, PhD thesis, Technical University Berlin, Germany, 2008.\n[26] F. Tisseur, Backward error and condition of polynomial eigenvalue problems, Linear\nAlgebra Appl., 309(2000), pp.339-361.\n[27] F. Tisseur and N. J. Higham, Structured pseudospectra for polynomial eigenvalue\nproblems, with applications, SIAM J. Matrix Anal. Appl. 23(2001), pp.187-208.\n\n27\n\n\f"}