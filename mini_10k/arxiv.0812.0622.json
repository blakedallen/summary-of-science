{"id": "http://arxiv.org/abs/0812.0622v2", "guidislink": true, "updated": "2009-06-07T15:31:05Z", "updated_parsed": [2009, 6, 7, 15, 31, 5, 6, 158, 0], "published": "2008-12-03T02:57:01Z", "published_parsed": [2008, 12, 3, 2, 57, 1, 2, 338, 0], "title": "Remarks on Feedforward Circuits, Adaptation, and Pulse Memory", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0812.3519%2C0812.0285%2C0812.4021%2C0812.1105%2C0812.4741%2C0812.0007%2C0812.1127%2C0812.0406%2C0812.1421%2C0812.3825%2C0812.2276%2C0812.4147%2C0812.1000%2C0812.3210%2C0812.1230%2C0812.3124%2C0812.2978%2C0812.4759%2C0812.1112%2C0812.1544%2C0812.2756%2C0812.2330%2C0812.0165%2C0812.0932%2C0812.0622%2C0812.4131%2C0812.1992%2C0812.4462%2C0812.1201%2C0812.2410%2C0812.2745%2C0812.3982%2C0812.0676%2C0812.1053%2C0812.3521%2C0812.4948%2C0812.3368%2C0812.1904%2C0812.3696%2C0812.3459%2C0812.3970%2C0812.4126%2C0812.4271%2C0812.2059%2C0812.1724%2C0812.5044%2C0812.0237%2C0812.0958%2C0812.1276%2C0812.4181%2C0812.4809%2C0812.4575%2C0812.0975%2C0812.3064%2C0812.0152%2C0812.4060%2C0812.4448%2C0812.0641%2C0812.3692%2C0812.4737%2C0812.2061%2C0812.0480%2C0812.1665%2C0812.4940%2C0812.1958%2C0812.0774%2C0812.1836%2C0812.2912%2C0812.3417%2C0812.3288%2C0812.1257%2C0812.2165%2C0812.3322%2C0812.2616%2C0812.1355%2C0812.0437%2C0812.3918%2C0812.4077%2C0812.0324%2C0812.0345%2C0812.3406%2C0812.2250%2C0812.0049%2C0812.4392%2C0812.2561%2C0812.2114%2C0812.1843%2C0812.1059%2C0812.4393%2C0812.1922%2C0812.4040%2C0812.1219%2C0812.5112%2C0812.1907%2C0812.4746%2C0812.0422%2C0812.1569%2C0812.3237%2C0812.2970%2C0812.4191%2C0812.3211&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Remarks on Feedforward Circuits, Adaptation, and Pulse Memory"}, "summary": "This note studies feedforward circuits as models for perfect adaptation to\nstep signals in biological systems. A global convergence theorem is proved in a\ngeneral framework, which includes examples from the literature as particular\ncases. A notable aspect of these circuits is that they do not adapt to pulse\nsignals, because they display a memory phenomenon. Estimates are given of the\nmagnitude of this effect.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0812.3519%2C0812.0285%2C0812.4021%2C0812.1105%2C0812.4741%2C0812.0007%2C0812.1127%2C0812.0406%2C0812.1421%2C0812.3825%2C0812.2276%2C0812.4147%2C0812.1000%2C0812.3210%2C0812.1230%2C0812.3124%2C0812.2978%2C0812.4759%2C0812.1112%2C0812.1544%2C0812.2756%2C0812.2330%2C0812.0165%2C0812.0932%2C0812.0622%2C0812.4131%2C0812.1992%2C0812.4462%2C0812.1201%2C0812.2410%2C0812.2745%2C0812.3982%2C0812.0676%2C0812.1053%2C0812.3521%2C0812.4948%2C0812.3368%2C0812.1904%2C0812.3696%2C0812.3459%2C0812.3970%2C0812.4126%2C0812.4271%2C0812.2059%2C0812.1724%2C0812.5044%2C0812.0237%2C0812.0958%2C0812.1276%2C0812.4181%2C0812.4809%2C0812.4575%2C0812.0975%2C0812.3064%2C0812.0152%2C0812.4060%2C0812.4448%2C0812.0641%2C0812.3692%2C0812.4737%2C0812.2061%2C0812.0480%2C0812.1665%2C0812.4940%2C0812.1958%2C0812.0774%2C0812.1836%2C0812.2912%2C0812.3417%2C0812.3288%2C0812.1257%2C0812.2165%2C0812.3322%2C0812.2616%2C0812.1355%2C0812.0437%2C0812.3918%2C0812.4077%2C0812.0324%2C0812.0345%2C0812.3406%2C0812.2250%2C0812.0049%2C0812.4392%2C0812.2561%2C0812.2114%2C0812.1843%2C0812.1059%2C0812.4393%2C0812.1922%2C0812.4040%2C0812.1219%2C0812.5112%2C0812.1907%2C0812.4746%2C0812.0422%2C0812.1569%2C0812.3237%2C0812.2970%2C0812.4191%2C0812.3211&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "This note studies feedforward circuits as models for perfect adaptation to\nstep signals in biological systems. A global convergence theorem is proved in a\ngeneral framework, which includes examples from the literature as particular\ncases. A notable aspect of these circuits is that they do not adapt to pulse\nsignals, because they display a memory phenomenon. Estimates are given of the\nmagnitude of this effect."}, "authors": ["Eduardo D. Sontag"], "author_detail": {"name": "Eduardo D. Sontag"}, "author": "Eduardo D. Sontag", "arxiv_comment": "Updates version 1; added many references, simulations, examples, and\n  also more comments on approximate adaptation", "links": [{"href": "http://arxiv.org/abs/0812.0622v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0812.0622v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "q-bio.QM", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "q-bio.QM", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0812.0622v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0812.0622v2", "journal_reference": null, "doi": null, "fulltext": "arXiv:0812.0622v2 [q-bio.QM] 7 Jun 2009\n\nRemarks on Feedforward Circuits, Adaptation,\nand Pulse Memory\nEduardo D. Sontag\nDepartment of Mathematics\nRutgers University\nNew Brunswick, NJ 08903\n\nAbstract\nThis note studies feedforward circuits as models for perfect adaptation to step signals in biological\nsystems. A global convergence theorem is proved in a general framework, which includes examples\nfrom the literature as particular cases. A notable aspect of these circuits is that they do not adapt\nto pulse signals, because they display a memory phenomenon. Estimates are given of the magnitude\nof this effect.\n\n1\n\nIntroduction\n\nFeedforward circuits have been often proposed for adaptation to constant signals in biological systems. Indeed, the review paper [26] gives a chemical reaction model, called there a \"sniffer\" and\nshown in Figure 1, as the paradigm for perfect adaptation. The chemical species S acts as a \"sigk3\n\nS\n\n@\n@\n\n-\n\n0\n\nk2\n\nk1 @\n\nR\n@\n\nk4\n\nX\n\nR\n\n?\n-\n\n0\n\nFigure 1: \"Sniffer\" network, from [26]\n\nnal\", and the species R is viewed as a \"response\" element. The third species, X, is an intermediate\nspecies. The species S directly helps promote the formation of R (arrow labeled \"k1 \"), and also the\nformation of X (arrow labeled \"k3 \"). On the other hand, X also enhances degradation of the species\nR (vertical arrow labeled \"k2 \"), and thus S also acts through X as an inhibitor of R, counteracting\nthe positive direct effect. This \"incoherent\" counterbalance between a positive and a negative effect\ngives rise to a regulation property.\nMathematically, the model is described in [26] as a system of two coupled differential equations\n\n1\n\n\ffor the concentrations of the substances in question, using mass-action kinetics:\n\u1e8b = k3 s \u2212 k4 x\n\u1e59 = k1 s \u2212 k2 xr\n\n(1a)\n(1b)\n\nwhere dot is used to indicate time derivative. The key fact is that in steady state and for nonzero\nconstant signals S, the concentration of R equals kk21 kk34 , and this value is independent of the actual\nvalue of S. (This follows simply by setting the right-hand sides of the equations to zero and solving\nfor r.)\nSimilar constructions have been given in other biological investigations of adaptation, notably\nin [30], where various possible chemical networks are proposed for modeling adaptation by the\nchemotaxis pathway of Dictyostelium.\nA common feature of these models is that they have the form of a stable linear system which\nin turn drives a one-dimensional (generally nonlinear) system, whose state-variable represents the\nresponse that should adapt. The interconnection is set up so that the whole system becomes a\n\"feedforward circuit\" [1].\nGeneral framework\nThe strength of the external input signal (a non-negative real number) will be denoted by u, the\nstate of the linear system (an n-dimensional vector) by x, and the state of the driven response\n(a real number) by y. Then, a mathematical description of the evolution of concentrations of the\nvarious signals is given by a system of n + 1 differential equations as follows:\n\u1e8b = Ax + bu\n\u1e8f = c(y)x + d(y)u\n\n(2)\n\nwhere A and b are a constant stable matrix and column vector respectively, A \u2208 Rn\u00d7n , b \u2208 Rn\u00d71 ,\nand c(y) and d(y) are continuous functions of y so that, for each y, c(y) \u2208 R1\u00d7n and d(y) \u2208 R.\nSystem (2) is a system with inputs and outputs, in the standard sense of control theory [23]. The\nstate variables x(t) and y(t) take values in some subsets X \u2286 Rn and Y \u2286 R respectively, where Y\nis a closed, possibly unbounded, interval. The sets X and Y can be used in order to impose nonnegativity and/or mass conservation constraints. Enough regularity is assumed so that, for every\nnon-negative constant input u0 , and every initial condition (x0 , y0 ) \u2208 X \u00d7 Y, the equations (2) have\na unique solution (x(t), y(t)) \u2208 X \u00d7 Y defined for all t \u2265 0.\nFor example, in the \"sniffer\" reactions (1) from [26], and writing u, x, and y instead of s, x, and\nr respectively, one has X = Y = R\u22650 , A = \u2212k4 , b = k3 , c(y) = \u2212k2 y, and d(y) = k1 (constant). In\nthese notations Equations (1) become:\n\u1e8b = \u2212k4 x + k3 u\n\u1e8f = \u2212k2 xy + k1 u.\n\n(3a)\n(3b)\n\nAdaptation to step inputs\nFor each nonzero constant input u0 , the steady states (x0 , y0 ) of the system (2) are obtained by first\nsetting \u1e8b = 0, which gives x0 = \u2212A\u22121 bu0 (the inverse is well-defined because A was assumed to be\n2\n\n\fstable, and in particular all its eigenvalues are nonzero), and then substituting into the left-hand\nside of the y-equation. There obtains the following algebraic equation:\nd(y) \u2212 c(y)A\u22121 b = 0\n\n(4)\n\n(after canceling out u0 6= 0). A key hypothesis made from now on (and which is satisfied in all the\ncited examples) is that there is a unique solution y = y0 of the algebraic equation (4), and that this\nsolution is an asymptotically stable state for the reduced system\n\u1e8f = (d(y) \u2212 c(y)A\u22121 b)u0\nthat would result if x(t) were already at its steady state \u2212A\u22121 bu0 . To be precise, the following\nhypothesis will be imposed:\n\u0002\n\u0001\n\u0003\n(\u2203 y0 \u2208 Y) (\u2200 y \u2208 Y) (y \u2212 y0 ) d(y) \u2212 c(y)A\u22121 b < 0\n(H)\n(that is, \u1e8f = (d(y) \u2212 c(y)A\u22121 b)u0 is positive when y < y0 and negative when y > y0 ). It is\nfundamental to observe that y0 (though not, of course, x0 ) is independent of the particular numerical\nvalue of u0 .\nProposition 2.1 shows that, assuming boundedness of trajectories, systems (2) \"adapt\" to\nnonzero constant signals u0 (\"step signals\"), in the sense that all the solutions of the system (2)\nconverge to the above steady state (x0 , y0 ), where y0 is independent of u0 .\nTake again as an example the equations (3) from [26], now with all ki = 1, Figure 1(b) plots\nthe response to the piecewise constant input with nonzero values that is shown in Figure 1(a). It is\nclear that this response adapts to the value y0 = 1.\nMemory of pulse inputs\nOne of the main objectives of this note is to bring attention to the following additional facts. When\nu0 = 0, that is, in the absence of an external signal, steady states are no longer unique. Indeed, any\nvector of the form (0, y) is a steady state. This has an important consequence for the behavior of\nsystem (2) when a pulse input is used. A pulse is defined here as an input u which has the following\nform: u(t) = u0 6= 0 for some interval t \u2208 [0, T ], and u(t) = 0 for t > T . Suppose that the interval\nis long enough (T \u001d 1) so that one may assume that x(T ) and y(T ) are (approximately) in steady\nstate: x(T ) \u2248 \u2212A\u22121 bu0 and y(T ) \u2248 y0 . Upon removal of the external excitation at time T , the\nequations for the system become \u1e8b = Ax and \u1e8f = c(y)x for t > T , with initial conditions x(T )\nand y(T ), so x(t) \u2248 \u2212e(t\u2212T )A A\u22121 bu0 for t \u2265 T . The solution of \u1e8f = c(y)x starts at y0 but adds a\nquantity which integrates the effect of the nonzero function x(t). The response may then settle to\na new value which is different than the adapted value y0 .\nThus, feedforward systems for adaptation as those discussed here exhibit a \"memory\" effect\nwith respect to (ideal) pulses. This phenomenon was apparently not remarked upon earlier. The\npresent note discusses the effect and provides estimates.\nTo illustrate the phenomenon with the simplest possible (if not biologically meaningful) example,\ntake n = 1, A = \u22121, b = 1, c(y) = \u22121, and d(y) = 1. One has that \u1e8f \u2248 \u2212eT \u2212t u0 , so y(t) \u2192 y0 \u2212u0 <\ny0 as t \u2192 \u221e (assuming that u0 > 0). In fact, the larger the u0 , the smaller the new asymptotic\nvalue y0 \u2212 u0 is. For the nonlinear equations (3) from [26], the same phenomenon holds. Taking all\nki = 1, Figure 1(d) plots the response to a pulse of unit amplitude and Figure 1(f) plots the response\n3\n\n\fFigure 2: Plots for example discussed in text. In left column are inputs u(t), in right column\nare responses y(t). Initial conditions are x(0) = y(0) = 0. u(t) is constant up to time t = 5,\nswitches to another constant value at time t = 5. (a,b) u switches to a nonzero value, y adapts\nagain. (c,d) Pulse of magnitude 1: asymptotic value of y is \u2248 1/e \u2248 0.37 after pulse. (e,f) Pulse of\nlarger magnitude 2: asymptotic value of y is smaller: \u2248 1/e2 \u2248 0.14 after pulse. (g,h) Exponential\ndecaying u(t) = 2e(t\u22125)/10 after time t = 5 results in return to close to adapted value y(\u221e) \u2248 0.9\n(u(t) plotted only on interval [0, 10] for ease of comparison).\n\nto a pulse of twice the amplitude. Once again, the response settles to a value that is smaller when\nthe amplitude of the pulse was larger. The sharp cut-off of an ideal pulse plays an important role\non this \"memory\" effect: when the input instead returns slowly enough to its baseline value, an\nalmost-adapted response is recovered, as shown in Figure 1(h).\nFeedforward motifs in systems biology\nFeedforward circuits are ubiquitous in biology, as emphasized in [1], where (incoherent) feedforward circuits were shown to be over-represented in E.coli gene transcription networks compared to\nother \"motifs\" involving three nodes. Similar conclusions apply to certain control mechanisms in\nmammalian cells [13]. A large number of papers have been devoted to the signal-processing capabilities of the feedforward motif, notably [15] which looked into its properties as a \"change detector\"\n(essentially, sensitivity to changes in the magnitude of the input signal), and [5] which studies its\noptimality with respect to periodic inputs. Comparisons with other \"three node\" architectures\nwith respect to the trade-off of sensitivity versus noise filtering are given in [8]. Other references\non feedforward circuits include [22] (showing their over-representation at the interface of genetic\nand metabolic networks), [28] (classification of different subtypes of such circuits), and [10] (clas4\n\n\fsification into \"time-dependent\" versus \"dose-dependent\" biphasic responses, which are in a sense\nthe opposite of adaptated responses). The latter reference provides a large number of additional\nincoherent feedforward input-to-response circuits, including: EGF to ERK activation [21, 18], glucose to insulin release [17, 19], ATP to intracellular calcium release [14, 16], nitric oxide to NF-\u03baB\nactivation [20], microRNA regulation [25], and many others. Dealing specifically with adaptation\nproperties of feedforward circuits, and in addition to the papers [26, 30], are the paper [29] on\nmicroRNA-mediated loops, and [11], which deals with the role of feedforward structures in the\nrobust behavior in E.coli carbohydrate uptake via the carbohydrate phosphotransferase system (an\nanalogous metabolic mechanism is also discussed in [27]).\nOutline of paper\nSection 2 has statements of the convergence results. Section 3 has a brief discussion of \"approximate\"\nadaptation by feedforward circuits. Section 4 shows estimates of the magnitude of the pulse memory\neffect. Section 5 has the proofs of the convergence results. Section 6 revisits the motivating examples\nand also briefly discusses the systems in [11, 29]. Finally, it is known that, under appropriate\ntechnical assumptions, perfect adaptation implies that the system may be written, after a suitable\nnonlinear change of coordinates, as a system in which the integral of the regulated quantify is\nfed-back, see for instance [6, 7, 31, 24]. This fact is not incompatible with the system being a\nfeedforward system, as remarked in Section 7. Section 8 summarizes the results and speculates on\ntheir significance.\n\n2\n\nStatements of convergence results\n\nThe main convergence result is as follows. Note that, since the x-coordinate of a solution (x(t), y(t))\nfor constant u always converges (because of the stability assumption on the linear system) and hence\nis bounded, asking that (x(t), y(t)) is bounded is the same as asking that y(t) is.\nProposition 2.1 Suppose that Property (H) holds. Then, for each step input u \u2261 u0 6= 0, and\nevery initial condition, if the corresponding solution (x(t), y(t)) of (2) is bounded, then it converges\nto (x0 , y0 ).\nBoundedness is automatically satisfied if Y is itself a bounded interval, as is the case if mass\nconservation laws constrain the system dynamics. More generally, the following condition can be\nhelpful. It strengthens Property Property (H) for small and for large values of y:\n(\u2200 u0 > 0)(\u2203 \u03b5\u0304 > 0)\n\u0001\n\u0003\n|c(y)| \u03b5\u0304 + u0 d(y) \u2212 c(y)A\u22121 b < 0\n\u0002\n\u0001\n\u0003\n(\u2203 y1 \u2208 Y) (\u2200 y1 > y \u2208 Y) \u2212 |c(y)| \u03b5\u0304 + u0 d(y) \u2212 c(y)A\u22121 b > 0\n\n(\u2203 y2 \u2208 Y) (\u2200 y2 < y \u2208 Y)\n\n\u0002\n\n(H\u2217 )\n\n(where |c| denotes the norm of the vector c) and it says that the inequality in (H) is preserved\nunder small enough perturbations proportional to c(y), as long as y is large or small enough.\nLemma 2.2 Suppose that (H) and (H\u2217 ) are satisfied. Then, for each step input u \u2261 u0 6= 0, and\nevery initial condition, the corresponding solution (x(t), y(t)) of (2) is bounded.\n5\n\n\fFrom Proposition 2.1 and Lemma 2.2, there is the following immediate consequence:\nCorollary 2.3 Suppose that (H) and (H\u2217 ) are satisfied. Then, for each step input u \u2261 u0 6= 0,\nand every initial condition, the corresponding solution (x(t), y(t)) of (2) converges to (x0 , y0 ).\nCondition (H\u2217 ) is often automatically satisfied in examples:\nLemma 2.4 Suppose that c(y) and d(y) are affine in y. That is, there are two row vectors c0 , c1 \u2208\nR1\u00d7n and two scalars d0 , d1 such that c(y) = c0 + yc1 and d(y) = d0 + yd1 . Then, Property (H)\nimplies Property (H\u2217 ).\n\n3\n\nApproximate adaptation\n\nPerfect adaptation is an ideal mathematical property. In biological systems, regulated behavior\nmay break down due to dilution, turn-over due to gene expression and protein degradation, and\nother effects, especially over long time intervals. From a modeling viewpoint, it is thus interesting\nto study mechanisms which provide \"approximate\" adaptation, in the sense that the response of\nthe system remains approximately constant, as long as parameters (kinetic constants, production\nrates, degradation rates) stay within appropriate ranges. The reader is referred to the papers [3, 2]\nfor formulations of certain approximate adaptation mechanisms for linear and nonlinear models.\nThis section discusses a few general facts, and works out details for a particular class of systems,\nto be illustrated with an example in Section 6.5.\nOne general fact is that a perturbation of the right-hand side of a differential equation results\nin small perturbations of trajectories, on bounded intervals of time. Specifically, suppose that x(t)\nis the solution of a set of differential equations \u1e8b = f (x), with initial condition x(0) = x0 , and\nconsider any fixed time interval [0, T ]. Next, consider a perturbed equation \u017c = f (z) + h(z), and\nlet z(t) be its solution with the same initial condition z(0) = x0 . Then, if the vector field \"h\"\nis small in an appropriate sense (uniformly, for instance, or more generally if its integral along\ntrajectories is small), then it follows that z(t) \u2248 x(t) for all t \u2208 [0, T ]; see Theorem 55 in Appendix\nC of [23] for details. In principle, and in the absence of additional stability assumptions, the\ntheoretical estimates tend to be conservative, in that the guaranteed approximation is very poor as\nT increases. However, in practice the approximation may be quite good. As an illustration, consider\nonce again the \"sniffer\" reactions (3) from [26], and suppose that one perturbs the right-hand side\nof the equations by adding saturated terms:\nV1 y\nK1 + y\nV2 x\n\u1e8f = \u2212k2 xy + k1 u +\nK2 + x\n\n\u1e8b = \u2212k4 x + k3 u +\n\nrepresenting cross-activating feedbacks. Using the step input from Figure 1(a), Figure 3 compares\nthe results of simulations (starting from the zero initial state) of the original and the perturbed\nsystems, when all constants have been chosen as 1. Notice that the perturbed system has a response\nwhich is quite close to that of the original system, on the given interval.\n\n6\n\n\fFigure 3: Approximate adaptation: comparison of responses when right-hand side of equation is\nperturbed as discussed in text. Input is as in Figure 1(a). Solid line is for original system and\ndashed line for perturbed system.\n\nAnother sense of approximate adaptation to step inputs is when adaptation behavior happens\nonly for input signal values in a restricted range. This is illustrated next, using a perturbation of\nthe \"sniffer\" reactions (3) from [26]. Suppose that the equations are as follows:\n\u1e8b = \u2212k4 x + k3 u + r(y)\n\u1e8f = \u2212k2 xy + k1 u \u2212 p(y).\n\n(5a)\n(5b)\n\nThe term p(y) may represent, for example, a linear or nonlinear degradation effect for the species\ny, while r(y) might represent an activating feedback. (In Section 6.5, it will be shown that a\nmicroRNA-based feedforward loop studied in the literature can be represented, after a coordinate\nchange, in this form.) The steady state corresponding to a given constant input u \u2261 u0 can be\nfound as follows. Setting the right-hand sides of (5) to zero and solving the first equation for x gives\nx = k14 (k3 u + r(y)). The expression for x is then substituted in the second equation, to provide the\nfollowing relation for u in terms of y:\nu = Q(y) =\n\nk2 yr(y) + k4 p(y)\nk1 k4 \u2212 k2 k3 y\n\nSuppose that p(0) = 0 and that k2 yr(y) + k4 p(y) is an increasing function of y (this happens\nautomatically if, for example, p(y) and q(y) are non-negative and increasing functions of y). Then\nQ is an increasing function on the interval 0 \u2264 y < \u03b1 = kk21 kk34 , with Q(0) = 0 and a pole at \u03b1, see\nFigure 3. The function Q can be then inverted, so as to obtain y as a function of u, y = Q\u22121 (u).\nFor every step input u whose amplitude is large enough, the steady state value of the response\ny is close to \u03b1. In that sense, \"approximate\" adaptation holds. One way to characterize this effect\nis as follows. Define K = Q(\u03b1/2). This number plays a role analogous to that of a \"half maximal\neffective concentration\" or \"EC50 value\" in pharmacology and biochemistry: for any input value u\nlarger than K, y is within \u03b1/2 and \u03b1.\nFor example, if p(y) = ky (linear degradation/dilution) and q(y) = 0, then y = Q\u22121 (u) =\nfor appropriate numbers V and K. For u > K, the response value is within V /2 and V .\n\n7\n\nVu\nK+u\n\n\fFigure 4: The function Q\n\n4\n\nPulse memory effects\n\nAs remarked in the Introduction, when a pulse input u(t) is applied to the system (2), the asymptotic\nvalue of y does not typically return to its adapted value. There is a \"memory\" effect as the\nasymptotic value of y depends on the magnitude of the step. Thus, this section analyzes the\neffect of a pulse input, that is u(t) = u0 6= 0 for some interval t \u2208 [0, T ], and u(t) = 0 for\nt > T . The underlying assumption is that the interval is long enough (T \u001d 1) so that x(T ) and\ny(T ) are (approximately) in steady state: x(T ) \u2248 \u2212A\u22121 bu0 and y(T ) \u2248 y0 . This means that\nx(t) \u2248 \u2212e(t\u2212T )A A\u22121 bu0 for t \u2265 T , and y approximately solves \u1e8f = \u2212c(y)e(t\u2212T )A A\u22121 bu0 starting at\nthe adapted value y0 .\nTherefore, and changing for simplicity the origin of time to t = T , one wishes to estimate the\nlimiting value of the solution of the initial-value problem:\n\u1e8f = \u2212c(y)etA A\u22121 bu0 ,\n\ny(0) = y0 .\n\n(6)\n\nIn general, such a differential equation, even though scalar, is not easy to solve, because of the time\ndependence. Two special cases are as follows.\n\n4.1\n\nAffine case\n\nWhen c(y) = c0 + yc1 is affine in y, one may write (6) as:\n\u1e8f + \u03b1(t)y = \u03b2(t)\nwhere \u03b1(t) = c1 etA A\u22121 bu0 and \u03b2(t) = \u2212c0 etA A\u22121 bu0 . This is a linear\nR differential equation, which\ncan be solved in a standard manner by using the integrating factor e \u03b1(t)dt .\n\n4.2\n\nSeparable case\n\nAnother special case is that in which one may decompose c(y) as follows:\nc(y) = \u03b8(y)c\n\n8\n\n(7)\n\n\fwhere \u03b8(y) is a nowhere vanishing scalar continuous function of y, and c is a row vector. Details in\nthis special case are as follows.\nSeparating variables,\nZ y(t)\ny0\n\ndz\n= \u2212c\n\u03b8(z)\n\nt\n\n\u0012Z\n\ne\n\nsA\n\n\u0013\n\n\u0001\nds A\u22121 bu0 = c I \u2212 etA A\u22122 bu0 .\n\n0\n\nR y dz\nThe function \u03980 (y) := y0 \u03b8(z)\nis strictly increasing or strictly decreasing if \u03b8 is positive or negative\nrespectively, so its inverse \u0398 := \u0398\u22121\nis well defined, as it is also strictly increasing or strictly\n0\ndecreasing respectively.\nOne concludes that:\n\u0177u0 = \u0398 cA\u22122 bu0\n\n\u0001\n\nis the steady-state value of y after the system has been subjected to a long pulse of amplitude u0\nand the pulse is removed. Recalling the conditions under which \u0398 is increasing or decreasing, one\nmay summarize as follows:\nProposition 4.1 Assuming the form in (7), with \u03b8(y) nonzero and continuous on Y, the steady\nstate value \u0177u0 is:\n(a) an increasing function of u0 if \u03b8(y0 )cA\u22122 b > 0, and\n(b) a decreasing function of u0 if \u03b8(y0 )cA\u22122 b < 0.\nNotice that \u0398(0) = y0 , so the steady state \u0177u0 after a pulse is smaller (respectively, larger)\nthan the adaptation steady state y0 (that results after a step input) provided that \u03b8(y0 )cA\u22122 b < 0\n(respectively, > 0).\n\n4.3\n\nNon-ideal pulses\n\nObserve that, while the previous analysis concerned only ideal pulses (the value of u(t) returns\nexactly to zero after time t = T ), approximately the same phenomenon will still occur if u merely\nreturns to a \"small\" value, in the following sense. Suppose that u(t) = u0 6= 0 for some interval\nt \u2208 [0, T ], and u(t) = \u03b5 for t > T , where \u03b5 is sufficiently small. The asymptotic value of the response\ny will eventually converge to the adapted value y0 , if \u03b5 6= 0. However, if \u03b5 \u2248 0, this convergence\nto y0 will be extremely slow, as the behavior will be close of that for ideal pulses. Mathematically,\nthis fact is a trivial consequence of the continuous dependence of solutions of differential equations\non parameters (on finite time intervals).\nTo formulate this property precisely, call z(t) the value of y(t) that would correspond to the\nideal pulse (u(t) = 0 for t > T ), and y\u03b5 (t) the value that corresponds to the input with u(t) = \u03b5 for\nt > T . The subscript \u03b5 is used to emphasize the dependence on the numerical value of \u03b5. For any\nfixed time T 0 > T , it holds that y\u03b5 (T 0 ) \u2248 z(T 0 ), in the sense that y\u03b5 (T 0 ) \u2192 z(T 0 ) as \u03b5 \u2192 0. (See for\nexample, Theorem 1 in [23] for a proof; explicit estimates of convergence can be obtained using the\nGronwall inequality, as discussed in that textbook.)\nAnother way in which a pulse may differ from an ideal pulse is if the cut-off to u(t) = 0 is\nnot sharp. In fact, current microfluidics technologies allow one to produce pulsatile-like inputs to\n9\n\n\fcell signaling systems, but these might exhibit a slow decay at the tail end. (The same effect may\nmanifest itself in real systems, when an intermediate species stands between the input and the x\nand y variables.) If the cut-off is sharp enough, a continuity argument similar to the one explained\nfor pulses that sharply return to a constant value 6= 0 applies. However, for slower decays to u = 0,\nthe asymptotic value of the response may indeed return to close to adapted values, as was earlier\nillustrated with an example, see Figure 1(h).\n\n5\n\nProofs\n\nThe following is an elementary observation about scalar differential equations.\nLemma 5.1 Consider the scalar time-dependent differential equation\n\u1e8f = F (t, y) + \u03c6(y)\nwhere F and \u03c6 are differentiable functions. Assume that F (t, y) \u2192 0 as t \u2192 \u221e uniformly on y \u2208 K,\nwhere K \u2286 R is a closed and bounded interval, and that there is some y0 \u2208 K such that \u03c6(y) > 0\nfor all y < y0 and \u03c6(y) < 0 for all y > y0 . Then, every solution y : [0, \u221e) \u2192 K is so that y(t) \u2192 y0\nas t \u2192 \u221e.\nProof. Let y(t) be a solution with values in K, and pick any open neighborhood N of y0 . We must\nshow that, for some T , y(t) \u2208 N for all t > T . The set K \\ N is the union of two closed and\nbounded sets A\u2212 and A+ (either of which might possibly be empty, if y0 is an endpoint of K) such\nthat y \u2208 A\u2212 \u21d2 y < y0 and y \u2208 A+ \u21d2 y > y0 . By continuity of the function \u03c6, there is some\npositive number \u03b4 such that \u03c6(y) > \u03b4 for all y \u2208 A\u2212 and \u03c6(y) < \u2212\u03b4 for all y \u2208 A+ . For some t0 ,\n|F (t, y)| < \u03b4/2 for all y \u2208 K \\ N and all t \u2265 t0 . Thus, for t \u2265 t0 we have that \u1e8f(t) > \u03b4/2 if y(t) \u2208 A\u2212\nand \u1e8f(t) < \u2212\u03b4/2 if y(t) \u2208 A+ . This means that for some T > t0 it will hold that y(t) exits K \\ N\nand does not enter again, as needed.\n\nProof of Proposition 2.1\nWe will apply Lemma 5.1. Suppose that Property (H) holds. Pick any step input u \u2261 u0 6= 0\nand an initial condition of (2), and suppose that the corresponding solution (x(t), y(t)) of (2) is so\nthat y(t) is bounded. Since Y is a closed set, this is the same as saying that y(t) \u2208 K for all t, for\nsome closed and bounded interval K \u2286 Y. We have that x(t) = \u03b8(t) \u2212 A\u22121 bu0 for all t \u2265 0, where\n\u03b8(t) = etA (x0 + A\u22121 bu0 ) and therefore y satisfies:\n\u1e8f = F (t, y) + \u03c6(y) = c(y)\u03b8(t) + \u03c6(y)\n\n(8)\n\nwhere \u03c6(y) = (d(y) \u2212 c(y)A\u22121 b)) u0 . Property (H) gives the property needed for \u03c6 in the Lemma.\nOn the other hand, \u03b8(t) \u2192 0 (as etA \u2192 0, by stability), so F (t, y) \u2192 0 uniformly on y \u2208 K. Thus,\nLemma 5.1 gives the desired conclusion.\n\n10\n\n\fProof of Lemma 2.2\nWe pick any initial condition, and want to show that the corresponding solution (x(t), y(t)) of (2) is\nsuch that y(t) is bounded. We will prove that y(t) is upper-bounded, the lower bound proof being\nsimilar, and assume that Y is not upper bounded, since otherwise we are done. By Property (H\u2217 ),\nwe may pick \u03b5\u0304 > 0 and y2 \u2208 Y such that |c(y)| \u03b5\u0304 + \u03c6(y) < 0 for all y > y2 , where the function \u03c6 is\nas in the proof of Proposition 2.1. By (8), we know that \u1e8f(t) < 0 as long as y(t) > y2 and t \u2265 t0 ,\nwhere t0 is picked so that |\u03b8(t)| < \u03b5\u0304 for all t \u2265 t0 . This clearly implies that y(t) is upper bounded.\n\nProof of Lemma 2.4\nSuppose that c(y) and d(y) are affine in y, c(y) = c0 + yc1 and d(y) = d0 + yd1 . As Property (H)\nholds,\n\u03bc + \u03bdy = d0 + yd1 \u2212 (c0 + yc1 )A\u22121 b < 0\nfor y > y0 , y \u2208 Y, where we are writing \u03bc := d0 \u2212 c0 A\u22121 b and \u03bd := d1 \u2212 c1 A\u22121 b.\nFix any u0 > 0. We need to show that Property (H\u2217 ) holds. We will show the existence of \u03b5\u0304\nand y2 ; existence of y2 is proved in a similar way. Our goal is to pick y2 \u2208 Y in such a way that\n\u0001\n|c(y)| \u03b5\u0304 + u0 d(y) \u2212 c(y)A\u22121 b < 0\n(9)\nwhenever y > y2 is an element of Y. If the interval Y is upper bounded, we may pick y2 equal to\nits right endpoint, and this property is satisfied vacuously. Thus, we assume from now on that Y is\nnot upper bounded.\nWe claim that \u03bd < 0. Indeed, if \u03bd \u2265 0 then \u03bc + \u03bdy \u2265 \u03bc + \u03bdy0 = 0 for any y > y0 , y \u2208 Y, which\nwould contradict Property (H). (Note that there exist such y > y0 , because y0 cannot be the right\nendpoint of Y, because Y is not upper bounded.)\nFor (9) to be satisfied, and assuming we pick y2 \u2265 0, it is enough that this inequality should\nhold:\n(|c0 | \u03b5\u0304 + u0 \u03bc) + y (|c1 | \u03b5\u0304 + u0 \u03bd) < 0\n(10)\n(because |c0 + c1 y| \u2264 |c0 | + |c1 | y). We let \u03b5\u0304 := \u2212 2|c1\u03bd|u0 . Then, for y > 0,\n(|c0 | \u03b5\u0304 + u0 \u03bc) + y (|c1 | \u03b5\u0304 + u0 \u03bd) < (|c0 | \u03b5\u0304 + u0 \u03bc) + yu0 \u03bd/2\nand, since the upper bound is a linear function with negative slope, it will be negative for large y.\n\n6\n\nExamples\n\nWe show here how the results apply, in particular, to the models in the papers [26] and [30].\n\n6.1\n\n\"Sniffer\" model\n\nThe \"perfect adaptation\" model in [26] is, after a renaming of variables and a slight rearranging\nto bring into the form (2), as shown in (3). Here y0 = kk21 kk34 , and (H) is satisfied because d(y) \u2212\n11\n\n\fc(y)A\u22121 b = k1 \u2212 kk2 k4 3 y changes sign at y = y0 . This example has the form in Lemma 2.4, so\nconvergence holds.\nTo study\nR y the effect of pulses, we write c(y) in the form (7) using c = \u2212k2 and \u03b8(y) = y. So\n\u03980 (y) = y0 dz/z = ln(y) \u2212 ln(y0 ) = ln(y/y0 ). It follows that \u0398(r) = y0 er , so\n\u0177u0\n\n\u0012\n\u0013\nk2 k3\n= y0 exp \u2212 2 u0\nk4\n\nwhich decreases with u0 .\n\n6.2\n\nDictyostelium chemotaxis models from [30]\n\nThere are several models given in [30], but they all have the same general interpretation. The\nauthors of [30], based on previous work [12], postulate the existence of a \"response regulator\" R, a\nvariable that correlates to the chemotactic activity of the system, that can be in an \"active\" or in an\n\"inactive\" form. The activation and inactivation of R are regulated by a pair of opposing processes:\nan excitation process that induces an increase in the level of the response R, and an inhibition\nprocess that lowers this response. The input to the system is the extracellular chemoattractant\nconcentration, and it is assumed that this signal triggers increases in concentrations in both the\nactivation and inactivation elements. We denote by y(t) the concentration of active regulator, by\n\u03b1\u2212y(t) the concentration of inactive regulator, where \u03b1 is the total concentration (active+inactive),\nassumed constant, and by x1 (t) and x2 (t) the concentrations of the activation and inactivation\nelements respectively.\nThere are several alternative models given in [30]. The first one is, in our notations:\n\u1e8b1 = \u2212k1 x1 + k2 u\n\u1e8b2 = \u2212k3 x2 + k4 u\n\u1e8f = k5 (\u03b1 \u2212 y)x1 \u2212 k6 yx2\nwhere the ki 's are positive constants. This has the form (2), with X = R2\u22650 , Y = [0, \u03b1], c(y) =\n(k5 (\u03b1 \u2212 y), \u2212k6 y), and d(y) = 0. To simplify notations, let us write P = kk2 k1 5 and Q = kk4 k3 6 . Note\nthat Property (H) is satisfied, as the solution y0 of\nP (\u03b1 \u2212 y) \u2212 Qy = 0\n\n(11)\n\nbelongs to the interval (0, \u03b1), and the algebraic expression changes there from positive to negative.\nThe y-dynamics is bounded, by definition, so we have convergence.\nSince the y equation is affine, the memory effect of pulses can be obtained by solving an appropriate linear differential equation, as explained earlier, but the expression for the solution is\nalgebraically very involved. We can, however, make some qualitative remarks.\nLemma 6.1 The solution of the initial-value problem\n\u1e8f = P (\u03b1 \u2212 y)e\u2212k1 t u0 \u2212 Qye\u2212k3 t u0 , y(0) = y0\nhas a limit \u0177u0 . If k3 > k1 then \u0177u0 > y0 , and if k3 < k1 then \u0177u0 < y0 .\n12\n\n(12)\n\n\fProof. We assume that k3 > k1 ; the case k3 < k1 is proved in an analogous fashion. Since y(t) is\nbounded, it will be enough to show that there cannot exist two limit points 0 \u2264 \u02331 < \u02332 \u2264 \u03b4 of\nthe solution. So assume that such points exist, and let 0 < t1 < s1 < t2 < s2 . . . \u2192 \u221e be so that\ny(ti ) \u2192 \u02331 as i \u2192 \u221e and y(si ) \u2192 \u02332 as i \u2192 \u221e. Pick \u03b5 := 21 (\u02332 \u2212 \u02331 ) + (\u03b1 \u2212 \u02332 ) > 0 and some time\nt\u0304 > 0 such that P \u03b5 > \u03b1Qe(k1 \u2212k3 )t\u0304 (there is such a t\u0304 because k1 \u2212 k3 < 0).\nNote the following property:\ny(t) < \u03b1 \u2212 \u03b5 and t \u2265 t\u0304 \u21d2 \u1e8f(t) > 0 .\n\n(13)\n\nIndeed,\nek1 t\n\u1e8f = P (\u03b1 \u2212 y(t)) \u2212 Qy(t)e(k1 \u2212k3 )t\u0304 > P \u03b5 \u2212 Q\u03b1e(k1 \u2212k3 )t > 0\nu0\nbecause \u03b1 \u2212 y(t) > \u03b5 and y(t) < \u03b1, so \u1e8f(t) > 0 as claimed.\nSince \u02332 > \u03b1 \u2212 \u03b5, there is some i so that y(si ) > \u03b1 \u2212 \u03b5. Without loss of generality, we may\nassume that si was picked larger than t\u0304. Then,\nt > si \u21d2 y(t) \u2265 \u03b1 \u2212 \u03b5 .\n\n(14)\n\n(Otherwise, there would exist some a < \u03b1 \u2212 \u03b4 and some T > si such that y(T ) = a, and we can\nassume that T has been picked smallest possible with this property, for the given a. Pick \u03b4 > 0\nso that si < T \u2212 \u03b4 and so that the interval I = (T \u2212 \u03b4, T ] has the property that y(I) \u2286 [0, \u03b1 \u2212 \u03b5).\nThen, by property (13), \u1e8f(t) > 0 for all t \u2208 I. So y(t) < y(T ) for all t \u2208 I, which contradicts the\nminimality of T .)\nOn the other hand, since \u02331 < \u03b1\u2212\u03b5, y(tj ) < \u03b1\u2212\u03b5 for all sufficiently large j. This contradicts (14)\nif j > i. The contradiction shows that such \u02331 < \u02332 cannot exist, so the function y(t) is convergent\nas t \u2192 \u221e.\nWe must now prove that \u0177u0 > y0 . Since y0 solves (11), and e(k1 \u2212k3 )t < 1 for all t \u2265 0, it follows\nthat P (\u03b1 \u2212 y0 )e\u2212k1 t \u2212 Qy0 e\u2212k3 t > 0 for all t \u2265 0. Thus:\n\u1e8f(t) = P (\u03b1 \u2212 y(t))e\u2212k1 t \u2212 Qy(t)e\u2212k3 t \u2265 P (\u03b1 \u2212 y0 )e\u2212k1 t \u2212 Qy0 e\u2212k3 t > 0\nwhenever t \u2265 0 is such that y(t) \u2264 y0 . This implies that y(t) > y(0) = y0 for all t > 0. Therefore\nthe limit also satisfies \u0177u0 > y0 .\nThe interpretation of Lemma 6.1 is obvious: k3 > k1 means that the inhibitor (x2 ) degrades\nat a faster rate than the activator (x1 ). Thus, when the external signal is turned-off, there is a\nresidual effect due to the additional activator still present, which implies a positive memory effect,\nin the sense that the response is higher than its value at u = 0. Similarly, when k3 < k1 , there is\nadditional repressor present and the memory effect is negative (that is, lower than when u = 0).\nThe other models from [30] are similar, differing only in the placement of the feedforward terms\nin the y equation, and the stability results apply equally well. Let us consider one of the variants:\n\u1e8b1 = \u2212k1 x1 + k2 u\n\u1e8b2 = \u2212k3 x2 + k4 x1\n\u1e8f = k5 (\u03b1 \u2212 y)u \u2212 k6 yx2 .\nNote that the activator now acts so as to enhance the inhibitor, and the input signal acts directly\non the response element. This has the form (2), with X = R2\u22650 , Y = [0, \u03b1], c(y) = (0, \u2212k6 y), and\n13\n\n\fd(y) = k5 (\u03b1 \u2212 y). Note that Property (H) is satisfied, as k5 (\u03b1 \u2212 y) \u2212 kk2 k1 k4 k3 6 y changes sign at a\ny0 \u2208 (0, \u03b1). The y-dynamics is bounded, by definition, so we have convergence.\nOnce again, since the y equation is affine, the memory effect of pulses can be computed using\nlinear differential equations theory. The memory effect is in this case decreasing in u0 , independently\nof the parameters ki > 0. This is because the initial value problem after the signal has been turnedoff has the form:\n\u1e8f(t) = \u2212y(t)\u03b8(t)\nfor some positive function \u03b8(t), so y(t) < 0 for all t. Intuitively: the activation effect (u) turns-off\nimmediately, but there is a residual inhibition effect (x2 ).\nAs an concrete illustration, let us work out the case in which all constants are equal to 1. In\nthis case, solving (1 \u2212 y) \u2212 y = 0 gives y0 = 1/2, and \u1ef9u0 is the limiting value of the solution of:\n\u1e8f = \u2212ye\u2212t (t + 1)u0\n\u2212t \u22122]u\n0\n\n(because x2 (t) = e\u2212t (t + 1)u0 ). Thus, y(t) = 21 e[(2+t)e\nindeed, the memory effect is negative.\n\n6.3\n\nand therefore \u0177u0 = 21 e\u22122u0 , so that,\n\nA Michaelis-Menten model\n\nNon-affine variant of the above examples may be obtained by using Michaelis-Menten dynamics for\nactivation and inhibition reactions. For instance, we may write:\n\u1e8f =\n\nV2 y\nV1 (\u03b1 \u2212 y)\nu\u2212\nx2\nK1 + (\u03b1 \u2212 y)\nK2 + y\n\nfor some positive constants Vi and Ki . Once again, our hypotheses apply, and there is convergence\nto y0 .\nWe study memory effects for pulses for this example, but only in the special case in which all\nconstants are equal to 1 and for a 1-dimensional x-system:\n\u1e8b = \u2212x + u\n(1 \u2212 y)\ny\nu\u2212\nx.\n\u1e8f =\n1 + (1 \u2212 y)\n1+y\nWe have that y0 = 1/2 and x0 = u0 , and c(y) = \u2212y/(1 + y). We are in the separable situation\ndescribed earlier, and so solve \u1e8f = c(y)e\u2212t u0 using separation of variables. Writing\nZ\n\ny(t)\n\nln y(t) + ln 2 + y(t) \u2212 1/2 =\n1/2\n\n1\n( + 1) ds = \u2212\ns\n\nZ\n\nt\n\ne\u2212s ds u0 = (e\u2212t \u2212 1)u0\n\n0\n\nwe have, taking limits, that \u0177u0 is the solution of the algebraic equation:\nln \u0177u0 + \u0177u0 = 1/2 \u2212 ln 2 \u2212 u0\nand so decreases with u0 . For example, if u0 = 1 then \u0177u0 \u2248 0.24, which is less than one-half of the\nadapted value y0 = 0.5.\n\n14\n\n\f6.4\n\nA carbohydrate uptake system\n\nThe paper [11] deals with a feedforward motif that appears in one of the carbohydrate uptake systems in E.coli, the phosphotransferase system (PTS) for glucose uptake involving phosphoenolpyruvate (PEP). The reactions in this system result in the phosphorylation of Enzyme II A. \"EIIA-P\" is\nused to denote the phosphorylated form of this enzyme, which in turn has various regulatory functions through synthesis of cAMP. A feedforward loop is obtained when viewing u = Glc6P (glucose\n6-phosphate) as input to the system, and using as state variables the concentrations x = TP (triose\nphosphate) and y = PEP. See Figure 2 in that paper: there are positive effects of u on x, and of\nx on y, as well as a countering negative direct effect of u on y that involves the dephosphorylation\nof PEP into Prv via pyruvate kinase. For a simplified analysis following [11], assuming equation\n(1) from that paper, there results that the output of the system, the concentration of EIIA-P, is\nan increasing function of the ratio of concentrations PEP/Prv, where Prv is pyruvate (equations\n(3) and (5) in the citation). The objective of keeping EIIA-P approximately constant is achieved\nif the ratio PEP/Prv is kept approximately constant. The model in [11], Supplemental Materials,\nequations (2,3,11) together with the assumption that equation (1) in the paper holds, provides the\nfollowing equations for x and y:\n\u1e8b = \u2212ax + bu + \u03b1\n\u1e8f = ax \u2212 puy \u2212 \u03b2\n\n(15a)\n(15b)\n\nassuming that the simplest mass-action model is used for supplemental equation (12) of the reference. The constants \u03b1 and \u03b2 represent uptake rates (supplementary equations (8,9)). In the\ncase when \u03b1 = \u03b2 = 0, there results a system of the general form (2), with A = a, c(y) = a and\nd(y) = \u2212py (affine case). Solutions for constant nonzero inputs have y(t) \u2192 y0 = b/p, and the\neffect of pulses can be analyzed easily. When \u03b1 and \u03b2 are nonzero, the adaptation property fails,\nalthough it holds approximately if these numbers are small. However, even for large \u03b1, \u03b2, the steady\nstate when u is a constant equal to u0 is:\ny0 =\n\n\u03b1\u2212\u03b2\nb\n.\n+\np\npu0\n\nThis is still approximately constant, y0 \u2248 b/p, provided that u0 be sufficiently large, just as in the\nprevious discussion of approximate adaptation.\n\n6.5\n\nAn example of approximate adaptation\n\nThe paper [29] provides the following model of microRNA-mediated feedforward adaptation:\n\u1e571 = \u03b11 \u03c9 \u2212 \u03b21 p1\n\u03b1 2 pm\n1\n\u1e411 =\n\u2212 \u03b3m1 m2 \u2212 \u03b22 m1\n1 + pm\n1\n\u03b1 3 pm\n1\n\u1e412 =\n\u2212 \u03b3m1 m2 \u2212 \u03b23 m2\n1 + pm\n1\n\u1e572 = \u03b14 m2 \u2212 \u03b24 p2\nwhere p1 , m1 , m2 , p2 , \u03c9 are respectively the species concentrations of an \"upstream factor\", a microRNA, a target mRNA, the protein produced by the target mRNA, and an inducer of the upstream\n15\n\n\ffactor. The various constants represent transcription, translation, and degradation rates as well as\nwell as the efficiency of pairing of the microRNA to its target. (As in the reference, we pick identical\nHill coefficients for both promoters.) The interest in [29] is in studying the robustness of the steady\nstate value of p2 . Since this value is directly proportional\nto the steady state value of m2 , we omit\npm\n1\np2 from the model from now on. Similarly, as 1+pm is an increasing function of p1 , which is in turn\n1\nproportional to \u03c9 at steady state, we will think of this term as an input \"u\" and drop the equation\nfor p1 as well. We are left with the following two-dimensional (m1 , m2 ) system:\n\u1e411 = \u03b12 u \u2212 \u03b3m1 m2 \u2212 \u03b22 m1\n\u1e412 = \u03b13 u \u2212 \u03b3m1 m2 \u2212 \u03b23 m2 .\nWhen expressed in the alternative coordinates x = m1 \u2212 m2 and y = m2 , the system has the\nform in Equations (5), with k1 = \u03b13 , k2 = \u03b3, k3 = \u03b12 \u2212 \u03b13 , k4 = \u03b22 , r(y) = (\u03b23 \u2212 \u03b22 )y, and\np(y) = \u03b3y 2 + \u03b23 y. Thus this system exhibits an approximately adaptive behavior for large inputs,\nas discussed in Section 3. In particular, consider the parameter values used in [29]: \u03b11 = 0.01,\n\u03b12 = 0.1, \u03b13 = 0.02, \u03b14 = 0.01, \u03b21 = 0.001, \u03b22 = 0.0025, \u03b23 = 0.002, \u03b24 = 0.001, and \u03b3= 0.001.\n2 +0.000005y\nand, with the notations in Section 3, the \"adaptation\" value for m2\nThen Q(y) = 0.000002y\n0.00005\u22120.00008y\nis \u03b1 = 0.625 with the \"EC50 value\" K = Q(\u03b1/2) \u2248 0.07. The corresponding steady state value of\np2 is \u03b14 m2 /\u03b24 = 6.25. (Compare Figure 2 in [29].)\n\n7\n\nRemarks on integral feedback\n\nThe \"internal model principle\" (see e.g. [24]) states that, if a system perfectly adapts to all step\ninputs, then it may be re-written, possibly after performing a nonlinear change of coordinates, as a\nsystem in which an integral of the regulated quantity (response variable) is fed-back. A feedforward\n(not feedback) system that exhibits perfect adaptation might appear at first sight to be a counterexample to this fact. However, there is not necessarily a contradiction, as a change of coordinates\nmay allow one to transform a feedforward into a feedback system. This observation was made in [9],\nand we discuss it further here through an example.\nAs an illustration, consider the following two-dimensional linear system:\n\u1e8b = \u2212x + u\n\u1e8f = \u2212x \u2212 ay + u\n\n(16a)\n(16b)\n\n(where \"a\" is some positive constant). This system has the property, when the input u is constantly\nequal to a value u0 , that every solution converges to the state (u0 , 0) as t \u2192 \u221e. Thus, the response\nvariable y(t) converges to y0 = 0 no matter what is the actual value of u0 . The system response is\nperfectly adaptative.\nThe system (16) has a feedforward form. However, the same system can be recast as an integral\nfeedback system, as follows. Suppose that we choose to represent the system using the state variables\nz = x \u2212 y and y instead of x and y. In the new set of coordinates:\n\u017c = ay\n\u1e8f = \u2212z \u2212 (a + 1)y + u\n\n(17a)\n(17b)\n\nwhich can be viewed as a system in which the rate of change of the regulated quantity y depends\non y itself (proportional negative feedback) as well as on z, which is (up to a positive constant\nmultiple) the integral of y (integral feedback term).\n16\n\n\fNotice that, especially when seen as an integral feedback system, it is immediately obvious that\nfor every step input u \u2261 u0 (not merely nonzero steps), any steady state has the value y = 0,\nsince 0 = \u017c = ay at steady states. So, after a pulse, the system will eventually also converge\nto the adapted value (since we can see the behavior, after the end of the pulse, as the behavior\ncorresponding to a zero step). Thus, the memory effect discussed in this note will not occur for a\ntrue integral feedback system such as the linear system shown above. (Note that the system (16)\ndoes not have the exact form (2) studied in this paper, because of the additive, not multiplicative,\nterm \"\u2212ay\".)\nAs an example, the plot shown in Figure 7(b) shows the response to the pulse in Figure 7(a),\nfor system (16) with a = 0.1. Adaptation to y = 0 results in this case, which also happens with\nthe response in Figure 7(d) to the step input in Figure 7(c). (Scales for y have been normalized,\nso as to show relative changes. The response in (d) eventually settles back to zero, not shown.)\nNote that the adaptation to the pulse is faster than that for the step input. Interestingly, this\n\nFigure 5: Responses to a pulse and to a step input, for a linear feedforward system discussed in the\ntext. (a) Pulse input. (b) Response to the input in (a). (c) Step input. (d) Response to the input\nin (c).\nmodel reproduces qualitatively Figure 2 from [4]\u2217 , reproduced as Figure 7 in this paper. The figure\ncompares the changes in translocation of CRAC (cytosolic regulator of adenylyl cyclase), reported\nby relative fluorescence of a CRAC-GFP construct, in chemotactic Dictyostelium in response to a\n\"short\" (i.e., pulse) or a \"continuous\" (i.e., step) stimulus generated of cAMP.\nThe integral feedback form (17) is often said to be more \"robust\" for adaptation than the\nfeedforward form (16), because the steady-state response y is still zero even if the second equation\nis arbitrary modified: if \u017c = 0 and a 6= 0, one has that y = 0. In contrast, modifications in (16)\naffect the steady state value of y. This claim of robustness is very misleading, however, because\nperturbations of the first equation in (17) will generally change the steady state value of y.\nThe connection to the theory in [24] is somewhat subtle. It is shown there that, under appropriate\n\u2217\n\nThe author thanks Pablo Iglesias for pointing out this reference.\n\n17\n\n\fFigure 6: Reproduced (microscopy inset removed) with permission from Figure 2 in [4]. Responses\nto step and pulse cAMP input in Dictyostelium, as discussed in text. The response to the pulse\ninput settles faster than the response to the step.\n\ntechnical restrictions on the dynamics, even a nonlinear system that adapts to all step inputs can\nbe recast as an integral feedback system. The key is the assumption \"all inputs\" \u2013 the recasting\nmay fail to be global when inputs are restricted. Rather than explaining here the nonlinear theory,\na simple local (linearized) version is analyzed next as an illustration of these ideas.\nOnce again, take as an illustration the \"sniffer\" equations from [26] given in (3). For simplicity\nof notations (nothing much changes in the general case), take all kinetic constants equal to one:\n\u1e8b = \u2212x + u\n\u1e8f = \u2212yx + u .\nSuppose that one is only interested in studying the behavior of this system in the vicinity of the\nsteady state (x\u0304, \u0233) = (a, 1) and the step input u(t) \u2261 a for all t. For small changes in initial states\nand input values, the system is well-approximated by its linearization around these values, that is,\nthe system that is obtained when replacing the nonlinear term \"yx\" by\n(\u2202(yx)/\u2202x)x + (\u2202(yx)/\u2202y)y,\nwhere the partial derivatives are understood as evaluated at (x\u0304, \u0233). Since \u2202(yx)/\u2202x = \u0233 = 1 and\n\u2202(yx)/\u2202y = x\u0304 = a, we have that the linearized system is precisely the system (16). Thus, so long as\na 6= 0, the system can be recast (locally) as an integral feedback system. However, in the special case\nwhen a = 0, the recast system has the form \u017c = 0, \u1e8f = \u2212z \u2212 y + u. This system is not an integral\nfeedback system, since z no longer contains information about the integral of y. (Mathematically,\nthere is now a zero eigenvalue; thus, the system is no longer asymptotically stable, and hence no\nregulation property holds.)\n\n8\n\nDiscussion\n\nAdaptation is a feature often exhibited by biological systems, as discussed in the cited references.\nThis paper started from the well-known observation that certain types of feedforward circuits proposed in biological models have adaptation properties, and established rigorous mathematical results\nalong those lines.\n18\n\n\fPerhaps of more interest, it was shown that a \"memory\" effect is often displayed after pulses.\nThe magnitude of this effect is a nonlinear function of the magnitude of the pulse, and estimates\nwere given of its value.\nOne may speculate regarding what beneficial roles these memory effects of pulses might play.\nIn at least some of the examples, the calculations show that after a very high-amplitude pulse\nis turned-off, the response settles down to a close to \"relaxed\" steady state. In the context of a\ncomplex system, this response might be appropriate, for example, in a situation in which resources,\nused up while responding to a large external input, need to be replenished, and this is achieved by\nturning-off processes controlled by the feedforward circuit; in this way, a \"refractory period\" would\nbe established.\nOf course, the \"memory\" effect of pulses may or may not play a role in real systems, because\nparameter ranges may be such that the effect is negligible, or because sharp cutoffs of signals are\nrare in nature. It remains to see if feedforward circuits function in these regimes, in any real systems.\nFrom an experimental viewpoint, the results in this paper suggest that one might be able to use\nthe pulse-memory property as a way to experimentally distinguish true integral feedback systems\nfrom feedforward ones, through the testing of system responses against ideal pulses.\n\nAcknowledgments\nThe author wishes to thank Yuan Wang and Pablo Iglesias, as well as two anonymous reviewers,\nfor many useful comments on the manuscript. This research was supported in part by grants from\nAFOSR, NSF, and NIH, and was carried out in part while visiting the Laboratory for Information\nand Decision Systems at MIT.\n\nReferences\n[1] U. Alon. An Introduction to Systems Biology: Design Principles of Biological Circuits. Chapman & Hall, 2006.\n[2] B. Andrews, P. Iglesias, and E.D. Sontag. Signal detection and approximate adaptation implies\nan approximate internal model. In Proc. IEEE Conf. Decision and Control, San Diego, Dec.\n2006, pages 2364\u20132369. IEEE, 2006.\n[3] B. Andrews, E.D. Sontag, and P. Iglesias. An approximate internal model principle: Applications to nonlinear models of biological systems. In Proc. 17th IFAC World Congress, Seoul,\npages Paper FrB25.3, 6 pages, 2008.\n[4] Carsten Beta, Danica Wyatt, Wouter-Jan Rappel, and Eberhard Bodenschatz. Flow photolysis\nfor spatiotemporal stimulation of single cells. Analytical Chemistry, 79(10):3940\u20133944, 2007.\n[5] A. Cournac and J. A. Sepulchre. Simple molecular networks that respond optimally to timeperiodic stimulation. BMC Syst Biol, 3:29, 2009.\n[6] B.A. Francis and W.M. Wonham. The internal model principle for linear multivariable regulators. Appl. Math. Optim., 2:170\u2013194, 1975.\n19\n\n\f[7] J. S. A. Hepburn and W. M. Wonham. Error feedback and internal models on differentiable\nmanifolds. IEEE Trans. Automatic Control, 29:397\u2013403, 1984.\n[8] G. Hornung and N. Barkai. Noise propagation and signaling sensitivity in biological networks:\na role for positive feedback. PLoS Comput. Biol., 4:e8, Jan 2008.\n[9] P.A. Iglesias. Feedback control in intracellular signaling pathways: Regulating chemotaxis in\ndictyostelium discoideum. European J. Control., 9:216225, 2003.\n[10] D. Kim, Y. K. Kwon, and K. H. Cho. The biphasic behavior of incoherent feed-forward loops\nin biomolecular regulatory networks. Bioessays, 30:1204\u20131211, Nov 2008.\n[11] A. Kremling, K. Bettenbrock, and E. D. Gilles. A feed-forward loop guarantees robust behavior\nin escherichia coli carbohydrate uptake. Bioinformatics, 24:704\u2013710, 2008.\n[12] A. Levchenko and P.A. Iglesias. Models of eukaryotic gradient sensing: Application to chemotaxis of amoebae and neutrophils. Biophys J., 82:50\u201363, 2002.\n[13] A. Ma'ayan, S. L. Jenkins, S. Neves, A. Hasseldine, E. Grace, B. Dubin-Thaler, N. J. Eungdamrong, G. Weng, P. T. Ram, J. J. Rice, A. Kershenbaum, G. A. Stolovitzky, R. D. Blitzer,\nand R. Iyengar. Formation of regulatory patterns during signal propagation in a Mammalian\ncellular network. Science, 309:1078\u20131083, Aug 2005.\n[14] M. P. Mahaut-Smith, S. J. Ennion, M. G. Rolf, and R. J. Evans. ADP is not an agonist at\nP2X(1) receptors: evidence for separate receptors stimulated by ATP and ADP on human\nplatelets. Br. J. Pharmacol., 131:108\u2013114, Sep 2000.\n[15] S. Mangan, S. Itzkovitz, A. Zaslaver, and U. Alon. The incoherent feed-forward loop accelerates\nthe response-time of the gal system of Escherichia coli. J. Mol. Biol., 356:1073\u20131081, Mar 2006.\n[16] S. Marsigliante, M. G. Elia, B. Di Jeso, S. Greco, A. Muscella, and C. Storelli. Increase of\n[Ca(2+)](i) via activation of ATP receptors in PC-Cl3 rat thyroid cell line. Cell. Signal.,\n14:61\u201367, Jan 2002.\n[17] P. Men\u00e8, G. Pugliese, F. Pricci, U. Di Mario, G. A. Cinotti, and F. Pugliese. High glucose\nlevel inhibits capacitative Ca2+ influx in cultured rat mesangial cells by a protein kinase Cdependent mechanism. Diabetologia, 40:521\u2013527, May 1997.\n[18] T. Nagashima, H. Shimodaira, K. Ide, T. Nakakuki, Y. Tani, K. Takahashi, N. Yumoto, and\nM. Hatakeyama. Quantitative transcriptional control of ErbB receptor signaling undergoes\ngraded to biphasic response for cell differentiation. J. Biol. Chem., 282:4045\u20134056, Feb 2007.\n[19] R. Nesher and E. Cerasi. Modeling phasic insulin release: immediate and time-dependent\neffects of glucose. Diabetes, 51 Suppl 1:S53\u201359, Feb 2002.\n[20] L. A. Ridnour, A. N. Windhausen, J. S. Isenberg, N. Yeung, D. D. Thomas, M. P. Vitek,\nD. D. Roberts, and D. A. Wink. Nitric oxide regulates matrix metalloproteinase-9 activity\nby guanylyl-cyclase-dependent and -independent pathways. Proc. Natl. Acad. Sci. U.S.A.,\n104:16898\u201316903, Oct 2007.\n[21] S. Sasagawa, Y. Ozaki, K. Fujita, and S. Kuroda. Prediction and validation of the distinct\ndynamics of transient and sustained ERK activation. Nat. Cell Biol., 7:365\u2013373, Apr 2005.\n20\n\n\f[22] S. Semsey, S. Krishna, K. Sneppen, and S. Adhya. Signal integration in the galactose network\nof Escherichia coli. Mol. Microbiol., 65:465\u2013476, Jul 2007.\n[23] E.D. Sontag. Mathematical Control Theory. Deterministic Finite-Dimensional Systems, volume 6 of Texts in Applied Mathematics. Springer-Verlag, New York, second edition, 1998.\n[24] E.D. Sontag. Adaptation and regulation with signal detection implies internal model. Systems\nControl Lett., 50(2):119\u2013126, 2003.\n[25] J. Tsang, J. Zhu, and A. van Oudenaarden. MicroRNA-mediated feedback and feedforward\nloops are recurrent network motifs in mammals. Mol. Cell, 26:753\u2013767, Jun 2007.\n[26] J.J. Tyson, K. Chen, and B. Novak. Sniffers, buzzers, toggles, and blinkers: dynamics of\nregulatory and signaling pathways in the cell. Curr. Opin. Cell. Biol., 15:221\u2013231, 2003.\n[27] E. Voit, A. R. Neves, and H. Santos. The intricate side of systems biology. Proc. Natl. Acad.\nSci. U.S.A., 103:9452\u20139457, Jun 2006.\n[28] M. E. Wall, M. J. Dunlop, and W. S. Hlavacek. Multiple functions of a feed-forward-loop gene\ncircuit. J. Mol. Biol., 349:501\u2013514, Jun 2005.\n[29] F.-D. Xu, Z.-R. Liu, Z.-Y. Zhang, and J.-W. Shen. Robust and adaptive microRNA-mediated\nincoherent feedforward motifs. Chinese Physics Letters, 26(2):028701\u20133, February 2009.\n[30] L. Yang and P.A. Iglesias. Positive feedback may cause the biphasic response observed in the\nchemoattractant-induced response of dictyostelium cells. Systems Control Lett., 55(4):329\u2013337,\n2006.\n[31] T.-M. Yi, Y. Huang, M.I. Simon, and J. Doyle. Robust perfect adaptation in bacterial chemotaxis through integral feedback control. Proc. Natl. Acad. Sci. USA, 97:4649\u20134653, 2000.\n\n21\n\n\f"}