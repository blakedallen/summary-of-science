{"id": "http://arxiv.org/abs/0810.5751v1", "guidislink": true, "updated": "2008-10-31T18:11:22Z", "updated_parsed": [2008, 10, 31, 18, 11, 22, 4, 305, 0], "published": "2008-10-31T18:11:22Z", "published_parsed": [2008, 10, 31, 18, 11, 22, 4, 305, 0], "title": "Radio Interferometric Calibration Using The SAGE Algorithm", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0810.0624%2C0810.4342%2C0810.5699%2C0810.1083%2C0810.3758%2C0810.4563%2C0810.5240%2C0810.1037%2C0810.2471%2C0810.1778%2C0810.3790%2C0810.2914%2C0810.4429%2C0810.4854%2C0810.5474%2C0810.1135%2C0810.1777%2C0810.4867%2C0810.1036%2C0810.1824%2C0810.0116%2C0810.3556%2C0810.2887%2C0810.3266%2C0810.0123%2C0810.1441%2C0810.4364%2C0810.2054%2C0810.4047%2C0810.0838%2C0810.5294%2C0810.2253%2C0810.0173%2C0810.0434%2C0810.4809%2C0810.1124%2C0810.0053%2C0810.5375%2C0810.1494%2C0810.3785%2C0810.0846%2C0810.0197%2C0810.2508%2C0810.1014%2C0810.0552%2C0810.5035%2C0810.4663%2C0810.2297%2C0810.1947%2C0810.0860%2C0810.3530%2C0810.2413%2C0810.5264%2C0810.4268%2C0810.1154%2C0810.5701%2C0810.2906%2C0810.4787%2C0810.5192%2C0810.2205%2C0810.2363%2C0810.3378%2C0810.0626%2C0810.3409%2C0810.1538%2C0810.5573%2C0810.2246%2C0810.0591%2C0810.0344%2C0810.4467%2C0810.0967%2C0810.0230%2C0810.4153%2C0810.4775%2C0810.1226%2C0810.0167%2C0810.5134%2C0810.1130%2C0810.2380%2C0810.4664%2C0810.1991%2C0810.2774%2C0810.0768%2C0810.0410%2C0810.5460%2C0810.1133%2C0810.2680%2C0810.2463%2C0810.3251%2C0810.0145%2C0810.4328%2C0810.0538%2C0810.1091%2C0810.4560%2C0810.5751%2C0810.5043%2C0810.2835%2C0810.3260%2C0810.0730%2C0810.5667%2C0810.2531&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Radio Interferometric Calibration Using The SAGE Algorithm"}, "summary": "Radio Interferometry is an essential method for astronomical observations.\nSelf-calibration techniques have increased the quality of the radio\nastronomical observations (and hence the science) by orders of magnitude.\nRecently, there is a drive towards sensor arrays built using inexpensive\nhardware and distributed over a wide area acting as radio interferometers.\nCalibration of such arrays poses new problems in terms of computational cost as\nwell as in performance of existing calibration algorithms. We consider the\napplication of the Space Alternating Generalized Expectation Maximization\n(SAGE) \\cite{Fess94} algorithm for calibration of radio interferometric arrays.\nApplication to real data shows that this is an improvement over existing\ncalibration algorithms that are based on direct, deterministic non linear\noptimization. As presented in this paper, we can improve the computational cost\nas well as the quality of the calibration using this algorithm.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0810.0624%2C0810.4342%2C0810.5699%2C0810.1083%2C0810.3758%2C0810.4563%2C0810.5240%2C0810.1037%2C0810.2471%2C0810.1778%2C0810.3790%2C0810.2914%2C0810.4429%2C0810.4854%2C0810.5474%2C0810.1135%2C0810.1777%2C0810.4867%2C0810.1036%2C0810.1824%2C0810.0116%2C0810.3556%2C0810.2887%2C0810.3266%2C0810.0123%2C0810.1441%2C0810.4364%2C0810.2054%2C0810.4047%2C0810.0838%2C0810.5294%2C0810.2253%2C0810.0173%2C0810.0434%2C0810.4809%2C0810.1124%2C0810.0053%2C0810.5375%2C0810.1494%2C0810.3785%2C0810.0846%2C0810.0197%2C0810.2508%2C0810.1014%2C0810.0552%2C0810.5035%2C0810.4663%2C0810.2297%2C0810.1947%2C0810.0860%2C0810.3530%2C0810.2413%2C0810.5264%2C0810.4268%2C0810.1154%2C0810.5701%2C0810.2906%2C0810.4787%2C0810.5192%2C0810.2205%2C0810.2363%2C0810.3378%2C0810.0626%2C0810.3409%2C0810.1538%2C0810.5573%2C0810.2246%2C0810.0591%2C0810.0344%2C0810.4467%2C0810.0967%2C0810.0230%2C0810.4153%2C0810.4775%2C0810.1226%2C0810.0167%2C0810.5134%2C0810.1130%2C0810.2380%2C0810.4664%2C0810.1991%2C0810.2774%2C0810.0768%2C0810.0410%2C0810.5460%2C0810.1133%2C0810.2680%2C0810.2463%2C0810.3251%2C0810.0145%2C0810.4328%2C0810.0538%2C0810.1091%2C0810.4560%2C0810.5751%2C0810.5043%2C0810.2835%2C0810.3260%2C0810.0730%2C0810.5667%2C0810.2531&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Radio Interferometry is an essential method for astronomical observations.\nSelf-calibration techniques have increased the quality of the radio\nastronomical observations (and hence the science) by orders of magnitude.\nRecently, there is a drive towards sensor arrays built using inexpensive\nhardware and distributed over a wide area acting as radio interferometers.\nCalibration of such arrays poses new problems in terms of computational cost as\nwell as in performance of existing calibration algorithms. We consider the\napplication of the Space Alternating Generalized Expectation Maximization\n(SAGE) \\cite{Fess94} algorithm for calibration of radio interferometric arrays.\nApplication to real data shows that this is an improvement over existing\ncalibration algorithms that are based on direct, deterministic non linear\noptimization. As presented in this paper, we can improve the computational cost\nas well as the quality of the calibration using this algorithm."}, "authors": ["Sarod Yatawatta", "Saleem Zaroubi", "Ger de Bruyn", "Leon Koopmans", "Jan Noordam"], "author_detail": {"name": "Jan Noordam"}, "author": "Jan Noordam", "arxiv_comment": "6 pages, 3 figures, Appearing in 13th IEEE DSP workshop (IEEE Signal\n  Processing Society)", "links": [{"href": "http://arxiv.org/abs/0810.5751v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0810.5751v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "astro-ph", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "astro-ph", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0810.5751v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0810.5751v1", "journal_reference": null, "doi": null, "fulltext": "Radio Interferometric Calibration Using The SAGE\nAlgorithm\n\narXiv:0810.5751v1 [astro-ph] 31 Oct 2008\n\nSarod Yatawatta1,2,3, Saleem Zaroubi1, Ger de Bruyn1,2 , Leon Koopmans1 and Jan Noordam2\n\nAbstract- Radio Interferometry is an essential method\nfor astronomical observations. Self-calibration techniques have\nincreased the quality of the radio astronomical observations (and\nhence the science) by orders of magnitude. Recently, there is a\ndrive towards sensor arrays built using inexpensive hardware\nand distributed over a wide area acting as radio interferometers.\nCalibration of such arrays poses new problems in terms of computational cost as well as in performance of existing calibration\nalgorithms. We consider the application of the Space Alternating\nGeneralized Expectation Maximization (SAGE) [1] algorithm for\ncalibration of radio interferometric arrays. Application to real\ndata shows that this is an improvement over existing calibration\nalgorithms that are based on direct, deterministic non linear\noptimization. As presented in this paper, we can improve the\ncomputational cost as well as the quality of the calibration using\nthis algorithm.\n\nI. I NTRODUCTION\nRadio synthesis arrays have greatly benefited by self calibration techniques invented during the last 30 years. Calibration\nrefers to estimation of errors introduced by the instrument\n(and also the propagation path, such as the ionosphere),\nand correction for such errors, before any imaging is done.\nAt the beginning of radio astronomy, calibration was done\nby observing a known celestial object (called the external\ncalibrator), in addition to the part of the sky being observed.\nThis was improved by self-calibration, which is essentially\nusing the observed sky itself for the calibration. Therefore,\nself calibration entail considering both the sky as well as the\ninstrument as unknowns. Nevertheless, by iteratively refining\nthe sky and the instrument model, the quality of the calibration\nwas improved by orders of magnitude in comparison to using\nan external calibrator.\nFrom a signal processing perspective, calibration is essentially the Maximum Likelihood (ML) estimation of the\ninstrument and sky parameters using a non linear optimization\ntechnique such as the Levenberg Marquardt [2],[3] (LM) algorithm. An in depth overview of existing calibration techniques\nare given in [4],[5]. However, with such techniques, we have\nreached a limit in sensitivity that can be achieved using present\nradio interferometers. This is because the achievable sensitivity\nis limited by the receiver collecting area itself. Moreover, with\nfinite computational cost, there is a bound in the performance\nof existing algorithms. Therefore, there is a drive towards\n1 Kapteyn Astronomical Institute, University of Groningen, Groningen, The\nNetherlands\n2 ASTRON, Dwingeloo, The Netherlands\n3 yatawatta@astron.nl\nAppearing in 13th IEEE DSP Workshop, Marco Island, FL, Jan. 2009.\n\nbuilding large, distributed, sensor arrays (SKA[6], LOFAR\n[7]) that increase the collecting area and hence the sensitivity,\nenabling new scientific research. However, this also increases\nthe parameter space that needs to be calibrated and hence, the\nrequired computational cost. A detailed analysis of calibration\nof LOFAR, which can be considered as a pathfinder for the\nnext generation interferometric arrays, can be found in [15].\nAlthough in [15], limitations (such as the Cramer Rao bound)\nof existing calibration techniques are defined, there is little\nwork existing on improving the computational cost or the\nspeed of convergence of such techniques.\nThis paper describes the application of the Expectation\nMaximization [8] (EM) algorithm for radio interferometric\ncalibration. The EM algorithm was first presented as a solution\nto maximum likelihood estimation when the complete data\nis not observed. Since then, EM type algorithms have been\nwidely used as an iterative method for ML estimation, with\neither faster convergence or reduced computational cost. The\nessential property of the EM algorithm is that the likelihood\ncan only increase in each iteration. The SAGE algorithm\nwas presented to improve the plain EM algorithm in terms\nof speed of convergence and has been successfully applied\nin diverse signal processing applications, such as medical\nimaging [9], communications systems [10], etc. In contrast to\n[15], in this paper we focus on finding algorithms that improve\nthe computational cost and quality of calibration. Naturally,\nin order to improve the performance of the ML estimation,\nwe choose the EM algorithm, and in particular the SAGE\nalgorithm. Therein lies the novelty of this paper.\nNotation: Lower case bold letters refer to column vectors\n(e.g. y). Upper case bold letters refer to matrices (e.g. C).\nUnless otherwise stated, all parameters are complex numbers.\nThe matrix inverse, transpose, Hermitian transpose, and conjugation are referred to as (.)\u22121 , (.)T , (.)H , (.)\u22c6 , respectively.\nThe matrix Kronecker product is given by \u2297. The statistical\nexpectation operator is given as E{.}. The vectorized representation of a matrix is given by vec(.). The diagonal matrix\nconsisting of only the diagonal entries of a square matrix\nis given by diag(.). The identity matrix is given by I. The\nKronecker delta function is given by \u03b4ij . Real and complex\nnumbers are represented as R and C, respectively. Estimated\nc All logarithms are to the\nparameters are denoted by a hat, (.).\nbase e.\nII. DATA M ODEL\nWe briefly describe the data model of the radio interferometer in this section. For more information about radio\n\n\finterferometry, the reader is referred to [11] and for the\ndata model in particular, [12],[13]. A more signal processing\noriented description is given in [4],[15].\nWe consider the radio frequency sky to be composed of\ndiscrete sources, far away from the earth such that the approaching radiation from each one of them appears to be plane\nwaves. Let the plane wave from the i-th source be decomposed\nto two orthogonal polarization directions ui = [uxi uyi ]T .\nThe interferometric array consists of N receiving elements or\nstations. At the p-th station, this plane wave causes an induced\nvoltage, which is dependent on the beam attenuation as well\nas the radio frequency receiver chain attenuation. Normally,\neach station has dual polarized feeds. So the induced voltages\nat the x and y feeds, \u1e7dpi = [vxpi vypi ]T due to source i are\ngiven as in (1).\n\u1e7dpi = Jpi ui\n(1)\nIn (1), the complex interaction of the approaching radiation\nwith the station beam shape as well as the remaining signal\npath is represented by the 2 by 2 Jones matrix Jpi . If there\nare K such sources, the total signal will be a superposition of\nK such signals as in (1). Moreover, the receiver noise \u03bd =\n[\u03bdx \u03bdy ]T is also added to this signal.\nThe signal of the p-th station is correlated with the signals\nof the other N \u2212 1 receivers at the correlator. Before this is\ndone, each signal is given a delay correction depending on the\ndirection on the sky being observed and also depending on the\nabsolute position of the receiver on the earth.\nAfter correlation, the correlated signal of the p-th station\nand the q-th station (named as the visibilities [12]), Vpq =\nE{vp vqH } is given by (2).\nVpq =\n\nK\nX\n\nJpi (\u03b8)Ci JH\nqi (\u03b8) + N, p, q \u2208 [1, . . . , N ]\n\n(2)\n\ni=1\n\nThis is the full matrix measurement equation, developed\nin [12]. In (2), Jpi (\u03b8) and Jqi (\u03b8) are the Jones matrices\ndescribing the electromagnetic and electronic interaction of the\nplane wave of source i with stations p and q, respectively. The\nparameter vector \u03b8 \u2208 CP describes the unknown instrument\nmodel. The 2 by 2 noise matrix is given as N. We can only\narrive at (2) because the radiation emitted by the sources in\nthe sky are uncorrelated. The coherency [12], Ci describes the\nintrinsic polarized radiation of the i-th source.\nThe instrumental properties (such as the beamshape, low\nnoise amplifier gain, system frequency response etc.) and\nthe path properties (such as tropospheric and ionospheric\ndistortion etc.) are described by the Jones matrices Jpi (\u03b8) and\nJqi (\u03b8) in (2). Calibration is essentially finding the parameters\n\u03b8 (P complex valued parameters or 2P real values parameters). There are numerous ways to parametrize these unknowns\nusing the parameter set \u03b8. For a more specialized treatment\nof the parametrization as well as factoring the Jones matrices,\nthe reader is referred to [14].\nTo a lesser extent, the source information Ci is also\nunknown. However, at the initial stage, we can use prior\n\ninformation about the source or sky properties obtained by\nprevious observations.\nNote that in (2), the noise matrix N = 0 for p 6= q if the\nnoise at each receiver is uncorrelated. However in practice this\ndoes not hold for the following reasons:\n\u2022 The integration time at the correlator has to be finite in\norder not to decorrelate the signal from the sources (or the\nsky). Hence there is always some receiver noise appearing\neven in the cross correlations, p 6= q.\n\u2022 The assumption that the sky is composed of a set of\ndiscrete sources is valid only up to a certain intensity\nlevel. There is low level diffused radiation from the sky,\nwhich appear especially in short baseline visibilities.\n\u2022 We select only K brightest sources in our data model.\nHowever, the multitude of fainter sources that are ignored\nin (2) contribute to the noise.\nThe vectorized form of (2), vpq = vec(Vpq ) can be written\nas in (3) where npq = vec(N).\nvpq =\n\nK\nX\n\nJ\u22c6qi (\u03b8) \u2297 Jpi (\u03b8)vec(Ci ) + npq\n\n(3)\n\ni=1\n\nIgnoring the autocorrelations where p = q, stacking up all\nT\nT\nT\nT\ncross correlations as y = [v12\nv13\n. . . . . . v(N\n\u22121)N ] , y \u2208\nM\nC , we get (4).\nK\nX\nsi (\u03b8) + n\n(4)\ny=\ni=1\n\nThe size of y, M , in (4) is at most 2N (N \u2212 1) provided all\ncross correlations are used. Typically, the number of parameters in \u03b8, P , is proportional to KN . So for large enough N and\nsmall enough K, we have enough constraints to estimate \u03b8.\nThe non-linear functions si (\u03b8) correspond to the contribution\nof each source to the observation. In previous formulations\nof the same problem, [15],[16], the noise n has been ignored\nbecause only the cross correlations are used. However, we\nstress that in our formulation, we consider n to be a Gaussian\nrandom variable with zero mean and covariance \u03a0 (M \u00d7 M\nmatrix), i.e., n \u223c N (0, \u03a0).\nNote that (4) is a superposition of K non linear signals, with\nunknown parameters, which is exactly the problem considered\nin [17]. The present calibration schemes estimate \u03b8 as the\nleast squared error estimate, typically using a gradient based\noptimization algorithm like LM algorithm.\nb = arg minky \u2212\n\u03b8\n\u03b8\n\nK\nX\n\nsi (\u03b8)k2\n\n(5)\n\ni=1\n\nIf the cost function is \u03c6(\u03b8) = ky \u2212\niteration, we estimate\n\nPK\n\ni=1 si (\u03b8)k\n\n2\n\n, at the k-th\n\n\u03b8k+1 = \u03b8k \u2212 (\u2207\u03b8 \u2207T\u03b8 \u03c6(\u03b8) + \u03bbH)\u22121 \u2207\u03b8 \u03c6(\u03b8)|\u03b8k\n\n(6)\n\nIn (6), \u2207\u03b8 is the gradient with respect to \u03b8 and \u03bb is a\nregularization parameter. The matrix H = diag(\u2207\u03b8 \u2207T\u03b8 \u03c6(\u03b8))\nis the diagonal of the Hessian matrix. Given suitable initial\nvalues, (6) should converge to the global optimum. However,\n\n\f(6) suffers from the same set of problems faced with any\nnon linear optimization problem, i.e., convergence to local\nminima, slow convergence and heavy computational cost. In\nthe next section we shall investigate the application of the EM\nalgorithm to overcome some of these problems.\nIII. T HE EM\n\nAND\n\nSAGE A LGORITHMS\n\nB. SAGE Algorithm\nNext, we investigate the application of the SAGE algorithm\nto our problem. As before we need to find a complete data\nspace (or a hidden data space as defined in [1]). Similar to\n[1], we select the hidden data space xS as in (12).\nxS = si (\u03b8 i ) + n\n\nIn this section, we first proceed to apply the EM algorithm\nto (4), in a similar way as done in [17]. We do this before\napplying the SAGE algorithm to clarify the presentation.\n\nThis gives the observed data y as in (13).\ny = xS +\n\nA. EM Algorithm\n\nx\u0303i = si (\u03b8 i ) + \u00f1i\n\n(7)\n\nNote that in (7), we have assumed the contribution of the\ni-th source depends only on a subset of parameters \u03b8 i , not\nthe full set of parameters \u03b8. In other words, we partition the\nparameter space to K components as \u03b8 = [\u03b8T1 \u03b8T2 . . . \u03b8TK ]T .\nThis is justified because each source is at a unique direction\non the sky. Even though the signal path for a given station\nis common for all sources, the different directions and the\nrotation of the sky makes this assumption justifiable. The noise\ncontribution \u00f1i is such that the total noise is decomposed into\nK noise sources.\nK\nX\n\nK\nX\n\nsl (\u03b8 l )\n\n(13)\n\nl=1,l6=i\n\nThe key step in applying the EM algorithm is to define a\ncomplete data set x from the observed data y. The obvious\nchoice would be to associate each source with a complete data\nspace x\u0303 = [x\u0303T1 x\u0303t2 . . . x\u0303TK ]T , with each component as in (7),\nP\nsuch that y = K\ni=1 x\u0303i .\n\nn=\n\n(12)\n\n\u00f1i , E{\u00f1i \u00f1H\nj } = \u03b2i \u03b4ij \u03a0,\n\nK\nX\n\n\u03b2i = 1\n\n(8)\n\ni=1\n\ni=1\n\ny = [I I . . . I]x = Gx\n\n(9)\n\nHaving this setup, it is rather straightforward to apply the\nEM algorithm to our problem as in [17].\nb\u0303i = E{x\u0303i |y, \u03b8 k }.\nE Step: We find the conditional mean of x\nTaking into account that y and x are jointly Gaussian, we get\nK\nX\n\nsl (\u03b8 kl ))\n\n(10)\n\nl=1\n\nM Step: For the k + 1-th iteration, we find \u03b8k+1\nthat\ni\nb\u0303i \u2212 si (\u03b8k+1 )k2 , given by:\nminimizes the cost \u03c6i (\u03b8 k+1\n)\n=\nk\nx\ni\ni\n\n\u03b8k+1\n= \u03b8 ki \u2212(\u2207\u03b8 i \u2207T\u03b8 \u03c6i (\u03b8 i )+\u03bbHi )\u22121 \u2207\u03b8 i \u03c6i (\u03b8 i )|\u03b8 k (11)\ni\ni\n\ni\n\nT\n\ncS = si (\u03b8 k ) + (y \u2212\nx\ni\n\nK\nX\n\nsl (\u03b8 kl )) = y \u2212\n\nl=1\n\nK\nX\n\nsl (\u03b8 kl ) (14)\n\nl=1,l6=i\n\nSAGE M Step: For the k+1-th iteration, \u03b8k+1\nthat minimizes\ni\ncS \u2212 si (\u03b8k+1 )k2 . This is similar to\nthe cost \u03c6S (\u03b8 k+1\n)\n=\nk\nx\ni\ni\n(11). As before, we iterate from k = 1 to an upper limit. At\neach iteration, we change the index set S to update all or some\nsources.\nNote that instead of partitioning per source, we could also\nperform the partitioning to include more than one source. This\nwould be better if some sources are closer in the sky and hence\nshare some parameters.\nC. Computational Cost\n\nThe \u03b2i s form an affine combination and we are free to\nchoose them. Typically, we can associate stronger sources with\nlower noise, hence low \u03b2i . Given the complete data x, we get\nthe observed data as in (9) where G is a block matrix with\nK identity matrices.\n\nx\u0303bi = si (\u03b8 ki ) + \u03b2i (y \u2212\n\nNote that in (12) and (13), we have selected the index set [1],\nS to be the i-th source. Moreover, we have associated all the\nnoise to xS , unlike in the classic EM algorithm. Once again,\nwe arrive at the following EM scheme:\nSAGE E Step: We find the conditional mean of xS =\nE{xS |y, \u03b8 k }.\n\nwhere Hi = diag(\u2207\u03b8 i \u2207\u03b8 \u03c6i (\u03b8 i )). We repeat the above two\ni\nsteps starting from iteration k = 1 until convergence or an\nupper limit has reached. At each iteration, we update each\nsource, so i goes from 1 to K.\n\nThe computational cost of direct estimation using (6) and\nthe EM algorithmic approach can be compared as follows.\nSolving (6) (without calculating the inverse) involves the\nsolution of a linear system of order KN . So the computational\ncost of the direct approach is O((KN )2 ). On the other hand,\nthe computational cost of solving (11), K times, is KO(N 2 ).\nThus, we gain a factor K by using the EM algorithm.\nFurthermore, we can increase this gain if the convergence of\nthe EM approach is faster (fewer iterations).\nD. Comparison With \"Peeling\"\nAs described in [15] in detail, Peeling is the conversion\nof the K source model in (4) to a series of single source\ncalibration problems, exploiting the temporal diversity due to\nthe rotation of the earth. The steps taken in Peeling can be\nbriefly given as follows:\n\u2022 Out of sources, i \u2208 [1, K], select the strongest source\n(say i = q).\n\u2022 Optionally, subtract the contributions of the remaining\nsources from (4), using an approximate a priori instrument model.\n\u2022 Multiply (4) by a diagonal matrix F such that the q-th\nsource is at the phase center. The matrix F is computed\n\n\fIV. S TATISTICAL M ODEL O RDER S ELECTION\nSo far in our analysis, we have assumed the number of\nsources, K, in (2), is known a priori. To some extent, this\nis true, given prior observational data and receiver noise\ncharacteristics. It is straightforward to find K sources that\nhas sufficient SNR given the aforementioned information.\nHowever, in situations where the receiver antenna beamshape\nvaries with time due to earth rotation (as in LOFAR), this\nis hard to predict (e.g. some sources might go close to, or,\neven below, the horizon). In this situation without a priori\nknowledge, we could use information theoretic criteria to find\nthe optimal K for a given observation. In this section, we\ndescribe the use of Akaike's Information Criterion (AIC) [18]\nfor this purpose. There are also alternative criteria, see for\ninstance [19] for more information.\nFrom (4), the likelihood of y is given by (15).\n1\n\u03c0 M |\u03a0|\n\nexp(\u2212(y\u2212\n\nsi (\u03b8))H \u03a0\u22121 (y\u2212\n\ni=1\n\nK\nX\n\nV. N UMERICAL E XAMPLE\nWe consider the calibration of some data obtained by the\nLOFAR test core station (CS1). This has N = 16 dipoles (with\ndual polarization) acting as an interferometric array. Since each\nstation is a single dipole, there is no beamforming and thus\nthe whole sky (hemisphere) is observed. In this setting, the\ntwo brightest sources are Cassiopeia A (CasA) and Cygnus A\n(CygA), with intensities about 20000 Jy each at 50 MHz. The\nobservation lasts for 24 hours. The correlator integration time\nis 30 sec. During the observation, the positions of the sources\n(azimuth and elevation) vary as shown on Fig. (1).\nSince both CasA and CygA are equally bright, traditional\nalgorithms such as peeling [15] will not work satisfactorily, as\ndescribed in section III-D. So we have a model with K = 2\nin (4). Note that as seen on Fig. (1), CygA goes very close\nto the horizon at one point. Around this time, the contribution\nfrom CygA is almost negligible due to the attenuation by the\ndipole beam. So, instead of using K = 2, we should be using\nK = 1. However, in this example, we only consider the data\nwhere both CasA and CygA are high in elevation (about 18\nhours). Future work will address using e.g., (19) to determine\nthis.\n200\nCasA\nCygA\n\n100\n0\n\u2212100\n\u2212200\n0\n\nsi (\u03b8)))\n\n5\n\n10\n\n15\n\n20\n\n25\n\n100\nCasA\nCygA\n\n80\n\n(15)\nAssuming the noise to be white, \u03a0 = \u03c3 2 I, we get the\nsimplified log-likelihood L(\u03b8) as in (16).\n(16)\n\n60\n40\n20\n0\n0\n\n5\n\n10\n\n15\n\n20\n\n25\n\nTime/hr\n\nFig. 1. The positions of CasA and CygA on the sky in azimuth and elevation,\nfor a geographic latitude of 53o .\n\nThe maximum likelihood estimate for the noise variance \u03c3 2\n(given \u03b8) is given by (17).\nK\nK\nX\nX\nc2 = 1 (y \u2212\nb\nb H (y \u2212\nsi (\u03b8))\nsi (\u03b8))\n\u03c3\nM\ni=1\ni=1\n\n(19)\n\nTime/hr\n\ni=1\n\nL(\u03b8) = log f (y|\u03b8)\n= \u2212M log \u03c0 \u2212 M log \u03c3 2\nK\nK\nX\nX\n1\n\u2212 2 (y \u2212\nsi (\u03b8))\nsi (\u03b8))H (y \u2212\n\u03c3\ni=1\ni=1\n\nb + 2(2P )\nAIC(K) = \u22122L(\u03b8)\n\nElevation/deg\n\nf (y|\u03b8) =\n\nK\nX\n\nUsing (18), we get the Akaike's Information Criterion as\n(19). We select K that gives the minimum value for (19).\n\nAzimuth/deg\n\nfor given time and the absolute position of the q-th source\nin the sky.\n\u2022 Provided that the remaining sources are weak enough,\nover a finite time interval, the contribution of those\nsources in (4) are averaged out, while the contribution\nof the q-th source remains constant.\n\u2022 Ignore the contribution from the other sources i \u2208\n[1, K], i 6= q in (4) and solve for the parameters of the\nq-th source. Subtract this from (4). Now, we have K \u2212 1\nsources left and we repeat the whole procedure.\nAs seen from above, the application of the proposed algorithm does not rely on the weaker sources being averaged\nout. Moreover, the proposed algorithm does not require an\na priori instrument model. When we have equally strong\nsources, Peeling might not work satisfactorily compared to\nthe proposed algorithm.\n\n(17)\n\nUsing (17) in (16), we arrive at (18).\n\nb = \u2212M log \u03c0 \u2212 M\nL(\u03b8)\n(18)\nK\nK\nX\nX\n\u0001\n1\nb\nb H (y \u2212\nsi (\u03b8))\n\u2212M log\nsi (\u03b8))\n(y \u2212\nM\ni=1\ni=1\n\nThe parametrization of the Jones matrices are done as\nfollows: We consider each entry of the 2 by 2 matrix to be a\nparameter. For K = 2 and N = 16, there are 2 \u00d7 16 \u00d7 4 = 128\nparameters.\n\u0014\n\u0015\nJp11i Jp12i\nJp (\u03b8i ) =\n,\nJp21i Jp22i\n\u03b8 i = [vec(Jp (\u03b8 i ))T , . . . , ]T \u2200p \u2208 [1 . . . , N ]\n\n(20)\n\nThe Jones matrices are initialized such that the diagonal entries\neach have a (real) value 0.0001 and the off diagonal entries\nto be zero.\n\n\fWe consider the estimation of the parameters using (5)\n(Normal Algorithm) and using the SAGE algorithm. For\nthe normal algorithm, we use 12 and 24 LM iterations to\nestimate 128 parameters using (5). For the SAGE algorithm,\nwe alternate between estimating parameters for CasA and\nCygA. In each iteration, we use 3 LM iterations for the M\nstep (11). We use 4 EM iterations, keeping the number of LM\niterations at 12. Yet, the SAGE algorithm is computationally\nless expensive than the normal algorithm with 12 iterations as\nnoted in section III-C.\nOnce we\n\u03b8, we make images of the residual,\nP have estimated\nb We also correct the residual using the\ni.e. y \u2212 K\ns\n(\n\u03b8).\ni\ni=1\nestimated \u03b8 [20]. We have given the images made by the\nnormal algorithm and the SAGE algorithm on Fig. 2. These\nimages show an area around CasA and CygA, respectively.\nPerfect subtraction should leave no residual from both these\nsources. However, we see that there is about 1% (of the\noriginal value) peak residual left by using the normal algorithm\nwith 12 iterations. On the other hand, the SAGE algorithm and\nthe normal algorithm with 24 iterations reduce this residual to\n0.1% level. Moreover, fainter, known sources can also be seen\non both images. Closer scrutiny reveals that the remaining\nsources are fainter in the results obtained using the SAGE\nalgorithm. This is due to over subtraction of the fluxes of the\nremaining sources and in fact, we could reduce the number\nof SAGE iterations, to overcome this effect. Future work will\naddress determining the correct number of iterations to avoid\nover subtraction.\nIn order to have a quantitative handle on the results, we\nhave also calculated the root mean square (rms) value of the\nresidual on these images. For an image with L1 \u00d7 L2 pixels,\nthe rms value, \u03b7 can be defined as in (21). In (21), the value\nat pixel i, j is given by zij .\nv\nu\nL1 X\nL2\nu 1 X\n(21)\nz2\n\u03b7=t\nL1 L2 i=1 j=1 ij\nWe have evaluated (21) on images centered around CasA\nand CygA, with 64 by 64 pixels in size, for about 30 different\nfrequencies around 50 MHz. The results can be seen on Fig.\n3 for both CasA and CygA. It is clearly seen that for the same\nnumber of iterations, the SAGE algorithm performs better. The\nnormal algorithm needs about more iterations to have the same\nperformance as the SAGE algorithm.\nVI. C ONCLUSIONS\nWe have presented the application of the SAGE algorithm\nfor calibration of radio interferometric arrays. This is an improvement over the generally used direct optimization methods\nin performance as well as in computing cost, as seen from\nthe results. We have only given some initial results of using\nthe SAGE algorithm on real data. One of the fundamental\nassumptions made in this paper was that the noise is white\nand Gaussian. Future work will address exact characterization\nof the noise and adaptation of the SAGE algorithm especially\n\nwhen the noise is non Gaussian. Moreover, future work will\naddress situations where we have more than 2 strong sources.\nVII. ACKNOWLEDGMENT\nThe first author would like to thank ASTRON for kind\nhospitality and NOVA for support. This work was also\nsupported by LOFAR and SNN. LOFAR is being funded\nby the European Union, European Regional Development\nFund, and by \"Samenwerkingsverband Noord-Nederland\",\nEZ/KOMPAS. We acknowledge Ronald Nijboer for reviewing\nan earlier version of this paper.\nR EFERENCES\n[1] J.A. Fessler and A.O. Hero, \"Space alternating generalized expectation\nmaximization algorithm,\" IEEE Trans. on Sig. Proc., vol. 42, no. 10, pp.\n2664-2677, Oct. 1994.\n[2] K. Levenberg, \"A method for the solution of certain non linear problems\nusing least squares,\" The Quarterly Jnl. of App. Math., vol. 2, pp. 164168, 1944.\n[3] D. Marquardt, \"An algorithm for least squares estimation of nonlinear\nparameters,\" SIAM Jnl. of App. Math., vol. 11, pp. 431-441, 1963.\n[4] A.J. Boonstra and A.J. ven der Veen, \"Gain calibration methods for radio\ntelescope arrays,\" IEEE Trans. on Sig. Proc., vol. 51, no. 1, pp. 25-38,\nJan. 2003.\n[5] A.J. van der Veen, A. Leshem, and A.J. Boonstra, \"Array signal\nprocessing for radio astronomy,\" Experimental Astronomy, vol. 17, no.\n1-3, pp. 231-249, Jun. 2004.\n[6] http://www.skatelescope.org/\n[7] http://www.lofar.org/\n[8] A.P. Dempster, N.M. Laird, and D.B. Rubin, \"Maximum likelihood from\nincomplete data via the EM algorithm,\" Jnl. Royal Stat. Soc. Series B,\nvol. 39, no. 1, pp. 1-38, 1977.\n[9] M. Krzywinski, V. Sossi, and T.J. Ruth, \"Comparison of FORE, OSEM\nand SAGE algorithms to 3DRP in 3D PET using phantom and human\nsubject data,\" IEEE Trans. on Nuclear Science, vol. 45, no. 4-2, pp.\n1114-1120, Aug. 1999.\n[10] A. Logothetis and C. Carelmalm, \"SAGE algorithms for multipath\ndetection and parameter estimation in asynchronous CDMA systems,\"\nIEEE Trans. on Sig. Proc, vol. 48, no. 11, pp. 3162-3174, Nov. 2000.\n[11] A.R. Thompson, J.M. Moran and G.W. Swenson Jr., \"Interferometry\nand synthesis in radio astronomy, 2nd ed.\" John Wiley and Sons, New\nYork 1998.\n[12] J.P. Hamaker, J.D. Bregman and R.J. Sault, \"Understanding radio\npolarimetry, paper I,\" Astronomy and Astrophysics Supp., vol. 117, no.\n137, pp. 96-109, Jan. 1996.\n[13] J.P. Hamaker, \"Understanding radio polarimetry, paper V,\" Astronomy\nand Astrophysics Supp., vol. 456, pp. 395-404, Jan. 2006.\n[14] J. Noordam, \"The measurement equation of a generic radio telescope,\nAIPS++ implementation note 185,\" ASTRON, Tech. Report, 1996\n[15] S. van der Tol, B. Jeffs, and A.J. van der Veen, \"Self calibration for the\nLOFAR radio astronomical array,\" IEEE Trans. Sig. Proc., vol. 55, no.\n9, pp. 4497-4510, Sep. 2007.\n[16] B. Jeffs, S. van der Tol, and A.J. van der Veen, \"Direction dependent\nself calibration of large distributed sensor arrays,\" in Proc. IEEE ICASSP\npp. 1069-1072, 2006\n[17] M. Feder and E. Weinstein, \"Parameter estimation of superimposed\nsignals using the EM algorithm,\" IEEE Trans. Acoust. Speech and Sig.\nProc. vol. 34, no. 4, pp. 477-489, Apr. 1988\n[18] H. Akaike, \"Information theory and an extension of the maximum\nlikelihood principle,\" in Proc. Second Int. Symp. on Information Theory,\npp. 267-281, Budapest, 1973.\n[19] M. Wax and T. Kailath, \"Detection of signals by information theoretic\ncriteria,\" IEEE Trans. Acoust., Speech, Sig. Proc, vol. ASSP-32, pp. 387392, 1985.\n[20] S. Yatawatta, \"LOFAR beamshapes and their use in calibration and\nimaging,\" ASTRON, Tech. Report, 2007.\n\n\f16\n\nCasA SAGE\nCasA Normal 12 iterations\nCasA Normal 24 iterations\n\n14\n\n12\n\n\u03b7/Jy\n\n10\n\nCasA\n\n8\n\nCygA\nSAGE, 12 iterations\n\n6\n\n4\n\n2\n\n40\n\n45\n\n50\n\n55\n\n60\n\nFreq/MHz\n\nCasA\n16\n\nCygA SAGE\nCygA Normal 12 iterations\nCygA Normal 24 iterations\n\n14\n\nCasA\n\n12\n\nCygA\nNormal, 12 iterations\n\u03b7/Jy\n\n10\n\n8\n\n6\n\n4\n\n2\n\n40\n\n45\n\n50\n\n55\n\n60\n\nFreq/MHz\n\nCygA\nCasA\n\nCygA\nNormal, 24 iterations\n\nFig. 2. Images around CasA (left column) and CygA (right column) after\napplying the SAGE algorithm (first row), Normal algorithm, 12 iterations\n(second row) and Normal algorithm, 24 iterations (bottom row). The residual\nof CasA is seen at top left on the images in the left column. The residual of\nCygA is seen at center left on the images in the right column. The grid lines\ncorrespond to sky coordinates: right ascension and declination.\n\nFig. 3. Pixel rms values around CasA and CygA using the normal calibration\nalgorithm and the SAGE calibration algorithm. For equal number of iterations,\nthe normal algorithm has higher residual compared to the SAGE algorithm.\nWith higher number of iterations, the normal algorithm gives comparable\nperformance.\n\n\f"}