{"id": "http://arxiv.org/abs/1107.2737v2", "guidislink": true, "updated": "2011-09-25T15:05:05Z", "updated_parsed": [2011, 9, 25, 15, 5, 5, 6, 268, 0], "published": "2011-07-14T06:35:45Z", "published_parsed": [2011, 7, 14, 6, 35, 45, 3, 195, 0], "title": "Second moment method for a family of boolean CSP", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1107.0709%2C1107.1298%2C1107.0471%2C1107.5505%2C1107.2039%2C1107.3518%2C1107.5532%2C1107.2950%2C1107.0163%2C1107.5138%2C1107.3307%2C1107.0306%2C1107.5584%2C1107.1951%2C1107.0813%2C1107.2956%2C1107.2145%2C1107.5390%2C1107.1578%2C1107.0425%2C1107.5455%2C1107.1393%2C1107.1244%2C1107.1666%2C1107.4169%2C1107.4039%2C1107.1412%2C1107.1316%2C1107.4932%2C1107.3342%2C1107.4719%2C1107.5089%2C1107.4591%2C1107.1751%2C1107.2110%2C1107.5874%2C1107.1193%2C1107.2703%2C1107.5062%2C1107.4778%2C1107.5065%2C1107.2737%2C1107.0753%2C1107.0704%2C1107.3622%2C1107.4822%2C1107.0242%2C1107.1310%2C1107.5105%2C1107.0146%2C1107.5764%2C1107.4209%2C1107.5747%2C1107.3515%2C1107.0298%2C1107.2482%2C1107.4628%2C1107.4592%2C1107.3257%2C1107.4079%2C1107.1944%2C1107.5250%2C1107.4862%2C1107.2151%2C1107.1210%2C1107.4499%2C1107.1925%2C1107.4801%2C1107.0858%2C1107.2968%2C1107.1081%2C1107.0818%2C1107.1156%2C1107.2267%2C1107.5093%2C1107.1981%2C1107.0554%2C1107.2824%2C1107.2930%2C1107.4042%2C1107.4265%2C1107.2000%2C1107.5714%2C1107.0476%2C1107.1979%2C1107.0652%2C1107.0138%2C1107.2984%2C1107.0596%2C1107.1037%2C1107.3652%2C1107.4464%2C1107.4947%2C1107.2199%2C1107.2508%2C1107.4140%2C1107.1927%2C1107.5248%2C1107.3219%2C1107.1778%2C1107.1066&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Second moment method for a family of boolean CSP"}, "summary": "The estimation of phase transitions in random boolean Constraint Satisfaction\nProblems (CSP) is based on two fundamental tools: the first and second moment\nmethods. While the first moment method on the number of solutions permits to\ncompute upper bounds on any boolean CSP, the second moment method used for\ncomputing lower bounds proves to be more tricky and in most cases gives only\nthe trivial lower bound 0. In this paper, we define a subclass of boolean CSP\ncovering the monotone versions of many known NP-Complete boolean CSPs. We give\na method for computing non trivial lower bounds for any member of this\nsubclass. This is achieved thanks to an application of the second moment method\nto some selected solutions called characteristic solutions that depend on the\nboolean CSP considered. We apply this method with a finer analysis to establish\nthat the threshold $r_{k}$ (ratio : #constrains/#variables) of monotone\n1-in-k-SAT is $\\log k/k\\leq r_{k}\\leq\\log^{2}k/k$.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1107.0709%2C1107.1298%2C1107.0471%2C1107.5505%2C1107.2039%2C1107.3518%2C1107.5532%2C1107.2950%2C1107.0163%2C1107.5138%2C1107.3307%2C1107.0306%2C1107.5584%2C1107.1951%2C1107.0813%2C1107.2956%2C1107.2145%2C1107.5390%2C1107.1578%2C1107.0425%2C1107.5455%2C1107.1393%2C1107.1244%2C1107.1666%2C1107.4169%2C1107.4039%2C1107.1412%2C1107.1316%2C1107.4932%2C1107.3342%2C1107.4719%2C1107.5089%2C1107.4591%2C1107.1751%2C1107.2110%2C1107.5874%2C1107.1193%2C1107.2703%2C1107.5062%2C1107.4778%2C1107.5065%2C1107.2737%2C1107.0753%2C1107.0704%2C1107.3622%2C1107.4822%2C1107.0242%2C1107.1310%2C1107.5105%2C1107.0146%2C1107.5764%2C1107.4209%2C1107.5747%2C1107.3515%2C1107.0298%2C1107.2482%2C1107.4628%2C1107.4592%2C1107.3257%2C1107.4079%2C1107.1944%2C1107.5250%2C1107.4862%2C1107.2151%2C1107.1210%2C1107.4499%2C1107.1925%2C1107.4801%2C1107.0858%2C1107.2968%2C1107.1081%2C1107.0818%2C1107.1156%2C1107.2267%2C1107.5093%2C1107.1981%2C1107.0554%2C1107.2824%2C1107.2930%2C1107.4042%2C1107.4265%2C1107.2000%2C1107.5714%2C1107.0476%2C1107.1979%2C1107.0652%2C1107.0138%2C1107.2984%2C1107.0596%2C1107.1037%2C1107.3652%2C1107.4464%2C1107.4947%2C1107.2199%2C1107.2508%2C1107.4140%2C1107.1927%2C1107.5248%2C1107.3219%2C1107.1778%2C1107.1066&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "The estimation of phase transitions in random boolean Constraint Satisfaction\nProblems (CSP) is based on two fundamental tools: the first and second moment\nmethods. While the first moment method on the number of solutions permits to\ncompute upper bounds on any boolean CSP, the second moment method used for\ncomputing lower bounds proves to be more tricky and in most cases gives only\nthe trivial lower bound 0. In this paper, we define a subclass of boolean CSP\ncovering the monotone versions of many known NP-Complete boolean CSPs. We give\na method for computing non trivial lower bounds for any member of this\nsubclass. This is achieved thanks to an application of the second moment method\nto some selected solutions called characteristic solutions that depend on the\nboolean CSP considered. We apply this method with a finer analysis to establish\nthat the threshold $r_{k}$ (ratio : #constrains/#variables) of monotone\n1-in-k-SAT is $\\log k/k\\leq r_{k}\\leq\\log^{2}k/k$."}, "authors": ["Yacine Boufkhad", "Olivier Dubois"], "author_detail": {"name": "Olivier Dubois"}, "author": "Olivier Dubois", "links": [{"href": "http://arxiv.org/abs/1107.2737v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1107.2737v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.DM", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.DM", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1107.2737v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1107.2737v2", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "SECOND MOMENT METHOD FOR A FAMILY OF BOOLEAN CSP\n\narXiv:1107.2737v2 [cs.DM] 25 Sep 2011\n\nYACINE BOUFKHAD AND OLIVIER DUBOIS\n\nAbstract. The estimation of phase transitions in random boolean Constraint Satisfaction Problems (CSP) is based on two fundamental tools: the first and second moment methods. While\nthe first moment method on the number of solutions permits to compute upper bounds on any\nboolean CSP, the second moment method used for computing lower bounds proves to be more\ntricky and in most cases gives only the trivial lower bound 0. In this paper, we define a subclass\nof boolean CSP covering the monotone versions of many known NP-Complete boolean CSPs. We\ngive a method for computing non trivial lower bounds for any member of this subclass. This is\nachieved thanks to an application of the second moment method to some selected solutions called\ncharacteristic solutions that depend on the boolean CSP considered. We apply this method with\na finer analysis to establish that the threshold rk (ratio : #constrains/#variables) of monotone\n1-in-k-SAT is log k/k \u2264 rk \u2264 log2 k/k.\n\nIntroduction\nThe empirical evidence has shown that random instances of boolean Constraint Satisfaction Problems CSP exhibit a phase transition i.e. a sudden change from SAT to UNSAT when the number\nof constraints increases: that is there exists a critical value r\u2217 of the ratio r number of constraints\nto number of variables such that random instances are w.h.p. satisfiable if r < r\u2217 and w.h.p.\nunsatisfiable if r > r\u2217 . r\u2217 is called the threshold value of the transition. The sharpness of the\nthreshold has been addressed in a series of works [12, 17, 5, 6].\nComputing the threshold associated to a CSP is at present out of reach apart from some exceptions\n[3, 14, 7, 11] for polynomial subclasses. Since this cannot be carried out, upper and lower bounds of\nr\u2217 are computed. These bounds are almost all obtained by different applications of the probabilistic\nmethod tools: the first and second moment methods and for some of them through anlaysis of\nalgorithms[10, 9, 8, 16, 2] for 3-SAT.\nWhile the first moment method on the number of solutions permits to obtain an upper bound of\nthe location of the threshold for any boolean CSP , the second moment method on the number of\nsolutions fails at any ratio to estimate the probability of satisfiability. In [1], an original method\nis presented to overcome this problem in the case of k-SAT for which the direct calculus also fails.\nWe define a subclass of CSP and a method that allow to bound the phase transition from both\nsides for this subclass. The latter is characterized by constraints having the property of being\nclosed under permutations. It includes the monotone versions of many well known problems like :\n1-in-kSAT, NAE-k-SAT... and then it includes many NP-Complete boolean CSP s.\nRoughly speaking, we show how the second method can be made \"to work\" for every problem\nin this class. More precisely, we parameterize the valuations by their number of variables having\nthe value 1 and we show that there exist precise values for this parameter depending on every\nproblem for which the second moment method gives a non trivial lower bound, the corresponding\nsolutions are called characteristic solutions. We prove that the bound given by this method is at\nleast some well defined value for any problem in the sublclass. However, the generality of this value\nis obtained at the cost of some weakness. Better bounds can be computed using the same scheme\nthrough a finer analysis on a case by case basis. To illustrate this, we do the full analysis for\nKey words and phrases. Constraint Satisfaction Problems, Phase transitions, Second moment method.\n1\n\n\f2\n\nY. BOUFKHAD AND O. DUBOIS\n\npositive 1-in-k-SAT to derive the asymptotically optimal lower bound with respect to our method\nthat is log k/k. To show that this lower bound is tight, we establish using the first moment method\nan upper bound of log2 k/k for k \u2265 7.\n1. Basic definitions and main results\nGiven a set X of n boolean variables, a valuation \u03c3 is a mapping X \u2192 {0, 1} that assigns to\nany variable x \u2208 X the value 0 or 1. k being an integer, a relation R of arity k is a subset of\n{0, 1}k . A relation is said to be trivial if (0, ..., 0) or (1, ..., 1) is an element of R. We consider\nthroughout the paper only non trivial relations. A constraint defined from a relation R of arity k,\nis a tuple of k boolean variables, denoted R (x1 , ..., xk ), which is said to be satisfied under some\nvaluation \u03c3 iff (\u03c3 (x1 ) , ..., \u03c3 (xk )) \u2208 R, otherwise it is said unsatisfied. Given a set of relations S, an\ninstance of boolean CSP with respect to S, denoted by CSP (S), is a conjunction set of constraints\nR (x1 , ..., xk ) where R \u2208 S. An instance CSP (S) is satisfied iff every constraint is satisfied.\nIn this paper, we consider a subclass of CSP (S)s defined as follows. A relation R is said to be\ninvariant by permutation, iff any permutation of the coordinates of a tuple t \u2208 R is also in R. Such\na relation is denoted by Rinv . The invariance property implies that for every tuple t \u2208 Rinv , all\ntuples having the same number of coordinates equal to 1 or (0s) as t must be also in Rinv . This\ndefines an equivalence relation, two elements t and t0 of Rinv belonging to the same equivalence\nclass iff they have the same number of coordinates equal to 1s (or 0s). Thus the equivalence classes\npartition Rinv into subsets each associated to an integer i equal to the number of 1s of the elements\nof the class.\nIn this paper, we will only consider boolean CSP s with respect to a single non trivial invariant under permutation relation denoted CSP ({Rinv }) . In order to designate more explicitly a\nCSP (Rinv ) we will denote it in an equivalent manner by CSP (Ik ), where Ik is the subset of integers in {1, ..., k \u2212 1} associated to all equivalence classes. Thus an instance CSP (Ik ) is satisfiable\nwith respect to Ik iff there exits a valuation \u03c3 such that the number of 1s in every constraint of\nCSP (Ik )1 is an element of Ik .\nExample 1. k = 4 and R = {1000, 0100, 0010, 0001, 0111, 1011, 1101, 1110}. R is invariant by\npermutation. The set of integers associated to R is I4 = {1, 3}. A constraint (xi1 , xi2 , xi3 , xi4 ) of\nan instance CSP (R) is satisfied iff exactly one or three of the four variables of the constraint has\nthe value 1.\nThe CSP s of the class defined above are NP-complete for any relation of arity greater or equal to 3\naccording to the Schaefer classification. They include two well known problems of this classification\nthat are positive 1-in-k-SAT (Ik = {1} according to the above definition) and positive not-all-equalk-SAT (Ik = {1, ..., k \u2212 1}).\nThe random version of a CSP (Ik ) is as follows. Given a relation Rinv , Ik the set of integers\nassociated with Rinv , a random CSP (Ik ) instance with m constraints over n boolean variables is\nformed by drawing uniformly, independently and with replacement m tuples of k variables over\nthe set of n variables. Such a random CSP (Ik ) instance is denoted by Ik (m, n). This defines a\nprobability space denoted by \u03a9(Ik , m, n) in which instances Ik (m, n) are equiprobable.\nDefinition 1. A p-valuation for some natural integer 0 \u2264 p \u2264 n is a valuation such that\n|{xi |\u03c3 (xi ) = 1}| = p.\nLet \u03b4 \u2208 [0, 1], for the sake of simplicity we will denote whenever it is non ambiguous a b\u03b4nc-valuation\nby \u03b4-valuation. A \u03b4-valuation that is a solution of an instance Ik (m, n) is said to be a \u03b4-solution.\nLet X\u03b4 be the random variable associating to each Ik (m, n) the number of its \u03b4-solutions.\n1Alternatively, this class can be seen as hypergraph bi-coloring problem where the number of vertices allowed to\nhave a certain color in some edge are taken only in Ik .\n\n\fSECOND MOMENT METHOD FOR A FAMILY OF BOOLEAN CSP\n\n3\n\nTheorem 1. For any CSP (Ik ), there exist a rI\u2217k > 0 and 0 < \u03b4 < 1 such that for all r < rI\u2217k ,\n2\n\n\u03b4]\nlimn\u2192\u221e E[X\n> 0.\nE[X 2 ]\n\u03b4\n\nRoughly speaking, the preceding Theorem states that for any problem in CSP (Ik ), there exists\na \u03b4 that makes the second moment to succeed in computing a lower bound. Combined with the\ninequality of Cauchy-Schwartz:\nP (X\u03b4 > 0) \u2265\n\nE[X\u03b4 ]2\nE[X\u03b42 ]\n\nand the sharpness of the threshold of the problems in this class [13] [4], we have the following\nconsequence of Theorem 1.\nCorollary 1. For any CSP (Ik ), there exists a real rI\u2217k > 0 such that for r < rI\u2217k ,\nlimn\u2192\u221e P r (Ik (n, rn) is satisfiable ) = 1.\nThe Theorem 1 states that the second moment succeeds for some values of \u03b4 using X\u03b4 as a random\nvariable. However, the value of the bound rI\u2217k mentioned in the theorem (and given in Section 2.2)\nis not the optimal bound that can be derived by the method. This is the price of its generality. The\nfull analysis establishing the optimal bound can somehow be done on a case by case basis. Note\nthat the best bound that can be obtained can not exceed the smallest ratio that make E[X\u03b4 ] \u2192 0\nwhen n \u2192 \u221e. Indeed, by Markov inequality the probability of X\u03b4 > 0 in that case is 0. The value\nof the best bound that can be expected for positive 1-in-k-SAT is asymptotically log k/k. This is\nprecisely what we obtain through the full analysis of this particular problem. We obtain :\nTheorem 2. Let 1k = {1}. limn\u2192\u221e Pr (1k (n, rn) is satisfiable) = 1 If r < log k/k and k \u2265 3.\nSpecifically, for k = 3 a better lower bound at 0.546 has been computed in [15] analyzing the\nsuccess to find out a solution with a specific algorithm. However our aim is to provide a tool\nyielding systematically a lower bound for a large class of CSPs. We give a rough upper bound at\n(log k)2 /k (valid for k \u2265 7) which shows that our bounds are tight around the threshold.\n2. Second moment and characteristic solutions\nWe first define the characteristic solutions before we give the second moment of their number.\nDefinition 2. Characteristic valuations for some CSP (Ik ) are \u03b4-valuations for which the probability of satisfying a uniformly randomly drawn constraint is locally maximum with respect to \u03b4.\nThe solutions of an instance that are characteristic valuations are said to be characteristic solutions\nfor this instance.\nGiven some \u03b4-valuation, the probability \u03c0i (\u03b4) that a randomly selected k-tuple contains i ones is\n\u0001\nk\u2212i\n\u03c0i (\u03b4) = ki \u03b4 i (1 \u2212 \u03b4) . So the probability that a \u03b4-valuation satisfies with respect to some set\nIk \u2282 {1, 2, ..., k \u22121} a randomly selected k-tuple is obtained by summing up, the mutually exclusive\n\u0001\nP\nP\nk\u2212i\ncases for different i's in I. This probability is gIk (\u03b4) = i\u2208Ik \u03c0i (\u03b4) = i\u2208Ik ki \u03b4 i (1 \u2212 \u03b4) . Let\n\u2206Ik be the set of reals for which gIk (\u03b4) is locally maximum. Clearly, for any \u03b4 \u2208 \u2206Ik , \u03b4-valuations\nare by definition the characteristic valuations of CSP (Ik ).\nSince Ik \u2286 {1, ..., k \u2212 1} then gIk (0) = gIk (1) = 0. The function gIk (\u03b4) being smooth, strictly\npositive inside ]0, 1[, it maximizes inside the interval ]0, 1[ at at least one stationary point. Thus\nfor any Ik \u2286 {1, ..., k \u2212 1}, \u2206Ik 6= \u2205. The fact that every \u03b4 \u2208 \u2206Ik is a stationary point for gIk (\u03b4)\nwill be used later.\n\n\f4\n\nY. BOUFKHAD AND O. DUBOIS\n\n2.1. First and second moment of number of characteristic solutions. The key idea used\nin the method presented in this paper is instead of taking as a random variable the number of\nsolutions, to consider as random variable the number of \u03b4-solutions. The first moment of X\u03b4 is:\n\u0012 \u0013\nn\n1\nn\nrn\n\u03b3Ik ,r (\u03b4)\nE[X\u03b4 ] =\ngIk (\u03b4) \u223c p\n\u03b4n\n2\u03c0\u03b4(1 \u2212 \u03b4)n\nWhere:\nr\ngIk (\u03b4)\n\u03b3Ik ,r (\u03b4) =\n1\u2212\u03b4\n\u03b4 \u03b4 (1 \u2212 \u03b4)\nlog(1\u2212\u03b4)\nRemark 1. It is easy to see that limn\u2192\u221e \u03b3Ik ,r (\u03b4) = 0 for any r > r\u0302Ik ,\u03b4 = \u03b4 log \u03b4+(1\u2212\u03b4)\n. By\nlog gIk (\u03b4)\nMarkov inequality, this means that the \u03b4-solutions does not exist for r > r\u0302Ik ,\u03b4 and then the lower\nbound that we can get through \u03b4-solutions is at most r\u0302Ik ,\u03b4 .\n\nFor computing the second moment, we consider two \u03b4-valuations \u03c31 and \u03c32 having p variables\nassigned 1 in \u03c31 and 0 in \u03c32 . This defines all the other categories of variables. Indeed, the number\nof variables assigned 0 in \u03c31 and 1 in \u03c32 must be also p in order that \u03c32 is a \u03b4-valuation. b\u03b4nc \u2212 p\nis the number of variables assigned 1 in both\u0010 solutions\nand n \u2212 b\u03b4nc \u2212 p are assigned 0 in both\n\u0011\n\np\nsolutions. First, we give the probability \u03c6i,j,\u03b4 b\u03b4nc\nthat a random k-tuple has i 1s under \u03c31 and\nj 1s under \u03c32 such that d variables of the k-tuple are equal to 1 in both assignments. d must range\nfrom dmin = max(0, i + j \u2212 k) to dmax = min(i, j).\n\n\u0012\n(1)\u03c6i,j,\u03b4\n\np\nb\u03b4nc\n\n\u0013\n=\n\ndX\nmax\n\n\u0012 \u0013\u0012 \u0013\u0012\n\u0013\u0012\n\u0013d\n\u0012\n\u0013k\u2212i\u2212j+d\nk\ni\nk\u2212i\nb\u03b4nc \u2212 p \u0010 p \u0011i+j\u22122d n \u2212 b\u03b4nc \u2212 p\ni\nn\nn\nn\nd j\u2212d\n\ndmin\n\nSumming up over couples (i, j), we get GIk ,\u03b4 (\u03bc), the probability that a couple of \u03b4-valuations\nhaving \u03bc\u03b4n variables taking a different value in \u03c31 or \u03c32 satisfies a random constraint:\n\u0012\nGIk ,\u03b4\n\np\nb\u03b4nc\n\n\u0013\n=\n\nXX\n\n\u0012\n\u03c6i,j,\u03b4\n\ni\u2208Ik j\u2208Ik\n\np\nb\u03b4nc\n\n\u0013\n\nWe can now write the second moment by summing up over all possible couples (\u03c31 , \u03c32 ) :\nmin(b\u03b4nc,n\u2212b\u03b4nc) \u0012\n\nE[X\u03b42 ]\n\nX\n\n=\n\np=0\n\n\u0013rn\n\u0013\n\u0012\nn\np\nGIk ,\u03b4\nb\u03b4nc\n(b\u03b4nc \u2212 p) p p (n \u2212 b\u03b4nc \u2212 p)\n\nE[X\u03b42 ]\n\nWe now estimate\nas a function of n, using a classical asymptotic estimate of the multinomial\ncoefficient. For small multinomial numbers the asymptotic estimate being also an upper bound, it\np\nwill be sufficient for the estimation we need. We set : \u03bc = b\u03b4nc\n.\n\u0013\nn\n(2\u03c0n)\u22123/2\n\u2212n\n\u2264p\n(t\u03b4 (\u03bc))\n(1 \u2212 \u03bc) \u03b4n \u03bc\u03b4n \u03bc\u03b4n (1 \u2212 \u03b4 \u2212 \u03bc\u03b4) n\n2\u03bc\u03b4(1 \u2212 \u03bc)\u03b4(1 \u2212 \u03b4 \u2212 \u03bc\u03b4)\n\n\u0012\n\n(1\u2212\u03bc)\u03b4\n\nwhere : t\u03b4 (\u03bc) = ((1 \u2212 \u03bc) \u03b4)\n(2)\n\nE[X\u03b42 ] \u2264\n\n(1 \u2212 \u03b4 \u2212 \u03bc\u03b4)\n\n1\u2212\u03b4\u2212\u03bc\u03b4\n\n. We have :\n\n(2\u03c0n)\u22123/2\n\nX\np\n1\n\u03bc\u2208{0, b\u03b4nc\n,...,min(1,\n\nwith:\n\n2\u03bc\u03b4\n\n(\u03bc\u03b4)\n\nn\u2212b\u03b4nc\nb\u03b4nc\n\n)}\n\n2\u03bc\u03b4(1 \u2212 \u03bc)\u03b4(1 \u2212 \u03b4 \u2212 \u03bc\u03b4)\n\n(\u0393Ik ,\u03b4,r (\u03bc))\n\nn\n\n\fSECOND MOMENT METHOD FOR A FAMILY OF BOOLEAN CSP\n\n5\n\nr\n\n(3)\n\n\u0393Ik ,\u03b4,r (\u03bc) =\n\nGIk ,\u03b4 (\u03bc)\nt\u03b4 (\u03bc)\n\nEach term in (2) consisting of a polynomial factor and an exponential factor in n the sum can be\nestimated with a discrete version of Laplace method. Thus :\nLemma 1. if u and v are smooth real-valued functions of one variable x, and if v has a single\nmaximum on [a, +\u221e[, located at \u03be0 with \u03be > a and if further v 00 (\u03be0 ) is not 0, then :\n\u221a\n\u03c9n\n2\u03c0\u03c9\n1 X\ni\ni\n\u221a\nexp(nv(\u03be0 ))\nu( )exp(nv( )) \u223c g(\u03be0 ) p\nn\nn i=a\u03c9n n\n|v 00 (\u03be0 )|\n3\n\nWe will apply Lemma 1, setting v(\u03bc) = log(\u0393Ik ,\u03b4,r (\u03bc)) and u(\u03bc) = \u221a\n\n(4)\n\nE[X\u03b42 ]\n\n\u2264n\n\n\u22121\n\n\u221a\n2\u03c0min (\u03b4, (1 \u2212 \u03b4))\np\n\u00d7 q\n2(1 \u2212 \u03b4)3 \u03b4 3\n|\u039300Ik ,\u03b4,r (1 \u2212 \u03b4)|\n\n(2\u03c0)\u2212 2\n\n2\u03bc\u03b4 2 (1\u2212\u03bc)(1\u2212\u03b4\u2212\u03bc\u03b4)\n\n. Then :\n\n!n\n\n(2\u03c0)\u22123/2\n\nmax\n\n\u03bc\u2208[0,min(1, 1\u2212\u03b4\n\u03b4 )]\n\n\u0393Ik ,\u03b4,r (\u03bc)\n\nThe success of\u0001 the second moment method relies mainly on the behavior of \u0393Ik ,\u03b4,r (\u03bc) for \u03bc \u2208\n[0, min 1, 1\u2212\u03b4\n]\n\u03b4\nThe upper bound of the ratio\n\nE[X\u03b4 ]2\nE[X\u03b42 ]\n\nwill then depend mainly on its exponential part\n\nthat must be equal to 1 otherwise, all what we will get is the trivial relation\nsee in the next Section that this achieved through characteristic solutions.\nFrom (1) we will write in the sequel of the paper :\nmin(i,j)\n\n\u03c6i,j,\u03b4 (\u03bc)\n\n(5)\n\n=\n\nX\nd=max(0,i+j\u2212k)\n\n(6)\n\nwith :\n\nd\n\n\u03b3Ik ,r (\u03b4)2\n\nmax\n\n\u03bc\u2208[0,min 1, 1\u2212\u03b4\n\u03b4\n\n2\n\nE[X\u03b4 ]\nE[X\u03b42 ]\n\n(\n)]\n\u2265 0. We will\n\n\u0012 \u0013\u0012 \u0013\u0012\n\u0013\nk\ni\nk\u2212i\n\u03bai,j,d,\u03b4 (\u03bc)\ni\nd j\u2212d\n\ni+j\u22122d\n\n\u03bai,j,d,\u03b4 (\u03bc) = ((1 \u2212 \u03bc) \u03b4) (\u03bc\u03b4)\n\n((1 \u2212 \u03b4 \u2212 \u03bc\u03b4))\n\nk\u2212i\u2212j+d\n\nand :\n(7)\n\nGIk ,\u03b4 (\u03bc)\n\n=\n\nXX\n\n\u03c6i,j,\u03b4 (\u03bc)\n\ni\u2208Ik j\u2208Ik\n\n2.2. Proof of Theorem 1 and its Corollary. In the following, we sketch first the proof by\ndiscussing its most important ingredients. A crucial point for the success of the method is the\npoint where \u03bc = 1 \u2212 \u03b4 or the independence point. To understand this, consider two valuations\ndrawn independently uniformly at random from the set of \u03b4-valuations. A variable is assigned 1\nunder one of the two \u03b4-valuations with probability \u03b4 and 0 with probability 1 \u2212 \u03b4. Since the two\nvaluations are selected independently, the probability of being assigned 1 by a \u03b4-valuation and 0 by\nthe other is \u03b4(1 \u2212 \u03b4). Thus, according to the notation of the Section 2.1, these pairs of \u03b4-valuations\nare characterized by Hamming distance 2\u03bc with \u03bc = 1\u2212\u03b4. These uncorrelated pairs of \u03b4-valuations\nplay a central role in the success of the method. Indeed:\n\n\u0393Ik ,\u03b4,r (\u03bc)\n\n\f6\n\nY. BOUFKHAD AND O. DUBOIS\n\nGIk ,\u03b4 (1 \u2212 \u03b4)\n\n=\n\nXX\n\n\u03c6i,j,\u03b4 (1 \u2212 \u03b4)\n\ni\u2208Ik j\u2208Ik\n\n=\n=\n=\n\n\u0012 \u0013 X \u0012 \u0013\u0012\n\u0013\nk\ni\nk\u2212i\n\u03b4\n(1 \u2212 \u03b4)\ni\nd j\u2212d\ni\u2208Ik j\u2208Ik\nd\n\u0012\n\u0013\u0012\n\u0013\nXX\nk\n2k\u2212i\u2212j k\n\u03b4 i+j (1 \u2212 \u03b4)\ni\nj\ni\u2208Ik j\u2208Ik\nXX\n\u03c0i (\u03b4) \u03c0j (\u03b4)\nXX\n\n2k\u2212i\u2212j\n\ni+j\n\ni\u2208Ik j\u2208Ik\n\n=\n\n2\n\ngI (\u03b4)\n\u0010\n\u00112\n1\u2212\u03b4\nIt is easy to see that t\u03b4 (1 \u2212 \u03b4) = \u03b4 \u03b4 (1 \u2212 \u03b4)\n, thus :\nr\n\n(8)\n\n\u0393Ik ,\u03b4,r (1 \u2212 \u03b4) =\n\nGIk ,\u03b4 (1 \u2212 \u03b4)\n=\u0010\nt\u03b4 (1 \u2212 \u03b4)\n\n2r\n\ngIk (\u03b4)\n\n2\n\n1\u2212\u03b4\n\n\u03b4 \u03b4 (1 \u2212 \u03b4)\n\n\u00112 = \u03b3Ik ,r (\u03b4)\n\n2\n\nSince \u0393Ik ,\u03b4,r (1 \u2212 \u03b4) /\u03b3Ik ,r (\u03b4) = 1, if \u03bc = 1 \u2212 \u03b4 is not the global maximum of \u0393Ik ,\u03b4,r (\u03bc), there exist\n2\nsome \u03bc for which \u03b3Ik (\u03b4) /\u0393Ik ,\u03b4,r (\u03bc) < 1 making the method to fail.\nConsequently, a necessary condition for the success of the method is that \u03bc = 1 \u2212 \u03b4 is a stationary\npoint. Lemma 2 states that\u0010this is the case only\u0011for the characteristic solutions.\n00\n\u03b4\n\u03b42\nLet \u03c1 = max\u03bc\u2208[0,min(1, 1\u2212\u03b4 )] 1\u2212\u03bc\n+ 2\u03b4\n\u03bc + 1\u2212\u03b4\u2212\u03b4\u03bc , \u03bd = max\u03bc\u2208[0,min(1, 1\u2212\u03b4 )] (log (GIk ,\u03b4 (\u03bc))) . Let:\n\u03b4\n\n\u03b4\n\n\u03c1\n(9)\nrI\u2217k =\n\u03bd\nThe Lemma 3 states that rI\u2217k is well defined and that it is strictly positive and for any r < rI\u2217k , the\nsecond derivative of log (\u0393Ik ,\u03b4,r (\u03bc)) is negative for any \u03bc \u2208 [0, min (1, (1 \u2212 \u03b4)/\u03b4)]. This function is\nthen concave in the previous interval. Combining the two lemmas, we can conclude that there is\na range of ratios ]0, rI\u2217k [ for which \u03bc = 1 \u2212 \u03b4 is the global maximum of \u0393Ik ,\u03b4,r .\nRemark 2. In general, the point \u03bc = 1 \u2212 \u03b4 continues to be the global maximum in a range beyond\nrI\u2217k after the function ceases to be concave, allowing through a more precise analysis to get better\nlower bound than rI\u2217k . However, a general bound beyond concavity is hard to figure out for the\nclass and we do not need this fact for the proof of Theorem 1 which aim is to give the conditions\nunder which the second moment succeeds regardless of the value of the bound obtained. When\none needs for a particular problem to compute the best lower bound with respect to \u03b4-solutions, a\nfiner analysis is required for this particular problem. This is what we do to get the best possible\nlower bound with respect to \u03b4-solutions for positive 1-in-k-SAT.\nLemma 2. \u03930Ik ,\u03b4,r (1 \u2212 \u03b4) = 0 iff \u03b4 \u2208 \u2206Ik .\nProof. Considering (3), it is easy to check that the derivative of t0\u03b4 (\u03bc) (defined in (6)) is such that\nt0\u03b4 (1 \u2212 \u03b4) = 0. It is then necessary and sufficient that G0Ik ,\u03b4 (1 \u2212 \u03b4) = 0. It can be shown (see\nAppendix A), that:\n0 \u00012\n\u03b4 gIk (\u03b4)\n0\n(10)\nGIk ,\u03b4 (1 \u2212 \u03b4) = \u2212\n2\nk (1 \u2212 \u03b4)\n0\n\nwhich is equal to 0 iff gIk (\u03b4) = 0 i.e. \u03b4 \u2208 \u2206Ik .\n\n\u0003\n\n\fSECOND MOMENT METHOD FOR A FAMILY OF BOOLEAN CSP\n\n7\n00\n\nLemma 3. rI\u2217k (as defined in (9)) is strictly greater than 0 and for every r < rI\u2217k , log (\u0393Ik ,\u03b4,r (\u03bc)) <\n0 for \u03bc \u2208 [0, min (1, (1 \u2212 \u03b4)/\u03b4)].\nProof.\n\u0013\n\u03b4\n2\u03b4\n\u03b42\n00\n\u2212\n\u2212\n+ r (log (GIk ,\u03b4 (\u03bc)))\n1\u2212\u03bc\n\u03bc\n1 \u2212 \u03b4 \u2212 \u03b4\u03bc\n\u0011\n\u0010\n\u03b4\n\u03b42\nIt can be shown (see Appendix B) that \u2212 1\u2212\u03bc\n\u2212 2\u03b4\n\u2212\n\u03bc\n1\u2212\u03b4\u2212\u03b4\u03bc is negative and bounded from above\n\u0012\n\n00\n\n(log (\u0393Ik ,\u03b4,r (\u03bc)))\n\n=\n\n\u2212\n\n00\n\n00\n\nby \u2212\u03c1 and that (log (GIk ,\u03b4 (\u03bc))) is positive and bounded from above by \u03bd, then (log (\u0393Ik ,\u03b4,r (\u03bc))) \u2264\n\u2212\u03c1 + r\u03bd < 0 if r < \u03c1/\u03bd = rI\u2217k .\n\u0003\nNow we are in position to give the proof of Theorem 1.\nProof of Thorem 1\nThanks to Lemma 2, we know that \u03bc = 1 \u2212 \u03b4 is a stationary point for log(\u0393Ik ,\u03b4,r (\u03bc)) and thanks\nto Lemma 3, we know that log(\u0393Ik ,\u03b4,r (\u03bc)) is concave for r < rI\u2217k . Combining these two facts, we\ndeduce that \u03bc = 1 \u2212 \u03b4 is a global maximum for log(\u0393Ik ,\u03b4,r (\u03bc)). The inequality (4) becomes:\n\u221a\n(2\u03c0)\u22123/2\n2\u03c0min (\u03b4, (1 \u2212 \u03b4))\n2\n\u22121\n\u00d7 q\nE[X\u03b4 ] \u2264 n p\n(\u0393Ik ,\u03b4,r (1 \u2212 \u03b4))n\n3\n3\n00\n2(1 \u2212 \u03b4) \u03b4\n|\u0393Ik ,\u03b4,r (1 \u2212 \u03b4)|\n\u22123/2\n\nOn putting C1 = \u221a(2\u03c0)\n\n2(1\u2212\u03b4)3 \u03b4 3\n\n\u00d7\n\n\u221a\n2\u03c0min(\u03b4,(1\u2212\u03b4))\nq\n|\u039300\nI ,\u03b4,r (1\u2212\u03b4)|\n\nand having thanks to (8) \u0393Ik ,\u03b4,r (1 \u2212 \u03b4) = \u03b3Ik ,r (\u03b4)2 ,\n\nk\n\nthis yields : E[X\u03b42 ] \u2264 n\u22121 C1 (\u03b3Ik ,r (\u03b4)2n ). Allowing for the relation E[X\u03b4 ] \u2265 \u221a\n\ne\u22121/6\n2\u03c0\u03b4(1\u2212\u03b4)n\n\nn\n\n(\u03b3Ik ,r (\u03b4)) ,\n\nwe deduce :\nE[X\u03b4 ]2\n\u2265 C2\nE[X\u03b42 ]\nC2 being a positive constant. Thus Theorem 1 is proved.\nFrom the Creignou and Daud\u00e9 criterion [5, 6] for k \u2265 3 a CSP (Ik ) is neither depending on one\ncomponent nor strongly depending on a 2XOR-relation, it can be stated according to the Friedgut's\ntheorem in [12] the following fact :\nFact 1. For every k \u2265 3 and a random CSP (Ik ), there exists a function \u03bbk (n) such that for any\n\u000f > 0:\n(\n1 if r > \u03bbk (n)(1 \u2212 \u000f)\nlim P r(Ik (rn, n) is satisf iable) =\nn\u2192\u221e\n0 if r < \u03bbk (n)(1 \u2212 \u000f)\nIt follows that for any CSP (Ik ) , if r < rI\u2217k as defined (9), then :\nlim n\u2192\u221e Pr (Ik (n, rn) is satisfiable ) = 1. Thus Corollary 1 is proved.\n3. Positive 1-in-k-SAT case: proof of Theorem 2\nk\u22121\n\nFor 1-in-k-SAT, we denote the corresponding Ik by 1k = {1}. The function g1k (\u03b4) = k\u03b4 (1 \u2212 \u03b4)\n.\nIt is easy to check that \u22061k = { k1 }. We note first that the best lower bound that we can hope to get\nr\u0302\n\n1k ,1/k\nis r\u03021k ,1/k as defined in Remark 1. It is easy to check that limk\u2192\u221e log\nk/k = 1. Then asymptotically,\nthe best lower bound that can be obtained with respect to 1/k-solutions is log k/k.\nFor the second moment, as previously we consider only \u03b4-valuations. Only the function G1k ,1/k (\u03bc)\nchanges:\n\u0001\n\u0001\nk\u22122\nG1k ,1/k (\u03bc) = k (k \u2212 1) \u03ba1,1,1,1/k (\u03bc) + k\u03ba1,1,0,1/k (\u03bc) = k 1\u2212k (k \u2212 1 \u2212 \u03bc)\nk 1 \u2212 \u03bc + \u03bc2 \u2212 1\n\n\f8\n\nY. BOUFKHAD AND O. DUBOIS\n\nThanks to Lemma 2, we know that \u03bc = 1 \u2212 1/k is stationary point of \u03931k , k1 ,r (\u03bc) and that\n2\n\n\u03931k , k1 ,r (1 \u2212 1/k) = \u03b31k ,r (1/k) . It remains to prove that it is a global maximum for r \u2264 log k/k.\nThis bound goes in general beyond concavity so we need a finer analysis. That is the purpose of\nthis Lemma.\n2\n\nLemma 1. For any \u03bc \u2208 [0, 1], \u03931k , k1 ,r (\u03bc) \u2264 \u03b31k ,r (1/k) .\nProof. We give here just an outline of the proof. A detailed one is given in the Appendix C.\nThe interval of \u03bc is divided into two parts [0, 1/2] and [1/2, 1] where the function \u03931k , k1 ,r is bounded\nfrom above using two different techniques.\nFirst for \u03bc \u2208 [0, 1/2]: In this interval, we use mainly the fact that for some a \u2208 [0, 1/2], 1\u2212 \u03bc \u2212 \u03bc2 \u2264\nla = 1 \u2212 a \u2212 a2 for any \u03bc \u2208 [a, 1/2]. Let\n\u0010\n\u0011\nk\u22122\n\u03c4a (\u03bc) = log k log k 1\u2212k (k \u2212 1 \u2212 \u03bc)\n(kla \u2212 1) \u2212 k log t1/k (\u03bc)\n\u03c4a (\u03bc) bounds from above k log \u03931k , 1 , log k (\u03bc) in the interval [a, 1/2]. It can be shown that \u03c4a (\u03bc)\nk\nk\nis strictly increasing in the above interval. Beginning with a0 = 0, we find a value a1 such that\n\u03c4a0 (a1 ) < 2k log \u03b31k ,r (1/k) proving the desired inequality for \u03bc \u2208 [a0 , a1 ]. We repeat the same\nwith \u03c4a1 and find a a2 and so on... until an ai \u2265 1/2 which finishes this part of the proof. In fact,\nonly two steps are sufficient with a1 = 0.15.\nSecond for \u03bc \u2208 [1/2, 1]: Recall that k log \u03931k , 1 , log k (\u03bc) = log k log G1k , k1 (\u03bc) \u2212 k log t1/k (\u03bc). We\nk\nk\nprove first separately that the derivatives of log G1k , k1 (\u03bc) and \u2212 log t1/k (\u03bc) are concave in the whole\nconsidered interval. Then we split the above interval in two parts ]1/2, 1 \u2212 1/k[ and ]1 \u2212 1/k, 1].\nConsidering their concavity, both functions can be bound from below in the first interval by the\nlinear functions representing the chords joining the two points corresponding to the two bounds of\nthe interval. The sum of these two linear functions being positive, this proves that the derivative\nof k log \u03931k , 1 , log k (\u03bc) is positive in the first interval and then that the value of the function at\nk\nk\n\u03bc = 1 \u2212 1/k is maximum. For the second interval, the functions are bounded from above by\nthe linear functions representing the tangent lines at \u03bc = 1 \u2212 1/k. The sum of these two linear\nfunctions being negative, the derivative of k log \u03931k , 1 , log k (\u03bc) is negative in the second interval and\nk\nk\nthen \u03bc = 1 \u2212 1/k is also the maximum in the second interval. Summing up, \u03931k , 1 , log k (1 \u2212 1/k) =\nk\n\n2\n\nk\n\n\u03b31k ,r (1/k) is the maximum of \u03931k , 1 , log k (\u03bc) within [1/2, 1].\nk\n\nk\n\n\u0003\n\n3.1. A general upper bound for positive 1-in-k-SAT. X is the random variable associating\nto each 1k (m, n) the number of its solutions.. We have:\nEX =\n\n\u0013rn \u0012\n\u0013n\nn \u0012 \u0013\u0012\nX\nn\np\u0010\np \u0011k\u22121\nk\n1\u2212\n\u223c max (\u03b31k ,r (\u03b4)) poly(n)\nn\nn\np\n\u03b4\u2208[0,1]\np=0\n\nFor the upper bound, we prove that for k \u2265 7 and r = log2 k/k, max\u03b4\u2208[0,1] (\u03b31k (\u03b4)) < 1. This is\nthe purpose of the following Fact.\n\u0001\nFact 2. for k \u2265 7 , max\u03b4\u2208[0,1] \u03b31k ,log2 k/k (\u03b4) < 1.\nr\n\n1\nProof. We prove it first in the interval \u03b4 \u2208 [1/2, 1]. Both g1k (\u03b4) and \u03b4\u03b4 (1\u2212\u03b4)\n1\u2212\u03b4 are decreasing\n2\n\u0001\nlog\nk/k\nr\nin \u03b4 in this interval. \u03b31k ,r (1/2) = 2g1k (1/2) = 2 2kk\n< 1 then \u03b31k ,log2 k/k (\u03b4) < 1 in\nk\u22121\nthe interval \u03b4 \u2208 [1/2, 1] . g1k (\u03b4) = k\u03b4 (1 \u2212 \u03b4)\nincreases from 0 until \u03b4 = 1/k. In the same\n2\n\n2\n\ninterval \u03b4 \u03b4 (1 \u2212 \u03b4)\nke\n\n1\u2212\u03b4\n\n(-1+k) (-1+logk) (1+logk)\nk\n\nis decreasing. Then \u03b31k ,log2 k/k (\u03b4) =\n< 1 for k \u2265 7.\n\ng1k (\u03b4)log k/k\n\u03b4 \u03b4 (1\u2212\u03b4)1\u2212\u03b4\n\n\u2264\n\ng1k (1/k)log k/k\n(1\u22121/k)1\u22121/k (1/k)1/k\n\n\u2264\n\n\fSECOND MOMENT METHOD FOR A FAMILY OF BOOLEAN CSP\n\nIt remains to handle the function within the interval [1/k, 1/2]. Since log\n\n1\n\u03b4 \u03b4 (1\u2212\u03b4)1\u2212\u03b4\n\n9\n\nis concave it can\n2\n\nbe bound from above by the line of slope its derivative\n2\n\nlog k/k\n\n(\u22121 + k)\u22121+\u03b4 k g1k (\u03b4)\n\u0010\n\n1\n\u03b4 \u03b4 (1\u2212\u03b4)1\u2212\u03b4\nlog2 k/k\n\n\u22121+\u03b4\n. (\u22121 + k)\u0011\nk g1k (1/k)\n\n\u2264 (\u22121 + k)\u22121+\u03b4 k.\n\ng1k (\u03b4)log k/k\n\u03b4 \u03b4 (1\u2212\u03b4)1\u2212\u03b4\n\n\u2264\n\nis less than 1 within [1/k, s] where\n\n2\n\ns = \u2212 log (1 \u2212 1/k) (k \u2212 1) log (k) \u2212 k /(k log (k \u2212 1)). Finally, we bound from above log g1k (\u03b4)\n\nby log g10 k (s) (\u03b4 \u2212 s) + log g1k (s). The upper bound is less than 1 for k > 7 in [s, 1/2].\n\n\u0003\n\nThe application of Markov inequality finishes the proof of the upper bound.\n4. Discussion\nAny element of \u2206Ik is necessary and sufficient to make the second moment method to be successful\nas stated by theorem 1. An interesting question that is raised by the fact that \u2206Ik may have many\nvalues is : what value gives the better lower bound? Precisely, is there a simple criterion that\npermits to select the \u03b4 \u2208 \u2206Ik that gives the best lower bound?\nIn the example of Figure 1, the function gI13 is represented for I13 = {1, 8, 12}. It has three local\nmaxima and so \u2206I13 = {\u03b41 , \u03b42 , \u03b43 } with gI13 (\u03b42 ) < gI13 (\u03b41 ) < gI13 (\u03b43 ). As said before, the second\nmoment method succeeds only for those three values of \u03b4. An immediate candidate for this choice\nof the best value could be \u03b43 since it is the one for which the probability of satisfying a randomly\nselected constraint is maximum. In fact, the best lower bound is obtained using \u03b42 . The latter is\nthe one that maximizes the first moment of X\u03b4 i.e. that corresponds to max\u03b4\u2208\u2206Ik (\u03b3Ik (\u03b4)). Since\n\u03b4\u22121\n\n\u03b4\u22121\n\n\u03b3Ik (\u03b4) = \u03b4 \u2212\u03b4 (1 \u2212 \u03b4)\ngIk (\u03b4), the entropy term \u03b4 \u2212\u03b4 (1 \u2212 \u03b4)\ncentered on 1/2 tends to favor\nvalues of \u03b4 near 1/2. We have verified this fact for many problems. We conjecture that for any\nproblem defined by the set Ik , the best value of \u03b4 for the second moment method is the \u03b4 \u2217 \u2208 \u2206Ik\nthat maximizes \u03b3Ik (\u03b4).\n\n0.8\n\ngI\n\"I13\n13\n\n0.7\n\n0.6\n\n0.5\n\n0.4\n\n0.3\n\n0.2\n\n0.1\n\n0\n0\n\n!1\n\n0.2\n\n0.4\n\n0.6\n\n!2\n\n0.8\n\n!3\n\n1\n\n!\n\nFigure 1. An example of the functions gIk and \u03b3Ik for I13 = {1, 8, 12} for r = 0.64.\nReferences\n[1] D Achlioptas and Y Peres. The Threshold for Random k-{SAT} is 2\u02c6{\\mbox{k}}ln2 - O(k). J. Amer. Math.\nSoc., 17(4):947\u2013973, 2004.\n[2] Yacine Boufkhad and Thomas Hugel. Non Uniform Selection of Solutions for Upper Bounding the 3-SAT\nThreshold. In SAT, pages 99\u2013112, 2010.\n[3] V Chv\u00e1tal and B Reed. Mick Gets Some (the Odds Are on His Side). In FOCS, pages 620\u2013627, 1992.\n\n\f10\n\nY. BOUFKHAD AND O. DUBOIS\n\n[4] N Creignou and H Daud\u00e9. Generalized satisfiability problems: minimal elements and phase transitions. Theor.\nComput. Sci., 1-3(302):417\u2013430, 2003.\n[5] N Creignou and H Daud\u00e9. Combinatorial sharpness criterion and phase transition classification for random\nCSPs. Inf. Comput., 190(2):220\u2013238, 2004.\n[6] Nadia Creignou and Herv\u00e9 Daud\u00e9. The SAT-UNSAT transition for random constraint satisfaction problems.\nDiscrete Mathematics, 309(8):2085\u20132099, 2009.\n[7] W Fernandez de la Vega. On random 2-SAT 1992. unpublished manuscript.\n[8] Josep D\u0131\u0301az, Lefteris M Kirousis, Dieter Mitsche, and Xavier P\u00e9rez-Gim\u00e9nez. On the satisfiability threshold of\nformulas with three literals per clause. Theor. Comput. Sci., 410(30-32):2920\u20132934, 2009.\n[9] O Dubois, Y Boufkhad, and J Mandler. Typical random 3-{SAT} formulae and the satisfiability threshold. In\nSymposium on Discrete Algorithms, pages 126\u2013127, 2000.\n[10] O Dubois, Y Boufkhad, and J Mandler. Typical random 3-{SAT} formulae and the satisfiability threshold.\nTechnical Report TR03-007, ECCC, 2003.\n[11] O Dubois and J Mandler. The 3-{XORSAT} threshold. In Proceedings of the 43rd Annual IEEE Symposium\non Foundations of Computer Science, FOCS'2002 (Vancouver, BC, Canada, November 16-19, 2002), pages\n769\u2013778, Los Alamitos-Washington-Brussels-Tokyo, 2002. IEEE Computer Society, IEEE Computer Society\nPress.\n[12] E Friedgut. Sharp thresholds for graph properties and the k-{SAT} problem. J. Amer. Math. Soc., 12:1017\u2013\n1054, 1999.\n[13] Ehud Friedgut and Gil Kalai. Every Monotone Graph Property has a Sharp Threshold. Proceedings of the\nAmerican Mathematical Society, 124(10):2993\u20133002, 1996.\n[14] A Goerdt. A Threshold for Unsatisfiability. J. Comput. Syst. Sci., 53(3):469\u2013486, 1996.\n[15] Vamsi Kalapala and Cris Moore. The Phase Transition in Exact Cover. CoRR, abs/cs/050, 2005.\n[16] A C Kaporis, L M Kirousis, and E G Lalas. The probabilistic analysis of a greedy satisfiability algorithm.\nRandom Struct. Algorithms, 28(4):444\u2013480, 2006.\n[17] Michael Molloy. Models and thresholds for random constraint satisfaction problems. In STOC, pages 209\u2013217,\n2002.\n\n\fSECOND MOMENT METHOD FOR A FAMILY OF BOOLEAN CSP\n\n11\n\nAppendix A. Proof of the equality (10)\nProof. Considering (7) :\nG0Ik ,\u03b4 (1 \u2212 \u03b4)\n\nXX\n\n=\n\n\u03c60i,j,\u03b4 (1 \u2212 \u03b4)\n\ni\u2208Ik j\u2208Ik\n\nX X X \u0012 i \u0013\u0012 k \u2212 i \u0013\n\n=\n\ni\u2208Ik j\u2208Ik\nd\n\ni+j\u22122d\n\nRecall that \u03bai,j,d,\u03b4 (\u03bc) = ((1 \u2212 \u03bc) \u03b4) (\u03bc\u03b4)\n\u0012\n0\n\u03bai,j,d,\u03b4 (\u03bc) = \u03bai,j,d,\u03b4 (\u03bc) \u2212\n\nd\n\nd\n\nj\u2212d\n\n((1 \u2212 \u03b4 \u2212 \u03bc\u03b4))\n\n\u03ba0i,j,d,\u03b4 (1 \u2212 \u03b4)\n\nk\u2212i\u2212j+d\n\nand then\n\nd\ni + j \u2212 2d \u03b4 (k \u2212 i \u2212 j + d)\n+\n\u2212\n1\u2212\u03bc\n\u03bc\n(1 \u2212 \u03b4 \u2212 \u03b4\u03bc)\n\n2k\u2212i\u2212j\n\nNoting that \u03bai,j,d,\u03b4 (1 \u2212 \u03b4) = \u03b4 i+j (1 \u2212 \u03b4)\n\u0001\n2k\u2212i\u2212j k\u0001 P\ni\n\u03c60i,j,\u03b4 (1 \u2212 \u03b4) = \u03b4 i+j (1 \u2212 \u03b4)\nd d\ni\n\nwe\u0010 get:\n\u0001\n\u2212 d\u03b4 +\n\nk\u2212i\nj\u2212d\n\ni+j\u22122d\n1\u2212\u03b4\n\n\u2212\n\n\u03b4(k\u2212i\u2212j+d)\n(1\u2212\u03b4)2\n\n\u0013\n\n\u0011\n\n.\n\u0001\nPj\nUsing the mean of the hypergeometric distribution of parameters k, i and j ( d=0 d di\nij\nk ) and Vandermonde identity, we get: \u0010\n\u0011\n2k\u2212i\u2212j k\u0001 k\u0001\ni+j\u22122ij/k\n\u03b4(k\u2212i\u2212j+ij/k)\nij\n+\n\u2212\n\u03c60i,j,\u03b4 (1 \u2212 \u03b4) = \u03b4 i+j (1 \u2212 \u03b4)\n.\n\u2212\n2\n1\u2212\u03b4\ni j\n(1\u2212\u03b4)\n\u0012 \u0013k\u03b4\nP\nk i\nk\u2212i\nDenoting the quantity hIk (\u03b4) = i\u2208I i\n\u03b4 (1 \u2212 \u03b4)\ni\n\u0012 \u0013 X \u0012 \u0013\u0012\n\u0013\nXX\ni\nk\u2212i\n2k\u2212i\u2212j k\n2\n\u03b4 i+j (1 \u2212 \u03b4)\nij = hIk (\u03b4)\ni\nd j\u2212d\ni\u2208Ik j\u2208Ik\nd\n\u0013\n\u0012 \u0013 X \u0012 \u0013\u0012\nXX\ni\nk\u2212i\n2k\u2212i\u2212j k\nij = hIk (\u03b4) gIk (\u03b4)\n\u03b4 i+j (1 \u2212 \u03b4)\nd j\u2212d\ni\ni\u2208Ik j\u2208Ik\nd\n\u0012 \u0013 X \u0012 \u0013\u0012\n\u0013\nXX\ni\nk\u2212i\n2k\u2212i\u2212j k\n2\ni+j\n\u03b4\n(1 \u2212 \u03b4)\n= gIk (\u03b4)\ni\nd j\u2212d\ni\u2208Ik j\u2208Ik\n\nG0Ik ,\u03b4\n\n(1 \u2212 \u03b4)\n\n=\n\nXX\n\n\u03b4\n\ni+j\n\n\u2212\n=\n\n\u2212\n\n/\n\nk\nj\n\n\u0001\n\n=\n\n(1 \u2212 \u03b4)\n\n!\n\u0012 \u0013\u0012 \u0013\ni + j \u2212 2ij/k \u03b4 (k \u2212 i \u2212 j + ij/k)\nk\nk\nij\n\u2212\n\u2212 +\n2\nk\u03b4\n1\u2212\u03b4\ni\nj\n(1 \u2212 \u03b4)\n\n2k\u2212i\u2212j\n\n2\n\n\u2212\n\n\u0001\n\nd\n\ni\u2208Ik j\u2208Ik\n\n=\n\nk\u2212i\nj\u2212d\n\n2\n\nhIk (\u03b4)\n2hIk (\u03b4) gIk (\u03b4) \u2212 2hIk (\u03b4) /k\n+\nk\u03b4\n1\u2212\u03b4\n\u0010\n\u0011\n2\n2\n\u03b4 kgIk (\u03b4) \u2212 2hIk (\u03b4) gIk (\u03b4) + hIk (\u03b4) /k\n2\n\n(1 \u2212 \u03b4)\n(hIk (\u03b4) \u2212 k\u03b4gIk (\u03b4))\n\u03b4(1 \u2212 \u03b4)2\n\n2\n\nNoting that because of:\ngI0 k\n\n(\u03b4)\n\n=\n\nX \u0012k \u0013\ni\u2208I\n\ni\n\ni\n\nk\u2212i\n\n\u03b4 (1 \u2212 \u03b4)\n\n\u0012\n\nk\u2212i\ni\n\u2212\n\u03b4\n1\u2212\u03b4\n\n\u0013\n=\n\n1\nhI (\u03b4) \u2212 k gIk (\u03b4)\n\u03b4 k\n\nhIk (\u03b4) \u2212 k\u03b4gIk (\u03b4) = \u03b4gI0 k (\u03b4) allowing for the desired relation.\n\u0003\n\n\f12\n\nY. BOUFKHAD AND O. DUBOIS\n\nAppendix B. Proof of Lemma 3\nProof. The second derivative of log (\u0393Ik ,\u03b4,r (\u03bc)) is:\n(log (\u0393Ik ,\u03b4,r (\u03bc)))\n\n00\n\n\u03b4\n2\u03b4\n\u03b42\n\u2212\n\u2212\n1\u2212\u03bc\n\u03bc\n1 \u2212 \u03b4 \u2212 \u03b4\u03bc\n\n\u0013\n\n=\n\n\u0012\n\u2212\n\n\u03b4\n2\u03b4\n\u03b42\n\u2212\n\u2212\n1\u2212\u03bc\n\u03bc\n1 \u2212 \u03b4 \u2212 \u03b4\u03bc\n\n\u0013\n\n=\n\n\u0012\n\u2212\n\n00\n\n+ r (log (GIk ,\u03b4 (\u03bc)))\n\n0\n\n+r\n\n\u03b4\n\u2212\nIt is easy to check that the second derivative of \u2212 1\u2212\u03bc\n\n2\u03b4\n\u03bc\n\nGIk ,\u03b4 (\u03bc) G00Ik ,\u03b4 (\u03bc) \u2212 GIk ,\u03b4 (\u03bc)\n\n2\n\n2\n\nGIk ,\u03b4 (\u03bc)\n\u03b42\n1\u2212\u03b4\u2212\u03b4\u03bc\n\n\u2212\n\nis negative and that its\n2\n\n\u03b4\n\u03b4\nderivative tends to \u221e when \u03bc tends to 0 and to \u2212\u221e on the other side then \u2212 1\u2212\u03bc\n\u2212 2\u03b4\n\u03bc \u2212 1\u2212\u03b4\u2212\u03b4\u03bc\nincreases from \u2212\u221e attains a maximum at a negative value then decreases to \u2212\u221e. Let \u2212\u03c1 (\u03c1 > 0)\nbe its maximum value.\n2\nIn the second part GIk ,\u03b4 (\u03bc) is bounded and strictly positive. Indeed it is formed by a sum\nof positive terms\n\u0001 some of which are strictly positive. Indeed all \u03bai,j,d,\u03b4 (\u03bc) > 0 for every \u03bc \u2208\n]0, min 1, 1\u2212\u03b4\n[. Moreover, \u03bai,i,i,\u03b4 (0) > 0 and if \u03b4 \u2264 1/2 \u03bai,i,0,\u03b4 (1) > 0 otherwise \u03bai,i,2i\u2212k,\u03b4 ((1 \u2212 \u03b4) /\u03b4) >\n\u03b4\n0.\n\u0001\n0\n2\nGIk ,\u03b4 (\u03bc) G00Ik ,\u03b4 (\u03bc) \u2212 GIk ,\u03b4 (\u03bc) is a polynomial in \u03bc. It is also bounded for \u03bc \u2208 [0, min 1, 1\u2212\u03b4\n].\n\u03b4\nThe second part have no singular point and it it bounded. Le \u03bd be its maximum value. We prove\nthat \u03bd > 0. We know thanks to Lemma 2 that G0Ik ,\u03b4 (1 \u2212 \u03b4) = 0. Moreover the second derivative\n\nG00Ik ,\u03b4 (1 \u2212 \u03b4) =\n\n\u03b4 2 gI00 (\u03b4)2\nk\nk(k\u22121)\n\n2\n\nand as seen before GIk ,\u03b4 (1 \u2212 \u03b4) = gIk (\u03b4) . We deduce that \u03bd > 0. Indeed,\n0\n\n\u03bd\u2265\n\nGIk ,\u03b4 (1 \u2212 \u03b4) G00Ik ,\u03b4 (1 \u2212 \u03b4) \u2212 GIk ,\u03b4 (1 \u2212 \u03b4)\n2\n\nGIk ,\u03b4 (1 \u2212 \u03b4)\n\n2\n\n=\n\n\u03b4 2 gI00k (\u03b4)\n\n2\n2\n\nk (k \u2212 1) gIk (\u03b4)\n\n>0\n\n. Finally :\n\u0012\n\n2\u03b4\n\u03b42\n\u03b4\n\u2212\n\u2212\n\u2212\n1\u2212\u03bc\n\u03bc\n1 \u2212 \u03b4 \u2212 \u03b4\u03bc\n\n0\n\n\u0013\n\nGIk ,\u03b4 (\u03bc) G00Ik ,\u03b4 (\u03bc) \u2212 GIk ,\u03b4 (\u03bc)\n\n2\n\n\u2264 \u2212\u03c1 + r.\u03bd\n2\nGIk ,\u03b4 (\u03bc)\n\u0001\nThe second derivative if then negative over [0, min 1, 1\u2212\u03b4\n] for every r < rI\u2217k = \u03c1/\u03bd.\n\u03b4\n+r\n\n\u0003\n\nAppendix C. Detailed proof of Lemma 1\nProof. \u03bc \u2208 [0, 1/2]: For \u03bc \u2208 [0, 1]he second derivative of \u2212 log t1/k (\u03bc) is negative and so is the\nsecond derivative of log (k \u2212 1 \u2212 \u03bc). This permits to conclude that \u03c4a0 (\u03bc) is decreasing. \u03c4a0 (1/2) =\nlog(2 k \u2212 3) \u2212 (2(k \u2212 2) log (k))/(2k \u2212 3) > 0 for every k > 3 . So \u03c4a0 (\u03bc) > 0 for \u03bc \u2208 [0, 1/2] and\nthen \u03c4a (\u03bc) is strictly increasing in the same \u0010interval.\n\u0001\u0011\n< 0 for every k > 3. Consequently\nIt is easy to check that \u03c40 (0.15) \u2212 2 k log \u03b31k , log k k1\nk\n\u0011\n\u0010\n\u0001\nlog \u03931k , 1 , log k (\u03bc) < 2 log \u03b31k , log k k1\nfor every \u03bc \u2208 [0, 0.15].\nk\nk\n\u0010 k\n\u0011\nSimilarly \u03c40.15 (0.5) \u2212 2 k log \u03b31k , log k (1/k) < 0 for any k > 3. Concluding that\nk\n\u0012\n\u0012 \u0013\u0013\n1\nlog \u03931k , 1 , log k (\u03bc) < 2 log \u03b31k , log k\nk\nk\nk\nk\nin the interval [0, 21 ].\n1\n1\n\u03bc \u2208 [1/2, 1[: The second derivative of \u2212k log t1/k (\u03bc) is \u2212 1\u2212\u03bc\n\u2212 k\u22121\u2212\u03bc\n\u2212 \u03bc2 . It can be checked\neasily that its third derivative is negative in [1/2, 1]. Then the first derivative of k log t1/k (\u03bc) is\nconcave. log G1k , k1 (\u03bc) have also the same properties.\n\n\fSECOND MOMENT METHOD FOR A FAMILY OF BOOLEAN CSP\n\n13\n\n\u00010\nThe value of \u2212k log t1/k (\u03bc) at the point \u03bc = 1/2 is log (2k \u2212 3). The line joining the points\n\u00010\n(1 \u2212 1/k, 0) to (1/2, log (2k \u2212 3)) bounds from below this first derivative. So k log t1/k (\u03bc) \u2265\nlog(2k\u22123)\n(\u03bc \u2212 1 + 1/k).\n1\n\u2212 12 + k\n\u0010\n\u00110\n(2\u2212k) log k\nSimilarly log k log G1k , k1 (\u03bc) \u2265 k\u2212\n(\u03bc \u2212 1 + 1/k).\n1\n1\n( 32 )(\u2212\n\u00122 + k )\n\u0013\n\u00110\n\u0010\n(2\u2212k) log k\nlog(2k\u22123)\nSumming up k log \u03931k , 1 , log k (\u03bc) \u2265\n+\n(\u03bc \u2212 1 + 1/k) \u2265 0 for \u03bc \u2208\n1\n\u2212 12 + k\n(k\u2212 32 )(\u2212 21 + k1 )\nk\nk\n[1/2, 1\u22121/k[. As a consequence: log \u03931k , 1 , log k (\u03bc) is increasing in this interval and then log \u03931k , 1 , log k (\u03bc) <\nk\nk\nk\nk\n\u03931k , 1 , log k (1 \u2212 1/k) = 2 log \u03b31k , log k (1/k) for \u03bc \u2208 [1/2, 1 \u2212 1/k[.\nk\nk\nk\nWe prove in the following that in this interval, k log \u03931k , 1 , log k (\u03bc) is strictly decreasing. As already\nk\nk\nseen the first derivative of \u2212k log t1/k (\u03bc) is concave and can be bounded from above by its tangent\n\u00010\nk3\nin 1 \u2212 1/k. Then k log t1/k (\u03bc) \u2264 \u2212 (k\u22121)\n2 (\u03bc \u2212 1 + 1/k). log k log G1k , 1 (\u03bc) have also the same\nk\n\u0010\n\u00110\n3\nk log k\nproperties log k log G1k , k1 (\u03bc) \u2264 (k\u22121)3 (\u03bc \u2212 1 + 1/k).\n\u00110\n\u0010\n\u0011\n\u0010\nlog k\nk3\nSumming up k log \u03931k , 1 , log k (\u03bc) \u2264 (k\u22121)\n\u2212\n1\n(\u03bc \u2212 1 + 1/k) < 0 for k \u2265 3. As a conse2\nk\u22121\nk\nk\n\u0010\n\u0011\nquence: log \u03931k , 1 , log k (\u03bc) < \u03931k , 1 , log k (1 \u2212 1/k) = 2 log \u03b31k , log k (1/k) for \u03bc \u2208]1 \u2212 1/k, 1].\n\u0003\nk\n\nk\n\nk\n\nk\n\nk\n\n(Y. Boufkhad) LIAFA, Universit\u00e9 Paris Diderot, CNRS UMR 7089\nParis, France\nE-mail address:\nYacine.Boufkhad@liafa.jussieu.fr\n(O. Dubois) LIP6, CNRS UMR7606, Universit\u00e9 Pierre et Marie Curie\nParis, France\nE-mail address:\nOlivier.Dubois@lip6.fr\n\n\f"}