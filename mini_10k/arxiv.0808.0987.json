{"id": "http://arxiv.org/abs/0808.0987v1", "guidislink": true, "updated": "2008-08-07T09:26:12Z", "updated_parsed": [2008, 8, 7, 9, 26, 12, 3, 220, 0], "published": "2008-08-07T09:26:12Z", "published_parsed": [2008, 8, 7, 9, 26, 12, 3, 220, 0], "title": "A new graph perspective on max-min fairness in Gaussian parallel\n  channels", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0808.3855%2C0808.4126%2C0808.1567%2C0808.0460%2C0808.2306%2C0808.4078%2C0808.0634%2C0808.3110%2C0808.0194%2C0808.0788%2C0808.1491%2C0808.2532%2C0808.1638%2C0808.2795%2C0808.2839%2C0808.2407%2C0808.1317%2C0808.2134%2C0808.3218%2C0808.1807%2C0808.3108%2C0808.2064%2C0808.2771%2C0808.2264%2C0808.3253%2C0808.0987%2C0808.2469%2C0808.2627%2C0808.3296%2C0808.4157%2C0808.1685%2C0808.3477%2C0808.3867%2C0808.0199%2C0808.2046%2C0808.0886%2C0808.3410%2C0808.1999%2C0808.2195%2C0808.3865%2C0808.2756%2C0808.1686%2C0808.2579%2C0808.3821%2C0808.3784%2C0808.0354%2C0808.2797%2C0808.1850%2C0808.2086%2C0808.4124%2C0808.2483%2C0808.1447%2C0808.0893%2C0808.2298%2C0808.0830%2C0808.0303%2C0808.2845%2C0808.3102%2C0808.1875%2C0808.3599%2C0808.1131%2C0808.2386%2C0808.3900%2C0808.3467%2C0808.1507%2C0808.2887%2C0808.2234%2C0808.0721%2C0808.2493%2C0808.0962%2C0808.3310%2C0808.1268%2C0808.3912%2C0808.1056%2C0808.1170%2C0808.0459%2C0808.4147%2C0808.3318%2C0808.1661%2C0808.0352%2C0808.2777%2C0808.4118%2C0808.0915%2C0808.3789%2C0808.3844%2C0808.1202%2C0808.2002%2C0808.1653%2C0808.4049%2C0808.1707%2C0808.2815%2C0808.0726%2C0808.2484%2C0808.2204%2C0808.2468%2C0808.2699%2C0808.0243%2C0808.1716%2C0808.1654%2C0808.3358%2C0808.1476&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "A new graph perspective on max-min fairness in Gaussian parallel\n  channels"}, "summary": "In this work we are concerned with the problem of achieving max-min fairness\nin Gaussian parallel channels with respect to a general performance function,\nincluding channel capacity or decoding reliability as special cases. As our\ncentral results, we characterize the laws which determine the value of the\nachievable max-min fair performance as a function of channel sharing policy and\npower allocation (to channels and users). In particular, we show that the\nmax-min fair performance behaves as a specialized version of the Lovasz\nfunction, or Delsarte bound, of a certain graph induced by channel sharing\ncombinatorics. We also prove that, in addition to such graph, merely a certain\n2-norm distance dependent on the allowable power allocations and used\nperformance functions, is sufficient for the characterization of max-min fair\nperformance up to some candidate interval. Our results show also a specific\nrole played by odd cycles in the graph induced by the channel sharing policy\nand we present an interesting relation between max-min fairness in parallel\nchannels and optimal throughput in an associated interference channel.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0808.3855%2C0808.4126%2C0808.1567%2C0808.0460%2C0808.2306%2C0808.4078%2C0808.0634%2C0808.3110%2C0808.0194%2C0808.0788%2C0808.1491%2C0808.2532%2C0808.1638%2C0808.2795%2C0808.2839%2C0808.2407%2C0808.1317%2C0808.2134%2C0808.3218%2C0808.1807%2C0808.3108%2C0808.2064%2C0808.2771%2C0808.2264%2C0808.3253%2C0808.0987%2C0808.2469%2C0808.2627%2C0808.3296%2C0808.4157%2C0808.1685%2C0808.3477%2C0808.3867%2C0808.0199%2C0808.2046%2C0808.0886%2C0808.3410%2C0808.1999%2C0808.2195%2C0808.3865%2C0808.2756%2C0808.1686%2C0808.2579%2C0808.3821%2C0808.3784%2C0808.0354%2C0808.2797%2C0808.1850%2C0808.2086%2C0808.4124%2C0808.2483%2C0808.1447%2C0808.0893%2C0808.2298%2C0808.0830%2C0808.0303%2C0808.2845%2C0808.3102%2C0808.1875%2C0808.3599%2C0808.1131%2C0808.2386%2C0808.3900%2C0808.3467%2C0808.1507%2C0808.2887%2C0808.2234%2C0808.0721%2C0808.2493%2C0808.0962%2C0808.3310%2C0808.1268%2C0808.3912%2C0808.1056%2C0808.1170%2C0808.0459%2C0808.4147%2C0808.3318%2C0808.1661%2C0808.0352%2C0808.2777%2C0808.4118%2C0808.0915%2C0808.3789%2C0808.3844%2C0808.1202%2C0808.2002%2C0808.1653%2C0808.4049%2C0808.1707%2C0808.2815%2C0808.0726%2C0808.2484%2C0808.2204%2C0808.2468%2C0808.2699%2C0808.0243%2C0808.1716%2C0808.1654%2C0808.3358%2C0808.1476&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "In this work we are concerned with the problem of achieving max-min fairness\nin Gaussian parallel channels with respect to a general performance function,\nincluding channel capacity or decoding reliability as special cases. As our\ncentral results, we characterize the laws which determine the value of the\nachievable max-min fair performance as a function of channel sharing policy and\npower allocation (to channels and users). In particular, we show that the\nmax-min fair performance behaves as a specialized version of the Lovasz\nfunction, or Delsarte bound, of a certain graph induced by channel sharing\ncombinatorics. We also prove that, in addition to such graph, merely a certain\n2-norm distance dependent on the allowable power allocations and used\nperformance functions, is sufficient for the characterization of max-min fair\nperformance up to some candidate interval. Our results show also a specific\nrole played by odd cycles in the graph induced by the channel sharing policy\nand we present an interesting relation between max-min fairness in parallel\nchannels and optimal throughput in an associated interference channel."}, "authors": ["Marcin Wiczanowski", "Holger Boche"], "author_detail": {"name": "Holger Boche"}, "author": "Holger Boche", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/ISITA.2008.4895521", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0808.0987v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0808.0987v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "41 pages, 8 figures. submitted to IEEE Transactions on Information\n  Theory on August the 6th, 2008", "arxiv_primary_category": {"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.DM", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.CO", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.IT", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0808.0987v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0808.0987v1", "journal_reference": null, "doi": "10.1109/ISITA.2008.4895521", "fulltext": "A new graph perspective on max-min\nfairness in Gaussian parallel channels\n\narXiv:0808.0987v1 [cs.IT] 7 Aug 2008\n\nMarcin Wiczanowski\u2020 , Holger Boche\u2217\u2020\n\u2217\nHeinrich-Hertz Group for Mobile Communications, EECS,\nBerlin University of Technology, Einsteinufer 25, 10587 Berlin, Germany\n\u2020\nFraunhofer German-Sino Lab for Mobile Communications (MCI)\nEinsteinufer 37, 10587 Berlin, Germany\nEmail: {marcin.wiczanowski,boche}@hhi.fraunhofer.de\nPhone: +4930-314-28462, Fax: +4930-314-28320\n\nSubmitted to IEEE Transactions on Information Theory, August the 6th, 2008\n\nAbstract\nIn this work we are concerned with the problem of achieving max-min fairness in Gaussian\nparallel channels with respect to a general performance function, including channel capacity or\ndecoding reliability as special cases. As our central results, we characterize the laws which determine\nthe value of the achievable max-min fair performance as a function of channel sharing policy and\npower allocation (to channels and users). In particular, we show that the max-min fair performance\nbehaves as a specialized version of the Lovasz function, or Delsarte bound, of a certain graph\ninduced by channel sharing combinatorics. We also prove that, in addition to such graph, merely\na certain 2-norm distance dependent on the allowable power allocations and used performance\nfunctions, is sufficient for the characterization of max-min fair performance up to some candidate\ninterval. Our results show also a specific role played by odd cycles in the graph induced by the\nchannel sharing policy and we present an interesting relation between max-min fairness in parallel\nchannels and optimal throughput in an associated interference channel.\nIndex Terms\nLovasz function, Delsarte bound, parallel channels, max-min fairness, graphs\n\nI. I NTRODUCTION\nFairness represents an important goal in the design of power, bandwidth and time allocation\npolicies for multi-user channels. It is usually desired to achieve fairness with respect to communications and information theory metrics, such as spectral efficiency, decoder reliability,\netc. [1], [2]. The mostly used notion of fairness is the max-min fairness, which is an instance\nof equity in terms of economy markets and consists in the maximal possible improvement\nof the worst performance metric [3] [4], [5].\nThe single-user communication over parallel channels is a well-studied topic both from the\nviewpoint of information theoretic optimality as well as suboptimal practical power allocation\napproaches, see e.g. [6], [7], [8], [9], [10] and references therein. However, the max-min fair\nallocation of power, bandwidth and time to multiple users sharing the parallel channels access\nstill poses practical problems and needs a deeper understanding [1], [11]. The issue of maxmin fairness in (multi-user) parallel channels has been addressed in [11], [12], [13], [14] and\nreferences therein. Concurrently, a cellular downlink or uplink using Orthogonal Frequency\nDivision Multiplex (OFDM) appears to be the most relevant example of parallel channels\nshared among multiple users. In [11], the max-min fair carrier and antenna assignment is\nstudied for a multiple antenna OFDM downlink. More generally, in [12], [13] the performance\n\n\fof max-min fair power allocation and max-min fair assignment of parallel channels is\ncharacterized within the framework of so-called blocking and antiblocking polyhedra [15],\n[16]. The characterization of user performance achieved under max-min fairness is provided\nin [12], [13] in the form of bounds and duality-like optimization problems.\nSeveral important aspect of the fairness problem in parallel channels, such as e.g. the\noptimum interrelations between the combinatorics of channel sharing and the real-valued\npower allocation, are still open in the general case. Also the essential straight questions such\nas \"what is the user performance under max-min fairness in parallel channels equal to?\" or\n\"what is the power/time/bandwidth function describing it?\" remain unanswered so far. In\nthis work we make a step towards satisfying answers to the above questions in Gaussian\nparallel channels, when the interest is in max-min fairness with respect to user performance\nmeasured by a general performance/QoS function; this includes the most celebrated cases\nof channel capacity, spectral efficiency, decoder reliability (unity minus decoder error rate),\netc. We state insightful optimistic and pessimistic bounds on the user performance (Sections\nIV, V). The essence of our results is that, under constraints on transmit power, the maxmin fair performance behaves as a specialized version of the Lovasz function [17], [18] of a\nspecific graph, which is induced by the channel sharing topology, or combinatorics. We prove\nfurther that, in addition to such graph description, a certain 2-norm distance dependent on\nthe allowable power allocations and users' performance functions is sufficient for enclosing\nthe max-min fair performance by some lower and upper bounds. These bounds prove to be\nespecially insightful as they offer a separation of influences of the channel sharing policy\nand the real-valued problem of power allocation. We aid the interpretations of the introduced\nchannel sharing topologies and the proposed bounds by several parallel channel examples\nand visualizations.\nOur results exhibit a specific role of odd cycles in the graph induced by the channel sharing\npolicy. We present also an interesting relation between max-min fairness in parallel channels\nand optimal throughput in an associated interference channel. Furthermore, the presented\nbounds show a link between the user performance under max-min fairness and (zero-error)\ngraph capacity [19], [17]. The proofs of our results are constructive and allow for the design of\nseveral novel power and time allocation algorithms for parallel channels with predetermined\nchannel sharing topology; this can be motivated by regulations on processing of traffic\nclasses or standardization/hardware constraints (Section VI). The proposed algorithms offer\na better performance-complexity trade off than conventional solution methods and achieve\nuser performance within some specified distance from the max-min fairness.\nII. M ODEL AND P RELIMINARIES\nWe consider the set of Gaussian (in the sense of Additive-White-Gaussian-Noise) parallel\nchannels, treated as one multi-user channel1 . The transmitter-receiver pairs communicating\nwith each other over this channel are referred to abstractly as users and are grouped in the set\nK = {1, . . . , K}. The parallel channels are assumed to be deterministic and frequency-flat.\nNotation: The nonnegative and positive orthants in RK\u00d7N , where we set RK\u00d71 = RK and CK\u00d71 = CK , are denoted\nK\nwe denote the set of symmetric matrices in RK\u00d7K and the cones of doubly\nand RK\u00d7N\nas RK\u00d7N\n++ , respectively. By S\n+\nnonnegative matrices and completely positive matrices in RK\u00d7K are denoted as DK and PK , respectively (see Appendix\nA for the definitions). By S\u01eb (X) we denote a ball with radius \u01eb centered at X \u2208 CK\u00d7N . By \u0017 we denote the usual partial\norder on the set of symmetric matrices and X \u25e6 Y , denotes the Kronecker product of X, Y \u2208 CK\u00d7N . For any vector\nx = (x1 , . . . , xK ) \u2208 CK we define (x)k = xk . Given a matrix X \u2208 CK\u00d7N with elements xkl , 1 \u2264 k \u2264 K, 1 \u2264 l \u2264 N ,\nwe write simply X = (xkl ) and define similarly (X )kl = xkl . By X \u2032 we denote the conjugate transpose of X \u2208 CK\u00d7N .\nGiven X \u2208 CK\u00d7K , diag(X) \u2208 CK\u00d7K is such that (diag(X))kk = (X )kk and (diag(X ))kl = 0, k 6= l, 1 \u2264 k, l \u2264 K.\n1\n1\n\u221a\nFurther, given x = (x1 , . . . , xK ) \u2208 RK\nxk . The identity matrix is denoted by I,\n+ , a vector x 2 is defined as (x 2 )k =\nek is the unit vector such that (ek )k = 1 and (ek )l = 0, k 6= l, and we also define vector 1 as (1)k = 1, where in all\nthree cases the matrix/vector dimension follows from the context. By hx, yi we denote the inner product of x, y \u2208 CK .\nWithout introducing ambiguity, we do not differ in the notation between random values and deterministic values. The mean\nof a random matrix (variable) X \u2208 CK\u00d7N is denoted as E(X).\n1\n\n\fA. The parallel channels\nThe set of parallel channels is denoted as N = {1, . . . , N}. Let xk = (xk1 , . . . , xkN ) \u2208 CN\nbe a random vector grouping the independent (zero-mean) symbols of user k \u2208 K transmitted\nover the channels n \u2208 N equidistantly, at distance Ts . Then, the sampled signal of user k \u2208 K\nreceived over the parallel channels can be written as y k = (yk1, . . . , ykN ), with\nykn = hkn xkn + nkn ,\n\nn \u2208 N,\n\nwhere hk = (hk1 , . . . , hkN ) \u2208 CN collects the path coefficients between the transmitter and\nreceiver of user k \u2208 K on channels n \u2208 N and nk = (nk1 , . . . , nkN ) \u2208 CN is a random\nvector which contains (zero-mean, independent of xk ) Gaussian noise variables perceived at\n2\nthe receiver of user k \u2208 K on channels n \u2208 N , where we assume \u03c3kn\n= E(|nkn |2 ) > 0. The\ntransmit power allocation to users and channels (in short, power allocation) can be written as\nP = (p1 , . . . , pK )\u2032 \u2208 RK\u00d7N\n, where vector pk = (pk1 , . . . , pkN ) is such that pkn = E(|xkn |2 )\n+\nis the transmit power allocated to user k \u2208 K on channel n \u2208 N .\nLet A = (a1 , . . . , aK )\u2032 \u2208 RK\u00d7N\ndenote the sharing matrix of the channels among users\n+\nsuch that ak = (ak1 , . . . , akN ) collects the relative fractions of time which are assigned to\nuser k \u2208 K for the exclusive access to channels n \u2208 N . Thus, as in practice the operation\ntime is partitioned into frames of some fixed duration T \u226b Ts , the collection of times T ak\nis reserved for user k \u2208 K for the exclusive access to the respective channels n \u2208 N within\neach frame. The set of allowed sharing matrices of the parallel channels takes the form\nX\nA(r) = {A \u2208 RK\u00d7N\n:\nka\nk\n\u2264\nr\n,\nk\n\u2208\nK,\n(\nakn ) \u2264 1, n \u2208 N }, r \u2208 RK\n(1)\nk 1\nk\n+\n++ .\nk\u2208K\n\nAccording to the first constraint in (1), a predefined vector r = (r1 , . . . , rK ) \u2208 RK\n++ , with\nkrk1 \u2264 N, is such that rk /N represents the fraction of the set of parallel channels which\nis assigned to user k \u2208 K over time (over each frame). It proves useful in the remainder\nto introduce also R \u2208 RK\u00d7K\nsuch that (R)kl = 0, k 6= l, and (R)kk = rk , k, l \u2208 K. For\n+\nN\ninstance, under r = K 1 any user is assigned an equal 1/K-fraction of the ensemble of\nparallel channels over time (over each frame). The second inequality in the definition (1)\nmodels then the obvious constraint that the aggregate time of exclusive uses of a single\nchannel n \u2208 N by the users k \u2208 K does not exceed the total operation time (the total\nduration of each frame). Currently, the most celebrated instance of the considered parallel\nchannels is the multi-tone/multi-carrier channel accessed by multiple users, as considered\ne.g. in [20], [21]. In this case, ak groups user's k \u2208 K relative times of exclusive uses of\ncarriers n \u2208 N and rk /N represents the fraction of the multi-carrier spectrum which he is\nassigned over time [22].\nGiven a sharing matrix A \u2208 A(G, r) under use, we assume an arbitrary set P(A) of\nallowed power allocations, requiring merely that\nP(A) \u2287 (S\u01eb (0) \u2229 RK\u00d7N\n),\n+\n\nfor some \u01eb > 0,\n\n\u01eb = \u01eb(A),\n\n(2)\n\nSuch condition means, broadly, that all power allocations which are sufficiently small for\nthe used sharing matrix are allowable. In particular, assuming frames of duration T , we can\ntake either of the sets\nX\nT hak , pk i \u2264 E}, A \u2208 A(r),\n(3a)\nP(A) = {P \u2208 RK\u00d7N\n:\n+\nk\u2208K\n\nP(A) = {P \u2208\n\nRK\u00d7N\n+\n\n: T hak , pk i \u2264 Ek ,\n\nk \u2208 K},\n\nA \u2208 A(r),\n\n(3b)\n\nfor some E, Ek > 0, k \u2208 K, which mirror the limitations of energy per frame as a crucial\nconstraint in current and future wireless communication systems [23], [24]. The latter set\ncorresponds to conventional limitations of energy per frame in a multi-user Gaussian channel\nwith user energy per frame budgets constrained by Ek , k \u2208 K. The first set models the\n\n\fpossibility of energy coordination among all users under the joint energy per frame budget\nconstrained by E. This is the case, for instance, when the considered parallel channels are a\nmeans of representation of the orthogonalized broadcast channel which applies, suboptimally,\nsingle-user precoding instead of multi-user precoding [25], [26] (for the combination of\nparallel channels and the broadcast channel see also [27]).\nComplementarily to frame energy constraints it is sometimes desired to account for transmit\npower constraints at any time in a frame. In analogy to (3), under limitation of transmit\npower of any user k \u2208 K by Pk > 0 and under the joint transmit power budget of all users\nconstrained by P > 0 we take, respectively,\nP(A) = P = {P \u2208 RK\u00d7N\n: |||P |||1 \u2264 P },\n+\n\nP(A) = P = {P \u2208 RK\u00d7N\n: kpk k1 \u2264 Pk ,\n+\n\n(4a)\nk \u2208 K}.\n\n(4b)\n\nIt is interesting to note that transmit power constraints at any time within a frame make\nthe set of allowable power allocations independent of sharing matrix A \u2208 A(r) under use,\nwhich will be of key importance at several points in the remainder.\nB. The user performance\nFor any user k \u2208 K accessing the parallel channels, we assume a general vector-valued\nperformance/ QoS function\np 7\u2192 fk (p) \u2208 RN ,\n\np \u2208 RN\n+,\n\nwhere we have fk (p) = (fk1 (p1 ), . . . , fkN (pN )), with p 7\u2192 fkn (p), p \u2265 0, n \u2208 N . Function\nfkn expresses the performance of user k \u2208 K on channel n \u2208 N , as a function of power\nallocated to channel n \u2208 N , when the user accesses this channel exclusively throughout the\noperation time. We restrict us to nonnegative QoS functions\nfk (p) \u2208 RN\n+,\n\np \u2208 RN\n+,\n\nk \u2208 K,\n\n(5)\n\nand to avoid later technical queerness we assume that \u2202p\u2202k fk (p) > 0, k \u2208 K, for p \u2208\nS\u01eb (0) \u2229 RK\n+ and some \u01eb > 0 (that is, performance functions are componentwise Frechetdifferentiable and increasing at least for sufficiently small power allocations).\nDue to (5) and the assumed independent symbols of a user on each one of the parallel\nchannels, it is reasonable to consider\n(a, p) 7\u2192 ha, fk (p)i,\n\nN\n(a, p) \u2208 RN\n+ \u00d7 R+ ,\n\nkak1 \u2264 rk ,\n\nas the performance/QoS metric of user k \u2208 K. Such metric represents the aggregate performance achieved by user k \u2208 K on the entire channel ensemble, throughout the operation time\n(throughout each frame), as a function of powers allocated to channels n \u2208 N and relative\ntime fractions of exclusive channel uses. We refer to a value of the performance metric of a\nuser, for some A \u2208 A(r) and P \u2208 P(A), as user performance under policy (A, P ).\nLet any predefined requirement/expectation of user k \u2208 K with respect to the user performance be denoted as \u03b3k > 0, k \u2208 K. Then, mink\u2208K hak ,f\u03b3kk(pk )i can be seen as the\nworst relative performance among the users accessing the parallel channels under a policy\n(A, P ) \u2208 A(r) \u00d7 P(A). Hereby, we implicitly assume that a smaller user performance\nimplies a worse perceived service quality at the corresponding receiver. Such assumption\ncomplies with the nature of the very most QoS functions used in communications and\ninformation theory, but does not necessarily require strict componentwise increasingness\nof fk , k \u2208 K. We give a few celebrated examples of such performance functions.\n\n\fExample 1 (Symbol decoding reliability): Let user k \u2208 K access channel n \u2208 N and use\nuncoded constant-envelope modulation. Then, the achieved probability of error-free symbol\ndecoding is\ns\nc p|hkn |2\nfkn (p) = 1 \u2212 Q(\n),\n(6)\n2\nlog2 M \u03c3kn\nwith Q denoting the Marcum Q-function, M denoting the constellation size, and c > 0 as\nsome constant (e.g., c = 2 for binary Phase Shift Keying or c = 1 for binary Frequency Shift\nKeying) [28]. By (6) and the uniform symbol distance Ts , the map (ak , pk ) 7\u2192 TTs hak , fk (pk )i,\n(A, P ) \u2208 A(r) \u00d7 P(A), expresses the aggregate (over channels n \u2208 N ) average number of\nerror-free decoded symbols of user k \u2208 K in a frame as a function of policy.\nExample 2 (Mean square detection reliability): If the receiver of user k \u2208 K utilizes the\nMinimum Mean Square Error (MSE) receiver and the user accesses channel n \u2208 N , then\nthe achieved MSE can be expressed as pkn1|hkn |2 [29]. As a consequence,\n1+\n\n\u03c32\nkn\n\nfkn (p) = 1 \u2212\n\n1\n1+\n\np|hkn |2\n2\n\u03c3kn\n\n,\n\n(7)\n\ncan be regarded as a kind of symbol detection reliability in the mean square sense. Thus,\ngiven (7), (ak , pk ) 7\u2192 TTs hak , fk (pk )i, (A, P ) \u2208 A(r) \u00d7 P(A), describes the mean square\ndetection reliability of user k \u2208 K, aggregated over all symbols received in a frame, as a\nfunction of policy.\nExample 3 (Spectral efficiency): Let the modulation constellation size of user k \u2208 K\nwhich accesses channel n \u2208 N be constrained by M. The spectral efficiency, in the sense\nof maximum number of reliably decodable bits/nats per symbols under given modulation\nconstellation3, is not expressible analytically but can be approximated by a function\np|hkn |2\nfkn (p) = g( 2 )\n\u03c3kn\nsuch that the map x 7\u2192 g(x), x \u2265 0, is nondecreasing, and g(0) = 0 and g(x) = log2 M,\nx \u2265 x0 , for some x0 = x0 (M) [8]. Then, it is easily seen that map (ak , pk ) 7\u2192 TTs hak , fk (pk )i,\n(A, P ) \u2208 A(r) \u00d7 P(A), describes the achievable number of reliably decoded bits/nats in a\nframe, as a function of policy.\nExample 4 (Capacity): If user k \u2208 K utilizes the Maximum Likelihood (ML) receiver,\nthen\np|hkn |2\nfkn (p) = log(1 +\n)\n(8)\n2\n\u03c3kn\nrepresents the (information) capacity3 , achievable by user k \u2208 K when accessing the channel\nn \u2208 N , that is, the overall maximum number of reliably decodable bits/nats per symbol. Thus,\ngiven (8), the function (ak , pk ) 7\u2192 TTs hak , fk (pk )i, (A, P ) \u2208 A(r) \u00d7 P(A), corresponds to\nthe achievable (under Gaussian codebook) number of reliably decoded bits/nats per frame.\nWith the given assumptions on user performance, the maximum attainable performance of\nthe worst-case user accessing the parallel channels among policies from A(r) \u00d7 P can be\nexpressed as\nhak , fk (pk )i\nmax\nmin\n.\n(9)\n(A,P )\u2208A(r)\u00d7P(A) k\u2208K\n\u03b3k\nAccording to the common understanding of fairness in various multi-user channels, see e.g.\n[1], [2], [11], [14], we refer to (9) as the max-min fair performance (in/of the considered parallel channels), and we say that a pair (A, P ) = arg max(A,P )\u2208A(r)\u00d7P(A) mink\u2208K hak ,f\u03b3kk(pk )i ,\nis a max-min fair policy, which is, in general, not unique.\n3\n\nObviously, the notions of spectral efficiency and capacity are meaningful only when the duration of the considered\nchannel access is sufficiently long, in the sense T akn \u226b Ts .\n\n\fIII. G RAPH OF PARALLEL CHANNELS SHARING\nFor any sharing matrix A \u2208 A(r) we define an undirected graph of parallel channels\nsharing, in short a sharing graph, which is induced by A. For the definition, recall that any\ngraph is a pair, say G = (K, E), where K is the set of graph vertices, and E is the set of\nedges; any edge is represented by a pair (k, l) \u2208 E such that k, l \u2208 K are the vertices which\nare joined/connected by this edge (are adjacent) [30].\nDefinition 1: For N \u2265 K and any A \u2208 A(r), a corresponding sharing graph G = G(A)\nis such that G = (K, E) where (k, l) \u2208 E, k 6= l, if hak , al i > 0.\nThe proposed induction of a sharing graph G by A is a version of orthogonal graph\nlabeling from [31], which further differs slightly from the original concept of orthonormal\nrepresentation of a graph in [17]. Precisely, a (not necessarily nonnegative) matrix A \u2208 RK\u00d7N\nis referred to as an orthonormal representation of graph G = G(A) = (K, E), which we write\nas A \u2208 A0 (G), if hak , ak i = 1, k \u2208 K, and (k, l) \u2208 E, k 6= l, whenever hak , al i =\n6 0. By\nDefinition 1, any two vertices k, l \u2208 K, k 6= l, of the sharing graph are adjacent if some of\nthe parallel channels are shared by users k, l, where a channel is said to be shared by some\ntwo users if both users access this channel exclusively some fraction of time. The converse\nis also clear: If two nodes k, l \u2208 K, k 6= l, of the sharing graph are nonadjacent, then no one\nof the channels n \u2208 N is shared by users k, l.\nIt is readily seen that, for any fixed A \u2208 A(r), an induced sharing graph G = G(A) is\nin general not unique. Besides this, the graph characterization of parallel channels sharing\nprovides merely the information on the topology, or combinatorics, of sharing relationships.\nThus, given any graph G = (K, E), different sharing matrices induce G as a sharing graph\nand we can group them in the set\nA(G, r) = {A \u2208 A(r) :\n\nG = G(A)},\n\nr \u2208 RK\n++ .\n\nThe illustration is provided in the following example.\nExample 5: Consider parallel channels as a multi-tone/multi-carrier channel with N = 7\ntones accessed by K = 4 users in the proportions r = (2, 2, 1, 2). Let the sharing of the\ntones be described by the sharing matrix\n\uf8f6\n\uf8eb\n0 0.2 0 0.5 0.5 0 0.8\n\uf8ec 1 0\n0 0.5 0.5 0\n0 \uf8f7\n\uf8f7 \u2208 A(2, 2, 1, 2),\nA=\uf8ec\n\uf8ed 0 0.3 0.3 0\n0 0.3 0.1 \uf8f8\n0 0.5 0.7 0\n0 0.7 0.1\n\nThen, the three possible sharing graphs G = G(A) are depicted in Fig. 1, with the graph\non the right hand side as the sharing graph with the minimal number of edges. On the other\nhand, for G as the minimum sharing graph from Fig. 1, the set A(G, (2, 2, 1, 2)) of sharing\nmatrices inducing it includes, in particular, column permutations of all matrices of the form\n\uf8f6\n\uf8eb\n0 a12 0 a14 a15 0 a17\n\uf8ec a21 0\n0 a24 a25 0\n0 \uf8f7\n\uf8f7,\nA=\uf8ec\n\uf8ed 0 a32 a33 0\n0 a36 a37 \uf8f8\n0 a42 a43 0\n0 a46 a47\n\nwith aij > 0, 1 \u2264 i \u2264 4, 1 \u2264 j \u2264 7.\nA special role in our considerations of sharing graphs is played by the subgraphs called\ncycles.\nDefinition 2 ([30], [32]): A cycle of length M in a graph G = (K, E) is a sequence of\ndistinct graph vertices ki \u2208 K, 1 \u2264 i \u2264 M, which satisfy (ki , ki+1 ) \u2208 E, 1 \u2264 i \u2264 M \u2212 1 and\n(kM , k1 ) \u2208 E.\n\n\f2\n\n2\n\n1\n\n3\n\n1\n\n2\n\n3\n\n1\n\n3\n\n4\n\n4\n\n4\n\nG = (K, E)\n\nG = (K, E)\n\nG = (K, E)\n\nFig. 1. Three sharing graphs of the multi-carrier channel with K = 4 users considered in Example 5; such graphs are\ninduced, in the sense G = G(A), by the matrices A from Example 5.\n\nG = (K, E)\n\nG = (K, E)\n\nFig. 2. Two exemplary sharing graphs of parallel channels with K = 7 and K = 12 users with marked exemplary cycles\nof length 3 (dotted edges), 4 (dash-dotted edges) and 5 (dashed edges).\n\nIn simple words, a cycle represents a simple closed path in a graph2 . Note that the length\nof a cycle is the number of edges, or equivalently vertices, constituting the cycle. As an\nillustration, in Fig. 2 particular cycles are emphasized in two exemplary sharing graphs. A\ncycle of a sharing graph has an easy interpretation in terms of sharing policies: A cycle of\nlength, say, M corresponds to a chain/sequence of M users accessing the parallel channels\nsuch that any pair of subsequent users shares some channel and the last user shares a channel\nwith the first user.\nIn Fig. 3 we show examples of M-partite sharing graphs for M = 2, 3, 4. As can be seen\nfrom the figure, such graphs contain only edges between some disjoint vertex subsets: The\nvertex set of an M-partite graph G = (K, E) is divided into partitions Ki , 1 \u2264 i \u2264 M, such\nthat (k, l) \u2208\n/ E whenever k, l \u2208 Ki , 1 \u2264 i \u2264 M. It is easily deduced that an M-partite graph\ncan not contain any cycle longer than M. An M-partite sharing graph is induced by sharing\npolicies of parallel channels which distinguish M classes of users with the property that\nusers within one class are not allowed, or not able, to share any channels over time. Such\nconstraint is likely to be imposed by traffic processing regulations and/or the implementation\n2\n\nIn the context of undirected graphs, some works prefer the notion of a circuit to the notion of a cycle used here. In\nsuch a convention, the cycle is understood as the analog to the circuit in directed graphs.\n\n\f3\n\nK2\n4\n\nK2\n\n5\n5\nK2\n\nK3\n\nK1\n\n4\nK3\n\n3\n\n6\n\n7\n\n1\n\nK1\nG = (K, E)\n\n2\n\n1\n\nK1\n\n2\n\nG = (K, E)\n\nK4\nG = (K, E)\n\nFig. 3. Three exemplary M -partite sharing graphs of parallel channels with K = 5, 7, 12 users and for M = 2, 3, 4,\nrespectively. The graph on the left-hand side is a sharing graph of the multi-carrier channel from Example 6 and is induced\n(in the sense G = G(A)) in particular by the matrix A from Example 6. The graph in the middle can be a sharing graph\nof the multi-carrier channel considered in Example 7.\n\neffort, as is illustrated by the following examples.\nExample 6: Consider parallel channels as a multi-carrier channel with N = 9 carriers and\nK = 5 users accessing the carrier set in the proportions r = (2, 2, 0.5, 1.5, 3) and having a\ncommon transmitter. Let the traffic of users 1, 2 \u2208 K1 be the real-time traffic, like voice or\nmultimedia, while users 3, 4, 5 \u2208 K2 transmit and receive so-called background traffic, such\nas file transfer, signaling or system information. From the viewpoint of percepted QoS and\ntraffic processing complexity, it may be required to assign a carrier to real-time traffic for\na large relative time fraction, say, no less than half of the total time, so that no carrier can\nbe shared by two real-time users. Due to the processing effort, it may be also undesired to\nshare a carrier between multiple users carrying the minor background traffic. These conditions\nenforce that the single carriers are either user-specific or carry mostly the real-time traffic\nof users K1 with some add-on background traffic of users K2 from time to time. Thus, an\nexemplary sharing matrix can take the form\n\uf8f6\n\uf8eb\n0 0.75 0.8 0.7 0 0 0 0.75 0\n0\n0 0.6 0 0 0 0.8 \uf8f7\n\uf8ec 0.6 0\n\uf8f7\n\uf8ec\n0\n0\n0\n0 0 0 0.25 0 \uf8f7 \u2208 A(3, 2, 0.25, 1.25, 2.5),\nA=\uf8ec 0\n\uf8ed 0 0.25 0\n0\n0 1 0 0\n0 \uf8f8\n0.4 0 0.2 0.3 0.4 0 1 0 0.2\nwhich induces the bipartite sharing graph G = G(A) on the left hand side of Fig. 3.\nExample 7: Let a multi-carrier channel with N = 13 carriers accessed by K = 7 users\nin the proportions r = (3, 2, 2, 1, 1, 3, 1) be the considered parallel channels with a common\nreceiver. Let the users be grouped in classes 1, 2 \u2208 K1 , 3, 4, 5 \u2208 K2 and 6, 7 \u2208 K3 such that for\nany two users within one class the difference between their propagation times is larger than\nsome critical propagation time difference (note that such classification is not always possible).\nThen, the sharing of a carrier between two users from one class can be undesired due to the\nrequired effort of time- and frequency synchronization to come up with the propagation time\ndifference. This implies that the carriers are either user-specific or shared only across the\nclasses K1 , K2 , K3 , and that a particular sharing matrix A \u2208 A(3, 2, 2, 1, 1, 3, 1) can induce\nthe 3-partite sharing graph G = G(A) in the middle of Fig. 3.\n\n\fAs shown in the remainder, the description of the channel sharing topology by a sharing\ngraph plays a key role in the problem of ensuring max-min fairness (9).\nA. Selected algebraic graph characterizations\nWe make use of the description of a graph by its so-called feasible matrix, which is a\nsymmetric matrix indicating an edge by a nonzero entry [33], [34], [35], [36]: The set of\nfeasible matrices of a graph G = (K, E) is\nC(G) = {C = (ckl ) \u2208 SK : ckl 6= 0, k 6= l,\n\niff (k, l) \u2208 E}.\n\nGiven G, another set of interest here is parameterized by a vector v \u2208 RK\n+ of its vertex\nweights and can be written as\n1\n\nB0 (G, v) = {B = (bkl ) \u2208 SK : bkl = (vk vl ) 2 ,\n\n(k, l) \u2208\n/ E or k = l}.\n\n(10)\n\nFor v = 1, this concept has its origin in the seminal work [17] where it was used in an\napproach to the problem of graph capacity. The generalization to the case v \u2208 RK\n+ was\nprovided later in the study of relaxations of the vertex packing problem [18]). The graph\ncapacity problem, as the key problem of zero-error information theory, remains still unsolved\nin the general case [19]. The set (10) is, however, a central element of the concept of socalled weighted Lovasz function, which in unweighted form (i.e. for v = 1) represents a\ngeneral upper bound on graph capacity and is equal to the capacity for a certain graph\nclass, including e.g. self-complementary graphs with vertex-transitive automorphism groups\n[17], [30]. Precisely, the weighted Lovasz function (later, simply Lovasz function) of a graph\nG = (K, E) is defined as the map\nvk\n(G, v) 7\u2192 \u03b80 (G, v) =\nmin\nmax\n, v \u2208 RK\n(11)\n+,\nA\u2208A0 (G), k\u2208K hak , ci2\nc\u2208RL :kck2 =1\n\nwith A0 (G) as the set of orthonormal representations of G, and it has the following property.\nProposition 1 ([18], [31]): For any graph G = (K, E), we have\n\u03b80 (G, v) =\n\nmin\n\nB\u2208B0 (G,v)\n\n\u03bbmax (B),\n\nv \u2208 RK\n+.\n\nIn [18], [31], [37] one can find further interesting characterizations of the Lovasz function.\nA similar set which we make use of is\n1\n\nB1 (G, v) = {B = (bkl ) \u2208 SK : bkl \u2265 (vk vl ) 2 ,\n\n(k, l) \u2208\n/ E or k = l},\n\n(12)\n\nfor any graph G = (K, E) and v \u2208 RK\n+ is a vector of its vertex weights. For the case v = 1,\nthe concept of the set (12) is known from the considerations on the Delsarte bound, or\nDelsarte number, in [38], and the generalization to the case v \u2208 RK\n+ is straightforward. The\nunweighted (i.e. for v = 1) Delsarte bound was proposed within the algebraic framework\nof coding theory in [39], as an upper bound on the cardinality of an M-clique, M \u2282\n{1, . . . , M}, in an association scheme with M associate classes denoted here as (K, {Ei }M\ni=1 ).\nAs the notion of association scheme is only loosely related with our topic, we refer here\nto Appendix B for an outline of the theory. One can relate the Delsarte bound for an\nM\nassociation scheme (K, {Ei }M\ni=1 ) to the graph G = (K, E), \u222ai=1 Ei , i.e. the graph whose edge\nset corresponds to the union of associate classes: The unweighted Delsarte number upper\nbounds the independence number of such graph [38] and the weighted Delsarte number (later,\nsimply Delsarte number/bound), denoted as map \u03b81 , has then the following characterization.\nProposition 2 ([38]): For any graph G = (K, E), we have\n\u03b81 (G, v) =\n\nmin\n\nB\u2208B1 (G,v)\n\n\u03bbmax (B),\n\nv \u2208 RK\n+.\n\n\fFurther formulations of the Delsarte number which are direct analogs of the original characterizations of the Lovasz function from [17] can be found, partly without proof, in [40]\nand [41]. In particular, the authors apply the framework of graph Laplacians and identify\nthe Delsarte number with the so-called \u03c3-function of a graph and the Lovasz function with\na related version of it. Similar characterizations of the Lovasz function and Delsarte bound\nand their properties in terms of edge orbits are studied in [42].\nFor our purposes, we define two further sets of the type (10), (12) and two related graph\nfunctions in the spirit of Propositions 1 and 2. First, we associate with a graph G = (K, E)\nand a weight vector v \u2208 RK\n+ , the set\n1\n\nB2 (G, v) = {B = (bkl ) \u2208 SK : bkl = (vk vl ) 2 ,\n\n(k, l) \u2208\n/ E or k = l,\n\n1\n2\n\nk, l \u2208 K}.\n\nbkl \u2264 (vk vl ) ,\n\n(13)\n\nIn analogy to Proposition 1, we define for any graph G the map\n(G, v) 7\u2192 \u03b82 (G, v) =\n\nmin\n\nB\u2208B2 (G,v)\n\n\u03bbmax (B),\n\nv \u2208 RK\n+.\n\n(14)\n\nSecond, also the set\n1\n\nB3 (G, v) = {B = (bkl ) \u2208 SK : bkl = (vk vl ) 2 ,\n1\n2\n\nv v\n\n1\u2032\n2\n\n(k, l) \u2208\n/ E or k = l\n\n\u2212 B + \u03bbmax (B)I \u2208 PK }\n\n(15)\n\nassociated with any G = (K, E) and v \u2208 RK\n+ proves to be of key use in the remainder. By\nthe definition of the class PK of completely positive matrices in RK\u00d7K (Appendix A), the\nlatter condition in (15) can be written equivalently as\n1\n\n1\u2032\n\nv 2 v 2 \u2212 B + \u03bbmax (B)I = V \u2032 V ,\n\n\u00d7K\nfor some V \u2208 RM\n, M \u2208 N.\n+\n1\n\n(16)\n\n1\u2032\n\nFurthermore, it is worth noting here that the condition v 2 v 2 \u2212 B + \u03bbmax (B)I \u2208 PK is\n1\n1\u2032\nK\n2 \u2212 B is included in the closure of P :\nimplied by a slightly stronger requirement that v 2 vP\np\np\n\u2032\nThis is an immediate consequence of \u03bbmax (B)I = k\u2208K \u03bbmax (B)ek \u03bbmax (B)ek and the\ncharacterization in Appendix A. By analogy to Proposition 1, for any G = (K, E) we define\na further map\n(G, v) 7\u2192 \u03b83 (G, v) = min\n\u03bbmax (B), v \u2208 RK\n(17)\n+.\n3\nB\u2208B (G,v)\n\nThe relations between (10), (12) and the proposed sets (13), (15) are readily seen. It is\nimmediate that B0 (G, v) \u2282 B1 (G, v) and that the second condition in (13) can be written\n1\u2032\n1\n. Thus, by the form (16) of the second condition in (15) and by\nas v 2 v 2 \u2212 B \u2208 RK\u00d7K\n+\ninspection of (10) and (13), it can be seen that\nB3 (G, v) \u2282 B2 (G, v) \u2282 B0 (G, v) \u2282 B1 (G, v),\nand thus\n\u03b83 (G, v) \u2265 \u03b82 (G, v) \u2265 \u03b80 (G, v) \u2265 \u03b81 (G, v)\n\n(18)\n\nfor any G = (K, E) and v \u2208 RK\n+ on hand.\nIt is worth noting here that, given v = 1, the classes of matrices (10), (12) generalize the\nset of so-called (1, \u03b4)-adjacency matrices of graph G introduced in [43]. Any (1, \u03b4)-adjacency\nmatrix is further affinely transformable to a Seidel adjacency matrix [32].\n\n\fB. Some relations of the characterizations\nThe algebraic graph descriptions introduced in Section III-A have some simple properties\nwhich turn out to be central to our results. The first lemma below can be partially deduced\nfrom the proof of Theorem 3.5 in [35]. We give the proof for completeness and refer to\nAppendix A for the notions related to the set of completely positive matrices PK , such as\nthe cp-rank.\nLemma 1: Given any graph G = (K, E), we have\nC(G) \u2229 PK 6= \u00f8.\n\nand the cp-rank satisfies\nK(K + 1)\n\u03c6(C) \u2264\n, C \u2208 C(G) \u2229 PK .\n2\nProof: Associate any edge (k, l) \u2208 E with e = e(k, l), 1 \u2264 e \u2264 |E|, and let B = (bkl ) \u2208\nK\u00d7|E|\nR+\nbe defined as3\nbek > 0, bel > 0 iff e = e(k, l).\nThen it is readily seen that (BB \u2032 )kl > 0, k 6= l iff (k, l) \u2208 E, so that C = BB \u2032 satisfies\nC \u2208 C(G) and, by Definition 6, we also have C \u2208 PK . This proves C(G) \u2229 PK 6= \u00f8.\nAccording to the known bound on cp-rank, see e.g. Section 1 in [33], if additionally\nC \u2208 PK , then we can find B \u2208 RK\u00d7N\nsuch that C = BB \u2032 for some N \u2264 K(K + 1)/2,\n+\nwhich completes the proof.\nThe lemma says essentially that the set of feasible matrices includes a completely positive\nmatrix for any graph on hand and any such matrix remains completely positive if all diagonal\nelements are replaced by the largest eigenvalue. Furthermore, for any graph with K vertices,\ne.g. a sharing graph of parallel channels accessed by K users, any of its completely positive\nfeasible matrices has a cp-rank no larger than K(K + 1)/2. The latter bound on the cp-rank\nis the best known, but likely not the best possible bound [33].\nLemma 2: Given any graph G = (K, E) and v \u2208 RK\n+ , consider the set\n1\n\n1\u2032\n\nDi (G, v) = {v 2 v 2 \u2212 B + \u03bbmax (B) : B \u2208 Bi (G, v)},\n\ni = 0, 2, 3.\n\nThen, we have\nD0 (G, v) \u2282 \u222aG\u2032 \u2282G C(G\u2032 ),\n\nD2 (G, v) \u2282 \u222aG\u2032 \u2282G C(G\u2032 )\u2229RK\u00d7K\n, D3 (G, v) \u2282 \u222aG\u2032 \u2282G C(G\u2032 )\u2229PK ,\n+\n\nwhere G\u2032 \u2282 G denotes that G\u2032 = (K\u2032 , E \u2032 ) is a subgraph of G in the sense that K\u2032 \u2286 K and\nE \u2032 \u2286 E. Moreover, we have\nequivalent to B2 (G, v) = B3 (G, v),\n\nD2 (G, v) = D3 (G, v),\n\nif either K \u2264 4 or G has no odd cycles longer than 4.\nProof: Let any C = (ckl ) \u2208 RK\u00d7K such that\n1\n\n1\u2032\n\nC = v 2 v 2 \u2212 B + \u03bbmax (B),\n\n(19)\n\nfor an arbitrary B \u2208 Bi (G, v), i = 0, 2, 3, be given. Then, by the definitions (10), (13), (15)\nwe have\nckl = 0, k 6= l, if (k, l) \u2208\n/ E,\nbut also ckl = 0, k 6= l, if (k, l) \u2208 F , for some F \u2286 E, where F = \u00f8 is allowed. This implies\nckl 6= 0,\n3\n\nk 6= l,\n\niff (k, l) \u2208 E \u2032 ,\n\nIn the particular case bek = 1, bel = 1 iff e = e(k, l), matrix B represents the so-called incidence matrix of graph G\n[30], [32].\n\n\fwith E \u2032 = E \\ F . Thus, for any matrix C we have C \u2208 C(G\u2032 ) for some subgraph G\u2032 \u2282 G,\nwith G\u2032 = (K\u2032 , E \u2032 ).\nIf now i = 2, then it is evident by the definition (13) and by4 \u03bbmax (B) \u2265 0 that C \u2208 DK\n(see Definition 5). By the result in [44] this implies C \u2208 PK whenever K \u2264 4 (see Appendix\nA). Since C \u2208 C(G\u2032 ) for some G\u2032 \u2282 G is proven for any (19), we have further by Theorem\n3.1 in [34], or by [45], that C \u2208 PK holds also if G has no odd cycles longer than 4. By\nthe definition (15), this completes the proof.\nAn implication of the lemma is that any matrix C \u2208 Di (G, v), v \u2208 RK\n+ , is a feasible\nmatrix of some subgraph of G. Further, any matrix C \u2208 D2 (G, v) is completely positive\nwhenever either a graph G with no more than 4 vertices is considered or when the maximum\nodd cycle length in the graph is no longer than 4 edges (the existence of some completely\npositive matrix C \u2208 D2 (G, v) is ensured already by Lemma 1). In particular, any such matrix\nis completely positive for G as a sharing graph if the parallel channels are accessed by no\nmore than 4 users, or if there are M \u2264 4 classes of parallel channels users, where channel\nsharing within a class is not allowed/possible due to restrictions on implementation or QoS.\nRecall that such parallel channels are illustrated by Examples 6, 7 and their graphs are given\nin Fig. 3.\nIV. U PPER BOUNDS ON MAX - MIN FAIR PERFORMANCE\nIn this section we derive several upper bounds on the worst-case user performance in the\nconsidered parallel channels. According to our performance model, an upper bound represents\nan optimistic case, i.e. a better value of user performance than the upper bounded one. The\nbounds in this section are not proven to be tight and thus, are not very interesting when\nconsidered alone. They become, however, interesting and lead to the central conclusions of\nthis work when considered together with the lower bounds from Section V.\nA. Upper bounds\nIn the following Proposition, a policy-specific bound on the worst performance within the\nuser population is proposed.\nProposition 3: Given N \u2265 K, any G = (K, E) and any (A, P ) \u2208 A(G, r) \u00d7 P(A),\nr \u2208 RK\n+ , we have\nminf\u2208F\u030c (A,P ) hf , f i\nhak , fk (pk )i2\nmin\n,\n\u2264\nk\u2208K\n\u03b3k2\n\u03b8i (G(A), w)\nwith w \u2208 RK\n+ such that\nwk =\n\n\u03b3k2\n,\nrk2\n\nk \u2208 K,\n\ni = 0, 1, 2,\n\n(20)\n\n(21)\n\nand where we defined\nF\u030c (A, P ) = {f \u2208 RN\nfor some \u0100 \u2208 A(G, r)}.\n+ : h\u0101k , f i \u2265 hak , fk (pk )i, k \u2208 K,\nProof: Given any A \u2208 A(G, r), f \u2208 RN\nand\nany\nP\n\u2208\nP(A)\nsuch that hak , fk (pk )i =\n6\n+\n\u2032\n0, k \u2208 K (which by our assumptions in Section II exists) , let us define Z = (z 1 , . . . , z K ) \u2208\nRK\u00d7N such that\np\nr\nwk hf , f i\nwk\nf\u2212\n\u0101k , k \u2208 K,\nz k = z k (\u0101k ) =\nhf , f i\nhak , fk (pk )i\n4\n\nThis is readily seen by the feature that for any C = BB \u2032 we have \u03bbmax (C) = maxx\u2208RK :kxk2 =1 x\u2032 B(x\u2032 B)\u2032 \u2265\n= (BB \u2032 )kk \u2265 0, k \u2208 K.\n\ne\u2032k B(e\u2032k B)\u2032\n\n\fwith an arbitrary \u0100 = (\u01011 , . . . , \u0101K )\u2032 \u2208 RK\u00d7N . Then, we have\n\u221a\n\u221a\n\u221a\nwk wl h\u0101k , f i\nwk wl h\u0101l , f i\nwk wl hf , f ih\u0101k , \u0101l i\n\u221a\nhz k , z l i = wk wl \u2212\n\u2212\n+\n,\nhak , fk (pk )i\nhal , fl (pl )i\nhak , fk (pk )ihal , fl (pl )i\n\nk, l \u2208 K,\n\n(22)\nfor any \u0100 \u2208 R\n. Let now f \u2208 F\u030c(A, P ), and note that then we can find a particular\n\u0100 \u2208 A(G, r) which satisfies\nK\u00d7N\n\nh\u0101k , f i = hak , fk (pk )i,\n\nk\u2208K\n\n(23)\n\n(in fact, the system (23) has always a solution \u0100 \u2208 RK\u00d7N and since by f \u2208 F\u030c (A, P ) there\nexists some \u00c3 \u2208 A(G, r) such that h\u00e3k , f i \u2265 hak , fk (pk )i, k \u2208 K, it is implied that \u0100 \u2264 \u00c3,\nand thus \u0100 \u2208 A(G, r)). When \u0100 \u2208 A(G, r) satisfying (23) is taken in (22), we yield\n\u221a\n(24)\nhz k , z l i \u2265 \u2212 wk wl , k, l \u2208 K,\nk h\u0101k ,\u0101k ihf ,fi\nwhere in particular hz k , z k i = \u2212wk + wha\n/ E\n2 , and, since by Definition 1 (k, l) \u2208\nk ,fk (pk )i\nimplies hak , al i = 0, also\n\u221a\n/ E, k 6= l.\n(25)\nhz k , z l i = \u2212 wk wl , (k, l) \u2208\n\nThus, by the definition (13), we can write\n\u2212 B = ZZ \u2032 \u2212 hf , f iG(\u0100),\n\nfor some B \u2208 B2 (G, w),\n\n(26)\n\nwhere the map \u00c3 7\u2192 G(\u00c3), \u00c3 \u2208 RK\u00d7N\n, follows by the definition of w as (G(\u00c3))kk =\n+\n\u03b3k2 h\u00e3k ,\u00e3k i\n, k \u2208 K, and (G(\u00c3))kl = 0 for k, l \u2208 K, k 6= l. Feature (26) implies then\nr 2 hak ,fk (p )i2\nk\n\nk\n\nmax\nk\u2208K\n\n\u03b3k2 hf , f i\nI \u2212 B \u0017 ZZ \u2032 ,\nhak , fk (pk )i2\n\nsince by such definition of G and by the property\nmaxk\u2208K\n\n\u03b3k2\n\nhak ,fk (pk )i2\n\nh\u0101k ,\u0101k i\nrk2\n2\n\n=\n\nh\u0101k ,\u0101k i\nh\u0101k ,1i2\n\n(27)\n\u2264 1 we have (G)kk \u2264\n\n, k \u2208 K. For the particular B \u2208 B (G, w) in (26) we have then\nmax\nk\u2208K\n\n\u03bbmax (B)\n\u03b3k2\n\u2265\n,\n2\nhak , fk (pk )i\nhf , f i\n\nf \u2208 F\u030c(A, P ),\n\nso that for i = 2 the result follows by the definition (13). For the cases i = 0, 1 the proposition\nfollows then from the definitions (10), (12) and from the property (18), which completes the\nproof.\nBy the proposition, the worst squared user performance achieved under any policy (A, P ) \u2208\nA(r) \u00d7 P(A) in parallel channels is no better than the ratio of the least 2-norm achieved\namong the vectors within the set F\u030c(A, P ) and the function \u03b82 evaluated for a sharing graph\ninduced by A and for the vector w such that (21). According to (18), when such value of\n\u03b82 is replaced by the Lovasz function value or Delsarte bound value assumed by the sharing\ngraph and the vector w, the bound from Proposition 3 is loosened. Since \u03b3k is a predefined\nperformance requirement and rk the fraction of the channel set N assigned to user k \u2208 K\nover time, w can be interpreted as the vector of squared user performance requirements\nnormalized by assigned channel fractions.\nIt is readily seen that F\u030c(A, P ) is the set of values of performance functions5 which\n\u2022 are equal for any user accessing the parallel channels and,\n\u2022 for some sharing matrix which induces the same sharing graph as A (i.e. under fixed\nsharing graph), attain user performance no worse than under policy (A, P ).\n5\nThe value of the performance function fk , k \u2208 K, is a vector in RN\n+ and shall not be confused with the user performance,\nsee our performance model in Section II-B.\n\n\fThus, in some sense, F\u030c (A, P ) can be seen as a set of dominating values of QoS functions\nfor the policy (A, P ). Note that a QoS function value f \u2208 F\u030c (A, P ) may be not achievable\nby an allowable power allocation from P(A), as such value leads to a superior multiuser performance under the penalty of being equal for all users. The set F\u030c(A, P ) is not\na polyhedron for a general (A, P ) \u2208 A(r) \u00d7 P(A). Nevertheless, for any given policy\n(A, P ), F\u030c (A, P ) contains the polyhedron\n{f \u2208 RN\n+ : hak , f i \u2265 hak , fk (pk )i,\n\nk \u2208 K}\n\n(28)\n\nand its further polyhedral subset {f \u2208 RN\nk \u2208 K} which depends merely\n+ : f \u2265 fk (pk ),\non P . Both polyhedra give rise to obvious simplifications of (20): In particular, for any\n(A, P ) \u2208 A(r) \u00d7 P(A) and for fmax (P ) = (maxk\u2208K fk1 (pk ), . . . , maxk\u2208K fkN (pk )), we\nhave\nP\nP\nh k\u2208K fk (pk ), k\u2208K fk (pk )i\nhak , fk (pk )i2\nhfmax (P ), fmax (P )i\nmin\n\u2264\n, i = 0, 1, 2,\n\u2264\nk\u2208K\n\u03b3k2\n\u03b8i (G(A), w)\n\u03b8i (G(A), w)\nwith w such that (21). Thus, given any policy in parallel channels, the worst squared\nuser performance can be no better than the squared 2-norm of the channel-wise maximum,\nrespectively sum, of performance functions of users divided by the function \u03b82 (or the Lovasz\nfunction or the Delsarte bound) evaluated for the induced sharing graph and the vector of\nsquared user performance requirements per assigned channel fraction.\nThe technicality of the bound (20) lies in the structure of the optimization domain F\u030c(A, P ),\nwhile the weight vector w is easily interpretable. As Corollary 8 in Appendix C, we prove an\nalternative version of Proposition 3 which simplifies the optimization domain in the bound at\nthe expense of a more complex weight vector structure. The bounds from Proposition 3 and\nCorollary 8 yield the following implication on the max-min fair performance under given\nsharing topology of parallel channels.\nCorollary 1: Given N \u2265 K, any G = (K, E) and r \u2208 RK\n++ , we have\nmax\n\nmin\n\n(A,P )\u2208A(G,r)\u00d7P(A) k\u2208K\n\nminf\u2208F\u030c (G,r) hf , f i\nhak , fk (pk )i2\n,\n\u2264\n2\n\u03b3k\n\u03b8i (G, w)\n\ni = 0, 1, 2,\n\n(29)\n\nwhere w is such that (21) and where\nF\u030c (G, r) = {f \u2208 RN\n+ : h\u0101k , f i \u2265 h\u00e2k , fk (p\u0302k )i,\n\nk \u2208 K,\n\n\u0100 \u2208 A(G, r)},\n\nfor some\n\nwith\n\nhak , fk (pk )i2\n.\n(A,P )\u2208A(G,r)\u00d7P(A) k\u2208K\n\u03b3k2\nBy Proposition 3 it is evident that F\u030c (G, r) is equivalent to the set of dominating QoS function\nvalues F\u030c (\u00c2, P\u0302 ), where (\u00c2, P\u0302 ) \u2208 A(G, r) \u00d7 P(\u00c2) is a max-min fair policy under a fixed\nsharing graph G. As F\u030c (\u00c2, P\u0302 ) contains the polyhedron (28) for P = P\u0302 , we get the following\nloosened version of (29).\nCorollary 2: Given N \u2265 K, any G = (K, E) and r \u2208 RK\n++ , we have\n(\u00c2, P\u0302 ) = arg\n\nmax\n\nmin\n\n(A,P )\u2208A(G,r)\u00d7P(A) k\u2208K\n\nmax\n\nmin\n\nminf\u2208F\u0303 (G,r) hf , f i\nhak , fk (pk )i2\n,\n\u2264\n\u03b3k2\n\u03b8i (G, w)\n\ni = 0, 1, 2,\n\n(30)\n\nwhere w is such that (21) and where, with \u00c2 defined as in Corollary 1,\nF\u0303 (G, r) = {f \u2208 RN\nk \u2208 K, P \u2208 P(\u00c2)}.\n+ : kf k1 \u2265 kfk (pk )k1 ,\nProof: First notice that for the policy (\u00c2, P\u0302 ) defined in Corollary 1 we necessarily\nhave k\u00e2k k1 = rk , k \u2208 K. Further, as for any A \u2208 A(G, r) such that kak k1 = rk , k \u2208 K,\n\n\fP\nit follows that\nk\u2208K ak = 1, we can write the condition hf , 1i \u2265 hfk (pk ), 1i, k \u2208 K,\nP \u2208 P(\u00c2), specifically as\nX\nX\nX\nhf , ak i \u2265 maxhfl (pl ),\n\u00e2k i =\nhmax fl (pl ), \u00e2k i, A \u2208 A(G, r), P \u2208 P(\u00c2).\nk\u2208K\n\nl\u2208K\n\nk\u2208K\n\nk\u2208K\n\nl\u2208K\n\nThis further implies for a particular P = P\u0302 that\nX\nX\nhak , f i \u2265\nh\u00e2k , fk (p\u0302k )i,\nk\u2208K\n\nk\u2208K\n\nA \u2208 A(G, r).\n\n(31)\n\nLet now A be defined as ak = \u03b1fk (p\u0302k ) \u25e6 \u00e2k \u25e6 f \u22121 , k \u2208 K, where f \u22121 = (1/f1 , . . . , 1/fN )\nand \u03b1 > 0 is chosen to ensure kak k1 \u2264 rk , k \u2208 K, and thus A \u2208 A(G, r) (it is evident that\nany sufficiently small \u03b1 satisfies such condition). For this particular A we have hak , f i =\n\u03b1h\u00e2k , fk (p\u0302k )i, k \u2208 K, so that together with (31) it is implied that \u03b1 \u2265 1 and on the other\nhand\nhak , f i \u2265 h\u00e2k , fk (p\u0302k )i, k \u2208 K.\n\nConsequently, F\u0303 (G, r) \u2286 F\u030c (G, r) which, by Corollary 1, completes the proof.\nThe set F\u0303(G, r) includes all QoS function values, equal for all users, which are in the sum\nover all channels superior to any QoS function value achieved by an allowable (for some\n\u00c2 \u2208 A(G, r)) power allocation. Thus, F\u0303 (G, r) can be seen as a hull of any user dimension\nof the feasible QoS/performance set of parallel channels, which we define in analogy to the\ntheory for channels with interference as [46]\n{(f1 (p1 )), . . . , fK (pK )) : P \u2208 P(\u00c2)},\n\n(32)\n\n(equivalently, \u00d7k\u2208K F\u0303 (G, r) is a hull of the feasible QoS set).\nCorollary 1 implies that a squared max-min fair performance under the condition of a fixed\nsharing graph G in parallel channels can never exceed the ratio of the minimum squared 2norm within the hull F\u0303 (G, r) of any user dimension of (32) and the value of the function \u03b82\n(or the Lovasz function, or the Delsarte number) assumed by G and the vector w satisfying\n(21).\nConsider now constraints on transmit power at any time (in a frame), as expressed e.g.\nby (4a), in which case we have P(A) = P, A \u2208 A(r) (allowable power allocations are\nindependent of sharing matrices and sharing graphs). In such case it is readily seen that also\nset F\u0303 (G, r) is independent of the sharing graph on hand, i.e. F\u0303(G, r) = F\u0303(r) regardless of\nG, and thus the bound (30) assumes a specific separated structure. Precisely, the max-min fair\nperformance under a fixed sharing graph is upper-bounded by a ratio of a value dependent\nsolely on this graph and a vector norm determined completely by the the attainable power\nallocations. Thus, (30) provides a separation between the influence of the combinatorial\ntopology induced by the channel sharing policy via Definition 1 and the impact of (the\nstructure of) the set of allowable power allocations. The optimistic bound (30), although\nlooser than the one from Corollary 1, proves in the next section to be particularly insightful,\nsince a complementary pessimistic bound of the same type can be given. Again, recall that\naccording to (18), Corollary 1 and (30) provide the tightest bounds when the extension \u03b82\nof the Lovasz function and the Delsarte bound is incorporated.\nObviously, we can reformulate Corollary 1 and (30) for the max-min fair performance\nnonrestricted in term of the sharing graph. Precisely,\nminf\u2208F\u030c (\u011c,r) hf , f i\nminf\u2208F\u0303 (G,r) hf , f i\nhak , fk (pk )i2\nmax\nmin\n\u2264\n,\n\u2264\n(A,P )\u2208A(r)\u00d7P(A) k\u2208K\n\u03b3k2\n\u03b8i (\u011c, w)\n\u03b8i (\u011c, w)\n\ni = 0, 1, 2,\n\n\fwith \u011c as the max-min fair sharing graph in the sense that \u00c2 \u2208 A(\u011c, r) (equivalently,\n\u011c = G(\u00c2)), where now\n(\u00c2, P\u0302 ) = arg\n\nmax\n\nmin\n\n(A,P )\u2208A(r)\u00d7P(A) k\u2208K\n\nhak , fk (pk )i2\n\u03b3k2\n\n(33)\n\nis the (graph-nonrestricted) max-min fair policy of the parallel channels.\nB. Relations to coding and zero-error capacity\nRelations of max-min fair performance in parallel channels to coding and zero-error\ninformation theory results are obtained in the setting\n\u03b3k\n= 1, k \u2208 K.\n(34)\nrk\nThis can be assumed for a homogeneous user population, that is, if an equal fraction of\nthe parallel channels is to be assigned (over time) to any user and all users have equal\nperformance requirements. By the celebrated result in [17], the Lovasz function of G, w\nsatisfies in such case\n\u03b80 (G, w) \u2265 \u0398(G),\np\nwhere \u0398(G) = limn\u2192\u221e n \u03b1(Gn ) represents the (zero-error) capacity of G; \u03b1 expresses\nhereby the independence number of a graph and Gn denotes an n-fold concatenation, or\npower, of graph G [30]. The capacity interpretation of \u0398(G) originates from the fact that\n\u03b1(Gn ) represents the maximum number of n-letter messages which will not be confounded\nwhen k \u2208 K correspond to alphabet letters and any edge (k, l) \u2208 E models the (danger of)\nconfusion of letters k, l [17]. As a consequence of Corollary 1, (30) and the result of Lovasz\nwe yield for any sharing graph G that\nmax\n\nminhak , fk (pk )i2 \u2264\n\n(A,P )\u2208A(G,1)\u00d7P(A) k\u2208K\n\nminf\u2208F\u0303 (G,r) hf , f i\nminf\u2208F\u030c (G,1) hf , f i\n\u2264\n.\n\u0398(G)\n\u0398(G)\n\nIn words, under a homogeneous user population accessing the parallel channels and under\nsharing graph fixed to G, the max-min fair performance never exceeds the minimum 2-norm\nwithin the set F\u030c (G, 1) (respectively, within the hull F\u0303 (G, r)) divided by the square root of\nthe sharing graph capacity. This means also that the max-min fair performance scales at most\nwith the capacity of the corresponding sharing graph G = (K, E), i.e. with the effective size\nof the alphabet needed for error-free communication of the letters K where the letter pairs\nE are confusable [17].\nGiven (34), we have also the central relation of the Delsarte bound of G and the graph's\nindependence number according to [38]\n\u03b81 (G, w) \u2265 \u03b1(G),\n\n(recall that by (18) we have additionally \u03b80 (G, w) \u2265 \u03b81 (G, w)). Thus,\nmax\n\nminhak , fk (pk )i2 \u2264\n\n(A,P )\u2208A(G,1)\u00d7P(A) k\u2208K\n\nminf\u2208F\u0303 (G,r) hf , f i\nminf\u2208F\u030c (G,1) hf , f i\n\u2264\n,\n\u03b1(G)\n\u03b1(G)\n\nwhich, with definition of the independence number, means that the ratio of minf\u2208F\u030c (G,1) hf , f i\n(respectively, minf\u2208F\u0303 (G,r) hf , f i) and the maximum cardinality of a vertex subset of a sharing graph G such that no two vertices in it are adjacent upper bounds the max-min fair\nperformance under fixed sharing graph. This implies that the max-min fair performance in\nparallel channels scales at most with the independence number of the sharing graph.\nWe close the discussion of the upper bounds by pointing out two crucial issues. First, the\ngiven upper bounds on the max-min fair performance apply to the case N \u2265 K, i.e. to the\nparallel channel instances with the channel ensemble no smaller than the user population\n\n\faccessing them. Thus, the bounds apply to, in some sense, non-overloaded parallel channels,\nwhich allow the possibility of permanent (i.e. in each frame) access to a channel for any user.\nSecond, the generality of the upper bounds has to be underlined. The bounds apply to any\nperformance function for which the formulation of the max-min fair performance according\nto (9) is meaningful, that is, when a larger user performance implies a better perceived service\nquality level at the user receiver (Examples 1-4).\nV. L OWER BOUNDS ON MAX - MIN FAIR PERFORMANCE\nThe lower bounds on max-min fair performance presented in this section correspond to\npessimistic values, in the sense that the max-min fair performance is guaranteed to be no\nworse. These bounds are analogs, or complements, of the optimistic bounds from Section\nIV, and together embrace the max-min fair performance in parallel channels.\nA. Some notes on matrix scalings\nThe proposed bounds make use of some novel elements of the theory of matrix similarity\nand matrix scaling which are outlined in the following. Let us define a scaling of a nonnegative matrix by straightforwardly extending the idea of scaling of a square positive matrix\nfrom [47].\nDefinition 3: A matrix A \u2208 RK\u00d7N\nis said to be (r, c)-scalable, where r \u2208 RK\n+\n++ and c \u2208\nN \u00d7N\nN\nR++ , if krk1 = kck1 and if there exist X = diag(X) \u2208 RK\u00d7K\nand\nY\n=\ndiag(Y\n) \u2208 R+\n+\nsuch that\nXAY 1 = r,\n1\u2032 XAY = c\u2032 .\n(35)\nThe pair (X, Y ) is then referred to as an (r, c)-scaling of A.\nThus, an (r, c)-scaling of a nonnegative matrix collects scaling factors of rows and columns,\nin the form of two diagonal matrices, such that row sums grouped in r and column sums\ngrouped in c are obtained under row-wise and column-wise scaling. A related notion which\nproves useful in later considerations is the set\nX (A, r, c) = {x = X1, y = Y 1 : (X, Y ) is (r\u0304, c\u0304)-scaling of A \u2208 RK\u00d7N\n, (r\u0304, c\u0304) \u2264 (r, c)}.\n+\nIn words, X (A, r, c) consists of vector pairs which collect diagonal entries of those (r\u0304, c\u0304)scalings of A \u2208 RK\u00d7N\nwhich are no larger than6 (r, c).\n+\nN\nGiven predefined r \u2208 RK\n++ and c \u2208 R++ , it is obvious that matrices which are not\nK\u00d7N\n(r, c)-scalable exist in R+ . Nevertheless, for any nonnegative matrix we can always find\na scaling which leads to row and column sums no larger than the predefined ones.\nN\nLemma 3: Given any A \u2208 RK\u00d7N\nand any r\u0304 \u2208 RK\n+\n++ , c\u0304 \u2208 R++ , there exist r \u2264 r\u0304 and\nc \u2264 c\u0304 such that A is (r, c)-scalable.\nProof: Let A = (a1 , . . . , aK )\u2032 , with ak \u2208 RN\n+ , k \u2208 K, and define \u0100 = XA, where\nX = diag(X) is such that X1 = x and\nr\u0304k\nxk =\n, k \u2208 K.\nhak , 1i\n\nThen, letting \u0100 = (\u01011 , . . . , \u0101K )\u2032 , we have \u01001 = r\u0304, so that if 1\u2032 \u0100 \u2264 c\u0304, the proof is\ncompleted. Otherwise, let \u00c2 = \u0100Y , where Y = diag(Y ) is such that Y 1 = y, with\nc\u0304n\n, n \u2208 N.\nyn = min \u2032\nn\u2208N (1 \u0100)\nn\n\nThen, it is evident that 1\u2032 \u00c2 \u2264 c\u0304\u2032 . Further, as (1\u2032 \u0100)n > c\u0304n for some n \u2208 N (by assumption),\nwe have 0 < y < 1, which implies also \u00c21 < \u01001 = r\u0304 and completes the proof.\n6\n\nHere and hereafter we refer to a scaling as larger/smaller than an other scaling if the obtained column and row sums\nare componentwise larger/smaller.\n\n\fThe original characterization of a scaling (of a square positive matrix) was given in [47] in\nterms of a nonlinear program. The currently known descriptions of scalings of nonnegative\nmatrices are mostly in terms of optimization problems, see e.g. [48] and references therein.\nIn the following we provide a novel (to the best of our knowledge) characterization which\nextends the concept from [49].\nN\nLemma 4: Let A \u2208 RK\u00d7N\nbe (r, c)-scalable for some r \u2208 RK\n+\n++ , c \u2208 R++ . Then, if we\nN\ndefine r\u0304 = (r \u2032 0)\u2032 \u2208 RN\n+ and if y \u2208 R++ satisfies\n\u2207\u03c6(y) \u2264 0\nfor the function\nz 7\u2192 \u03c6(z) = \u2212\nand if x \u2208 RK\n++ is such that\n\nX\n\nlog\n\nn\u2208N\n\nxk = xk (y) =\n\n(36)\n\nzncn\n,\n(Az)r\u0304nn\n\nrk\n,\n(Ay)k\n\nz \u2208 RN\n++ ,\n\nk \u2208 K,\n\n(37)\n\nthen (X, Y ) such that X1 = x and Y 1 = y is an (r, c)-scaling of A. Moreover, (36) is\nsatisfied if and only if y is a global minimizer\nX\nzncn\nlog\ny = arg min \u2212\n.\n(38)\nz\u2208RN\n(Az)r\u0304nn\n++\nn\u2208N\nP\nrk\n\u2212 zcnn , n \u2208 N , for\nProof: By the definition, we can write (\u2207\u03c6(z))n = k\u2208K akn (Az)\nk\nany z \u2208 RN\n++ , so that with (37) we have in particular for z = y that\ncn\ncn\n(\u2207\u03c6(y))n = (A\u2032 x)n \u2212\n= (A\u2032 X1)n \u2212 , n \u2208 N .\nyn\nyn\nThis implies together with (36) that\n1\u2032 XAY \u2264 c.\n\n(39)\n\nFurther, we have\n(XAY 1)k = xk (Ay)k = rk ,\n\nk \u2208 K,\n\nby the definition (37), and thus 1\u2032 XAY 1 = 1\u2032 c, since 1\u2032 c = 1\u2032 r holds by assumption\n(Definition 3). Consequently, (39) is satisfied only if XAY = c, and thus \u2207\u03c6(y) \u2264 0 only\nif \u2207\u03c6(y) = 0. To prove that the latter condition is equivalent to (38), apply the transform\nv = log z, z \u2208 RN\n++ , and then rewrite \u03c6 with the properties of the logarithm as\nX\nX\nevn\n\u2212\n(cn \u2212 r\u0304n )vn , v \u2208 RN .\n\u03c6(ev ) = \u2212\nr\u0304n log\nv\n(Ae )n n\u2208N\nn\u2208N\nvn\n\ne\nN\nAs r\u0304 \u2208 RN\n+ and the map v 7\u2192 (Aev )n , v \u2208 R , is known to be log-concave (see, e.g., [46],\nChapter 6), it is immediate that v 7\u2192 \u03c6(ev ) is convex for v \u2208 RN . Thus, \u2207\u03c6(ew) = 0 is\nequivalent to w = arg minv\u2208RN \u03c6(ev ), which by the one-to-one setting w = log y gives (38)\nand completes the proof.\nIt is worth mentioning that function \u03c6 from the lemma is multiplicatively homogeneous\nin the sense that \u03c6(z) = \u03c6(\u03b1z) for any z \u2208 RK\n++ and \u03b1 > 0 (so that any minimizer (38)\nscaled by some \u03b1 > 0 is a minimizer of \u03c6 as well). This is readily seen from the exponential\ntransformation\nQK\nrk\n\u03c6(z)\nk=1 (Az)k\n,\ne\n= QN\ncn\nn=1 zn\n\nas used originally in [49], and from the condition krk1 = kck1 . Furthermore, there is a\nsurprising relation of function \u03c6 to the throughput optimization under interference. Let\n\n\fus interpret z \u2208 RN\n+ as a transmit power vector of the user population N accessing the\nN \u00d7N\ninterference channel which has (A\u2032 0)\u2032 \u2208 R+\nas its interference matrix, defined in the\nusual way as e.g. in [46], [50] (this implies that the channel gains of N \u2212 K users are zero).\nThen, by defining the Signal-to-Interference functions of users in the interference channel as\nzn\n, n \u2208 N [50], we can write\nz 7\u2192 SIRn (z) = (Az)\nn\n\u03c6(z) = \u2212\n\nK\nX\nk=1\n\nN\nK\nX\nX\nck log zk .\n(ck \u2212 rk ) log zk \u2212\nrk log SIRk (z) \u2212\n\n(40)\n\nk=K+1\n\nk=1\n\nBy this form, \u2212\u03c6 can be recognized as the weighted throughput function of the described\ninterference channel with additional cost functions. When ck \u2265 rk \u2265 0, k \u2208 K, such cost\nfunctions penalize logarithmically the excessive use of transmit power by the users. By\nthe proof of Lemma 4, the weighted throughput function (40) is known to be convex as a\nfunction of the logarithmic power vector v = log z, z \u2208 RN\n++ (e.g. power allocation in dB).\nLemma 4 and the above interpretation lead to the conclusion that (X, Y ), with Y 1 = y and\nX1 = x, is an (r, c)-scaling of an ((r, c)-scalable) A if y represents a power allocation\nwhich globally minimizes the penalized weighted throughput function (40) in the described\ninterference channel and x is determined by y via (37).\nFinally, we need the following scaling-related function.\nK\u00d7N\nDefinition 4: Given r \u2208 RK\n, be defined as7\n++ , let the map V 7\u2192 \u03bc(V ), V \u2208 R+\n\u03bc(V ) =\n\nmax\n\nmin\n\n(x,y)\u2208X (V ,r,1) (n,k)\u2208N \u00d7K\n\n(xk yn )2 .\n\nSuch function represents the minimum squared geometric mean of pairs of diagonal entries\nof an (r\u0304, c\u0304)-scaling of a given matrix, achievable among all (r\u0304, c\u0304)-scalings no larger than\n(r, c). In the spirit of [51], we can regard \u03bc as a (kind of) metric, or measure, of the entire\nclass of such scalings of a given matrix.\nAs the simple property of later interest, we observe that if the row and column sum vectors\nof V do not exceed (r, 1), i.e. V 1 \u2264 r and 1\u2032 V \u2264 1\u2032 , then \u03bc(V ) \u2265 1.\nB. Lower bounds\nUsing Definition 4 we can formulate the following lower bound on the max-min fair\nperformance in parallel channels under fixed sharing graph.\nProposition 4: Given any G = (K, E) and r \u2208 RK\n++ , we have\nmax\n\nmin\n\n(A,P )\u2208A(G,r)\u00d7P(A) k\u2208K\n\nhak , fk (pk )i2\n\u2265\n\u03b3k2\n\n\u03bc(RV ) maxf\u2208F\u0302 (G,r) hf , f i\n\nmax\n\nB\u2208B3 (G,w), V \u2208RK\u00d7N\n:\n+\n1\n\n\u03bbmax (B)\n\n1\u2032\n\nV V \u2032 =\u03bbmax \u22121 (B)(w 2 w 2 \u2212B)+I\n\n(41)\nwhere w is such that (21), where\nN\u2265\n\nK(K + 1)\n,\n2\n\n(42)\n\nand where, with \u00c2 defined as in Corollary 1,\nF\u0302(G, r) = {f \u2208 RN\n+ :f = fk (pk ),\n\nk \u2208 K,\n\nfor some P \u2208 P(\u00c2),\nhak , f\u0304 i2\nf = arg max max min 2\n}.\nA\u2208A(G,r) k\u2208K \u03b3k hf\u0304 , f\u0304 i\nf\u0304\u2208RN\n+\n\nMoreover, for a particular\nB = arg\n7\n\nmin\n\nB\u0304\u2208B3 (G,w)\n\n\u03bbmax (B\u0304)\n\n(43)\n\nWe omit here the indication of the dependence on r, since it does not introduce any ambiguities in the remainder.\n\n,\n\n\f(41) implies further\nmax\n\nmin\n\n(A,P )\u2208A(G,r)\u00d7P(A) k\u2208K\n\nhak , fk (pk )i2\n\u2265\n\u03b3k2\n\n\u03bc(RV ) maxf\u2208F\u0302 (G,r) hf , f i\n\nmax\n\nV \u2208RK\u00d7N\n:\n+\n1\n\n\u03b83 (G, w)\n\n1\u2032\n\nV V \u2032 =\u03bbmax \u22121 (B)(w 2 w 2 \u2212B)+I\n\n(44)\nProof: Let any G = (K, E) and any B \u2208 B (G, w) be given, and let V = (v 1 , . . . , v K )\u2032\nsatisfy\n1\n1\u2032\nV V \u2032 = \u03bbmax \u22121 (B)(w 2 w 2 \u2212 B) + I, V \u2208 RK\u00d7N\n,\n(45)\n+\n3\n\nwhere by the definition (15) it is known that such V exists whenever N = N(B) satisfies\n1\n1\n1\n1\n1\u2032\n1\nN \u2265 \u03c6(\u03bbmax \u22121 (B)(w 2 w 2 \u2212 B) + I). Defining W 2 = diag(W 2 ) as (W 2 )kk = (w 2 )k ,\nk \u2208 K, the right-hand side of (45) can be rewritten due to \u2212B + \u03bbmax (B)I \u0017 0 as\n1\n\n1\u2032\n\n1\n\n1\n\n\u03bbmax \u22121 (B)(w 2 w 2 \u2212 B) + I = \u03bbmax \u22121 (B)W 2 CC \u2032 W 2 + XX \u2032 ,\n\n(46)\n\nwith any C = (c, . . . , c)\u2032 \u2208 RK\u00d7N such that hc, ci = 1 and with any X = (x1 , . . . , xK )\u2032 \u2208\nRK\u00d7N which satisfies XX \u2032 = \u2212B + \u03bbmax (B)I and (xk )n = 0, n > K, k \u2208 K. Letting\n1\n1\u2032\nnow N \u2265 max{K + 1, \u03c6(\u03bbmax \u22121 (B)(w 2 w 2 \u2212 B) + I)}, we can find for any such X some\nC = C(X) \u2208 RK\u00d7N\nsatisfying\n+\nhc, xk i = 0,\n\nk \u2208 K,\n\n(47)\n\nso that (46) can be rewritten as\n1\n\n1\u2032\n\n1\n\n1\n\n1\n\n1\n\n\u2032\n\n\u03bbmax \u22121 (B)(w 2 w 2 \u2212 B) + I = (\u03bbmax \u2212 2 (B)W 2 C \u00b1 X)(\u03bbmax \u2212 2 (B)W 2 C \u00b1 X) . (48)\nq\nk\nc, k \u2208 K, yielding (48) satisfies\nBy (45), it follows now that any vector tuple xk + \u03bbmaxw(B)\nr\nr\nwk\nwl\nhxk +\nc, xl +\nci = hvk , v l i, k, l \u2208 K,\n\u03bbmax (B)\n\u03bbmax (B)\nq\nk\ni.e., vector tuple xk + \u03bbmaxw(B)\nc, k \u2208 K, has the same lengths and mutual angles as any\nvector tuple v k , k \u2208 K, yielding (45). As a consequence, for any tuple v k , k \u2208 K, satisfying\n(45) and for any c and xk , k \u2208 K, from (48), there exists a rotation matrix Q \u2208 RN \u00d7N (a\nreal-valued orthogonal matrix with unit determinant) for which [52]\nr\nwk\nv k = Q(xk +\nc), k \u2208 K.\n\u03bbmax (B)\nBy orthogonality of Q we have hQc, Qci = hc, ci and hQxk , Qxl i = hxk , xl i, k, l \u2208 K,\nand (47) implies hQc, Qxk i = 0, k \u2208 K. Thus, it follows now that any factor in (45) can\nbe written as\nq\n1\n(49)\nV = \u03bbmax \u22121 (B)W 2 C \u00b1 X\n\nK\u00d7N\nfor some C = (c, . . . , c)\u2032 \u2208 R+\n, hc, ci = 1, and for some X \u2208 RK\u00d7N satisfying (47)\n(where X is such that XX \u2032 = \u2212B + \u03bbmax (B)I). This further yields that\nr\nwk\nhv k , ci =\n, k \u2208 K,\n(50)\n\u03bbmax (B)\n\nand, by the Definition (15), also\nhv k , v k i = 1,\nBy (50) we have\n\nk \u2208 K,\n\nhv k , v l i = 0, k 6= l,\n\nwk\n\u03bbmax (B)\n=\n,\nhf , f i\nhv k , f i2\n\nk \u2208 K,\n\nif\n\n(k, l) \u2208\n/ E.\n\n(51)\n\n(52)\n\n.\n\n\f\u221af\nfor any f \u2208 RN\n+ chosen to satisfy\n\nhf,fi\n\n= c for the particular vector c in (50). By Lemma\n\nK\u00d7K\nN \u00d7N\n3 it is further implied that there exist (Z, Y ) \u2208 R+\n\u00d7 R+\nwhich represent an (r\u0304, c\u0304)scaling of RV such that (r\u0304, c\u0304) \u2264 (r, 1): By setting Z1 = z, Y 1 = y this means that\nwe can take any (z, y) \u2208 X (RV , r, 1), so that by (51) and Definition 1 it follows that\nU = ZRV Y satisfies U \u2208 A(G, r). Furthermore, writing U = (u1 , . . . , uK )\u2032 , we have\nthen by the definition of w that\n\n\u03b3k2 min(k,n)\u2208K\u00d7N (zk yn )2\n\u03b3k2\n\u03b3k2 zk2\nwk\nP\nP\n=\n,\n=\n\u2265\nhv k , f i2\n( n\u2208N rk (v k )n fn )2\nhuk , f i2\n( n\u2208N y1n (uk )n fn )2\n\nk \u2208 K,\n(53)\n\nwhich implies with (52) and Definition 4 finally that\n\n\u03bbmax (B)\n\u03b3k2\n\u2265\n,\n\u03bc(RV )hf , f i\nhuk , f i2\n\n\u221af\nNote now that (54) holds for any f \u2208 RN\n+ with\n\nhf,fi\n\nk \u2208 K.\n\n(54)\n\n= c for the particular c in (50) and,\n\nby the assumption (2) and the assumptions with respect to fk , k \u2208 K, we can always find\na particular f such that additionally f = fk (pk ), k \u2208 K, for an arbitrary A \u2208 A(G, r) and\nfor some P \u2208 P(A) 8 . Consequently, it is further implied that\n\u03bbmax (B)\n\u2265\n\u03bc(RV )\n\nmin\n\nA\u2208A(G,r),f\u2208RN\n+:\nf=fk (pk ),k\u2208K, for some P \u2208P(\u00c2)\n\nmax\nk\u2208K\n\n\u03b3k2 hf , f i\n\u03b3k2 hf\u0302 , f\u0302 i\n=\nmax\n,\nk\u2208K h\u0101 , f\u0302 i2\nhak , f i2\nk\n\nf\u0302 \u2208 F\u0302(G, r),\n\n\u03b3 2 hf\u0302,f\u0302i\narg minA\u2208A(G,r) maxk\u2208K hak ,f\u0302i2 .\nk\n\nwhere \u00c2 is defined as in Corollary 1 and \u0100 =\nit is immediate that\n\u03b3k2\n\u03bbmax (B)\n\u2265\nmin\nmax\n,\n\u03bc(RV )hf , f i (A,P )\u2208A(G,r)\u00d7P(A) k\u2208K hak , fk (pk )i2\n\n(55)\nThus, finally\n\nf \u2208 F\u0302 (G, r),\n\n(56)\n1\n\n1\u2032\n\nfor any B \u2208 B3 (G, w), for any V satisfying (45) and N \u2265 max{K+1, \u03c6(\u03bbmax \u22121 (B)(w 2 w 2 \u2212\nB) + I)}. According to Lemmas 1, 2, the latter condition is satisfied regardless of B \u2208\nB3 (G, w) if N \u2265 K(K + 1)/2. As (56) is satisfied in particular for B\u0304 such that \u03bbmax (B\u0304) =\nmaxB\u2208B3 (G,w) \u03bbmax (B) = \u03b83 (G, w), the proof is completed.\nThe proposition says that the squared max-min fair performance achieved in parallel\nchannels under fixed sharing topology is guaranteed to be no worse than the maximum\nratio of some two expressions. The denominator expression is the maximum eigenvalue of a\nmatrix B from B3 (G, w), which is determined by the given sharing graph G and the vector\nof squared user performance requirements normalized by assigned channel fractions. The\nnumerator corresponds to the squared 2-norm of a vector from the set F\u0302(G, r) multiplied by\nthe value of the metric \u03bc of the class of (r\u0304, c\u0304)-scalings no larger than (r, 1), of a nonnegative\nfactor of\n1\n1\u2032\nR(\u03bbmax \u22121 (B)(w 2 w 2 \u2212 B) + I)R.\n(57)\nBy Lemma 2, the matrix (57) represents a particular feasible matrix of a subgraph of the\nsharing graph. Obviously, the looser bound (41) is obtained by replacing the maximization of\n\u03bc(RV )/\u03bbmax (B), conducted over B \u2208 B3 (G, w) and the factors of (57), by the minimization\n8\nEquivalently, by these assumptions, {f \u2208 RN\n+ : f = fk (pk ), k \u2208 K,\nf\nthe ray {f \u2208 RN\n= c} for any c \u2208 RN\n+ : \u221a\n+ , and A \u2208 A(G, r).\nhf ,f i\n\nP \u2208 P(A)} has a nonempty intersection with\n\n\fof the eigenvalue only. By Corollary 1 and Proposition 4 we have now\nminf\u2208F\u030c (G,r) hf , f i\nminf\u2208F\u030c (G,r) hf , f i\n= max\n2\nB\u2208B2 (G,w)\n\u03b8 (G, w)\n\u03bbmax (B)\nhak , fk (pk )i2\n\u2265\nmax\nmin\n\u2265\n(A,P )\u2208A(G,r)\u00d7P(A) k\u2208K\n\u03b3k2\n(58)\n\u03bc(RV ) maxf\u2208F\u0302 (G,r) hf , f i\n\u03bc(RV ) maxf\u2208F\u0302 (G,r) hf , f i\n\u2265\n,\nmax\n\u03bbmax (B)\n\u03b83 (G, w)\nB\u2208B3 (G,w), V \u2208RK\u00d7N\n:\n+\n1\n\n1\u2032\n\nV V \u2032 =\u03bbmax \u22121 (B)(w 2 w 2 \u2212B)+I\n\nwhere RV in the outer lower bound denotes any nonnegative factor of (57) for the particular\nmatrix (43), achieving the value of the \u03b83 function (see (17)). While F\u030c (G, r) was shown to\nbe the set of dominating performance function values for some policy (\u00c2, P\u0302 ), set F\u0302 (G, r)\nincludes precisely those QoS function values which\n\u2022 are equal for any user accessing the parallel channels,\n\u2022 are attainable by some allowable power allocation (under some \u00c2 \u2208 A(G, r)) and,\n\u2022 optimize the worst user performance under fixed sharing graph G and under QoS\nfunction values normalized to unit 2-norm and equal for all users.\nIt is immediate that F\u0302 (G, r) is included in the feasible performance set (32) of the parallel\nchannels and has the property that f \u2208 F\u0302(G, r) implies \u03b1f \u2208 F\u0302(G, r), \u03b1 < 1.\nThe inequality (58) contains the tightest proposed bounds which utilize the extensions\n2 3\n\u03b8 , \u03b8 of the Lovasz function and Delsarte number. Since the intricacy of these bounds lies\nevidently in the structure of the sets F\u030c(G, r), F\u0302(G, r), we proceed by proving some loosened\nlower bounds which together with the looser lower bound (30) lead to our central insights.\nCorollary 3: Given any G = (K, E) and r \u2208 RK\n++ , we have\nmax\n\nmin\n\n(A,P )\u2208A(G,r)\u00d7P(A) k\u2208K\n\nhak , fk (pk )i2\n\u2265\n\u03b3k2\n\nmax\n\nB\u2208B3 (G,w), V \u2208RK\u00d7N\n:\n+\n1\n\n\u03bc(RV ) maxf\u2208F\u0304 (G,r) hf , f i\n,\n\u03bbmax (B)\n\n1\u2032\n\nV V =\u03bbmax \u22121 (B)(w 2 w 2 \u2212B)+I\n\u2032\n\nwith w such that (21), with N \u2208 N satisfying (42), and, given \u00c2 defined as in Corollary 1,\nF\u0304(G, r) = {f \u2208 RN\n+ : hf\u0304 , f\u0304 i \u2264 hf , f i \u21d2 f\u0304 = fk (pk ), k \u2208 K,\n\nfor some P \u2208 P(\u00c2)}.\n\nMoreover, given a particular (43), this further implies\nmax\n\nmin\n\n(A,P )\u2208A(G,r)\u00d7P(A) k\u2208K\n\nhak , fk (pk )i2\n\u2265\n\u03b3k2\n\n\u03bc(RV ) maxf\u2208F\u0304 (G,r) hf , f i\n.\n\u03b83 (G, w)\n\nmax\n\nV \u2208RK\u00d7N\n:\n+\n1\n\n1\u2032\n\nV V \u2032 =\u03bbmax \u22121 (B)(w 2 w 2 \u2212B)+I\n\nProof: The definition of F\u0304 (G, r) implies that f \u2208 F\u0304(G, r) if and only if\nhf , f i \u2264 max \u03b4\n\u03b4>0\n\nsubject to B(\u03b4) \u2286 \u2229k\u2208K {f = fk (pk ) : P \u2208 P(\u00c2)},\n\n(59)\n\nwhere we define B(\u03b4) = {f \u2208 RN\n+ : hf , f i \u2264 \u03b4}. On the other hand, we can write by the\ndefinition of F\u0302(G, r) (quite redundantly)\nmax hf , f i = min \u03b4\u0304\n\nf\u2208F\u0302 (G,r)\n\n\u03b4\u0304>0\n\nsubject to B(\u03b4\u0304) \u2287 ( \u2229k\u2208K {f = fk (pk ) : P \u2208 P(\u00c2)}\n\n(60)\n\n\u2229 {f = \u03b1f\u0302 : \u03b1 \u2265 0}),\n\u03b3 2 hf,fi\n\nwhere f\u0302 = arg minf\u2208RN+ minA\u2208A(G,r),f\u2208RN+ maxk\u2208K hak k ,fi2 . Now, as any f\u0302 is arbitrarily\nnonnegatively scalable (that is, the latter set in the constraints in (60) is a ray in RN\n+ ),\nit is implied further by (60) that\nmax hf , f i \u2265 min \u03b4\u0304\n\nf\u2208F\u0302 (G,r)\n\n\u03b4\u0304>0\n\nsubject to B(\u03b4\u0304) \u2287 B(\u03b4),\n\n(61)\n\n\ffor any \u03b4 satisfying the constraints in (59). Thus, by (59), (61) it follows finally\nhf , f i \u2264 max hf\u0304 , f\u0304 i,\nf\u0304\u2208F\u0302 (G,r)\n\nf \u2208 F\u0304 (G, r),\n\nwhich is, according to Proposition 4, sufficient for the proof for any given G = (K, E) and\nr \u2208 RK\n++ .\nBy (30) and Corollary 3 we have now\nminf\u2208F\u0303 (G,r) hf , f i\n\u03b82 (G, w)\n\nmax\n\nB\u2208B3 (G,w), V \u2208RK\u00d7N\n:\n+\n1\n\n=\n\nmax\n2\n\nminf\u2208F\u0303 (G,r) hf , f i\n\n\u03bbmax (B)\nhak , fk (pk )i2\n\u2265\n\u2265\nmax\nmin\n(A,P )\u2208A(G,r)\u00d7P(A) k\u2208K\n(62)\n\u03b3k2\n\u03bc(RV ) maxf\u2208F\u0304 (G,r) hf , f i\n\u03bc(RV ) maxf\u2208F\u0304 (G,r) hf , f i\n\u2265\n,\n\u03bbmax (B)\n\u03b83 (G, w)\nB\u2208B (G,w)\n\n1\u2032\n\nV V \u2032 =\u03bbmax \u22121 (B)(w 2 w 2 \u2212B)+I\n\nwith RV in the last expression as any nonnegative factor of the particular matrix (57), with\n(43). From the proof of the corollary it is evident that F\u0304 (G, r) can be interpreted as the\nlargest, say, ball (in the 2-norm) of performance function values, equal for all users, included\nin each user dimension of the feasible QoS set (32) of the parallel channels. On the other\nhand, recall that the hull F\u0303(G, r), determining the optimistic bound in (62), contains any\nsuch user dimension of the feasible QoS set. Thus, the ball F\u0304 (G, r) and the hull F\u0303 (G, r)\ndetermine the interval (62) of candidate max-min fair performance values in terms of the\nstructure of the feasible performance set of parallel channels; that is, in terms of the structure\nof the set of allowable power allocations P(\u00c2) and the features of the QoS functions fk ,\nk \u2208 K. In precise terms, the only such feature which is decisive for the bounds (62) is the\n(squared 2-norm of the) minimum gap between F\u0303 (G, r) and F\u0304(G, r), measured as\nmin hf , f i \u2212 max hf , f i.\n\nf\u2208F\u0303 (G,r)\n\nf\u2208F\u0304 (G,r)\n\nSuch gap is visualized, together with the hull F\u0303(G, r) and the ball F\u0304(G, r) for exemplary\ninstance of parallel channels in Figs. 4 and 59 .\nConsider now specifically the case of limitations of transmit powers at any time (in a\nframe), e.g. constrained transmit power of any user or constrained joint power budget of all\nusers resulting in (4a), respectively. As in such case P(A) = P, A \u2208 A(r), it is readily\nseen that also F\u0304 (G, r) = F\u0304 (r) for any sharing graph G (i.e., F\u0304(G, r) is independent of\nthe induced sharing graph). As a consequence, the influence of the features of the channel\nsharing policy on the interval (62) of candidate values of max-min fair performance is\nin such case completely separated from the impact of the allowable power allocations.\nThe combinatorial properties of the sharing graph G govern the inner bounds in (62) via\nthe minimum achievable eigenvalues \u03bbmax (B) among matrices B \u2208 B2 (G, w) and the\nnormalized eigenvalues \u03bbmax (B)/\u03bc(RV ) among matrices B \u2208 B3 (G, w); the normalization\nis by the (values of) the metrics \u03bc of the associated factors of (57). Analogously, the outer\nbound behavior is described by the function values \u03b82 (G, w) and normalized function values\n\u03b83 (G, w)/\u03bc(RV ), for the sharing graph G and the vector of squared user performance\nrequirements per assigned channel fraction w, where the normalization is now by the metric\n\u03bc of the corresponding factor of (57) such that \u03bbmax (B) = \u03b83 (G, w). Thus, the tightest\npessimistic bound is obtained for a matrix B \u2208 B3 (G, w) and a nonnegative factor RV\nof (57) which provide the minimum normalized eigenvalue \u03bbmax (B)/\u03bc(RV ). Similarly, the\n9\n\nNote here that the main results of this work are not proven to hold for the parallel channels instances from Figs. 4, 5\nas the condition N \u2265 K is violated in these cases. Figs. 4, 5 serve, however, only as an exemplary visualization of the\nnotions.\n\n\ffk2 (pk2) = log(1 +\n\n|hk2 |2 pk2\n)\n2\n\u03c3k2\n\n1\n\n{fk (pk ) : P \u2208 P}\n\n0.8\n\n0.8\n\n0.6\n\n0.6\n\n0.4\n\n0.4\n\n0.2\n\n0\n0\n\n0.2\n\n0.5\n\n1\n\nfk1 (pk1) = log(1 +\n\nF\u0303(r)\n\n1\n\n0\n0\n\n\u03b4\n\nF\u0304(r)\n\n0.5\n\n1\n\n|hk1 |2 pk1\n)\n2\n\u03c3k1\n\nFig. 4. The user dimensions of the feasible QoS set of parallel channels under the per-user power constraints (4b)\nand capacity (8) as performance function (left hand side), as well as the resulting hull F\u0303(r), the ball F\u0304 (r) and the\ngap \u03b4 = minf \u2208F\u0303 (r) hf , f i \u2212 maxf \u2208F\u0304(r) hf , f i (right hand side). We simulated the parallel channels with K = 4 users\nk = 1, 2, 3, 4 accessing N = 2 channels n = 1, 2. The channels hkn and the variances \u03c3kn were picked randomly from\nuniform distributions resulting in an average Signal-to-Noise Ratio of 6 dB.\n\nfk2(pk2) = 1 \u2212\n\n1\n1+\n\npk2 |hk2 |2\n\u03c32\nk2\n\n0.8\n\n{fk (pk ) : P \u2208 P}\n\n0.8\n\n0.7\n\n0.7\n\n0.6\n\n0.6\n\n0.5\n\n0.5\n\n0.4\n\n0.4\n\n0.3\n\n0.3\n\n0.2\n\n0.2\n\n0.1\n\n0.1\n\nF\u0303(r)\n\n\u03b4\n\n0\n0\n\n0\n0\n\n0.5\nfk1(pk1) = 1 \u2212\n\nF\u0304(r)\n\n0.5\n\n1\np |h |2\n1+ k1 2k1\n\u03c3\nk1\n\nFig. 5. The user dimensions of the feasible QoS set of parallel channels under the per-user power constraints (4b) and\nmean square reliability (7) as performance function (left hand side), as well as the resulting hull F\u0303 (r), the ball F\u0304 (r) and\nthe gap \u03b4 = minf \u2208F\u0303 (r) hf , f i \u2212 maxf \u2208F\u0304(r) hf , f i (right hand side). We simulated the parallel channels as in Fig. 4, but\nfor an average Signal-to-Noise Ratio of 9 dB.\n\n\fouter bounds in (62) are tightest for a factor RV of the particular (57), with (43), which\nmaximizes metric \u03bc.\nThe outer bounds in (62) can be made in some sense symmetric whenever there exists a\nnonnegative factor RV of the matrix (57) satisfying (43) which has row sums not exceeding\nr and each column sum no larger than 1: In fact, as it is immediate from the Definition 4\nthat then \u03bc(RV ) \u2265 1, we can embrace the max-min fair performance according to\nminf\u2208F\u0303 (G,r) hf , f i\n\u03b82 (G, w)\n\n\u2265\n\nmax\n\nmin\n\n(A,P )\u2208A(G,r)\u00d7P(A) k\u2208K\n\nmaxf\u2208F\u0304 (G,r) hf , f i\nhak , fk (pk )i2\n,\n\u2265\n2\n\u03b3k\n\u03b83 (G, w)\n\n(63)\n\nwhere we have purely spectral dependence on the sharing graph G in the form of functions\n(14), (17). By the theory of matrix scaling [49], [48], the existence of such particular factor\ndepends on the pattern of its zero entries, which is shown by the following paraphrased result\nfrom [53].\nProposition 5 ([53]): Let denote by RV (L|M), with L \u2282 K, M \u2282 N , the submatrix of\nRV \u2208 RK\u00d7N\nwhich is obtained by deleting all rows k \u2208 L and all columns n \u2208 M from\n+\nRV . Then, we have \u03bc(RV ) \u2265 1 if\nX\nX\nr\u0304k <\nc\u0304n if RV (K \\ L|M) = 0, RV (L|N \\ M) 6= 0,\nn\u2208M\n\nk\u2208L\n\nX\n\nr\u0304k =\n\nX\n\nc\u0304n\n\nn\u2208M\n\nk\u2208L\n\nif RV (K \\ L|M) = 0,\n\nRV (L|N \\ M) = 0,\n\n(64)\n\nholds for some (r\u0304, c\u0304) \u2264 (r, 1). Thus, the max-min fair performance satisfies (63) if there exists\na nonnegative factor RV of the matrix (57), such that (43) and (64) for some (r\u0304, c\u0304) \u2264 (r, 1).\nRecall here from Lemma 2 that any matrix (57) is a feasible matrix of some subgraph of the\nsharing graph. Thus, by the above proposition, the existence of a factor ensuring \u03bc(RV ) \u2265 1,\ndepends on the existence/nonexistence of certain edges in the sharing graph.\nC. Role of scalings\nThe row and column sums of factors of the certain feasible matrix (57) of some sharing\nsubgraph influence the max-min fair performance in a specific way, which we show more\nexplicitly here. Proposition 7 in Appendix C provides a technical alternative version of the\nbounds from Corollary 3 and we simplify it in the following. By the proof, one can readily\nsee that the bounds from Proposition 7 are slightly tighter than those from Corollary 3, at the\nexpense of higher complexity10 Under apriori setting y = 1 in Proposition 7 and using the\ndefinition of w(x) and (15), we obtain a more insightful, loosened version of the bounds:\nTogether with (30), we yield then precisely\nminf\u2208F\u0303 (G,r) hf , f i\n\u03b82 (G, w)\n\nmax\n\nB\u2208B3 (G,w),\n(x,1)\u2208X (RV ,r,1), V \u2208RK\u00d7N\n:\n+\n1\n\n=\n\nmax\n2\n\nminf\u2208F\u0303 (G,r) hf , f i\n\n\u03bbmax (B)\nhak , fk (pk )i2\n\u2265\nmax\nmin\n\u2265\n(A,P )\u2208A(G,r)\u00d7P(A) k\u2208K\n\u03b3k2\nmink\u2208K xk maxf\u2208F\u0304 (G,r) hf , f i\nmink\u2208K xk maxf\u2208F\u0304 (G,r) hf , f i\n\u2265\n,\n\u03bbmax (B)\n\u03b83 (G, w)\nB\u2208B (G,w)\n\n1\u2032\n\nV V \u2032 =\u03bbmax \u22121 (B)(w 2 w 2 \u2212B)+I\n\n(65)\nwhere in the last expression we can take any x satisfying (x, 1) \u2208 X (RV , r, 1) for any\nnonnegative factor RV of the matrix (57) for (43) (note here that for F\u0303(G, r, y), y \u2208 RN\n++ ,\n10\n\nNote also that the proof of Proposition 7 allows for an even tighter bound formulation which generalizes Proposition\n4; set F\u0304(G, r, y) has to be merely replaced by F\u0302 (G, r, y) given in (82).\n\n\fdefined in Proposition 7 we have F\u0304(G, r, 1) = F\u0304(G, r)). If the constraints of transmit\npower at any time in a frame are considered (e.g. either of (4a)), then one can see the\nsame separate impact of allowable power allocations and the channel sharing combinatorics\non the bounds (65) as in the case of (62): In terms of P(A) = P, A \u2208 A(G, r), the\ninterval of max-min fair performance values is determined by the distance between the\nlargest included ball F\u0304 (G, r) and the hull F\u0303 (G, r) of each user dimension of the feasible\nQoS set. Independently, the minimum achievable eigenvalues \u03bbmax (B) within sets (13) and\n(15), or the spectral characterizations \u03b82 and \u03b83 , govern the bounds in terms of the channel\nsharing topology expressed by the sharing graph G. By the definition of X (RV , r, 1), it is\nfurther evident that the outer lower bound in (65) is a linear function of the minimum row\nscaling factor which is required to scale a nonnegative factor RV of (57) down, until each\ncolumn sum does not exceed unity and the vector of row sums is no larger than r. This\nleads to a conclusion that the outer bounds (65) embrace the max-min fair performance value\nas tightly as possible if such a nonnegative factor RV is taken which has componentwise\nsmallest row sum vector relative to r. Note that, as (57) represents some feasible matrix of\nsome sharing subgraph G\u2032 \u2282 G, the row sums of a factor of (57) are determined by the\nchannel sharing combinatorics, that is, by the existence/nonexistence of certain edges in the\nsharing graph (and by the vector w of squared user performance requirements per assigned\nchannel fraction).\nBy the bounds (65) it can be again seen that a symmetric embracing of max-min fair\nperformance according to (63) is implied whenever there exists a factor RV of (57), for\nthe particular (43), which has all column sums no larger than unity and all row sums\ncomponentwise not exceeding r (see Proposition 5): In fact, in such case we can find a\nparticular x such that mink\u2208K xk \u2265 1 among all (x, 1) \u2208 X (RV , r, 1).\nConsider now the complementary simplification of Proposition 7, where x = 1 is set\napriori. Then, together with (30) we yield immediately\nminf\u2208F\u0303 (G,r) hf , f i\n\u03b82 (G, w)\n\n=\n\nmax\n2\n\nminf\u2208F\u0303 (G,r) hf , f i\n\n\u03bbmax (B)\nhak , fk (pk )i2\n\u2265\n\u2265\nmax\nmin\n(A,P )\u2208A(G,r)\u00d7P(A) k\u2208K\n\u03b3k2\nmaxf\u2208F\u0304 (G,r,y) hy \u25e6 f , y \u25e6 f i maxf\u2208F\u0304 (G,r,y) hy \u25e6 f , y \u25e6 f i\nmax\n\u2265\n,\n\u03bbmax (B)\n\u03b83 (G, w)\nB\u2208B3 (G,w), (1,y)\u2208X (RV ,r,1), V \u2208RK\u00d7N\n:\n+\n1\n\nB\u2208B (G,w)\n\n1\u2032\n\nV V \u2032 =\u03bbmax \u22121 (B)(w 2 w 2 \u2212B)+I\n\n(66)\nwhere in the outer lower bound we can choose any y such that (y, 1) \u2208 X (RV , r, 1), with\nRV as any nonnegative factor of (57), where (43). It is evident from the definition that the\nset F\u0304(G, r, y) consists of performance function values which\nN\n\u2022 are equal to, say, f \u2208 R+ for all users accessing the parallel channels and,\n\u2022 when weighted by y in the sense y \u25e6 f , are included in each user dimension of the\nfeasible performance set of parallel channels.\nBy analogy to F\u0304(G, r), we can interpret the set F\u0304(G, r, y) as a kind of largest ball which is\nincluded in each user dimension of set (32), but which size is measured in a weighted (by y)\nEuclidean norm. Thus, the interval of max-min fair performance values (66) is influenced by\nthe structure of the set P(\u00c2) and functions fk , k \u2208 K, through the included weighted-norm\nball F\u0304(G, r, y) and the hull F\u0303(G, r) of any user dimension of set (32); the impact is purely\nvia the weighted norm gap\nmin hf , f i \u2212\n\nf\u2208F\u0303 (G,r)\n\nmax\n\nhf , f i,\n\n(1,y)\u2208X (RV ,r,1),F\u0304 (G,r,y)\n\n\fwhere RV is a factor of (57) for B \u2208 B3 (G, w) achieving the tighter lower bound, or a\nfactor of (57) for (43) when the outer lower bound is considered.\nRecall that under constraints on transmit power at any time in a frame, such as (4a), we\nhave F\u0304 (G, r) = F\u0304 (r) and F\u0303 (G, r) = F\u0303 (r) regardless of G, and thus the power allocations\nand channel sharing graph influence separately the numerator and denominator of the bounds\n(66). In addition to the impact of channel sharing combinatorics through the minimum of\n\u03bbmax (B) within (13) and (15) (respectively, via the Lovasz function and Delsarte bound\nextensions \u03b82 , \u03b83 ), we see that the looser lower bound in (66) is proportional to the weighted\nsquared 2-norm of y subject to (1, y) \u2208 X (RV , r, 1). Thus, the lower bound scales bilinearly\nwith the vector of scaling factors which are needed in column-wise scaling of a nonnegative\nfactor RV of (57) to attain row sums and column sums componentwise not exceeding (r, 1).\nAgain, as (57) is a feasible matrix of a certain subgraph of the sharing graph, the column\nsums of RV are determined by the channel sharing topology and by the vector w. It can\nbe observed that a factor RV which achieves smallest possible column sums is desired to\nprovide as tight as possible outer interval of max-min fair performance values in (66). The\nbounds (66) confirm the conclusion that we have the symmetric bounds (63) whenever matrix\n(57) satisfying (43) has a nonnegative factor with row sum vector no larger than r and no\ncolumn sum exceeding unity (in this case (63) is implied by (66) by taking y = 1, and we\nalso have F\u0304(G, r, 1) = F\u0304(G, r)).\nWe can finally conclude that each of the inequalities proposed so far allows us to embrace\nby bounds also the nonrestricted max-min fair performance of parallel channels, i.e. the\nmax-min fair performance when no sharing graph is given apriori. For instance, (62) implies\nminf\u2208F\u0303 (\u1e20,r) hf , f i\n\u03b82 (\u011c, w)\n\nmax\n\nB\u2208B3 (\u011c,w), V \u2208RK\u00d7N\n:\n+\n1\n\n1\u2032\n\n=\n\nmax\n\nminf\u2208F\u0303 (\u1e20,r) hf , f i\n\n\u03bbmax (B)\nhak , fk (pk )i2\n\u2265\n\u2265\nmax\nmin\n(A,P )\u2208A(r)\u00d7P(A) k\u2208K\n\u03b3k2\n\u03bc(RV ) maxf\u2208F\u0304 (\u1e20,r) hf , f i\n\u03bc(RV ) maxf\u2208F\u0304 (\u1e20,r) hf , f i\n,\n\u2265\n\u03bbmax (B)\n\u03b83 (\u011c, w)\nB\u2208B2 (\u011c,w)\n\nV V \u2032 =\u03bbmax \u22121 (B)(w 2 w 2 \u2212B)+I\n\nwhere \u011c is a max-min fair sharing graph, i.e. a graph induced by the max-min fair sharing\npolicy \u00c2, such that (33) (that is, we have \u011c = G(\u00c2) and \u00c2 \u2208 A(\u011c, r)). Clearly, the other\nbounds (58), (63), (65), (66) give rise to analogous enclosing of graph-nonrestricted max-min\nfair performance, when a max-min fair sharing graph is incorporated.\nD. Relation to the interference channel\nBy (66), one can recognize an interesting relation between max-min fair performance in\nparallel channels and the (weighted) throughput optimization in the interference channel\nconsidered in Section V-A. Lemma 4 and the definition of X (RV , r, 1) make evident\nthat vector y in the lower bounds in (66) corresponds to a certain power allocation in the\nassociated interference channel.\nCorollary 4: Let an interference channel with user population N have an interference\nN \u00d7N\nmatrix ((RV )\u2032 0)\u2032 \u2208 R+\n, describing the interference among users according to [46],\nwhich corresponds to any nonnegative factor of (57) such that (43). Then, y in the outer\nlower bound (66) is a power allocation in such interference channel which maximizes the\nweighted throughput\nX\nr\u0304k log SIRk (z), z \u2208 RN\n++ ,\nk\u2208K\n\nwith additive logarithmic power penalty terms (c\u0304k \u2212 r\u0304k ) log zk , k \u2208 K, and c\u0304k log zk , k \u2208\nN \\ K, for some (r\u0304, c\u0304) \u2264 (r, 1).\n\n\fPrecisely, by Lemma 4, the weight vectors (r\u0304, c\u0304) in the throughput function collect row\nand column sums obtained under columnwise scaling of RV by y. The interesting point is\nthat the throughput-optimal power allocation y in the described interference channel influences the pessimistic bounds on max-min fair performance in the related parallel channels.\nFor instance, the outer lower bound (66) becomes tighter if the taken nonnegative factor\n((RV )\u2032 0)\u2032 of the matrix (57) for the particular (43) represents such an interference matrix\nof the associated interference channel, which enforces higher user powers for optimizing\nthe weighted throughput from the corollary. Recall here that (57) is a feasible matrix of\nsome sharing subgraph G\u2032 \u2282 G, so that the candidate interference matrices of the associated\ninterference channel depend on the channel sharing topology in the original parallel channels.\nE. Role of sharing graph cycles\nWhat is apparent in all proposed inequalities enclosing the max-min fair performance\nso far, is the difference in the dependence on the channel sharing combinatorics between\nthe upper and lower bounds. Upper bounds depend on the given sharing graph G (and\nweight vector w) through the minimum eigenvalue \u03bbmax (B) among matrices B \u2208 B2 (G, w),\nrespectively through the associated value of the function \u03b82 . The lower bounds depend on\nthe channel sharing policy via the minimum of \u03bbmax (B) among matrices B from the smaller\nset B3 (G, w), respectively via the value which the function \u03b83 assumes for G and w. By the\nrecent results on completely positive graphs, we can, however, unify the dependence on the\nsharing graph for a large class of sharing graphs/topologies.\nProposition 6: Let G = (K, E) be any sharing graph with K \u2264 4 or including no odd\ncycles longer than 4. Then, the bounds from Propositions 4, 7 and Corollary 3 and the\nbounds (58), (62), (63), (65), (66) are satisfied with\nB2 (G, w) = B3 (G, w), and thus, \u03b83 (G, w) = \u03b82 (G, w).\nThe proposition is an immediate consequence of Lemma 2 and the definitions (14), (17).\nThe key to the above identity of \u03b82 and \u03b83 is that, for any sharing graph G with no more than\nK = 4 vertices or no odd cycles longer than 4, any feasible matrix (57) of a sharing subgraph,\nfor any B \u2208 B2 (G, w), is completely positive and not only doubly nonnegative (see proof\nof Lemma 2). Proposition 6 implies that whenever the parallel channels are accessed by no\nmore than K = 4 users, the value of the function \u03b82 assumed for the sharing graph G (and\nvector w) is a sufficient characterization of the sharing policy for enclosing the max-min fair\nperformance from above and from below, according to (58), (62), (63), (65) or (66). Similarly,\nthe value \u03b82 (G, w), for the given sharing graph G, is a sufficient description of the channel\nsharing for the proposed bounds (58), (62), (63), (65), (66) on max-min fair performance,\nwhen there is no odd chain of more than K = 4 users such that any two subsequent users\nshare some channel and the last user shares a channel with the first one (this makes up a\ncycle in the sharing graph). In particular, we have such property when the users accessing\nthe parallel channels can be partitioned into no more than M = 4 groups such that no pair\nof users within one group is allowed (or able) to share a channel; for instance, due to certain\nconstraints on traffic class processing or hardware. The channel sharing is represented in\nsuch case by an M-partite sharing graph, M = 2, 3, 4, with particular examples depicted in\nFig. 3. Two parallel channel instances of this type, and thus such that the bounds (58), (62),\n(63), (65), (66) are determined solely be the function \u03b82 , were presented in Examples 6 and\n7: In the multi-user multi-carrier channel from Example 6 certain user constellations are not\nallowed to share channels due to regulations on traffic processing, while in Example 7 the\nsharing of channels within some user classes is prevented/undesired because of excessive\ndifference of delay times.\nTo summarize, we note that whenever the parallel channels are shared according to\nany sharing graph G from Proposition 6, the proposed bounds enclosing the max-min fair\nperformance are determined by the spectral properties of the channel sharing combinatorics\n\n\fvia some value of \u03bbmax (B) among matrices B \u2208 B2 (G, w), respectively via the value of\n\u03b82 assumed by graph G and vector w collecting squared user performance requirements per\nassigned channel fraction. The structural features of the sharing topology have impact on\nthe bounds through the metric \u03bc, or row-sums, or column sums of a nonnegative factor of\na feasible matrix (57) of some sharing subgraph. As far as transmit power constraints at\nany time (in a frame) are considered, e.g. (4a), the impact of the (set of) allowable power\nallocations and the curvature of QoS functions is decoupled from the influence of the sharing\ngraph; it is mirrored by the gap separating the hull F\u0303 (r) from the largest included ball F\u0304(r)\nof each user dimension of the feasible QoS set.\nWe close the discussion on the max-min fair performance by discussing the issue of\nthe channel ensemble. It is evident from Corollary 1 and Propositions 4, 7 that the maxmin fair performance of parallel channels can be enclosed by bounds (58), (62), (63), (65),\n(66) whenever the number of accessed parallel channels satisfies (42). This means that the\nproposed bounds apply to non-overloaded parallel channels for which the (cardinality of)\nchannel population exceeds the (cardinality of) user population K at least by the factor\n(K + 1)/2. From the proofs of Propositions 4, 7 it is evident that such condition results\nfrom the use of the general nontight bound on cp-rank of matrix (57) implied by Lemmas\n1, 2. As a consequence, the class of parallel channels instances satisfying (42) can be\ngeneralized, depending on the particular matrices B \u2208 B3 (G, w) achieving the lower bounds\nin Propositions 4, 7. Precisely, the bounds (58), (62), (63), (65), (66) apply, more generally,\nwhen\n1\n1\u2032\nN \u2265 max{K + 1, \u03c6(\u03bbmax\u22121 (B)(w 2 w 2 \u2212 B) + I)}\nis satisfied for the corresponding matrices B \u2208 B3 (G, w) in the lower bounds. In other\nwords, the proposed bounds apply, more generally, when the channel population exceeds the\nuser population K by a factor no smaller than max{K + 1, \u03c6}/K, with \u03c6 as the cp-rank of\nmatrix (57), for B achieving the lower bound of interest.\nVI. C HARACTERIZATION OF SOME FAIR POLICIES\nThe proofs of the lower bounds from Propositions 4, 7 are constructive, that is, they contain\nimplicit specifications of certain parallel channels policies. This allows us in this section\nto derive some algorithms for the computation of fair policies in the case of predefined\ntopology, or equivalently graph, of parallel channels sharing. A fair policy is understood\nhere as a policy which ensures user performance of any user be no worse than some\nspecified pessimistic bound. According to Definition 1, a predefined sharing graph means\npredetermined binary relations consisting in sharing/no sharing of channels by the single\nuser pairs. We already explained in Section III that the predetermination of channel sharing\ntopology can be motivated by regulations on processing of different traffic classes, e.g. in the\nmanner as in the multi-user multi-carrier channel from Example 6. The fixing of a channel\nsharing graph can be also necessary under certain constraints on hardware and/or signal\nprocessing, similarly to the Example 7 of parallel channels.\nIn order to simplify the presentation, we assume that the predefined sharing topology\nresults in a sharing graph with no odd cycles longer than 4, so that we have the equivalence\nfrom Proposition 6 throughout this section. Also, we restrict our attention to constraints on\ntransmit power, e.g. by assuming individually constrained user power or constrained joint\npower budget of users at any time (in a frame) according to (4a): As a consequence, in what\nfollows we have F\u0303 (G, r) = F\u0303(r) and F\u0304(G, r) = F\u0304(r) regardless of the sharing graph G.\nIt is, however, easily verified that all the algorithmic concepts proposed in the following are\nstraightforwardly extendable to the case of energy constraints (per frame).\n\n\fA. Fair policy as orthonormal-like representation\nUsing the conventional optimization formulation, the problem of ensuring max-min fairness\nunder given channel sharing topology can be written as\n(\nhak , fk (pk )i\n(A, P ) \u2208 A(r) \u00d7 P\nmin max \u2212\n, subject to\n(67)\n(A,P ) k\u2208K\n\u03b3k\nhak , al i \u2264 0, (k, l) \u2208\n/ E,\nwhere the set E is such that K2 \\ E collects all user pairs which are not allowed to share a\nchannel or, equivalently (Definition 1), G = (K, E) is a given sharing graph11 . Conventional\noptimization methods (e.g. interior point methods [54]) allow for a global solution basically in\nthe case of convexity of the problem. Such feature is prevented in (67) since a bilinear form,\nused in the constraints, is not a convex function. Additionally, we consider very general\nperformance functions fk , k \u2208 K, and arbitrary constraints on transmit power, so that a\nstandard method solution of (67) is expected, in general, to be only local. In this light,\nresorting to efficient computation methods of (suboptimal) fair policies seems to be an\nattractive alternative.\nOne possible method is implied in the proof of Proposition 7 by the inequality (a reformulation of the first inequality in (81))\nhy \u25e6 f\u0302 , y \u25e6 f\u0302 i\nh\u00e2k , f\u0302 i2\n\u2264 min\n,\nk\u2208K\n\u03bbmax (B)\n\u03b3k2\n(\u00c2, q\n\nf\u0302\nhy \u25e6 f\u0302 , y \u25e6 f\u0302 i\n\n) = arg min max \u2212\n(A,c) k\u2208K\n\nhak , ci\n\u03b3k\n\nsubject to\n\n\uf8f1\nN\n\uf8f4\n\uf8f2 (A, c) \u2208 A(r) \u00d7 R+\nhak , al i \u2264 0, (k, l) \u2208\n/E\n\uf8f4\n\uf8f3 hy \u25e6 c, y \u25e6 ci \u2264 1,\n(68)\n\n12\ngiven any B \u2208 B2 (G, w(x)), with map z 7\u2192 w(z), z \u2208 RK\n7.\n++ , defined in Proposition\nHereby, any vectors x, y satisfying (x, y) \u2208 X (RV , r, 1) for (45) can be chosen. It is evident\nby (11) that the problem in (68) is closely related to the computation of an orthonormal\nrepresentation and a unit vector which achieve the value of the Lovasz function (11) (recall\nthe definition of orthonormal representation from Section III): In (68), the unit vector c is,\nhowever, considered in weighted norm and is additionally restricted to be nonnegative, while\nthe constraints on A are expressed in 1-norm. The complexity of the problem in (68) is\nsignificantly reduced in relation to the original problem (67). We can restate this problem as\nan instance of so-called bilinear program by replacing the objective by some variable s and\nby adding the inequalities hak , ci/\u03b3k \u2212 s \u2264 0, k \u2208 K, to the constraints. Although a bilinear\nprogram does not represent a convex problem, there exists a variety of efficient methods for\nits global and local solution; without giving further details we refer for a selection of such\nmethods to [55], [56] and references therein.\n) obtained from the bilinear\nClearly, in the orthonormal-like representation (\u00c2, \u221a f\u0302\nhy\u25e6f\u0302,y\u25e6f\u0302i\n\nprogram in (68) vector f\u0302 is arbitrarily scalable by \u03b1 > 0. Due to our assumption (2), a\npower allocation P\u0302 \u2208 P satisfying\nfk (p\u0302k ) = \u03b1f\u0302 ,\n\nk \u2208 K,\n\n(69)\n\nalways exists and is trivially constructed whenever \u03b1 > 0 is chosen sufficiently small: Under\nan appropriate \u03b1, any user k \u2208 K accessing the parallel channels simply assigns on any\nchannel n \u2208 N a transmit power p\u0302kn which achieves performance \u03b1f\u02c6n and the resulting\npower allocation P\u0302 remains allowable. By iterative increasing of \u03b1 in suitably small steps,\n11\n\nNote, that the inequality in the second constraint in (67) is equivalent to equality as nonnegativity is implicit from\nA \u2208 A(r).\n12\nFrom the objective of the problem it is readily seen that the last inequality constraint can be replaced by equality.\n\n\fwe achieve, with some accuracy, the particular largest \u03b1 for which (69) is yet fulfilled for\nsome P\u0302 \u2208 P. Under a simple structure of the set of allowable power allocations, e.g. (4a),\nsuch value of \u03b1 is often computable directly/non-iteratively once the performance functions\nfk , k \u2208 K, are known. For such particular \u03b1 we achieve the tightest lower bound in (68)\namong all \u03b1f\u0302 inside the set F\u0302 (r, y) which is further smaller than the corresponding bound\nfor any \u03b1f\u0302 \u2208 F\u0304 (r, y) (recall (82), (83)).\nBy (the proof of) Lemma 4, a candidate vector y in (68) is computable as a solution\nof an unconstrained convex problem. As a first approach we prefer, however, to apply the\nsimplification y = 1, which implicitly enforces x to satisfy (x, 1) \u2208 X (RV , r, 1). This\nresults in the following simple procedure, for which r, \u03b3k , k \u2208 K, and the set E of user pairs\nnot allowed to share a channel (equivalently, sharing graph G = (K, E)) are given as input\nparameters along with some suitably small \u03b1, \u03b4 > 0.\nAlgorithm 1:\n1: Find a sharing matrix \u00c2 and vector f\u0302 from (68), y = 1, by any bilinear programming\nmethod [55], [56].\n2: Compute a power allocation P\u0302 from (69).\n3: If P\u0302 \u2208 P then set \u03b1 7\u2192 \u03b1 + \u03b4 and go to step 2, otherwise stop.\nWith Proposition 6, the user performance of the obtained fair policy (\u00c2, P\u0302 ) is immediately\nevident from the proof of Proposition 7 (see bounds (65)).\nCorollary 5: Given E such that G = (K, E) has no odd cycles longer than 4, the policy\n(\u00c2, P\u0302 ) from Algorithm 1 satisfies the bounds from Proposition 7 for y = 1, which implies\nminf\u2208F\u0303 (r) hf , f i\n\u03b82 (G, w)\n\n\u2265 min\nk\u2208K\n\nmink\u2208K xk maxf\u2208F\u0304 (r) hf , f i\nh\u00e2k , fk (p\u0302k )i2\n,\n\u2265\n2\n\u03b3k\n\u03b82 (G, w)\n\nwhere (x, 1) \u2208 X (RV , r, 1) subject to (45) and\nB = arg\nThus, mink\u2208K\n\nh\u00e2k ,fk (p\u0302k )i2\n\u03b3k2\n\nmin\n\nB\u0304\u2208B2 (G,w)\n\n\u03bbmax (B\u0304).\n\n(70)\n\nis at most\n\nminf\u2208F\u0303 (r) hf , f i \u2212 mink\u2208K xk maxf\u2208F\u0304 (r) hf , f i\n\u03b82 (G, w)\n\n,\n\n(71)\n\naway from the max-min fair performance under given E.\nFig. 6 provides an exemplary comparison between the user performance achieved by the\npolicy from Algorithm 1 and the max-min fair performance. For the evaluated ensemble\nof parallel channels (with their sharing graphs) we observe a loss of about 20 % to the\nmax-min fair performance. One can also show by simulation that such loss decreases if the\ndifferences between the user channel vectors hk , k \u2208 K, and the differences between the\nvariance ensembles \u03c3kn , n \u2208 N , of users k \u2208 K diminish. In fact, this behavior can be\nrecognized already from the feature (69) of the policy from Algorithm 1, which means that\nthe resulting performance function value is the same for all users. Using Corollary 5, the\nsame limit behavior can be also deduced from Figs. 4 and 5 since in the case of similar\nchannel vectors and variance ensembles the (forms of) user dimensions of the feasible QoS\nset become similar as well and make the 2-norm gap between the hull F\u0303(r) and the ball\nF\u0304 (r) vanish. As can be expected conversely, under variations between the channel vectors\nand variance ensembles of users becoming more severe, the loss of the policy from Algorithm\n1 increases.\nThe advantageous complexity-performance trade off of Algorithm 1 becomes evident when\nthe bilinear program in (68) and the original problem solution (67) are both computed by\nthe same local optimization method. As shown in Fig. 7 for some selected parallel channel\n\n\f10\nmax\n\nmin hak ,fk1(pk ,j)i\n\n9\n\nmin h\u00e2k (j),fk1(p\u0302k (j),j)i\nk\u2208K\n\n8\n\n(A,P )\u2208A(G(j),N/K1)\u00d7P k\u2208K\n\n7\n6\n5\n4\n3\n2\n1\n0\n\n20\n\n40\n\n60\n\n80\n\nj\n\n100\n\nFig. 6. The comparison of user performance under the policy (\u00c2, P\u0302 ) from Algorithm 1 (dashed line) with the max-min fair\nperformance (solid line), with sum-power constraint (4a) and with the capacity (8) as performance function. We simulated\nparallel channels with K = 4 users accessing N = 6 channels, equal user performance requirements \u03b3k = 1, k \u2208 K, and\nr = N/K1. The sharing graphs G(j), 1 \u2264 j \u2264 100, were picked randomly from all graphs with vertex set K and edges\noccurring independently with probability 0.5. The channels hkn (j) and the variances \u03c3kn (j), 1 \u2264 j \u2264 100 were picked\nrandomly from uniform distributions resulting in an average Signal-to-Noise Ratio of 20 dB.\n\ninstances (and sharing graphs), the efficient and widely used Broyden-Fletcher-GoldfarbShanno (BFGS) method may be attracted by highly suboptimal local optima of the original\nnonlinear problem. On the other hand, the values of the local optima of the bilinear program\nin (68) are apparently much less scattered, so that the same BFGS method is able to find\na good (local) solution (68) quite reliably. As a result, the worst user performance under\npolicy from Algorithm 1 happens to be superior to the locally computed max-min fair policy\n(under given sharing graph).\nAs a second approach to the scaling of RV , instead of the simplification y = 1 we can find\na scalar scaling so that (1, y1) \u2208 X (RV , r, 1) for some y > 0. In this case, w(x) reduces to\nw defined as (21) and thus matrix B, which gives rise to the nonnegative factorization (45),\nneeds to satisfy B \u2208 B2 (G, w). In the best case, a particular matrix (70) is desired. Since the\nconstraints determining the set (13) are linear, the problem in (70) corresponds to eigenvalue\nminimization over a polyhedron, which is a canonical problem in optimization theory and\na variety of efficient solution methods exists [54]. For the nonnegative factorization of any\ngiven B \u2208 B2 (G, w), or the particular (70), we use one of the two celebrated methods which\nare proposed in [57] and are further extended and analyzed e.g. in [58], [59]. Precisely, for\nany m \u2208 N, we apply the particular form\n\n1\u2032\n1\n(V (m))kn X (V (m))ln (\u03bbmax \u22121 (B)(w 2 w 2 \u2212 B) + I)kl\n(V (m + 1))kn = \u2032\n, (k, n) \u2208 K\u00d7N ,\n(1 V (m))n l\u2208K\n(V (m)V \u2032 (m))kl\n(72)\nof the factorization iteration from Theorem 2 in [57]. The sequence RV (m), m \u2208 N,\nobtained by (72) converges monotonically to a matrix RV which achieves a stationary point\nof the generalized Kullback-Leibler (KL) divergence between RV V \u2032 R and (57) (for the\ndefinition of this divergence and further discussion we refer to [57]). The minimization of\nthe generalized KL divergence between a matrix and its factorization is an intricate problem\nwith multiple local minima, so that RV V \u2032 R obtained from (72) can happen to remain at\na nonzero, but relatively small, generalized KL divergence to (57). For this reason, we can\nresort also to alternative factorization iterations, such as the gradient descent method, which\n\n\f0\nmin \u2212hak (j),f1 k (pk ,j)i\nk\u2208K\n\nmin \u2212h\u00e2k (j),f1k (p\u0302k (j),j)i\nk\u2208K\n\n\u22121\n\u22122\n\u22123\n\u22124\n\u22125\n\u22126\n\u22127\n\u22128\n\u22129\n\n\u221210\n0\n\n2\n\n4\n\n6\n\n8\n\nj\n\n10\n\nFig. 7. The comparison of user performance under the policy (\u00c2, P\u0302 ) from Algorithm 1 using the BFGS method in step\n1 (dashed line), and under policy (A, P ) as a local BFGS solution to problem (67) (solid line), with sum-power constraint\n(4a) and with the capacity (8) as performance function. We simulated the parallel channels as in Fig. 6, but for K = 3,\nN = 4 and an average Signal-to-Noise Ratio of 10 dB.\n\nseem, however, to be inferior to the methods from [57] in terms of complexity-convergence\ntrade off [57], [59].\nThe above discussion leads to the following second procedure which uses r, \u03b3k , k \u2208 K,\nand E as input data and some sufficiently small parameters \u03b1, \u03b4 > 0.\nAlgorithm 2:\n1: Compute a matrix (70) by any convex eigenvalue minimization method [54].\n2: Compute V by the iteration (72).\n\u2032\n\u2032\n3: Compute the largest solution y > 0 of the inequalities y1 RV \u2264 1 , yRV 1 \u2264 r.\n4: Find a sharing matrix \u00c2 and vector f\u0302 from (68), y = y1, by any bilinear programming\nmethod [55], [56].\n5: Compute a power allocation P\u0302 from (69).\n6: If P\u0302 \u2208 P then set \u03b1 7\u2192 \u03b1 + \u03b4 and go to step 5, otherwise stop.\nBy Proposition 6, Theorem 2 in [57] and the proof of Proposition 7 we have the following\nresult on the user performance under the fair policy (\u00c2, P\u0302 ) from Algorithm 2.\nCorollary 6: Assume the generalized KL divergence between (57) and RV , with V computed in step 3 of Algorithm 2, be zero and let E such that G = (K, E) has no odd cycles\nlonger than 4 be given. Then, the policy (\u00c2, P\u0302 ) from Algorithm 2 satisfies the bounds from\nProposition 7 for y = y1, with y computed in step 3, which implies\nminf\u2208F\u0303 (r) hf , f i\n\u03b82 (G, w)\n\nThus, mink\u2208K\n\nh\u00e2k ,fk (p\u0302k )i2\n\u03b3k2\n\n\u2265 min\nk\u2208K\n\nmaxf\u2208F\u0304 (r,y1) hyf , yfi\nh\u00e2k , fk (p\u0302k )i2\n.\n\u2265\n2\n\u03b3k\n\u03b82 (G, w)\n\n(73)\n\nis at most\nminf\u2208F\u0303 (r) hf , f i \u2212 maxf\u2208F\u0304 (r,y1) hyf , yfi\n\u03b82 (G, w)\n\n(74)\n\naway from the max-min fair performance under given E.\nObviously, by adding more technicality, Corollary 6 can be extended to the case when the\nfactorization iteration in step 3 happens to converge only locally, i.e., when the KL divergence\nbetween RV V \u2032 R and (57) does not vanish.\n\n\fThe performance and complexity-performance trade off of the policy from Algorithm 2\nbehaves, essentially, quite identically to the policy from Algorithm 2 (see Figs. 6, 7). The\npotential nonzero KL divergence remaining after iteration by (72) is hereby hardly visible.\nB. Fair policy from factorization\nTo summarize so far, by the Algorithms 1, 2, the solution of the original intricate problem\n(67) is replaced by some algebraic operations and the solution of canonical, more efficiently\nsolvable optimization problems: The sharing matrix is obtained directly from the solution\nof a bilinear program, while the power allocation results from simple scaling (Algorithm\n1), respectively, from the solution of eigenvalue minimization, nonnegative factorization and\nscaling (Algorithm 2). As the price payed for this simplification, the resulting fair parallel\nchannels policies are suboptimal, but achieve the worst user performance within the distances\n(71) and (74), respectively, from the optimum under given sharing graph G.\nThe proof of Proposition 7 implies, however, that a bilinear program can be further\nexchanged here by nonnegative factorization and a solution of a simple equation system.\nThe key step of the proof which gives rise to such alternative algorithm is the equality (see\n(80))\nhy \u25e6 f\u0302 , y \u25e6 f\u0302 i\nh\u00e2k , f\u0302 i2\n=\n, k \u2208 K, B \u2208 B2 (G, w(z)),\n(75)\n\u03bbmax (B)\n\u03b3k2\nfor the given sharing graph G, for any B \u2208 B2 (G, w(z)), for map x 7\u2192 w(x), x \u2208 RK\n++ ,\nK\nN\ndefined in Proposition 7 and for some z \u2208 R++ , \u00c2 \u2208 A(G, r), f\u0302 \u2208 R+ related as follows.\n\u2022 Any sharing matrix \u00c2 results from scaling of a factor RV , such that (45), by a scaling\n(Z, Y ) with (z, y) \u2208 X (RV , r, 1), where Z1 = z, Y 1 = y.\n\u2032\n\u2022 Factor RV can be split as (49), w = w(z), with X = (x1 , . . . , xK ) as a factor of\n\u22121\nK\u00d7N\nI \u2212 \u03bbmax (B)B, where C = (c, . . . , c)\u2032 \u2208 R+\nis orthogonal according to (47) and\ny\u25e6f\u0302\n\u221a\n= c.\ndetermines f\u0302 as\nhy\u25e6f\u0302,y\u25e6f\u0302i\n\nAgain, in the best case, a nonnegative factor RV of a particular matrix (70), w = w(z),\nobtained from canonical eigenvalue minimization [54], is desired. As above, such factor is\ncomputable by the version (72) of a factorization method from [57]. Once a factor RV is\ncomputed, vector f\u0302 follows as a solution of a simple vector equation. Precisely, combining\n(49) with the definition \u221a y\u25e6f\u0302\n= c and the orthogonality condition (47) shows that f\u0302 is\nhy\u25e6f\u0302,y\u25e6f\u0302i\n\na solution to the equation\nVp\n\ny\u25e6f\n\nhy \u25e6 f , y \u25e6 f i\n1\n\n1\n\n\u2212 \u03bbmax \u22121 (B)W 2 (z) = 0,\n1\n\n1\n\nf \u2208 RN\n+,\n1\n\n(76)\n\nwhere the definition W 2 (z) = diag(W 2 (z)), (W 2 (z))kk = w 2 (z)k , k \u2208 K, is obvious.\nWe are free to solve the equation (76) by any available numerical method; we refer here\nto [60] for a wide selection of such methods. Any solution to (76) is arbitrarily scalable\nby a positive \u03b1 and from the discussion in Section VI-A it is clear how a power allocation\nP\u0302 \u2208 P satisfying (69) is constructed for a sufficiently small \u03b1. Again, by gradual increasing\nthe particular largest \u03b1 is found, for which (69) yet holds for some allowable power allocation\nP\u0302 \u2208 P. For such an \u03b1, \u03b1f\u0302 achieves the value of the left hand side of (75), which is further\nno smaller than the corresponding maximum value among all \u03b1f\u0302 \u2208 F\u0304 (r, y).\nAs a simplified approach to the scaling of RV , we find a scalar scaling which yields\n(1, y1) \u2208 X (RV , r, 1), for some y > 0. Since then w(z) reduces to w given by (21) and\nmatrices B \u2208 B2 (G, w) have to be considered, the above discussion results in the following\nprocedure (as above, E, r, and \u03b3k , k \u2208 K, together with suitably small \u03b1, \u03b4 > 0 are given\nas input parameters).\nAlgorithm 3:\n\n\f8\nmax\nmin hak ,fk1(pk ,j)i\n(A,P )\u2208A(G(j),N/K1)\u00d7P k\u2208K\n\n7\n\nmin h\u00e2k (j),fk1(p\u0302k (j),j)i\nk\u2208K\n\n6\n5\n4\n3\n2\n1\n0\n\n20\n\n40\n\n60\n\n80\n\nj\n\n100\n\nFig. 8. The comparison of user performance under the policy (\u00c2, P\u0302 ) from Algorithm 3 (dashed line) with the max-min fair\nperformance (solid line), with sum-power constraint (4a) and with the capacity (8) as performance function. We simulated\nthe parallel channels as in Fig. 6, but for K = 6 and N = 7.\n\nCompute a matrix (70) by any convex eigenvalue minimization method [54].\nCompute V by the iteration (72).\n3: Compute the sharing matrix \u00c2 = yRV , for the largest solution y > 0 of the inequalities\ny1\u2032 RV \u2264 1, yRV 1 \u2264 r.\n4: Compute a solution f\u0302 to equation (76) by any numerical method [60].\n5: Compute a power allocation P\u0302 from (69).\n6: If P\u0302 \u2208 P then set \u03b1 7\u2192 \u03b1 + \u03b4 and go to step 5, otherwise stop.\nAccording to Proposition 6, Theorem 2 in [57] and Proposition 7, the fair policy (\u00c2, P\u0302 )\ncomputed by Algorithm 3 achieves the following user performance.\nCorollary 7: Assume the generalized KL divergence between (57) and RV , with V computed in step 2 of Algorithm 3, be zero and let E such that G = (K, E) has no odd cycles\nlonger than 4 be given. Then, the policy (\u00c2, P\u0302 ) from Algorithm 3 satisfies the bounds\nfrom Proposition 7 for y = y1, with y computed in step 3, which implies (73). Thus,\n2\nk )i\nmink\u2208K h\u00e2k ,f\u03b3k (p\u0302\nis at most (74) away from the max-min fair performance under given E.\n2\nk\nFig. 8 shows an exemplary comparison of user performance achieved under the policy from\nAlgorithm 3 and the max-min fair performance. It is evident that the average loss to the\nmax-min fair performance is about 23 % for the simulated instances of parallel channels and\ntheir sharing graphs (thus, the potential nonzero KL divergence remaining after iteration (72)\ndoes hardly manifest itself in a gap to the performance of Algorithm 1). By the feature (69),\nor by Corollary 7 and the Figs. 4, 5, we recognize again that such loss evolves analogously\nas in the case of Algorithms 1 and 2; it decreases with the user channel vectors and user\nnoise variance ensembles converging to common values, and increases with the corresponding\nvariations becoming stronger.\n1:\n\n2:\n\nVII. C ONCLUSIONS\nThis work allows for several novel conclusions on the behavior of the max-min fair performance in parallel channels, understood as the maximum attainable worst user performance.\nWe assumed a very general performance function which is subject to the max-min fairness\ncriterion; it includes the most celebrated functions in communications and information theory\n(capacity, spectral efficiency, decoder reliability) as very special cases. We succeeded in\n\n\fembracing the max-min fair performance by optimistic and pessimistic bounds which show,\nunder constraints on transmit power, the same behavior as functions of the channel sharing\ntopology. This lead to the first central conclusion that the max-min fair performance in parallel\nchannels behaves as a special extension of the Lovasz function, or Delsarte bound, of a certain\ngraph G (the sharing graph) characterizing the combinatorial topology of channel sharing\namong the users. An essential role is played hereby by the minimum spectral characterization\n\u03bbmax (B) achievable within certain G-dependent sets B2 (G, w), B3 (G, w) with vector w as a\nparameterizing vector determined by the user performance requirements. When such spectral\ncharacterization of the channel sharing topology is obtained, the characterization of the realvalued subproblem of power allocation to users and shared channels by a simple 2-norm\ndistance is sufficient for embracing the max-min fair performance by the proposed bounds:\nThe influence of all properties of the allowable power allocations and all analytic features of\nthe used QoS functions on the max-min fair performance is accumulated in a simple 2-norm\ngap between a certain hull and a certain included ball of the feasible QoS set of the parallel\nchannels.\nOur results showed also that a key role is played by the existence/nonexistence of cycles in\nthe sharing graph, interpretable as closed chains of users such that any two subsequent users\nin such a chain share a channel: We showed that under nonexistence of long odd chains\nof such type, the max-min fair performance is characterized by the minimum achievable\n\u03bbmax (B) in the specific set B2 (G, w) as a function of the channel sharing topology (and the\ngap between the proposed bounds is equal precisely to the 2-norm gap between some hull\nand some included ball of the feasible QoS set). As a byproduct of our calculations, we\nalso illustrated a relation of the max-min fair performance in parallel channel to the graph\ncapacity and independence number of the graph describing the channel sharing topology.\nThe constructive proofs of our bounds allowed further for the formulation of three novel\npower and time allocation algorithms for parallel channels with predefined channel sharing\ntopologies (which is the case, e.g., under certain regulations/constraints on QoS class processing). The algorithms offer a nice performance-complexity trade off and incorporate some\nsurprising techniques, such as nonnegative factorization.\nA PPENDIX\nA. Doubly nonnegative and completely positive matrices\nDefinition 5 ([44]): A matrix X \u2208 RK\u00d7K is said to be doubly nonnegative, and we write\nX \u2208 DK , if D \u2208 RK\u00d7K\nand D \u0017 0.\n+\nIn simple words, a matrix X \u2208 DK is nonnegative in the conventional order \u2265 on RK\u00d7K\nand in the partial order \u0017 on the set of symmetric matrices in RK\u00d7K .\nDefinition 6 ([44]): A matrix X \u2208 RK\u00d7K is said to be completely positive, and we write\nX \u2208 PK , if there exists some N \u2208 N such that\nX =YY\u2032\n\nfor some\n\nY \u2208 RK\u00d7N\n.\n+\n\n(77)\n\nThe smallest number N for which we have (77) is referred to as the cp-rank of X and is\ndenoted as N = \u03c6(X).\nCondition (77) is frequently used in its equivalent form as\nX=\n\nN\nX\ni=1\n\ny i y \u2032i\n\nfor some y i \u2208 RK\n+,\n\n1 \u2264 i \u2264 N,\n\nwhere Y = (y 1 , . . . , y N ) is assumed.\nBy Definition 6, it is readily seen that X \u2208 PK implies X \u2208 DK (PK \u2282 DK ). By the\ncelebrated result from [44] it is further known that PK = DK whenever K \u2264 4, while\notherwise examples of matrices X \u2208 DK such that X \u2208\n/ PK can be constructed.\n\n\fB. Association schemes\nFrom the view of graph theory, the most accessible definition of an association scheme is\nbased on the notion of edge coloring of a graph, as a partition of its edge set into vertexdisjoint edge classes. Precisely, an edge M-coloring of a graph G = (K, E) corresponds to\nthe tuple (K, {Ei }M\ni=1 ), where (k, l), (m, n) \u2208 Ei implies that k 6= m and l 6= n [30].\nDefinition 7 ([61]): An association scheme with M associate classes on a set K is an\nedge M-coloring of a (complete) graph G = (K, K2 ) such that\ni.) for any 1 \u2264 k, l, m \u2264 M there exists so called intersection number pm\nkl \u2208 N such that\nm\npkl = |{n \u2208 K : (i, n) \u2208 Ek , (n, j) \u2208 El }| whenever (i, j) \u2208 Em ,\nii.) for any 1 \u2264 k \u2264 M there exists qk \u2208 N such that qk = |{(i, j) \u2208 Ek : i = n}| for any\nn \u2208 K.\niii.) Ek 6= \u00f8, 1 \u2264 k \u2264 M.\nDefinition 8: Given an association scheme (K, {Ei }M\ni=1 ) and any M \u2282 {1, . . . , M}, we\nrefer to L \u2282 K as an M-clique of the association scheme if i, j \u2208 L, i 6= j, implies\n(i, j) \u2208 \u222am\u2208M Em .\nFor any association scheme (K, {Ei }M\ni=1 ) and any its M-clique L \u2282 K, the unweighted\nDelsarte number can be formulated as the map\n((K, {Ei }M\ni=1 ), L, M) 7\u2192\n\nmax\n\na\u2208A1 ((K,{Ei }M\ni=1 ),L,M):\n1+ha,\u03c3i\u22650\n\n1 + ha, 1i,\n\n(78)\n\nwhere A1 ((K, {Ei }M\ni=1 ), L, M) denotes the set of so-called inner distributions of the Mclique L and \u03c3 = (\u03c31 , . . . , \u03c3M ) \u2208 RM collects especially normalized eigenvalues of the\nadjacency matrices of graphs (K, Em ), 1 \u2264 m \u2264 M, having a common eigenvector [39].\nC. Additional bound formulations\nCorollary 8: Given N \u2265 K, any G = (K, E) and any (A, P ) \u2208 A(G, r) \u00d7 P(A),\nr \u2208 RK\n++ , we have\nmin\nk\u2208K\n\nminf\u2208RN+ hf , f i\nhak , fk (pk )i2\n,\n\u2264 i\n2\n\u03b3k\n\u03b8 (G(A), w(f ))\n\ni = 0, 1, 2,\n\n(79)\n\nwhere f 7\u2192 w(f ), f \u2208 RN\n+ , is such that, for any k \u2208 K,\n\n\u03b3k2 hak , f i2\n\u03b3k2 hak , f i2\nif\ni\n=\n1,\nw\n(f\n)\n=\nif i = 0, 2.\nk\nrk2 hak , fk (pk )i2\nrk2 hak , fk (pk )i2\nProof: The proof is a slight modification of the proof of Proposition 3. For any A \u2208\nA(G, r), f \u2208 RN\n6 0, k \u2208 K (which by our\n+ and P \u2208 P(A) such that hak , fk (pk )i =\nassumptions on P(A) and fk , k \u2208 K, exists), let Z = (z 1 , . . . , z K )\u2032 \u2208 RK\u00d7N , be given as\ns\np\n\u03b3k hf , f i\nwk (f )\nzk =\nf\u2212\nak , k \u2208 K.\nhf , f i\nrk hak , fk (pk )i\nwk (f ) \u2264\n\nThen,\np\np\np\n\u03b3k wl (f )hak , f i \u03b3l wk (f )hal , f i\n\u03b3k \u03b3l hf , f ihak , al i\n\u2212\n+\n,\nhz k , z l i= wk (f )wl (f )\u2212\nrk hak , fk (pk )i\nrl hal , fl (pl )i\nrk rl hak , fk (pk )ihal , fl (pl )i\n\nfor any k, l \u2208 K, so that by the definition of w in the case i = 0, 2 we yield again (24), with\n\u03b3 2 ha ,a ihf,fi\nw = w(f ) and with hz k , z k i = \u2212wk (f ) + rk2 hakk ,fkk(p )i2 in particular, while by Definition\nk\nk\n1 again (25) for w = w(f ) is satisfied. In the case of i = 1, the definition of w implies\n\u03b3 2 ha ,a ihf,fi\nhz k , z k i \u2264 \u2212wk (f ) + rk2 hakk ,fkk(p )i2 and together with Definition 1 also\nk\nk\np\nhz k , z l i \u2264 \u2212 wk (f )wl (f ), (k, l) \u2208\n/ E, k 6= l.\n\n\fThus, given i = 0, 2, we can write (26) with \u0100 = A and w = w(f ) by the definition (13),\nwhile \u2212B \u0017 ZZ \u2032 \u2212 hf , f iG(A) is satisfied for some B \u2208 B1 (G, w(f )) in the case i = 1.\nIn either case (27) is implied and up from (27) the proof goes as the proof of Proposition\n3.\nProposition 7: Given any G = (K, E) and r \u2208 RK\n++ , we have\nmax\n\nmin\n\n(A,P )\u2208A(G,r)\u00d7P(A) k\u2208K\n\nhak , fk (pk )i2\n\u2265\n\u03b3k2\n\nmax\n3\n\nB\u2208B (G,w(x))\n(x,y)\u2208X (RV ,r,1), V \u2208RK\u00d7N\n:\n+\n1\n\nmaxf\u2208F\u0304 (G,r,y) hy \u25e6 f , y \u25e6 f i\n,\n\u03bbmax (B)\n\n1\u2032\n\nV V \u2032 =\u03bbmax \u22121 (B)(w 2 w 2 \u2212B)+I\n\nwhere x 7\u2192 w(x), x \u2208 RK\n++ , is such that\nwk (xk ) =\n\n\u03b3k2\n,\n(xk rk )2\n\nk \u2208 K,\n\nwhere N \u2208 N satisfies (42), and where, given \u00c2 defined as in Corollary 1, we defined\nF\u0304(G, r, y) = {f \u2208 RN\n+ :hy \u25e6 f\u0304 , y \u25e6 f\u0304 i \u2264 hy \u25e6 f , y \u25e6 f i \u21d2\nf\u0304 = fk (pk ), k \u2208 K,\n\ny \u2208 RN\n++ . Moreover, given a particular\n\nB = arg\n\nmin\n\nB\u0304\u2208B3 (G,w(x))\n\nfor some P \u2208 P(\u00c2)},\n\n\u03bbmax (B\u0304),\n\nthis further implies\nmax\n\nmin\n\n(A,P )\u2208A(G,r)\u00d7P(A) k\u2208K\n\nhak , fk (pk )i2\n\u2265\n\u03b3k2\n\nmax\n\n(x,y)\u2208X (RV ,r,1), V \u2208RK\u00d7N\n:\n+\n1\n\nmaxf\u2208F\u0304 (G,r,y) hy \u25e6 f , y \u25e6 f i\n.\n\u03b83 (B, w(x))\n\n1\u2032\n\nV V \u2032 =\u03bbmax \u22121 (B)(w 2 w 2 \u2212B)+I\n\nProof: Under the substitution w = w(x), with an arbitrary x \u2208 RK\n++ , the proof goes\nexactly as the proof of Proposition 4 up to the implication (52) for any f \u2208 RN\n+ such that\n\u221a f = c is satisfied for the particular c from (50). Again, by Lemma 3, it follows that we\nhf,fi\n\ncan always find some (z, y) \u2208 X (RV , r, 1) such that (45), w = w(x), and thus we have\nU \u2208 A(G, r) for U = ZRV Y with Z1 = z, Y 1 = y. Writing now f = y \u25e6 f\u0304 , for some\n\u2032\nf\u0304 \u2208 RN\n+ , and U = (u1 , . . . , uK ) and setting x = z, we have by the definition of the map\nx 7\u2192 w(x), x \u2208 RK\n++ , that\n\u03b3k2\n\u03b3k2\n\u03b3k2\nwk (zk )\nP\nP\n=\n,\n=\n=\nhvk , y \u25e6 f\u0304 i2\n( n\u2208N zk rk (v k )n yn f \u0304n )2\n( n\u2208N (uk )n f \u0304n )2\nhuk , f\u0304 i2\n\nk \u2208 K.\n\nWith (52), w = w(z), this yields\n\n\u03bbmax (B)\n\u03b3k2\n,\n=\nhy \u25e6 f\u0304 , y \u25e6 f\u0304 i\nhuk , f\u0304 i2\n\n\u221a\nfor any f\u0304 \u2208 RN\n+ such that\n\ny\u25e6f\u0304\n\nhy\u25e6f\u0304,y\u25e6f\u0304i\n\nk \u2208 K,\n\n(80)\n\n= c is satisfied for c from (50). By our assumption (2)\n\nand the assumptions on fk , k \u2208 K, we can always find a particular f\u0304 such that f\u0304 = fk (pk ),\nk \u2208 K, for an arbitrary A \u2208 A(G, r) and some P \u2208 P(A), so that it is implied then with\n(80) that\n\u03b3 2 hy \u25e6 f , y \u25e6 f i\nmax k\n\u03bbmax (B) \u2265\nmin\nk\u2208K\nhak , f i2\n(A,f)\u2208A(G,r)\u00d7RN\n+\n=\n\nmin\n\nmax\n\nk\u2208K\nA\u2208A(G,r),f\u2208RN\n+:\nf=fk (pk ),k\u2208K, for some P \u2208P(\u00c2)\n\n\u03b3k2 hy \u25e6 f , y \u25e6 f i\n\u03b3k2 hy \u25e6 f\u0302 , y \u25e6 f\u0302 i\n=\nmin\nmax\nA\u2208A(G,r) k\u2208K\nhak , f i2\nhak , f\u0302 i2\n(81)\n\n\ffor any f\u0302 \u2208 F\u0302(G, r, y). Hereby, we defined (as a straight generalization of F\u0302 (G, r))\nF\u0302 (G, r, y) = {f \u2208 RN\n+ :f = fk (pk ), k \u2208 K,\n\nfor some P \u2208 P(\u00c2),\nh\u0101k , f\u0304 i2\n}.\nf = arg max max min 2\nk\u2208K \u03b3 hy \u25e6 f\u0304 , y \u25e6 f\u0304 i\nf\u0304\u2208RN\n+ \u0100\u2208A(G,r)\nk\n\n(82)\n\nThus, it follows finally that\n\u03bbmax (B)\n\u03b3k2\n\u2265\nmin\nmax\n,\nhy \u25e6 f , y \u25e6 f i (A,P )\u2208A(G,r)\u00d7P(\u00c2) k\u2208K hak , fk (pk )i2\n\nfor any B \u2208 B3 (G, w(z)), any V such that (45), w = w(z), any y satisfying (z, y) \u2208\n\u2032\n1\n1\nX (RV , r, 1) and N \u2265 max{K + 1, \u03c6(\u03bbmax\u22121 (B)(w 2 (z)w 2 (z) \u2212 B) + I)}. Hereby, by\nLemmas 1, 2, the last condition is implied by N \u2265 K(K + 1)/2 and additionally, along\nexactly the same lines as in the proof of Corollary 3, it is readily shown that\nhy \u25e6 f , y \u25e6 f i \u2264\n\nmax\n\nhy \u25e6 f\u0304 , y \u25e6 f\u0304 i,\n\nf\u0304\u2208F\u0302 (G,r,y)\n\nf \u2208 F\u0304 (G, r, y).\n\n(83)\n\nThis completes the proof of the first inequality of the proposition, while the second inequality is obtained by taking a particular B\u0304 with \u03bbmax (B\u0304) = maxB\u2208B3 (G,w(z)) \u03bbmax (B) =\n\u03b83 (G, w(z)).\nR EFERENCES\n[1] L. Tassiulas and S. Sarkar, \"Maxmin Fair Scheduling in Wireless Networks,\" Proc. IEEE Conference on Computer\nCommunications (Infocom), Jun 2002.\n[2] B. Radunovic and J.-Y. L. Boudec, \"Why Max-min Fairness Is Not Suitable For Multi-Hop Wireless Networks,\"\nEcole Polytechnique Federale de Lausanne (EPFL), Lausanne, Report, 2000.\n[3] D. K. Foley, \"Resource Allocation and the Public Sector,\" Yale Economic Essays, vol. 7, 1967.\n[4] H. R. Varian, \"Equity, Envy, and Efficiency,\" Journal of Economic Theory, vol. 9, pp. 63\u201391, 1974.\n[5] H. Boche, M. Wiczanowski, and S. Stanczak, \"Unifying View on Min-Max Fairness, Max-Min Fairness, and Utility\nOptimization in Cellular Networks,\" Eurasip Journal on Wireless Communications and Networking, vol. 2007, p. ID\n34869, 2007.\n[6] A. Lozano, A. M. Tulino, and S. Verdu, \"Optimum Power Allocation for Parallel Gaussian Channels With Arbitrary\nInput Distributions,\" IEEE Transactions on Information Theory, vol. 52(7), pp. 3033\u20133051, Jul 2006.\n[7] D. P. Palomar and J. R. Fonollosa, \"Practical algorithms for a family of waterfilling solutions,\" IEEE Transactions\non Signal Processing, vol. 53(2), pp. 686\u2013695, Feb 2005.\n[8] G. D. Forney, Jr. and G. Ungerboeck, \"Modulation and Coding for Linear Gaussian Channels,\" IEEE Transactions\non Information Theory, vol. 44(6), pp. 2384\u20132415, Oct 1998.\n[9] J. A. C. Bingham, P. S. Chow, and J. M. Cioffi, \"A practical discrete multitone transceiver loading algorithm for data\ntransmission over spectrally shaped channels,\" IEEE Transactions on Communications, vol. 43(2), pp. 773\u2013775, Feb\n1995.\n[10] A. Lozano, A. M. Tulino, and S. Verdu, \"Mercury/waterfilling for fixed wireless OFDM systems,\" in Proc. IEEE\nRadio and Wireless Symp. (RWS'06), San Diego, CA, Jan 2006, pp. 211\u2013214.\n[11] I. Toufik and R. Knopp, \"Multiuser Channel Allocation Algorithms Achieving Hard Fairness,\" in Proc. IEEE Global\nTelecommunications Conference (Globecom), 2004.\n[12] M. Wiczanowski, H. Boche, and S. Stanczak, \"Characterization of Optimal Resource Assignments in the Framework\nof Blocking System Theory,\" in Proc. IEEE International Symposium on Information Theory and its Applications\n(ISITA), Seoul, Korea, Nov 2006.\n[13] --, \"Power Allocation and Resource Assignment in the View of Blocking and Antiblocking Polyhedra,\" in Proc.\nIEEE Information Theory Workshop (ITW), Chengdou, China, Oct 2006.\n[14] Y. J. Zhang and K. B. Lataief, \"Adaptive Resource Allocation for Multiaccess MIMO/OFDM Systems with Matched\nFiltering,\" IEEE Transactions on Communications, vol. 53(11), Nov 2005.\n[15] D. R. Fulkerson, Blocking Polyhedra, ser. Graph theory and its applications. Academic Press, 1970, pp. 93\u2013112.\n[16] --, \"Antiblocking Polyhedra,\" Journal on Combinatorial Theory, Series B, vol. 12, pp. 50\u201371, 1972.\n[17] L. Lovasz, \"On the Shannon Capacity of a Graph,\" IEEE Transactions on Information Theory, vol. 25(1), pp. 1\u20137,\n1979.\n[18] M. Gr\u00f6tschel, L. Lovasz, and A. Shrijver, \"Relaxations of Vertex Packing,\" Journal of Combinatorial Theory, Series\nB, vol. 40, pp. 330\u2013343, 1986.\n[19] J. K\u00f6rner and A. Orlitsky, \"Zero-error information theory,\" IEEE Transactions on Information Theory, vol. 44(6), pp.\n2207\u20132229, Oct 1998.\n[20] X. Qin and R. Berry, \"Distributed power allocation and scheduling for parallel channel wireless networks,\" in Proc.\nInternational Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WIOPT), 2005,\npp. 77\u201385.\n\n\f[21] C. Y. Wong, R. S. Cheng, K. B. Letaief, and R. D. Murch, \"Multiuser OFDM with Adaptive Subcarrier, Bit, and\nPower Allocation,\" IEEE Journal on Selected Areas in Communications, vol. 17(10), pp. 1747\u20131758, Oct 1999.\n[22] H. B\u00f6lcskei, \"MIMO-OFDM Wireless Systems: Basics, Perspectives, and Challenges,\" IEEE Wireless Communications, pp. 31\u201337, Aug 2006.\n[23] 3rd Generation Partnership Project (3GPP), \"Evolved Universal Terrestrial Radio Access (E-UTRA) and Evolved\nUniversal Terrestrial Radio Access Network (E-UTRAN) (Release 8),\" 3GPP Support Office, Valbonne, France,\nTechnical Specification, 2007.\n[24] --, \"Evolved Universal Terrestrial Radio Access (E-UTRA); Base Station (BS) radio transmission and reception\n(release 8),\" 3GPP Support Office, Valbonne, France, Technical Specification, 2008.\n[25] T. M. Cover, \"Comments on Broadcast Channels,\" IEEE Transactions on Information Theory, vol. 44(6), pp. 2524\u2013\n2530, Oct 1998.\n[26] N. Jindal and A. Goldsmith, \"Capacity and Optimal Power Allocation for Fading Broadcast Channels With Minimum\nRates,\" IEEE Transactions on Information Theory, vol. 49(11), pp. 2895\u20132909, Nov 2003.\n[27] D. N. Tse, \"Optimal Power Allocation over Parallel Gaussian Broadcast Channels,\" in Proc. IEEE International\nSymposium on Information Theory (ISIT), 1997, p. 27.\n[28] D. Tse and P. Viswanath, Fundamentals of Wireless Communication. Cambridge: Cambridge University Press, 2005.\n[29] S. Verdu, Multiuser Detection. New York: Cambridge University Press, 1998.\n[30] B. Bollobas, Modern Graph Theory. New York: Springer-Verlag, 1998.\n[31] D. E. Knuth, \"The Sandwich Theorem,\" Electronic Journal of Combinatorics, vol. 1, 1994.\n[32] D. M. Cvetkovic, M. Doob, and H. Sachs, Spectra of Graphs. New York: Academic Press, 1980.\n[33] J. H. Drew, C. R. Johnson, and R. Loewy, \"Completely Positive Matrices Associated with m-Matrices,\" Linear and\nMultilinear Algebra, vol. 37, pp. 303\u2013310, 1994.\n[34] N. Kogan and A. Berman, \"Characterization of completely positive graphs,\" Discrete Mathematics, vol. 114, pp.\n297\u2013304, 1993.\n[35] A. Berman and D. Hershkowitz, \"Combinatorial Results on Completely Positive Matrices,\" Linear Algebra and its\nApplications, vol. 95, pp. 111\u2013125, 1987.\n[36] C. Xu, \"Nearly Completely Positive Graphs,\" Applicable Algebra in Engineering Communication and Computing,\nvol. 13, pp. 1\u20138, 2002.\n[37] C. J. Luz and A. Schrijver, \"A Convex Quadratic Characterization of the Lovasz Theta Number,\" SIAM Journal on\nDiscrete Mathematics, vol. 19(2), pp. 382\u2013387, 1979.\n[38] A. Schrijver, \"A Comparison of the Delsarte and Lovasz Bounds,\" IEEE Transactions on Information Theory, vol.\n25(4), pp. 425\u2013429, Jul 1979.\n[39] P. Delsarte, \"An algebraic approach to the association schemes in coding theory,\" Philips Res. Reps. Suppl., vol. 10,\n1973.\n[40] F. Chung and R. M. Richardson, Weighted Laplacians and the Sigma Function of a Graph, ser. Quantum Graphs And\nTheir Applications - Contemporary Mathematics. American Mathematical Society, 2006, ch. 7, pp. 93\u2013108.\n[41] A. Galtman, \"Spectral Characterizations of the Lovasz Number and the Delsarte Number of a Graph,\" Journal of\nAlgebraic Combinatorics, vol. 12, pp. 131\u2013143, 2000.\n[42] R. J. McEliece, E. R. Rodemilch, and H. C. Rumsey Jr., \"The Lovasz Bound and Some Generalizations,\" Journal of\nCombinatorics Information & System Sciences, vol. 3(3), pp. 134\u2013152, 1978.\n[43] C. R. Johnson and M. Newman, \"A note on Cospectral Graphs,\" Journal of Combinatorial Theory, Series B, vol. 28,\npp. 96\u2013103, 1980.\n[44] L. J. Gray and D. G. Wilson, \"Nonnegative factorization of positive semidefinite nonnegative matrices,\" Linear Algebra\nand its Applications, vol. 31, pp. 119\u2013127, 1980.\n[45] A. Berman, Completely positive graphs, ser. Quantum Graphs And Their Applications - Contemporary Mathematics.\nAmerican Mathematical Society, 2006, ch. 7, pp. 93\u2013108.\n[46] S. Stanczak, M. Wiczanowski, and H. Boche, Resource Allocation in Wireless Networks. New York: Lecture Notes\nin Computer Science, Springer-Verlag, 2006.\n[47] A. W. Marshall and I. Olkin, \"Scaling of matrices to achieve specified row and column sums,\" Numerische Mathematik,\nvol. 12, pp. 83\u201390, 1968.\n[48] U. G. Rothblum and H. Schneider, \"Scalings of Matrices Which Have Prescribed Row Sums and Column Sums via\nOptimization,\" Linear Algebra and its Applications, vol. 114, pp. 737\u2013765, 1989.\n[49] D. London, \"On matrices with a doubly stochastic pattern,\" Journal of Mathematical Analysis and Applications,\nvol. 34, pp. 648\u2013652, 1971.\n[50] M. Schubert and H. Boche, QoS-Based Resource Allocation and Transceiver Optimization, ser. Foundations and\nTrends in Communications and Information Theory. Now Publishers, 2005, vol. 2(6).\n[51] U. G. Rothblum and H. Schneider, \"Characterization of Optimal Scalings of Matrices,\" Mathematical Programming,\nvol. 19, pp. 121\u2013136, 1980.\n[52] F. Murnaghan, The Unitary and Rotation Groups. Washington: Spartan Books, 1962.\n[53] R. A. Brualdi, \"Convex sets of nonnegative matrices,\" Canadian Journal of Mathematics, vol. 20, pp. 144\u2013157, 1968.\n[54] D. P. Bertsekas, Nonlinear Programming. Athens: Athena Scientific, 1999.\n[55] D. J. White, \"A linear programming approach to solving bilinear programmes,\" Mathematical Programming, vol. 56,\npp. 45\u201350, 1992.\n[56] H. D. Sherali and C. M. Shetty, \"A finitely convergent algorithm for bilinear programming problems using polar cuts\nand disjunctive face cuts,\" Mathematical Programming, vol. 19, pp. 14\u201331, 1980.\n[57] D. D. Lee and H. S. Seung, \"Algorithms for non-negative matrix factorization,\" Advances in Neural Information\nProcessing, vol. 13, pp. 556\u2013562, 2000.\n\n\f[58] P. O. Hoyer, \"Non-negative Matrix Factorization with Sparseness Constraints,\" Journal of Machine Learning Research,\nvol. 5, pp. 1457\u20131469, 2004.\n[59] C.-J. Lin, \"On the Convergence of Multiplicative Update Algorithms for Nonnegative Matrix Factorization,\" IEEE\nTransactions on Neural Networks, vol. 18(6), pp. 1589\u20131596, 2007.\n[60] J. M. Ortega and W. C. Rheinboldt, Iterative Solution of Nonlinear Equations in Several Variables. New York:\nAcademic Press, 1970.\n[61] R. A. Bailey, Association Schemes: Designed experiments, Algebra and Combinatorics. Cambridge: Cambridge\nUniversity Press, 2004.\n\n\f"}