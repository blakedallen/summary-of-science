{"id": "http://arxiv.org/abs/1109.1057v1", "guidislink": true, "updated": "2011-09-06T04:26:44Z", "updated_parsed": [2011, 9, 6, 4, 26, 44, 1, 249, 0], "published": "2011-09-06T04:26:44Z", "published_parsed": [2011, 9, 6, 4, 26, 44, 1, 249, 0], "title": "Toward Designing Intelligent PDEs for Computer Vision: An Optimal\n  Control Approach", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1109.3533%2C1109.4956%2C1109.6534%2C1109.3623%2C1109.3146%2C1109.4117%2C1109.4005%2C1109.2034%2C1109.4166%2C1109.3879%2C1109.4045%2C1109.5882%2C1109.5049%2C1109.3001%2C1109.3684%2C1109.2207%2C1109.0137%2C1109.0613%2C1109.4139%2C1109.6556%2C1109.2380%2C1109.2239%2C1109.0389%2C1109.5210%2C1109.5812%2C1109.1876%2C1109.1323%2C1109.4823%2C1109.6231%2C1109.6472%2C1109.1872%2C1109.5357%2C1109.5478%2C1109.5418%2C1109.0473%2C1109.4426%2C1109.6904%2C1109.5236%2C1109.0758%2C1109.5755%2C1109.6619%2C1109.2424%2C1109.6176%2C1109.4668%2C1109.2266%2C1109.0807%2C1109.1189%2C1109.6923%2C1109.1058%2C1109.6214%2C1109.4978%2C1109.5239%2C1109.6338%2C1109.1466%2C1109.3390%2C1109.2679%2C1109.4986%2C1109.6047%2C1109.2478%2C1109.1219%2C1109.1170%2C1109.1348%2C1109.1777%2C1109.0344%2C1109.3585%2C1109.1769%2C1109.3935%2C1109.6890%2C1109.3849%2C1109.4581%2C1109.5492%2C1109.4021%2C1109.1570%2C1109.2989%2C1109.4691%2C1109.1247%2C1109.1486%2C1109.6928%2C1109.5860%2C1109.2969%2C1109.1078%2C1109.0042%2C1109.1784%2C1109.2284%2C1109.6351%2C1109.5396%2C1109.1057%2C1109.5647%2C1109.4302%2C1109.5111%2C1109.1851%2C1109.3931%2C1109.1156%2C1109.4633%2C1109.5457%2C1109.2176%2C1109.1782%2C1109.6637%2C1109.6537%2C1109.2983%2C1109.4944&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Toward Designing Intelligent PDEs for Computer Vision: An Optimal\n  Control Approach"}, "summary": "Many computer vision and image processing problems can be posed as solving\npartial differential equations (PDEs). However, designing PDE system usually\nrequires high mathematical skills and good insight into the problems. In this\npaper, we consider designing PDEs for various problems arising in computer\nvision and image processing in a lazy manner: \\emph{learning PDEs from real\ndata via data-based optimal control}. We first propose a general intelligent\nPDE system which holds the basic translational and rotational invariance rule\nfor most vision problems. By introducing a PDE-constrained optimal control\nframework, it is possible to use the training data resulting from multiple ways\n(ground truth, results from other methods, and manual results from humans) to\nlearn PDEs for different computer vision tasks. The proposed optimal control\nbased training framework aims at learning a PDE-based regressor to approximate\nthe unknown (and usually nonlinear) mapping of different vision tasks. The\nexperimental results show that the learnt PDEs can solve different vision\nproblems reasonably well. In particular, we can obtain PDEs not only for\nproblems that traditional PDEs work well but also for problems that PDE-based\nmethods have never been tried before, due to the difficulty in describing those\nproblems in a mathematical way.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1109.3533%2C1109.4956%2C1109.6534%2C1109.3623%2C1109.3146%2C1109.4117%2C1109.4005%2C1109.2034%2C1109.4166%2C1109.3879%2C1109.4045%2C1109.5882%2C1109.5049%2C1109.3001%2C1109.3684%2C1109.2207%2C1109.0137%2C1109.0613%2C1109.4139%2C1109.6556%2C1109.2380%2C1109.2239%2C1109.0389%2C1109.5210%2C1109.5812%2C1109.1876%2C1109.1323%2C1109.4823%2C1109.6231%2C1109.6472%2C1109.1872%2C1109.5357%2C1109.5478%2C1109.5418%2C1109.0473%2C1109.4426%2C1109.6904%2C1109.5236%2C1109.0758%2C1109.5755%2C1109.6619%2C1109.2424%2C1109.6176%2C1109.4668%2C1109.2266%2C1109.0807%2C1109.1189%2C1109.6923%2C1109.1058%2C1109.6214%2C1109.4978%2C1109.5239%2C1109.6338%2C1109.1466%2C1109.3390%2C1109.2679%2C1109.4986%2C1109.6047%2C1109.2478%2C1109.1219%2C1109.1170%2C1109.1348%2C1109.1777%2C1109.0344%2C1109.3585%2C1109.1769%2C1109.3935%2C1109.6890%2C1109.3849%2C1109.4581%2C1109.5492%2C1109.4021%2C1109.1570%2C1109.2989%2C1109.4691%2C1109.1247%2C1109.1486%2C1109.6928%2C1109.5860%2C1109.2969%2C1109.1078%2C1109.0042%2C1109.1784%2C1109.2284%2C1109.6351%2C1109.5396%2C1109.1057%2C1109.5647%2C1109.4302%2C1109.5111%2C1109.1851%2C1109.3931%2C1109.1156%2C1109.4633%2C1109.5457%2C1109.2176%2C1109.1782%2C1109.6637%2C1109.6537%2C1109.2983%2C1109.4944&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Many computer vision and image processing problems can be posed as solving\npartial differential equations (PDEs). However, designing PDE system usually\nrequires high mathematical skills and good insight into the problems. In this\npaper, we consider designing PDEs for various problems arising in computer\nvision and image processing in a lazy manner: \\emph{learning PDEs from real\ndata via data-based optimal control}. We first propose a general intelligent\nPDE system which holds the basic translational and rotational invariance rule\nfor most vision problems. By introducing a PDE-constrained optimal control\nframework, it is possible to use the training data resulting from multiple ways\n(ground truth, results from other methods, and manual results from humans) to\nlearn PDEs for different computer vision tasks. The proposed optimal control\nbased training framework aims at learning a PDE-based regressor to approximate\nthe unknown (and usually nonlinear) mapping of different vision tasks. The\nexperimental results show that the learnt PDEs can solve different vision\nproblems reasonably well. In particular, we can obtain PDEs not only for\nproblems that traditional PDEs work well but also for problems that PDE-based\nmethods have never been tried before, due to the difficulty in describing those\nproblems in a mathematical way."}, "authors": ["Risheng Liu", "Zhouchen Lin", "Wei Zhang", "Kewei Tang", "Zhixun Su"], "author_detail": {"name": "Zhixun Su"}, "author": "Zhixun Su", "links": [{"href": "http://arxiv.org/abs/1109.1057v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1109.1057v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1109.1057v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1109.1057v1", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Toward Designing Intelligent PDEs for Computer\nVision: An Optimal Control Approach\nRisheng Liua , Zhouchen Linb , Wei Zhangc , Kewei Tanga , Zhixun Sua\n\narXiv:1109.1057v1 [cs.CV] 6 Sep 2011\n\na\n\nSchool of Mathematical Sciences, Dalian University of Technology, Dalian, China.\nb\nMicrosoft Research Asia, Beijing, China, e-mail: zhoulin@microsoft.com.\nc\nDepartment of Information Engineering, The Chinese University of Hong Kong, China.\n\nAbstract\nMany computer vision and image processing problems can be posed as solving\npartial differential equations (PDEs). However, designing PDE system usually requires high mathematical skills and good insight into the problems. In this paper,\nwe consider designing PDEs for various problems arising in computer vision and\nimage processing in a lazy manner: learning PDEs from real data via data-based\noptimal control. We first propose a general intelligent PDE system which holds\nthe basic translational and rotational invariance rule for most vision problems. By\nintroducing a PDE-constrained optimal control framework, it is possible to use the\ntraining data resulting from multiple ways (ground truth, results from other methods, and manual results from humans) to learn PDEs for different computer vision\ntasks. The proposed optimal control based training framework aims at learning a\nPDE-based regressor to approximate the unknown (and usually nonlinear) mapping of different vision tasks. The experimental results show that the learnt PDEs\ncan solve different vision problems reasonably well. In particular, we can obtain\nPDEs not only for problems that traditional PDEs work well but also for problems that PDE-based methods have never been tried before, due to the difficulty\nin describing those problems in a mathematical way.\nPreprint submitted to IVC\n\nMay 26, 2018\n\n\fKeywords: Optimal Control, PDEs, Computer Vision, Image Processing.\n1. Introduction\nThe wide applications of partial differential equations (PDEs) in computer vision and image processing can be attributable to two main factors [1]. First, PDEs\nin classical mathematical physics are powerful tools to describe, model, and simulate many dynamics such as heat flow, diffusion, and wave propagation. Second,\nmany variational problems or their regularized counterparts can often be effectively solved from their Euler-Lagrange equations. Therefore, in general there are\ntwo types of methods for designing PDEs for vision tasks. For the first kind of\nmethods, PDEs are written down directly (e.g., anisotropic diffusion [2], shock\nfilter [3], based on some understandings on the properties of mathematical operators and the physical natures of the problems, and curve-evolution-based equations [4]). The second kind of methods basically define an energy functional and\nthen derive the evolution equations by computing the Euler-Lagrange equation of\nthe energy functional (e.g., total-variation-based variational methods [5][6][7]).\nIn either way, people have to heavily rely on their intuition on the vision tasks.\nTherefore, traditional PDE-based methods require good mathematical skills when\nchoosing appropriate PDE forms and predicting the final effect of composing related operators such that the obtained PDEs roughly meet the goals. If people do\nnot have enough intuition on a vision task, they may have difficulty in acquiring\neffective PDEs. For example, although there has been much work on PDE-based\nimage segmentation [8][9][10][11], the basic philosophy is always to follow the\nstrong edges in the image and also require the edge contour to be smooth. Can we\nhave a PDE system for objective detection (Fig. 1) that locates the object region\n2\n\n\fFigure 1: Can we design a PDE system which can detect the object of interest (e.g., the helicopter\nin the left image) and does not respond if the object is absent (e.g., the right image)?\n\nif the object is present and does not respond if the object is absent? We believe\nthat this is a big challenge to human intuition and is much more difficult than\ntraditional segmentation tasks if a PDE-based method is required, because it is\nhard to describe an object class, which may have significant variation in shape,\ntexture and pose. Without using additional information to judge the content, the\nexisting PDEs for segmentation, e.g., [10], always output an \"object region\" for\nany non-constant image. In short, current PDE design methods greatly limit the\napplications of PDEs to a wider and more complex scope. This motivates us to\nexplore whether we can acquire PDEs that are less artificial yet more powerful.\nIn this paper, we give an affirmative answer to this question. We demonstrate that\nlearning particular coefficients of a general intelligent PDE system from a given\ntraining data set might be a possible way of designing PDEs for computer vision\nin a lazy manner. Furthermore, borrowing this learning strategy from machine\nlearning can generalize PDEs techniques for more complex vision problems.\nInspired by the electromagnetic field theory and Maxwell's equations [12],\nwe assume that the visual processing has two coupled evolutions in different scale\nspaces: one is in the image scale space, which controls the evolution of the output,\nand the other is in the indicator scale space that helps collect the global informa3\n\n\ftion to guide the evolution in the image scale space. In this way, our general\nintelligent PDE system consists of two coupled evolutionary PDEs. Both PDEs\nare coupled equations between the image and indicator, up to their second order\npartial derivatives. Another key idea of our general intelligent PDE system is to\nassume that the PDEs that are sought could be written as combinations of \"atoms\"\nwhich satisfy the general properties of vision tasks. As a preliminary investigation, we utilize all the translational and rotational invariants as such\"atoms\" and\npropose the general intelligent PDE system as a linear combination of all these\ninvariants [13]. Then the problem boils down to determining the combination\ncoefficients among such \"atoms\".\nThe theory of optimal control [14] has been well developed for over fifty years.\nWith the enormous advances in computing power, optimal control is now widely\nused in multi-disciplinary applications such as biological systems, communication\nnetworks and socio-economic systems etc [15]. Optimal design and parameter estimation of systems governed by PDEs give rise to a class of problems known\nas PDE-constrained optimal control [16]. In this paper, a PDE-constrained optimal control technique as the training tool is introduced for our PDE system. We\nfurther propose a general framework for learning PDEs to accomplish a specific\nvision task via PDE-constrained optimal control, where the objective functional\nis to minimize the difference between the expected outputs and the actual outputs\nof the PDEs, given the input images. Such input-output image pairs are provided\nin multiple ways (e.g., ground truth, results from other methods or manually generated results by humans) for different tasks. Therefore, we can train the general\nintelligent PDE system to solve various vision problems which traditional PDEs\nmay find difficult or even impossible.\n\n4\n\n\fIn summary, our contributions are as follows:\n1. Our intelligent PDE system provides a new way to design PDEs for computer vision. Based on this framework, we can design particular PDEs for\ndifferent vision tasks using different sources of training images 1 . This may\nbe very difficult for traditional PDE design methods. However, we would\nlike to remind the readers that we have no intention to beat all the existing\napproaches for each task, because these approaches have been carefully and\nspecially tuned for the task.\n2. We propose a general data-based optimal control framework for training the\nPDE system. Fed with pairs of input and output images, the proposed PDEconstrained optimal control training model can automatically learn the combination coefficients in the PDE system. Unlike previous design methods,\nour approach requires much less human wits and can solve more difficult\nproblems in computer vision.\nThe rest of the paper is structured as follows. We first introduce in Section 2\nthe general intelligent PDE system. In Section 3 we utilize the PDE-constrained\noptimal control technique as the training framework for our intelligent PDE system. Then in Section 4 we evaluate our intelligent PDE system with optimal\ncontrol training framework by a series of computer vision and image processing\nproblems. Finally, we give concluding remarks and a discussion on the future\nwork in Section 5.\n1\n\nSimilar idea also appeared in [17]. But in that work, the authors only train special PDEs\n\ninvolving the curvature operator for basic image restoration tasks. In contrast, our work here\nproposes a more unified and elegant framework for more problems in computer vision.\n\n5\n\n\f2. General PDE System for Computer Vision\n2.1. Electromagnetic Field vs. Image Evolution\nElectromagnetism is the force that causes the interaction among electrically\ncharged particles. The areas in which electromagnetic interaction happens are\ncalled the electromagnetic fields. But in physics, electrically charged objects were\nfirst thought to produce two types of fields associated with their charge property:\nAn electric field and a magnetic field. Over time, it was realized that the electric\nand magnetic fields are better thought of as two parts of a greater whole \u2013 the\nelectromagnetic field [12]. It affects the behavior of charged objects in the vicinity of the field. The electromagnetic field extends infinitely throughout space and\ndescribes the electromagnetic interaction. The theoretical implications of electromagnetism also led to the development of special relativity by Albert Einstein in\n1905.\nIn this paper, inspired by this fundamental force of nature, we consider the\nimage evolution in a similar way. For a target image signal u(t), different from\nmost traditional ways, which only consider the evolution in the image scale space,\nwe define a companion signal v(t) named the indicator signal. It changes with\ntime and guides the evolution of u(t) by collecting large scale information in the\nimage. In this way, these two signals evolve in two coupled scale spaces.\n2.2. The Intelligent PDE System\nSimilar to Maxwell's equations [12], which are a set of PDEs describing how\nthe electric and magnetic fields relate to their sources and how they develop with\ntime, we propose a general PDE system for the evolution of our coupled signals.\n\n6\n\n\fThe space of all PDEs is infinitely dimensional. To find the right form, we start\nwith the properties that our PDE system should have, in order to narrow down the\nsearch space. We notice that translationally and rotationally invariant properties\nare very important for computer vision, i.e., in most vision tasks, when the input\nimage is translated or rotated, the output image is also translated or rotated by\nthe same amount. So we require that our PDE system is translationally and rotationally invariant. According to the differential invariant theory [13], the form\nof our PDEs must be functions of the fundamental differential invariants under\nthe group of translation and rotation. The fundamental differential invariants are\ninvariant under translation and rotation and other invariants can be written as their\nfunctions. We list those up to second order in Table 1, where some notations can\nbe found in Table 2. In the sequel, we shall use {invj (u, v)}16\nj=0 to refer to them\nin order. Note that those invariants are ordered with u going before v. We may\nreorder them with v going before u. In this case, the j-th invariant will be referred\nto as invj (v, u). So the simplest choice of our general PDE system is the linear\ncombination of the differential invariants, leading to the following form:\n\uf8f1\n\u2202u\n\uf8f4\n\uf8f4\n\u2212 F (u, v, {aj }16\nj=0 ) = 0, (x, y, t) \u2208 Q,\n\uf8f4\n\u2202t\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\nu(x, y, t) = 0,\n(x, y, t) \u2208 \u0393,\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2 u| = f ,\n(x, y) \u2208 \u03a9,\nt=0\nu\n\u2202v\n\uf8f4\n\uf8f4\n\u2212 F (v, u, {bj }16\n\uf8f4\nj=0 ) = 0, (x, y, t) \u2208 Q,\n\u2202t\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\nv(x, y, t) = 0,\n(x, y, t) \u2208 \u0393,\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3 v| = f ,\n(x, y) \u2208 \u03a9,\nt=0\nv\n\n(1)\n\nwhere\nF (u, v, {aj }16\nj=0 ) =\n\nP16\n\nF (v, u, {bj }16\nj=0 ) =\n\nP16\n\nj=0\n\naj (t)invj (u, v),\n\nj=0 bj (t)invj (v, u),\n\n7\n\n(2)\n\n\f\u03a9 is the rectangular region occupied by the input image I, T is the time that the\nPDE system finishes the visual information processing and outputs the results,\nand fu and fv are the initial functions of u and v, respectively. The meaning of\nother notations in (1) can be found in Table 2. For computational issues and the\nease of mathematical deduction, I will be padded with zeros of several pixels\nwidth around it. As we can change the unit of time, it is harmless to fix T =\n16\n1. {aj (t)}16\nj=0 and {bj (t)}j=0 are sets of functions defined on Q that are used to\n\ncontrol the evolution of u and v, respectively. As \u2207u and Hu change to R\u2207u\nand RHu RT , respectively, when the image is rotated by a matrix R, it is easy\nto check the rotational invariance of those quantities. So the PDE system (1)\nis rotationally invariant. Furthermore, the following proposition implies that the\ncontrol functions aj (t) and bj (t) can be functions of t only.\nProposition 2.1. Suppose the PDE system (1) is translationally invariant, then\n16\nthe control functions {aj }16\nj=0 and {bj }j=0 must be independent of (x, y).\n\nThe proof of Proposition 2.1 is presented in Appendix A.\n3. Training the PDE System via Data-based Optimal Control\nIn this section, we propose a data-based optimal control framework to train\nthe intelligent PDE system for particular vision tasks.\n3.1. The Objective Functional\nGiven the forms of PDEs shown in (1), we have to determine the coefficient functions aj (t) and bj (t). We may prepare training samples {(Im , Om )}M\nm=1 ,\nwhere Im is the input image and Om is the expected output image, and compute\n\n8\n\n\fTable 1: Translationally and rotationally invariant fundamental differential invariants up to the\nsecond order.\n\nj\n\ninvj (u, v)\n\n0,1,2\n\n1, v, u\n\n3,4\n\nk\u2207vk2 = vx2 + vy2 , k\u2207uk2 = u2x + u2y\n\n5\n\n(\u2207v)T \u2207u = vx ux + vy uy\n\n6,7\n\ntr(Hv ) = vxx + vyy , tr(Hu ) = uxx + uyy\n\n8\n\n(\u2207v)T Hv \u2207v = vx2 vxx + 2vx vy vxy + vy2 vyy\n\n9\n\n(\u2207v)T Hu \u2207v = vx2 uxx + 2vx vy uxy + vy2 uyy\n\n10\n\n(\u2207v)T Hv \u2207u = vx ux vxx + (vx uy + vy ux )vxy + vy uy vyy\n\n11\n\n(\u2207v)T Hu \u2207u = vx ux uxx + (vx uy + vy ux )uxy + vy uy uyy\n\n12\n\n(\u2207u)T Hv \u2207u = u2x vxx + 2ux uy vxy + u2y vyy\n\n13\n\n(\u2207u)T Hu \u2207u = u2x uxx + 2ux uy uxy + u2y uyy\n\n14\n\n2\n2\n2\n+ vyy\n+ 2vxy\ntr(H2v ) = vxx\n\n15\n\ntr(Hv Hu ) = vxx uxx + 2vxy uxy + vyy uyy\n\n16\n\ntr(H2u ) = u2x + 2u2xy + u2y\n\n9\n\n\fTable 2: Notations.\n\n\u03a9\n\nAn open bounded region in R2\n\n\u2202\u03a9\n\nBoundary of \u03a9\n\n(x, y)\n\n(x, y) \u2208 \u03a9, spatial variable\n\nt\n\nt \u2208 (0, T ), temporal variable\n\nQ\n\n\u03a9 \u00d7 (0, T )\n\n\u0393\n\n\u2202\u03a9 \u00d7 (0, T )\n\n|*|\n\nThe area of a region\n\nXT\n\nTranspose of matrix (or vector)\n\nk*k\n\nL2 norm\n\ntr(*)\n\nTrace of matrix\n\n\u2207u\n\nGradient of u\n\nHu\n\nHessian of u\n\n\u2118\n\n\u2118 = {(0, 0), (0, 1), (1, 0), (0, 2), (1, 1), (2, 0)}, index set for partial differentiation\n\nthe coefficient functions that minimize the following functional:\n16\n16\nJ({um }M\nm=1 , {aj }j=0 , {bj }j=0 )\nR\nP\n2\n= 12 M\nm=1 \u03a9 [um (x, y, 1) \u2212 Om ] d\u03a9\nR1 2\nR1 2\nP\nP16\n1\n+ 21 16\nj=0 \u03bbj 0 aj (t)dt + 2\nj=0 \u03bcj 0 bj (t)dt,\n\n(3)\n\nwhere um (x, y, 1) is the output image at time t = 1 computed from (1) when\nthe input image is Im , and \u03bbi and \u03bci are positive weighting parameters. The first\nterm requires that the final output of our PDE system be close to the ground truth.\nThe second and the third terms are for regularization so that the optimal control\nproblem is well posed, as there may be multiple minimizers for the first term.\n\n10\n\n\f3.2. Solving the Optimal Control Problem\nThen we have the following optimal control problem with PDE constraints:\n16\n16\narg min J({um }M\nm=1 , {aj }j=0 , {bj }j=0 )\n16\n16\n{aj }j=0 ,{bj }j=0\n\uf8f1\n\u2202u\n\uf8f4\n\uf8f4\n\u2212 F (u, v, {aj }16\nj=0 ) = 0, (x, y, t) \u2208 Q,\n\uf8f4\n\u2202t\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\nu(x, y, t) = 0,\n(x, y, t) \u2208 \u0393,\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2 u| = f ,\n(x, y) \u2208 \u03a9,\nt=0\nu\ns.t.\n\uf8f4\n\uf8f4 \u2202v\n\u2212 F (v, u, {bj }16\n\uf8f4\nj=0 ) = 0, (x, y, t) \u2208 Q,\n\u2202t\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\nv(x, y, t) = 0,\n(x, y, t) \u2208 \u0393,\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3 v| = f ,\n(x, y) \u2208 \u03a9.\nt=0\n\n(4)\n\nv\n\nBy introducing the adjoint equation of (4), the G\u00e2teaux derivative of J can be\n16\ncomputed and consequently, the (local) optimal {aj }16\nj=0 and {bj }j=0 can be com-\n\nputed via gradient-based algorithms (e.g., conjugate gradient). Here, we give the\nadjoint equation and G\u00e2teaux derivative directly:\n3.2.1. Adjoint Equation\n\uf8f1\n\u2202\u03c6m\n\uf8f4\n\uf8f4\n+ E(um , vm , \u03c6m , \u03c6m ) = 0,\n\uf8f4\n\u2202t\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\u03c6m = 0,\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2 \u03c6 | = O \u2212 u (1),\nm t=1\nm\nm\n\u2202\u03c6m\n\uf8f4\n\uf8f4\n+ E(vm , um , \u03c6m , \u03c6m ) = 0,\n\uf8f4\n\u2202t\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\u03c6m = 0,\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3 \u03c6 | = 0,\nm t=1\n\n11\n\n(x, y, t) \u2208 Q,\n(x, y, t) \u2208 \u0393,\n(x, y) \u2208 \u03a9,\n(x, y, t) \u2208 Q,\n(x, y, t) \u2208 \u0393,\n(x, y) \u2208 \u03a9,\n\n(5)\n\n\fwhere\nE(um , vm , \u03c6m , \u03c6m )\nP\np+q\npq (vm )\u03c6m )\n=\n,\n(\u22121)p+q \u2202 (\u03c3pq (um\u2202x)\u03c6pm\u2202y+\u03c3\nq\n(p,q)\u2208\u2118\n\nE(vm , um , \u03c6m , \u03c6m )\nP\np+q\npq (vm )\u03c6m )\n=\n(\u22121)p+q \u2202 (\u03c3pq (um\u2202x)\u03c6pm\u2202y+\u03c3\n,\nq\n\n(6)\n\n(p,q)\u2208\u2118\n\n\u03c3pq (u) =\n\u03c3pq (v) =\n\n\u2202F (u)\n\u2202upq\n\u2202F (v)\n\u2202vpq\n\n=\n=\n\n\u2202 invj (u,v)\n,\n\u2202upq\nP16\n\u2202 invj (v,u)\n,\nj=0 bj\n\u2202vpq\n\nP16\n\nj=0\n\naj\n\nupq =\nvpq =\n\n\u2202 p+q u\n,\n\u2202xp \u2202y q\n\u2202 p+q v\n.\n\u2202xp \u2202y q\n\n3.2.2. G\u00e2teaux Derivative of the Functional\nWith the help of the adjoint equation, at each iteration the derivative of J with\nrespect to aj (t) and bj (t) are as follows:\n\u2202J\n\u2202aj\n\n= \u03bbj aj \u2212\n\n\u2202J\n\u2202bj\n\n= \u03bc j bj \u2212\n\nM R\nP\nm=1\nM R\nP\nm=1\n\n\u03a9\n\n\u03c6m invj (um , vm )d\u03a9,\n\nj = 0, ..., 16,\n(7)\n\n\u03a9\n\n\u03c6m invj (vm , um )d\u03a9,\n\nj = 0, ..., 16,\n\nwhere the adjoint functions \u03c6m and \u03c6m are the solutions to (5).\n3.2.3. Initialization\nGood initialization increases the approximation accuracy of the learnt PDEs.\nIn our current implementation, we simply set the initial functions of u and v as\nthe input image:\num (x, y, 0) = vm (x, y, 0) = Im (x, y), m = 1, 2, ..., M.\nThen we employ a heuristic method to initialize the control functions. At each\ntime step,\n\n\u2202um\n\u2202t\n\nis expected to be dm (t) =\n\nOm \u2212um (t)\n1\u2212t\n\nso that um (t) moves towards\n\nthe expected output Om and by the form of (1) we may solve {aj (t)}16\nj=0 such that\nM Z\nX\n2\n[F (um , vm , {aj (t)}16\n(8)\nj=0 ) \u2212 dm (t)] d\u03a9\nm=1\n\n\u03a9\n\n12\n\n\fis minimized2 . In this way, we initialize aj (t) successively in time while fixing\nbj (t) = 0, j = 0, 1, ..., 16.\n3.2.4. Finite Difference Method for Numerical Solution\nTo solve the intelligent PDE system numerically, we design a finite difference\nscheme [18] for the PDEs. We discretize the PDEs, i.e. replace the derivatives\n\u2202f\n\u2202x\n\nand\n\n\u22022f\n\u2202x2\n\nwith finite differences as follows:\n\uf8f1\n(t)\n\u2202f\n\uf8f4\n\uf8f4\n= f (t+\u2206t)\u2212f\n,\n\uf8f4\n\u2206t\n\uf8f2 \u2202t\n(x)\n\u2202f\n= f (x+1)\u2212f\n,\n\u2202x\n2\n\uf8f4\n\uf8f4\n\uf8f4\n2\n\uf8f3 \u2202 f = f (x \u2212 1) \u2212 2f (x) + f (x + 1).\n\n\u2202f\n,\n\u2202t\n\n(9)\n\n\u2202x2\n\nThe discrete forms of\n\n\u2202f \u2202 2 f\n,\n\u2202y \u2202y 2\n\nand\n\n\u22022f\n\u2202x\u2202y\n\ncan be defined similarly. In addition, we\n\ndiscretize the integrations as\n\uf8f1 R\nP\n\uf8f2\nf (x, y)d\u03a9 = N1 \u03a9 f (x, y),\n\u03a9\n\uf8f3 R t f (t)dt = \u2206t PTm f (i * \u2206t),\ni=0\n0\n\n(10)\n\nwhere N is the number of pixels in the spatial area, \u2206t is a properly chosen time\n1\nstep size and Tm = b \u2206t\n+ 0.5c is the index of the expected output time. Then we\n\nuse an explicit scheme to compute the numerical solutions.\n3.3. The Optimal-Control-Based Training Framework\nWe now summarize in Algorithm 1 the data-based optimal control training\nframework for the intelligent PDE system. After the PDE system is learnt, it can\nbe applied to new test images by solving (1), whose inputs fu and fv are both the\ntest image and the solution u(t)|t=1 is the desired output image.\n2\n\nIt is to minimize the difference between the left and the right hand sides of (1).\n\n13\n\n\fAlgorithm 1 (Data-based optimal control framework for training the PDE\nsystem)\nInput: Training image pairs {(Im , Om )}M\nm=1 .\n1:\n\nInitialize aj (t), t = 0, \u2206t, ..., 1 \u2212 \u2206t, by minimizing (8) and fix bj (t) = 0,\nj = 0, 1, ..., 16.\n\n2:\n\nwhile not converged do\n\u2202J\n\u2202aj\n\n\u2202J\n,\n\u2202bj\n\nj = 0, ..., 16, using (7).\n\n3:\n\nCompute\n\n4:\n\nDecide the search direction using the conjugate gradient method [19].\n\n5:\n\nPerform golden search along the search direction and update aj (t) and\n\nand\n\nbj (t), j = 0, ..., 16.\n6:\n\nend while\n\n16\nOutput: The coefficient functions {aj (t)}16\nj=0 and {bj (t)}j=0 .\n\n4. Experimental Results\nIn this section, we apply our data-based optimal control framework to learn\nPDEs for four groups of basic computer vision problems: Natural image denoising, edge detection, blurring and deburring, and image segmentation and object\ndetection. As our goal is to show that the data-based optimal control framework\ncould be a new approach for designing PDEs and an effective regressor for many\ncomputer vision tasks, NOT to propose better algorithms for these tasks, we are\nnot going to fine tune our PDEs and then compare it with the state-of-the-art algorithms in every task.\n4.1. Learning from Ground Truth: Natural Image Denoising\nImage denoising is one of the most fundamental low-level vision problems.\nFor this task, we compare our learnt PDEs with the existing PDE-based denoising\n14\n\n\fmethods, ROF [5] and TV-L1 [6], on images with unknown natural noise. This\ntask is designed to demonstrate that our method can solve problems by learning\nfrom the ground truth. This is the first advantage of our data-based optimal control\nmodel. We take 240 images, each with a size of 150 \u00d7 150 pixels, of 11 objects\nusing a Canon 30D digital camera, setting its ISO to 1600. For each object, 30\nimages are taken without changing the camera settings (by fixing the focus, aperture and exposure time) and without moving the camera position. The average\nimage of them can be regraded as the noiseless ground truth image. We randomly\nchoose 8 objects. For each object we randomly choose 5 noisy images. These\nnoisy images and their ground truth images are used to train the PDE system.\nThen we compare our learnt PDEs with the traditional PDEs in [5] and TV-L1 [6]\non images of the remaining 3 objects.\nFig. 2 shows the comparison results. One can see that the PSNRs of our intelligent PDEs are dramatically higher than those of traditional PDEs. This is because\nour data-based PDE learning framework can easily adapt to unknown types of\nnoise and obtain PDE forms to fit for the natural noise well, while most traditional\nPDE-based denoising methods were designed under specific assumptions on the\ntypes of noise (e.g., ROF is designed for Gaussian noise [5] while TV-L1 is designed for impulsive noise [20]). Therefore, they may not fit for unknown types\nof noise as well as our intelligent PDEs. The curves of the learnt coefficients for\nimage denoising are shown in Fig. 3.\n4.2. Learning from Other Methods: Edge Detection\nThe image edge detection task is used to demonstrate that our PDEs can be\nlearnt from the results of different methods and achieve a better performance than\nall of them. This is another advantage of our data-based optimal control model.\n15\n\n\fFigure 2: The results of denoising images with natural noise. (a) original noiseless image. (b)\nnoisy image with real noise. (c)-(e) denoised images using the ROF, TV-L1 , and our intelligent\nPDE system, respectively. The PSNRs are presented below each image.\n\nFigure 3: Learnt coefficients of the intelligent PDE system for the natural noise denoising problem.\n16\n(a) the coefficients {aj (t)}16\nj=0 for the image evolution. (b) the coefficients {bj (t)}j=0 for the\n\nindicator evolution.\n\n16\n\n\fFor this task, we use three simple first order edge detectors [21] (Sobel, Roberts\nCross, and Prewitt) to generate the training data. We randomly choose 7 images\nfrom the Berkeley image database [22] and use the above three detectors to generate the output images3 , together with the input images, to train our PDE system\nfor edge detection.\nFig. 4 shows part of the edge detection results on other images in the Berkeley\nimage database. One can see that our PDEs respond selectively to edges and\nbasically produce visually significant edges, while the edge maps of other three\ndetectors are more chaotic. Note that the solution to our PDEs is supposed to\nbe a more or less smooth function. So one cannot expect that our PDEs produce\nan exactly binary edge map. Instead, an approximation of a binary edge map is\nproduced. The curves of the learnt coefficients for edge detection are shown in\nFig. 5.\n4.3. Learning to Solve Both Primal and Inverse Problems: Blurring and Deblurring\nThe traditional PDEs for solving different problems are usually of very different appearance. The task of solving both blurring and deblurring is designed\nto show that the same form of PDEs can be learnt to solve both the primal and\ninverse problems. This is the third advantage of our data-based optimal control\nmodel.\nFor the image blurring task (the primal problem), the output image is the convolution of the input image with a Gaussian kernel. So we generate the output\n3\n\nThis implies that we actually use a kind of combination of the results from different methods\n\nto train our PDE system.\n\n17\n\n\fFigure 4: The results of edge detection. (a) original image. (b)-(e) edge detection results using the\nSobel, Roberts Cross, Prewitt, and our intelligent PDE, respectively.\n\nFigure 5: Learnt coefficients of the intelligent PDE system for the edge detection problem. (a) the\n16\ncoefficients {aj (t)}16\nj=0 for the image evolution. (b) the coefficients {bj (t)}j=0 for the indicator\n\nevolution.\n\n18\n\n\fimages by blurring high resolution images using a Gaussian kernel with \u03c3 = 1.\nThe original images are used as the input. As shown in the third row of Fig. 6,\nthe output is nearly identical to the ground truth (the second row of Fig. 6). For\nthe image deblurring task (the inverse problem), we just exchange the input and\noutput images for training. One can see in the bottom row of Fig. 6 that the output\nis very close to the original image (first row of Fig. 6). The curves of the learnt\ncoefficients for image deblurring are shown in Fig. 7.\n\nFigure 6: The results of image blurring and deblurring. The top row are the original images. The\nsecond row are the blurring results of a Gaussian kernel. The third row are the blurring results of\nour Intelligent PDE. The bottom row are the deblurring results of our Intelligent PDE. The PSNRs\nare presented below each image.\n\n19\n\n\fFigure 7: Learnt coefficients of the intelligent PDE system for image blurring (top row) and deblurring (bottom row) problems. (a) and (c) are the coefficients {aj (t)}16\nj=0 for the image evolutions.\n(b) and (d) are the coefficients {bj (t)}16\nj=0 for the indicator evolutions.\n\n20\n\n\f4.4. Learning from Humans: Image Segmentation and Object Detection\nImage segmentation and object detection are designed to demonstrate that our\nPDE system can learn from the human behavior directly (learn the segmentation\nand detection results provided by humans, e.g., manually segmented masks).\nFor image segmentation, it is a highly ill-posed problem and there are many\ncriteria that define the goal of segmentation, e.g., breaking an image into regions\nwith similar intensity, color, texture, or expected shape. As none of the current\nimage segmentation algorithms can perform object level segmentation well out\nof complex backgrounds, we choose to require our PDEs to achieve a reasonable\ngoal, namely segmenting relatively darker objects against relatively simple backgrounds, where both the foreground and the background can be highly textured\nand simple thresholding cannot separate them. So we select 60 images from the\nCorel image database [23] that have relatively darker foregrounds and relatively\nsimple backgrounds, but the foreground is not of uniformly lower graylevels than\nthe background, and also prepare the manually segmented binary masks as the outputs of the training images, where the black regions are the backgrounds (Fig. 8).\n\nFigure 8: Examples of the training images for image segmentation. In each group of images, on\nthe left is the input image and on the right is the ground truth output mask.\n\nPart of the segmentation results are shown in Fig. 9, where we have set a\nthreshold for the output mask maps of our learnt PDEs with a constant 0.5. We\nsee that our learnt PDEs produce fairly good object masks. We also test the active\n\n21\n\n\fcontour method by Li et al. [10]4 and the normalized cut method [24]5 . One can\nsee from Fig. 9 that the active contour method cannot segment object details due\nto the smoothness constraint on the object shape and the normalized cut method\ncannot produce a closed foreground region. To provide a quantitative evaluation,\nwe use the F -measures that merge the precision and recall of segmentation:\nF\u03b1 =\n\n(1 + \u03b1) * recall * precision\n, where\n\u03b1 * precision + recall\n\nrecall =\n\n|A \u2229 B|\n,\n|A|\n\nprecision =\n\n|A \u2229 B|\n,\n|B|\n\nin which A is the ground truth mask and B is the computed mask. The most\ncommon choice of \u03b1 is 2. On our test images, the F2 measures of our PDEs, [10]\nand [24] are 0.90 \u00b1 0.05, 0.83 \u00b1 0.16 and 0.61 \u00b1 0.20, respectively. One can see\nthat the performance of our PDEs is better than theirs, in both visual quality and\nquantitative measure. The curves of the learnt coefficients for image segmentation\nare shown in Fig. 10.\nWe also present the evolution process of the mask maps across time (Fig. 11).\nOne can see that although the foreground is relatively darker than the background,\nthe PDEs correctly detect the most salient points/edges and then propagate the\ninformation across the foreground region, resulting in a brighter output region for\nthe foreground.\nNow we apply our intelligent PDEs for a more complex task: Object detection.\nNamely, the PDEs should respond strongly to the object of interest while not\nresponding (or responding much more weakly) if the object is absent in the image.\nIt should be challenging enough for one to manually design PDEs to perform\n4\n5\n\nCode available at http://www.engr.uconn.edu/\u223ccmli/\nCode available at http://www.cis.upenn.edu/\u223cjshi/software/\n\n22\n\n\fFigure 9: The results of image segmentation. The top row are the segmentation results of active\ncontour [10] on the original images. The bottom row are the results obtained by our Intelligent\nPDE.\n\nFigure 10: Learnt coefficients of the intelligent PDE system for image segmentation problems.\n16\n(a) the coefficients {aj (t)}16\nj=0 for the image evolution. (b) the coefficients {bj (t)}j=0 for the\n\nindicator evolution.\n\n23\n\n\fFigure 11: The evolution of the mask maps. For each row, the first image is the input image, the\nsecond to the fifth are the mask maps at time t = 0.25, 0.50, 0.75, 1.0, respectively, and the last\nimage is the final mask map with a threshold of 0.5.\n\nsuch a problem. As a result, we are unaware of any PDE-based method that can\naccomplish this task. The existing PDE-based segmentation algorithms always\noutput an \"object region\" even if the image does not contain the object of interest.\nIn contrast, we will show that as desired our PDEs are able to respond selectively.\nWe choose the \"plane\" data set in Corel [23]. We select 30 images from this data\nset as positive samples and also prepare 30 images without the object of interest\nas negative samples. We also provide their ground truth object masks6 in order to\ncomplete the training data.\nIn Fig. 12, one can see that our learnt PDEs respond well to the objects of interest (first three images), while the response to images without the objects of interest\nis relatively low across the whole images (last two images). It seems that our PDEs\nautomatically identify that the concurrent high-contrast edges/junctions/corners\nare the key features of planes. The above examples show that our learnt PDEs\nare able to differentiate the object/non-object regions, without requiring the user\n6\n\nFor the positive samples, we manually segment binary masks as the output images. For the\n\nnegative samples, the ground truth output masks are all-zero images.\n\n24\n\n\fto teach them what features are and what factors to consider. The curves of the\nlearnt coefficients for object detection are shown in Fig. 13.\n\nFigure 12: The results of \"plane\" detection. The top row are the original images, the first three are\nimages containing planes and the last two are without planes. The bottom row are the detection\nresults of our intelligent PDE for images with and without planes, respectively.\n\nFigure 13: Learnt coefficients of the intelligent PDE system for the plane detection problem.\n16\n(a) the coefficients {aj (t)}16\nj=0 for the image evolution. (b) the coefficients {bj (t)}j=0 for the\n\nindicator evolution.\n\n5. Conclusion\nIn this paper, we have presented a framework for using data-based optimal\ncontrol to learn PDEs as a general regressor to approximate the nonlinear map25\n\n\fpings of different visual processing tasks. The experimental results on some computer vision and image processing problems show that our framework is promising. However, the current work is still preliminary, so we plan to improve and\nenrich our work in the following aspects. First, more theoretical issues should be\naddressed for this PDE system. For example, we will try to apply the Adomian\ndecomposition method [25] to express the exact analytical solution to (1) and then\nanalyze its physical properties. Second, we would like to develop more computationally efficient numerical algorithms to solve our PDE-constrained optimal\ncontrol problem (4). Third, we will apply our framework to more vision tasks to\nfind out to what extent it works.\nAppendix A. Proof of Property 2.1\n16\nWe prove that the coefficients {aj }16\nj=0 and {bj }j=0 must be independent of\n\n(x, y).\nProof. We prove for F (u, v, {aj }16\nj=0 ) in (1) only. We may rewrite\nF (u, v, {aj }16\nj=0 ) = F\u0303 (u, v, x, y, t).\nThen it suffices to prove that F\u0303 is independent of (x, y).\nBy the definition of translational invariance, when I(x, y) changes to I(x \u2212\nx0 , y\u2212y0 ) by shifting with a displacement (x0 , y0 ), u(x, y) and v(x, y) will change\nto u(x\u2212x0 , y \u2212y0 ) and v(x\u2212x0 , y \u2212y0 ), respectively. So the pair u(x\u2212x0 , y \u2212y0 )\nand v(x \u2212 x0 , y \u2212 y0 ) fulfils (1), i.e.,\n\u2202u(x \u2212 x0 , y \u2212 y0 )\n\u2202t\n\u2212F\u0303 (u(x \u2212 x0 , y \u2212 y0 ), v(x \u2212 x0 , y \u2212 y0 ), x, y, t) = 0.\n26\n\n\fNext, we replace (x \u2212 x0 , y \u2212 y0 ) in the above equation with (x, y) and have:\n\u2202u(x, y)\n\u2212 F\u0303 (u(x, y), v(x, y), x + x0 , y + y0 , t) = 0.\n\u2202t\nOn the other hand, the pair (u(x, y), v(x, y)) also fulfils (1), i.e.,\n\u2202u(x, y)\n\u2212 F\u0303 (u(x, y), v(x, y), x, y, t) = 0.\n\u2202t\nTherefore, F\u0303 (u, v, x + x0 , y + y0 , t) = F\u0303 (u, v, x, y, t), \u2200(x0 , y0 ) that confines the\ninput image inside \u03a9. So F\u0303 is independent of (x, y).\nAcknowledgment\nThis work was partially supported by the grants of the National Science Foundation of China, No. U0935004 and 60873181.\nReferences\n[1] T. Chen and J. Shen, Image processing and analysis: variational, PDE,\nSIAM Publisher, 2005.\n\nwavelet, and stochastic methods.\n\n[2] P. Pietro and M. Jitendra, \"Scale-space and edge detection using anisotropic\ndiffusion,\" IEEE Transactions on Pattern Analysis and Machine Intelligence,\nvol. 12, pp. 629\u2013639, 1990.\n[3] S. Osher and L. Rudin, \"Feature-oriented image enhancement using shock\nfilters,\" SIAM Journal on Numerical Analysis, vol. 27, pp. 919\u2013940, 1990.\n[4] G. Sapiro, Geometric partial differential equations and image analysis.\nCambridge University Press, 2001.\n\n27\n\n\f[5] L. Rudin, S. Osher, and E. Fatemi, \"Nonlinear total variation based noise\nremoval algorithms,\" Physica D., vol. 60, pp. 259\u2013268, 1992.\n[6] T. Chan and S. Esedoglu, \"Aspects of total variation regularizaed L1 function\napproximation,\" SIAM Journal on Applied Mathematics, vol. 65, pp. 1817\u2013\n1837, 2005.\n[7] D. Strong and T. Chan, \"Edge-preserving and scale-dependent properties of\ntotal variation regularization,\" Inverse Problems, vol. 19, pp. 165\u2013187, 2003.\n[8] X. Bresson, S. Esedoglu, P. Vandergheynst, J.-P. Thiran, and S. Osher, \"Fast\ngobal minimization of the active contour/snake model,\" Journal of Mathematical Imaging and Vision, vol. 28.\n[9] A. Chambolle, \"Total variation minimization and a class of binary MRF\nmodels,\" in Energy Minimization Methods in Computer Vision and Pattern\nRecognition (EMMCVPR), 2008.\n[10] C. Li, C. Xu, C. Gui, and M. Fox, \"Level set evolution without reinitialization: a new variational formulation,\" in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2005.\n[11] X. Gao, B. Wang, D. Tao, and X. Li, \"A relay level set method for automatic\nimage segmentation,\" IEEE Transactions on Systems, Man and Cybernetics\nPart B: Cybernetics, vol. 41, pp. 518\u2013525, 2011.\n[12] D. Cheng, Field and wave electromagnetics (2nd Edition).\n1989.\n\n28\n\nPrentics-Hall,\n\n\f[13] P. Olver, Applications of Lie groups to differential equations.\n\nSpringer-\n\nVerlarg, 1993.\n[14] D. Kirk, Optimal control theory: an introduction.\n\nPrentice-Hall, 1971.\n\n[15] A. Ababnah and B. Natarajan, \"Optimal control-based strategy for sensor\ndeployment,\" IEEE Transactions on Systems, Man and Cybernetics Part B:\nCybernetics, vol. 41, pp. 97\u2013104, 2011.\n[16] J. Lions, Optimal control systems governed by partial differential equations.\nSpringer-Verlag, 1971.\n[17] R. Liu, Z. Lin, W. Zhang, and Z. Su, \"Learning PDEs for image restoration\nvia optimal control,\" in European Conference on Computer Vision (ECCV),\n2010.\n[18] A. Jain, \"Partial differential equations and finite-difference methods in image processing, part 1,\" Journal of Optimization Theory and Applications,\nvol. 23, pp. 65\u201391, 1977.\n[19] J. Stoer and R. Bulirsch, Introduction to numerical analysis (2nd Edition).\nSpringer-Verlarg, 1998.\n[20] N. Mila, \"A variational approach to reomve outliers and impulse noise,\"\nJournal of Mathematical Imaging and Vision, vol. 20, pp. 99\u2013120, 2004.\n[21] J. Parker, Algorithms for image processing and computer vision. John Wiley\n& Sons Inc, 1997.\n\n29\n\n\f[22] D. R. Martin, C. Fowlkes, D. Tal, and J. Malik, \"A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics,\" in International Conference on\nComputer Vision (ICCV), 2001.\n[23] Corel photo library, corel corp., Ottawa, Canada.\n[24] J. Shi and J. Malik, \"Normalized cuts and image segmentation,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, no. 8, pp.\n888\u2013905, 2000.\n[25] A. Wazwaz, Partial differential equations and solitary waves theory.\nSpringer-Verlag, 2009.\n\n30\n\n\f"}