{"id": "http://arxiv.org/abs/0809.5087v1", "guidislink": true, "updated": "2008-09-29T23:00:22Z", "updated_parsed": [2008, 9, 29, 23, 0, 22, 0, 273, 0], "published": "2008-09-29T23:00:22Z", "published_parsed": [2008, 9, 29, 23, 0, 22, 0, 273, 0], "title": "Hybrid Neural Network Architecture for On-Line Learning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0809.3039%2C0809.3545%2C0809.0331%2C0809.4527%2C0809.4346%2C0809.4843%2C0809.2216%2C0809.2704%2C0809.3915%2C0809.0320%2C0809.2011%2C0809.1732%2C0809.1049%2C0809.1490%2C0809.3363%2C0809.2610%2C0809.1321%2C0809.2694%2C0809.0135%2C0809.1067%2C0809.3590%2C0809.0420%2C0809.3972%2C0809.1947%2C0809.3166%2C0809.0203%2C0809.3628%2C0809.1018%2C0809.2788%2C0809.5087%2C0809.1850%2C0809.2021%2C0809.4546%2C0809.2512%2C0809.0366%2C0809.2834%2C0809.4659%2C0809.2776%2C0809.1859%2C0809.2785%2C0809.4132%2C0809.4334%2C0809.0607%2C0809.4431%2C0809.2405%2C0809.0317%2C0809.0458%2C0809.3250%2C0809.1366%2C0809.5054%2C0809.0966%2C0809.2654%2C0809.1964%2C0809.2088%2C0809.0867%2C0809.3113%2C0809.2586%2C0809.2032%2C0809.4787%2C0809.2975%2C0809.4406%2C0809.0170%2C0809.4007%2C0809.2269%2C0809.1821%2C0809.2852%2C0809.1690%2C0809.2888%2C0809.3329%2C0809.1546%2C0809.0742%2C0809.5023%2C0809.4829%2C0809.1527%2C0809.5134%2C0809.2486%2C0809.3525%2C0809.2068%2C0809.2666%2C0809.0936%2C0809.4220%2C0809.2231%2C0809.3928%2C0809.4623%2C0809.5159%2C0809.4645%2C0809.0298%2C0809.4850%2C0809.4962%2C0809.0535%2C0809.3976%2C0809.1770%2C0809.3380%2C0809.0710%2C0809.4234%2C0809.1468%2C0809.3203%2C0809.4791%2C0809.2278%2C0809.0872%2C0809.1515&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Hybrid Neural Network Architecture for On-Line Learning"}, "summary": "Approaches to machine intelligence based on brain models have stressed the\nuse of neural networks for generalization. Here we propose the use of a hybrid\nneural network architecture that uses two kind of neural networks\nsimultaneously: (i) a surface learning agent that quickly adapt to new modes of\noperation; and, (ii) a deep learning agent that is very accurate within a\nspecific regime of operation. The two networks of the hybrid architecture\nperform complementary functions that improve the overall performance. The\nperformance of the hybrid architecture has been compared with that of\nback-propagation perceptrons and the CC and FC networks for chaotic time-series\nprediction, the CATS benchmark test, and smooth function approximation. It has\nbeen shown that the hybrid architecture provides a superior performance based\non the RMS error criterion.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0809.3039%2C0809.3545%2C0809.0331%2C0809.4527%2C0809.4346%2C0809.4843%2C0809.2216%2C0809.2704%2C0809.3915%2C0809.0320%2C0809.2011%2C0809.1732%2C0809.1049%2C0809.1490%2C0809.3363%2C0809.2610%2C0809.1321%2C0809.2694%2C0809.0135%2C0809.1067%2C0809.3590%2C0809.0420%2C0809.3972%2C0809.1947%2C0809.3166%2C0809.0203%2C0809.3628%2C0809.1018%2C0809.2788%2C0809.5087%2C0809.1850%2C0809.2021%2C0809.4546%2C0809.2512%2C0809.0366%2C0809.2834%2C0809.4659%2C0809.2776%2C0809.1859%2C0809.2785%2C0809.4132%2C0809.4334%2C0809.0607%2C0809.4431%2C0809.2405%2C0809.0317%2C0809.0458%2C0809.3250%2C0809.1366%2C0809.5054%2C0809.0966%2C0809.2654%2C0809.1964%2C0809.2088%2C0809.0867%2C0809.3113%2C0809.2586%2C0809.2032%2C0809.4787%2C0809.2975%2C0809.4406%2C0809.0170%2C0809.4007%2C0809.2269%2C0809.1821%2C0809.2852%2C0809.1690%2C0809.2888%2C0809.3329%2C0809.1546%2C0809.0742%2C0809.5023%2C0809.4829%2C0809.1527%2C0809.5134%2C0809.2486%2C0809.3525%2C0809.2068%2C0809.2666%2C0809.0936%2C0809.4220%2C0809.2231%2C0809.3928%2C0809.4623%2C0809.5159%2C0809.4645%2C0809.0298%2C0809.4850%2C0809.4962%2C0809.0535%2C0809.3976%2C0809.1770%2C0809.3380%2C0809.0710%2C0809.4234%2C0809.1468%2C0809.3203%2C0809.4791%2C0809.2278%2C0809.0872%2C0809.1515&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Approaches to machine intelligence based on brain models have stressed the\nuse of neural networks for generalization. Here we propose the use of a hybrid\nneural network architecture that uses two kind of neural networks\nsimultaneously: (i) a surface learning agent that quickly adapt to new modes of\noperation; and, (ii) a deep learning agent that is very accurate within a\nspecific regime of operation. The two networks of the hybrid architecture\nperform complementary functions that improve the overall performance. The\nperformance of the hybrid architecture has been compared with that of\nback-propagation perceptrons and the CC and FC networks for chaotic time-series\nprediction, the CATS benchmark test, and smooth function approximation. It has\nbeen shown that the hybrid architecture provides a superior performance based\non the RMS error criterion."}, "authors": ["Yuhua Chen", "Subhash Kak", "Lei Wang"], "author_detail": {"name": "Lei Wang"}, "author": "Lei Wang", "arxiv_comment": "19 pages, 16 figures", "links": [{"href": "http://arxiv.org/abs/0809.5087v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0809.5087v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.NE", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.NE", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0809.5087v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0809.5087v1", "journal_reference": null, "doi": null, "fulltext": "Hybrid Neural Network Architecture for On-Line Learning\nYuhua Chen*\u2020 * Subhash Kak\u2021 * Lei Wang\u00a7\n\nAbstract Approaches to machine intelligence based on brain models have\nstressed the use of neural networks for generalization. Here we propose the use\nof a hybrid neural network architecture that uses two kind of neural networks\nsimultaneously: (i) a surface learning agent that quickly adapt to new modes of\noperation; and, (ii) a deep learning agent that is very accurate within a specific\nregime of operation. The two networks of the hybrid architecture perform\ncomplementary functions that improve the overall performance. The performance\nof the hybrid architecture has been compared with that of back-propagation\nperceptrons and the CC and FC networks for chaotic time-series prediction, the\nCATS benchmark test, and smooth function approximation. It has been shown\nthat the hybrid architecture provides a superior performance based on the RMS\nerror criterion.\nKeywords Neural Networks * Instantaneously trained networks * BackPropagation * On-line learning\n\n1\n\nIntroduction\n\nOn-line learning requires the learning of the mode or context, out of a set of\nmany, within which the time-varying system is evolving. A few examples of timevarying systems are: aircraft during flight since the configurations of control\nsurfaces as well as flight conditions and the weight of the aircraft are continually\nchanging; the human vocal tract, as the shape of the vocal organs gets modified\nin the production of different vocalizations; electric or computer networks which\nmay have different modes of behavior depending of the time of the day; and the\nfinancial system which changes according to the investor sentiment. In this paper,\nwe consider such non-standard pattern recognition and discovery problems\nwhere statistical techniques and conventional neural networks are not convenient\nto use because of their slow speed.\nPattern discovery may be based on statistical methods [1], [2] or on neural\nnetworks. The currently researched techniques include various kinds of neural\nnetworks [3], principal-component analysis [4], principal-component regression\n*\n\nCorresponding author, e-mail: yuhua.chen@mail.uh.edu\nDepartment of Electrical and Computer Engineering, University of Houston, Houston, TX 77204-4005,\nUSA\n\u2021\nDepartment of Computer Science, Oklahoma State University, Stillwater, OK 74078, USA\n\u00a7\nDepartment of Electrical and Computer Engineering, University of Houston, Houston, TX 77204-4005,\nUSA\n\u2020\n\n1\n\n\f[4], partial least-squares regression [5], and combinatorial methods [6]. The\nVapnik-Chervonenkis dimension [1] quantifies the ease of learning categories\nfrom small data sets, and if the dimension is finite, machine learning of a certain\nkind can be efficiently done. The time-varying nature of the data sets that we\nwish to consider here precludes this approach. Machine intelligence that is based\non brain models has stressed the use of neural networks [7] that learn from a\ntraining set and then generalize on new input data. However, it has been argued\n[8], [9] that such models miss on the short-term learning component of biological\nsystems which is a very important component in adaptation to changing\nenvironment.\nBiological systems operate in time-changing environments, and they are\nespecially good at learning in such conditions. Biological learning appears to be\nat the basis of the capacity of biological systems to adapt to time-varying\nenvironments [10],[11]. The learning components of biological systems may be\ndivided into three types: sensory, short-term and long-term [12]. The sensory\ncomponent provides immediate simple reactions to certain changes in the\nenvironment. One example of the sensory component is human reflex, which is\nalmost instant in response to stimulus. The long-term learning component is\nbased on experiences gained over periods of time. The short-term learning\nstands in between the sensory and long-term learning components, and is\ncapable of performing more complex learning tasks than the sensory component\nwhile being able to adapt to the changing environment quickly.\nThe interplay among these biological learning components appears to provide\nto the organism the capacity to operate in uncertain environments. In addition,\ntwo cognitive processes that help in preventing overloading are sensory gating\n(by which the brain adjusts its response to stimuli) and selective attention (which\nallows the brain to concentrate on one aspect to the exclusion of others). This is\nseen, for example, in the driving of a car, where the driver may not be paying\ntotal attention to the road in ordinary circumstances. But when the driving\nconditions are difficult, a different center takes over the driving completely. The\nfirst of the two cases may be ascribed to long-term learning and the second to\nshort-term learning.\nIn this paper, we propose a hybrid architecture for on-line learning of a timevarying system. The proposed hybrid architecture employs a surface learning\ncomponent which can adapt to quick changes in system conditions, as well as a\ndeep learning component which is highly accurate to minimize errors within the\nsame regime of operation. A high level cognitive agent monitors the outputs from\nthe surface learning and deep learning components, and automatically generates\ndesirable system outputs.\nWe show that the proposed approach provides much better performance\ncompared to traditional approaches. The proposed model provides a framework\nwhich may lead to flexible intelligence that is able to adapt to changing\nenvironment quickly. It will be helpful for processing of information associated\nwith complex \"intelligent\" tasks in the real world with dynamic and intentional\nphenomena in the presence of uncertainty about the environment. Specifically,\n2\n\n\fwe will be able to explore novel and hybrid methods that extend the breadth of\nreasoning to include uncertain and dynamic environments, and also consider the\nperformance with interacting agents.\nThe rest of the paper is organized as follows. Section 2 described the\nproposed hybrid system architecture. Section 3 discusses some candidate\ncomponents in building the hybrid system. Section 4 evaluates the performance\nof the proposed hybrid system. We conclude our work in Section 5.\n\nSurface Learning\nAgent\nCognitive\nAgent\nDeep Learning\nAgent\n\nHybrid System Architecture\n\nFig. 1. Hybrid System Architecture\n\n2\n\nHybrid System Architecture for On-Line Learning\n\nThe proposed hybrid system can be applied to a broad range of applications\nsuch as function approximation, time series prediction, and pattern classification.\nEach of these areas naturally covers many specific applications. For example,\ntime series prediction may be applied to financial or signal data, and pattern\nrecognition includes application to engineering, military, or medical systems. In\nthis section, we describe the general framework of the proposed hybrid system\narchitecture that enables fast and accurate on-line learning of a time-varying\nsystem.\nFigure 1 shows the proposed hybrid system architecture, which consists of a\nsurface learning agent, a deep learning agent, and a cognitive agent. In the\nhybrid system architecture, the surface learning agent and the deep learning\nagent work in parallel in responding to the changes of the environment. In\nparticular, the surface learning agent picks up the short-term structure of the\ninformation signal, and performs quick analysis to respond to the stimulus. The\ndeep learning agent seeks out long-term structure of the information, and\nabstracts longer correlations present within the system. The high level cognitive\nagent monitors the environment, as well as the decisions made by the surface\nand deep learning agents, and automatically generates the most desirable\nsystem output based on the situation.\nConsider the system of Figure 2 where the input X (t ) is generated by a\n3\n\n\frandom switching between several random processes { X i (t ), i = 1,..., N } ; S is a\ndynamic system; and Y (t ) is the output random process. The objective is to\npredict the realization Y (t ) of the output process from its past values.\n\nXi(t)\n\nY(t)\n\nS\n\nFig. 2. System Under Consideration\nThe motivation for solving this problem is the consideration of real world\nprocesses where the input is time varying in such a manner that it is best\nrepresented as a series of different random processes. For an agent that wishes\nto predict Y (t ) based on its past, it is essential to learn which of the N X i s is at\nthe input, where it is assumed that the statistical characteristics of the X i s are\nknown so that its prediction can be made relatively easily. The problem arises\nfrom the fact that the input signal switches between different processes and\ntherefore no single statistical technique will work at the output all the time.\nWe divide the problem of prediction into two components: deep learning and\nsurface learning. Deep learning operates within the regime of a specific index i\nof X i and provides the best performance with respect to some criterion (such as\nminimization of RMS error). One would expect that it would take the deep\nlearning agent some amount of time to adapt to the statistical characteristics of\nthe signal at the input and, therefore, it would be assumed that the switching\nbetween the modes takes place slower than this characteristic time. Surface\nlearning operates best during the transition regime between, let us say, the\nindices i and j .\nThe dichotomy of the surface and deep learning agents in the proposed\nhybrid system can find its success in linguistics [13]. For example, in speech or\ntext understanding, without knowing the context, a narrative may appear\nmeaningless. The syntax is provided by the surface structure, whereas the\nsemantics come from the deep structure. Clearly, the surface learning and deep\nlearning agents in the proposed hybrid system is not quite identical to that of\nsyntax and semantics, but it does constitute a step in this direction.\nThe role of the cognitive agent can be as simple as making a binary decision\nof selecting the system output from either the surface learning agent or the deep\nlearning agent, or as complex as synthesizing the outputs of the two learning\nagents into a high level of intelligence. For example, the cognitive agent in the\nhybrid architecture monitors the errors produced by the surface learning agent\n4\n\n\fand the deep learning agent, and automatically switches the system output\naccording to the system conditions. When the system function changes suddenly,\nthe surface learning agent is able to catch up with the changes quickly while the\ndeep learning agent requires more time to produce results with acceptable\noutputs. In this case, the cognitive agent will use the outputs produced by the\nsurface learning agent. When the system stabilizes in a certain operational\nregion, the deep learning agent will eventually catch up and produces outputs\nwith more accuracy. When this happens, the cognitive agent will select the\noutputs from the deep learning agent instead. As a result, the hybrid architecture\ncan respond to the changing system quickly and accurately.\n\n3\n\nBuilding Blocks of Hybrid Architecture\n\nThe deep learning agent in the hybrid system must have the property of\ndisregarding quick changes or transients in the input. In other words, it must\nlearn such exemplars that are typical of an established mode. The deep learning\nagent is, therefore, not very good at determining the transition between modes\nand this is the reason why it takes more time than an agent that is focused on\nlearning quick changes in the signal. In the biological domain, the deep learning\nagent is the collection of long-term learning mechanisms.\nSeveral neural networks listed in the section on historical notes of [14] could\nserve as the deep learning agent. In this paper, we use the multi-layer perceptron\nwith back-propagation as the deep learning agent because it is able to learn the\nlong-term characteristics of the patterns most efficiently [15]. For the rest of the\nsection, we focus on the choices of surface learning agent, which is the most\nchallenging component in designing in the hybrid system.\nThe surface learning agent needs to be able to learn the changed system\nfunction instantaneously or near-instantaneously. The performance of the surface\nlearning agent directly affects the performance of the hybrid system. We describe\ntwo candidates for the surface learning agent in detail as follows.\n3.1 Corner Classification (CC) Networks\nThe corner classification (CC) network is based on the idea of phonological\nloop and the visio-spatial sketchpad. It was proposed by Kak in three variations\n[8],[9]. These and its more advanced variants are also known as the class of Kak\nneural networks. There are four versions of the CC technique, represented by\nCC1 through CC4. The concept of radius of generalization was introduced in\nCC3 and thus this neural network overcame the generalization problem that\nplagued the earlier CC2 network. Each node in the network acts as a filter for the\ntraining sample. The filter is realized by making it act as a hyper plane to\nseparate the corner of the n-dimensional cube represented by the training vector\nand hence the name corner-classification technique. The CC4 is shown to be\nbetter than the other networks in the CC category [16], and is described in detail\nas follows.\n\n5\n\n\fH1\n\u20101\n\u20101\n1\n\nX1\n\n\u20101\n\n\u20101\n\nH2\n\n1\n\n1\n\n0\n\nX2\n\u20101\n0\n\nX3=1\n\n1\n\nH3\n\n\u20101\n\n1\n\u20101\n\n1\n\nY\n\n1\n\nH4\n\nFig. 3. CC4 network architecture for learning the XOR function\n\nCC4 uses a feedforward network architecture consisting of three layers of\nneurons as shown in Figure 3. The number of input neurons is equal to the\nlength of input patterns or vectors plus one, the additional neuron being the bias\nneuron, which has a constant input of 1. The number of hidden neurons is equal\nto the number of training samples, each hidden neuron correspond to one\ntraining example. The last node of the input layer is set to one to act as a bias to\nthe hidden layer. The binary step function is used as the activation function for\nboth the hidden and output neurons. The output of the activation function is 1 if\nsummation is positive and zero otherwise.\nInput and output weights are determined as follows. For each training vector\npresented to the network, if an input neuron receives a 1, its weight to the hidden\nneuron corresponding to this training vector is set to I. Otherwise, it is set to -1.\nThe bias neuron is treated differently. If s is the number of l's in the training\nvector, excluding the bias input, and the desired radius of generalization is r, then\nthe weight between the bias neuron and the hidden neuron corresponding to this\ntraining vector is r - s + 1. Thus, for any training vector xi of length n including the\nbias, the input layer weights are assigned according to the following equation:\n\u23a71\n\u23aa\nwi [ j ] = \u23a8\u22121\n\u23aa r \u2212 s +1\n\u23a9\n\nif xi [ j ] = 1\nif xi [ j ] = 0\nif j = n.\n\nThe weights in the output layer are equal to 1 if the output value is 1 and \u20131 if the\n\n6\n\n\foutput value is 0. This amounts to learning both the input class and its\ncomplement and thus instantaneous. The radius of generalization, r can be seen\nby considering the all-zero input vectors for which wn+1 = r + 1. The choice of r\nwill depend on the nature of generalization sought. Figure 3 presents a network\nfor the implementation of the XOR example using CC4. Since the weights are 1, 1, or 0, it is clear that actual computations are minimal. In the general case, the\nonly weight that can be greater in magnitude than 1 is the one associated with\nthe bias neuron.\n3.2 Fast Classification (FC) Network\nHere we present another candidate for the surface learning agent, the fast\nclassification (FC) network [17][18], which is a generalization of the CC networks.\nWhereas the CC networks perform nearest-neighbor generalization of data as\nbinary vectors, the FC network does the same by considering analog-valued\nvectors. The FC network uses some appropriate metric to compare the stored\nvectors of the data to the input data. It depends on the concept of \"nearest\nneighbor\" for generalization and consists of three layers - an input layer, a hidden\nlayer and an output layer.\nThe input data is normalized and presented as input vector x. The hidden\nneuron is represented by the weight vector wi and its elements are represented\nby wi, j ,i =(1,2,...,S) and j=(1,2,...,R), where R is the number of components of\nthe input vector and S is the number of hidden neurons (the number of training\nsamples). The output is the dot product of the vectors \u03bc and u, where \u03bc is the\nInput Layer\n\nx1\n\nOutput Layer\n\nHidden Layer\n\nd1\n\nw1,1\nw1,2\nw1,R\n\nh1\n\n\u03bc1\nu1\n\nr1\nd2\n\nx2\n\nF\n\nF\n\nh2\n\n\u03bc2\nu2\n\nRule\nBase\n\n...\n\n...\n\n...\n\nr2\n\nwS,R\n\ny =\n\nS\n\n\u2211\n\ni =1\n\nwS,1\nxR\n\ny\n\n\u2211\n\n\u03bc iu i\n\nuS\ndS\n\nd i = dist ( x , w )\n\nF\nrS\n\nhS\n\n\u03bcS\n\nh i = F ( d i , ri )\n\nFig 4: FC network architecture\nvector at the output of the Rule Base and u is the vector of weights in the output\n\n7\n\n\flayer as shown in Figure 4. This network can be trained with just two passes of\nthe samples, the first pass assigns the synaptic weights and the second pass\ndetermines the radius of generalization for each training sample by fuzzification\nof the location of the each training sample and by assigning fuzzy membership\nfunctions of output classes to new input vectors.\nThe network behaves as a 1NN classifier and a kNN classifier (1- or knearest neighbor classifier) according to whether the input vector falls within the\nradius of generalization of a training vector or not. The radius of generalization\nacts as a switch between the 1NN classifier and the kNN classifier. The FC\nnetwork meets the specifications set by traditional function approximation that\nevery data point is covered in the given training sample and also Cover's\ntheorem on separability of patterns [19]. In the practical case, the k values are\ndetermined by the sample size and be a fraction of the sample size. If k=S then\nthe FC network operating as a kNN classifier can be viewed as a RBF network\n[14] provided the membership function is chosen to be a Gaussian distributed.\nOn the other hand, if the weighting function is chosen to be the membership\nfunction, the FC classifier can be considered as kernel regression [18]. As in the\nCC networks, this network requires as many hidden neurons as the number of\ntraining samples (although the number of hidden neurons could be trimmed to a\ncertain extent).\nAs mentioned before, the CC networks work on binary data, which requires\nquantization of input values. If that is a constraint one wishes to avoid for certain\nreasons, one can use FC networks, which are a generalization of CC networks\nand they work on continuous valued data. FC networks require a comparison\nwith stored information in one pass, and, therefore, they are not quite\ninstantaneous, but the calculation can be done in time that could be smaller than\nthe time instant at which the next data comes in.\n\n4. Performance Evaluation\nIn this section, we evaluate the performance of the hybrid system using\nseveral benchmarks.\n4.1 Mackey-Glass Time Series Prediction\nTime series prediction is widely used in financial data for prediction of stocks,\ncurrency, interest rates and engineering such as electric load demand. The\nnetwork is trained by historical data set with time index and the network predicts\nthe future values based on past values. Mackey-Glass (MG) time series is a\nchaotic time series based on Mackey-Class differential equation,\ndx(t )\nx(t \u2212 D)\n= \u2212 B * x(t ) + a *\ndt\n1 + x(t \u2212 D) C ,\n\nwhere the choice of D has important influence on its chaotic behavior. In most\nresearch work, D is set to be 17 or 30 because the interesting quasi-periodic\n\n8\n\n\fbehaviors these two values present.\nWe investigate the system response of the hybrid system when the MG\nseries migrates from parameter set 1 to parameter set 2. More specifically, the\nhybrid system is first trained to predict MG series with parameter set 1 (P1 = {A =\n0.8, B=0.1, C=10, D=30}), and then the MG series with parameter set 2 (P2 =\n{A=0.8, B=0.1, C=10, D=17}). The sliding window is of size 6, and thus inputs\nconsist of 6 consecutive points that are use to predict the very next point ahead:\n^\n\n( x ( k + 1) = f { x ( k ), x ( k \u2212 1),..., x ( k \u2212 5)} ).\nWe obtained the raw data from the Working Group on Data Modeling\nBenchmarks (under IEEE Neural Networks Council Standards Committee). The\nfirst 3500 points in the initialization stage are not used for either training or testing.\nThe next 1000 points are used for training and validation. Another 500 points are\nused for testing.\nThe performance of CC and FC are compared as the potential candidates for\nthe surface learning agent. The multi-layer perceptron with back-propagation (BP)\nis used for the deep learning agent. We are interested in studying how CC, FC\nand BP will respond to the change of parameters in the MG series. We use the\nRMS error as the performance measure of the system response to the relearning\nprocess. In Figure 5, we observe that as the candidates for the surface learning\nagent, CC and FC has reduced RMS error almost instantaneously. On the other\nhand, it takes some time for the deep learning agent BP to converge to new\nparameters. However, in a long run, the RMS error produced by the deep\nlearning agent BP is smaller than the surface learning agent CC or FC. The\nvertical line marks the stopping point (at 1886-th adaptation cycle) which is\ndetermined by the RMS error validation set so as to avoid system over-fitting.\n\nFig. 5 RMS Errors vs. Adaptation cycles\n\n9\n\n\fFig. 6 RMS error of the hybrid system\nSince FC produces smaller RMS errors than CC, we use FC and BP as the\nsurface learning agent and the deep learning agent in the hybrid system,\nrespectively. The cognitive agent automatically selects the output from the\nsurface learning agent FC once it detects that the system function changes, and\nswitches to the deep learning agent BP after it catches up. The RMS error of the\nhybrid system is shown in Figure 6. It is clear that the hybrid system has\nenhanced performance, taking advantage of the surface learning agent and the\ndeep learning agent.\n4.2 CATS Benchmark Test\nThe CATS benchmark arises from the well-known Time Series Prediction\nCompetition held in 2004, in which participants were invited to predict 100\nmissing points from a 5000-point artificial time series. This 100 data points were\ndivided into 5 groups, each located in the position range 981-1000, 1981-2000,\n2981-3000, 3981-4000 and 4981-5000, respectively. Participants proposed\nseveral prediction methods, linear as well as nonlinear and the winner suggests\nthat good division of the problem into short-term prediction and long-term\nprediction lead to good result. Since we are interested in the system response of\nthe hybrid system, we skip the input selection stage and only the use short-term\nprediction.\nThe\nshort-term\nprediction\nis\nknown\nas\n^\n\nx(t + 1) = f ( x(t ), x(t \u2212 1),..., x(t \u2212 W + 1)) , where W indicates the window size.\nEach time after a prediction is made, the oldest point in the window will be\ndropped and the newly predicted point is appended on the other side, becoming\nthe current value to predict the next point. We use validation sets of 10 points\n(from the known points) to find the best window size, with which we train the final\nnetwork. We first train the networks to learn points 1-980 and 1001-1980 to\n\n10\n\n\fpredict points 981-1000. Thereafter, based on the trained network, relearning is\nlaunched to learn another two segments 3001-3980 and 4001-4980. The system\nresponse during the relearning process is thus evaluated. In both cases, 10-point\nvalidation sets are utilized, and they are selected to be points 971-980 and 39713980, which are adjacent to the to-be-predicted points 981-1000 and 3981-4000,\nrespectively. CC precision is fixed at 256 and window size is selected to be 30\nbased on the results of validation sets.\n4000\n\n^\n\n\u2211 ( yt \u2212 yt ) 2\n\nFigure 7 plots the E1 errors for points 3981-4000 ( t =3981\n\n) produced by\n100\nBP, CC and FC during the relearning process. The BP result is obtained by\naveraging the results of 10 different trials. Note that the average stopping point\nfor BP is at the 502th adaptation cycle determined by the validation set. As\nexpected, FC produces good results almost instantly. BP converges slowly but\nachieves better results eventually. The large error produced by CC is due to the\nprecision. Since FC is consistently better than CC, we use FC as the surface\nlearning agent and BP as the deep learning agent for the hybrid system. The\nhybrid system switches automatically between the surface learning agent FC and\nthe deep learning agent BP in the relearning process. The E1 error of the hybrid\nsystem is shown in Figure 8. This further demonstrates the advantages of the\nhybrid system.\n\nFig. 7 E1 Errors during the relearning process\n\n11\n\n\fFig. 8 E1 Error produced by the hybrid system\n\n4.3 Smooth Function Approximation\nThe problem in smooth function approximation is to implement a function,\nF(x), which approximates an unknown smooth function, f(x), with a priori as the\ninput-output pairs in a Euclidian sense for all inputs.\nAgain we use the CC and FC as the potential candidates for the surface\nlearning agent, and BP as the deep learning agent. The hybrid system is first\ntrained to approximate a smooth function with parameter set P1, and then\nrelearns the function as the parameter set changes to P2. The objective smooth\nfunction is selected to be the pdf of the Multivariate Normal Distribution,\n1\n1\nf X ( x1 , x 2 ) =\nexp(\u2212 ( x \u2212 \u03bc ) T \u03a3 \u22121 ( x \u2212 \u03bc )) . The configurations of the two\n1/ 2\n2\n2\u03c0 \u03a3\nparameter sets are in shown table I. The training set is constructed by uniformly\nsampling 900 points in the 2-D input space, and another 1600 points make up\nthe testing set.\n\nP1\n\nP2\n\n\u03bc={0,0}\n\n\u03bc={-0.2,0.7}\n\n\u2211={0.8 0.2;0.2 0.1}\n\n\u2211={0.25 0.3;0.3 1}\n\nTable I. Smooth function parameter configuration\n\n12\n\n\fTo understand how the deep learning agent and the surface learning agent in\nthe hybrid system respond to the changed function, we plot a series of\ntransitional plots as follows. The actual function with parameter set P1 was\nplotted in Figure 9. Figure 10-12 capture the relearning processes for the deep\nlearning agent BP. It can be observed that the deep learning agent BP adapts\nfrom parameter set P1 to P2 gradually. Figure 13 and Figure 14 show the\napproximation of the surface learning agent candidates CC and FC after\ninstantaneous training, respectively.\nThe RMS errors produced by the BP, CC and FC during the relearning\nprocesses are plotted in Figure 15. As we can see from the figure, it takes a\nconsiderable number of adaptation cycles for the deep learning agent BP to\ncatch up with the surface learning agent CC or FC. Since FC produces smaller\nRMS errors, we choose FC as the surface learning agent for smooth function\napproximation. The RMS errors of the hybrid system are plotted in Figure16.\n\nFig. 9 Actual smooth function with parameter P1\n\n13\n\n\fFig. 10 BP shape after 1 adaptation cycles\n\nFig. 11 BP shape after 5001 relearning adaptation cycles\n\n14\n\n\fFig. 12 BP shape after 300003 relearning adaptation cycles\n\nFig. 13 CC Approximation of P2\n\n15\n\n\fFig. 14 FC approximation of P2\n\nFig. 15 RMS errors vs. Adaptation cycles\n\n16\n\n\fFig. 16 RMS of the Hybrid Architecture\n\n5. Conclusion\nThis paper has proposed a hybrid neural network architecture that uses two\nkinds of neural networks simultaneously: (i) a surface learning network that can\nquickly adapt to new modes of operation; and, (ii) a deep learning, accurate\nnetwork for use within a specific regime of operation. The two networks of the\nhybrid architecture perform functions like that of short-term and long-term\nlearning. Such a hybrid architecture can be based on different classes of learning\nsystems although in this paper we have considered CC and FC fast learning\nnetworks on the one hand and back-propagation networks on the other.\nThe performance of the hybrid architecture has been compared with that of\nmulti-layer perceptron with back-propagation and the CC and FC networks for\nchaotic time-series prediction, the CATS benchmark test, and smooth function\napproximation. It has been shown that the hybrid architecture provides a superior\nperformance based on a RMS error criterion.\nWe expect the applications of our hybrid neural network architecture to\nproblems in finance, control, time-series prediction, and economic forecasting.\n\n17\n\n\fReferences\n\n[1] V.N. Vapnik, The Nature of Statistical Learning Theory. Springer-Verlag, Berlin,\n1995.\n[2] M.J. Kearns and U.V. Vazirani, An Introduction to Computational Learning Theory.\nMIT Press, 1994.\n[3] C.G. Looney, Pattern Recognition Using Neural Networks. Oxford University Press,\nNew York, 1997.\n[4] I.T. Joliffe, Principal Component Analysis. Springer-Verlag, 2002/\n[5] Frank, Ildiko and Jerome Friedman, \"A Statistical View of Some Chemometrics\nRegression Tools\", Technometrics, 35(2), pp 109\u2013148, 1993.\n[6] C.H. Papadimitrou and K. Steiglitz, Combinatorial Optimization. Dover\nPublications, New York, 1998.\n[7] C.M. Bishop, Neural Networks for Pattern Recognition. Oxford University Press,\nOxford, 1996.\n[8] S. Kak, \"Three languages of the brain: Quantum, reorganizational, and associative,\n\" In Learning as Self-Organization, K. Pribram and J. King, eds., Lawrence Erlbaum,\nMahwah, N.J., 1996, pp. 185--219.\n[9] S. Kak, \"Faster web search and prediction using instantaneously trained neural\nnetworks,\" IEEE Intelligent Systems, vol. 14, pp. 79-82, November/December 1999.\n[10] S. Kak, Stream computing. 2008. arXiv:0801.1336\n[11] S. Kak, \"Artificial and biological intelligence\", ACM Ubiquity, vol. 6, No. 42, pp. 120, 2005. Also arXiv: cs.AI/0601052\n[12] E.R. Kandel, In Search of Memory: The Emergence of a New Science of Mind. W.W.\nNorton, New York, 2007.\n[13] N. Chomsky, Syntactic Structures. Mouton, 1957.\n[14] S. Haykin, Neural Networks. Prentice-Hall, 1999.\n[15] A.R. Barron, Universal approximation bounds for superpositions of a sigmoidal\nfunction. IEEE Trans. Information Theory, Volume 39, Issue 3, May 1993, pp.\n930 \u2013 945.\n[16] K. W. Tang and S. Kak, \"A new corner classification approach to neural network\ntraining.\" Circuits, Systems, Signal Processing, vol. 17, pp. 459-469, 1998.\n\n18\n\n\f[17] S. Kak, \"A class of instantaneously trained neural networks\", Information Sciences,\nvol. 148, pp. 97-102, 2002.\n[18] K.W. Tang and S. Kak, \"Fast classification networks for signal processing.\" Circuits,\nSystems, Signal Processing, vol. 21, pp. 207-224, 2002.\n[19] T.M. Cover, Geometrical and statistical properties of systems of linear inequalities\nwith applications in pattern recognition, IEEE Trans. Electron. Comput. Vol. 14, pp.\n326\u2013334, 1965.\n\n19\n\n\f"}