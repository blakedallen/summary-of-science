{"id": "http://arxiv.org/abs/0905.2364v1", "guidislink": true, "updated": "2009-05-14T16:03:51Z", "updated_parsed": [2009, 5, 14, 16, 3, 51, 3, 134, 0], "published": "2009-05-14T16:03:51Z", "published_parsed": [2009, 5, 14, 16, 3, 51, 3, 134, 0], "title": "Formalizing Safety Requirements Using Controlling Automata", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0905.3410%2C0905.3835%2C0905.4335%2C0905.1393%2C0905.1916%2C0905.3122%2C0905.2902%2C0905.1262%2C0905.1518%2C0905.4886%2C0905.4223%2C0905.1227%2C0905.2337%2C0905.2242%2C0905.0201%2C0905.4542%2C0905.2851%2C0905.4172%2C0905.4041%2C0905.3926%2C0905.1553%2C0905.1483%2C0905.0335%2C0905.2694%2C0905.0490%2C0905.2915%2C0905.3878%2C0905.2007%2C0905.1161%2C0905.0328%2C0905.3046%2C0905.4050%2C0905.3116%2C0905.3379%2C0905.3394%2C0905.1902%2C0905.3386%2C0905.1681%2C0905.3857%2C0905.4548%2C0905.1122%2C0905.2131%2C0905.0826%2C0905.0609%2C0905.3145%2C0905.1092%2C0905.4235%2C0905.4487%2C0905.3466%2C0905.0774%2C0905.1488%2C0905.0942%2C0905.1169%2C0905.2890%2C0905.2041%2C0905.4836%2C0905.4688%2C0905.2823%2C0905.1086%2C0905.2191%2C0905.1932%2C0905.0790%2C0905.3529%2C0905.3364%2C0905.2719%2C0905.1970%2C0905.3485%2C0905.1702%2C0905.0271%2C0905.2356%2C0905.4133%2C0905.3809%2C0905.0131%2C0905.1408%2C0905.1900%2C0905.1718%2C0905.1091%2C0905.1987%2C0905.1765%2C0905.0212%2C0905.1210%2C0905.3313%2C0905.1163%2C0905.3251%2C0905.0312%2C0905.0385%2C0905.1187%2C0905.2361%2C0905.2657%2C0905.2338%2C0905.0914%2C0905.3801%2C0905.2464%2C0905.1662%2C0905.3207%2C0905.0180%2C0905.1278%2C0905.3874%2C0905.3551%2C0905.2364%2C0905.0850&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Formalizing Safety Requirements Using Controlling Automata"}, "summary": "Safety is an important element of dependability. It is defined as the absence\nof accidents. Most accidents involving software-intensive systems have been\nsystem accidents, which are caused by unsafe inter-system or inter-component\ninteractions. To validate the absence of system hazards concerning\ndysfunctional interactions, industrials call for approaches of modeling system\nsafety requirements and interaction constraints among components. This paper\nproposes such a formalism, namely interface control systems (or shortly\nC-Systems). An interface C-System is composed of an interface automaton and a\ncontrolling automaton, which formalizes safe interactions and restricts system\nbehavior at the meta level. This framework differs from the framework of\ntraditional model checking. It explicitly separates the tasks of product\nengineers and safety engineers, and provides a top-down technique for modeling\na system with safety constraints, and for automatically composing a safe system\nthat conforms to safety requirements. The contributions of this work include\nformalizing safety requirements and a way of automatically ensuring system\nsafety.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=0905.3410%2C0905.3835%2C0905.4335%2C0905.1393%2C0905.1916%2C0905.3122%2C0905.2902%2C0905.1262%2C0905.1518%2C0905.4886%2C0905.4223%2C0905.1227%2C0905.2337%2C0905.2242%2C0905.0201%2C0905.4542%2C0905.2851%2C0905.4172%2C0905.4041%2C0905.3926%2C0905.1553%2C0905.1483%2C0905.0335%2C0905.2694%2C0905.0490%2C0905.2915%2C0905.3878%2C0905.2007%2C0905.1161%2C0905.0328%2C0905.3046%2C0905.4050%2C0905.3116%2C0905.3379%2C0905.3394%2C0905.1902%2C0905.3386%2C0905.1681%2C0905.3857%2C0905.4548%2C0905.1122%2C0905.2131%2C0905.0826%2C0905.0609%2C0905.3145%2C0905.1092%2C0905.4235%2C0905.4487%2C0905.3466%2C0905.0774%2C0905.1488%2C0905.0942%2C0905.1169%2C0905.2890%2C0905.2041%2C0905.4836%2C0905.4688%2C0905.2823%2C0905.1086%2C0905.2191%2C0905.1932%2C0905.0790%2C0905.3529%2C0905.3364%2C0905.2719%2C0905.1970%2C0905.3485%2C0905.1702%2C0905.0271%2C0905.2356%2C0905.4133%2C0905.3809%2C0905.0131%2C0905.1408%2C0905.1900%2C0905.1718%2C0905.1091%2C0905.1987%2C0905.1765%2C0905.0212%2C0905.1210%2C0905.3313%2C0905.1163%2C0905.3251%2C0905.0312%2C0905.0385%2C0905.1187%2C0905.2361%2C0905.2657%2C0905.2338%2C0905.0914%2C0905.3801%2C0905.2464%2C0905.1662%2C0905.3207%2C0905.0180%2C0905.1278%2C0905.3874%2C0905.3551%2C0905.2364%2C0905.0850&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Safety is an important element of dependability. It is defined as the absence\nof accidents. Most accidents involving software-intensive systems have been\nsystem accidents, which are caused by unsafe inter-system or inter-component\ninteractions. To validate the absence of system hazards concerning\ndysfunctional interactions, industrials call for approaches of modeling system\nsafety requirements and interaction constraints among components. This paper\nproposes such a formalism, namely interface control systems (or shortly\nC-Systems). An interface C-System is composed of an interface automaton and a\ncontrolling automaton, which formalizes safe interactions and restricts system\nbehavior at the meta level. This framework differs from the framework of\ntraditional model checking. It explicitly separates the tasks of product\nengineers and safety engineers, and provides a top-down technique for modeling\na system with safety constraints, and for automatically composing a safe system\nthat conforms to safety requirements. The contributions of this work include\nformalizing safety requirements and a way of automatically ensuring system\nsafety."}, "authors": ["Zhe Chen", "Gilles Motet"], "author_detail": {"name": "Gilles Motet"}, "author": "Gilles Motet", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/DEPEND.2009.18", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/0905.2364v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/0905.2364v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "6 pages. In Proceedings of the 2nd International Conference on\n  Dependability (DEPEND 2009), Athens, Greece. IEEE Computer Society, 2009", "arxiv_primary_category": {"term": "cs.SE", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.SE", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.FL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "D.2; F.1.1", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/0905.2364v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/0905.2364v1", "journal_reference": null, "doi": "10.1109/DEPEND.2009.18", "fulltext": "Formalizing Safety Requirements Using Controlling Automata\n\narXiv:0905.2364v1 [cs.SE] 14 May 2009\n\n\u2020\n\nZhe Chen \u2020\nLaboratory LATTIS, INSA, University of Toulouse\n135 Avenue de Rangueil, 31077 Toulouse, France\nEmail: zchen@insa-toulouse.fr\n\nGilles Motet \u2020,\u2021\nFoundation for an Industrial Safety Culture\n6 All\u00e9e Emile Monso, 31029 Toulouse, France\nEmail: gilles.motet@insa-toulouse.fr\n\u2021\n\nAbstract\nSafety is an important element of dependability. It is\ndefined as the absence of accidents. Most accidents involving software-intensive systems have been system accidents,\nwhich are caused by unsafe inter-system or inter-component\ninteractions. To validate the absence of system hazards\nconcerning dysfunctional interactions, industrials call for\napproaches of modeling system safety requirements and\ninteraction constraints among components. This paper proposes such a formalism, namely interface control systems (or\nshortly C-Systems). An interface C-System is composed of\nan interface automaton and a controlling automaton, which\nformalizes safe interactions and restricts system behavior at\nthe meta level. This framework differs from the framework of\ntraditional model checking. It explicitly separates the tasks\nof product engineers and safety engineers, and provides\na top-down technique for modeling a system with safety\nconstraints, and for automatically composing a safe system\nthat conforms to safety requirements. The contributions of\nthis work include formalizing safety requirements and a way\nof automatically ensuring system safety.\n\n1. System Safety Requirements\nCritical systems are always controlled by software applications, which overcome the shortcomings of human control,\nbut also introduce new failure modes that are changing the\nnature of accidents [1]. Inter-system and inter-component\ndependability are becoming important, since industrials are\ndeveloping complicated software-intensive systems which\nconsist of numerous components (subsystems) and a huge\nnumber of actions (both internal and interactive). A recent\nchallenge of dependability is the system accident, caused by\nincreasing inter-system and inter-component couplings and\ntheir interactive complexity [2][3]. In contrast, accidents arising from component failures are termed component failure\naccidents.\nSystem safety and component reliability are different\nelements of dependability. They are system property and\ncomponent property, respectively [2]. Reliability is defined\nas the capability that a component satisfies its specified\n\nFigure 1. A Chemical Reactor Design\n\nbehavioral requirements, whereas safety is defined as the absence of accidents - events involving an unacceptable loss\n[4]. People are now constructing intellectually unmanageable\nsoftware systems that go beyond human cognitive limits.\nThis allows potentially unsafe interactions to be undetected.\nAccidents often result from hazardous interactions among\nperfectly functioning components.\nAs an example, a system accident occurred in a batch\nchemical reactor in England [5]. The design of the system\nis shown in Fig. 1. The computer controlled the input flow\nof cooling water into the condenser and the input flow of\ncatalyst into the reactor by manipulating the valves. The\ncomputer was told that if any component in the plant gets\nabnormal, it had to leave all controlled variables as they were\nand to sound an alarm. On one occasion, the computer just\nstarted to increase the cooling water flow, after a catalyst had\nbeen added into the reactor. Then the computer received an\nabnormal signal indicating a low oil level in a gearbox, and\nit reacted as its requirements specified: sounded an alarm\nand maintained all the control variables with their present\ncondition. Since the water flow was kept at a low rate, then\nthe reactor overheated, the relief valve lifted and the contents\nof the reactor were discharged into the atmosphere.\nSome other system accidents in avionics are also due\nto uncontrolled interactions between components [6]. The\nself-destructing explosion of Ariane 5 launcher was resulted\nfrom the successive failures of the active Inertial Reference\n\n\fSystem (IRS) and the backup IRS [6]. Ariane 5 adopted the\nsame reference system as Ariane 4. However, the profile\nof Ariane 5 was different from that of Ariane 4 - the\nacceleration communicated as input value to IRS of Ariane\n5 was higher. Furthermore, the interactions between IRS and\nother components were not redefined and checked. Due to\nthe overflow of input value computation, the IRS stopped\nworking [7]. Then, the signaled error was interpreted as a\nlauncher attitude, and led the control system to rotate the\ntailpipe at the end stop [8].\nIn these accidents, the components are reliable in terms of\nsatisfying their specified requirements, but the systems are\nnot safe as a whole. Since most software related accidents\nhave been system accidents [1], people need to model and\nconstrain interactions of system components to validate the\nabsence of dysfunctional interactions. As Leveson mentioned in STAMP (Systems-Theoretic Accident Model and\nProcesses) [1], these accidents result from inadequate control\nor enforcement of safety-related constraints of the systems.\nTraditionally, in order to validate the absence of system hazards, industrials identify system safety requirements\n[9][10], and use model checking to verify if system behaviors conform to safety requirements [11].\nIn this paper, we will consider safety requirements as\ncontrol structures that restrict system behaviors at metamodel level. That is, the two models of a system and its\nsafety constraints will be developed at the same time. Then\nthe two models are \"combined\" to deduce a safe system.\nThis paper is organized as follows: the architecture of our\napproach is presented in Section 2. To illustrate the idea,\na preliminary introduction on interface automata appears\nin Section 3. The interface C-System based on controlling\nautomata is introduced in Sections 4 and 5, where examples\nare used to illustrate how to formalize safety rules and\ncombine them with a system specification. In Section 6, we\ncompare our work to classic verification techniques, such as\nmodel checking, and conclude the paper.\n\nUnlike model checking, our architecture takes another\nway. It consists of the following steps:\n(1) Modeling system behavior, including specifications of\nits components, internal and external interactions, e.g., using\ninterface automata.\n(2) Modeling system safety constraints using a certain\nformal technique, e.g., controlling automata in this paper.\n(3) Combining these two models to deduce a safe system model, that is, a system model whose behavior is in\naccordance with its safety constraints.\nAs [15] mentioned, system behavior specifies an operational semantics, which defines what a system is able to do.\nSystem behavior modeling is achieved by product engineers\n(designers), such as programmers and developers. In the\nexample of the chemical reactor control system, the actions\n\"opening the catalyst flow\", \"opening the cooling water\nflow\" and \"sounding an alarm\" are actions of the system\nbehavior.\nIn the second step, the model of safety constraints specifies a correctness semantics, which defines what a system\nis authorized to do. This process is the duty of safety engineers whose responsibility is to assure system safety. Safety\nengineers may consist of requirement engineers, testing\nengineers, managers from higher socio-technical levels who\ndefine safety standards or regulations [1], etc. In the example\nof the chemical reactor system, the constraint \"opening the\ncatalyst flow must be followed by opening the cooling water\nflow\" is an instance of system safety constraints.\nIn the third step, in order to ensure system safety, we\ncombine a system model with its safety constraints model.\nThen we ensure that the system is safe under the constraints\nspecifying safety requirements. A precondition of this approach is that we must formalize safety requirements. And\nwe also need to carefully define the composition of a system\nmodel and its constraints model. We will introduce such\nmeans based on controlling automata.\n\n2. The Architecture of our Methodology\n\nTo model component-based concurrent systems with different input, output and internal actions, the theory of interface automata [16] extends Input/Output automata [17][18],\nwhich extends classic automata theory [19].\nUnlike I/O automata, an interface automaton is not required to be input-enabled (i.e., some inputs may be recognized as illegal in some states) and only allows the\ncomposition of two automata (I/O automata allow the composition of infinite automata), and a synchronization of one\noutput and one input action results a hidden action after the\ncomposition.\nDefinition 1: An interface automaton (simply an automaton) is a tuple A = (Q, \u03a3I , \u03a3O , \u03a3H , \u03b4, S), where:\n(1) Q is a set of states.\n(2) \u03a3I , \u03a3O , \u03a3H are pairwise disjoint sets of input, output\n\nThe most popular technique of system safety verification\nis model checking [12]. Hundreds of checking patterns are\ncollected for system engineers [13] and specific uses in\nsafety engineering [11]. In this framework, we have three\nsteps in verifying a system. At first, we formalize system\nbehavior as a model (e.g., a finite-state transition system, a\nKripke model [14]). At the second step, we specify the safety\nconstraints that we aim at validating using temporal logics\n[13]. At the third step, a certain checking algorithm is used\nto search for a counterexample which is an execution trace\nviolating the specified features. If the algorithm finds such\na counterexample, we have to modify the original design to\nensure safety constraints.\n\n3. Preliminary: Interface Automata\n\n\fS\nS\nand internal actions, respectively. Let \u03a3 = \u03a3I \u03a3O \u03a3H\nbe the set of actions.\n(3) \u03b4 \u2286 Q \u00d7 \u03a3 \u00d7 Q is a set of labeled transitions.\n(4) S \u2286 Q is a set of start states, where |S| \u2264 1.\n\u0003\n\u2032\nIn the graph notation, a transition pk : (q, a, q ) \u2208 \u03b4\nis denoted by an arc from q to q \u2032 labeled pk : a, where\npk is the name of the transition. To discriminate explicitly\nthe different sets of actions in diagrams, we may suffix a\nsymbol \"?\", \"!\" or \";\" to an input, output or internal action,\nrespectively.\nThe composition of two composable automata allows\nthe automata to synchronize on shared actions, and asynchronously interleave all other actions.\nDefinition 2: Two interface automata A and B are comI\nI\nO\nO\nposable if \u03a3H\nA \u2229 \u03a3B = \u2205, \u03a3A \u2229 \u03a3B = \u2205, \u03a3A \u2229 \u03a3B = \u2205,\nH\n\u03a3B \u2229 \u03a3A = \u2205. We let shared(A, B) = \u03a3A \u2229 \u03a3B .\n\u0003\nDefinition 3: If A and B are composable interface automata, their product A \u2297 B is the interface automaton\ndefined by\n(1) QA\u2297B = QA \u00d7 QB\n(2) \u03a3IA\u2297B = (\u03a3IA \u222a \u03a3IB ) \u2212 shared(A, B)\nO\nO\n(3) \u03a3O\nA\u2297B = (\u03a3A \u222a \u03a3B ) \u2212 shared(A, B)\nH\nH\nH\n(4) \u03a3A\u2297B = \u03a3A \u222a \u03a3B \u222a shared(A, B)\n(5)\n\u03b4A\u2297B = { pi : ((v, u), a, (v \u2032 , u)) | pi : (v, a, v \u2032 ) \u2208 \u03b4A\n\u2227a 6\u2208 shared(A, B) \u2227 u \u2208 QB }\n\u222a {pj : ((v, u), a, (v, u\u2032 )) | pj : (u, a, u\u2032 ) \u2208 \u03b4B\n\u2227a 6\u2208 shared(A, B) \u2227 v \u2208 QA }\n\u222a {pij : ((v, u), a, (v \u2032 , u\u2032 )) | pi : (v, a, v \u2032 ) \u2208 \u03b4A\n\u2227pj : (u, a, u\u2032 ) \u2208 \u03b4B \u2227 a \u2208 shared(A, B)}\n(6) SA\u2297B = SA \u00d7 SB .\n\u0003\nNote that the name of the transition pij of A \u2297 B may\ncontain the names of two original transitions pi \u2208 \u03b4A and\np j \u2208 \u03b4B .\nIn the product A \u2297 B, there may be illegal states, where\none component is able to send an output a \u2208 shared(A, B)\nand the other is not able to receive a.\nThe composition of two interface automata A, B is obtained by restricting the product of the two automata to the\nset Cmp(A, B) of compatible states, which are the states\nfrom which there exists a legal environment that can prevent\nentering illegal states.\nDefinition 4: If A and B are composable interface automata, their composition A||B is the interface automaton\ndefined by\n(1) QA||B = Cmp(A, B)\n(2) \u03a3IA||B = \u03a3IA\u2297B\nO\n(3) \u03a3O\nA||B = \u03a3A\u2297B\nH\n(4) \u03a3A||B = \u03a3H\nA\u2297B\n(5) \u03b4A||B = \u03b4A\u2297B \u2229 (Cmp(A, B) \u00d7 \u03a3A||B \u00d7 Cmp(A, B))\n(6) SA||B = SA\u2297B \u2229 Cmp(A, B).\n\u0003\n\n4. Safety Constraints on a Single Component\nIn this section, we start from a simple case \u2013 modeling\nsafety constraints on a single component. In the example\nof the batch chemical reactor (C.f. Fig. 1), the computer\nsystem behavior is modeled using an interface automaton\nA of Fig. 2(1). The automaton A includes a set of input\nactions \u03a3I = {l} (low oil signal), a set of output actions\n\u03a3O = {c, w, a} (opening catalyst flow, opening water flow,\nsounding an alarm, respectively), and a set of internal actions\n\u03a3H = {e} (ending all operations).\nThe normal operational behavior includes opening the\ncatalyst flow (p1 ), then opening the water flow (p2 ), etc., resulting in an infinite execution trace p1 p2 p1 p2 .... To respond\nto abnormal signals as soon as possible, the states q0 , q1 both\nhave a transition labeled l, which leads to a state that can\nsound an alarm (p5 ) and stop the process (p6 ). Unfortunately,\nthis design leads to hazardous behaviors: (cw)\u2217 clae, that is,\nafter a sequence of opening catalyst and water flows (cw)\u2217 ,\nthen the catalyst flow is opened (c) when an abnormal signal\nis received (l), then an alarm is sounded (a). So water is not\nadded after the catalyst flow is opened. This sequence of\nevents leads to the accident mentioned in Section 1.\nNote that this hazard is due to the uncontrolled sequences\nof transitions - p1 must be followed by p2 and not by p4 .\nTo solve this problem, we need to specify the authorized\nsequences (satisfying safety constraints) on the transitions\n\u03b4 and not on the actions \u03a3. Thus, these constraints are\nnot at the behavioral model level, but at the meta-model\nlevel. We propose the concept of controlling automata to\nformalize safety constraints. Then, we combine a controlling\nautomaton with the system automaton.\nDefinition 5: A controlling automaton \u00c2 over an interface automaton A = (Q, \u03a3, \u03b4, S) is a tuple \u00c2 = (Q\u0302, \u03a3\u0302, \u03b4\u0302, \u015c),\nwhere:\n(1) Q\u0302 is a set of states disjoint with Q.\n(2) \u03a3\u0302 is a set of terminals, such that \u03a3\u0302 = \u03b4.\n(3) \u03b4\u0302 \u2286 Q\u0302 \u00d7 \u03a3\u0302 \u00d7 Q\u0302 is a set of labeled transitions.\n(4) \u015c \u2286 Q\u0302 is a nonempty set of start states.\n\u0003\nNote that the transitions \u03b4 of A are terminals of \u00c2, so we\nsay that \u00c2 is at the meta level of A. Figure 3 illustrates the 3\nlevels in our framework. Let \u03a3\u2217 be a set of execution traces\nof actions, A describes the behavior on \u03a3. \u00c2 specifies the\nbehavior on the A-transitions (\u03a3\u0302 = \u03b4), that is, a behavior\non the behavior of A. This meta-behavior expresses safety\nrequirements.\nIn the example, to prevent accidents, we need to impose\nthe safety constraint \"opening catalyst must be followed by\nopening water,\" that is, \"whenever the transition p1 : c\noccurs, the transition p2 : w must occur after that\". This\nconstraint can be formalized as a controlling automaton \u00c2\nof Fig. 2(2). When we express this constraint, we only\nspecify the sequence of transitions p1 , p2 at the meta-model\nlevel, and we concern little about the implementation of\n\n\fq1\n\n{pi }2\u2264i\u22646\n\np4 : l?\n\np1\np2 : w!\n\np1 : c!\n\nq2\n\nq3\np5 : a!\n\nq0\n\nq4\n\nq\u03020\n\np2\n\np6 : e;\n\nq\u03021\n\np3 : l?\n(2)\u00c2\n\n(1)A\nFigure 2. Automata of the Reactor Control System\nC\n\u00c2\n\nLevel L3\n(safety requirements)\n\n\u03b4\nA\n\np2 : w!\nLevel L2\n(functional requirements)\n\n\u03a3\n\u03a3\u2217\n\nq11\n\nLevel L1\n(execution traces)\n\nFigure 3. A 3-levels Overview\n\nthe system at the model level. The next step is to compose\nthe system automaton A with its controlling automaton \u00c2,\nand automatically generate a system C satisfying the safety\nrequirement.\nDefinition 6: The meta-composition C of an interface\nautomaton A = (Q, \u03a3, \u03b4, S) and a controlling automaton\n\u00c2 = (Q\u0302, \u03a3\u0302, \u03b4\u0302, \u015c) over A is a tuple:\n\u2192\nC = A\u2212\n* \u00c2 = (Q \u00d7 Q\u0302, \u03a3, \u03b4 \u2032 , S \u00d7 \u015c)\n(1)\nwhere pk : ((qi , q\u0302j ), a, (qm , q\u0302n )) \u2208 \u03b4 \u2032 iff,\n(1) pk : (qi , a, qm ) \u2208 \u03b4, and\n(2) (q\u0302j , pk , q\u0302n ) \u2208 \u03b4\u0302.\nWe say that A and \u00c2 constitute an interface control\nsystem (or simply interface C-System).\n\u0003\n\u2192\nThe symbol \u2212\n* is called meta-composition operator, and\nread \"meta-compose\". Its left and right operands are an\nautomaton and a controlling automaton, respectively. Notice that an interface C-System is equivalent to the metacomposition C of an interface automaton and a controlling\nautomaton.\nNotice that \u03b4 = {pk }k\u2208K plays a key role in associating\ntransitions of A and terminals of \u00c2. For our example, we\ncombine the automata A and \u00c2 of Fig. 2, thus we get the\n\u2192\nautomaton C = A\u2212\n* \u00c2 of Fig. 4 where qij denotes (qi , q\u0302j ).\nThe meta-composition contains exactly all the paths satisfying the safety constraint. Formally, we have the following\ntheorem (the proof is omitted for its simpleness and intuitiveness from the definition):\nTheorem 7: Given A, \u00c2 and the meta-composition C,\nan execution trace t\u03a3 \u2208 \u03a3\u2217 is recognized by C iff, t\u03a3\n\np1 : c!\n\nq20\n\nq30\np5 : a!\n\nq00\n\nq40\np6 : e;\n\np3 : l?\n\nFigure 4. The Meta-Composition C\nis recognized by A, and its transition trace t\u03b4 \u2208 \u03b4 \u2217 is\nrecognized by \u00c2.\n\u0003\nObviously, the set of traces of C is a subset of the traces\nof A. Formally, let L(A) be the set of traces of A (i.e. the\nlanguage of A), we have L(C) \u2286 L(A).\nThanks to \u00c2, the hazardous execution traces, for example\ncwclae, which exists in A, will be eliminated, because its\ntransition trace p1 p2 p1 p4 p5 p6 6\u2208 L(\u00c2) (the language of \u00c2).\nThe comparison between A of Fig. 2(1) and C of Fig. 4\nhighlights the hazardous transition p4 of A. However, in\ngeneral, this diagnosis is much more complex and cannot\nbe achieved manually, since a real system A has too many\nstates to be expressed clearly on a paper. That is why we\ndeveloped a formal and automated method for eliminating\nhazardous transitions.\n\n5. Safety Constraints on Multi-Components\nTo illustrate this case, we use an example concerning\na system composed of two components with interactions:\na candy vending machine and a customer. We hope that,\nsince this class of examples is so popular in the literatures\nof formal methods (e.g., Hoare's Communicating Sequential\nProcesses (CSP) and I/O automata [17]), they will provide an\ninteresting illustration of our idea. The candy machine Am ,\nspecified in Fig. 5(1), may receive inputs b1 , b2 indicating\nthat buttons 1 and 2 are pushed, respectively. It may output\ns, a, indicating candy dispensation actions, SKYBARs and\nALMONDJOYs, respectively. The machine may receive\nseveral inputs before delivering a candy. A greedy user Au ,\nspecified in Fig. 5(2), can push buttons b1 , b2 or get a candy\ns, a. The greedy user does not wait for a candy bar before\n\n\fpressing a button again.\nThe composition of the machine behavior and the user\nbehavior is defined by Amu = Am ||Au of Fig. 5(3), where\nqij denotes the composite state (mi , uj ), pi,j denotes two\nsynchronized transitions {pi , pj }. A transition of the composition may be composed of two transitions of components.\nFor example, p1,13 : s is a synchronization of p1 : s!\nand p13 : s?, which belong to Am and Au , respectively.\nGenerally, a transition of A = P ||Q may be composed\nof one or two transitions of its components, where two\ntransitions constitute a synchronization.\nIn the context of meta-composition, a composite transition\nis allowed if and only if both of its sub-transitions are\nallowed by its controlling automaton. Thus, we define the\nmeta-composition operator as follows:\nDefinition 8: The meta-composition (or interface CSystem) C of a composition A = P ||Q and a controlling\nautomaton \u00c2 = (Q\u0302, \u03a3\u0302, \u03b4\u0302, \u015c) over A is a tuple:\n\u2192\nC = A\u2212\n* \u00c2 = (Q \u00d7 Q\u0302, \u03a3 , \u03b4 \u2032 , S \u00d7 \u015c)\n(2)\nA\n\n\u2032\n\nA\n\n\u2032\n\n\u2032\n\nA\n\n\u2032\n\nwhere pI : ((v, u, q), a, (v , u , q )) \u2208 \u03b4 (pI contains a set\nof transitions {pk }k\u2208I ) iff,\n(1) pI : (((v, u), a, (v \u2032 , u\u2032 )) \u2208 \u03b4A , and\n(2) \u2200k : k \u2208 I \u2022 (q, pk , q \u2032 ) \u2208 \u03b4\u0302.\n\u0003\nNotice that the specification of the example allows a\nhazardous situation: the greedy user repeatedly pushes the\nbuttons without giving the machine a chance to dispense a\ncandy bar (e.g., the transition labeled p5,11 : b1 of q11 does\nnot allow the transition (q11 , s, q00 ) to be fired). To prevent\nthis situation, the following constraints forbid successive\noccurrences of pressing buttons: \"the transitions p11 , p12 are\nnot allowed, when interactions occur between the machine\nand the user\". Differing from the previous example, this\ntype of constraints needs to synchronize the actions of the\nmachine and of the user.\nFormalizing the constraints, the semantics of the controlling automaton Ac of Fig. 6(1) is: whenever the user pushes\na button (p9 , p10 ), she or he cannot push it again (p11 , p12 ),\nbut can only wait for a candy bar.\nCombining the whole system Amu with its constraint\n\u2192\nAc , we get the system C = (Am ||Au )\u2212\n* Ac in Fig. 6(2),\nwhere qijk denotes the composite state (mi , uj , ck ). All of\nits execution traces satisfy the constraint, and thus prevent\nthe hazardous situation.\nSince we formally defined the meta-composition operator,\nit can be easily implemented to be an automated tool. Thus,\nit can be applied to more complex systems.\n\n6. Conclusion\nWe proposed formalizing system safety requirements using controlling automata. As we illustrated using examples,\nthis approach can formally model safe interactions between\ncomponents or systems. This framework differs from the\n\none of model checking. It explicitly separates the tasks\nof product engineers and safety engineers, and provides a\ntechnique for modeling a system with safety constraints, and\nfor automatically composing a safe system that conforms to\nsafety requirements.\nThe essential ideas of our approach are the separation\nand formalization of the system specification A (core functional requirements) and the safety constraints \u00c2 (safety\nrequirements). The automaton A handles inputs to produce\noutputs using activities depending on the states, whereas the\ncontrolling automaton \u00c2 treats activities to produce the set\nof acceptable activities depending on safety requirements.\nOur framework has different objectives and uses different\napproaches to those of model checking. Model checking\ntechniques use a bottom-up approach - it verifies execution\ntraces \u03a3\u2217 at the lower level L1 to prove the correctness and\nsafety of the system model A at the middle level L2 (see\nFig. 3). However, our proposal uses a top-down approach\n- we model safety requirements as acceptable sequences of\ntransitions (\u03b4 \u2217 ) at the higher level L3 to ensure the correct\nuse of A. Then any execution trace (at L1 ) that conforms to\nthe meta-composition C is definitely a safe execution. The\ntwo techniques are complementary. Model checking may be\nused to reduce the design fault likelihood, and our approach\ncan be applied to avoid behavior that are not in accordance\nwith some critical safety requirements.\nThis paper continues our work on C-Systems (formal\nlanguage control systems). In [20], we actually proposed the\ninput/output C-System. The context-free C-System was proposed in [21] for restricting the use of modeling languages,\nin order to ensure guidelines and consistency rules of UML.\nIn the future, it might be a good direction to study the\nformalization of parameterized safety constraints. Another\ndirection is empirical case study on applying this formalism\nin large and complex systems.\n\nReferences\n[1] N. Leveson, \"A new accident model for engineering safer\nsystems,\" Safety Science, vol. 42, no. 4, pp. 237\u2013270, 2004.\n[2] N. Leveson, \"Applying systems thinking to analyze and\nlearn from events,\" in Workshop NeTWorK 2008: Event\nAnalysis and Learning From Events, 2008, available from\nhttp://sunnyday.mit.edu/papers/network-08.doc.\n[3] C. Perrow, Normal Accidents: Living with High-Risk Technologies. Princetown University Press, USA, 1999.\n[4] N. Leveson, Safeware: System Safety and Computers.\nAddison-Wesley, Reading, MA, 1995.\n[5] T. Kletz, \"Human problems with computer control,\"\nPlant/Operations Progress, vol. 1, no. 4, 1982.\n\n\fp5,11 : b1 ;\n\np5 : b 1 ?\nm1\n\np1 : s!\n\np8 : b 2 ?\n\nm0 p 3 : b 1 ?\np4 : b 2 ?\np7 : b 1 ?\np2 : a!\n\nm2\n\nq11\n\np1,13 : s;\n\np11 : b1 !\np12 : b2 !\np13 : s?\np14 : a?\nu0\nu1\np9 : b 1 !\np10 : b2 !\n\nb2 ;\nb1 ;\n\nq00\n\nb2 ;\na;\n\nb1 ;\nq21\np6,12 : b2 ;\n\np6 : b 2 ?\n(1)Am\n\n(2)Au\n\n(3)Amu\n\nFigure 5. Automata of the Candy Machine System\n\nc0\n\nq110\n\ns;\n\n\u03b4m \u222a \u03b4n \u2212 {p11 , p12 }\n\nb1 ;\n\nq000\n\nb2 ;\na;\n(1)Ac\n\nq210\n\n(2)C\n\nFigure 6. A Safety Constraint of the Candy Machine System\n\n[6] N. Leveson, \"Evaluating accident models using recent\naerospace accidents,\" Technical Report, MIT Dept.\nof Aeronautics and Astronautics, 2001, available from\nhttp://sunnyday.mit.edu/accidents.\n[7] T. Kohda and Y. Takagi, \"Accident cause analysis of complex\nsystems based on safety control functions,\" in Proceedings\nof Annual Reliability and Maintainability Symposium (RAMS\n'06). ACM, 2006, pp. 570\u2013576.\n[8] J.-C. Geffroy and G. Motet, Design of Dependable Computing\nSystems. Kluwer Academic Publishers, 2002.\n[9] K. Allenby and T. Kelly, \"Deriving safety requirements using\nscenarios,\" in Proceedings of the 5th IEEE International\nSymposium on Requirements Engineering (RE 2001). IEEE\nComputer Society, 2001, pp. 228\u2013235.\n[10] D. Firesmith, \"Engineering safety requirements, safety constraints, and safety-critical requirements,\" Journal of Object\nTechnology, vol. 3, no. 3, pp. 27\u201342, 2004.\n[11] F. Bitsch, \"Safety patterns - the key to formal specification of\nsafety requirements,\" in Proceedings of the 20th International\nConference on Computer Safety, Reliability and Security\n(SAFECOMP 2001), ser. Lecture Notes in Computer Science,\nU. Voges, Ed., vol. 2187. Springer, 2001, pp. 176\u2013189.\n[12] E. M. Clarke, O. Grumberg, and D. A. Peled, Model Checking. The MIT Press, 2000.\n[13] M. B. Dwyer, G. S. Avrunin, and J. C. Corbett, \"Patterns\nin property specifications for finite-state verification,\" in Proceedings of the 1999 International Conference on Software\nEngineering (ICSE'99), 1999, pp. 411\u2013420.\n\n[14] M. Huth and M. Ryan, Logic in Computer Science: Modelling\nand Reasoning about Systems, Second Edition. Cambridge\nUniversity Press, 2004.\n[15] G. Motet, \"Risks of faults intrinsic to software languages: Trade-off between design performance and application safety,\" Safety Science, 2009.\n[16] L. de Alfaro and T. A. Henzinger, \"Interface automata,\"\nin Proceedings of the 8th European Software Engineering\nConference and 9th ACM SIGSOFT International Symposium\non Foundations of Software Engineering (ESEC/FSE 2001),\n2001, pp. 109\u2013120.\n[17] N. A. Lynch and M. R. Tuttle, \"An introduction to input/output automata,\" CWI Quarterly, vol. 2, no. 3, pp.\n219\u2013246, 1989, also available as MIT Technical Memo\nMIT/LCS/TM-373.\n[18] N. A. Lynch, Distributed Algorithms.\nPublishers, San Mateo, CA, 1996.\n\nMorgan Kaufmann\n\n[19] J. E. Hopcroft and J. D. Ullman, Introduction to Automata\nTheory, Languages, and Computation.\nAddison-Wesley,\n1979.\n[20] Z. Chen and G. Motet, \"Modeling system safety requirements\nusing input/output constraint meta-automata,\" in Proceedings\nof the 4th International Conference on Systems (ICONS'09).\nIEEE Computer Society, 2009, pp. 228\u2013233.\n[21] Z. Chen and G. Motet, \"A language-theoretic view on guidelines and consistency rules of UML,\" in Proceedings of the\nFifth European Conference on Model Driven Architecture Foundations and Applications (ECMDA-FA 2009), ser. Lecture Notes in Computer Science. Springer, 2009.\n\n\f"}