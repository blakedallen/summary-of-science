{"id": "http://arxiv.org/abs/1111.0574v2", "guidislink": true, "updated": "2012-04-06T16:42:56Z", "updated_parsed": [2012, 4, 6, 16, 42, 56, 4, 97, 0], "published": "2011-11-02T17:32:23Z", "published_parsed": [2011, 11, 2, 17, 32, 23, 2, 306, 0], "title": "Particle algorithms for optimization on binary spaces", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1111.3329%2C1111.2159%2C1111.2526%2C1111.1629%2C1111.0277%2C1111.3793%2C1111.4626%2C1111.6084%2C1111.5428%2C1111.1598%2C1111.4357%2C1111.1452%2C1111.5588%2C1111.5775%2C1111.5341%2C1111.0237%2C1111.1231%2C1111.0968%2C1111.7162%2C1111.6463%2C1111.6255%2C1111.4745%2C1111.2091%2C1111.0047%2C1111.4582%2C1111.5388%2C1111.3508%2C1111.4785%2C1111.6129%2C1111.3448%2C1111.5735%2C1111.5825%2C1111.2211%2C1111.3472%2C1111.5040%2C1111.6436%2C1111.2486%2C1111.1686%2C1111.0179%2C1111.3957%2C1111.0474%2C1111.6492%2C1111.2169%2C1111.1556%2C1111.2953%2C1111.0814%2C1111.6126%2C1111.5022%2C1111.4665%2C1111.1883%2C1111.4927%2C1111.5945%2C1111.4001%2C1111.5076%2C1111.6259%2C1111.0735%2C1111.5645%2C1111.2581%2C1111.3337%2C1111.7146%2C1111.4758%2C1111.6561%2C1111.6881%2C1111.2447%2C1111.3897%2C1111.1306%2C1111.6652%2C1111.3061%2C1111.7214%2C1111.1820%2C1111.0541%2C1111.4478%2C1111.3557%2C1111.3278%2C1111.0574%2C1111.2657%2C1111.3736%2C1111.0009%2C1111.6038%2C1111.3703%2C1111.3997%2C1111.1756%2C1111.2502%2C1111.4610%2C1111.0744%2C1111.4876%2C1111.3589%2C1111.6318%2C1111.4976%2C1111.5054%2C1111.0293%2C1111.3574%2C1111.4769%2C1111.5105%2C1111.4019%2C1111.3087%2C1111.1645%2C1111.4471%2C1111.3398%2C1111.1352%2C1111.2453&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "Particle algorithms for optimization on binary spaces"}, "summary": "We discuss a unified approach to stochastic optimization of pseudo-Boolean\nobjective functions based on particle methods, including the cross-entropy\nmethod and simulated annealing as special cases. We point out the need for\nauxiliary sampling distributions, that is parametric families on binary spaces,\nwhich are able to reproduce complex dependency structures, and illustrate their\nusefulness in our numerical experiments. We provide numerical evidence that\nparticle-driven optimization algorithms based on parametric families yield\nsuperior results on strongly multi-modal optimization problems while local\nsearch heuristics outperform them on easier problems.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=&id_list=1111.3329%2C1111.2159%2C1111.2526%2C1111.1629%2C1111.0277%2C1111.3793%2C1111.4626%2C1111.6084%2C1111.5428%2C1111.1598%2C1111.4357%2C1111.1452%2C1111.5588%2C1111.5775%2C1111.5341%2C1111.0237%2C1111.1231%2C1111.0968%2C1111.7162%2C1111.6463%2C1111.6255%2C1111.4745%2C1111.2091%2C1111.0047%2C1111.4582%2C1111.5388%2C1111.3508%2C1111.4785%2C1111.6129%2C1111.3448%2C1111.5735%2C1111.5825%2C1111.2211%2C1111.3472%2C1111.5040%2C1111.6436%2C1111.2486%2C1111.1686%2C1111.0179%2C1111.3957%2C1111.0474%2C1111.6492%2C1111.2169%2C1111.1556%2C1111.2953%2C1111.0814%2C1111.6126%2C1111.5022%2C1111.4665%2C1111.1883%2C1111.4927%2C1111.5945%2C1111.4001%2C1111.5076%2C1111.6259%2C1111.0735%2C1111.5645%2C1111.2581%2C1111.3337%2C1111.7146%2C1111.4758%2C1111.6561%2C1111.6881%2C1111.2447%2C1111.3897%2C1111.1306%2C1111.6652%2C1111.3061%2C1111.7214%2C1111.1820%2C1111.0541%2C1111.4478%2C1111.3557%2C1111.3278%2C1111.0574%2C1111.2657%2C1111.3736%2C1111.0009%2C1111.6038%2C1111.3703%2C1111.3997%2C1111.1756%2C1111.2502%2C1111.4610%2C1111.0744%2C1111.4876%2C1111.3589%2C1111.6318%2C1111.4976%2C1111.5054%2C1111.0293%2C1111.3574%2C1111.4769%2C1111.5105%2C1111.4019%2C1111.3087%2C1111.1645%2C1111.4471%2C1111.3398%2C1111.1352%2C1111.2453&start=0&max_results=1000&sortBy=relevance&sortOrder=descending", "value": "We discuss a unified approach to stochastic optimization of pseudo-Boolean\nobjective functions based on particle methods, including the cross-entropy\nmethod and simulated annealing as special cases. We point out the need for\nauxiliary sampling distributions, that is parametric families on binary spaces,\nwhich are able to reproduce complex dependency structures, and illustrate their\nusefulness in our numerical experiments. We provide numerical evidence that\nparticle-driven optimization algorithms based on parametric families yield\nsuperior results on strongly multi-modal optimization problems while local\nsearch heuristics outperform them on easier problems."}, "authors": ["Christian Sch\u00e4fer"], "author_detail": {"name": "Christian Sch\u00e4fer"}, "author": "Christian Sch\u00e4fer", "links": [{"href": "http://arxiv.org/abs/1111.0574v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1111.0574v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "stat.CO", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "stat.CO", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "math.OC", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1111.0574v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1111.0574v2", "arxiv_comment": null, "journal_reference": null, "doi": null, "fulltext": "Particle algorithms for optimization on\nbinary spaces\nChristian Sch\u00e4fer1,2\n\narXiv:1111.0574v2 [stat.CO] 6 Apr 2012\n\nOctober 22, 2018\n\nWe discuss a unified approach to stochastic optimization of pseudo-Boolean\nobjective functions based on particle methods, including the cross-entropy\nmethod and simulated annealing as special cases. We point out the need for\nauxiliary sampling distributions, that is parametric families on binary spaces,\nwhich are able to reproduce complex dependency structures, and illustrate\ntheir usefulness in our numerical experiments. We provide numerical evidence\nthat particle-driven optimization algorithms based on parametric families\nyield superior results on strongly multi-modal optimization problems while\nlocal search heuristics outperform them on easier problems.\nKeywords Binary parametric families * Unconstrained binary optimization * Sequential\nMonte Carlo * Cross-Entropy method * Simulated Annealing\n\n1 Particle optimization\n1.1 Introduction\n1.1.1 Pseudo-Boolean optimization\nWe call f : Bd := {0, 1}d \u2192 R a pseudo-Boolean function. The present work discusses\napproaches to obtain heuristics for the program\nmaximize\nsubject to\n\nf (x)\nx \u2208 Bd\n\n(1)\n\nusing sequential Monte Carlo techniques. In the sequel, we refer to f as the objective\nfunction. For an excellent overview of applications of binary programming and equivalent\nproblems we refer to the survey paper by Boros and Hammer (2002) and references\ntherein.\nThe idea to use particle filters for global optimization is not new [(Del Moral et al.,\n2006), Section 2.3.1.c], but novel sequential Monte Carlo methodology making use of\nsuitable parametric families on binary spaces Sch\u00e4fer and Chopin (2011) may allow to\nconstruct more efficient samplers for the special case of pseudo-Boolean optimization.\n1\n2\n\nCentre de Recherche en \u00c9conomie et Statistique, 3 Avenue Pierre Larousse, 92240 Malakoff, France\nCEntre de REcherches en MAth\u00e9matiques de la DEcision, Universit\u00e9 Paris-Dauphine, Place du Mar\u00e9chal de Lattre de Tassigny 75775 Paris, France\n\n\fWe particularly discuss how this methodology connects with the cross-entropy method\nRubinstein (1997) which is another particle driven optimization algorithm based on\nparametric families.\nThe sequential Monte Carlo algorithm as developed by Sch\u00e4fer and Chopin (2011) is\nrather complex compared to local search algorithms such as simulated annealing Kirkpatrick et al. (1983) or k-opt local search Merz and Freisleben (2002) which can be\nimplemented in a few lines. The aim of this paper is to motivate the use of advanced\nparticle methods and sophisticated parametric families in the context of pseudo-Boolean\noptimization and to provide conclusive numerical evidence that these complicated algorithms can indeed outperform simple heuristics if the objective function has poorly\nconnected strong local maxima. This is not at all clear, since, in terms of computational\ntime, multiple randomized restarts of fast local search heuristics might very well be more\nefficient than comparatively complex particle approaches.\n1.1.2 Outline\nThe article is structured as follows. We first introduce some notation and review how\nto model an optimization problem (1) as a filtering problem on an auxiliary sequence\nof probability distributions. Section 2 describes a sequential Monte Carlo sampler Del\nMoral et al. (2006) designed for global optimization on binary spaces Sch\u00e4fer and Chopin\n(2011). Section 3 reviews three parametric families for sampling multivariate binary\ndata which can be incorporated in the proposed class of particle algorithms. Section\n4 discusses how the cross-entropy method Rubinstein (1997) and simulated annealing\nKirkpatrick et al. (1983) can be interpreted as special cases of the sequential Monte Carlo\nsampler. In Section 5 we carry out numerical experiments on instances of the unconstrained quadratic binary optimization problem. First, we investigate the performance\nof the proposed parametric families in particle-driven optimization algorithms. Secondly,\nwe compare variants of the sequential Monte Carlo algorithm, the cross-entropy method,\nsimulated annealing and simple multiple-restart local search to analyze their respective\nefficiency in the presence or absence of strong local maxima.\n1.1.3 Notation\nWe briefly introduce some notation that might be non-standard. We denote scalars in\nitalic type, vectors in italic bold type and matrices in straight bold type. Given a set\nM , we write |M | for the number of its elements and 1M for its indicator function. For\na, b \u2208 Z we denote by [[a, b]] = {a, . . . , b} the discrete interval from a to b. Given a vector\nx \u2208 Bd and an index set I \u2286 [[1, d]], we write xI \u2208 B|I| for the sub-vector indexed by I\nand x\u2212I \u2208 P\nBd\u2212|I| for its complement. We occasionally use the norms kxk\u221e := maxi xi\nand |x| := di=1 |xi |.\n\n1.2 Statistical modeling\n1.2.1 Associated probability measures\nFor particle optimization, the common approach is defining a family of probability measures {\u03c0% : % \u2265 0} associated to the optimization problem maxx\u2208Bd f (x) in the sense\n\n2\n\n\fthat\n\u03c00 = UBd ,\n\nlim \u03c0% = UMf ,\n\n%\u2192\u221e\n\nwhere US denotes the uniform distribution on the set S and Mf = argmaxx\u2208Bd f (x)\nthe set of maximizers. The idea behind this approach is to first sample from a simple\ndistribution, potentially learn about the characteristics of the associated family and\nsmoothly move towards distributions with more mass concentrated in the maxima. We\nreview two well-known techniques to explicitly construct such a family \u03c0% .\nTempered family We call {\u03c0% : % \u2265 0} a tempered family, if it has probability mass\nfunctions of the form\n\u03c0% (\u03b3) := \u03bd% exp(% f (\u03b3)),\n(2)\nP\n\u22121\nwhere \u03bd% := \u03b3\u2208Bd exp(% f (\u03b3)).\nAs % increases, the modes of \u03c0% become more accentuated until, in the limit, all mass\nis concentrated on the set of maximizers. The name reflects the physical interpretation\nof \u03c0% (x) as the probability of a configuration x \u2208 Bd for an inverse temperature % and\nenergy function \u2212f . This is the sequence used in simulated annealing Kirkpatrick et al.\n(1983).\nLevel set family We call {\u03c0% : % \u2265 0} a level set family, if it has probability mass\nfunctions of the form\n\u22121\n\u03c0% (\u03b3) := |L+\n(\u03b3),\n(3)\n% | 1L+\n%\nd\n\u2217\n\u2217\nwhere L+\n% := {\u03b3 \u2208 B : %[f (x ) \u2212 f (\u03b3)] \u2264 1} for x \u2208 Mf .\n\u2217\nIndeed, L+\n% is the super-level set of f with respect to the level c = f (x ) \u2212 1/%, for % > 0,\nand \u03c0% (\u03b3) is the uniform distribution on L+\n% . As % increases, the support of \u03c0% becomes\nrestricted to the points that have an objective value sufficiently close to the maximum\nof the f . In the limit, the support is reduced to the set of global maximizers.\n\nFigure 1: Associated sequences \u03c0%t for a toy example f : B3 \u2192 [\u221220, 20]. The colors\nindicate the advance of the sequences from yellow to red. For simplicity, we\nchoose %t = t for t \u2208 [[0, 16]].\n20\n\n1.0\n\n1.0\n\n0.8\n\n0.8\n\n0.6\n\n0.6\n\n0.4\n\n0.4\n\n0.2\n\n0.2\n\n0.0\n\n0.0\n\n10\n\n0\n\n\u221210\n\n\u221220\n\n(a) objective function f (x)\n\n(b) tempered sequence (2)\n\n(c) level set sequence (3)\n\nThe particle-driven optimization algorithms are computationally more involved than\nlocal search heuristics since we need to construct a sequence of distributions instead\n\n3\n\n\fof a sequence of states. We shall see that this effort pays off in strongly multi-modal\nscenarios, where even sophisticated local search heuristics can get trapped in a subset\nof the state space.\n1.2.2 Rare event simulation\nWhile the tempered sequence is based on a physical intuition, the level set sequence\nhas an immediate interpretation as a sequence of rare events since, as % increases, the\nsuper-level set becomes a 'rare event' with respect to the uniform measure. Rare event\nsimulation and global optimization are therefore closely related concepts and methods\nfor rare event estimation can often be adapted to serve as optimization algorithms.\nParticle algorithms for rare event simulation include the cross-entropy method Rubinstein (1997) and the sequential Monte Carlo sampler Johansen et al. (2006). The former\nuses the level set sequence, the latter uses a logistic potential family\n\u03c0% (\u03b3) := \u03bd% `(%[f (\u03b3) \u2212 f (x\u2217 )]),\nP\n\u2217\n\u22121\nwhere \u03bd%\u22121 :=\n\u03b3\u2208Bd `(%[f (\u03b3) \u2212 f (x )]) and ` : R \u2192 (0, 1), `(x) = [1 + exp(\u2212x)]\ndenotes the logistic function. Johansen et al. (2006) did not specifically design their\nalgorithm for optimization but their approach to static rare event simulation is closely\nrelated to the particle optimization framework.\n\n2 Sequential Monte Carlo\nWe discuss a static sequential Monte Carlo sampler that uses a transition kernel with\nindependent proposals in the move step based on suitable parametric families. This\nmethodology has been demonstrated to reliably estimate the mean of the posterior distribution in Bayesian variable selection problems for linear normal models Sch\u00e4fer and\nChopin (2011). In this section, we provide a self-contained description of this framework.\nFor a more general overview of sequential Monte Carlo methods we refer to Del Moral\net al. (2006).\n\n2.1 Sequential Importance Sampling\nFor convenience of notation, we index the sequence of distributions (\u03c0%t )t directly by t\nrather that by the parameter of the family %t . We refer to X = (x1 , . . . , xn )| \u2208 Bn\u00d7d and\nw \u2208 [0, 1]n with |w| = 1 as a particle system with n particles. We say the particle\nP system\n(w, X) targets the probability distribution \u03c0 if the empirical distribution nk=1 wk \u03b4xk\nconverges to \u03c0 for n \u2192 \u221e.\n2.1.1 Importance weights\nWe sample (w0 , X0 ) with x1,0 , . . . , xn,0 \u223c UBd = \u03c00 and set w0 = 1/n to initialize the\nsystem. Suppose we are given a particle approximation (wt , Xt ) of \u03c0t and want to target\nthe subsequent distribution \u03c0t+1 . For all k \u2208 [[1, n]] and \u03b1 > 0, we update the weights to\nuk,t,\u03b1\n\u03c0\u0303% +\u03b1 (xk,t )\nwk,t,\u03b1 := Pn\n, where uk,t,\u03b1 := wk,t t\n,\n\u03c0\u0303%t (xk,t )\ni=1 ui,t,\u03b1\n\n(4)\n\nand \u03c0\u0303% \u221d \u03c0% denotes the unnormalized version of \u03c0% . The normalizing constants \u03bd% and\n|L+\n% | defined in equations (2) and (3) are unknown but the algorithm only requires ratios\n\n4\n\n\fof unnormalized probability mass functions. We refer to \u03b1 as the step length at time t.\nAfter updating, the particle system targets the distribution\nP\n(5)\n\u03c0%t +\u03b1 \u2248 nk=1 wk,t,\u03b1 \u03b4xt,k .\nAs we choose \u03b1 larger, that is \u03c0%t +\u03b1 further from \u03c0%t , the weights become more uneven and the accuracy of the importance approximation deteriorates. If we repeat the\nweighting step, we just increase \u03b1 and finally obtain an importance sampling estimate\nof \u03c0\u221e = UMf with instrumental distribution \u03c00 = UBd . This yields a poor estimator\nsince the probability to hit the set Mf with n uniform draws is 1 \u2212 (1 \u2212 2\u2212d |Mf |)n and\ndecreases rapidly as the dimension d grows. The pivotal idea behind sequential Monte\nCarlo is to alternate moderate updates of the importance weights and improvements of\nthe particle system via resampling and Markov transitions.\nEffective sample size The importance weight degeneracy is often measured through\nthe effective sample size criterion Kong et al. (1994) defined as\n\u0003\u22121\n\u0002 P\n\u03b7n (w) := n nk=1 wk2\n\u2208 [1/n, 1].\nThe effective sample size is 1 if the weights are uniform, that is equal to 1/n; the effective\nsample size is 1/n if all mass is concentrated in a single particle.\n2.1.2 Finding the step length\nGiven any increasing sequence (\u03c0%t )t , we could repeatedly reweight and monitor whether\nthe effective sample size falls below a critical threshold. For the special case of annealing\nvia sequential Monte Carlo, however, the effective sample size after weighting \u03b7n (wt,\u03b1 )\nis merely a function of \u03b1. For a particle system (Xt , wt ) at time t, we pick a step length\n\u03b1 such that\n\u03b7n (wt ) \u03b2 = \u03b7n (wt,\u03b1 ),\n(6)\nthat is we lower the effective sample with respect to the current particle approximation\nby some fixed ratio \u03b2 \u2208 (0, 1) [(Jasra et al., 2011), (Del Moral et al., 2011)]. This\nensures a 'smooth' transition between two auxiliary distributions, in the sense that\nconsecutive distributions are close enough to approximate each other reasonably well\nusing importance weights; in our numerical experiments, we took \u03b2 = 9/10. We obtain\nthe associated sequence (%t )t by setting %t+1 = %t +\u03b1t where \u03b1t is a unique solution of (6).\nSince \u03b7n (wt,\u03b1 ) is continuous and monotonously decreasing in \u03b1 we can use bi-sectional\nsearch to solve (6).\n\n2.2 Conditioning the particle system\nIn this section, we discuss how to condition the weighted system and improve its quality\nbefore we proceed with the next weighting step.\n2.2.1 Resampling\nWe replace the system (wt+1 , Xt ) targeting \u03c0t+1 by a selection of particles x\u03021 , . . . , x\u0302n\ndrawn from the current particle reservoir x1,t , . . . , xn,t such that\nE (n(xk )) = n wk ,\n\n5\n\n\fwhere n(x) denotes the number of particles identical with x. Thus, in the resampled\nsystem particles with small weights have vanished while particles with large weights\nhave been multiplied. For the implementation of the resampling step, there exist several recipes. We could apply a multinomial resampling Gordon et al. (1993) which is\nstraightforward. There are, however, more efficient ways like residual Liu and Chen\n(1998), stratified Kitagawa (1996) and systematic resampling Carpenter et al. (1999).\nWe use the latest in our simulations, see Procedure 1.\nProcedure 1: Resampling (systematic)\n[ht] Input: w = (w1 , . . . , wn ), X = (x1 , . . . , xn )|\nv \u2190 n w, i \u2190 1, c \u2190 v1\nsample u \u223c U[0,1]\nfor k \u2208 [[1, n]] do\nwhile c < u do i \u2190 i + 1, c \u2190 c + vi\nx\u0302k \u2190 xi , u \u2190 u + 1\nend\nb = (x\u03021 . . . , x\u0302n )|\nreturn X\n\n2.2.2 Moving the system\nIf we repeated the weighting and resampling steps several times, we would rapidly reduce\nthe number of different particles to a very few. The key to fighting the depletion of\nthe particle reservoir is moving the particles according to a Markov transition kernel\n(0)\n\u03bat+1 with invariant measure \u03c0t+1 . The particle x\u0302k,t+1 is by construction approximately\ndistributed according to \u03c0t+1 , and a draw\n(1)\n\n(0)\n\nx\u0302k,t+1 \u223c \u03bat+1 (\u2022 | x\u0302k,t+1 )\nis therefore again approximately distributed according to \u03c0t+1 . The last sample of the\n(0)\n(s)\ngenerated Markov chain (x\u0302k,t+1 , . . . , x\u0302k,t+1 ) is, for sufficiently many move steps s \u2208 N,\nalmost exactly distributed according to the invariant measure \u03c0t+1 and independent of\nits starting point.\n2.2.3 Stopping rule\nWhile we could always apply a fixed number of move steps, we rather use an adaptive\nstopping criterion based on the number of distinct particles.\nParticle diversity We define the particle diversity as\n\u03b6n (X) := n\u22121 |{xk : k \u2208 [[1, n]]}| \u2208 [1/n, 1].\nIdeally, the sample diversity \u03b6n (X) should correspond to the expected diversity\nP\n\u03b6n (\u03c0) := 1 \u2227 n\u22121 \u03b3\u2208Bd 1{x\u2208Bd : cn \u03c0(x)\u22651} (\u03b3),\nP\nwhere cn is the smallest value that solves\n\u03b3\u2208Bd bcn \u03c0(\u03b3)c \u2265 n. This is the particle\ndiversity we would expect if we had an independent sample from \u03c0(x). Therefore, if\n\u03bat+1 is fast-mixing, we want to move the system until\nb (s) ) \u2248 \u03b6n (\u03c0t+1 ).\n\u03b6n (X\nt+1\n\n6\n\n\fSince the quantity on the right hand side is unknown, we stop moving the system as\nsoon as the particle diversity reaches a steady state we cannot push it beyond Sch\u00e4fer\nand Chopin (2011).\nMore precisely, we stop if the absolute diversity is above a certain threshold \u03b6 \u2217 \u2248 0.95\n\u2217 > 0. We always\nor the last improvement of the diversity is below a certain threshold \u03b6\u2206\n\u2217\n\u2217\nstop after a finite number of steps but the thresholds \u03b6 and \u03b6\u2206 need to be calibrated\nto the efficiency of the transition kernel. For slow-mixing kernels, we recommend to\nperform batches of consecutive move steps instead of single move steps.\n\u2217 , it\nIf the average acceptance rate \u03bb of the kernel (see Section 2.2.4) is smaller than \u03b6\u2206\nis likely that the algorithm stops after the first iteration although further moves would\n\u2217 to be proportional to\nhave been necessary. We could adaptively adjust the threshold \u03b6\u2206\nan estimate of the average acceptance rate; for our numerical experiments, however, we\n\u2217 \u2248 10\u22122 .\nkept it fixed to \u03b6\u2206\nProcedure 2: Move\n(0)\n\nInput:\n\n(0)\n\nX = (x1 , . . . , xn )| targeting \u03c0\nP\n\u03ba(\u03b3 | \u2022) with \u03c0(\u03b3) = x\u2208B \u03c0(x)\u03ba(\u03b3 | x)\n\ns\u21901\nrepeat\n(s)\n(s\u22121)\nsample xk \u223c \u03ba(\u2022 | xk\n) for all k \u2208 [[1, n]]\n(s)\n(s\u22121)\n\u2217\nuntil \u03b6(X ) \u2212 \u03b6(X\n) < \u03b6\u2206\nor \u03b6(X(s) ) > \u03b6 \u2217\n(s)\n\n(s)\n\nreturn X(s) = (x1 . . . , xn )|\n\n2.2.4 Transition kernels\nMost transition kernels in Monte Carlo simulations are some variant of the MetropolisHastings kernel (see e.g. Robert and Casella (2004)),\nh\ni\nP\n\u03bat+1 (\u03b3 | x) := \u03bbqt+1 (\u03b3, x)qt+1 (\u03b3 | x) + \u03b4x (\u03b3) 1 \u2212 y\u2208Bd \u03bbqt+1 (y, x)qt+1 (y | x) ,\nwhere we sample from the kernel by proposing a new state \u03b3 \u223c qt+1 (\u03b3 | x) and accepting\nthe proposal with probability\n\u03bbqt+1 (\u03b3, x) := 1 \u2227\n\n\u03c0\u0303t+1 (\u03b3)qt+1 (x | \u03b3)\n\u03c0\u0303t+1 (x)qt+1 (\u03b3 | x)\n\n(7)\n\nor returning x otherwise. Again, we denote by \u03c0\u0303t+1 \u221d \u03c0t+1 the unnormalized version\nof \u03c0t+1 since the kernel only requires the ratio of the unnormalized probability mass\nfunctions.\nSymmetric kernel On binary spaces, a common choice for the proposal distribution\nis\nP\nq(\u03b3 | x) = dk=1 pk \u03b4k (|x \u2212 \u03b3|) k!(d \u2212 k)!/d!,\n(8)\nwith weight vector p \u2208 [0, 1]d normalized such that |p| = 1.\nWith probability pk , the kernel proposes a uniform draw from the k-neighborhood of x,\nNk (x) := {\u03b3 \u2208 Bd : |x \u2212 \u03b3| = k}.\n\n7\n\n(9)\n\n\fWe refer to this type of kernel as symmetric kernel since q(\u03b3 | x) = q(x | \u03b3) and equation\n(7) simplifies. This class of kernels provide a higher mutation rate than the random-scan\nGibbs kernel (see Sch\u00e4fer and Chopin (2011) for adiscussion).\nLocally operating transition kernels of the symmetric type are known to be slowly\nmixing. If we put most weight on small values of k, the kernel only changes one or a\nfew entries in each step. If we put more weight on larger values of k, the proposals will\nhardly ever be accepted if the invariant distribution \u03c0 is multi-modal. Ideally, we want\nthe particles sampled from the transition kernel to be nearly independent after a few\nmove steps which is often hard to achieve using local transition kernels.\nAdaptive independent kernel For the sequential Monte Carlo algorithm, we use\nadaptive independent kernels which have proposal distributions of the kind\nq(\u03b3 | x) = q\u03b8 (\u03b3),\n\n\u03b8 \u2208 \u0398,\n\nwhich do not depend on the current state x but have a parameter \u03b8 which we adapt\nduring the course of the algorithm.\nThe adaptive independent kernel is rapidly mixing if we can fit the parametric family\nq\u03b8 such that the proposal distribution qt+1 = q\u03b8t+1 is sufficiently close to the target\ndistribution \u03c0t+1 , yielding thus, on average, high acceptance rates \u03bbqt+1 . The general\nidea behind this approach is to take the information gathered in the current particle\napproximation into account (see e.g. Chopin (2002)). The usefulness of this strategy for\nsampling on binary spaces has been illustrated by Sch\u00e4fer and Chopin (2011).\nWe fit a parameter \u03b8t+1 to the particle approximation of \u03c0t+1 according to some\nsuitable criterion. Precisely, \u03b8t+1 is taken to be the maximum likelihood or method\nof moments estimator applied to the weighted sample (wt+1 , Xt ). The choice of the\nparametric family q\u03b8 is crucial to the implementation of a sequential Monte Carlo sampler\nwith adaptive independent kernel. We discuss this issue in detail in Section 3.\nAdaptation could, to a certain extent, also be done for local transition kernels. Nott\nand Kohn (2005) propose an adaptive kernel which replaces the full conditional distribution of the Gibbs sampler by an easy to compute linear approximation which is\nestimated from the sampled particles. This method accelerates Gibbs sampling if the\ntarget distribution \u03c0 is hard to evaluate but does not provide fast mixing like the adaptive independent kernel (see Sch\u00e4fer and Chopin (2011) for a comparison).\nStill, the use of local kernels in the context of the proposed sequential Monte Carlo\nalgorithm might be favorable if, for instance, the structure of the problem allows to\nrapidly compute the acceptance probabilities of local moves. Further, batches of local moves can be alternated with independent proposals to ensure that the algorithm\nexplores the neighborhood of local modes sufficiently well.\n\n2.3 Remark on discrete state spaces\nSince the sample space Bd is discrete, a given particle is not necessarily unique. This\nraises the question whether it is sensible to store multiple copies of the same weighted\nparticle in our system. In the sequel, we discuss some more details concerning this issue\nwhich has only been touched upon briefly by Sch\u00e4fer and Chopin (2011).\nLet n(x) denote the number of copies of the particle x in the system (w, X). Indeed,\nfor parsimonious reasons, we could just keep a single representative of x and aggregate\nthe associated weights to w\u2217 (x) = n(x) w(x).\n\n8\n\n\f2.3.1 Impact on the effective sample size\nShifting weights between identical particles does not affect the nature of the particle\napproximation but it obviously changes the effective sample size \u03b7n (w) which is undesirable since we introduced the effective sample size as a criterion to measure the goodness\nof a particle approximation. From an aggregated particle system, we cannot distinguish\nthe weight disparity induced by reweighting according to the importance function (4)\nand the weight disparity induced by multiple sampling of the same states which occurs\nif the mass of the target distribution is concentrated. More precisely, we cannot tell\nwhether the effective sample size is actually due to the gap between \u03c0t and \u03c0t+1 or the\npresence of particle copies due to the mass of \u03c0t concentrating on a small proportion of\nthe state space which occurs by construction of the auxiliary distribution in Section 1.2.\n2.3.2 Impact on the resample-move step\nAggregating the weights means that the number of particles is not fixed at runtime.\nIn this case, the straightforward way to implement the move step presented in Section\n2.2.2 is breaking up the particles into multiple copies corresponding to their weights and\nmoving them separately. But instead of permanently splitting and pooling the weights\nit seems more efficient to just keep the multiple copies.\nWe could, however, design a different kind of resample-move algorithm which first\naugments the number of particles in the move step and then resamples exactly n weighted\nparticles from this extended system using a variant of the resampling procedure proposed\nby Fearnhead and Clifford (2003). A simple way to augment the number of particles is\nsampling and reweighting via\n(1)\n\n(0)\n\nxk \u223c qt+1 (\u2022 | xk ),\n(1)\n\n(1)\n\n(0)\n\nwk = wk \u03bb, wk = wk (1 \u2212 \u03bb),\n\n(0)\n\nwhere \u03bb = \u03bbqt+1 (xk , xk ) denotes the acceptance probability (7) of the MetropolisHastings kernel. We tested this variant but could not see any advantage over the standard sampler presented in the preceding sections. For the augment-resample type algorithm the implementation is more involved and the computational burden significantly\nhigher. In particular, the Rao-Blackwellization effect one might achieve when replacing\nthe accept-reject steps of the transition kernel by a single resampling step does not seem\nto justify the extra computational effort.\nIndeed, aggregating the weights does not only prevent us from using the effective\nsample size criterion, but also requires extra computational time of O(n log n) in each\niteration of the move step since pooling the weights is as complex as sorting. With our\napplication in mind, however, computational time is more critical than memory, and we\ntherefore recommend to refrain from aggregating the weights.\n\n3 Parametric families on binary spaces\nWe review three parametric families on Bd . In contrast to the similar discussion in\nSch\u00e4fer and Chopin (2011), we also consider a parametric family which cannot be used\nin sequential Monte Carlo samplers but in the context of the cross-entropy method. For\nmore details on parametric families on binary spaces we refer to Sch\u00e4fer (2012).\n\n9\n\n\f3.1 Suitable parametric families\nWe frame some properties making a parametric family suitable as proposal distribution\nin sequential Monte Carlo algorithms.\n(a) For reasons of parsimony, we prefer a family of distributions with at most d(d + 1)/2\nparameters like the multivariate normal.\n(b) Given a sample X = (x1 , . . . , xn )| from the target distribution \u03c0, we need to estimate\n\u03b8\u2217 in a reasonable amount of computational time.\n(c) We need to generate samples Y = (y1 , . . . , ym )| from the family q\u03b8 . We need the\nrows of Y to be independent.\n(d) For the sequential Monte Carlo algorithm, we need to evaluate q\u03b8 (y) point-wise.\nHowever, the cross-entropy method still works without this requirement.\n(e) We want the calibrated family q\u03b8\u2217 to reproduce e.g. the marginals and covariance\nstructure of \u03c0 to ensure that the parametric family q\u03b8\u2217 is sufficiently close to \u03c0.\n\n3.2 Product family\nThe simplest non-trivial distributions on Bd are certainly those having independent\ncomponents.\nProduct family For a vector m \u2208 (0, 1)d of marginal probabilities, we define the product family\nQd\n\u03b3i\n1\u2212\u03b3i .\nu (\u03b3) :=\n(10)\nqm\ni=1 mi (1 \u2212 mi )\n3.2.1 Properties\nWe check the requirement list from Section 3.1: (a) The product family is parsimonious\nwith dim(\u03b8) = d. (b) The maximum likelihood estimator m\u0302 is the weighted sample\nu . (d) We can easily evaluate the mass function\nmean. (c) We can easily sample y \u223c qm\nu\nqm (y). (e) However, the product family does not reproduce any dependencies we might\nobserve in (w, X).\nThe last point is the crucial weakness which makes the product family impractical\nfor particle optimization algorithms on strongly multi-modal problems. Consequently,\nthe rest of this section deals with ideas on how to sample binary vectors with a given\ndependence structure. There are, to our knowledge, two major strategies to this end.\n(1) We construct a generalized linear model which permits to compute the conditional\ndistributions. We apply the chain rule and write q\u03b8 as\nQ\nq\u03b8 (\u03b3) = q\u03b8 (\u03b31 ) di=2 q\u03b8 (\u03b3i | \u03b31:i\u22121 ),\n(11)\nwhich allows to sample the entries of a random vector component-wise.\n(2) We sample from an auxiliary distribution \u03c6\u03b8 and map the samples into Bd . We call\nR\nq\u03b8 (\u03b3) = \u03c4 \u22121 (\u03b3) \u03c6\u03b8 (v)dv\n(12)\na copula family, although we refrain from working with explicit uniform marginals.\nWe first present a generalized linear model and then review a copula approach.\n\n10\n\n\f3.3 Logistic conditionals family\nEven for rather simple non-linear models we usually cannot derive closed-form expressions for the marginal probabilities required for sampling according to (11). Therefore,\nwe might directly construct a parametric family from its conditional probabilities.\nLogistic conditionals family We define, for a lower triangular matrix A \u2208 Rd\u00d7d , the\nlogistic conditionals family as\n\u0011i1\u2212\u03b3i\n\u0011\u03b3i h\n\u0010\n\u0010\nPi\u22121\nQ\nPi\u22121\n` (\u03b3) :=\na\n\u03b3\na\n\u03b3\n1\n\u2212\n`\na\n+\nqA\n`\na\n+\nij\nj\nij\nj\nii\nii\nj=1\nj=1\ni\u2208[[1,d]]\nwhere ` : R \u2192 (0, 1), `(x) = [1 + exp(\u2212x)]\u22121 is the logistic function. We readily identify\nu as the special case A = diag`\u22121 (m).\nthe product family qm\nThe virtue of the logistic conditionals family is that, by construction, we can sample\n` (y) of the sample y is\na random vector component-wise while the full probability qA\ncomputed as a by-product of Procedure 3. We refer to the Online Supplement for\ninstructions on how to fit the parameter A.\nProcedure 3: Sampling via chain rule factorization\ny = (0, . . . , 0), p \u2190 1\nfor i \u2208 [[1, d]] do\nPi\u22121\n` (y = 1 | y\nr \u2190 qA\ni\n1:i\u22121 ) = `(aii +\nj=1 aij yj )\nu \u223c U[0, 1]\nif u (\n< r then yi \u2190 1\np*r\nif yi = 1\np\u2190\np * (1 \u2212 r) if yi = 0\nend\nreturn y, p\n\n3.3.1 Properties\nWe check the requirement list from Section 3.1: (a) The logistic conditionals family is\nsufficiently parsimonious with dim(\u03b8) = d(d + 1)/2. (b) We can fit the parameter A via\nlikelihood maximization. The fitting is computationally intensive but feasible. (c) We\n` using the chain rule factorization (11). (d) We can exactly evaluate\ncan sample y \u223c qA\n` (y). (e) The family q ` reproduces the dependency structure of the data X although\nqA\nA\nwe cannot explicitly compute the marginal probabilities.\n\n3.4 Gaussian copula family\nLet \u03c6\u03b8 be a family of multivariate auxiliary distributions on X and \u03c4 : X \u2192 Bd a mapping\ninto the binary space. We can sample from the copula family (12) by setting x = \u03c4 (v)\nfor a draw v \u223c \u03c6\u03b8 from the auxiliary distribution. Most multivariate parametric families\nwith at most d(d + 1)/2 parameters appear to either have a rather limited dependency\nrange or they do not scale to higher dimensions Joe (1996). Therefore, the natural and\nseemingly only viable option for \u03c6\u03b8 is the multivariate normal distribution Emrich and\nPiedmonte (1991).\n\n11\n\n\fGaussian copula family For a vector a \u2208 Rd and a correlation matrix \u03a3 \u2208 Rd\u00d7d , we\nintroduce the mapping\n\u03c4a : Rd \u2192 Bd , \u03c4a (v) := (1(\u2212\u221e,ai ] (v1 ), . . . , 1(\u2212\u221e,ad ] (vd )),\nand define the Gaussian copula family as\nd\n\n1\n\ngc (\u03b3) := (2\u03c0)\u2212 2 det\u03a3\u2212 2\nqa,\u03a3\n\nR\n\n\u03c4a\u22121 (\u03b3) exp\n\n\u0001\n\u2212 12 v | \u03a3\u22121 v dv.\n\nFor index sets I \u2286 [[1, d]], the cross-moments\nP\nQ\ngc (\u03b3)\nmI = \u03b3\u2208Bd qa,\u03a3\ni\u2208I \u03b3i\nare equal the cumulative distribution function of the multivariate normal with respect to\nthe entries indexed by I (see Sch\u00e4fer (2012) for a more detailed discussion). In particular,\nthe first and second moments are\nmi = \u03a61 (ai ),\n\nmij = \u03a62 (ai , aj ; \u03c3ij ),\n\ni, j \u2208 [[1, d]],\n\nwhere \u03a61 (*) and \u03a62 (*, *; \u03c3ij ) denote the cumulative distribution functions of the univariate and bivariate normal distributions with zero mean, unit variance and correlation\ncoefficient \u03c3ij \u2208 [\u22121, 1]. We refer to the Online Supplement for instructions on how to\nfit the parameters a and \u03a3.\n3.4.1 Properties\nWe check the requirement list from Section 3.1: (a) The Gaussian copula family is\nsufficiently parsimonious with dim(\u03b8) = d(d + 1)/2. (b) We can fit the parameters a and\n\u03a3 via method of moments. However, the parameter \u03a3 is not always positive definite. (c)\ngc using y = \u03c4 (v) with v \u223c \u03c6 . (d) We cannot easily evaluate\nWe can sample y \u223c qa,\u03a3\na\n\u03a3\ngc\nqa,\u03a3 (y) since this requires computing high-dimensional integral expressions which is a\ncomputationally challenging problem in itself (see e.g. Genz and Bretz (2009)). The\nGaussian copula family is therefore less useful for sequential Monte Carlo samplers but\ncan be incorporated into the cross-entropy method reviewed in Section 4.2. (e) The\ngc reproduces the exact mean and, possibly scaled, correlation structure.\nfamily qa,\u03a3\n\n3.5 Toy example\nWe briefly discuss a toy example to illustrate the usefulness of the parametric families.\nFor the quadratic function\n\uf8eb\n\uf8f6\n1 2\n1\n0\n\uf8ec2 1 \u22123 \u22122\uf8f7\n\uf8f7,\nf (x) = x| Fx, F := \uf8ec\n(13)\n\uf8ed1 \u22123 1\n2\uf8f8\n0 \u22122 2 \u22122\nthe associated probability mass function \u03c0(\u03b3) \u221d exp(\u03b3 | F\u03b3) has a correlation matrix\n\uf8eb\n\uf8f6\n1\n0.127 \u22120.106 \u22120.101\n\uf8ec 0.127\n1\n\u22120.941 \u22120.866\uf8f7\n\uf8f7,\nR\u2248\uf8ec\n\uf8ed\u22120.106 \u22120.941\n1\n0.84 \uf8f8\n\u22120.101 \u22120.866\n0.84\n1\n\n12\n\n\fwhich indicates that this distribution has considerable dependencies and its mass function is therefore strongly multi-modal. We generate pseudo-random data from \u03c0, adjust\nthe parametric families to the data and plot the mass functions of the fitted parametric\nfamilies.\nFigure 2 shows how the three parametric families cope with reproducing the true mass\nfunction. Clearly, the product family is not close enough to the true mass function to\nyield a suitable instrumental distribution while the logistic conditional family almost\ncopies the characteristics of \u03c0 and the Gaussian copula family allows for an intermediate\ngoodness of fit.\n\n0.4\n0.3\n0.2\n0.1\n0.0\n\n0000\n0001\n0010\n0011\n0100\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\n\n(a) True mass function \u03c0(\u03b3)\n0.4\n0.3\n0.2\n0.1\n0.0\n\n0000\n0001\n0010\n0011\n0100\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\n\n0.4\n0.3\n0.2\n0.1\n0.0\n\n(b) Product family qm (\u03b3)\n\n(c) Logistic conditionals family qA (\u03b3)\n\n0000\n0001\n0010\n0011\n0100\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\n\n0.4\n0.3\n0.2\n0.1\n0.0\n\n0000\n0001\n0010\n0011\n0100\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\n\nFigure 2: Toy example showing how well the parametric families replicate the mass function of the distribution \u03c0(\u03b3) \u221d exp(\u03b3 | F\u03b3) as defined in (13).\n\n(d) Gaussian copula family qa,\u03a3 (\u03b3)\n\n4 Optimization algorithms\nIn this section, we provide a synopsis of all steps involved in the sequential Monte\nCarlo algorithm and connect this framework to the cross-entropy method and simulated\nannealing. In Table 1, we state the necessary formulas for the tempered and the level\nset sequence introduced in Section 1.2.\n\n4.1 Sequential Monte Carlo\nFor convenience, we summarize the complete sequential Monte Carlo sampler in Algorithm 1. Note that, in practice, the sequence \u03c0%t is not indexed by t but rather by %t ,\nwhich means that the counter t is only given implicitly.\nThe algorithm terminates if the particle diversity sharply drops below some threshold\n\u03b4 > 0 which indicates that the mass has concentrated in a single mode. If we use a\nkernel with proposals from a parametric family q\u03b8t , we might already stop if the family\ndegenerates in the sense that only a few components of q\u03b8t , say less than d\u2217 = 12,\n\n13\n\n\fare random while the others are constant ones or zeros. In this situation, additional\nmoves using a parametric family are a pointless effort. We either return the maximizer\nwithin the particle system or we solve the subproblem of dimension d\u2217 by brute force\nenumeration. We might also perform some final local moves in order to further explore\nthe regions of the state space the particles concentrated on.\nAlgorithm 1: Sequential Monte Carlo optimization\nInput: f : Bd \u2192 R\niid\nsample xk \u223c UBd for all k \u2208 [[1, n]].\n\u03b1 \u2190 find step length(0, X),\nw \u2190 importance weights(\u03b1, \u03c0, X)\nwhile \u03b6n (X) > \u03b4 do\nq\u03b8 \u2190 fit parametric family(w, X)\nb \u2190 resample(w, X)\nX\nb\nX \u2190 move(\u03ba\u03c0,q , X)\n\u03b8\n\n(see Section 3)\n(Procedure 1)\n(Procedure 2)\n\n\u03b1 \u2190 find step length(%, X)\nw \u2190 importance weights(\u03b1, \u03c0% , X)\n% \u2190%+\u03b1\nend\nreturn argmaxx\u2208{x1 ,...,xn } f (x)\n\n4.2 Cross-entropy method\nFor the level set sequence, the effective sample size is the fraction of the particles which\nhave an objective function value greater than maxx\u2208Bd f (x) \u2212 1/(%t + \u03b1); see Table 1\nand equation (3). The remaining particles are discarded since their weights equal zero.\nConsequently, there is no need to explicitly compute \u03b1t as a solution of (6). We simply\norder the particles xk according to their objective values f (xk ) and only keep the n(1\u2212\u03b2)\nparticles with the highest objective values.\nRubinstein Rubinstein (1997), who popularizes the use of level set sequences in the\ncontext of the cross-entropy method, refers to n(1 \u2212 \u03b2) as the size of the elite sample.\nThe cross-entropy method has been applied successfully to a variety of combinatorial\noptimization problems, some of which are equivalent to pseudo-Boolean optimization\nRubinstein and Kroese (2004), and is closely related to the proposed sequential Monte\nCarlo framework.\nHowever, the central difference between the cross-entropy method and the sequential\nMonte Carlo algorithm outlined above is the use of the invariant transition kernel in the\nlatter. We obtain the cross-entropy method as a special case if we replace the kernel \u03bat\nby its proposal distribution q\u03b8t . The sequential Monte Carlo approach uses a smooth\nfamily of distributions {\u03c0% : % \u2265 0} and explicitly schedules the evolution \u03c0%t which in\nturn leads to the proposal distributions q\u03b8t . The cross-entropy method, in contrast,\ndefines the subsequent proposal distribution\nq\u03b8t+1 \u2248 q\u03b8t 1L+\n%\n\nt+1\n\nwithout any reference sequence \u03c0t to balance the speed of the particle evolution.\n\n14\n\n\fTable 1: Formulas for optimization sequences\nexp(%f )\ne\u03b1f (xk,t )\n\nut,\u03b1 (xk,t )\n\n1L+\n\n%t +\u03b1\n\n2\ne\u03b1f (xk,t )\nPk=1\nn nk=1 e2\u03b1f (xk,t )\n\n\u0002Pn\n\u03b7n (wt,\u03b1 )\n\u03bbqt+1 (\u03b3 | xk,t )\n\n1L+\n%\n\n1\u2227\n\n\u0003\n\ne\u03b1(f (\u03b3)\u2212f (xk,t ))\nelog qt (\u03b3)\u2212log qt (xk,t )\n\n(xk,t )\n\n|{xk,t | k \u2208 [[1, n]]} \u2229 L+\n%t +\u03b1 |\nn\n1\u2227\n\n1L+\n%\n\n(\u03b3)\n\nt+1\n\nelog qt (\u03b3)\u2212log qt (xk,t )\n\nIn order to decelerate the advancement of the cross-entropy method, we introduce a\nlag parameter \u03c4 \u2208 [0, 1) and use a convex combination of the previous parameter \u03b8t\u22121\nand the parameter \u03b8\u0302t fit to the current particle system, setting\n\u03b8t := (1 \u2212 \u03c4 )\u03b8\u0302t + \u03c4 \u03b8t\u22121 .\nHowever, there are no guidelines on how to adjust the lag parameter during the run\nof the algorithm. Therefore, the sequential Monte Carlo algorithm is easier to calibrate\nsince the reference sequence \u03c0t controls the stride and automatically prevents the system\nfrom overshooting.\nOn the upside, the cross-entropy method allows for a broader class of auxiliary distributions q\u03b8t since we do not need to evaluate q\u03b8t (x) point-wise which is necessary in the\ncomputation of the acceptance probability of the Hastings kernel; see Section 3.4.\n\n4.3 Simulated annealing\nA well-studied approach to pseudo-Boolean optimization is simulated annealing Kirkpatrick et al. (1983). While the name stems from the analogy to the annealing process\nin metallurgy, there is a pure statistical meaning to this setup. We can picture simulated\nannealing as approximating the mode of a tempered sequence (2) using a single particle.\nSince a single observation does not allow for fitting a parametric family, we have to rely\non symmetric transition kernels (8) in the move step.\nA crucial choice is the sequence %t which in this context is often referred to as the\ncooling schedule. There is a vast literature advising on how to calibrate %t where a typical\nguideline is the expected acceptance rate of the Hastings kernel. We calibrate %t such\nthat the empirical acceptance rate\nP\n\u03bbt\u2212s:t := tr=t\u2212s \u03bbr , s > 0\nfollows approximately (t + 1)\u22125 for t \u2208 [0, 1]. There are variants of simulated annealing\nwhich use more complex cooling schedules, tabu lists and multiple restarts, but we stick\nto this simple version for the sake of simplicity. Algorithm 2 describes the version we\nuse in our numerical experiments in Section 5.3.3.\n\n15\n\n\fAlgorithm 2: Simulated annealing optimization\n[ht] Input: f : Bd \u2192 R, T \u2217 \u2208 R\nx \u223c UBd , x\u2217 \u2190 x, t \u2190 0, T\u2206 \u2190 0 (time elapsed)\nwhile T\u2206 < T \u2217 do\nsample\n\u03b3 \u223c UN1 (x) , u \u223c U[0,1] , \u03bbt \u2190 1 \u2227 exp [%t (f (\u03b3) \u2212 f (x))]\nif u < \u03bbt then x \u2190 \u03b3\nif f (x) > f (x\u2217 ) then x\u2217 \u2190 x\nadjust %t such that \u03bbt\u2212s:t \u2248 (1 + T\u2206 /T \u2217 )\u22125\nt\u2190t+1\nend\nreturn x\u2217\n\n4.4 Randomized local search\nWe describe a greedy local search algorithm which works on any state space that allows\nfor defining a neighborhood structure. The typical neighborhood on binary spaces is the\nk-neighborhood defined in (9). A greedy local search algorithm computes the objective\nvalue of all states in the current neighborhood and moves to the best state found until\na local optimum is reached. The local search algorithm is called k-opt if it searches the\nneighborhood \u222aki=1 Ni (*) (see e.g. Merz and Freisleben (2002) for a discussion).\nThe algorithm can be randomized by repeatedly restarting the procedure from randomly drawn starting points. There are more sophisticated versions of local search\nalgorithms exploit the properties of the objective function but even a simple local search\nprocedure can produce good results Alidaee et al. (2010). Algorithm 3 describes the\n1-opt local search procedure we use in our numerical experiments in Section 5.3.3.\nAlgorithm 3: Randomized local search\n[ht] Input: f : Bd \u2192 R, T \u2217 \u2208 R\nx\u2217 \u223c UBd , T\u2206 \u2190 0 (time elapsed)\nwhile T\u2206 < T \u2217 do\nx \u223c UBd\nwhile x is not a local optimum do\nx \u2190 argmax\u03b3\u2208N1 (x) f (\u03b3)\nend\nif f (x) > f (x\u2217 ) then x\u2217 \u2190 x\nend\nreturn x\u2217\n\n16\n\n\f5 Applications\n5.1 Unconstrained Quadratic Binary Optimization\n5.1.1 Introduction\nIt is well-known that any pseudo-Boolean function f : Bd \u2192 R can be written as a\nmulti-linear function\nY\nX\nY\nY\nX\naI\nxi ,\n(14)\n(1 \u2212 xi ) =\nf (1I (1), . . . , 1I (d))\nxi\nf (x) =\nI\u2286[[1,d]]\n\ni\u2208I\n\ni\u2208[[1,d]]\\I\n\nI\u2286[[1,d]]\n\ni\u2208I\n\nwhere aI \u2208 R are real-valued coefficients. We say the function f is of order k if the\ncoefficients aI are zero for all I \u2286 [[1, d]] with |I| > k. While optimizing a first order\nfunction is trivial, optimizing a non-convex second order function is already an NP-hard\nproblem Garey and Johnson (1979).\nIn the sequel, we focus on optimization of second order pseudo-Boolean functions to\nexemplify the stochastic optimization schemes discussed in the preceding sections. If f\nis a second order function, we restate program (1) as\nmaximize\nsubject to\n\nx| Fx\nx \u2208 Bd ,\n\n(15)\n\nwhere F \u2208 Rd\u00d7d is a symmetric matrix. We call (15) an unconstrained quadratic binary\noptimization problem (uqbo); we refer to Boros et al. (2007) for a list of applications and\nequivalent problems. In the literature it is also referred to as unconstrained quadratic\nBoolean or bivalent or zero-one programming Beasley (1998).\n5.1.2 Particle optimization and meta-heuristics\nMeta-heuristics are a class of algorithms that optimize a problem by improving a set\nof candidate solutions without systematically enumerating the state space; typically\nthey deliver solutions in polynomial time while an exact solution has exponential worst\ncase running time. The outcome is neither guaranteed to be optimal nor deterministic\nsince most meta-heuristics are randomized algorithms. We briefly discuss the connection\nto particle optimization against the backdrop of the unconstrained quadratic binary\noptimization problem where we roughly separate them into two classes: local search\nalgorithms and particle-driven meta-heuristics.\nLocal search algorithms iteratively improve the current candidate solution through\nlocal search heuristics and judicious exploration of the current neighborhood; examples\nare local search Boros et al. (2007); Merz and Freisleben (2002), tabu search Glover et al.\n(1998); Palubeckis (2004), simulated annealing Katayama and Narihisa (2001). Particle\ndriven meta-heuristics propagate a set of candidate solutions and improve it through\nrecombination and local moves of the particles; examples are genetic algorithms Merz\nand Freisleben (1999), memetic algorithms Merz and Katayama (2004), scatter search\nAmini et al. (1999). For comparisons of these methods we refer to Hasan et al. (2000)\nor Beasley (1998).\nThe sequential Monte Carlo algorithm and the cross-entropy method are clearly in the\nlatter class of particle-driven meta-heuristics. The idea behind sequential Monte Carlo\nis closely related to the intuition behind population (or swarm) optimization and genetic\n\n17\n\n\f(or evolutionary) algorithms. However, the mathematical framework used in sequential\nMonte Carlo allows for a general formulation of the statistical properties of the particle\nevolution while genetic algorithms are often problem-specific and empirically motivated.\n5.1.3 Particle optimization and exact solvers\nIf we can explicitly derive the multi-linear representation (14) of the objective function,\nthere are techniques to turn program (1) into a linear program. For the uqbo it reads\nmaximize\n\nf (x) = 2\n\nd X\ni\u22121\nX\ni=1 j=1\n\nsubject to\n\nfij xij +\n\nd\nX\n\nfii xii\n\ni=1\n\nx \u2208 Bd(d+1)/2\n\uf8fc\nxij \u2264 xii\n\uf8fd\nxij \u2264 xjj\nfor all i, j \u2208 [[1, d]].\n\uf8fe\nxij \u2265 xii + xjj \u2212 1\n\n(16)\n\nNote, however, that there are more parsimonious linearization strategies than this straightforward approach [(Hansen and Meyer, 2009), (Gueye and Michelon, 2009)]. The transformed problem allows to access the tool box of linear integer programming which consist of branch-and-bound algorithms that are combined with rounding heuristics, various relaxations techniques and cutting plane methods [(Pardalos and Rodgers, 1990),\n(Palubeckis, 1995)].\nNaturally, the question arises whether particle-driven meta-heuristics can be incorporated into exact solvers to improve branch-and-bound algorithms. Indeed, stochastic\nmeta-heuristics deliver lower bounds for maximization problems, but particle-driven algorithms are computationally somewhat expensive for this purpose unless the objective\nfunction is strongly multi-modal and other heuristics fail to provide good results; see the\ndiscussion in Section 5.2.5.\nHowever, the sequential Monte Carlo approach in combination with the level set sequence (3) might also be useful to determine a global branching strategy, since the\nalgorithm provides an estimator for\nP\n\u22121\n(\u03b3),\n\u03b3 c := |L+\nc |\n\u03b3\u2208Bd \u03b3 1L+\nc\nd\nwhich is the average of the super-level set L+\nc := {x \u2208 B : f (x) \u2265 c}. These estimates\ngiven for a sequence of levels c might provide branching strategies than are superior to\nlocal heuristics or branching rules based on fractional solutions. A further discussion of\nthis topic is beyond the scope of this paper but it certainly merits consideration.\n\n5.2 Construction of test problems\n5.2.1 Introduction\nThe meta-heuristics we want to compare do not exploit the quadratic structure of the\nobjective function and might therefore be applied to any binary optimization program.\nIf the objective function can be written in multi-linear form like (15) there are efficient\nlocal search algorithms Boros et al. (2007); Merz and Freisleben (2002) which exploit\nspecial properties of the target function and easily beat particle methods in terms of\ncomputational time.\n\n18\n\n\fTherefore, the use of particle methods is particularly interesting if the objective function is expensive to compute or even a black box. The posterior distribution in Bayesian\nvariable selection for linear normal models is an example of such an objective function\n(see Sch\u00e4fer and Chopin (2011) and references therein). We stick to the uqbo for our\nnumerical comparison since problem instances of varying difficulty are easy to generate\nand interpret while the results carry over to general binary optimization.\nIn the vast literature on uqbo, authors typically compare the performance of metaheuristics on a suite of randomly generated problems with certain properties. Pardalos\n(1991) proposes standardized performance tests on symmetric matrices F \u2208 Zd\u00d7d with\nentries fij drawn from the uniform\nqc (k) :=\n\n1\n1\n(k),\n2c [[\u2212c,c]]\n\nc \u2208 N.\n\nThe test suites generated by Beasley (1990, OR-library) and Glover et al. (1998) follow\nthis approach have been widely used as benchmark problems in the uqbo literature (see\nBoros et al. (2007) for an overview). In the sequel we discuss the impact of diagonal\ndominance, shifts, the density and extreme values of F on the expected difficulty of the\ncorresponding uqbo problem.\n5.2.2 Diagonal\nGenerally, stronger diagonal dominance in F corresponds to easier uqbo problems Billionnet and Sutter (1994). Consequently, the original problem generator presented by\nPardalos (1991) is designed to draw the off-diagonal elements from a uniform on a different support [[\u2212q, q]] with q \u2208 N.\nIn this context, we point out that the impact of diagonal dominance carries over to\nthe statistical properties of the tempered distributions (2) we defined in the introductory Section 1.2. Indeed, stronger diagonal dominance in F corresponds to exponential\nquadratic distributions\nexp(\u03b3 | F\u03b3)\n\u03c0(\u03b3) := P\n|\n\u03b3\u2208Bd exp(\u03b3 F\u03b3)\nhaving lower dependencies between the components of \u03b3. We can analytically derive a\n` that approximates \u03c0(\u03b3) where\nparameter A \u2208 Rd\u00d7d for a logistic conditionals family qA\nthe quality of the approximation increases as the diagonal of F becomes more dominant\nSch\u00e4fer (2012). We can accelerate the sequential Monte Carlo algorithm by initializing\n` instead of U d . However, we did not exploit this option to keep the\nthe system from qA\nB\npresent work more concise.\nFor positive definite F \u001f 0, the optimization problem is convex and can be solved\nin polynomial time Kozlov et al. (1979); in exact optimization, this fact is exploited to\nconstruct upper bounds for maximization problems Poljak and Wolkowicz (1995). We\nobserve a corresponding complexity reduction in statistical modeling. For F \u001f 0, the\nauxiliary distribution\n\u03b3 | F\u03b3\n\u03c0(\u03b3) := d\u22122 |\n,\n2\n(1 F1 + tr (F))\nis a feasible mass function, and we can derive analytical expressions concerning all crossmoments and marginal distributions Sch\u00e4fer (2010) which allows to largely analyze the\nproperties of \u03c0(\u03b3) without enumerating the state space.\n\n19\n\n\f5.2.3 Shifts\nThe global optimum of the uqbo problem is more difficult to detect as we shift the\nentries of the matrix F but the relative gap between the optimum and any heuristic\nvalue diminishes. If we sample fij = fij\u03c4 from a uniform on the shifted support\nqc,\u03c4 (k) := U[[\u2212c+\u03c4,c+\u03c4 ]] (k),\n\nc \u2208 N, \u03c4 \u2208 [[\u2212c, c]],\n\nwe obtain an objective function\nd\n\nf\u03c4 (x) = x| F\u03c4 x = x| (F0 + \u03c4 11| )x = f0 (x) + \u03c4 |x|2 ,\nd\n\nwhere = means equality in distribution. Hence, with growing |\u03c4 | the optimum depends\nless on F and the relative gap between the optimum and a solution provided by any\nmeta-heuristic vanishes. Boros et al. (2007) define a related criterion\n\u03c1\u0304 :=\n\n1\n\u03c4 + 2\u03c4 c\n+\n\u2208 [0, 1]\n2 2(\u03c4 2 + c2 + c)\n\nand report a significant impact of \u03c1\u0304 on the solution quality of their local search algorithms\nwhich is not surprising.\n5.2.4 Density\nThe difficulty of the optimization problem is related to the number of interactions, that\nis the number of non-zero elements of F. We call the proportion of non-zeros the density\nof F. Drawing fij from the mixture\nqc,\u03c9 (k) = \u03c9 U[[\u2212c,c]] (k) + (1 \u2212 \u03c9)\u03b40 (k),\n\nc \u2208 N, \u03c9 \u2208 (0, 1]\n\nwe adjust the difficulty of the problem to a given expected density \u03c9.\nNote that not all algorithms are equally sensitive to the density of F. Using the basic\nlinearization (16), each non-zero off-diagonal element requires the introduction of an\nauxiliary variable and three constraints. Thus, the expected total number of variables\nand the expected total number of constraints, which largely determine the complexity\nof the optimization problem, are proportional to the density \u03c9.\nOn the other hand, many randomized approaches, including the particle algorithms\ndiscussed in Section 2, are less sensitive to the density of the problem in the sense that\nreplacing zero elements by small values has a minor impact on the performance of these\nalgorithms. Rather than the zero/non-zero duality, we suggest that the presence of\nextreme values determines the difficulty of providing heuristic solutions.\n5.2.5 Extreme values\nThe uniform sampling approach advocated by Pardalos (1991) is widely used in the\nliterature for comparing meta-heuristics. Certainly, particle-driven methods are computationally too expensive to outperform local search heuristics on test problems with\nuniformly drawn entries; Beasley (1998) confirms this intuition with respect to genetic\nalgorithms versus tabu search and simulated annealing. However, the uniform distribution does not produce extreme values and it is vital to keep in mind that these have an\nenormous impact on the performance of local search algorithms.\n\n20\n\n\fExtreme values in F lead to the existence of distinct local maxima x\u2217 \u2208 Bd of f\nin the sense that there is no better candidate solution than x\u2217 in the neighborhood\n\u222aki=1 Ni (x\u2217 ) even for relatively large k. Further, extreme local minima might completely\nprevent a local search heuristic from traversing the state space in certain directions.\nConsequently, local search algorithms, as discussed in Section 5.1.2, depend more heavily\non their starting value, and their performance deteriorates with respect to particle-driven\nalgorithms.\nWe propose to draw the matrix entries fij from a discretized Cauchy distribution\nCc (k) \u221d (1 + (k/c)2 )\u22121 ,\n\nc\u2208N\n\n(17)\n\nthat has heavy tails which cause extreme values to be frequently sampled. Figure 3 shows\nthe distribution of a Cauchy and a uniform to illustrate the difference. The resulting\nuqbo problems have quite distinct local maxima; in that case we also say that the\nfunction f (x) is strongly multi-modal.\nFigure 3: Histograms of a Cauchy C5 and a uniform U10 distribution.\nCauchy distribution\nUniform distribution\n\u221250\n\n\u221240\n\n\u221230\n\n\u221220\n\n\u221210\n\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\n5.3 Numerical comparison\nIn this section, we provide numerical comparisons based on instances of the uqbo problem. We generated two random test suites of dimension d = 250, each having 10 instances. For the first suite, we sampled the matrix entries from a uniform distribution\nU100 on [[\u2212100, 100]]; for the second, we sampled from a Cauchy distribution C100 as\ndefined in (17). For performance evaluation, we run a specified algorithm 100 times on\nthe same problem and denote the outcome by x1 , . . . , x100 .\n5.3.1 Visualization\nSince the absolute values are not meaningful, we report the relative ratios\n%k :=\n\nf (xk ) \u2212 worst solution found\n\u2208 [0, 1],\nbest known solution \u2212 worst solution found\n\nwhere the best known solution is the highest objective value ever found for that instance\nand the worst solution is the lowest objective value among the 100 outcomes. We summarize the results in a histogram. The first n bins are singletons bk := {%\u2217k } for the\nhighest values %\u22171 > * * * > %\u2217n \u2208 {%k : k \u2208 [[1, 100]]}; the following n bins are equidistant\nn\u2212k \u2217 n\u2212k+1 \u2217\n<\nintervals b<\n%n ). The graphs show the bins b1 , . . . , bn , b<\n1 , . . . , bn in\nk := [ n %n ,\nn\ndescending order from left to right on the x-axis. The interval bins are marked with a\nsign \"<\" and the lower bound. The y-axis represents the counts.\nFor comparison, we draw the outcome of several algorithms into the same histogram,\nwhere the worst solution found is the lowest overall objective value among the outcomes.\nFor each algorithm, the counts are depicted in a different color and, for better readability,\n\n21\n\n\fwith diagonal stripes in a different angle. To put it plainly, an algorithm performs well\nif its boxes are on the left of the graph since this implies that the outcomes where often\nclose to the best known solution.\n5.3.2 Comparison of binary parametric families\nWe study how the choice of the binary parametric family affects the quality of the\ndelivered solutions. The focus is on the cross-entropy method, since we cannot easily\nuse the Gaussian copula family in the context of sequential Monte Carlo. We use n =\n1.2 \u00d7 104 particles, set the speed parameter to \u03b2 = 0.8 (or the elite fraction to 0.2) and\nthe lag parameter to \u03c4 = 0.5.\nThe numerical comparisons, given in Figures 5(b) and 5(a), clearly suggest that using\nmore advanced binary parametric families allows the cross-entropy method to detect\nlocal maxima that are superior to those detected using the product family. Hence, the\nnumerical experiments confirm the intuition of our toy example in Figure 2.\nOn the strongly multi-modal instance 5(a) the numerical evidence for this conjecture\nis stunningly clear-cut; on the weakly multi-modal problem 5(b) its validity is still unquestionable. This result seems natural since reproducing the dependencies induced by\nthe objective function is more relevant in the former case than in the latter.\nFigure 4: The cross-entropy method using different binary parametric families.\n200\nGaussian copula model\nLogistic conditionals model\nProduct model\n\n150\n100\n\n0\n\n1.000\n0.351\n0.335\n0.303\n0.292\n0.286\n0.265\n0.263\n0.261\n0.254\n0.245\n0.241\n0.237\n0.232\n0.232\n0.214<\n0.196<\n0.178<\n0.16<\n0.143<\n0.125<\n0.107<\n0.089<\n0.071<\n0.053<\n0.036<\n0.018<\n0.000<\n\n50\n\n(a) problem f (x) = x| Fx with fij \u223c C100 for i, j \u2208 [[1, 250]]\n\n80\n60\n40\n\n0\n\n1.000\n0.993\n0.979\n0.971\n0.970\n0.969\n0.960\n0.949\n0.947\n0.943\n0.942\n0.941\n0.930\n0.928\n0.926\n0.854<\n0.783<\n0.712<\n0.641<\n0.57<\n0.498<\n0.427<\n0.356<\n0.285<\n0.214<\n0.142<\n0.071<\n0.000<\n\n20\n\n(b) problem f (x) = x| Fx with fij \u223c U100 for i, j \u2208 [[1, 250]]\n\n22\n\n\f5.3.3 Comparison of optimization algorithms\nWe compare a sequential Monte Carlo sampler with parametric family, a sequential\nMonte Carlo sampler with a single-flip symmetric kernel (8), the cross-entropy method,\nsimulated annealing and 1-opt local search as described in Section 4.\nFor the cross entropy method, we use the same parameters as in the preceding section. For the sequential Monte Carlo algorithm, we use n = 0.8 \u00d7 104 particles and\nset the speed parameter to \u03b2 = 0.9; we target a tempered auxiliary sequence (2). For\nboth algorithms we use the logistic conditionals family as sampling distribution. With\nthese configurations, the algorithms converge in roughly 25 minutes. We calibrate the\nsequential Monte Carlo sampler with local moves to have the same average run time by\nprocessing batches of 10 local moves before checking the particle diversity criterion. The\nsimulated annealing and 1-opt local search algorithms run for exactly 25 minutes.\nThe results shown in Figures 6(b) and 6(a) assert the intuition that particle methods\nperform significantly better on strongly multi-modal problems. However, on the easy test\nproblems, the particle methods tend to persistently converge to the same sub-optimal\nlocal modes. This effect is probably due to their poor local exploration properties. Since\nparticle methods perform significantly less evaluations of the objective function, they\nare less likely to discover the highest peak in a region of rather flat local modes. The use\nof parametric families aggravates this effect, and it seems advisable to alternate global\nand local moves to make a particle algorithm more robust against this kind of behavior.\nFurther numerical results are shown in Figure 6 and Figure 7.\n\n6 Discussion and conclusion\nThe numerical experiments carried out on different parametric families revealed that the\nuse of the advanced families proposed in this paper significantly improves the performance of the particle algorithms, especially on the strongly multi-modal problems. The\nexperiments demonstrate that local search algorithms, like simulated annealing and randomized 1-opt local search, indeed outperform particle methods on weakly multi-modal\nproblems but deliver inferior results on strongly multi-modal problems.\nUsing tabu lists, adaptive restarts and rounding heuristics, we can certainly design\nlocal search algorithms that perform better than simulated annealing and 1-opt local\nsearch. Still, the structural problem of strong multi-modality persists for path-based\nalgorithms. On the other hand, cleverly designed local search heuristics will clearly beat\nsequential Monte Carlo methods on easy to moderately difficult problems.\nThe results encourage the use of particle methods if the objective function is known\nto be potentially multi-modal and hard to analyze analytically. We have to keep in\nmind that multiple restarts of rather simple local search heuristics can be very efficient\nif they make use of the structure of the objective function. For 25 minutes of randomized\nrestarts, the heuristic proposed by Boros et al. (2007), which exploits the fact that the\npartial derivatives of a multi-linear function are constant, practically always returns the\nbest known solution on all test problems treated to create Figures 6 and 7.\nThe numerical work was completely done in Python 2.6 using SciPy packages and run\non a cluster with 1.86 GHz processors. The sources used in this work and the problems\nprocessed in this paper can be found at http://code.google.com/p/smcdss.\n\n23\n\n\fFigure 5: Comparison of stochastic optimization algorithms on two uqbo problems.\n1\u2212opt local search\nSimulated annealing\nSMC symmetric\nSMC parametric\nCross\u2212entropy\n\n200\n150\n100\n\n0\n\n1.000\n0.986\n0.984\n0.983\n0.973\n0.964\n0.956\n0.946\n0.943\n0.943\n0.939\n0.938\n0.936\n0.930\n0.927\n0.856<\n0.785<\n0.713<\n0.642<\n0.571<\n0.499<\n0.428<\n0.357<\n0.285<\n0.214<\n0.143<\n0.071<\n0.000<\n\n50\n\n(a) problem f (x) = x| Fx with fij \u223c C100 for i, j \u2208 [[1, 250]]\n\n150\n\n100\n\n0\n\n1.000\n0.921\n0.884\n0.841\n0.835\n0.814\n0.692\n0.684\n0.672\n0.649\n0.633\n0.623\n0.610\n0.607\n0.601\n0.554<\n0.508<\n0.462<\n0.416<\n0.37<\n0.323<\n0.277<\n0.231<\n0.185<\n0.139<\n0.092<\n0.046<\n0.000<\n\n50\n\n(b) problem f (x) = x| Fx with fij \u223c U100 for i, j \u2208 [[1, 250]]\n\n7 Acknowledgments\nThis work is part of the author's Ph.D. thesis at CREST under supervision of Nicolas\nChopin whom I would like to thank for the numerous discussions on particle algorithms.\nI thank the editor and two anonymous referees for their detailed comments which helped\nto significantly improve this paper.\n\n8 Appendix: Fitting the parameters\nWe briefly summarize how the parameters of the logistic conditionals family and the\nGaussian copula family can be assessed for a given particle system X = (x1 , . . . , xn )|\nwith weights w = (w1 , . . . , wn ). We denote by\nP\nP\nx\u0304i := nk=1 wk xki , x\u0304ij := nk=1 wk xki xkj , i, j \u2208 [[1, d]]\n(18)\nthe weighted first and second sample moments.\n\n24\n\n\f50\n\n0\n0\n\n(a) r250c problem 01\n400\n\n150\n300\n\n100\n200\n\n50\n100\n\n0\n0\n\n(c) r250c problem 03\n200\n\n150\n150\n\n100\n100\n\n50\n50\n\n0\n0\n\n(e) r250c problem 05\n\n200\n\n150\n\n100\n\n50\n\n250\n\n200\n\n150\n\n(i) r250c problem 09\n\n25\n0\n\n(g) r250c problem 07\n\n100\n\n100\n\n50\n\n50\n\n0\n\n0\n\n1.000\n0.999\n0.996\n0.973\n0.957\n0.953\n0.948\n0.902\n0.901\n0.837\n0.836\n0.829\n0.818\n0.816\n0.801\n0.74<\n0.678<\n0.616<\n0.555<\n0.493<\n0.432<\n0.37<\n0.308<\n0.247<\n0.185<\n0.123<\n0.062<\n0.000<\n\n100\n\n1.000\n0.952\n0.942\n0.895\n0.894\n0.650\n0.642\n0.624\n0.607\n0.587\n0.567\n0.550\n0.439\n0.182\n0.173\n0.083<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n\n50\n\n1.000\n0.986\n0.984\n0.983\n0.973\n0.964\n0.956\n0.946\n0.943\n0.943\n0.939\n0.938\n0.936\n0.930\n0.927\n0.856<\n0.785<\n0.713<\n0.642<\n0.571<\n0.499<\n0.428<\n0.357<\n0.285<\n0.214<\n0.143<\n0.071<\n0.000<\n\n150\n200\n\n1.000\n1.000\n0.996\n0.990\n0.973\n0.973\n0.971\n0.970\n0.967\n0.963\n0.961\n0.955\n0.954\n0.953\n0.948\n0.875<\n0.803<\n0.73<\n0.657<\n0.584<\n0.511<\n0.438<\n0.365<\n0.292<\n0.219<\n0.146<\n0.073<\n0.000<\n\n200\n\n1.000\n0.968\n0.956\n0.949\n0.925\n0.914\n0.908\n0.892\n0.880\n0.848\n0.848\n0.844\n0.837\n0.831\n0.826\n0.763<\n0.699<\n0.635<\n0.572<\n0.508<\n0.445<\n0.381<\n0.318<\n0.254<\n0.191<\n0.127<\n0.064<\n0.000<\n250\n\n1.000\n0.994\n0.994\n0.980\n0.974\n0.973\n0.965\n0.954\n0.953\n0.949\n0.942\n0.932\n0.915\n0.913\n0.913\n0.842<\n0.772<\n0.702<\n0.632<\n0.562<\n0.491<\n0.421<\n0.351<\n0.281<\n0.211<\n0.14<\n0.07<\n0.000<\n\n200\n\n1.000\n0.988\n0.972\n0.962\n0.962\n0.957\n0.948\n0.943\n0.939\n0.930\n0.922\n0.921\n0.918\n0.916\n0.908\n0.838<\n0.768<\n0.698<\n0.629<\n0.559<\n0.489<\n0.419<\n0.349<\n0.279<\n0.21<\n0.14<\n0.07<\n0.000<\n\n200\n\n1.000\n0.996\n0.982\n0.975\n0.962\n0.957\n0.954\n0.953\n0.935\n0.934\n0.930\n0.906\n0.904\n0.901\n0.897\n0.828<\n0.759<\n0.69<\n0.621<\n0.552<\n0.483<\n0.414<\n0.345<\n0.276<\n0.207<\n0.138<\n0.069<\n0.000<\n\n1.000\n0.995\n0.988\n0.986\n0.985\n0.980\n0.976\n0.975\n0.974\n0.963\n0.960\n0.960\n0.958\n0.957\n0.954\n0.88<\n0.807<\n0.734<\n0.66<\n0.587<\n0.514<\n0.44<\n0.367<\n0.293<\n0.22<\n0.147<\n0.073<\n0.000<\n\n0\n\n1.000\n0.999\n0.943\n0.932\n0.926\n0.923\n0.920\n0.912\n0.905\n0.889\n0.889\n0.875\n0.859\n0.857\n0.849\n0.783<\n0.718<\n0.653<\n0.588<\n0.522<\n0.457<\n0.392<\n0.326<\n0.261<\n0.196<\n0.131<\n0.065<\n0.000<\n\nFigure 6: Comparison of stochastic optimization algorithms. 10 problems f (x) = x| Fx\nwith fij \u223c C100 for i, j \u2208 [[1, 250]]\n300\n\n150\n\n100\n\n1\u2212opt local search\nSimulated annealing\nSMC symmetric\nSMC parametric\nCross\u2212entropy\n\n(b) r250c problem 02\n\n(d) r250c problem 04\n\n(f) r250c problem 06\n\n300\n\n250\n\n200\n\n150\n\n100\n\n50\n\n(h) r250c problem 08\n\n250\n\n200\n\n150\n\n(j) r250c problem 10\n\n\f0\n\n0\n\n150\n\n100\n\n120\n\n80\n\n40\n\n250\n\n150\n\n100\n\n(i) r250u problem 09\n\n26\n\n(a) r250u problem 01\n\n0\n\n(c) r250u problem 03\n\n0\n\n(e) r250u problem 05\n\n0\n\n(g) r250u problem 07\n\n0\n\n1.000\n0.943\n0.875\n0.841\n0.809\n0.766\n0.674\n0.663\n0.619\n0.608\n0.522\n0.512\n0.501\n0.488\n0.187\n0.096<\n0.005<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n\n0\n\n1.000\n0.887\n0.878\n0.843\n0.799\n0.746\n0.699\n0.681\n0.540\n0.418\n0.265\n0.263\n0.221\n0.217\n0.186\n0.095<\n0.003<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n\n50\n\n1.000\n0.997\n0.992\n0.988\n0.982\n0.982\n0.973\n0.968\n0.966\n0.965\n0.962\n0.959\n0.957\n0.955\n0.941\n0.869<\n0.796<\n0.724<\n0.651<\n0.579<\n0.507<\n0.434<\n0.362<\n0.29<\n0.217<\n0.145<\n0.072<\n0.000<\n\n1.000\n0.921\n0.884\n0.841\n0.835\n0.814\n0.692\n0.684\n0.672\n0.649\n0.633\n0.623\n0.610\n0.607\n0.601\n0.554<\n0.508<\n0.462<\n0.416<\n0.37<\n0.323<\n0.277<\n0.231<\n0.185<\n0.139<\n0.092<\n0.046<\n0.000<\n\n100\n\n1.000\n0.978\n0.950\n0.844\n0.839\n0.830\n0.827\n0.789\n0.782\n0.759\n0.756\n0.743\n0.742\n0.735\n0.724\n0.669<\n0.613<\n0.557<\n0.501<\n0.446<\n0.39<\n0.334<\n0.279<\n0.223<\n0.167<\n0.111<\n0.056<\n0.000<\n\n1.000\n0.984\n0.946\n0.943\n0.928\n0.918\n0.897\n0.895\n0.893\n0.862\n0.859\n0.856\n0.851\n0.851\n0.836\n0.772<\n0.708<\n0.643<\n0.579<\n0.515<\n0.45<\n0.386<\n0.322<\n0.257<\n0.193<\n0.129<\n0.064<\n0.000<\n\n150\n\n1.000\n0.997\n0.942\n0.884\n0.806\n0.738\n0.734\n0.733\n0.727\n0.721\n0.693\n0.692\n0.682\n0.678\n0.674\n0.622<\n0.57<\n0.519<\n0.467<\n0.415<\n0.363<\n0.311<\n0.259<\n0.207<\n0.156<\n0.104<\n0.052<\n0.000<\n\n350\n300\n250\n200\n150\n100\n50\n0\n1.000\n0.923\n0.894\n0.466\n0.398\n0.376\n0.288\n0.277\n0.233\n0.211\n0.176\n0.151\n0.140\n0.104\n0.069\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n\n0\n\n1.000\n0.984\n0.976\n0.974\n0.951\n0.930\n0.925\n0.918\n0.911\n0.908\n0.902\n0.900\n0.899\n0.892\n0.887\n0.819<\n0.75<\n0.682<\n0.614<\n0.546<\n0.478<\n0.409<\n0.341<\n0.273<\n0.205<\n0.136<\n0.068<\n0.000<\n\n0\n\n1.000\n0.987\n0.963\n0.962\n0.944\n0.942\n0.930\n0.927\n0.896\n0.888\n0.883\n0.880\n0.865\n0.822\n0.819\n0.679<\n0.539<\n0.399<\n0.259<\n0.119<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n0.000<\n\nFigure 7: Comparison of stochastic optimization algorithms. 10 problems f (x) = x| Fx\nwith fij \u223c U100 for i, j \u2208 [[1, 250]]\n350\n\n300\n\n250\n\n200\n\n150\n\n1\u2212opt local search\nSimulated annealing\nSMC symmetric\nSMC parametric\nCross\u2212entropy\n\n100\n50\n\n(b) r250u problem 02\n\n200\n\n150\n\n50\n100\n\n50\n\n(d) r250u problem 04\n\n150\n\n100\n\n50\n\n(f) r250u problem 06\n\n100\n150\n\n60\n100\n\n20\n50\n\n(h) r250u problem 08\n\n300\n\n200\n\n150\n\n100\n\n50\n\n50\n\n(j) r250u problem 10\n\n\f8.1 Logistic conditionals family\n8.1.1 Derivatives of the log-likelihood function\nThe log-likelihood function of the weighted logistic regression of y (i) := X\u2022i on Z(i) :=\n(X\u20221:i\u22121 , 1) is\nlog L(a) =\n\nn\nX\n\nh\ni\n(i)\n(i)\n(i)\n(i)\nwk yk log[`(zk\u2022 a)] + (1 \u2212 yk ) log[1 \u2212 `(zk\u2022 a)]\n\nk=1\n\n=\n\nn\nX\n\nh\ni\n(i) (i)\n(i)\nwk yk zk\u2022 a \u2212 log[1 + exp(zk\u2022 a)] ,\n\nk=1\n\nwhere we used that log[1 \u2212 `(x| a)] = \u2212 log[1 + exp(x| a)] = \u2212x| a + log[`(x| a)]. Since\n\u2202 log[1 + exp(x| a)]/\u2202a = `(x| a)x, the gradient of the log-likelihood is\ns(a) =\n\nn\nX\n\nh\ni\n(i) (i)\n(i)\n(i)\n(i)\nwk yk zk\u2022 \u2212 `(zk\u2022 a)zk\u2022 = (Z(i) )| diag(w)[y (i) \u2212 pa ],\n\nk=1\n(i)\n\n(i)\n\nwhere (pa )k := `(zk\u2022 a). Since \u2202`(x| a)/\u2202a = \u2212`(x| a)[1\u2212`(x| a)]x, the Hessian matrix\nof the log-likelihood is\n0\n\ns (a) = \u2212\n\nn\nX\n\nh\ni\n(i)\n(i)\n(i) (i)\n(i)\nwk `(zk\u2022 a)[1 \u2212 `(zk\u2022 a)] zk\u2022 (zk\u2022 )| = \u2212(Z(i) )| diag(w)diag(qa )Z(i) ,\n\nk=1\n(i)\n\n(i)\n\n(i)\n\nwhere (qa )k := `(zk\u2022 a)[1 \u2212 `(zk\u2022 a)].\n8.1.2 Complete separation\nThe data might suffer from complete or quasi-complete separation Albert and Anderson\n(1984) which causes the likelihood function L(a) to be monotonic. In that case there is\nno maximizer. We can avoid the monotonicity by assigning a suitable prior distribution\nto the parameter a. Firth (1993) recommends the Jeffreys prior for its bias reduction\nwhich can conveniently be implemented via data adjustment Kosmidis and Firth (2009).\nFor the sake of simplicity, however, we only assign a simple Gaussian prior with\nvariance \u03b5\u22121 > 0 such that, up to a constant, the log-posterior distribution is the loglikelihood function plus a quadratic penalty term and therefore always convex. The score\nfunction and its Jacobian matrix become\n(i)\n\ns(a) = (Z(i) )| diag(w)[y (i) \u2212 pa ] \u2212 \u03b5a,\n\n(i)\n\ns0 (a) = \u2212(Z(i) )| diag(w)diag(qa )Z(i) \u2212 \u03b5I.\n\nThe bias-reduced estimators are known to shrink towards 0.5 which is an undesired\nproperty when fitting a parametric family. Therefore, we attempt to keep the shrinkage\nparameter \u03b5 as small as possible.\n8.1.3 Newton-Raphson iterations\nThe first order condition s(a) = 0 is solved iteratively\na(t+1) = a(t) \u2212 [s0 (a(t) )]\u22121 s(a(t) ) = a(t) + x(t)\n\n27\n\n\fwhere x(t) is the vector that solves\nh\ni\nh\ni\n(i)\n(i)\n(Z(i) )| diag(w)diag(qa(t) )(Z(i) )| + \u03b5I x(t) = (Z(i) )| diag(w)[y (i) \u2212 pa(t) ] \u2212 \u03b5a(t) .\nIf the Newton iteration at the ith component fails to converge, we can either augment\nthe penalty term \u03b5 which leads to stronger shrinkage of the mean mi towards 0.5 or\nwe can drop some covariates \u03b3j for j \u2208 {1, . . . , i \u2212 1} from the iteration to improve the\nnumerical condition of the procedure.\nIn practice, we drop the predictors from the regression model which are only weakly\ncorrelated with the explained variable. This step is important to speed up the algorithm\nand improve its numerical properties. For a proposal distribution, it is particularly\nimportant to take the strong dependencies into account but it is often sufficient to work\nwith very sparse logistic conditionals families.\nIn particularly difficult cases, we might prefer to set aii = `\u22121 (x\u0304i ) and ai,1:i\u22121 = 0,\nwhere x\u0304i is defined in (18), which guarantees that at least the mean is correct. This is\nan important issue since misspecification of the mean of \u03b3i also affects the distribution\nof the components \u03b3j for j \u2208 {i + 1, . . . , d} which are sampled conditional on \u03b3i .\nAlgorithm 4: Fitting the weighted logistic regressions\nInput: X = (x1 , . . . , xn )| , w = (w1 , . . . , wn ), A \u2208 Rd\u00d7d\nfor i \u2208 [[1, d]] do\nZ \u2190 (X\u20221:i\u22121 , 1), y \u2190 X\u2022i , a(0) \u2190 Ai,1:i\nrepeat\npk \u2190 `(Zk\u2022 a(t) )\nfor all k \u2208 [[1, n]]\nqk \u2190 pk (1 \u2212 pk )\nfor all k \u2208 [[1, n]]\nh\ni\u22121\n\u00d7\na(t+1) \u2190 a(t) + (Z(i) )| diag[w]diag[q]Z(i) + \u03b5I\nh\ni\n(i) |\n(t)\n(Z ) diag[w] [y \u2212 p] \u2212 \u03b5a\nuntil ka(t+1) \u2212 a(t) k\u221e < \u03b4\nAi,1:i \u2190 a\nend\nreturn A\n\n8.2 Gaussian copula family\ngc by method of moments. We need to solve\nWe adjust the Gaussian copula family qa,\u03a3\nthe non-linear equations\n\n\u03a61 (ai ) = x\u0304i ,\n\n\u03a62 (ai , aj ; \u03c3ij ) = x\u0304ij ,\n\ni, j \u2208 [[1, d]],\n\n(19)\n\nwhere x\u0304i and x\u0304ij are defined in (18) while \u03a61 (vi ) and \u03a62 (vi , vj ; \u03c3ij ) denote the cumulative\ndistribution functions of the univariate and bivariate normal distributions with zero\nmean, unit variance and correlation coefficient \u03c3ij \u2208 [\u22121, 1].\nWhile the parameter ai = \u03a6\u22121\n1 (x\u0304i ) is easy to assess, the challenging task is to compute\nthe bivariate variances \u03c3ij for all i, j \u2208 [[1, d]]. Recall the standard result [(Johnson et al.,\n2002), p.255]\n\u2202\u03a62 (x1 , x2 ; \u03c3)\n= \u03c6(x1 , x2 ; \u03c3),\n(20)\n\u2202\u03c3\n\n28\n\n\fwhere \u03c6(*, *; \u03c3) denotes the density of the bivariate normal distribution with correlation\ncoefficient \u03c3. We obtain the following Newton-Raphson iteration\n(t)\n\n\u03c3\n\n(t+1)\n\n=\u03c3\n\n(t)\n\n\u2212\n\n\u03a62 (ai , aj ; \u03c3ij ) \u2212 x\u0304ij\n(t)\n\n,\n\n(21)\n\n\u03c6(ai , aj ; \u03c3ij )\n(0)\n\nstarting at some initial value \u03c3ij \u2208 (\u22121, 1); see Procedure 5. In the sequential Monte\nCarlo context, good initial values are obtained from the parameters of the previous\nauxiliary distributions.\nWe use a fast series approximation Drezner and Wesolowsky (1990) to evaluate \u03a62 (ai , aj ; \u03c3ij ).\nThese approximations are critical when \u03c3ij comes very close to either boundary of [\u22121, 1].\nThe Newton iteration might repeatedly fail when restarted at the corresponding bound(0)\nary \u03c3ij \u2208 {\u22121, 1}. In any event, \u03a62 (x1 , x2 ; \u03c3) is strictly monotonic in \u03c3 since its\nderivative (20) is positive, and we can switch to bi-sectional search if necessary.\nAlgorithm 5: Fitting the dependency matrix\nInput: x\u0304i , x\u0304ij for all i, j \u2208 [[1, d]]\nai \u2190 \u03a6\u22121 (x\u0304i ) for all i \u2208 [[1, d]]\n\u03a3(0) \u2190 I\nfor i, j \u2208 [[1, d]], i < j do\nrepeat\n(t)\n\n(t+1)\n\n\u03c3ij\n\n(t)\n\n\u2190 \u03c3ij \u2212\n\n(t+1)\n\nuntil |\u03c3ij\n\n\u03a62 (ai , aj ; \u03c3ij ) \u2212 x\u0304ij\n(t)\n\n\u03c6(ai , aj ; \u03c3ij )\n\n(t)\n\n\u2212 \u03c3ij | < \u03b4\n\n(t+1)\n\n\u03c3ji \u2190 \u03c3ij\n\nend\nif not \u03a3 \u001f 0 then \u03a3 \u2190 (\u03a3 + |\u03bb| I)/(1 + |\u03bb|)\nreturn a, \u03a3\n\nThe locally fitted correlation matrices \u03a3 might not be positive definite for d \u2265 3\nbecause the Gaussian copula is not flexible enough to model the full range of crossmoments binary distributions might have (see Sch\u00e4fer (2012) for an extended discussion).\nWe obtain a feasible parameter replacing \u03a3 by\n\u03a3\u2217 = (\u03a3 + |\u03bb| I)/(1 + |\u03bb|),\nwhere \u03bb is smaller than all eigenvalues of the locally fitted matrix \u03a3. This approach\nevenly lowers the local correlations to a feasible level and is easy to implement on standard software. In practice, we also prefer to work with a sparse version of the Gaussian\ncopula family that concentrates on strong dependencies and sets minor correlations to\nzero.\n\nReferences\nAlbert, A. and Anderson, J. A. (1984). On the existence of maximum likelihood estimates\nin logistic regression models. Biometrika, 72:1\u201310.\n\n29\n\n\fAlidaee, B., Kochenberger, G., and Wang, H. (2010). Theorems supporting r-flip search\nfor pseudo-Boolean optimization. International Journal of Applied Metaheuristic\nComputing (IJAMC), 1(1):93\u2013109.\nAmini, M., Alidaee, B., and Kochenberger, G. (1999). A scatter search approach to\nunconstrained quadratic binary programs. In New ideas in optimization, pages 317\u2013\n330. McGraw-Hill Ltd., UK.\nBeasley, J. (1990). OR-Library: Distributing test problems by electronic mail. Journal\nof the Operational Research Society, pages 1069\u20131072.\nBeasley, J. (1998). Heuristic algorithms for the unconstrained binary quadratic programming problem. Technical report, Management School, Imperial College London.\nBillionnet, A. and Sutter, A. (1994). Minimization of a quadratic pseudo-Boolean function. European Journal of Operational Research, 78(1):106\u2013115.\nBoros, E. and Hammer, P. (2002). Pseudo-Boolean optimization. Discrete Applied\nMathematics, 123(1-3):155\u2013225.\nBoros, E., Hammer, P., and Tavares, G. (2007). Local search heuristics for quadratic\nunconstrained binary optimization (QUBO). Journal of Heuristics, 13(2):99\u2013132.\nCarpenter, J., Clifford, P., and Fearnhead, P. (1999). Improved Particle Filter for nonlinear problems. IEE Proc. Radar, Sonar Navigation, 146(1):2\u20137.\nChopin, N. (2002). A sequential particle filter method for static models. Biometrika,\n89(3):539.\nDel Moral, P., Doucet, A., and Jasra, A. (2006). Sequential Monte Carlo samplers.\nJournal of the Royal Statistical Society: Series B (Statistical Methodology), 68(3):411\u2013\n436.\nDel Moral, P., Doucet, A., and Jasra, A. (2011). An adaptive sequential Monte Carlo\nmethod for approximate Bayesian computation. Statistics and Computing, to appear.\ndoi: 10.1007/s11222-011-9271-y.\nDrezner, Z. and Wesolowsky, G. O. (1990). On the computation of the bivariate normal\nintegral. Journal of Statistical Computation and Simulation, 35:101\u2013107.\nEmrich, L. and Piedmonte, M. (1991). A method for generating high-dimensional multivariate binary variates. The American Statistician, 45:302\u2013304.\nFearnhead, P. and Clifford, P. (2003). Online inference for hidden Markov models via\nparticle filters. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 65(4):887\u2013899.\nFirth, D. (1993). Bias reduction of maximum likelihood estimates. Biometrika, 80:27\u201338.\nGarey, M. and Johnson, D. (1979). Computers and Intractability: A Guide to the Theory\nof NP-completeness. WH Freeman & Co.\nGenz, A. and Bretz, F. (2009). Computation of multivariate normal and t probabilities,\nvolume 195. Springer.\n\n30\n\n\fGlover, F., Kochenberger, G., and Alidaee, B. (1998). Adaptive memory tabu search for\nbinary quadratic programs. Management Science, 44:336\u2013345.\nGordon, N. J., Salmond, D. J., and Smith, A. F. M. (1993). Novel approach to\nnonlinear/non-Gaussian Bayesian state estimation. IEE Proc. Radar, Sonar Navigation, 140(2):107\u2013113.\nGueye, S. and Michelon, P. (2009). A linearization framework for unconstrained\nquadratic (0-1) problems. Discrete Applied Mathematics, 157(6):1255\u20131266.\nHansen, P. and Meyer, C. (2009). Improved compact linearizations for the unconstrained\nquadratic 0-1 minimization problem. Discrete Applied Mathematics, 157(6):1267\u20131290.\nHasan, M., AlKhamis, T., and Ali, J. (2000). A comparison between simulated annealing,\ngenetic algorithm and tabu search methods for the unconstrained quadratic PseudoBoolean function. Computers & Industrial Engineering, 38(3):323\u2013340.\nJasra, A., Stephens, D., Doucet, A., and Tsagaris, T. (2011). Inference for L\u00e9vy-Driven\nStochastic Volatility Models via Adaptive Sequential Monte Carlo. Scandinavian Journal of Statistics.\nJoe, H. (1996). Families of m-variate distributions with given margins and m (m-1)/2\nbivariate dependence parameters. Lecture Notes-Monograph Series, 28:120\u2013141.\nJohansen, A., Moral, P. D., and Doucet, A. (2006). Sequential Monte Carlo samplers\nfor rare events. In Proceedings of the 6th International Workshop on Rare Event\nSimulation, pages pp. 256\u2013267.\nJohnson, N., Kotz, S., and Balakrishnan, N. (2002). Continuous multivariate distributions - models and applications, volume 2. New York: John Wiley & Sons,.\nKatayama, K. and Narihisa, H. (2001). Performance of Simulated Annealing-based\nheuristic for the unconstrained binary quadratic programming problem. E. J. of Operational Research, 134(1):103\u2013119.\nKirkpatrick, S., Gelatt, C., and Vecchi, M. (1983). Optimization by simulated annealing.\nScience, 220(4598):671.\nKitagawa, G. (1996). Monte Carlo filter and smoother for non-Gaussian nonlinear state\nspace models. Journal of computational and graphical statistics, 5(1):1\u201325.\nKong, A., Liu, J. S., and Wong, W. H. (1994). Sequential imputation and Bayesian\nmissing data problems. Journal of the American Statistical Association, 89:278\u2013288.\nKosmidis, I. and Firth, D. (2009). Bias reduction in exponential family nonlinear models.\nBiometrika, 96(4):793\u2013804.\nKozlov, M., Tarasov, S., and Khachiyan, L. (1979). Polynomial solvability of convex\nquadratic programming. In Soviet Mathematics Doklady, volume 20, pages 1108\u20131111.\nLiu, J. and Chen, R. (1998). Sequential Monte Carlo methods for dynamic systems.\nJournal of the American Statistical Association, 93(443):1032\u20131044.\n\n31\n\n\fMerz, P. and Freisleben, B. (1999). Genetic algorithms for binary quadratic programming. In Proceedings of the genetic and evolutionary computation conference, volume 1, pages 417\u2013424. Citeseer.\nMerz, P. and Freisleben, B. (2002). Greedy and local search heuristics for unconstrained\nbinary quadratic programming. Journal of Heuristics, 8(2):197\u2013213.\nMerz, P. and Katayama, K. (2004). Memetic algorithms for the unconstrained binary\nquadratic programming problem. BioSystems, 78(1-3):99\u2013118.\nNott, D. and Kohn, R. (2005). Adaptive sampling for Bayesian variable selection.\nBiometrika, 92(4):747.\nPalubeckis, G. (1995). A heuristic-based branch and bound algorithm for unconstrained\nquadratic zero-one programming. Computing, 54(4):283\u2013301.\nPalubeckis, G. (2004). Multistart tabu search strategies for the unconstrained binary\nquadratic optimization problem. Annals of Operations Research, 131(1):259\u2013282.\nPardalos, P. (1991). Construction of test problems in quadratic bivalent programming.\nACM Transactions on Mathematical Software (TOMS), 17(1):74\u201387.\nPardalos, P. and Rodgers, G. (1990). Computational aspects of a branch and bound\nalgorithm for quadratic zero-one programming. Computing, 45(2):131\u2013144.\nPoljak, S. and Wolkowicz, H. (1995). Convex relaxations of (0, 1)-quadratic programming. Mathematics of Operations Research, pages 550\u2013561.\nRobert, C. and Casella, G. (2004). Monte Carlo statistical methods. Springer Verlag.\nRubinstein, R. Y. (1997). Optimization of computer simulation models with rare events.\nEuropean Journal of Operations Research, 99:89\u2013112.\nRubinstein, R. Y. and Kroese, D. P. (2004). The Cross-Entropy Method: A unified approach to combinatorial optimization, Monte-Carlo simulation, and Machine Learning.\nSpringer-Verlag.\nSch\u00e4fer, C. (2010).\narXiv:1008.0055.\n\nParametric families on binary spaces.\n\nTechnical report.\n\nSch\u00e4fer, C. (2012). On parametric families for sampling binary data with specified mean\nand correlation. Technical report. arXiv:1111.0576.\nSch\u00e4fer, C. and Chopin, N. (2011). Sequential Monte Carlo on large binary sampling\nspaces. Statistics and Computing, to appear. doi: 10.1007/s11222\u2013011\u20139299\u2013z.\n\n32\n\n\f"}