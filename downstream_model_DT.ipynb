{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Of Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install transformers\n",
    "#!pip install torch\n",
    "#!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\derek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import requests\n",
    "import io\n",
    "import json\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import html\n",
    "from collections import defaultdict, Counter\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import ngrams\n",
    "from rouge_score import rouge_scorer\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "from transformers import PegasusTokenizer, TFPegasusForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import tensorflow\n",
    "import sentencepiece\n",
    "\n",
    "sns.set_style(\"dark\")\n",
    "plot_dims = (16, 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./data/aan_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load our 10k data into a dataframe\n",
    "papers = []\n",
    "filenames = [] #keep a reference for later transformations\n",
    "\n",
    "abstracts, bodys, cits =[],[],[]\n",
    "\n",
    "for root, dirs, files in os.walk(DATASET_PATH):\n",
    "    for f in files:\n",
    "        fn = root+\"/\"+f\n",
    "        if \"abstract\" in fn:            \n",
    "            in_file = open(fn, 'r')\n",
    "            file = in_file.readlines()\n",
    "\n",
    "            new_list = [''.join(file[i*4:(i+1)*4]) for i in range(int(len(file)/4))]\n",
    "            list_no_n = [item.replace('\\n','') for item in new_list]\n",
    "\n",
    "            string = ''\n",
    "            for item in list_no_n:\n",
    "                string = string + item            \n",
    "            abstracts.append(string)\n",
    "            \n",
    "        elif \"body\" in fn:\n",
    "            in_file = open(fn, 'r')\n",
    "            file = in_file.readlines()\n",
    "\n",
    "            new_list = [''.join(file[i*4:(i+1)*4]) for i in range(int(len(file)/4))]\n",
    "            list_no_n = [item.replace('\\n','') for item in new_list]\n",
    "\n",
    "            string = ''\n",
    "            for item in list_no_n:\n",
    "                string = string + item            \n",
    "            bodys.append(string)\n",
    "        \n",
    "        elif \"CS\" in fn:\n",
    "            in_file = open(fn, 'r')\n",
    "            file = in_file.readlines()\n",
    "            string = [''.join(file) for i in file]\n",
    "            if len(string) > 0: \n",
    "                string = [''.join(file) for i in file][0].replace('\\n','')\n",
    "            cits.append(string)\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #    with open(fn) as jsonfile:\n",
    "    #        d = json.load(jsonfile)\n",
    "    #    papers.append(d)\n",
    "    #    filenames.append(f)\n",
    "\n",
    "df = pd.DataFrame({'Abstract':abstracts,'Body':bodys,'Citations':cits})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Body</th>\n",
       "      <th>Citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A major obstacle to the construction ofa pro...</td>\n",
       "      <td>Parallel texts have been used in a number of...</td>\n",
       "      <td>A compilation of parallel texts offered in a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This paper proposes a way to improve the tran...</td>\n",
       "      <td>Recently, various dialogue translation syste...</td>\n",
       "      <td>We plan to improve the accuracy obtained so fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This paper describes an application of APE (t...</td>\n",
       "      <td>The purpose of the Atlas project is to enlarg...</td>\n",
       "      <td>Computer dialogue is now used at production st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this paper we describe an implemented fram...</td>\n",
       "      <td>In this paper we present a linguistically mot...</td>\n",
       "      <td>From this viewpoint, research on paraphrasing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This paper reports on a large-scale, end-to- ...</td>\n",
       "      <td>One major goal of information extraction (IE)...</td>\n",
       "      <td>For example, Aone and Ramos-Santacruz (2000) p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>We present in this paper an unsupervised meth...</td>\n",
       "      <td>Development of electronic morphological resou...</td>\n",
       "      <td>Next along the spectrum of orthographic simila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>This paper presents an unsupervised method fo...</td>\n",
       "      <td>Choosing the correct translation of a content...</td>\n",
       "      <td>For comparable corpora, previous bilingual sen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>In this paper we report on an unsupervised a...</td>\n",
       "      <td>In this paper we discuss a potential solutio...</td>\n",
       "      <td>Watkinson and Manandhar (1999) present an unsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>This paper presents results from a study comp...</td>\n",
       "      <td>In evaluating the state of technology for ext...</td>\n",
       "      <td>It may be noted that \"correctly\" is a problema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>Over the past few years, HNC has developed a ...</td>\n",
       "      <td>While the current MatchPlus learning law has ...</td>\n",
       "      <td>As such a matrix reduction, we utilized a lear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4273 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Abstract  \\\n",
       "0       A major obstacle to the construction ofa pro...   \n",
       "1      This paper proposes a way to improve the tran...   \n",
       "2      This paper describes an application of APE (t...   \n",
       "3      In this paper we describe an implemented fram...   \n",
       "4      This paper reports on a large-scale, end-to- ...   \n",
       "...                                                 ...   \n",
       "4268   We present in this paper an unsupervised meth...   \n",
       "4269   This paper presents an unsupervised method fo...   \n",
       "4270    In this paper we report on an unsupervised a...   \n",
       "4271   This paper presents results from a study comp...   \n",
       "4272   Over the past few years, HNC has developed a ...   \n",
       "\n",
       "                                                   Body  \\\n",
       "0       Parallel texts have been used in a number of...   \n",
       "1       Recently, various dialogue translation syste...   \n",
       "2      The purpose of the Atlas project is to enlarg...   \n",
       "3      In this paper we present a linguistically mot...   \n",
       "4      One major goal of information extraction (IE)...   \n",
       "...                                                 ...   \n",
       "4268   Development of electronic morphological resou...   \n",
       "4269   Choosing the correct translation of a content...   \n",
       "4270    In this paper we discuss a potential solutio...   \n",
       "4271   In evaluating the state of technology for ext...   \n",
       "4272   While the current MatchPlus learning law has ...   \n",
       "\n",
       "                                              Citations  \n",
       "0     A compilation of parallel texts offered in a s...  \n",
       "1     We plan to improve the accuracy obtained so fa...  \n",
       "2     Computer dialogue is now used at production st...  \n",
       "3     From this viewpoint, research on paraphrasing ...  \n",
       "4     For example, Aone and Ramos-Santacruz (2000) p...  \n",
       "...                                                 ...  \n",
       "4268  Next along the spectrum of orthographic simila...  \n",
       "4269  For comparable corpora, previous bilingual sen...  \n",
       "4270  Watkinson and Manandhar (1999) present an unsu...  \n",
       "4271  It may be noted that \"correctly\" is a problema...  \n",
       "4272  As such a matrix reduction, we utilized a lear...  \n",
       "\n",
       "[4273 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = [\n",
    "     \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
    "]\n",
    "\n",
    "model_name = 'google/pegasus-xsum'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"California's largest electricity provider has turned off power to hundreds of thousands of customers.\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Pretrain\n",
    "\n",
    "# AAN PEGASUS-XSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 : 0.75\n",
      "rouge2 : 0.2857142857142857\n",
      "rougeL : 0.625\n",
      "rougeLsum : 0.625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1','rouge2', 'rougeL','rougeLsum'], use_stemmer=True)\n",
    "scores = scorer.score('The quick brown fox jumps over the lazy dog',\n",
    "                      'The quick brown dog jumps on the log.')\n",
    "for k in scores:\n",
    "    score = scores[k]\n",
    "    print(\"{} : {}\".format(k,score[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" In this paper, we propose a method for ex- tracting key paragraphs in articles based on the degree of context dependency. Like Luhn's technique, our method assumes that the words related to theme in an arti- cle appear throughout paragraphs. Our ex- traction technique of keywords is based on the degree of context dependency that how strongly a word is related to a given con- text. The results of experiments demon- strate the applicability of our proposed \""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Abstract[136]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "11\n",
      "21\n",
      "31\n",
      "41\n",
      "51\n",
      "61\n",
      "71\n",
      "81\n",
      "91\n",
      "101\n",
      "111\n",
      "121\n",
      "131\n",
      "141\n",
      "151\n",
      "161\n",
      "171\n",
      "181\n",
      "191\n",
      "201\n",
      "211\n",
      "221\n",
      "231\n",
      "241\n",
      "251\n",
      "261\n",
      "271\n",
      "281\n",
      "291\n",
      "301\n",
      "311\n",
      "321\n",
      "331\n",
      "341\n",
      "351\n",
      "361\n",
      "371\n",
      "381\n",
      "391\n",
      "401\n",
      "411\n",
      "421\n",
      "431\n",
      "441\n",
      "451\n",
      "461\n",
      "471\n",
      "481\n",
      "491\n",
      "501\n",
      "511\n",
      "521\n",
      "531\n",
      "541\n",
      "551\n",
      "561\n",
      "571\n",
      "581\n",
      "591\n",
      "601\n",
      "611\n",
      "621\n",
      "631\n",
      "641\n",
      "651\n",
      "661\n",
      "671\n",
      "681\n",
      "691\n",
      "701\n",
      "711\n",
      "721\n",
      "731\n",
      "741\n",
      "751\n",
      "761\n",
      "771\n",
      "781\n",
      "791\n",
      "801\n",
      "811\n",
      "821\n",
      "831\n",
      "841\n",
      "851\n",
      "861\n",
      "871\n",
      "881\n",
      "891\n",
      "901\n",
      "911\n",
      "921\n",
      "931\n",
      "941\n",
      "951\n",
      "961\n",
      "971\n",
      "981\n",
      "991\n",
      "1001\n",
      "1011\n",
      "1021\n",
      "1031\n",
      "1041\n",
      "1051\n",
      "1061\n",
      "1071\n",
      "1081\n",
      "1091\n",
      "1101\n",
      "1111\n",
      "1121\n",
      "1131\n",
      "1141\n",
      "1151\n",
      "1161\n",
      "1171\n",
      "1181\n",
      "1191\n",
      "1201\n",
      "1211\n",
      "1221\n",
      "1231\n",
      "1241\n",
      "1251\n",
      "1261\n",
      "1271\n",
      "1281\n",
      "1291\n",
      "1301\n",
      "1311\n",
      "1321\n",
      "1331\n",
      "1341\n",
      "1351\n",
      "1361\n",
      "1371\n",
      "1381\n",
      "1391\n",
      "1401\n",
      "1411\n",
      "1421\n",
      "1431\n",
      "1441\n",
      "1451\n",
      "1461\n",
      "1471\n",
      "1481\n",
      "1491\n",
      "1501\n",
      "1511\n",
      "1521\n",
      "1531\n",
      "1541\n",
      "1551\n",
      "1561\n",
      "1571\n",
      "1581\n",
      "1591\n",
      "1601\n",
      "1611\n",
      "1621\n",
      "1631\n",
      "1641\n",
      "1651\n",
      "1661\n",
      "1671\n",
      "1681\n",
      "1691\n",
      "1701\n",
      "1711\n",
      "1721\n",
      "1731\n",
      "1741\n",
      "1751\n",
      "1761\n",
      "1771\n",
      "1781\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-27dded12182b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mk\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'longest'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtranslated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mtgt_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, **model_kwargs)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_encoder_decoder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m             )\n\u001b[1;32m-> 1044\u001b[1;33m             return self.beam_search(\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, **model_kwargs)\u001b[0m\n\u001b[0;32m   1717\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1719\u001b[1;33m             outputs = self(\n\u001b[0m\u001b[0;32m   1720\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1721\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1264\u001b[0m                 )\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         outputs = self.model(\n\u001b[0m\u001b[0;32m   1267\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[0;32m   1152\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, encoder_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1013\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1015\u001b[1;33m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[0;32m   1016\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, encoder_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[1;31m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(\n\u001b[0m\u001b[0;32m    438\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[0mkey_value_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;31m# cross_attentions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_value_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[0mvalue_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_value_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[1;31m# reuse k, v, self_attention\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "summaries = []\n",
    "k=0\n",
    "for i in df.Body:\n",
    "    k+=1\n",
    "    batch = tokenizer(i, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    translated = model.generate(**batch)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    \n",
    "    f = open('aan_data_xsum_summaries_r1.csv','a')\n",
    "    f.write(tgt_text[0])\n",
    "    f.write('\\n') \n",
    "    f.close()\n",
    "    \n",
    "    summaries.append(tgt_text)\n",
    "    if k % 10 == 1:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1781"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Text-to-speech (MT) systems have been around since the 1970s, but their performance has been poor.'],\n",
       " ['The aim of this paper is to identify the central factors that in- fluence pronominalization across genres.'],\n",
       " ['The aim of this project is to develop methods for segmenting written text in a collection to improve information retrieval.'],\n",
       " ['We present a word-for-word glossing algorithm that requires only a source language corpus.'],\n",
       " ['We have developed a language model that combines syntactic, semantic, and domain knowledge.'],\n",
       " ['dependency analysis is one of the most popular approaches to syntactic analysis in many languages.'],\n",
       " ['parsing and machine translation of low density languages are often in short supply.'],\n",
       " ['In this paper, we study a learning approach that is specifically tailored for problems in which the potential number of features is very large but only a fairly small number of them actually participates in the decision.'],\n",
       " ['We have developed a statistical system to automatically identify inappropriate usage of specific vocabulary words in essays by looking at the local contextual cues around a target word.'],\n",
       " ['In this paper, we propose a method for detecting errors in a marked cor- pus using an anomaly detection technique.']]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[29:39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This method was shown to be a generalization of the reference distribution method (Johnson and Riezler, 2000). Johnson and Riezler (2000) suggested the possibility of the method for adapting a stochastic unification-based grammar including HPSG to another domain. This model is introduced as a reference distribution (Jelinek, 1998; Johnson and Riezler, 2000) of the probabilistic HPSG model; i.e., the computation of parse trees given low probabilities by the model is omitted in the estimation stage (Miyao and Tsujii, 2005), or a probabilistic model can be augmented by several distributions estimated from the larger and simpler corpus (Johnson and Riezler, 2000). Johnson and Riezler (2000) achieved a gain of 1% over this result by including a classbased lexicalization. Johnson and Riezler (2000) looked at adding features to a maximum entropy model for stochastic unification-based grammars (SUBG), from corpora that are not annotated with the SUBG, but rather with simpler treebank annotations for which there are much larger treebanks. '"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Citations[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "11\n",
      "21\n",
      "31\n",
      "41\n",
      "51\n",
      "61\n",
      "71\n",
      "81\n",
      "91\n",
      "101\n",
      "111\n",
      "121\n",
      "131\n",
      "141\n",
      "151\n",
      "161\n",
      "171\n",
      "181\n",
      "191\n",
      "201\n",
      "211\n",
      "221\n",
      "231\n",
      "241\n",
      "251\n",
      "261\n",
      "271\n",
      "281\n",
      "291\n",
      "301\n",
      "311\n",
      "321\n",
      "331\n",
      "341\n",
      "351\n",
      "361\n",
      "371\n",
      "381\n",
      "391\n",
      "401\n",
      "411\n",
      "421\n",
      "431\n",
      "441\n",
      "451\n",
      "461\n",
      "471\n",
      "481\n",
      "491\n",
      "501\n",
      "511\n",
      "521\n",
      "531\n",
      "541\n",
      "551\n",
      "561\n",
      "571\n",
      "581\n",
      "591\n",
      "601\n",
      "611\n",
      "621\n",
      "631\n",
      "641\n",
      "651\n",
      "661\n",
      "671\n",
      "681\n",
      "691\n",
      "701\n",
      "711\n",
      "721\n",
      "731\n",
      "741\n",
      "751\n",
      "761\n",
      "771\n",
      "781\n",
      "791\n",
      "801\n",
      "811\n",
      "821\n",
      "831\n",
      "841\n",
      "851\n",
      "861\n",
      "871\n",
      "881\n",
      "891\n",
      "901\n",
      "911\n",
      "921\n",
      "931\n",
      "941\n",
      "951\n",
      "961\n",
      "971\n",
      "981\n",
      "991\n",
      "1001\n",
      "1011\n",
      "1021\n",
      "1031\n",
      "1041\n",
      "1051\n",
      "1061\n",
      "1071\n",
      "1081\n",
      "1091\n",
      "1101\n",
      "1111\n",
      "1121\n",
      "1131\n",
      "1141\n",
      "1151\n",
      "1161\n",
      "1171\n",
      "1181\n",
      "1191\n",
      "1201\n",
      "1211\n",
      "1221\n",
      "1231\n",
      "1241\n",
      "1251\n",
      "1261\n",
      "1271\n",
      "1281\n",
      "1291\n",
      "1301\n",
      "1311\n",
      "1321\n",
      "1331\n",
      "1341\n",
      "1351\n",
      "1361\n",
      "1371\n",
      "1381\n",
      "1391\n",
      "1401\n",
      "1411\n",
      "1421\n",
      "1431\n",
      "1441\n",
      "1451\n",
      "1461\n",
      "1471\n",
      "1481\n",
      "1491\n",
      "1501\n",
      "1511\n",
      "1521\n",
      "1531\n",
      "1541\n",
      "1551\n",
      "1561\n",
      "1571\n",
      "1581\n",
      "1591\n",
      "1601\n",
      "1611\n",
      "1621\n",
      "1631\n",
      "1641\n",
      "1651\n",
      "1661\n",
      "1671\n",
      "1681\n",
      "1691\n",
      "1701\n",
      "1711\n",
      "1721\n",
      "1731\n",
      "1741\n",
      "1751\n",
      "1761\n",
      "1771\n",
      "1781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['A parallel corpus is a collection of parallel texts offered in a serviceable form.'],\n",
       " ['The use of \"polite\" people for dialogue translation has been proposed as a way to improve the accuracy of translation systems.'],\n",
       " ['We have developed a dialogue management system for intelligent tutoring systems called Atlas.'],\n",
       " ['This paper presents a corpus-based technique for paraphrasing Korean phrases and sentences into English structures.'],\n",
       " ['In this paper, we introduce a new type of information extraction system for extracting relations and events.'],\n",
       " ['Mixed-initiative dialogue systems (MIMIC) have been proposed as an alternative to directed dialog systems.'],\n",
       " ['The goal of this paper is to improve the performance of spoken dialogue systems.'],\n",
       " ['A formal representation language for natural language generation systems has been proposed in this paper.'],\n",
       " ['A prototype of a computer aided translation tool has been developed in our laboratory.'],\n",
       " ['The goal of this paper is to develop a machine translation system that predicts which words a human translator will type next, based on the source text under translation and some prefix of the target text that has already been typed.'],\n",
       " ['This paper presents a novel approach to anaphora/coreference resolution on English and Romanian language texts.'],\n",
       " ['This paper presents a reimplementation of the query-selection system described in Prager et al.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Sharmila Tagore looks at the role of natural language in information retrieval.'],\n",
       " ['Decision trees have been used to identify common nouns, pronouns, and various types of names.'],\n",
       " [\"An open-ended question-answering system that allows users to pose questions of any type and in any language, without domain restrictions, remains beyond the scope of today's text-processing systems.\"],\n",
       " ['The aim of this project is to extract information about chemokines from biomedical literature that draws on a tagger (see Cutting et al.'],\n",
       " ['Expressive grammar formalisms have come a long way in recent decades.'],\n",
       " ['The ro- bust lexicon problem is one of the most challenging natural language processing problems.'],\n",
       " ['Part-of-speech (PoS) and part-of-speech (PTB) taggers are widely used in machine learning.'],\n",
       " ['The morphology of anguage, a type of seaweed, has been the subject of much controversy.'],\n",
       " ['Text-based information extraction is one of the fastest growing areas of research in computer science.'],\n",
       " ['Tagging named entities using gazetteer lists is one of the most computationally intensive tasks in document processing.'],\n",
       " ['An Entity Indexing project has been evaluated from a single user perspective.'],\n",
       " ['Dependency relations have been found to be useful in information extraction (Culotta and Sorensen, 2004; Yangarber et al.'],\n",
       " ['A number of Natural Language Recognition (NER) systems have been proposed and tested.'],\n",
       " ['The ability to answer specific questions is a foundation for improving information-retrieval systems.'],\n",
       " ['In this paper, we investigate the use of sentence simplification systems to produce summaries from extracted sentences.'],\n",
       " ['The performance of named entity extraction systems on online text has been investigated.'],\n",
       " ['The expectation of denial (DofE) is an important feature of any discourse management system.'],\n",
       " ['In this paper, we show that rhetorical tree-to-speech (RST) systems can improve the performance of text-to-speech systems.'],\n",
       " ['Pronominalisation is an area of research that has received little attention in the literature.'],\n",
       " ['This paper presents the results of the LetSum Thematic segmentation project.'],\n",
       " ['A word-for-word glossing algorithm based on the Moby Thesaurus has been proposed.'],\n",
       " ['We have trained a speech recognition system on a corpus of Wall Street Journal (WSJ) news articles.'],\n",
       " ['In this paper, a syntactic analysis of Japanese subordinate clauses is presented.'],\n",
       " ['Machine translation of text has become an increasingly important part of Q&A applications.'],\n",
       " ['The prediction of all-words is one of the most challenging problems in machine learning.'],\n",
       " ['In this paper, we study the problem of grammar errors in essays written by non-native learners of English.'],\n",
       " ['corpus error detection is an important problem in corpus linguistics.'],\n",
       " ['A number of methods have been proposed for \"unification-based grammars\".'],\n",
       " ['We present a new method for the generation of dependency trees.'],\n",
       " ['The goal of automatic summaries is to produce summaries that are as concise and coherent as human-written abstracts.'],\n",
       " ['The acoustic features of spoken lan- guage have been the subject of a number of papers in recent years.'],\n",
       " ['This paper presents a natural language generator designed to generate news stories from the Wall Street Journal (WSJ) corpus.'],\n",
       " ['A spoken dialogue system that automatically adapts dia- logue strategies is presented.'],\n",
       " ['The aim of this paper is to investigate the use of artificial intelligence (AI) to predict problems in spoken dialogue interaction.'],\n",
       " ['The aim of this paper is to investigate the role of prosody in speech recognition.'],\n",
       " ['Information extraction is one of the most challenging tasks in machine learning.'],\n",
       " ['In this paper, we present a new method for assigning function tags to constituents identified by the Penn treebank.'],\n",
       " ['In our series of letters from around the world, we look at word segmentation in Japanese.'],\n",
       " ['The size of context-free grammars has been a major issue in the field of machine learning.'],\n",
       " ['diathesis alternations in corpus-based NLP tasks 4.2 Verb Selection We evaluate our method on the causative alternation in order for comparison to the earlier method of McCarthy (2000).'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmed Rashid looks at the role of sentence boundary disam-biguators in text processing.'],\n",
       " ['In this paper, we investigate a parsing algorithm for a class of probabilistic grammars that, in their probabilistic versions, have been widely adopted as real language models.'],\n",
       " ['The role of acknowledgments andpoliteness in human-human dialogue has been hotly debated.'],\n",
       " ['Natural language reduplication is an important problem in the study of morphology.'],\n",
       " ['A new method for converting graphemes to phoneme strings has been proposed.'],\n",
       " ['The aim of this paper is to investigate the semantics of the verb \"to deliver\".'],\n",
       " ['This paper presents the open problems and what we have learned as did the EUFID group when they accomplished their system (Templeton, Burger 1983).'],\n",
       " ['We have developed a system for critiquing written material on points of grammar and style.'],\n",
       " ['Sentence fragments and ill-formedness have been studied in a number of areas.'],\n",
       " ['The LRC Machine Translation System uses a \"phrasal analysis\" technique to construct a \"phrasal analysis\" of ungrammatical input.'],\n",
       " ['The aim of this paper is to show how natural language processing techniques can be used to improve the processing of news reports.'],\n",
       " ['The anaphora resolution system proposed in this paper is based on the syntax-based Lucy system.'],\n",
       " ['The Department of Computer Science and Engineering at the University of California, Los Angeles, has a long tradition of research in the area of natural language processing.'],\n",
       " ['The problem of representing scope ambiguities in natural language understanding systems is addressed in this paper.'],\n",
       " ['Text-free grammars are increasingly being used in computer programming.'],\n",
       " ['A set of tools and grammars for creating a lexical data base representation (LDB) for lexical information, a set of tools and grammars for converting machine readable dictionary (MRD) type- setting tapes to the LDB representation, and a set of tools and grammars for specifying a Lexical Query'],\n",
       " ['Thesaurus information has been used to improve information retrieval systems for many years.'],\n",
       " ['The aim of this work is to develop a text-processing system that is easy to learn and easy to use.'],\n",
       " [\"We have received a grant from the National Institute of Standards and Technology's (NIA) National Science Foundation (NSF) to develop a new kind of query language for on-line dictionaries.\"],\n",
       " ['A natural language interface to a knowledge base has been proposed and developed over the past 30 years.'],\n",
       " ['In this paper, we propose a new approach to processing large-scale natural language sentences by applying a set of meta rules.'],\n",
       " ['The goal of this paper is to develop an artificial intelligence system that can identify the correct names of vehicles.'],\n",
       " ['In the 1980s and 1990s, a large number of papers were published in the fields of word segmentation and part-of-speech analysis.'],\n",
       " ['The two-level morphology of Slocum (1988) is represented by the so-called paradigm matrix of Humor systems.'],\n",
       " ['We present a new approach to the problem of syntactic ambiguity.'],\n",
       " ['combinatorial problems in natural language processing.'],\n",
       " ['In our previous papers we have proposed a new design paradigm for the connection of two or more pieces of pipe, one of which is a polypropylene (PP) pipe and the other a polyethylene (PE) pipe.'],\n",
       " ['Abductive inference has a long history in plan recognition, text understanding and discourse processing.'],\n",
       " ['A number of graphical models have been proposed for the presentation of 3D images.'],\n",
       " ['A natural language-based interface to information systems is the aim of this paper.'],\n",
       " ['A number of approaches have been proposed in the area of machine read- able dictionaries.'],\n",
       " [\"The ACQUILI'X l,exicon l)evelopment Environmen| is a large scale lexicon which can be used by Natural Language Processing (NLP) systems.\"],\n",
       " ['The relationship between word relations in computational lexicons is well known.'],\n",
       " ['The aim of this paper is to provide an overview of the current state-of-the-art in statistics-based methods for learning linguistic requirements.'],\n",
       " ['The purpose of this paper is to present the results of the DILEMMA-2 project, which aims to develop a Translational Language (T/L) for medical English.'],\n",
       " ['Natural anguage processing systems can provide cost-effective solutions to business problems.'],\n",
       " ['In our last paper we looked at the design of a system that can extract information from large amounts of text.'],\n",
       " ['The problem of anaphoral resolution in machine translation systems has been reported by Nakaiwa and Ikehara, Nakaiwa and Ikehara, Nakalwa and Ikehara, Nakaiwa and Ikehara, Nakaiwa and Ikehara, Nakaiwa and Ikehara, Nakaiwa and Ikehara, Nakaiwa and Ike'],\n",
       " ['This paper presents two prototypes of dialogue management software, one in English and one in French.'],\n",
       " ['We have developed a number of statistical systems for the management of telecommunications equipment.'],\n",
       " ['In this paper we consider the problem of deterring the use of word shape tokens as part of language identification.'],\n",
       " ['We have been investigating the use of word shape tokens for document content identification since the 1990s.'],\n",
       " ['Syntactic analysis of English coordinate sentences is one of the most difficult problems for machine translation (MT) systems.'],\n",
       " ['Part-of-speech disambiguators have been proposed as a means of resolving ambiguity in speech.'],\n",
       " ['We train part-of-speech taggers without the need for a manually annotated corpus.'],\n",
       " ['The corpus of knowledge is one of the most important sources of information in computer science.'],\n",
       " ['In this paper, we aim to develop a system which automatically learns grammars based on parsing failures and which can be used as a tool for linguistic knowledge.'],\n",
       " ['Sentence boundaries have been used to improve the navigation of documents for many years.'],\n",
       " ['We present a novel approach to machine translation, which combines multiple machine translations through a Multi-Engine MT architecture.'],\n",
       " ['A anguage is a form of speech in which the speaker makes an ill-formed utterance.'],\n",
       " ['This paper presents a new method for extracting the meaning of words in French.'],\n",
       " ['Morphology-based point-of-service (POS) taggers have been proposed and tested in a number of languages.'],\n",
       " ['Itowevcr is a natural language processing system for the processing of medical discharge summaries.'],\n",
       " ['The homophone problem is one of the major problems in Japanese computer science.'],\n",
       " ['A probabilistic model for automatic text categorization has been proposed.'],\n",
       " [\"The aim of this paper is to investigate the use of the term 'term-based information retrieval' to describe the process of retrieving documents from large databases.\"],\n",
       " ['This paper describes the development and use of the Forecast Generator (FoG) at Environment Canada.'],\n",
       " ['Part-of-speech recognition has been a promising area of research for many years.'],\n",
       " ['It is a difficult case even for sentence boundary  systerns which are built for exactly that purpose, i.e., to decide whether a capitalized word which follows an abbreviation is attached it or whether there is a sentence boundary between them.'],\n",
       " ['A temporal annotation scheme ( SMES) for scheduling agents has been proposed.'],\n",
       " ['Table 2: Features ranked in 6 DMSs Feature A B C D E F G Eli 2 1 1 2 3 2 2 2 [3] 2 1 1 3 1 1 1 [4] 1 1 1 6 2 [5] 3 6 5 3 2 [6] 3 5 5 5 5.'],\n",
       " ['We have been working on the constructions of rule-based full dependency grammars.'],\n",
       " ['A new approach for robust parsing of corpus analysis sentences has been proposed.'],\n",
       " ['A number of approaches to natural language analysis have been proposed over the years.'],\n",
       " [\"syntactically annotated grammar corpora ('treebanks') for induction.\"],\n",
       " ['The relationship between natural language processing (NLP) systems and text types is well known.'],\n",
       " ['In this paper we present two methods for learning accenting rules for word formation in Dutch.'],\n",
       " ['Speech recognition is one of the major areas of research in computer science.'],\n",
       " ['The aim of this research project is to develop tools for instant understanding of English.'],\n",
       " ['In this paper we investigate the construction of Lisplike Exicons (LCS).'],\n",
       " ['Grammar checking has been an area of interest for computer scientists since the 1960s.'],\n",
       " ['IBM has announced that it is developing a grammar-checking system for computers.'],\n",
       " ['A new method for correcting spelling errors has been proposed in this paper.'],\n",
       " ['The goal of this paper is to show how natural language processing (NLP) algorithms can be used to improve essay scoring.'],\n",
       " ['Hidden Markov Models (HMMs) and Entropy Models (MaxEnt) have been used to train speech recognition systems.'],\n",
       " ['In recent years, a number of research projects have been carried out in the area of information extraction.'],\n",
       " ['This paper aims to provide an overview of the state-of-the-art in table layout research.'],\n",
       " ['In our work on news summarization at Columbia University (McKeown and Radev, 1995; Radev, 1996), information is extracted from news articles (MUC, 1992; Grishman et al, 1992 and is analyzed by a generation com- ponent o produce a summary that shows'],\n",
       " ['This paper presents a corpus-based Natural Language Processing (NLP) architecture based on the SGML language semantics.'],\n",
       " ['The goal of this paper is to provide an example of a text-based natural language processing (NLP) pipeline architecture, which provides a software infrastructure on top of which heterogeneous NLP processing modules may be evaluated and refined individually, or may be combined into larger application systems.'],\n",
       " ['A TIPSTER-compliant architecture for natural language processing has been implemented in Java.'],\n",
       " ['In the early 1990s, researchers at the Massachusetts Institute of Technology (MIT) developed CogentHelp, an on-line help system.'],\n",
       " ['Multex is a speech-to-text system that can be used for a variety of purposes.'],\n",
       " ['Most research on single document summarization, particularly for domain independent tasks, uses sentence extraction to produce a summary (Lin and Hovy, 1997; Marcu, 1997; Salton et al.'],\n",
       " ['1 Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy'],\n",
       " ['syntactic query/corpus parsing for information retrieval.'],\n",
       " ['The aim of our work is to build lists of web pages with descriptive names (NEs).'],\n",
       " ['The acquisition of translation lexicons is an important issue in the field of cross-lingual text retrieval.'],\n",
       " ['Soft decision-making is a key feature of the Alembic toolkit for natural language processing (NLP).'],\n",
       " ['A machine-readable subcategorization dictionary for English.'],\n",
       " ['The problem of extracting knowledge of verbs from Japanese syntactic data has been investigated in a number of papers over the years.'],\n",
       " [\"The Oxford English Dictionary is the world's largest collection of English word forms.\"],\n",
       " ['The problem of word-sense in natural language processing is well known, and a number of comparative studies have all reported that no method achieves significantly greater accuracy than the Naive Bayesian classifier.'],\n",
       " ['In our series of letters from African journalists, novelists, and other writers, novelists, and other writers, novelists, and other writers, novelists, and Selection restrictions are typically used to capture facts about the world that are generally, but not necessarily, true.'],\n",
       " ['In this paper, we compare a number of systems for learning statis- tical tags.'],\n",
       " ['The use of rankers to generate grammars in natural anguage is well known.'],\n",
       " ['The Tree-DOP model has been proposed as a machine learning architecture for sentence processing.'],\n",
       " ['The Data  Parsing (DOP) model is one of the most promising tools for learning from corpus data.'],\n",
       " ['The aim of this paper is to investigate the use of numeral classifiers for uncountable nouns.'],\n",
       " ['Software engineering is a branch of computer science that deals with the design, development, and maintenance of software.'],\n",
       " ['This paper presents a new semantic disambiguator for English.'],\n",
       " ['The Prague Dependency Treebank is a corpus (a part of the Czech Na.tional Cortms) PDT is a corpus ( a part of the Czech Na.tional Cortms) TFA attribute have been specified in (Buranova et al.'],\n",
       " ['The following is a list of some of the most common multiword terms.'],\n",
       " ['This paper presents a new approach for word sense classification that addresses the ambiguity problems arising from Levins classification.'],\n",
       " ['This paper presents a news clustering system for extracting information from tile news stories.'],\n",
       " ['First, it has long been assumed (Lua 1997; Chen and Chen 2000) that the overwhelming majority of Chinese compounds are more or less endocentric, where the compounds denote a hyponym of the head component in the compound.'],\n",
       " [\"The likelihood of a word appearing in a document's history is one of the most important questions in language research.\"],\n",
       " ['The question of which words are more likely to be ate-with or strawberries-with is of great interest to linguists.'],\n",
       " ['In our series of letters from leading scientists, we look at the use of natural language processing (NLP) and artificial intelligence (AI) for the extraction of biological named entities (NEs).'],\n",
       " ['This paper presents a novel system for resolving anaphors in a corpus of English.'],\n",
       " ['Learning non-reeursive noun phrases can be a difficult task.'],\n",
       " [\"An al3pl'oacll to a spec views a dorctmlcnt as a mixture of wee-like strttcttre, expressed througll balanced labelled parentheses (tim lags), and of sul:face, expressed llu'ough free lexi interspersed\"],\n",
       " ['The aim of this paper is to develop a text mining tool for the extraction of answers from texts.'],\n",
       " ['The aim of this paper is to explore the use of semantic features in discourse processing.'],\n",
       " ['Pronominalization is a major problem in the development of natural language generation algorithms.'],\n",
       " ['The representativeness of a term is one of the most important issues in language research.'],\n",
       " ['The aim of this paper is to show how the art of parsing can be improved.'],\n",
       " ['This paper presents a new method for transforming left-recursive grammars into right-recursive grammars.'],\n",
       " ['multimodal parsing and understanding (MMFST) is an emerging area of research in language processing.'],\n",
       " ['The development of multimodal interfaces for mobile devices is a major challenge.'],\n",
       " ['Transliteration of a name, for the purpose of this work, is defined as its transcription in a different language, preserving the phonetics in a different orthography.'],\n",
       " ['The asaurus is an important part of the corpus of a language.'],\n",
       " ['dependency analysis is one of the most important areas of research in machine learning.'],\n",
       " ['Korean is the second largest language in the world after English.'],\n",
       " [\"A context-fl'ee language is a language that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar\"],\n",
       " ['A case frame dictionary is a dictionary that describes the case structure of verbs in a language.'],\n",
       " ['The MetaGrammar (MG) is one of the most widely used algorithms for tagging English texts.'],\n",
       " ['Texts with noisy remaining contexts are a major problem for machine learning.'],\n",
       " ['The lmdersl)eci- eci description has been extended to deal with anaphoric semantics.'],\n",
       " ['In this paper, we propose a method to manage speech recognition errors using confidence measures.'],\n",
       " ['A system to automatically generate instructional texts in the languages of Eastern Europe has been proposed as part of the Drafter project.'],\n",
       " ['In this paper, we propose a method to identify and discard sentences that contain no or few signature terms.'],\n",
       " ['The management of ecient dialogue systems is a major problem.'],\n",
       " ['The notion of term similarity has been defined and considered in different ways: terms can have functional and/or structural similarities, though they can be correlated with different relationships (Grefenstette 1994).'],\n",
       " ['A Korean-to-Japanese machine translation system using MWTUs is presented.'],\n",
       " ['In my previous papers I have shown how to implement standard parsing algorithms directly in a constraint system.'],\n",
       " ['In this paper, we investigate the use of wordbased language in speech recognition.'],\n",
       " ['We have proposed a Monte Carlo approach to retrieve parses licensed by a grmnmar.'],\n",
       " ['We propose a occurrence method with the database information and co-occurrence information for the interpretation of natural language queries in multilingual query interpretation.'],\n",
       " ['This paper presents a new system for learning the problem of tagging.'],\n",
       " ['Recent research has focused on tools detecting translation equivalents for technical vocabulary in a restricted domain, e.g.'],\n",
       " ['We study the problem of generating correct grammars in type logical grmnmars.'],\n",
       " ['A syntax-based model for machine translation has been proposed to address the following problems:'],\n",
       " ['A new approach to the problem of text plmming.'],\n",
       " ['In this paper, we show that a Verb Class can be used to classify ambiguous text.'],\n",
       " ['This paper presents a probabilistic probabilistic translation system based on Verbmobil.'],\n",
       " ['In this paper we present a new model for the segmentation of DNA sequences into nuclei.'],\n",
       " ['This paper deals with the automatic acquisition of subcategorization frames for verbs in English.'],\n",
       " ['In this paper, we introduce a variable context length model for Japanese named entity identification task and perform better results.'],\n",
       " [\"The verb seman(;ic) (Levlass of l&h, icle Names coni, a verbs like lmlloo'n, bicycle, ca.'n, oe, skate, ski which agree in (;they prol)erties (1)-(4)ehaviour XI\"],\n",
       " ['The dependency structure of words in Thai is similar to that of the Japanese word structure.'],\n",
       " ['In this paper, we present three methods for dependency analysis of natural lan- guage sentences.'],\n",
       " ['The UNL project of network-oriented multilinguat communication has proposed a standard for encoding the meaning of natural language utterances as semantic hypergraphs intended to be used as pivots in information and communication systems.'],\n",
       " ['Two kinds of word-extraction algorithms have been proposed.'],\n",
       " ['Text processing is one of the fastest growing areas of research in computer science.'],\n",
       " ['verbs can be classi- lied according to the diathesis aJterna.'],\n",
       " ['The aim of this paper is to develop a grammar for word-breaking in Japanese.'],\n",
       " ['Speech to speech machine translation (SMT) is one of the most promising areas of research in machine learning.'],\n",
       " ['chunk-based statistical translation has been proposed as an alternative to the traditional beam search algorithm for statistical translation (Tillmann and Ney, 2000).'],\n",
       " ['In this paper we show how word order can be used to generate surface text in a natural order (NLG).'],\n",
       " ['\"at-a-glance\" summaries of documents have been proposed as a way to reduce reading stress.'],\n",
       " ['In this paper, we investigate the metonymy of lnetonylny in a corpus of Japanese words.'],\n",
       " ['Machine translation using corpus-based ap- proaches is one of the major challenges in machine learning.'],\n",
       " ['We find that a word that normally would be pronominal is often not, as in this example: We find that a word that normally would be pronominal is often not, as in this example:'],\n",
       " ['In Yamamoto and Matsumoto (2000), we proposed a method for automatically extracting translation pairs between words in English and Japanese.'],\n",
       " ['A number of studies are related to the work we presented, most specifically work on parallel-text based information projection for parsing (Hwa et al.'],\n",
       " ['First, the automatic segmentation of spoken language is useful in two ways.'],\n",
       " ['This paper presents a new approach to the detection of argument alternations in verb lexicons.'],\n",
       " ['An example of a machine translation system based on an example-based machine translation architecture has been developed at the University of Tokyo.'],\n",
       " ['A context-free grmnmar is a grammar rule with a context-free feature structure.'],\n",
       " ['This paper presents some of the arguments for and against a unified dependency-based representation of a graph.'],\n",
       " ['Text pairs in colnparable corpus can be useful for corpus-based CLIR approaches when we use them as training data instead of a parallel corpus.'],\n",
       " ['Extracts from books are often difficult to read.'],\n",
       " ['The translation of natural language from one language to another is one of the most challenging tasks in computer science.'],\n",
       " ['The goal of the translation process in statistical machine translation can l)e fornmlated as tbl- lows: A source language string.f = f l.'],\n",
       " ['The Hidden-Markov (HMM) alignment model has been used for many years to model phrase level translation.'],\n",
       " ['The IR.EX project aims to create a common platform for the research and development of IR and IE technologies.'],\n",
       " ['The goal of this paper is to develop a statistical machine translation (T) system that automatically derives a hierarchical T from a corpus of words.'],\n",
       " ['The development of translation models and translation lexica is one of the most important areas of research in computer science.'],\n",
       " ['The translation of base noun phrases is a major problem in computer science.'],\n",
       " ['The use of relation/head/dependents in large-scale language-processing tasks has been discussed in previous papers.'],\n",
       " ['The significance of sound correspondences between languages is well-known.'],\n",
       " ['The goal of this paper is to improve the performance of speech-to-text systems.'],\n",
       " ['Recent work on Natural Language Processing (NLP) has focused on the recognition of named entities.'],\n",
       " ['This paper presents a text classification approach for definitional QA.'],\n",
       " ['The aim of this paper is to test the correctness of a text processing system developed in Bulgaria.'],\n",
       " ['Collocation extraction methods have been used for many years to study topics in texts.'],\n",
       " ['Sentences are one of the most challenging problems in machine learning.'],\n",
       " ['verbs and their underlying argu-ments.'],\n",
       " ['Question Answering (QA) has emerged as a key area in natural language processing (NLP) to apply question parsing, information extraction, and language generation techniques.'],\n",
       " ['unknown word extraction (CWS) is a branch of linguistics which deals with the problem of word identification.'],\n",
       " ['English-to-Japanese translation, where English takes the structure that places emphasis at the beginning of a sentence, hence prefers left-to-right de-coding.'],\n",
       " ['The use of zeros in second language learning has received little attention in the literature.'],\n",
       " ['How well seman-tic classes predict countability?'],\n",
       " ['Support Vector Machines (SVMs) are robust even when the number of features is large.'],\n",
       " ['The aim of this paper is to develop a multi-translation (MT) system for paraphrasing documents.'],\n",
       " ['Two new methods for unsupervised word-sense translation (WSD) have been proposed in this paper.'],\n",
       " ['.'],\n",
       " ['The generation of natural sentences from corpus data is a challenging problem.'],\n",
       " ['The translation of electronic documents is increasingly being carried out in parallel with the translation of paper documents.'],\n",
       " ['Cross-lingual information extraction is an area of interest in machine learning.'],\n",
       " ['This paper presents a NLP system which integrates a linguistic PartofSpeech PoS tagger and chunker as opposed to datadriven as a preprocessing module of a broadunicationbased grammar of Spanish.'],\n",
       " ['This paper presents a new model for the analysis of English sentences based on the unification-based grammar.'],\n",
       " ['The number of zeros in general in our data is 347, while Seki resolved 355 detected zeros in (Seki et al.'],\n",
       " ['A large number of machine learning methods have been applied to the problem of named entity recognition.'],\n",
       " ['The name extraction (NE) problem is one of the most challenging in machine learning.'],\n",
       " ['syllable-to-word (STW) conversion method based on word-sense.'],\n",
       " ['The so-called thesauri is a set of rules that govern the acquisition of information from un-annotated text.'],\n",
       " ['The prosodic structure of a sentence can be modelled using ProL, a language for constructing sentences.'],\n",
       " ['In this paper, we study the clustering of German words in a training corpus.'],\n",
       " ['A machine system that automatically converts English words into Korean words has been developed by Oh and Choi (2002).'],\n",
       " ['In this paper, we present a new method for error detection in corpus-based systems.'],\n",
       " ['The properties of Property Grammars (PG) have been proposed as a possible solution to the problem of text-to-speech systems.'],\n",
       " ['The aim of this paper is to develop a new type of word recognition system, Word Sense Disambiguation (WSD).'],\n",
       " ['We have developed a concept discovery algorithm for hand-built lexicons.'],\n",
       " ['word sense tronic (ME) has been applied to word search (WSD) and has shown to be competitive in WSD when compared to other machine learning approaches.'],\n",
       " ['In this paper, we investigate the validity of the Zipfs Law for word tokens in a corpus.'],\n",
       " ['A case frame dictionary is a dictionary that contains case information about an expression.'],\n",
       " ['A term co-occurring with a word co-occurring with another word co-occurring with another word co-occurring with another word co-occurring with another word co-occurring with another word co-occurring with another word co-occurring with another word co-occurring with another word co-occurring with another word'],\n",
       " ['Empirical machine learning (EM) has been used to learn head-percolation rules in tree-banks since the 1990s.'],\n",
       " ['It has been shown that fine-grained classification of named entities is fundamental for improving accuracy and reducing the amount of training data in many natural language tasks.'],\n",
       " ['We are developing a probabilistic model of verb ar-gument structure alternation behavior.'],\n",
       " ['The aim of this paper is to develop a method for dependency parsing of a large-scale spoken dialoguecorpus.'],\n",
       " ['The goal of this paper is to investigate how different components of a natural language system can be made to work together, whether they can easily be ported to other domains, and whether they can be inte-grated in a real-time dialog system.'],\n",
       " ['The Japanese writing system consists of the three orthographies of hiragana, katakana and kanji.'],\n",
       " ['A word sense classifier (WSD) is used to identify difficult verbs.'],\n",
       " ['The aim of this paper is to improve word coreference systems by clustering nouns to derivesemantic classes.'],\n",
       " ['The Chinese Penn Chinese Treebank (PCTB) was first tested in the Klein and Manning corpus (2001, 2002).'],\n",
       " ['This paper is a follow-up to Roth and Yih (2002), who developed a novel probabilistic framework for recognizing entities and relations together.'],\n",
       " ['The aim of this paper is to address the problem of dialogue management of information retrieval systems.'],\n",
       " ['The XTAG Project aims at the development of natural resources based on Tree Adjoining Gram-mars.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Farai Sevenzo looks at the challenges of identifying disease names.'],\n",
       " ['In this paper, wordbased speech recognition is proposed and tested.'],\n",
       " ['Re paraphrasing is a well-established technique for improving information retrieval (IR).'],\n",
       " ['In this paper, we present a new machine translation (MT) model that is more similar to the human translation model than other MT systems.'],\n",
       " ['Information extraction is one of the most challenging problems in machine learning.'],\n",
       " ['The extraction of bilingual lexicons from non-parallel but comparable corpora has been studied by a number of researchers.'],\n",
       " ['A dictionary is a collection of thousands of words that can be searched and stored in a database.'],\n",
       " ['In this paper, an opinion on the detection of abbreviations in a corpus is presented.'],\n",
       " ['In our series of letters from African journalists, film-maker, and columnist Ahmedou Ould-Abdallah looks at some of the linguistic ob-stacles faced by machine translation (MT) systems.'],\n",
       " [\"The aim of this project is to build a Chinese-English bilingual concept Merriam-Webster's Revised Dictionary (MRD).\"],\n",
       " ['The aim of this paper is to investigate the accuracy of speech recognition systems developed for corpus-based processing of spoken language.'],\n",
       " ['The aim of this study is to show how a general bilingual dictionary can be used as a spatio-temporal translator (SWT) for medical texts.'],\n",
       " ['We have developed an AI system called ATT-Meta for metaphor interpretation that employs reasoning within the terms of the source domain using various sources of information including world and linguistic knowledge.'],\n",
       " ['We present a series of papers on phoneme corre-spondences between languages.'],\n",
       " ['The retrieval of typed feature structures is an area of interest in machine learning.'],\n",
       " ['PARENT-ANCESTOR is the most accurate method for dependency analysis of Japanese sentences.'],\n",
       " ['The word sense Markov model (MIIM) has been used in many applications, such as text chunking, in supervised, semisupervised, and in unsupervised settings (Banko and Moore, 2004; Goldwater and Griffiths, 2007; Johnson, 2007; Zhou, 2004).'],\n",
       " ['The aim of this work is to improve the quality of word-aligned bilingual corpora.'],\n",
       " ['We study the syntactic structure of the Rhetorical Supplement to the Discourse (RST-DT).'],\n",
       " ['A new type-inheritance grammar that combines the structure of the English fragment in Sag and Wa-sow with the structure of the English fragment in HPSG has been used for a variety of tasks, such as wide-coverage parsing and sentence realization.'],\n",
       " ['We have previously reported on the use of dependency parsing in Swedish (Nivre and Scholz 2004; Nivre and Scholz 2004; Nivre and Scholz 2004; Nivre and Scholz 2004; Nivre and Scholz 2004; Nivre and Scholz 2004; Nivre and Scholz 2004; Nivre and Scholz 2004; Nivre and Scholz 2004; Nivre and Scholz'],\n",
       " ['The context-free grammar is an important tool in the study of language.'],\n",
       " ['A new al-gorithm for learning regular languages.'],\n",
       " ['Machine translation (MT) is a branch of computer science that aims to improve the performance of human translators.'],\n",
       " ['expressions of point of view in newswire andnarrative text.'],\n",
       " ['The aim of this paper is to develop a system to query the GEOQUERY corpus of spoken language.'],\n",
       " ['In this paper, we show that a Turkish language model (FLM) has a lower perplexity than a class-based language model (LM).'],\n",
       " ['The parsing of treebanks is an important problem in the field of machine learning.'],\n",
       " ['The Generalized ID/LP (GIDLP) grammar formalism was developed to serve as a processing backbone for linearization-HPSG grammars, separating the declaration of the constituent structure from the declaration of word order domains.'],\n",
       " ['The syntax-semantics interface is one of the most important areas of research in computer science.'],\n",
       " ['In this paper, we decompose the source-channel ap-proach to statistical machine translation into two knowledges: the lan-guage model and thetranslation model Pr(eI1).'],\n",
       " ['In our series of letters from African journalists, novelist and writer Saul Bellow looks at word alignment.'],\n",
       " ['In this paper, we will address the problem of word alignment in speech-to-text (SMT) systems.'],\n",
       " ['We have been interested in the problem of sluices in corpus dialogue for some time.'],\n",
       " ['Distributional similarity measures have been used to extract meaning from speech.'],\n",
       " ['We study word dependency analysis of English sen-tences without phrase labels.'],\n",
       " ['The parsing of man-ually constructed grammars is a major problem in machine learning.'],\n",
       " ['Ex-act parsing with large scale lexicalized gram-mars: a new formalism Fabs for ex-act parsing with large scale lexicalized gram-mars.'],\n",
       " ['This paper presents a new approach to the problem of machine translation.'],\n",
       " ['A machine translation system is investigated to improve translation prediction accuracy in post-editing, where words with low confidence could be marked as potential errors. Possible applications for confidence measures include post-editing, where words with low confidence could be marked as potential errors, improving translation prediction accuracy in trans-type-style interactive machine'],\n",
       " ['A discourseparser that can extract a better discourse from a text has been proposed and tested.'],\n",
       " ['Paraphrasing is one of the most common problems in machine learning.'],\n",
       " ['We present a novel methodology to create a semantically annotated corpus by exploiting information contained in an already annotated corpus, using word alignment as a bridge.'],\n",
       " ['The aim of this work is to improve the accuracy and speed of deep parsing systems.'],\n",
       " ['Text summarization and long answer generation are two of the most important natural language processing tasks.'],\n",
       " ['The use of language models in statistical machine translation has been explored in a number of papers.'],\n",
       " ['A number of syntactically motivated ap-proaches to statistical machine translation have been presented in this paper.'],\n",
       " ['We have proposed a new approach to automatic discourse parsing by splitting the annotation process into two parts.'],\n",
       " ['It is well known that the summation of sentences is not adequate when dealing with complex questions whose answers are expressed by long and articulated sentences or even paragraphs.'],\n",
       " ['unknown words are difficult to identify in morphological analysis of non-segmented language.'],\n",
       " ['The aim of this paper is to improve word segmentation methods in Chinese and Japanese.'],\n",
       " ['Text categorization is one of the most important areas of computer science.'],\n",
       " ['Machine translation (MT) methods for sentiment analysis have been reported in the past.'],\n",
       " ['The performance of machine translation can be affected by a number of factors, including the quality of the translation, the complexity of the text, and the number of words used.'],\n",
       " ['Text summarization is one of the major problems in computer science.'],\n",
       " ['In this paper, we focus on the problem of implicit entity recall ( IE ) by introducing a new approach to this problem.'],\n",
       " ['Tagging accuracy with partial dictionaries over 24k dataset; our closed-class lexicon is the closest approximation to 2004).'],\n",
       " ['In this paper, we use stylistic features suggested in the literature to identify the authors of text messages.'],\n",
       " ['This paper presents a novel probabilistic translation lexicon based on web anchor texts and their linking structure.'],\n",
       " ['Syntactic reordering approaches are an effective method for handling systematic differences in word order between source and target languages within the context of statistical machine translation (SMT) systems.'],\n",
       " ['Text-to-speech translation (SMT) is one of the most important areas of research in machine learning.'],\n",
       " ['De nitions are words or concepts that are likely to occur in a particular genus or differentia of the question concept.'],\n",
       " ['The order of a sentence is one of the most important features of a natural language.'],\n",
       " ['We have developed an easyIR system for information retrieval in the fields of genomics and healthcare.'],\n",
       " ['In this paper, we propose a new type of Chinese case structure, which is different from those presented in previous work.'],\n",
       " ['The goal of this paper is to provide an overview of the current state-of-the-art in sentence compression.'],\n",
       " ['Sentence ordering is a major problem in the study of text structure.'],\n",
       " ['The aim of this paper is to unify research on automatic text summarization and speech summarization.'],\n",
       " ['The discovery of semantic relations from large corpuses of text has been a major challenge for many years.'],\n",
       " ['A word sense system for English is based on a lemma-based ap-proach.'],\n",
       " ['The aim of this study was to investigate the accuracy of backtransliteration for word retrieval in Japanese.'],\n",
       " ['Opinion mining is a branch of computer science that deals with the analysis of customer feedback.'],\n",
       " ['Previous work has focused on extracting word translations from comparable corpora, but in a single language, English, across two news sources.'],\n",
       " ['Cross-lingual information extraction is an emerging area of research in machine learning.'],\n",
       " ['In this paper, we propose a method to summarize an email thread by detecting interrogative questions and their answers.'],\n",
       " ['The aim of this paper is to investigate the use of sentence clustering to reduce the complexity of human summaries.'],\n",
       " ['This paper presents a novel approach to the acquisition of selectional preferences for verbs.'],\n",
       " ['We have previously proposed methods to map FrameNets into bilingual BiFrameNets (Fung and Chen 2004).'],\n",
       " ['In this paper, I will focus on the use of ranking methods to select the most use-ful items from an all too often overwhelming list of candidates.'],\n",
       " ['The aim of this project is to enrich the NewsExplorer application with new language-independent vector representations of news clusters.'],\n",
       " ['Two classification systems have been proposed for the task of text classification (van Halteren and Oostdijk, 2004; van Halteren and Oostdijk, 2004; van Halteren and Oostdijk, 2004; van Halteren and Oostdijk, 2004; van Halteren and Oostdijk, 2004; van Halteren and Oostdijk, 2004; van'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmedou Ould-Abdallah considers expres-sions in natural language.'],\n",
       " ['We want to investigate the effect of frequency and choice of distributional similarity measure on the evaluation of distributionsal similarity methods.'],\n",
       " ['The search distance for frequent words is a fundamental problem in Natural Language Processing (NLP).'],\n",
       " ['We investigate the extraction of parallel sentences from non-parallel corpuses.'],\n",
       " ['The search for a new language has become increasingly important.'],\n",
       " ['We investigate tree-structured translation models that automatically align tree fragments in a fast and consistent fashion, and which requires no knowledge of the language pair.'],\n",
       " ['adjectives are often classified as either basic or event adjectives.'],\n",
       " ['Graph-based ranking algorithms have been traditionally and successfully used in Web-link analysis, social networks, and more recently in text processing applications.'],\n",
       " ['The knowledge of words can be expanded by the concept of domain-specific words (Fellbaum, 1998).'],\n",
       " ['This paper presents a new approach to the problem of finding the right sense in a corpus of words by using dictionaries as network of lexical items or senses.'],\n",
       " ['The problem of word segmentation in Thai language has been widely discussed in the literature.'],\n",
       " ['The corpus of loan words is an important area of research in machine learning.'],\n",
       " ['The evaluation of word senses is one of the most challenging areas of computer science.'],\n",
       " ['A framework for building a machine learning system for semantic parsing has been proposed.'],\n",
       " ['A method to derive semantic representations from parse trees has been proposed.'],\n",
       " ['How do we understand the meaning of language in the real world?'],\n",
       " ['The aim of this paper is to present a novel approach to Robust Minimal Recursions Robust Minimal Recursions (RASP).'],\n",
       " ['In our group we are developing a new type of Natural Language Processing (NLP) technique called semantic role labeling.'],\n",
       " ['This paper presents two classes of question answering: corpus-based and off-line.'],\n",
       " ['We have developed HITIQA, a web-based tool for automated question answering as part of the ARDA AQUAINT project.'],\n",
       " ['The Goi-Taikei dictionary is one of the most popular dictionaries in Japan.'],\n",
       " ['This paper presents the results of a study of word sense inference (WSI) on a corpus of English language content.'],\n",
       " ['verb-argument relations: a machine learning problem.'],\n",
       " ['Work definition extraction is an important NLP task, most frequently a subtask of terminology extraction.'],\n",
       " ['The aim of this paper is to develop a method to identify subjectivity in text.'],\n",
       " ['We have used the PropBank annotation in or-der to search for grammar for-malisms in a large corpus of Japanese.'],\n",
       " ['verb classes (VNs) are an important part of the corpus of word-semantics.'],\n",
       " ['Agirre and Lopez de Lacalle, 2008; Agirre and Lopez de Lacalle, 2008; Agirre and Lopez de Lacalle, 2008; Agirre and Lopez de Lacalle, 2008; Agirre and Lopez de Lacalle, 2008; Agirre and Lopez de Lacalle, 2008; Agir'],\n",
       " ['The use of natural language processing (NLP) to detect lies in language is a promising area of research.'],\n",
       " ['The aim of this project is to develop techniques for the processing of Noun compounds in the context of machine learning.'],\n",
       " ['dependency parsing is one of the main areas of research in machine learning.'],\n",
       " ['Sentence compression is one of the key techniques used in text summarization.'],\n",
       " ['The ROUGE toolkit has become the standard method for evaluating the content of summaries.'],\n",
       " ['In our group we have been investigating how to improve the quality and performance of Natural Language Processing (NLP).'],\n",
       " ['Prepositions and determiners are one of the most common sources of error for L2 En-glish speakers, a finding supported by our analysis of a small error-tagged corpus we created (deter-miners 17% of errors, prepositions 12%).'],\n",
       " ['The use of frames in word tagging has been well-known for some time (e.g., Dickinson and Jochim, 2008).'],\n",
       " ['Global reordering of words has been one of the major advances in statistical machine translation.'],\n",
       " ['The development of paraphrase knowledge is one of the major areas of research in machine learning.'],\n",
       " ['We study the use of comparative sentences in product reviews.'],\n",
       " ['The Tree Adjoining Grammar (LTAG) is an important part of the grammar writing process.'],\n",
       " ['This paper presents an instancebased learning algorithm for fine-grained named entity classification based on syntactic features (wordorder, case-marking, agreement, verb tenses, etc.). Giuliano and Gliozzo present an instancebased learning algorithm for fine-grained named entity classification based on syntactic features (wordorder,'],\n",
       " ['Natural lan-guage generation is a difficult problem to solve because of the complexity of the search space.'],\n",
       " ['In this paper, we show how to learn context dependent translation rules from corpus data.'],\n",
       " ['In this paper, we present a set of web-based frameworks for evaluating part-of-speech tag induction.'],\n",
       " ['In this paper, we show how to derive a textual entailment from a set of discourse commitments.'],\n",
       " ['We have developed a classifier for the parsing of Japanese sentences.'],\n",
       " ['We have developed a discriminative model for word segmentation and point-of-sale ( POS) tagging in a joint process.'],\n",
       " ['This paper presents the implementation of a semantic role labeler for WordNet.'],\n",
       " ['This paper presents a contribution to the field of Natural Language Processing by combining statisti-cal information with string distance measures.'],\n",
       " ['In this paper, we study the construction of coordinate structures.'],\n",
       " ['We report the design and implementation of a pa-per for predicting referring expressions in natural language.'],\n",
       " ['The aim of this study is to develop robust language pro-cessing tools, capable of bearing with the extremeform of noise?'],\n",
       " ['verbs from corpus data.'],\n",
       " ['The impact of the media on public opinion is well known.'],\n",
       " ['A translation model consists of two distinct elements: an unweighted ruleset, and a parameterization.'],\n",
       " ['There are two ways to deal with the problem of entailment relations in textualentailment systems.'],\n",
       " ['French and English are two of the most widely spoken languages in the world.'],\n",
       " [\"In this paper, we compare the performance of two approaches to grammar parsing: Matsuzaki and Tsujii's CCGbank (Clark and Curran, 2007; Matsuzaki and Tsujii, 2008) and the PTB (Clark and Curran, 2007; Matsuzaki and Tsujii, 2008).\"],\n",
       " ['Parsing is one of the most computationally intensive areas of machine learning, and its performance has been widely reported.'],\n",
       " ['The goal of this paper is to improve the accuracy and expressiveness of speech recognition systems.'],\n",
       " ['We have previously reported on the effects of multiple ran-dom restarts on minimum error rate training.'],\n",
       " ['Consonant inven-tories in human languages have been studied in the framework of complex networks.'],\n",
       " ['The use of event-based features to represent sentences inextractive summarisation systems has been proposed as an alternative to traditional approaches to sentence classification.'],\n",
       " ['Natural language processing (NLP) has become an important tool in the diagnosis and treatment of diseases.'],\n",
       " ['A corpus of state-of-the-art abbreviation recognizers is presented.'],\n",
       " ['Relation extraction from corpus data is a major problem in artificial intelligence (AI).'],\n",
       " ['This paper presents a new learning algorithm for unsupervised learning of grammar from text.Quality assessment of a learning algorithms output and selection of high quality instances have been addressed for supervised algorithms (see (Caruana and Niculescu-Mizil, 2006) for a survey) and specifically for supervised constituencys (Yates'],\n",
       " ['The problem of query similarity between documents and user queries has been addressed in a number of papers.'],\n",
       " ['In Roark and Hollingshead (2007), we extended methods from Roark and Hollingshead (2008) for reducing the worst-case complexity of a context-free parsing pipeline via hard constraints derived from finite-state tagging pre-processing.'],\n",
       " ['The aim of this project is to improve the annotation of gene regulation events.'],\n",
       " ['Associative anaphora resolution has been proposed as an alternative to zero anaphora resolution.'],\n",
       " ['A decision tree is used to train part-of-speech taggers.'],\n",
       " ['Parsing sentences using natural language processing (NLP) has been a challenge.'],\n",
       " ['The aim of this work is to investigate the role of discourse in opinion analysis and to develop annota170 tion schemes for interpreting opinions with discourse relations.'],\n",
       " ['relevance feedback has been used to generate word sense examples for word search (WSD) tasks.'],\n",
       " ['Opinion analysis is one of the most important areas of research in machine learning.'],\n",
       " ['subjectivity-ambiguity is a major problem in machine learning.'],\n",
       " ['This paper presents a new paradigmatic approach to the paradigmatic syntactic parsing problem of noun phrase chunking.'],\n",
       " ['In this paper we present a new framework for natural language processing based on unary templates.'],\n",
       " ['The accuracy of English as a second language (ESL) systems in the detection and correction of errors involving prepositions has been widely reported.'],\n",
       " ['In this paper, we consider the need for a unified approach to corpus-based seman-tics.'],\n",
       " ['gazetteers have been used to identify and extract attributes from a variety of data sources.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmed Rashid considers the role of metaphor in language.'],\n",
       " ['Domain adaptation in machine translation (MT) is an important problem.'],\n",
       " ['The aim of this paper is to provide an overview of the state-of-the-art in Chinese word segmentation.'],\n",
       " ['In this paper, we report a new type of Chinese case structure, which is different from those presented in previous work.'],\n",
       " ['In this paper, we develop an algorithm for reducing the size of rules in a Synchronous Context-Free Grammar (SCFG).'],\n",
       " ['In this paper, we propose a tree sequence-based translation model that uses tree sequence as the basic translation unit, rather than using single sub-tree as in the STSG.'],\n",
       " ['The automatic generation of parallel treebanks from paral-lel corpora is a major area of research in machine learning.'],\n",
       " ['In this paper we show how to decide when to stop active learning in WebKB.'],\n",
       " ['The use of context-free grammars in machine learning has been proposed as a way to reduce our set of rules.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmedou Ould-Abdallah looks at the problem of deciding between whole sentence levels of problematic translations.'],\n",
       " ['This paper presents a discourse-based opinion analysis scheme for interpreting opinions with discourse relations.'],\n",
       " ['We have shown that it is possible to partition a speech stream into utterance units using only left-context information.'],\n",
       " ['We present a novel approach to the problem of translating speech.'],\n",
       " ['OpinionFinder is a web search system that retrieves reviews from a variety of online sources.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmed Rashid considers discourse relations.'],\n",
       " ['This paper presents a new theory of motion based on spatio-temporal primitives and an annotation structure for motion in natural language.'],\n",
       " ['The selection probability of a specic attribute is a well-known problem in computer science.'],\n",
       " ['Dynamic programming systems are increasingly being used to solve complex problems in computer science.'],\n",
       " ['In this paper, we develop a method for selecting the most appropriate test case for the problem of ill-formed input to natural language interfaces.'],\n",
       " ['The study of vague word meanings in natural language texts is a difficult task.'],\n",
       " ['The use of prefixes and suffixes (PE) in the English language has three consequences: first, it reduces the number of words that can be used in the same sentence; second, it increases the number of words that can be used in the same sentence; and third, it increases the number of words'],\n",
       " [\"The SmSum system is a computer simulation of human summanzmg that automatically generates summaries of different content depending on the user's goals and needs.\"],\n",
       " ['The aim of the ISSCO 1 project is to develop a new approach to the modelling of LandCubed Bridges (LKBs).'],\n",
       " ['This paper deals with the decomposition of natural language into its constituent parts, i.e.'],\n",
       " ['Non-SVO word order helps the reader (or listener) to construct a discourse representation.'],\n",
       " ['A new class of grammars called Categorial Unification Grammars (CUGs).'],\n",
       " ['A dependency theory of syntactic structure indicates syntactic relations directly between the words of a sentence.'],\n",
       " ['The formal relationship between two systems of grammars has been investigated in a number of papers.'],\n",
       " ['The theory of general phrase structure grammar has been heavily criticised for its difficulty in dealing with complex feature structures.'],\n",
       " [\"Morphology is the study of a language's morphology.\"],\n",
       " ['lattices have been used for many years in the translation of Japanese text typed in kana (syllabic symbols) to kanji.'],\n",
       " ['The aim of this work is to investigate the use of deictic gestures to identify objects in natural language dialog systems.'],\n",
       " ['This paper presents a translation rule for translating non-singular concepts into English.'],\n",
       " ['The aim of this paper is to investigate the feasibility of a thesaurus as an information retrieval tool.'],\n",
       " ['The aim of our project is to design and implement a natural language based knowledge acquisition and query system and to build a legal expert system on its basis.'],\n",
       " ['A discourse-oriented nonmonotonic formalism has been proposed for the resolution of anaphora.'],\n",
       " ['In this talk I will give an overview of two recent research projects.'],\n",
       " ['Speech-to-speech (CTS) systems have been developed to produce spoken messages.'],\n",
       " ['This paper presents a knowledge-based machine translation system based on functional grammar and entity-oriented parsing.'],\n",
       " ['A machine translation system capable of translating English-Japanese computer manuals has been developed.'],\n",
       " ['In the 1970s and 1980s, a number of research projects aimed at improving access to Japanese material were carried out in Germany.'],\n",
       " ['This talk will focus on the study of anaphora and its relation to Discourse Representation Theory.'],\n",
       " ['In this paper we present a general parsing strategy that arose from the development of an Earley-type parsing algorithm for TAGs (Schabes and Joshi 1988) and from recent linguistic work in TAGs (Abeille 1988).'],\n",
       " ['This paper presents a semantics-based knowledge representation of temporal periods and phases.'],\n",
       " ['In this paper, we propose a new formalism for the finite element (FSM) system, which allows for more elegant descriptions of strings.'],\n",
       " ['This paper presents a new approach to the study of machine translation (MT).'],\n",
       " ['A new algorithm for feature graphs has been proposed.'],\n",
       " ['We have been working on automatic translation of large corpuses of English and French.'],\n",
       " ['A multi-lingual (MT) system must be able to deal with different grammars for different languages.'],\n",
       " ['The so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989).'],\n",
       " ['This paper presents three proposals for the integration of binding constraints into rules that already satisfies the syntactic onstraints on coreferenee.'],\n",
       " ['Free text parsing is one of the most important areas of research in machine learning.'],\n",
       " ['The generation of clauses (CIs) is a major problem in computer science.'],\n",
       " [\"We are developing a machine translation system that produces a style appropriate to the target language and preserves the original author's tylistic intent.\"],\n",
       " ['Temporal relations are an important area of study in philosophy.'],\n",
       " ['The French language has a long tradition of linguistic discrimination, with a particular emphasis on competence errors.'],\n",
       " ['A new method to express quantification i a precise and natural way in natural anguage has been proposed.'],\n",
       " ['It has been proposed that utterances should be mapped to user model entries in order to infer inference processes at the higher level, and that utterances should be mapped to attitude model entries in order to infer inference processes at the deeper level.'],\n",
       " ['This paper describes the development of a reM language that performs both syntactic anMysis and natural anguage.'],\n",
       " ['A good semantic interpreter must be able to derive the real or intended sense of each phrase without excessive computation or specialized knowledge.'],\n",
       " ['In this paper, we compare the approaches of Kasper and Mellish in extending Functional Unification Grammar (SFG).'],\n",
       " ['In this paper, we develop an algorithm to produce structural paraphrases of natural language questions.'],\n",
       " ['The aim of this study is error-correction of non-native speakers written ish text.'],\n",
       " ['This paper describes some of the major improvements made to news analysis systems over the past 25 years.'],\n",
       " ['The idea of infinite grammar was first proposed by Lounsbury in 1974 as a solution to the problem of parsing a sentence with unknown words.'],\n",
       " ['In our series of letters from African journalists, novelist and writer Germaine Greer looks at the issue of error ant i c ipat ion in second language learn ing.'],\n",
       " [\"Reading a narrative is a form of soci',d interaction.\"],\n",
       " ['A real-time on-line communication system including automatic translation was realized by combining a keyboard conversation function with an English-Japanese bi-directional machine system implemented on a workstation [Amano 1987].'],\n",
       " ['The concept of polysemy is an important area of research in the field of semantics.'],\n",
       " ['A first question in this thesis is how a discourse grammar can be implemented in the Higher Performance Study Group (HPSG).'],\n",
       " ['In this paper we present a new system for parsing natural language sentences.'],\n",
       " ['In our work, we exploit the formal MRL grammar for parsing and generation of logical forms.'],\n",
       " ['The aim of this work is to develop a method for the recognition of continuous speech, that is, a process that does not require the use of \"high level\" knowledge sources.'],\n",
       " ['We consider the implications of machine translation research for the study of human-computer interaction.'],\n",
       " ['The LFG-framework is a framework for the derivation of sentences from functional and/or semantic structures.'],\n",
       " ['Machine readable dictionaries can be used to derive some domain knowledge from large text corpora.'],\n",
       " ['The Distributed Language Translation (DLT) project at the British Science Organisation (BSO) has been experimenting with bilingual corpora as a potential knowledge source for the machine translation system.'],\n",
       " ['The Alvey Directorate at the University of Manchester has published a paper on its research into machine translation.'],\n",
       " ['The following is an example of a spoken-style Japanese conversation:'],\n",
       " ['The study of grammars has traditionally focused on the analysis of attribute-value systems.'],\n",
       " ['In this paper, we develop a program to extract co-occurrence patterns from corpus data.'],\n",
       " ['The aim of the project is to develop a multi-lingual tool to check the style of texts.'],\n",
       " ['The use of domain knowledge to improve the accuracy of text indexing has been a long-standing tradition in AI and Library Science.'],\n",
       " ['In this article, I will show you how to express your feelings in Mandarin Chinese.'],\n",
       " ['We have developed a speech synthesis system based on stress and intonation markers.'],\n",
       " ['The following is a list of some of the criticisms of the grammar G algorithm:'],\n",
       " ['The use of box codes in mnltilingual systems has attracted considerable attention.'],\n",
       " ['Tree Adjoining Grammars with Unification: Harbusch (1990).'],\n",
       " ['The generation of strings from logical forms was stud- ied intensively by [Shi88,89][Ca189], and the study of this problem shed light not only on the efficiency and soundness of generation algorithms, but also on the appropriateness of grammar itself.'],\n",
       " ['The correct program reads a list of misspelled words the input stream (stdin), and prints a set of corrections for each word on the output stream (stdout).'],\n",
       " ['The use of defaults in sentence construction has been debated for many years.'],\n",
       " ['The role of cue phrases in under- standing discourse is discussed in this paper.'],\n",
       " ['Morphological analysis of natural language sentences is one of the most challenging areas of computer science.'],\n",
       " ['In this paper, I propose a new approach to the study of extended explanations.'],\n",
       " ['For examl)le, infl)rmation on symonyms extra.'],\n",
       " ['The generation and processing of knowledge is one of the most important areas of research in artificial intelligence.'],\n",
       " ['I have been working on multi language translation for many years.'],\n",
       " ['This paper presents the results of an augmented grammar compilation procedure.'],\n",
       " ['Dictionary-based neural networks have been proposed many times over the past 30 years.'],\n",
       " ['The development and maintenance of Natural Language Processing (NLP) systems can be a challenge.'],\n",
       " ['The CLG(n) family of constraint logic grammars has been developed by Balari and Damas.'],\n",
       " ['Two-level morphology has come a long way in the last 30 years.'],\n",
       " ['The role of the human in the translation process has been hotly debated for many years.'],\n",
       " ['This paper considers the development of a bottom-up parsing algorithm for the analysis of disjunctive feature structures in natural grammars.'],\n",
       " ['This paper presents a new grammar theory for the Korean language.'],\n",
       " ['The aim of this paper is to present a new approach to the problem of parsing aud generation.'],\n",
       " ['The aim of this paper is to present a new approach to the problem of linguistic description inexplicit generation.'],\n",
       " ['The scoped quantification algorithm (QLF) is a well-known tool for dealing with complex noun phrases.'],\n",
       " ['This paper presents a formal account of the elusive concept of expressive power with respect to the kinds of categories and constructions that a grammar (of a given type) can reflect.'],\n",
       " ['This paper presents a new formalism for the study of Coordi:uation.'],\n",
       " ['The aim of this work is to improve word category prediction in Natural Language Processing (NLP).'],\n",
       " ['The aim of this paper is to improve the quality of example-based machine translations.'],\n",
       " ['Tree-adjoining rammars (TAG) have been proposed as a formalism for machine translation (MT).'],\n",
       " ['Sentence analysis hould be treated as defeasible reasoning, and presents treatments of chart pars-ing and euse analyses, and interpretation of Japanese noun phrases with adnominal particles.'],\n",
       " ['The translation of text from one language to another is one of the most challenging tasks in computer science.'],\n",
       " ['This paper is a follow-up to a previous paper on the use of reason-maintenance techniques to support incremental parsing and interpretation of human language.'],\n",
       " ['A new class of formalisms has been proposed in the area of object-oriented grammars.'],\n",
       " ['verbs, prepositions and conjunctions.'],\n",
       " ['The resolution of anaphora references has been one of the most hotly contested areas of linguistic research in recent years.'],\n",
       " ['The syntax of Arabic sentences in Definite Clause Grammar is well known.'],\n",
       " ['This paper is a continuation of our work on the manipulation of weather forecasts.'],\n",
       " ['Sentence segmentation is one of the most challenging problems in machine translation.'],\n",
       " ['In our series of letters from leading scientists, Prof Paul Harris looks at the potential of bilingual corpora as a knowledge source for machine translation.'],\n",
       " ['The study of text understanding systems based on Natural Language Processing (NLP) is not widespread.'],\n",
       " ['The morphology of agglutinative languages is a major challenge.'],\n",
       " ['The morphology of langtmge is often conceptualized in terms of paradigms.'],\n",
       " ['The integration of phonology into Head-driven Phrase Structure Grammar (HPSG) is a major challenge.'],\n",
       " ['The aim of this paper is to develop a word segmentation program for a monolingual dictionary.'],\n",
       " ['Rules for constructing a proof of a type in a Categorial Grammar.'],\n",
       " ['This paper presents a new approach to the study of phonological features in typed feature systems (HPSG) by adopting a formal, nonprocedural model of phonology and showing how it can be integrated into HPSG.'],\n",
       " ['A new approach to represent syntactic structures in large text corpora has been proposed.'],\n",
       " ['This paper presents a method for the analysis of a long Japanese sentence based on similarity of form.'],\n",
       " ['This paper presents a new approach to uriitication-ba.sed parsing.'],\n",
       " ['In our series of letters from leading academics, novelists and other writers, novelists and other writers, novelists and other writers, novelists and other writers, novelists and other writers, novelists and other writers, novelists and other writers, novelists and other writers, novelists and other writers'],\n",
       " ['This paper is part of a series of papers on natural language processing.'],\n",
       " [\"The fully lexicMized grammar formalism I_'rAG 1 is based on a non-monotonic approach to grammar development and maintenance (Vijay-Shanker and Schabes, 1992).\"],\n",
       " ['The semantics of bare plural NPs are well known.'],\n",
       " ['The generation of quantified expressions in the context of a natural language generation system is a major area of research in machine learning.'],\n",
       " ['The role of utterances in a dialogue is well known.'],\n",
       " ['In our series of letters from African journalists, Prof.'],\n",
       " ['The left context symbol is one of the most commonly used symbols in spoken language processing.'],\n",
       " ['The aim of this paper is to introduce a new type of word-sense recognition (WSD) that combines several sources of knowledge such as lexicon information, heuristics and others.'],\n",
       " ['EFD-closure is a very difficult grammar to define.'],\n",
       " ['In this paper, we present a novel parsing algorithm, which is capable of building a structure from two independent parts (a head and a single part).'],\n",
       " ['This paper deals with the formalisms of Categorial Grammars and Dependency Grammars.'],\n",
       " ['The performance of machine translation systems is an important consideration for system designers.'],\n",
       " [\"In this paper we propose a data-structure-sharing version of Wroblewski's quasi-destructive unification algorithm, Copy.\"],\n",
       " ['The aim of this work is to improve the classification of large quantities of text.'],\n",
       " ['Extragrammatical input into unification-based grammars is a common problem.'],\n",
       " ['A corpus of terms and ex- pressions that are not defined in a dictionary has been developed.'],\n",
       " ['In our series of letters from Japanese journalists, Shouichi YTLYAMA, I, and Prof.'],\n",
       " ['This paper deals with the abstract structure of argumentative paragraphs.'],\n",
       " ['Transfer-Driven Machine Translation (TDMT) performs efficient and robust spoken-language translation using various kinds of strategies to be able to treat diverse input.'],\n",
       " ['declarative representation of bi-lingual knowledge in machine translation systems.'],\n",
       " ['The aim of this project is to develop programming techniques to generate un-ambiguous utterances.'],\n",
       " ['The choice of anaphor for a word is one of the most important decisions a linguist can make.'],\n",
       " ['Transfer-based machine translation has been used for many years to improve the performance of human translators.'],\n",
       " ['The relationship between agents and their dialogue styles is one of the most important issues in the field of artificial intelligence.'],\n",
       " ['The goal of this paper is to develop a system for collaborative negotiation in which agents are solely interested in winning an argument and thus exhibit different behavior from collaborative agents.'],\n",
       " ['The aim of my research is to improve the state-of-the-art in natural language processing by introducing new approaches to stratification of linguistic resources.'],\n",
       " ['The Shalt2 system has been designed and implemented as a symmetric multi-lingual translation system with conceptual representation.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmedou Ould-Abdallah looks at a research project on automated Chinese text abstraction.'],\n",
       " ['This paper presents a speech recognition system based on tile interactive clarification approach.'],\n",
       " ['We have been working on a large-seale verb dictionary for some time.'],\n",
       " ['The disautbiguation of fire sanses has been one of the most hotly debated areas of linguistics in recent years.'],\n",
       " ['The adverbial adjective is a word or phrase used to describe something or someone.'],\n",
       " ['The problem of Chinese sentence tokenization has been the focus of considerable research efforts, and significant advancements have been made.'],\n",
       " ['Un- known words are a major problem in machine learning.'],\n",
       " ['In this paper we present a new approach for machine translation of compound words.'],\n",
       " ['We have developed a hierarchical structure for lex- ical knowledge which can capture significant linguistic gen- eralizations, eliminate rexlundancy, and facilitate both knowl- edge acquisition and efficient processing.'],\n",
       " ['T rans la t ion aM and example-based MT are well-known translation models.'],\n",
       " ['There are many ways in which trees can be improved.'],\n",
       " ['In our previous papers, we have proposed a corpus-based approach to corpus-based machine learning.'],\n",
       " ['Machine translation (MT) systems need to be able to predict noun phrase countability and number in English.'],\n",
       " [\"The KANT system, developed by CMU's Center for Machine Translation (Mitamura et al 1991), is a text-to-speech system that has been widely used in research into machine translation.\"],\n",
       " ['The goal of this paper is to present an example of an example-based machine translation system.'],\n",
       " ['Examples of machine translation systems have been developed over the years.'],\n",
       " ['The aim of this paper is to introduce a new approach to the translation of tiles, one based on the DBMT Interactive MT system.'],\n",
       " ['The aim of this paper is to explore the use of probabilistic models to train speech taggers.'],\n",
       " ['In our paper, we address the problem of supertag assignnmnt ambigu ity by using ta.ggels to reduce the supertag assignnmnt ambigu ity by using ta.ggels to reduce the supertag assignnmnt ambigu ity by using ta.gg'],\n",
       " ['In this paper we present a new approach to tag words with feature structures.'],\n",
       " ['In this paper, we train a corpus of Chinese-English texts to segment Chinese sentences.'],\n",
       " ['Part-of-speech taggers are used to constrain open class words.'],\n",
       " ['This paper presents a new approach to multi-tape two-level morphology.'],\n",
       " ['The \"Selective Error Correction Method\" to judge these three types of errors, and correct them, using ra-th order Markov chain model for Japanese \\'kanji-kana\\' characters, has been proposed and shown to be useful to detect and correct errors generated randomly.'],\n",
       " ['A morphological nalyzer that offers approxi- mately 95% accuracy on a statistical language model-ing technique and an efficient two-pass N-best search strategy is proposed.'],\n",
       " ['The parameter d shows the distance between two events.'],\n",
       " [\"The use of lexical rules to generate different uses of a word fl'om a kernel entry (Copestake gg Briscoe, 199l; Sanfilippo, 1994) provides a 1)rincipled alternative to word sense and can be made to eater for uovel uses of words.\"],\n",
       " ['acceptions as they are defined in the Papillon dictionary (Serasset, 1994), to represent the equivalence links between concepts of the different legal systems.'],\n",
       " ['In our series of letters from African journalists, filmmaker and columnist Farai Sevenzo looks at the meaning of vocabulary.'],\n",
       " ['The meaning of a word can be determined by a number of methods: dictionary-based, corpus-based, hand-encoded, light parsing, etc.'],\n",
       " ['In the 1980s and 1990s, a large number of dictionaries were developed, some of them bilingual.'],\n",
       " ['The PROVERB text planning framework has been developed at the University of California, Berkeley.'],\n",
       " ['Text analysis is one of the fastest growing areas of computer science.'],\n",
       " ['In this paper, we show how a natural language generation (NLG) system can be improved by defaulting to a more natural language.'],\n",
       " ['The aim of this paper is to develop an algorithm to control the construction of functional labels on the basis of pre-chunked input.'],\n",
       " ['The standard format of the English language, the languorous language (LP), is not well suited to processing \"flexible\" word order in natural languages.'],\n",
       " ['A blackboard-type architecture for speech translation has been proposed and demonstrated by Boitet and Seligman.'],\n",
       " ['finite-state transducers (FSTs) have been used to represent context-free grammars for many years.'],\n",
       " ['The coverage of principle-based grammars in the English language has been improved by the work of Lin and Minipar.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmedou Ould-Abdallah looks at some of the key issues in African journalism.'],\n",
       " ['The terminol-ogy extraction of English and French technical terms has been an area of interest for many years.'],\n",
       " ['This paper presents an algorithm for selecting an appropriate classifier for a noun in Thai.'],\n",
       " ['The English National Dictionary of Klingon (ENGCG) has been updated to include a new entry.'],\n",
       " ['An interactiw is a set of rules that can be used to train an unsupervised learning system (LR).'],\n",
       " [\"We use the term '(:luster) generation' instead of 'clustering' in our approach to information retrieval.\"],\n",
       " ['A new method of sorting sul)strings of a text has been developed.'],\n",
       " ['The relationship between word meanings of verbs and their usage within sentences is an important issue in machine translation.'],\n",
       " [\"Cilough Ei, llglltg(:: l i it(|ersi,all(l i,g ()11o ilillrLalll, and ll(IC-m:y, 1992mM Na.kagawa's)row\"],\n",
       " ['generative lexicons have been proposed as a way to support automatic sense shifts and to prevent a proliferation of senses in the semantic lexicon.'],\n",
       " ['This paper considers a problem with the standard approach to polysemy, arguing that in many cases this kind of \"forced-choice\" approach to formation leads to arbitrary decisions which have negative consequences for NLP systems.'],\n",
       " ['The problem of disambiguating sentences in a practical domain has been identified by a number of researchers (Engelson and Dagan 1996; Lewis and Gale 1994; Uramoto 1994a, Yarowsky 1995).'],\n",
       " ['The aim of this paper is to provide an overview of the literature on smoothing methods for the acquisition of selectional constraints.'],\n",
       " ['Text segmentation has become one of the major areas of research in machine learning.'],\n",
       " ['The aim of this paper is to develop a novel word sense acquisition algorithm which is able to identify the best matched category with a given input, from pre-defined candidates.'],\n",
       " ['We propose a new approach to linguistic knowledge acquisi- tion, which is a combination of symbolic and statistical approaches.'],\n",
       " ['The structure of compound nouns is one of the major problems in language-processing systems.'],\n",
       " ['In our series of letters from African journalists, novelists, and writers, novelist and writer Ahmedou Ould-Abdallah looks at the changing role of grammar tbrmalisms in natural language processing.'],\n",
       " ['Forma,lism is a type of feature structure which has a signature which can be inferned from any other type of forma,lism.'],\n",
       " ['This paper proposes a rule for constructing a grammar of spontaneously spoken language.'],\n",
       " ['This paper proposes a statistic that measures the strength of glue between words in a sampled text.'],\n",
       " ['This paper presents a method for document classification based on hard clustering of words.'],\n",
       " ['This paper presents a method for automatically aligning Japanese and English sentences from bilingual corpora.'],\n",
       " ['The aim of this paper is to investigate the impact of anaphora on the performance of discourse processing systems.'],\n",
       " ['The use of referring expressions in conversation has been investigated by a number of researchers.'],\n",
       " ['3 Anaphora Resolution System 4.1 Procedure Before referents are determined, sentences are transformed into a case structure by the ce structure (Kurohashi and Nagao 1994).'],\n",
       " ['This paper presents a new approach to the problem of text segmentation.'],\n",
       " ['An anaphor resolution is a technique for selecting correct antecedents from a large number of candi- date noun phrases.'],\n",
       " ['The problem of anaphora resolution in Natural Language Processing (NLP) has been hotly debated for many years.'],\n",
       " ['The rhel;orieal relal,ion delinil,ions causes problems, Our elaim is thai, the main cause'],\n",
       " ['A new model of dialogue, one based on the idea of \"grounding\"'],\n",
       " ['We have previously reported on a rule-based ap- proach to prepositional phrase attachment, disambiguating between prepositional attachent to the main verb and to the object nonn phrase.'],\n",
       " ['A discourseralegy is a strategy for communicaling with another agent.'],\n",
       " ['A new class of grammars, the unification-based grammar (I)CG, is proposed.'],\n",
       " ['The Chinese segmenter,EG is a complete system for highaccuracy Chinese segmentation.'],\n",
       " ['The object-oriented Haskell programming language (HPSG) is well known for its use of feature structures to describe objects.'],\n",
       " ['A full-size lexical transducer for Korean has been built at Xe- rox PARC within a tamework nown as two- level Inorpho logy.'],\n",
       " ['The classification of Chinese language sentences is one of the major challenges in the field of artificial intelligence.'],\n",
       " ['We present a new method for automatic onstruction of thesauri based on corpus data.'],\n",
       " ['We study the learning of dependencies between case slots and syntactic  tasks.'],\n",
       " ['In this paper, we present a Verbmobil Research Prototype for a multi- communication architecture for large, A l-systems, which is particularly use-ful for systems speech and language processing.'],\n",
       " ['The aim of this study is to propose a new way of dealing with corpus problems in Natural Language Processing (NLP).'],\n",
       " [\"A version of Brill's tagger is used for tagging Spanish texts, which includes unknown words.\"],\n",
       " ['verb sense disamibiguation in English text retrieval by (:orlms-based)roache.'],\n",
       " ['The morphology of words in Arabic has been studied by a number of researchers over the years.'],\n",
       " ['Floating quantifiers have been used in machine translation for many years.'],\n",
       " ['In this paper, we propose a novel approach to processing metonymy by building meaning representations of wholes.'],\n",
       " ['In this paper we describe the problematic behaviour of mental adjectives in French.'],\n",
       " ['This paper presents an example of an example-based translation system, where outputs from Transfer Machine Translation (MT), Knowledge-based MT and Example-based MT are combined on the chart during parsing.'],\n",
       " ['Prepositional phrases are usually attached to verbs according to text corpora.'],\n",
       " ['Proper nouns can be identified using corpus-based and rule-based methods (Chen and Lee, 1996; Chen, Ding and Tsai, 1998).'],\n",
       " ['The aim of this paper is to investigate the impact of natural language generation (NLG) systems on users.'],\n",
       " ['The performance of a text-to-speech program is investigated in the context of a psychological theory of reading aloud.'],\n",
       " ['The aim of this paper is to develop a tool for the development of application-oriented grammar.'],\n",
       " ['This paper presents a transfer-based approach to machine translation of spontaneous poken language in face-to-face dialogs.'],\n",
       " ['In this paper, we propose a novel methodology for learning fine-grained grammatmal knowledge from corpus data.'],\n",
       " ['German erst is ambigous.'],\n",
       " [\"The dependency tree (RHS) is a representation of a word's dependencies.\"],\n",
       " ['The use of preventative expressions in teaching has been explored in the fields of politeness and intentionality.'],\n",
       " ['In this paper I present a new theory of Italian referential expressions, that is based on the assumption that Italian referential expressions can be explained by the following:'],\n",
       " ['Speech processing is one of the most challenging areas of computer science.'],\n",
       " ['In this talk, I will describe some approaches to the translation of nominal compounds in Natural Language Processing (NLP).'],\n",
       " ['In this talk, we are going to look at how to carry out WSD on the basis of distributional evidence.'],\n",
       " ['The aim of this work is to develop a new type of machine translation, interactive translation.'],\n",
       " ['The translation of spoken language is one of the most challenging tasks in computer science.'],\n",
       " ['This paper presents an approach to tag classification using decision trees.'],\n",
       " ['In this paper, we show that higher-order unification can be used to model the interpretation of focus and its interaction with focus sensitive operators, adverbial quantifiers and second occurrence expressions.'],\n",
       " ['The US System (US) is a large scale multi-lingual speech-to-speech translation system designed to facilitate communication between two parties engaged in a spontaneous conversation in a limited domain.'],\n",
       " ['disjunctions in natural language grammars.'],\n",
       " [\"Two-level formalisin Koskenniemi, a serious rival to the two-level formalisin Koskenniemi, developed in response to practical difficulties encountered in writing large-scale mor- phological descriptions using Koskenniemi's nota-tion.\"],\n",
       " ['The COMLEX Syntax has been used by linguists for more than 20 years.'],\n",
       " ['A speech-to-text (S2T) system is being developed at the University of California, Los Angeles (UCLA) and the University of California, Berkeley (UC Berkeley).'],\n",
       " ['The resolution of anaphora and ellipses in English texts is a major problem in the area of semantics.'],\n",
       " ['The aim of this paper is to develop new approaches for the parsing of natural language texts.'],\n",
       " ['Two well-known methods for similaritytehing are herited feature-based similarity matching and the generation of lexical hierarchies from large text corpora.'],\n",
       " ['The theory of \"sloppy identity\" has been the subject of much research in recent years.'],\n",
       " ['corpus-based methods for retrieving bilinguals from large corpora.'],\n",
       " [\"The development of ensming, correcl, int'crelming, is an area of interest for many vmiotts.\"],\n",
       " ['This paper deals with a question that has received little attention: What conditions should an IR be applicable to a given lexical entry (henceforth: LE)?'],\n",
       " ['The information structure of utterances is an important topic in the field of word order analysis.'],\n",
       " ['Morphological analysis of word- tbrms in Bantu languages is a challenge.'],\n",
       " ['The extraction and mining of strings from corpus has been a major area of research for many years.'],\n",
       " ['Co-occurrence information between words and words in the same sentence has been used in phrase translation.'],\n",
       " ['Dialogue is one of the most important aspects of communication.'],\n",
       " ['The importance of punctuation in natural language processing has been debated for many years.'],\n",
       " ['We describe a portable, fast and robust natural language/analyser for advanced document processing systems.'],\n",
       " ['This paper presents the formalism of a replacement expression, which can be composed with transducers that encode: correction rules for the most frequent tagging errors which are automatically generated (Brill, 1992; Roche and Schabes, 1995) or manually written (Chanod and Tapanainen, 1995), in order to'],\n",
       " ['This paper presents a study of the modularity of codescriptive grammars.'],\n",
       " ['Cavnars method, combined with some heuristics, was used by Kikui (Kikui, 1996) to identify languages as well as encodings for a multilingual text.'],\n",
       " ['Multi-tape two-level morphology has been used to describe non-linear phenomena in the domain of non-linear morphology.'],\n",
       " ['This paper presents a formal study of dependency grammar ( DG).'],\n",
       " ['Dependency-based parsing has become quite popular in statistical natural language processing (Lafferty, Sleator, and Temperley 1992; Eisner 1996; Chelba et al.'],\n",
       " ['The aim of this project is to develop a semantics-based system for the classification and coding of medical procedures.'],\n",
       " ['In machine translation, word order is not always essential.'],\n",
       " [\"A cascading word-Pos guesser is reported to achieve higher guessing accuracy than quoted be- fore which in average was about by 8-9% better than that of the Xerox guesser and by 6-7% bet- ter than that of Brill's guesser, reaching 87-92% tagging accuracy on unknown words\"],\n",
       " ['The use of instruction manuals in machines is one of the most important areas of research in computer science.'],\n",
       " ['The aim of this paper is to develop a method for correcting the spelling error in the languages that have no word boundary.'],\n",
       " ['Anaphora resolution of Japanese zero pronouns has been investigated by Hiromi Nakaiwa and Satoshi Shirai (1996).'],\n",
       " ['The goal of word alignments for a bilingual corpus is the translation of a text given in some language F into a target language E.'],\n",
       " ['This paper deals with the problem of anaphora resolution in the field of natural language generation (NLG).'],\n",
       " ['Conjunctive postpositions have been used in Japanese discourse for many years.'],\n",
       " ['The aim of this paper is to evaluate the relaxation labelling algorithm described in Section 2.'],\n",
       " ['The smoothing of the transition probabilities between known and unknown words is one of the most important tasks in machine learning.'],\n",
       " ['The aim of this paper is to provide an overview of the state-of-the-art in natural language processing.'],\n",
       " ['The aim of this paper is to develop a method for selecting a suitable sentence from a speech recognition system using a statistical language model.'],\n",
       " ['A new generation method that produces multiple paraphrases encodes a semantic input which may contain ambiguities.'],\n",
       " ['The goal of this paper is to develop a method for learning concepts belonging to a given semantic class.'],\n",
       " ['Anaphor resolution is one of the most challenging problems in the study of language.'],\n",
       " ['The verbal case frame is an important area of research in machine learning.'],\n",
       " ['Thesauruses are an important part of natural language processing.'],\n",
       " ['The automatic acquisition of word sense definitions has been widely used in computer science for many years.'],\n",
       " ['Sentence selection is one of the most important problems in computer science.'],\n",
       " ['The multiword lexeme is one of the most commonly used expressions in natural language processing.'],\n",
       " ['The problem of identifying unknown words from a corpus of speech is well known.'],\n",
       " ['The word \"ta\" means \"toward\" or \"towards\" or \"towards\" or \"towards\" or \"towards\" (2003a), Takeda, Watanabe & Takeda (1998).'],\n",
       " ['We have developed an automatic word clustering (ATC) system for building thesauri from large corpora.'],\n",
       " ['Sentence compression systems have been tested on corpus data from the Ziff-Davis (ZD, henceforth) by Knight and Marcu (2000), general news articles by Clarke and Lapata (CL, henceforth) corpus (2007) and biomedical articles (Lin and Wilbur, 2007).'],\n",
       " ['Resolving surface divergence of texts into unified semantic representations has attracted much attention from researchers into various NLP applications including question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007; buy.v PropBank).'],\n",
       " ['The question of how to select the most likely answer from a corpus of documents is one of the most frequently asked in computer science.'],\n",
       " ['The aim of this paper is to develop a new approach to word alignment using a multi-lingual, par-allel (or multi-parallel) corpora.'],\n",
       " ['In this paper, we study the quality of Chinese-English and ArabicEnglish translation tasks using f-measure, a discriminative method for alignment.'],\n",
       " ['We have been investigating word sense  (WSD) in machine translation.'],\n",
       " ['Text-to-text rewriting is one of the most exciting areas of computer science.'],\n",
       " ['This talk will focus on the generation of natural language using ASGRE algorithms.'],\n",
       " ['The problem of automatic error de-tection is one of the most challenging in machine learning.'],\n",
       " ['In this paper, we compare the performance of two data-driven models for dependency parsing: MST and Malt.'],\n",
       " ['dependency parsing is one of the most computationally challenging algorithms in computer science, and its performance is often poor.'],\n",
       " ['Semi-supervised dependency-parsing methods for structured data are emerging.'],\n",
       " ['FID is a tool for improving the quality of English text.'],\n",
       " ['Di-rectionality of Inference Rules (DIRT) is a well-known method for learning textual entailment rules.'],\n",
       " ['We present a discriminative model for identifying misspelled web search terms.'],\n",
       " ['First, there are a number of similarity schemes that can be used to achieve good news document coreference performance.'],\n",
       " ['The use of trigram language models in spel-ling correction has been discussed elsewhere, but the use of contextual language models in spel-ling correction has been so success-ful that they are beginning to be rolled out to appli-cations with millions and millions of users.'],\n",
       " ['Table 1 compares the performance of our system on the setup of Cohen and Smith (2007) to the best results reported by them for the same tasks.'],\n",
       " ['Unsupervised lexicon construction for resource-scarce languages is an active area of research (Schone and Jurafsky, 2000; Goldsmith, 2001; Adler and Elhadad, 2006; Creutz and Lagus, 2007; Dasgupta and Ng, 2007; Biemann, 2006; Dasgupta and Ng, 2007; Frei'],\n",
       " ['The extraction of pro-tein interaction information from biomedical texts is an important area of research.'],\n",
       " ['The goal of this paper is to improve the accuracy of sequence alignment algorithms used in computer science.'],\n",
       " ['Sentence generation is a major problem in corpus linguistics.'],\n",
       " ['In this paper, we propose system combination for machine translation (SMT).'],\n",
       " ['The aim of this paper is to develop a synthetic corpus for training machine translation systems.'],\n",
       " ['In this paper we investigate the performance of Markov Models in unsupervised tag-ging.'],\n",
       " ['We have previously proposed a new method for resolving coordinate structures in Japanese.'],\n",
       " ['In this paper, we investigate the use of global features for structured prediction problem in Natural Language Processing (NLP).'],\n",
       " ['The Tongyici Cilin Chinese thesaurus is one of the largest of its kind in the world.'],\n",
       " ['Sentiment summarization has been well studied in the past decade (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Hu and Liu, 2004a, 2004b, Carenini et al., 2006; Liu et al., 2007; Liu and Liu, 2008) but'],\n",
       " ['A new entropy-based external evaluation measure for clustering is presented.'],\n",
       " ['We study the morphology of taggers in Hebrew.'],\n",
       " ['The goal of this paper is to develop a fully automated single-document extract sum-marie of newswire articles.'],\n",
       " ['e-negotiations and agent-customer interactions are growing in popularity.'],\n",
       " ['Language modelling is one of the most important areas of research in computer science, and the use of language models in computer code is a major challenge.'],\n",
       " ['In recent years active learning (AL) has attracted a lot of research interest, and has been studied in many natural language processing (NLP) tasks, such as text classification (TC) (Lewis and Gale, 1994; McCallum and Nigam, 1998), chunking (Ngai and Yarowsky, 2000),'],\n",
       " ['The aim of this paper is to investigate the use of natural language processing (NLP) for augmented and alternative communication systems.'],\n",
       " ['In this paper, the training criteria for statisti-cal machine translation (MERT) are compared with the training criteria for statisti-cal machine translation (SMT).'],\n",
       " ['The question of whether subject pronouns are referential in pro-drop languages has been debated for many years.'],\n",
       " ['Measures of word relatedness are useful for a large number of applications, including cross-language information retrieval (Nie et al., 1999; Monz and Dorr, 2005), cross-language text classification (Gliozzo and Strapparava, 2006), lexical choice in machine translation (Och and'],\n",
       " ['The aim of this paper is to develop a new method for measuring semantic relatedness for wordpairs based on random walkMarkov chain theory.'],\n",
       " ['The LTAG-spinal Treebank (LTAG) can be used to overcome some of the limitations of the previous work on SRL using LTAG: (Liu and Sarkar, 2007) uses LTAG-based features extracted from phrase-structure trees as an additional source of features and combined them with features from a'],\n",
       " ['In this paper, we propose a new learning model for detecting disambiguating coor-dinate conjunctions.'],\n",
       " ['Wikipedia has been used as a knowledge source for several language processing tasks, including taxonomy construction (Ponzetto and Strube, 2007a), coreference resolution (Ponzetto and Strube, 2007b), and English NER (e.g., Bunescu and Pasca 2006), Watanabe et al'],\n",
       " ['We present a new method for dynamically ranking speakers in a discussion.'],\n",
       " ['In our work, we explicitly model a prior over grammars within a Bayesian framework, aiming to automatically learn latent structure underlying treebanked data (Petrov et al., 2006; Liang et al., 2007; Finkel et al., 2007; DeNero et al., 2008).'],\n",
       " ['Named Entity Recognition (NER) can be improved by using gazetteers.'],\n",
       " ['The use of Wikipedia as a knowledge source for various language processing tasks has recently been used as a knowledge source for taxonomy construction (Ponzetto and Strube, 2007a), coreference resolution (Ponzetto and Strube, 2007b), and English NER (e.g., Bunescu and'],\n",
       " ['Information extraction (IE) is one of the most computationally intensive tasks in terrorism research.'],\n",
       " ['syntactic reordering of ap-proach for translation from Chinese to English.'],\n",
       " ['Syntax-based translation models can be used to produce desir-able translations.'],\n",
       " ['Machine translation has become a major area of research in the fields of computer science and linguistics.'],\n",
       " ['In recent years, there has been a growing interest in active learning (AL) methods for word sense and text classification.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmed Rashid considers the meaning of query tokens.'],\n",
       " ['The aim of this paper is to train a language model for a text database.'],\n",
       " ['This research focuses on the discovery and extraction of information from large corpora or heterogeneous resources.'],\n",
       " ['Citation analysis in the biosciences has been explored in several studies (Nakov et al., 2004; Ritchie et al., 2004; Schwartz et al., 2007; Siddharthan and Teufel, 2007; Nakov et al., 2004; Ritchie et al., 2004; Ritchie et al., 2004; Ritchie et'],\n",
       " ['We have used tensor perplexity (TPTs) to encode n-gram count databases such as the Google 1T web n-gram database (Brants and Franz, 2006), but are not able to provide detailed results within the space limitations of this paper.'],\n",
       " ['The phrase-based statistical machine translation (SMT) model has been widely used for translating from one language to another.'],\n",
       " ['analogical learning has been proposed as a method for improving information retrieval in the fields of search and translation.'],\n",
       " ['The CoNLL 2007 shared task tackled domain adaptation of dependencys for the rst time (Nivre et al., 2007; Nivre et al., 2007; Nivre et al., 2007; Nivre et al., 2007; Nivre et al., 2007; Nivre et al., 2007; Ni'],\n",
       " ['One of the major challenges in the field of dependency parsing is the problem of parsing multilingual input sequences.'],\n",
       " ['beam search for transition sequences in a dependency tree is a computationally challenging problem.'],\n",
       " ['We have developed a new type of dependency model for the parsing of texts written in different languages.'],\n",
       " ['In this paper, we explore the use of global features for graph-based parsing of structured prediction problems.'],\n",
       " ['This paper presents two extensions to the first-order model for dependency parsing.'],\n",
       " ['A number of techniques have been developed to improve the performance of learning systems.'],\n",
       " ['We have been developing techniques to improve the accuracy of phrase-based translation (SMT) systems.'],\n",
       " ['A new pipeline for efficient rule extraction in phrase-based translation systems is presented.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmedou Ould-Abdallah looks at the importance of proper name translation.'],\n",
       " ['A sense clustering algorithm for WordNet (WSD) has been proposed as a novel way to reduce the granularity of sense inventories.'],\n",
       " ['The word sense detection (WSD) task is one of the most challenging in computer science.'],\n",
       " ['In Sagae and Tsujii (2007).'],\n",
       " ['The aim of this paper is to investigate the effectiveness of feature-based learning (SCL) on the domain adaptation of NLP tasks.'],\n",
       " ['Opinion forecasting is one of the most promising areas of research in computer science.'],\n",
       " ['The aim of this paper is to develop a novel method for extracting customer opinions from weblog posts.'],\n",
       " ['Opinion mining has been a large and diverse body of research in opinion extraction, with most research at the text level.'],\n",
       " ['The problem of de-termining case of nouns and adjectives in syntactictrees is extremely useful, given the harmfulness of annotation errors for training, including the learning of noise.'],\n",
       " ['In this paper, we investigate the use of fine-grained latent annotations for Chinese part-of-speech tagging.'],\n",
       " ['Data-driven grammars, such as Bick (2007), Schneider et al.'],\n",
       " ['We have trained transition-based beam search models and graph-based beam search models.'],\n",
       " ['The goal of this paper is to improve the state-of-the-art in transition-based inference.'],\n",
       " ['In this paper we present a new model for transition-based dependency parsing, based on the assumption that the current state and history of a sentence will change over time.'],\n",
       " ['In this paper, we show that some graph-based parsing systems can correctly identify dependencies between sentences.'],\n",
       " ['dependency graphs are often used to train inference-based systems.'],\n",
       " ['The Pro3Gres is a dependency-trained system for tree-bank-grammar-based statistics.'],\n",
       " ['Structural correspondence learning (SCL) has been proposed as a novel approach to parsing languages.'],\n",
       " ['This paper reports on the training and adaptation of grammar-based learning models.'],\n",
       " ['The aim of this paper is to train machine learning-based word segmentation methods.'],\n",
       " ['The expected size of an argument set for a relation is a common problem for information extraction.'],\n",
       " ['In this work, we investigate the performance of a discriminative learning model for corpus-based word search.'],\n",
       " ['The use of dependency syntax in automatic role-semantic analysis has been discussed in a number of papers.'],\n",
       " ['We have developed a novel system for inference from large chunks of text extracted from the Web.'],\n",
       " ['The search for new translations in machine translation (SMT) systems has become increasingly important.'],\n",
       " ['In this paper, we present a new approach to the integration of language models with machine translation (ITG).'],\n",
       " ['subjectivity analysis in English is one of the most important areas of research in machine learning (Banea et al., 2008; Banea et al., 2008).'],\n",
       " ['In this paper, we present a novel method for parsing dependency trees using Monte Carlo.'],\n",
       " ['In this paper, we study the efficiency of binarizations in context-free grammar parsing.'],\n",
       " ['In this paper, we present a novel approach to automatic text summarization.'],\n",
       " ['This paper presents a new study on the interplay between discourse apects and language model features that have been extensively studied in prior work.'],\n",
       " ['We want to improve the quality of para-phrases extracted from parallel corpora.'],\n",
       " ['A discriminative training model for machine translation is presented.'],\n",
       " ['The aim of this work is to improve the quality of translation training by exploiting more of the parse forest.'],\n",
       " ['The aim of this paper is to investigate the annotation of natural language using the Amazon Mechanical Turk service.'],\n",
       " ['This paper presents work on the cross-document entity co-reference problem.'],\n",
       " ['A new classification-based coreference resolution system is proposed and tested in the context of a corpus of English language content (ACE) dataset.'],\n",
       " ['The aim of this paper is to investigate the use of Bayesian methods to learn phrase pairs from a bilingual corpus with little or no dependence on word alignments.'],\n",
       " ['Chinese speech recognition (SRL) is one of the fastest growing areas of research in artificial intelligence.'],\n",
       " ['Unsupervised topic segmentation is a major problem in machine learning.'],\n",
       " ['This paper is part of a series of papers on machine learning.'],\n",
       " ['Historical citation anal-ysis is the study of the history of ideas in research literature.'],\n",
       " ['One of the major challenges faced by linguists is the issue of cross-lingual translation.'],\n",
       " ['Questions and Answers (Q&A) are one of the most popular forms of document retrieval.'],\n",
       " ['The goal of this paper is to develop a scalable language processing algorithm that can be trained on large amounts of data.'],\n",
       " ['The term variation gen(q) is a well-known feature in the classification of English strings.'],\n",
       " ['The acquisition of frame semantics in Natural Language Processing (NLP) systems is an important area of research.'],\n",
       " ['subjectivity detection in face-to-face spoken communication.'],\n",
       " ['The aim of this study is to investigate whether Categorial Grammars ( CCGs) can be trained by constructions specific to the whobject construction.'],\n",
       " ['LTAG basedparsing has been developed for the generation of non-projective constructions on the treebank.'],\n",
       " ['We have proposed a new topic model forhypertext documents in this paper.'],\n",
       " ['The aim of this paper is to present a new approach to the problem of predicate argument structure analysis.'],\n",
       " ['In recent years, the use of Chinese lexicons for sentiment analysis has become increasingly popular.'],\n",
       " ['We have developed an arc-standard beam-search algorithm for parsing English Treebank data.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmedou Ould-Abdallah looks at some of the challenges that translators face when translating from one language to another.'],\n",
       " ['The aim of this paper is to improve information extraction algorithms by combining information sources and information extraction algorithms.'],\n",
       " ['Machine translation is one of the fastest growing fields in computer science.'],\n",
       " ['The loss function is a well-known problem in statistical language processing.'],\n",
       " ['Coreference resolution is one of the most challenging problems in machine learning.'],\n",
       " ['A general-purpose unsupervised learning model for unsuper-vised coreference resolution.'],\n",
       " ['In this paper, we introduce two new machine learning approaches for coreference resolution: a mention-ranking model and a tournament-based or ranking-based model.'],\n",
       " ['Multi-domain learning and adaptation is an emerging area of research in natural language processing.'],\n",
       " ['Markov Logic has been proposed as a solution to the problem of identifying temporal relation between events.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmed Rashid looks at the absence of grammatical tense and explicit expressions in Chinese.'],\n",
       " ['The scope of negation is an important problem in natural language processing (NLP), and a recent study (Morante et al., 2008) focuses on learning negation scope using memory-based classifiers trained on the BioScope corpus.'],\n",
       " ['We have proposed a new class of training criteria that provides a tighter connection between the decision rule and the final error metric.'],\n",
       " ['We have been investigating the influence of language pairs on translation quality.'],\n",
       " ['The aim of this paper is to investigate the use of summarization to extract knowledge from large document collections.'],\n",
       " ['How do we summarize conversations?'],\n",
       " ['The polarity of sentiment-bearing ex-pressions at or below the sentence level requires a bag-of-words approach.'],\n",
       " ['One of the major problems in natural language inference is the problem of natural language alignment.'],\n",
       " ['Decipherment is one of the most difficult programming problems.'],\n",
       " ['This paper presents a novel phrase-based translation system, DE-Annotated, based on a hierarchical phrase reordering model introduced by Galley and Manning (2008).'],\n",
       " ['We have presented a novel beamsearch algorithm to extract sentence pairs from comparable data.'],\n",
       " ['We have developed a self-training system for the parsing of coarse grammars.'],\n",
       " ['In this paper, we show how to train a machine translation model on English Chinese bitexts from the Chinese Translation Treebank (CTB).'],\n",
       " ['This paper presents a method for measur-ing the performance of statistical natural language parses on a wide range of domains and genres.'],\n",
       " ['corpus-based language processing is an emerging area of research in machine learning.'],\n",
       " ['Questions annealing (QA) is one of the most common tasks in QA research.'],\n",
       " ['This paper presents a new approach to the problem of Antonyms.'],\n",
       " ['We have addressed the problem of token classification in Japanese using supervised learning.'],\n",
       " ['The aim of this work is to develop and test an artificial intelligence (AI) system for learning English.'],\n",
       " ['This paper presents a BayesianHierarchical Markov Model (HMM) for part-of-speech tagging using corpus data from the Wall Street Journal (WSJ).'],\n",
       " ['Active learning (AL) is one of the most widely used techniques for learning to speak (L2P).'],\n",
       " ['We show that discriminative character and indicator features can be used to solve word problems in machine learning.'],\n",
       " ['The first and more closely related class deals with extracting information from a large database such as Wikipedia.'],\n",
       " ['The classification of Ontology Population from texts has been investigated in the literature by Tanev and Magnini (2006), Fleischman and Hovy (2006), Volker and Volker (2005), Thelen and Riloff (2002), Roark and Charniak (1998), Phillips and Riloff (2002), Pantel and Ravichandran (2004)'],\n",
       " ['This paper is part of a series of papers on statistical machine translation.'],\n",
       " ['In this paper, we propose a system combination algorithm based on confusion networks for machine translation.'],\n",
       " ['The aim of this paper is to investigate the use of cooperative responses ( CG) in spoken dialogue systems.'],\n",
       " ['syntactic parsing of data-driven treebanks has become a major area of research in machine learning.'],\n",
       " ['parsing dependency graphs in which aword may depend on multiple heads.'],\n",
       " ['syntactic structure of Turkish sentences using dependency grammars.'],\n",
       " ['La-tent Analysis (LA) has been proposed as a method for improving the performance of informationaccess tasks such as Transaction Server (TS).'],\n",
       " ['The use of tree kernels for Natural Language Processing (NLP) has been widely discussed in the literature.'],\n",
       " ['Mohammad and Hirst (2006) have proposed a bootstrapped corpus-based word sense dominance model (WCCM).'],\n",
       " ['The one-to-one constraint on syntax toword alignment has been well-established since the 1970s (Cherry and Lin, 2006).'],\n",
       " ['We investigate the problem of second-person pronoun resolution in speech.'],\n",
       " ['Opinion mining is an emerging area of text processing research. Researchers have found this at various levels of analysis, including the manual annotation of phrases (Takamura et al., 2006), sentiment classification of phrases (Wilson et al., 2005), sentiment tagging of words (Andreevskaia and Bergler,'],\n",
       " ['subjectivity analysis is the study of the meaning of words and phrases.'],\n",
       " ['We report on the compositional method (the underlined Japanese MWT actually exists) which produces all the combinations of shorter multi-word unit elements of a length less than or equal to a3.'],\n",
       " ['The aim of this paper is to show how a corpus of web content can be used to improve search engine results.'],\n",
       " ['This paper presents the results of a focussed analysis of the output of a machine translation system that has been substituted for a human translation system.'],\n",
       " ['Part-of-speech ( POS) tagging has become a popular method for learning from large amounts of data, but it is not clear how to learn from consistently misannotated data.'],\n",
       " ['The aim of this paper is to investigate the performance of automatic segmentation algorithms for multiparty dialogues.'],\n",
       " ['The aim of this paper is to develop a tutoring system that adapts to the needs of the student.'],\n",
       " ['This paper presents a questionnaire that can be used to study sentiment summarization.'],\n",
       " ['How well various corpus-based metrics agree with human judgments, when evaluating several NLG systems that generate sentences which de-scribe changes in the wind.'],\n",
       " ['The problem of generating appropriate descriptions for domain objects is well known.'],\n",
       " ['The aim of this project is to investigate the use of WordNet (WSD) to detect metaphor in corpus data.'],\n",
       " ['fuzzy cat-egory Examples of fuzzy cat-egory include idioms such as by andlarge, the bucket, and let the cat out of thebag.'],\n",
       " ['The use of facial gestures as part of multimodal dialogue systems has been explored in a number of papers.'],\n",
       " ['This paper presents a new approach to the parsing of Arabic dialects.'],\n",
       " ['Relation extraction (IR) is one of the fastest growing areas of Natural Language Processing (NLP).'],\n",
       " ['The aim of this paper is to show how to crawl the Web in a language.'],\n",
       " ['The aim of this research is to develop a language that can be used by non-experts to develop dialogue systems based on Business Process Models.'],\n",
       " ['In this paper we present a methodol-ogy that automatically selects an appropriate value for a word sense discrimination algorithm.'],\n",
       " ['In our research we have developed an in-car dialogue system which can be used as a platform for Reinforcement Learning.'],\n",
       " ['We are developing an algorithm for detecting trans-lation equivalents for technical vocabulary in a re-stricted domain.'],\n",
       " ['This paper presents a new approach to coreference resolution using semantic role features.'],\n",
       " ['Text-based Natural Language Processing (NLP) has become a major area of research in computer science.'],\n",
       " ['A new method for the analysis of dimensionality vectors between terms has been proposed.'],\n",
       " [\"The RoadSafe project aimed to reduce the number of deaths on Scotland's roads by improving road safety and reducing congestion.\"],\n",
       " ['The Wall Street Journal (WSJ) is an excellent example of a large-scale data set that is difficult to model using existing methods.'],\n",
       " ['A large number of text processing applications have already employed techniques for automatic subjectivity analysis, including automatic expressive text-to-speech synthesis and text semantic analysis.'],\n",
       " ['WhyQA is an emerging field in Rhetorical Analysis.'],\n",
       " ['Information retrieval methods for retrieving answers to how-to questions on the Web have been addressed for decades, often with very satisfying commercial products able to interact not only in text but especially via spoken interfaces.'],\n",
       " ['In this study, TiMBL was employed to train a metonymy classifier on a large corpus of corpus data.'],\n",
       " ['The internal grammar of the Italian language is governed by a set of rules which governed by a set of rules which are governed by a set of rules which are governed by a set of rules which are governed by a set of rules which are governed by a set of rules which are governed by a set of rules which'],\n",
       " ['The problems of conjunctions Coordinates for machine translation systems are discussed.'],\n",
       " ['The problem of synta tic analysis of N.L. L.Lesmo, P.Torasso (1983) : A Flexible Natural Language  Based on a To-ievel of Syntax.'],\n",
       " ['\"Every scheduler assigned a priority.'],\n",
       " ['In our group we have been developing a functional system for parsing Finnish.'],\n",
       " ['This paper is the latest in a series of papers on incremental parsing and interpretation of natural language.'],\n",
       " ['This paper considers the morphology and descriptional adequacy of the lexicon in Inflexlonal languages.'],\n",
       " ['This paper presents a probabilistic approach to the problem of tagging English language corpora.'],\n",
       " ['A natural anguage parsing system for dictionary entries has been proposed.'],\n",
       " ['A formalism for describing morphographemics is often discussed in terms of automata, but only if the rules adhere to theiz defined interpretation.'],\n",
       " ['The analysis of collocative meaning representation in the literature has led to the development of a number of NLP systems.'],\n",
       " ['The aim of this research is to develop a machine-readable dictionary for English.'],\n",
       " ['default inheritance networks have been proposed for the generation and automatic dictionary construction of lexicons (LKBs).'],\n",
       " ['Preference strategies have often been used for deal ing with the problem of ill- formed input (a part icular case of robust-ness,cf below section 2.2) (AJCL 1983, Charniak 1983).'],\n",
       " ['The aim of this paper is to show how a natural language interface called CWISE can be used in the development of computer software.'],\n",
       " ['Rule-invocation algorithms are used in many areas of graph analysis, such as histograms and candlesticks.'],\n",
       " ['This paper presents a new construction of the derivational equiva- lence problem in Combinatory Categorial Grammar (CCG).'],\n",
       " ['The Islamic State (IS) leader, Abu Bakr al-Baghdadi, has described a level of discourse structure for problem-solving dialogs.'],\n",
       " ['A new approach to the analysis of tenses on a Reichenbachian analysis is proposed.'],\n",
       " ['This paper presents a new approach to morphology and orthographic variation.'],\n",
       " ['A new language for representing knowledge, the lexical knowledge representation language (KATR), has been proposed by Roger Evans and Gerald Gazdar.'],\n",
       " ['A constraint logic programming language, cu-Prolog, is presented in this paper.'],\n",
       " ['In this paper I present two new approaches to the analysis of the grammar.'],\n",
       " ['The SRI Core Language Engine is a machine-readable dictionary designed to be used in the teaching of English.'],\n",
       " ['The management of word forms in Inflexional languages is a major problem in the area of natural language processing.'],\n",
       " ['The problem of plural anaphora is of particular interest to artificial intelligence (AI) researchers.'],\n",
       " ['A natural anguage generation approach to the production of explanations from knowledge-based systems.'],\n",
       " ['The use of unification-based formahsms in grammars has been investigated in a number of research projects over the past two decades.'],\n",
       " ['Our work on French syntax supports the claim that the complicated pattern of French linearity phenomena can be treated in a framework closely related to UCG.'],\n",
       " ['syntactic analysis of natural language sentences.'],\n",
       " ['The aim of this paper is to outline the approach to the translation of non-local reentrances proposed in Kaplan et al (1989).'],\n",
       " ['This paper presents the results of the PENMAN project, which developed a machine translation grammar for English and a machine translation grammar for German.'],\n",
       " ['The aim of this dissertation is to develop a new method for dealing with ambiguity in natural language grammars.'],\n",
       " ['The aim of this paper is to investigate head-driven parsing strategies for Lexicalized Tree Adjoining Grammars.'],\n",
       " ['The relationship between pronouns (NPs) and sentences is an important problem in the study of formal languages.'],\n",
       " ['In my previous chapter on syntactic analysis, I described a technique for testing command relations described in Latecki (1991).'],\n",
       " ['A description language based on types and constraints has been proposed in Saint-Dizier (1991).'],\n",
       " ['In this paper, Isamu Tomita presents a new approach to parse table construction.'],\n",
       " ['This paper presents a system for the management of spoken dialogues in VERBMOBIL.'],\n",
       " ['phonological description is a branch of formal language theory.'],\n",
       " ['How do we deal with words which do not appear in the English lexicon?'],\n",
       " ['Morphological and morphophonological generalisations in the lexicon have been of particular interest to computational linguists.'],\n",
       " ...]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_downstream = []\n",
    "k=0\n",
    "for i in range(len(summaries)):\n",
    "    string = summaries[i][0] + \" \" + df.Citations[i]\n",
    "    k+=1\n",
    "    \n",
    "    batch = tokenizer(string, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    translated = model.generate(**batch)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "\n",
    "    f = open('aan_data_xsum_summaries_downstream_r1.csv','a')\n",
    "    f.write(tgt_text[0])\n",
    "    f.write('\\n') \n",
    "    f.close()\n",
    "    \n",
    "    summaries_downstream.append(tgt_text)\n",
    "    if k % 10 == 1:\n",
    "        print(k)\n",
    "summaries_downstream "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare summaries\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1','rouge2', 'rougeL','rougeLsum'], use_stemmer=True)\n",
    "scores = []\n",
    "for i in range(len(summaries)):\n",
    "\n",
    "    s = scorer.score(df.Abstract[i], summaries[i][0])\n",
    "    \n",
    "    #simpler flat structure\n",
    "    x = {\n",
    "        \"rouge1:precision\":s[\"rouge1\"][0],\n",
    "        \"rouge1:recall\":s[\"rouge1\"][1],\n",
    "        \"rouge1:fmeasure\":s[\"rouge1\"][2],\n",
    "        \"rouge2:precision\":s[\"rouge2\"][0],\n",
    "        \"rouge2:recall\":s[\"rouge2\"][1],\n",
    "        \"rouge2:fmeasure\":s[\"rouge2\"][2],\n",
    "        \"rougeL:precision\":s[\"rougeL\"][0],\n",
    "        \"rougeL:recall\":s[\"rougeL\"][1],\n",
    "        \"rougeL:fmeasure\":s[\"rougeL\"][2],\n",
    "        \"rougeLsum:precision\":s[\"rougeLsum\"][0],\n",
    "        \"rougeLsum:recall\":s[\"rougeLsum\"][1],\n",
    "        \"rougeLsum:fmeasure\":s[\"rougeLsum\"][2],\n",
    "        \n",
    "    }\n",
    "    scores.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1:precision</th>\n",
       "      <th>rouge1:recall</th>\n",
       "      <th>rouge1:fmeasure</th>\n",
       "      <th>rouge2:precision</th>\n",
       "      <th>rouge2:recall</th>\n",
       "      <th>rouge2:fmeasure</th>\n",
       "      <th>rougeL:precision</th>\n",
       "      <th>rougeL:recall</th>\n",
       "      <th>rougeL:fmeasure</th>\n",
       "      <th>rougeLsum:precision</th>\n",
       "      <th>rougeLsum:recall</th>\n",
       "      <th>rougeLsum:fmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.552497</td>\n",
       "      <td>0.112506</td>\n",
       "      <td>0.178467</td>\n",
       "      <td>0.164739</td>\n",
       "      <td>0.031822</td>\n",
       "      <td>0.050710</td>\n",
       "      <td>0.398247</td>\n",
       "      <td>0.080006</td>\n",
       "      <td>0.127019</td>\n",
       "      <td>0.398247</td>\n",
       "      <td>0.080006</td>\n",
       "      <td>0.127019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.184309</td>\n",
       "      <td>0.064809</td>\n",
       "      <td>0.082544</td>\n",
       "      <td>0.161686</td>\n",
       "      <td>0.040516</td>\n",
       "      <td>0.056609</td>\n",
       "      <td>0.156621</td>\n",
       "      <td>0.049813</td>\n",
       "      <td>0.063122</td>\n",
       "      <td>0.156621</td>\n",
       "      <td>0.049813</td>\n",
       "      <td>0.063122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.070707</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.049689</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.049689</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.115942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>0.152174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rouge1:precision  rouge1:recall  rouge1:fmeasure  rouge2:precision  \\\n",
       "count       1781.000000    1781.000000      1781.000000       1781.000000   \n",
       "mean           0.552497       0.112506         0.178467          0.164739   \n",
       "std            0.184309       0.064809         0.082544          0.161686   \n",
       "min            0.000000       0.000000         0.000000          0.000000   \n",
       "25%            0.428571       0.070707         0.123077          0.050000   \n",
       "50%            0.555556       0.098361         0.166667          0.125000   \n",
       "75%            0.681818       0.139535         0.222222          0.250000   \n",
       "max            1.000000       0.641026         0.746269          1.000000   \n",
       "\n",
       "       rouge2:recall  rouge2:fmeasure  rougeL:precision  rougeL:recall  \\\n",
       "count    1781.000000      1781.000000       1781.000000    1781.000000   \n",
       "mean        0.031822         0.050710          0.398247       0.080006   \n",
       "std         0.040516         0.056609          0.156621       0.049813   \n",
       "min         0.000000         0.000000          0.000000       0.000000   \n",
       "25%         0.008403         0.014706          0.285714       0.049689   \n",
       "50%         0.021277         0.035294          0.384615       0.068966   \n",
       "75%         0.043478         0.071429          0.500000       0.097087   \n",
       "max         0.552632         0.646154          1.000000       0.615385   \n",
       "\n",
       "       rougeL:fmeasure  rougeLsum:precision  rougeLsum:recall  \\\n",
       "count      1781.000000          1781.000000       1781.000000   \n",
       "mean          0.127019             0.398247          0.080006   \n",
       "std           0.063122             0.156621          0.049813   \n",
       "min           0.000000             0.000000          0.000000   \n",
       "25%           0.086957             0.285714          0.049689   \n",
       "50%           0.115942             0.384615          0.068966   \n",
       "75%           0.152174             0.500000          0.097087   \n",
       "max           0.716418             1.000000          0.615385   \n",
       "\n",
       "       rougeLsum:fmeasure  \n",
       "count         1781.000000  \n",
       "mean             0.127019  \n",
       "std              0.063122  \n",
       "min              0.000000  \n",
       "25%              0.086957  \n",
       "50%              0.115942  \n",
       "75%              0.152174  \n",
       "max              0.716418  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare summaries\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1','rouge2', 'rougeL','rougeLsum'], use_stemmer=True)\n",
    "scores = []\n",
    "for i in range(len(summaries_downstream)):\n",
    "\n",
    "    s = scorer.score(df.Abstract[i], summaries_downstream[i][0])\n",
    "    \n",
    "    #simpler flat structure\n",
    "    x = {\n",
    "        \"rouge1:precision\":s[\"rouge1\"][0],\n",
    "        \"rouge1:recall\":s[\"rouge1\"][1],\n",
    "        \"rouge1:fmeasure\":s[\"rouge1\"][2],\n",
    "        \"rouge2:precision\":s[\"rouge2\"][0],\n",
    "        \"rouge2:recall\":s[\"rouge2\"][1],\n",
    "        \"rouge2:fmeasure\":s[\"rouge2\"][2],\n",
    "        \"rougeL:precision\":s[\"rougeL\"][0],\n",
    "        \"rougeL:recall\":s[\"rougeL\"][1],\n",
    "        \"rougeL:fmeasure\":s[\"rougeL\"][2],\n",
    "        \"rougeLsum:precision\":s[\"rougeLsum\"][0],\n",
    "        \"rougeLsum:recall\":s[\"rougeLsum\"][1],\n",
    "        \"rougeLsum:fmeasure\":s[\"rougeLsum\"][2],\n",
    "        \n",
    "    }\n",
    "    scores.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1:precision</th>\n",
       "      <th>rouge1:recall</th>\n",
       "      <th>rouge1:fmeasure</th>\n",
       "      <th>rouge2:precision</th>\n",
       "      <th>rouge2:recall</th>\n",
       "      <th>rouge2:fmeasure</th>\n",
       "      <th>rougeL:precision</th>\n",
       "      <th>rougeL:recall</th>\n",
       "      <th>rougeL:fmeasure</th>\n",
       "      <th>rougeLsum:precision</th>\n",
       "      <th>rougeLsum:recall</th>\n",
       "      <th>rougeLsum:fmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.492745</td>\n",
       "      <td>0.094913</td>\n",
       "      <td>0.152176</td>\n",
       "      <td>0.106582</td>\n",
       "      <td>0.018753</td>\n",
       "      <td>0.030466</td>\n",
       "      <td>0.355801</td>\n",
       "      <td>0.067263</td>\n",
       "      <td>0.108079</td>\n",
       "      <td>0.355801</td>\n",
       "      <td>0.067263</td>\n",
       "      <td>0.108079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.170404</td>\n",
       "      <td>0.050522</td>\n",
       "      <td>0.066883</td>\n",
       "      <td>0.119133</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>0.036138</td>\n",
       "      <td>0.138073</td>\n",
       "      <td>0.036348</td>\n",
       "      <td>0.048105</td>\n",
       "      <td>0.138073</td>\n",
       "      <td>0.036348</td>\n",
       "      <td>0.048105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.060345</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.074766</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.074766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.100719</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.100719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rouge1:precision  rouge1:recall  rouge1:fmeasure  rouge2:precision  \\\n",
       "count       1781.000000    1781.000000      1781.000000       1781.000000   \n",
       "mean           0.492745       0.094913         0.152176          0.106582   \n",
       "std            0.170404       0.050522         0.066883          0.119133   \n",
       "min            0.000000       0.000000         0.000000          0.000000   \n",
       "25%            0.380952       0.060345         0.105263          0.000000   \n",
       "50%            0.500000       0.084507         0.142857          0.076923   \n",
       "75%            0.600000       0.118644         0.188679          0.153846   \n",
       "max            1.000000       0.434783         0.433962          1.000000   \n",
       "\n",
       "       rouge2:recall  rouge2:fmeasure  rougeL:precision  rougeL:recall  \\\n",
       "count    1781.000000      1781.000000       1781.000000    1781.000000   \n",
       "mean        0.018753         0.030466          0.355801       0.067263   \n",
       "std         0.023970         0.036138          0.138073       0.036348   \n",
       "min         0.000000         0.000000          0.000000       0.000000   \n",
       "25%         0.000000         0.000000          0.260870       0.043103   \n",
       "50%         0.012821         0.021858          0.350000       0.060000   \n",
       "75%         0.025641         0.043478          0.437500       0.082645   \n",
       "max         0.272727         0.357143          1.000000       0.434783   \n",
       "\n",
       "       rougeL:fmeasure  rougeLsum:precision  rougeLsum:recall  \\\n",
       "count      1781.000000          1781.000000       1781.000000   \n",
       "mean          0.108079             0.355801          0.067263   \n",
       "std           0.048105             0.138073          0.036348   \n",
       "min           0.000000             0.000000          0.000000   \n",
       "25%           0.074766             0.260870          0.043103   \n",
       "50%           0.100719             0.350000          0.060000   \n",
       "75%           0.133333             0.437500          0.082645   \n",
       "max           0.400000             1.000000          0.434783   \n",
       "\n",
       "       rougeLsum:fmeasure  \n",
       "count         1781.000000  \n",
       "mean             0.108079  \n",
       "std              0.048105  \n",
       "min              0.000000  \n",
       "25%              0.074766  \n",
       "50%              0.100719  \n",
       "75%              0.133333  \n",
       "max              0.400000  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAN PEGASUS-ARXIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Body</th>\n",
       "      <th>Citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A major obstacle to the construction ofa pro...</td>\n",
       "      <td>Parallel texts have been used in a number of...</td>\n",
       "      <td>A compilation of parallel texts offered in a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This paper proposes a way to improve the tran...</td>\n",
       "      <td>Recently, various dialogue translation syste...</td>\n",
       "      <td>We plan to improve the accuracy obtained so fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This paper describes an application of APE (t...</td>\n",
       "      <td>The purpose of the Atlas project is to enlarg...</td>\n",
       "      <td>Computer dialogue is now used at production st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this paper we describe an implemented fram...</td>\n",
       "      <td>In this paper we present a linguistically mot...</td>\n",
       "      <td>From this viewpoint, research on paraphrasing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This paper reports on a large-scale, end-to- ...</td>\n",
       "      <td>One major goal of information extraction (IE)...</td>\n",
       "      <td>For example, Aone and Ramos-Santacruz (2000) p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>We present in this paper an unsupervised meth...</td>\n",
       "      <td>Development of electronic morphological resou...</td>\n",
       "      <td>Next along the spectrum of orthographic simila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>This paper presents an unsupervised method fo...</td>\n",
       "      <td>Choosing the correct translation of a content...</td>\n",
       "      <td>For comparable corpora, previous bilingual sen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>In this paper we report on an unsupervised a...</td>\n",
       "      <td>In this paper we discuss a potential solutio...</td>\n",
       "      <td>Watkinson and Manandhar (1999) present an unsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>This paper presents results from a study comp...</td>\n",
       "      <td>In evaluating the state of technology for ext...</td>\n",
       "      <td>It may be noted that \"correctly\" is a problema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>Over the past few years, HNC has developed a ...</td>\n",
       "      <td>While the current MatchPlus learning law has ...</td>\n",
       "      <td>As such a matrix reduction, we utilized a lear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4273 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Abstract  \\\n",
       "0       A major obstacle to the construction ofa pro...   \n",
       "1      This paper proposes a way to improve the tran...   \n",
       "2      This paper describes an application of APE (t...   \n",
       "3      In this paper we describe an implemented fram...   \n",
       "4      This paper reports on a large-scale, end-to- ...   \n",
       "...                                                 ...   \n",
       "4268   We present in this paper an unsupervised meth...   \n",
       "4269   This paper presents an unsupervised method fo...   \n",
       "4270    In this paper we report on an unsupervised a...   \n",
       "4271   This paper presents results from a study comp...   \n",
       "4272   Over the past few years, HNC has developed a ...   \n",
       "\n",
       "                                                   Body  \\\n",
       "0       Parallel texts have been used in a number of...   \n",
       "1       Recently, various dialogue translation syste...   \n",
       "2      The purpose of the Atlas project is to enlarg...   \n",
       "3      In this paper we present a linguistically mot...   \n",
       "4      One major goal of information extraction (IE)...   \n",
       "...                                                 ...   \n",
       "4268   Development of electronic morphological resou...   \n",
       "4269   Choosing the correct translation of a content...   \n",
       "4270    In this paper we discuss a potential solutio...   \n",
       "4271   In evaluating the state of technology for ext...   \n",
       "4272   While the current MatchPlus learning law has ...   \n",
       "\n",
       "                                              Citations  \n",
       "0     A compilation of parallel texts offered in a s...  \n",
       "1     We plan to improve the accuracy obtained so fa...  \n",
       "2     Computer dialogue is now used at production st...  \n",
       "3     From this viewpoint, research on paraphrasing ...  \n",
       "4     For example, Aone and Ramos-Santacruz (2000) p...  \n",
       "...                                                 ...  \n",
       "4268  Next along the spectrum of orthographic simila...  \n",
       "4269  For comparable corpora, previous bilingual sen...  \n",
       "4270  Watkinson and Manandhar (1999) present an unsu...  \n",
       "4271  It may be noted that \"correctly\" is a problema...  \n",
       "4272  As such a matrix reduction, we utilized a lear...  \n",
       "\n",
       "[4273 rows x 3 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PG&E scheduled the blackouts in response to forecasts for high winds amid dry conditions.<n>The aim is to reduce the risk of wildfires.']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text = [\n",
    "     \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
    "]\n",
    "\n",
    "model_name = 'google/pegasus-cnn_dailymail'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "amodel = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "translated = amodel.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "11\n",
      "21\n",
      "31\n",
      "41\n",
      "51\n",
      "61\n",
      "71\n",
      "81\n",
      "91\n",
      "101\n",
      "111\n",
      "121\n",
      "131\n",
      "141\n",
      "151\n",
      "161\n",
      "171\n",
      "181\n",
      "191\n",
      "201\n",
      "211\n",
      "221\n",
      "231\n",
      "241\n",
      "251\n",
      "261\n",
      "271\n",
      "281\n",
      "291\n",
      "301\n",
      "311\n",
      "321\n",
      "331\n",
      "341\n",
      "351\n",
      "361\n",
      "371\n",
      "381\n",
      "391\n",
      "401\n",
      "411\n",
      "421\n",
      "431\n",
      "441\n",
      "451\n",
      "461\n",
      "471\n",
      "481\n",
      "491\n",
      "501\n",
      "511\n",
      "521\n",
      "531\n",
      "541\n",
      "551\n",
      "561\n",
      "571\n",
      "581\n",
      "591\n",
      "601\n",
      "611\n",
      "621\n",
      "631\n",
      "641\n",
      "651\n",
      "661\n",
      "671\n",
      "681\n",
      "691\n",
      "701\n",
      "711\n",
      "721\n",
      "731\n",
      "741\n",
      "751\n",
      "761\n",
      "771\n",
      "781\n",
      "791\n"
     ]
    }
   ],
   "source": [
    "summaries_arxvi = []\n",
    "k=0\n",
    "for i in df.Body[0:len(summaries)]:\n",
    "    k+=1\n",
    "    batch = tokenizer(i, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    translated = amodel.generate(**batch)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    \n",
    "    f = open('aan_data_cnn_dailymail_summaries_r1.csv','a')\n",
    "    f.write(tgt_text[0])\n",
    "    f.write('\\n') \n",
    "    f.close()\n",
    "    \n",
    "    summaries_arxvi.append(tgt_text)\n",
    "    if k % 10 == 1:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We will describe a method which automatically searches for parallel texts on the Web.<n>We will discuss the text mining algorithm we adopted, some issues in trans- lation model training using the generated parallel corpus.',\n",
       " 'This paper describes a method of \"polite- ness\" selection according to a participant\\'s so- cial role.<n>It is possible to use a \"participant\\'s so- cial role\" to appropriately make the translation results \"polite\"',\n",
       " 'The Atlas project is to enlarge the scope of student interaction in an intelligent tutoring system.<n>A key component of Atlas is APE, the Atlas Planning Engine.<n>APE could also be used to manage other types of human-computer conversation.',\n",
       " 'We present a linguistically motivated framework for uniform lexico- structural processing.<n>It has been used for transformations of conceptual and syntactic structures during generation i monolingual nd multilingual natural language generation (NLG) and for transfer in machine translation (MT)<n>Our work extends directions taken in systems such as Ariane (Vauquois and Boitet, 1985), FoG (Kittredge and Polgu6re, 1991), JOYCE (Rainbow and Korelsky, 1992), and LFS (Iordanskaja et al, 1992)',\n",
       " 'State-of-the-art information extraction systems extract a small number of relations and events.<n>Our goal is to develop an IE system which scales up to extract as many types of relations and events as possible.<n>Currently, REES handles 100 types of relations and events, and it does so in a modular and scalable manner.',\n",
       " 'We describe MIMIC, a voice-enabled telephone-based dialogue system.<n>MIMIC adapts dialogue strategies based on participant roles, characteristics of the current utterance, and dia- logue history.',\n",
       " 'The basic task we consider in this paper is that of using spoken language to give commands to a semi-autonomous robot or other similar system.<n>In most of this and other related work the treatment is some variant of the following.<n>We suggest that the output representation should not be regarded as a logical expression, but rather as a pro- gram in some kind of scripting language.',\n",
       " \"This paper describes a representation devel- oped to meet complex data require- ments of NLG systems.<n>It supports different levels of representation, mixed repre- sentations and 'canned' representations.<n>We are using the approach to develop a high level data model for NLG systems as part of a generic generation architecture.\",\n",
       " 'The concept of a \"translation checker\" was initially proposed in Isabelle and al. [8] and led to a demonstration prototype concerned with the detection of deceptive cognates.<n>TransCheck allows for the detection of errors of omission, the comparison of diverse numerical expressions and the flagging of inconsistent terminology.',\n",
       " 'This paper deals with predictions which ex- tend to the next several words in the text.<n>A hypothetical user saves over 60% of the keystrokes needed to produce a translation i a word completion scenario.<n>We are currently undertaking a study to measure the extent o which our word-completion prototype can improve productivity.',\n",
       " 'Coreference r so-lution is a pervasive discourse phenomenon causing performance impediments in current IE systems.<n>We consider a corpus of aligned English and Roma- nian texts to identify coreferring expressions.<n>Identity coreference employ nouns, pronouns and noun phrases (including proper names) to their corresponding antecedents.',\n",
       " 'Question Answering is a task that calls for a combination of techniques from Information Re- trieval and Natural Language Processing.<n>We have attempted to carve out a middle ground, whereby we use a modified IR system augmented by shallow NL parsing.',\n",
       " 'People have questions and they need answers, not documents.<n>Current information retrieval systems allow us to locate documents hat might contain the pertinent information, but most of them leave it to the user to extract he useful information from a ranked list.<n>There is an urgent need for tools that would reduce the amount of text one might have to read in order to obtain the desired information.',\n",
       " 'In any real world use, a Natural Language Process- ing (NLP) system will encounter words that are not in its lexicon.<n>In this paper we introduce a system for cat- egorizing unknown words.',\n",
       " \"Open-ended question-answering systems remain beyond the scope of today's text-processing systems.<n>We describe and evaluate an imple- mented system for general-knowledge question- swering.\",\n",
       " 'More scientific information exists in the lit- erature than in any structured atabase.<n>We concentrate on molecular binding affinity, which provides a strong indication of macro- molecular function.<n>Initial studies indicate that there are ap- proximately 500,000 MEDLINE citations rele- vant to molecular binding affinity.',\n",
       " 'We apply ideas of Lexical Functional Gram- mar (LFG) in the incarnation of the Xerox Linguis- tic Environment (XLE)<n>The goal is to investigate to what extent corpus-based compilation techniques can reduce overgeneration of a d spurious ambiguity.',\n",
       " 'This paper describes an approach to the lexicon problem that emphasizes recognition of mor- phological structure in unknown words.<n>The system described here uses a collection of approximately 1200 knowledge-based morphologi- cal rules to extend a core lexicon of approximately 39,000 words.',\n",
       " 'A tagger with the highest possible accuracy is required for part-of-speech tagging.<n>This paper describes the models and techniques used by TnT together with the implementation.',\n",
       " 'Various languages exist in the world, and strategies for morphological nalysis differ by types of language.<n>We propose a framework of language independent morphologi- cal analysis ystem.<n>This approach enables a rapid implementation f morphological nalysis ys- tems for new languages.',\n",
       " 'Current information extraction (IE) systems are quite successful in efficient processing of large free text collections.<n>IE systems are ap- plied to English text, but there are now a number of systems which process other languages as well.',\n",
       " 'NE tagging is a complex task and high-performance systems are required in order to be practically usable.<n>In this paper we propose ahybrid method for combining NE tagging which combines all the modelling techniques mentioned above.',\n",
       " 'LEXIS-NEXIS adds 100,000 news articles daily to its collection of over 2 billion documents.<n>For marketing and product positioning reasons, we want to provide indexing for tens of thousands of companies.',\n",
       " 'Information Extraction (I-E) is the selective extraction of meaning from free natural language text.<n>\"Meaning\" is under- stood here in terms of a fixed set of semantic objects--entities, relationships among entities, and events in which entities participate.<n>The extracted objects are then stored in a relational database.',\n",
       " 'System which uses only the in- ternal evidence contained in lists of names is presen- ted.<n>In this paper a NE system which uses only the in- ternal evidence contained in lists of names is presen- ted.',\n",
       " \"We describe and evaluate a question- answering system based on passage retrieval and entity-extraction technology.<n>The system's per- formance was evaluated in the question-answering track that has been introduced this year at the TREC information-retrieval conference.\",\n",
       " 'Current automatic summarizers rely on sen- tence extraction to produce summaries.<n>We implement an automatic sentence reduction system.<n>We find that humans reduced the length of these 500 sentences by 44.2% on average.',\n",
       " 'In this paper we explore how performance degrades on noisy input.<n>Error rates of automatic speech recognizers (ASR) on broadcast news are still very high.<n>We evaluate a learning algorithm, a hidden Markov model (HM)',\n",
       " 'Key tasks of a dialogue manager are to update the representation f dialogue on the basis of processed input.<n>We use rich repre- sentations of information states, but simpler, more dialogue-specific deliberation methods.',\n",
       " 'What is said in two sentences in one language is said in only one, or in three, in the other.<n>For distant language pairs, such as Japanese and English, the differences are more significant.',\n",
       " 'Our aim is to identify the central factors that in- fluence pronominalization across genres.<n>Our analyses are based on a corpus of twelve texts from four different genres.',\n",
       " 'Existing work falls into one of two categories, lexical cohesion methods and multi-source methods.<n>The focus is on the segmentation f transcribed spoken text and broad- cast news stories.',\n",
       " 'Word-for-word glossing is the process of directly translating each word or term in a document without considering a large word order.<n>We present a word-for-word glossing algorithm that requires only a source language corpus.',\n",
       " 'We have developed a speech recognition component based on HMMs with a pow- erful grammar model based on Constraint Depen- dency (CDG)<n>The goal of this research is to construct and ex- perimentally evaluate a prototype of a spoken lan- guage system that loosely integrates a speech recog- nition component with an NLP component.',\n",
       " 'dependency analysis has been shown to be practical and effective in both rule-based and approaches to syntactic analysis.<n>In dependency analysis of a Japanese sentence, dependency ambiguities of sub-ordinate clauses are one of the most problem- atic ones.<n>We show that dependency ambiguities of subordinate clauses are among the most problematic source of ambiguities in a Japanese sentence.',\n",
       " 'We show that by building a small treebank of only a thousand sentences, we could develop a good basic machine learning within only three months.<n>We produce a tree describing the structure of a given sentence, including tense and semantic roles, as well as additional information.',\n",
       " 'In many NLP tasks it is necessary to de- termine the most likely word, part-of-speech (POS) tag or any other token, given its history or context.<n>Most approaches to these prob- lems are based on n-gram-like modeling.<n>In this paper we show that incorporating addi-tional information into the learning process is very beneficial.',\n",
       " \"A good indicator of whether aperson knows the meaning of a word is the ability to use it appropriately in a sentence.<n>We have developed a statistical system, ALEK, that uses statistical analysis for this purpose.<n>AlEK identifies inappropriate usage based on differences between the word's local context cues in an essay and the models of context it has derived from the corpora of well-formed sentences.\",\n",
       " 'We propose a method for detecting errors in a marked cor- pus using an anomaly detection technique.<n>This technique detects anomalies or elements which do not fit in with the rest of the corpus.<n>We evaluate this method over the part of speech tagged portion of the Penn Treebank cor- pus.',\n",
       " 'Unification-based Grammar estimators can capture a wide variety of linguistically important syntactic and semantic onstraints.<n>Recent work has shown how to define probability distributions over the parses of UBGs.',\n",
       " 'Corpus-based sta- tistical knowledge was applied to the generation process.<n>A lattice was able to represent large numbers alternative phrases.<n> lattice encodes 576 unique sentences.',\n",
       " 'There is a big gap between the summaries produced by current automatic summarizers and the abstracts written by human professionals.<n>We present a cut and paste based text sum- marization technique, aimed at reducing the gap between automatically generated summaries and human-written abstracts.',\n",
       " 'The amount of audio data on-line has been grow- ing rapidly in recent years.<n>One way of compressing audio information is the automatic creation of textual summaries.<n>This paper presents a novel method for evaluation of textual summaries from spoken lan- guage data.',\n",
       " 'This paper presents three trainable systems for sur- face natural language generation (NLG)<n>Surface NLG consists of generating agrammatical natural language phrase that expresses the meaning of an input semantic representation.',\n",
       " \"We introduce MIMIC, a mixed initiative spoken dialogue system that automatically adapts dia- logue strategies.<n>Our results show that MIMIC's mixed initiative and automatic adaptation fea- tures lead to more efficient dialogues and higher user sat- isfaction.\",\n",
       " 'Spoken dialogue systems promise fficient and nat- ural access to a large variety of information sources and services from any phone.<n>Current systems are limited in the interaction they support and brittle in many re- spects.<n>We show how spoken dialogue systems can learn to support more natural interaction on the ba- sis of their previous experience.',\n",
       " 'One of the central tasks of the dialogue manager in most current spoken dialogue systems (SDSs) is error handling.<n>The current paper looks at prosody as one possible predictor of ASR performance.',\n",
       " 'We report adapting a lexicalized, probabilistic context-free parsing algorithm to information extraction.<n>The technique was benchmarked in the Seventh Message Understanding Conference (MUC-7) in 1998.',\n",
       " 'The Penn treebank contains a great deal of additional syntactic and seman-tic information from which to gather statistics.<n>This paper details a process by which some of this information--the function tags--may be recovered automatically.',\n",
       " 'Because Japanese kanji is written withouts be- tween words, accurate word segmentation is a key step in text processing.<n>Proposed applications of segmentation technology include extracting new technical terms, indexing documents for information retrieval, and correcting character recognition (OCR) er- rors.',\n",
       " 'A long-standing issue regarding algorithms that ma- nipulate context-free grammars (Cs) in a \"top-down\" left-to-right fashion is that left recursion can lead to nontermination.<n>We develop a number of improvements to Panll\\'s algorithm, which help somewhat but do not completely solve the prob- lem.<n>We then go on to develop an alternative ap- proach based on the left-corner grammar transform.',\n",
       " 'Diathesis alternations are alternate ways in which the arguments of a verb are expressed syntactically.<n>These subtle changes of meaning are impor- tant in natural language generation.<n>We propose a method to acquire knowledge of alternation partic- ipation directly from corpora.',\n",
       " 'Sentence boundary disambiguation (SBD) is an im- portant aspect in developing virtually any text processing application.<n>State-of-the- art machine-learning and rule-based SBD systems achieve the error rate of about 0.8-1.5% measured on the Brown Corpus and the WSJ.',\n",
       " 'It has been argued that the choice of the most favourable strategy should depend on the grammar at hand.<n>We investigate a class of lexicalized grammars that, in their probabilistic versions, have been widely adopted as language models.',\n",
       " 'Acknowledgments play a role in managing turn-taking in mixed-initiative dialogue.<n>Current design practices both discourage and render meaningless the standard uses of acknowledgments.',\n",
       " 'Computational morphology has been quite successful in dealing with the chal- lenges posed by natural anguage word patterns.<n>It has been possible to describe both word formation and the concomi-tant phonological modifications in many languages.<n>In this paper I will lay out a proposal for handling reduplication with finite-state methods.',\n",
       " 'Automatic grapheme to phoneme conversion is essential for applications of text to speech synthesis.<n>We present a method for developing such grapheme to phoneme transducers based on a com- bination of hand-crafted conversion rules.',\n",
       " \"The research on semantic interpretation that was conducted in the pre-empiricist age of NLP was mainly driven by an interest in logical formalisms.<n>Recent eval- uation efforts within the field of information extrac-tion (IE) systems are going to remedy this shortcoming.<n>We first outline the model of semantic interpretation underlying our approach and then focus on 'its em- pirical assessment for two basic syntactic structures of the German language.\",\n",
       " 'EUFID allows users to communicate with database management systems in natural English.<n>At least three broad categories of issues had to be addressed during EUFID development.',\n",
       " 'EPISTLE is a system for critiquing written material on points of grammar and style.<n>EPISTLE currently uses syntactic, but not semantic, information.',\n",
       " 'Sentence fragments are found in.<n>technical communlcatlons, messages, headlines, and.<n>In te legraphic camunlcat lons.<n>The purpose of this paper is to describe the syntact ic character is ics of sentence fragments.',\n",
       " 'The LRC MT sys tem i s one of very few la rge-sca le app l i ca t ions of modern computat iona l l i ngu is t i cs techn iques [Lehmann, 1981].<n>Our \"app l ied\" sys tem remains a research veh ic le that serves as an exce l lent tes tbed fo r proposed new procedures.',\n",
       " 'This paper describes a pilot version of a commercial application of natural language processing techniques to the problem of categorizing news stories into broad topic categories.<n>Similar techniques could be employed on electronic mail messages, telex traffic, technical abstracts, etc.',\n",
       " 'The Lucy system is a prototype of a portable English front end for knowledge-based systems.<n>The system produces as its output a list of discourse referents and a set of assertions about them.<n>The job of the anaphora resolution system is to augment this assertion set with ad- ditional assertions.',\n",
       " \"One obvious benefit of acquiring domain- specific semantic information is rejecting parses generated by the syntactic component which are semantically anomalous.<n>As the system's semantic knowledge becomes increasingly rich, we can expect it to demonstrate some measure of learning.\",\n",
       " 'Natural anguages contain a variety of \"logical operators\" which interact with each other to give rise to different ypes of ambiguity.<n>The logical operators recognized by the scoping program include quantifiers, coordinators and negation.<n>The scoping program is designed to be used as an extension to a redundant/translator which generates initial logical expressions.',\n",
       " 'It is possible to adapt the Cocke-Younger-Kasami algorithm (Aho and Ullman p. 314 if) for parallel use.<n>The algorithm we describe below is basi- cally a CYK with top-down filtering 1, but the main control structure is an event queue rather than over a matrbc.',\n",
       " 'This paper briefly discusses the LDB structure, the tools and grammar for creating LDBs from existing sources, and then describes the facilities and im- plementation f LQL.',\n",
       " 'Computer systems aiding retrieval from full-text databases have been available for more than two decades.<n>Many people are becoming concerned about the serious limi- tations of those systems regarding effectiveness in finding desired references.<n>We believe that focusing on lexical and phrasal issues may be the most appropriate strategy for applying computational linguistics to information retrieval.',\n",
       " 'The System for Information Summarization, Organization and Retrieval (SCISOR) is an implemented system designed to extract information from texts.<n>The derived infor- mation is stored in a conceptual knowledge base and re-trieved using a natural language analyzer and generator.',\n",
       " 'This paper focuses on the automatic manipulation of synonyms found in an on-line thesaurus.<n>In the context of CT, a strong criterion for defining a set of words which share crucial semantic features is a criterion which requires every member of the set to be a synonym of every other member.<n>In the second section, we describe our first control measure - our manipulation of senses of words rather than myopic of words themselves.',\n",
       " 'Luke supports entering and maintaining the semantic mappings needed by a natural language interface to a knowledge base.<n>The application program and its NL interface must share a single knowledge base.<n>A semantic lexicon is then a collection of semantic mappings that specify translations for the words in the syntactic lexicon.',\n",
       " 'CRITIQUE is a large-scale natural anguage text processing system that identifies grammar and style errors in English text.<n>The first step determines sentence, heading, and par- agraph boundaries.<n>After lexical analysis, text is passed to a parse tree, and in so doing checks for grammar errors.<n>CRITIQUE also generates tatistical in-cussion formation about documents based on the lexical and syntactic analyses.',\n",
       " \"This paper describes enhancements made to current name search techniques used to access large databases of proper names.<n>The work focused on improving name search algorithms to yield better matching and retrieval performance on data-bases containing large numbers of non-European 'foreign' names.\",\n",
       " 'The paper describes the procedure that was followed in an extended experiment o reliably find basic surface clauses in unrestricted English text.<n>The purpose was to make some improvements in the detection and treatment of large prosodic units above the level of fgroups in the Bell Labs text-to-speech system.',\n",
       " 'morphological com-ponent is designed to perform a number of dif- ferent functions.<n>It has been used to produce a complete analyzer for Arabic.<n>Other functions have been implemented for several lan- guages.',\n",
       " 'This paper describes how information about alter- native parses is passed concisely from DIALOGIC to the pragmatics component.<n>We discuss a method of localizing the representation f syntactic ambi- guity in the logical form of a sentence.',\n",
       " 'This paper describes a method of addressing the prob- lem directly, by adapting standard searctl optimization techniques.<n>The output is first transfi rmed so that it is represented asa set of semantic hoice points.',\n",
       " 'We will discuss the pros and cons of a design paradigm that stays within the basic conduit model.<n>A frequent response to the problem of an explosion of syntactic parses in natural language systems is to have the parsing module assign canonical representations to families of structures.<n>The advantage of this approach is that the semantics module might be able to choose quickly between the multiple translations, even though the syntax could not choose between the parses.',\n",
       " 'This paper addresses how to connect a general NL interface and a back-end application in a principled way.<n>We will assume here that the interface takes input in a natural anguage and produces a representation in some kind of first- order logic.<n>The techniques used apply equally well to other NLP applications.',\n",
       " 'The WIP system is a knowledge-based presentation system.<n>It generates a multimodal document with communicative intent and a set of generation parameters.<n>The localisation component described in this paper was developed to support the generation ot cross-modal deietic referring expressions.',\n",
       " 'We propose a modular architecture for multi-modal interfaces composed of interaction tools.<n>In our approach we bring the kind of natural language ca- pabilities required by the first body of related work.',\n",
       " 'It is necessary to overcome inconsis- tencies, omissions and the occasional errors which are commonly found in MRDs.<n>The goal of this paper is to describe a software pack- age for correlating word senses across dictionaries.',\n",
       " 'ACQUILEX LKB is designed to support repre- sentation of multilingual exical information extracted from machine readable dictionaries (MRDs)<n>LKB represents extracted ata in such a way as to support browsing and querying.',\n",
       " 'One of the fundamental property of computational lexicons is an account of the relations between verbs and its arguments.<n>Words relate to each other in many different, often domain dependent ways.',\n",
       " 'It has been claimed that extra-linguistic, domain specific knowledge is in- dispensable in most NLP applications.<n>We propose an algorithm which auto-matically acquires knowledge of semantic ollocations among \"words\"',\n",
       " 'DILEMMA-2 is a lemmatizer-tagger for the sublanguage of medical abstracts.<n>It is an extension of DILEMMA-I, a lemmatizer-tagger for general English texts.',\n",
       " 'JASPER is a fact extraction system recently developed and deployed by Carnegie Group for Reuters Ltd.<n>It identifies which of those releases contain information on company earnings and dividends.<n>It then reformats that information into a candidate Reuters news story and ships it off to a financial journalist for validation or editing.',\n",
       " 'We have developed a system that can robustly extract information from massive corpora of unrestricted (\"open\") texts.<n>We have applied it to the task of infor- mation about changes in employment found in articles from the \"Who\\'s News\" column of the Wall Street Journal.',\n",
       " 'We propose a method of resolving zero 201pronouns common in Japanese discourse.<n>The method uses the dynamic haracteristics of verbs and the relationship between verbs.',\n",
       " 'The approach to dialogue managenaent described here has been developed as part of the Sundial project (Speech UNderstanding in DIALogue)<n>Our goal is to build real-time integrated computer systems capable of maintaining co-operative dialogues with users over telephone lines.',\n",
       " 'Bellcore and Columbia are jointly developing a system, PLANDoc.<n>PLANDoc will document the ac- tivity of planning engineers as they study telephone routes I.',\n",
       " \"In today's world of text-based information, how- ever, not all sources of text will be character coded.<n>We have developed a method which reliably mines the language or languages of a document image.<n>In this paper, we discuss Roman-alphabet languages such as English, Polish, and Swahili.\",\n",
       " 'We introduce word shape tokens and their generation from document images.<n>Character shape codes are grouped by word bound- ary into word shape tokens.<n>The correspondence between the scanned word image and the word shape token is one-to-one.',\n",
       " 'This paper presents a model for analyzing English sentences including coordinate conjunctions such as \"and\", \"or\", \"but\" and equivalent words.',\n",
       " 'This paper combines knowledge-based and statisti- cal methods for part-of-speech disambiguated.<n>We demonstrate a system that accurately resolves most part-of-speech by means of syntac-tic rules and employs a tagger to elimi-nate the remaining ambiguity.',\n",
       " 'Part-of-speech tagging is the process of assigning grammatical categories to individual words in a cor- pus.<n>One widely used approach makes use of a statistical technique called a Hidden Markov Model (HMM)',\n",
       " 'I argue for a general method for 59 extending the context-sensitivity of any knowledge source that calculates sentence hypothesis cores.<n>The method involves clustering the sentences in the training corpus into a number of subcorpora, each predicting a different probability distribution for linguistic objects.',\n",
       " 'We have already proposed a mechanism which acquires sub-specific linguistic knowledge from parsing failures.<n>Unlike probabilistic parsing, our system can suggest new pieces of knowledge including CorpusG rules, subcate- gorization frames, and other lexical features.',\n",
       " 'Labeling of sentence boundaries is necessary for many natural language process- ing (NLP) tasks.<n>About 90% of pe- 78 riods occur at the end of sentences, 10% at the end of sentences, and about 0.5% as both abbrevi- ations and sentence bounds.<n>Some systems have achieved accurate boundary determination by applying very large manual effort.',\n",
       " 'Current MT systems, whatever translation method they employ, do not reach an optimal output on free text.<n>Our hypothesis i that if an MT environment can use the best results from a variety of MT systems working simultaneously, the overall quality will improve.<n>Using this novel approach to MT in the latest version of the Pangloss MT project, we submit an input text to a battery of machine translation systems.',\n",
       " 'It is important that natural anguage interface systems have the capability of composing the globally most plausible explanation if a given input can not be syntactically parsed.<n>This paper proposes a new technique for parsing inputs that contain simple kinds of ill-formedness.',\n",
       " 'We present a tool for extracting terminology from large terminological databases.<n>The tool, called FASTR, is based on the PATR-H grammar formalism.<n>It can be used in areas of application such as automatic indexing.',\n",
       " 'This paper describes a text tagger for Turkish.<n>The tagger is based on a full scale two-level morphological specification of Turk- ish.',\n",
       " 'This paper focuses on the morphological and lex- ical component of the system, which is a combi- nation of a database application and a Prolog rule interpreter.<n>The importance of morphologic analy- sis of medical vocabulary has been widely recognised.',\n",
       " 'We have been using morphological nalysis to develop REVISE, a revision support system that corrects Japanese input errors.<n>RevISE can detect and correct various types of errors, using knowledge bases that describe the characteristics of each error type.<n>Homophone errors are one of the error types that can be detected and corrected in REVISE.',\n",
       " 'The purpose of this paper is to propose a new probabilistic model for automatic text categorization.<n>In a model of probabilistic text categorization, P(cld ) = \"the probability that a document d is categorized into a category c\"<n>Our model is very simple, but solves some problems of the previous models.',\n",
       " \"In large databases comprising hundreds of thousands of documents he use of phrasal terms is not just desirable, itbecomes necessary.<n>The reader may note various sections of this Topic, with desc> correspond- ing to the user's original request, further elaborated in narr>, and con> consisting of expert-assigned phrases denoting key concepts to be considered.\",\n",
       " 'FoG (for Forecast Generator) was developed 1985-89 (Kittredge t al., 1986; Bourbeau et al, 1990)<n>After tests at Environment Canada during 1989-91, FoG entered regular use during 1991-92.<n>Forty percent of the operational marine forecasts (roughly half of all marine forecast text) in Canada is now produced using FoG.',\n",
       " 'We investigate the performance of a neural network on the task of turn segmentation using parts of speech and indicative keywords.<n>On average approximately after every seventh token (i.e. 14% of the text) there is a segment boundary.',\n",
       " 'Training on 39441 sentences takes 18 minutes on a Sun Ultra Sparc.<n>Disambiguating the boundaries in a single Wall Street Journal article requires only 1.4 seconds.',\n",
       " 'COSMA allows human and machine agents to participate in appointment scheduling dialogues via e-mall.<n>Human utterances must be analyzed to corre- spond closely to agent actions.<n>Machine utterances must conform to human di- alogue strategies.',\n",
       " 'The imPlemented research prototype of the speech- to-speech translation system VEaBMOBIL consists of more than 40 modules for both speech and linguistic processing.<n>The central storage for dialogue information within the overall system is the dialogue module that ex- changes data with 15 of the other modules.',\n",
       " 'This paper describes surface-syntactic parsing of running text.<n> dependency links show the het-modifier relations between words.<n> labels refer to the syntactic function of the modifying word.',\n",
       " 'This paper aims at merging the constructive and the reductionist ap- proaches.<n>It maintains the coverage and gran-ularity of the constraint-based approach at a much lower computational cost.',\n",
       " 'syntactic language model is combined with statistical information using relaxation labelling.<n>The system has a recall of 100% if all words retain the correct morphological nd syntactic reading.<n>The system can use linguistic rules and corpus-based statistics.',\n",
       " \"The work reported in this paper aims at provi- ding syntactically annotated corpora ('treebanks') for existing grammar induction.<n>In particular, we focus on several methodological issues concerning the annotation of non-configurational lnguages.\",\n",
       " \"The notion of text 'domain' has been seen as a ma-jor constraint on the applicability of the knowledge.<n>In this paper, we describe two observations and an experiment which suggest an answer to the ques- tions.\",\n",
       " 'This paper presents a method for the automatic acquisition of two-level rules for source-target word pairs.<n>It is assumed that the target word is formed from the source through the addition of a prefix and/or a suffix 1.<n>We show how a partial acqui- sition of the morphotactic description results as a by-product of the rule-acquisition process.',\n",
       " 'In Chinese, there do not exist categorizations, such as spacing in English, to explicitly indicate boundaries between words.<n>No word segmenter and POS tagger for Chinese with satisfactory performance in treating unrestricted texts are available so far.',\n",
       " \"The project vision foresees that intermediate lan- guage learners/users of e.g., English, might be reading on the screen, perhaps a software manual.<n>The user can click the mouse on a word to invoke online help.<n>A morphological parse, separating'revert' and's', together with an explanation of the inflection.<n>The entry to the word'revert' in a bilingual English/Bulgarian dictionary or a monolingual English one.\",\n",
       " 'An example of a NLP application is an operational foreign language tutoring system called Military Lan- guage Tutor (MILT)<n>One of the tutoring lessons, the MicroWorld Lesson, requires the capability of the learner to state domain-specific actions in a variety of different ways.<n>In another tutoring lesson, Question-Answering, the student is asked to answer questions about a foreign language text that they have read.<n>Their answer is converted into an LCS which is matched against a prestored LCS corresponding to an answer typed in by a human instructor.',\n",
       " 'This paper describes the basic ideas behind an implementation f a prototype of a grammar checker for Czech.<n>The last but not least problem was to incorporate the prototype into a commercially available text editor.<n>The grammar checker is implemented as an independent Windows application (GRAMMAR) which runs on the background of the Word.',\n",
       " 'EasyEnglish helps writers produce clearer and simpler Eng- lish.<n>System can be viewed as a \"grammar checker++\"<n>EasyEnglish also works with the XEDIT editor on VM and the EPM editor on OS/2.',\n",
       " 'Spelling checkers only catch errors that result in misspelled words.<n>We introduce Latent Semantic Anal- ysis as a method for correcting contextual spelling errors.',\n",
       " 'The purpose of this work is to develop computer-based methods for scoring so that computer-administered natural language constructed-responses can be used on standardized tests.<n>One hundred Excellent essays from the original 200 essays were selected to train the scoring system.<n>The results show 87% agreement for exact scores between human rater and computer scores, and 94% agreement for exact or adjacent scores between human rater and computer scores.',\n",
       " 'We have built a named-entity recognition system using a slightly-modified version of an HMM.<n>To our knowledge, Nymble out-performs the best published results of any other learning name-finder.',\n",
       " 'The goal of IE is to build systems that find and link relevant infor- mation from text data.<n>Current IE systems are to be quite successfully in automatically processing large text collections.<n>This paper focuses on the technical and implementational aspects of the IE core technology used for achieving the desired portability.',\n",
       " 'Table markup contains a great deal of infor- mation about what a table looks like.<n>To express a given table denotation according to a given view, there is a repertoire of lay-out pat terns that express how domains can be grouped.<n>These layout syntax of table structure define the basic onfigura- tions that domain values and labels can appear in.',\n",
       " 'We describe a system called PROFILE that tracks prior references to a given entity by extracting descriptions for later use in summarization.<n> PROFILE can also be used in a real-time fash- ion to monitor entities and the changes of descrip- tions associated with them over the course of time.',\n",
       " 'Two major issues in corpus-based NLP are: how best to deal with medium to large scale corpora often with complex linguistic annota- tions, and what system architecture best supports the reuse of software components.<n>We describe the LT NSL system (McK- elvie et al 1996), an architecture for writing corpus processing tools.',\n",
       " 'We present an implementation of a system called GATE - a General Architecture for Text Engineer- ing.<n>Gate is now available for research purposes - see http.<n>ul;w. dcs. shef. ac. u_k/research/groups/ nlp/gate/ for details of how to obtain the system.',\n",
       " 'The shift from Computational Linguistics to Lan- guage Engineering 1 is indicative of new trends in NLP.<n>We believe that it is not simply a new fash- ion but that it is indicative of the growing matura- tion of the field.',\n",
       " 'CogentHelp is a prototype for authoring dynam- ically generated on-line help for applications with graphical user interfaces (GUIs)<n>This paper highlights the usefulness of certain natural anguage generation (NLG) tech- niques in supporting software-engineering (SE) goals for help authoring tools.',\n",
       " 'Communication regarding patient sta- tus is critical during the hour immediately follow- ing a coronary arterial bypass graft (CABG)<n>We are developing a mul- timedia briefing system, MAGIC, that takes as input online data collected uring the surgical operation.',\n",
       " \"Several methods have been tried to perform Topic Identification.<n>The Position Method, identified in the late 1950's, remains among the best.<n>It can outperform newer methods uch as those based on word counting.\",\n",
       " 'We propose a method for extract- ing key paragraphs in articles based on the degree of context dependency.<n>We show how the idea of con- text dependency can be used effectively to extract key paragraphs.',\n",
       " 'Information Retrieval is an increasingly impor- tant application area of Natural Language Process- ing (NLP)<n>The challenge in applying NLP to IR is to deal with a large amount of unrestricted natural lan- guage text.',\n",
       " 'monolingual users can currently access information only in their na- tive language.<n>It is not easy for a monolingual English speaker to locate necessary in- formation written in Japanese.<n>The system in- dexes texts in different languages (e.g., English and Japanese) and allows the users to retrieve relevant texts in their native language.',\n",
       " 'This paper investigates the utility of an algo- rithm for translation lexicon acquisition.<n>It is applied to a much smaller corpus to produce candidates for domain-specific translation lexicons.',\n",
       " 'The goal of the Alembic is to dramatically accelerate the process by which language processing systems are tailored to perform new tasks.<n>By reinvesting the knowledge available in the earliest raining data to pre- tag subsequent un-tagged ata, the Alembic can tralasform the process of manual tagging to one dominated by manual review.<n>Our focus in building the Alembic is to provide a natural but powerful environment for annotating texts in the service of developing natural language processing systems.',\n",
       " 'We describe a new system capable of distinguish- ing 160 verbal subcategorization classes in the Alvey NL Tools (ANLT) and COMLEX dictionaries.<n>We report an initial experiment which demonstrates that this system is capable of acquir- ing the subcategorization classes for individual predicates.',\n",
       " 'In corpus-based NLP, extraction of lexical/semantic collocation is one of the most important issues.<n>This paper focuses on extracting lexical/semantic collocational knowledge for ranking parses in syntactic analysis.<n>We propose a novel method for calculating subcategorization prefer- ence functions of verbs.',\n",
       " 'It is well known that statistically-based approaches to lexical knowledge acquisition are faced with the problem of low counts.<n>Since rare patterns are the majority, the quality and coverage of lexical earning may result severely affected.<n>Two generalisation strategies have been adopted: distributional approaches and semantic tagging.',\n",
       " 'Word-sense disambiguation is cast as a problem in supervised learning, where a classifier is induced from a corpus of sense-tagged text.<n>We adopt a statistical approach whereby a prob- abilistic model is selected that describes the inter- actions among the feature variables.<n>How well a model characterizes the train- ing sample is determined by measuring the fit of the model to the sample.',\n",
       " 'lPhe term selectional restrictions refers to se- mantic sortal constraints imposed on the 1)ar -ticipants of linguistic constructions.<n> selectional restrictions have proven very useflfl in practical appli- cations.<n>They have been employed in sev- eral large-scale natural language understanding systems.',\n",
       " 'We present tools for tuning of leanfing models based on statis- tical tagger.<n>The t)art-of-speech tag set we use is a slightly modified version of tile IPA POS tag set (RWCP, 2000) with about 500 distinct POS tags.<n>We use morphological analysis instead of part-of-speecll tagging since Japanese is an agglutinative language.',\n",
       " 'In this paper we present FERGUS (Flexible Em piricist/Rationalist Generation Using Syntax)<n>We use an existing wide-coverage grammar of English, the XTAG grammar developed at the University of Peru.<n>We describe the ar chitecture of the system, and some of the mod.malism, lexicalized tbrmalism, and some experiments.',\n",
       " 'We present an empirical ewduation of the LFG-DOP model introduced by Bed & Kaplan (1998).<n>LFG-DOP is a Data-Oriented Parsing (DOP) model based on the syntactic representations of Lexical Functional Grammar (Kaplan & Bresnan 1982)',\n",
       " \"A well-known property of grammars is their prope,lsity to assign highe, probabil it ies to shorter derivations o1' a sentence.<n>Shorter derivations involving fewer rules tend to have higher probabilities, ahnost regardless of the training data.<n>We investigate whether for STSG lhe bias in favor of shorter derivations is perhaps beneficial rather than llarmful.\",\n",
       " 'In English, uncountable nouns cannot be modified by numerals, instead the noun nmst be embedded in a noun phrase headed by a classi- tier.<n>We show how to generate numeral classifiers as piece in 2 pieces ilfl)aper.',\n",
       " 'This paper presents the adaptation of a particular Software Engineering (SE) method, illstrmnentation, to Grmmnar Engi- neering (GE)<n>Instrumentation allows to determine which test item exercises a certain piece of (software or grammar) code.',\n",
       " 'This paper describes an on- line lexical semantic disambiguation system for En- glish within a client/server linguistic application.<n>A linguistic strategy was im- plemented in order to select he best matching dis- ambiguation rule in a given context.<n>The originality of our implementation lies in the rule selection strategy for application as well as in the use of the client/server characteristics.',\n",
       " 'Prague Dependency Treebank (PDT) PDT is a corpus (a part of the Czech Na.tional Cortms)<n>The Prague Dependency Treebank (PDT) PDT is a corpus (a part of the Czech Na.tional Cortms)',\n",
       " \"Our goal is to elaborate a tool that helps ternfinologisl;s to assign semantic ('ategories when ut)dating the reli;ren(:e lx;rminology)\",\n",
       " 'Word sense disambiguation (WSD) remains an open probleln in Natural Language Processing (NLP)<n>WSD problem is exacerbated by the large number of senses of colmnonly used words and by the difficulty in determining relevant contextual features most suitable to the task.<n>We will address the first two issues by identiflying contexts in which knowledge can be obtained automatically, as opposed to those that require minimal manual tagging.',\n",
       " 'This paper will present a personal news secretariat that helps on-line readers absorb news information from multiple sources in different languages.<n>Such a news secretariat eliminates the redundant information in tile news articles, reorganizes tile news for readers, and helps them resolve the language barriers.',\n",
       " 'The occurrences of unknown words cause difficul- ties in natural language processing.<n>The syntactic and semantic categories of unknown words in principle can be determined by their content and contextual information.<n>We propose a representation model, which will be facilitated to identify, to disambiguate and to evaluate the structure of a compound noun.',\n",
       " 'Two methods, Pr( + adapt ) and Pr( + adapt2), will be introduced for estimating positive adaptation.<n>The two methods produce similar results, usually well within a factor of two of one another.',\n",
       " 'We propose a probabil- ity model in terms of senses from a semantic hi- erarchy.<n>We use the semantic hierarchy of noun senses in WordNet.<n>We demonstrate the effectiveness of our approach using a PP-attachment experiment.',\n",
       " 'Research aims at autonmti(:ally ex- tra(:ting facts Kern scientific abstracts and flfll papers ill the molecular- domain and us- ing these to update databases.<n>We have exllored th(; use of a generalisable, supervised training method based on hidden Markov models (ItMMs) (Ra- biner and.<n>]uang, 1986) fbr tim identification mid classitieation of technical expressions ill these texts.',\n",
       " 'Most current anaphora resolution systems implelnent apipeline architecture with three modules.<n>A COLLF.CT module determines a list of potential antecedents for each anaphor.<n>A FILTI,P module eliminates referees incompatible with the anaphor.<n>A PP, E module determines the most likely antecedent on the basis of an ordering policy.',\n",
       " 'AlliS is a learn- ing system which uses theory refinement in order to learn non-reeursive noun phrases.<n>It consists of two main steps: 1.. Build a more or less correct grammar on the basis of background knowled.qe.<n>The second step (the refinement) compares the prediction of the initial gramar with the training corpus in order to firstly identify the revision point.s.',\n",
       " 'A l)octunent Type l)elini- lion (DTD) is roughly similar to a coii-text-free gram- mar j with exactly one predelined terminal.<n>For leaves, lhe type is a semanlically specilic concept of this type, such as three or dog.',\n",
       " 'Textual Question Answer- ing (Q/A) aims at identitying the answer of a ques- tion in large collections of on-line documents.<n>In this paper we present our experiments with integrating knowledge-based NLP with shallow pro-cessing techniques.',\n",
       " \"Aulomal- ically learning features of this type from hugc corpora allows the construction or augmentation of lexicons.<n>Subjectivity in natmatically- ural language re['crs to aspects of language used to ex- press opinions and ewfluations.\",\n",
       " 'We introduce a more general algoritritn for the pronominalization decision.<n>We group noun phrases with definite determiner and proper nalnes together under tile term \"det\\'- inite description\"<n>The algorithm has been implemented as the reusable module gnome-np.',\n",
       " 'Measuring the representativeness of a term  is essential to various tasks in natural language processing.<n>Measuring the representativeness of a term  is essential to various tasks in natural language processing.',\n",
       " 'This paper explores two directions tbr the next step beyond the state of the art of statistical parsing: probabilistic partial parsing and committee-based decision making.',\n",
       " \"Tol)-down i)arsing techniques are al;tl'a(:tiv(! because of their simt)licity, and can often a(:hi(ve good 1)er-formance in 1)racti(:e (loark and.<n>]hns(m, 1999).<n>With a leftFG-re(:ursive grammar such l)ars('as tyl)i(:ally fail to termimte, a left-corner transformed grammar simulates a lefl;-(:orner using the original granllnar\",\n",
       " 'Multimodal interfaces allow content to be conveyed between humans and machines over multiple channels uch speech, graphics, pen, and hand gesture.<n>Pen input consists of gestures and drawings which are made in electronic ink on the computer display and processed by a gesture recognizer.<n>This paper is concerned with the relationship between spoken language parsing and nmltimodal parsing.',\n",
       " 'Multimodal interfaces are systems that allow input and/or output o be conveyed over multiple different channels uch as speech, graphics, and gesture.<n>Our specific concern here is with multimodal inter- faces supporting input by speech, pen, and touch, but the approach we describe has far broader applicabil- ity.',\n",
       " \"The transliteration of l'oreign words is indispensable in Korean language processing.<n>In this paper, we present a statistical method to transliterate English words in Korean alphabet to generate various candidates.\",\n",
       " 'Thesauri are classified into taxonomy-type thesauri and association thesauri.<n>An association the- saurus is a collection of pairs of semanti- cally associated terms.',\n",
       " 'Gram- mars are used to obtain precise features for probabil- ity estimation.<n>In this lmper, the most preferable parse trees are chosen with a statistical model.',\n",
       " 'In Korean technical documents, many English words are used in their original forms. But sometimes they are transliterated into Korean in different forms.<n>These various transliterations are not negligi- ble natural angnage processing, especially ill information retrieval.<n>An automatic translit- eration system is needed to find transliterations without manual intervention.',\n",
       " \":erl;ain linguistically mol;ivate, d subclass f LFG grammars.<n>Our luaill result is thai; the se, l. (f st;rings thai; su:h a grammar elates to a 1)articular f-stru:l;ure is a context-fl'ee language.\",\n",
       " \"In Japanese sentence analy- sis, case structure analysis is an important issue.<n>Some research institutes have constructed Japanese case frmne dictiouaries manually.<n>Others have tried to construct a case fl'mne dictionary automatically from analyzed corpora.\",\n",
       " 'Part of Speech (POS) tagging assigns limited morphosyntactic nformation to lexical items.<n>Supertags assign to each word in a sentence, instead of a traditional \"elementary tree\"<n>Supertags are difficult to read and thus difficult to annotate manually.<n>We show how one can associate one single structure, which we call hypertag, and which contains the same information as a set of supertags.',\n",
       " 'We propose a new automatic text categorization system based on unsupervised learning.<n>It creates training sentence sets using keywords of each category.<n>It then uses them for training and classifies text documents.',\n",
       " 'We show how local ambiguit ies - ambiguities can be processed effi- ciently.<n>We propose mploys de- terministic inference rules that can exclude the readings which violate anaphoric accessibility conditions.<n>These rules operate directly on underspecified descrip- tions and fully maintain underspecifiedness.',\n",
       " 'Confidence Measures (CMs) have been calculated for utterance verification that speech recognition result as a post-processing.<n>This paper proposes two concept-level CMs that are on content-word level and on semantic-attribute level for every content word.<n>The system can make efficient confir- mation and effective guidance according to the CMs.',\n",
       " 'This paper describes the Agile system I tbr the multilingual generation of instructional texts.<n>routine passages as found in the AutoCAD user-manual have been taken as target texts.<n>The Agile system produces con- tinuous instructional texts realizing the speci- fied content and conforming to the style of soft- ware user-manuals.',\n",
       " 'This t)aper describes the automated (:reation of what we call topic signatures, constructs that can I)lay a central role.<n>ToI)ic signatures can lie used to identify the t)resence of a (:omphx conce.pt a concept hat consists of several related coinl)onents in fixed relationships.',\n",
       " 'This paper applies reintbrce- ment learning to automatically learn design choices that optimize system pertbrnmnee for a cho- seLL pertbrmance measure.<n>Consider the spoken dialogue system named N J- Fun, built to help users find fun places to go in New Jersey.',\n",
       " 'The TRUCKS approach to term recognition focuses on identifying relevant contextual informa- tion from a variety of sources.<n>The NC-Value method uses a combination of lin- guistic and statistical information.',\n",
       " 'lexical and structural differences exist between source and target languages.<n>For such mapping strategies, we need to treat several words (or morphemes) as a single translation unit.<n> MWTUs to be treated in Korean-to-Japanese MT have an almost fixed word order sequence.<n>We propose a representation and recognition method of MWTUs for a Korean-to-Japanese MT system.',\n",
       " 'Parsing-as-deduction approach is well established in computalional lin- guistics.<n>This paper shows how to implement the parsing process as constraint propagation.<n>The resulting constraint store represents he chart which can be accessed to determine whether the parse success fu l or to reconstruct a parse tree.',\n",
       " 'In this paper, we propose taking Japanese as the object lan-om the speech recognition area.<n>This model treats a word sequence and predicts each word from left to right.<n>In Japanese each word depends on a subse-quent word, that is to say, each dependency relation is left to right.',\n",
       " 'Random Fields Models (RFMs) deal with the graphical structure of a parse.<n>RFMs do not make independence assumptions about the stochas- tic generation process that might have produced some parse.',\n",
       " \"Sentences with eoor(lination (:ontaill multil)le phrases of like syntacti(; tyl)e.<n>When the given sentence shows structm'al ambig'lfit;y, tiler(; may 1)e multii)le pairs of candidates tbr l)ossil)le con- juncts/disjuncts, usually a single pair.\",\n",
       " 'Part of Speech Tagging and Shallow Parsing are two well-known problems in Natural Language Process- ing.<n>A Tagger can be considered as 2 translator that reads sentences from a certain language and outputs the corresponding sequences of part of speech (POS) tags.<n>Shallow Parsing usually identifies non-recursive con-stituents, also called chunks.',\n",
       " 'This paper describes an algorithm to match two segments of words.<n>The algorithm is written for the general case (F layers)<n>This edition uses a sequence of basic edit operations between the words of the segments.',\n",
       " 'We consider proof nets of the intuitionistic implicative linear logic.<n>In this paper, we only consider proof nets of the Lam-Bek calculus.',\n",
       " 'We will give the instantiation of a model that uses DOP for machine translation.<n>The model is largely based on DOPI (Bod, 1998, chapt. 2)<n>To allow for translation ca- pabilities in tiffs model, we will use pairs of trees that incorporate semantic infonnation.',\n",
       " \"We show how a rhetorical str'ucttre can be realized by a te:rt struct.uT'e (TS)<n>TSs include, for example, vertical ists, sub-sections, and clauses ep- arated by semi-colons.<n>Our goal in ICONOCLAST has been to explore the huge variety of ways in which an RS can be con-eyed.\",\n",
       " 'The aim of this paper is to use only nfinimal, but yet precise information fbr lexical ambiguity resolution.<n>We will show that good results are obtainable by employing a simple and natural look-up in a probabilistic lass-labeled lexicon.',\n",
       " 'Verbmobil is a spontaneous speech-to-speech translation system and spoken German to English/Japanese and vice versa.<n>The input for the Vcrbmobil speaker independent speech recognizers is spontaneously spoken German (vocabuhl 10,000,000 word forms), English (7,534 word forms) and Japanese (2,848 word forms).<n>We extracted context fiee grammars for German, English and Japanese flom the Verbmobil treebank (German: 25,881 trees; English: 23,140 trees; Japanese: 4,534 trees) to be able to parse spontaneous utterances.',\n",
       " 'Theory of dependency grammar culminated in the seminal book by Ln TesniSre, (TesniSre, 1959)<n> dependency trees are unordered, a.nd that the two trees of Figure 1 are equivalent.<n>We will model dependency desc, notations as two separate processes generating the tree structure T and one bottom-up process generating the surt3.ce string(s)',\n",
       " \"We report on techniques that automatically extract SFs for Czech, which is a flee word-order language.<n>In the input data, we describe a novel addition to the hypoth-esis testing technique that uses observed fl'ames.<n>Using our techniques, we able to achieve 88% in distinguishing adjuncts on unseen parsed text.\",\n",
       " 'In tile English language, the task of named entity recognition is one of the tasks of the Message Understanding Confer- once (MUC)<n>In Japanese named entity recognition, it is quite common to apply morphological analy- sis as a t)reprocessing step.<n>We propose a method for incorporating richer contextual information as well as patterns of constituent morphemes within a named en- tity.',\n",
       " \"The idea is l(;lal;ed Ix) (lx'.vin) who de.lined verl> classes on the basis of verl) atterl)al;ion behaqour.<n>For exmnl)le, (;he seman(;ic (:lass of l&h, icle Names coni, ains verbs like lmlloo'n, bicycle, ca.'n, oe, skate, ski which agree in (;he prol)erties (1)-(4) below.\",\n",
       " \"Dependency analysis is regarded as one of the standard methods of Japanese syntactic anal- ysis.<n>The Japanese dependency structure is usually represented by the relationship between phrasal units called 'bunsetsu'\",\n",
       " \"We will propose a Japanese dependency analyzer using a Deterministic Fi- nile State Transducer (DFST)<n>A dependency between two bunsetsu has a direc-tion fl'om a dependent to its head.\",\n",
       " 'The UNL project of network-oriented multilinguat communication has proposed a standard for encoding the meaning of natural language utterances.<n>More than 16 partners representing 14 languages have worked to build deconverters transforming an (interlingual) UNL hypergraph into a natural language utterance.<n>The UNL-French deconverter under development first performs a \"localization\" operation within the UNL format.',\n",
       " 'There is no explicit word boundary in the Thai language.<n>\"Word\", generally, means a unit of expression which has universal intuitive recognition by native speakers.<n>This paper proposes an automatic word-extraction algorithm.',\n",
       " 'Development of text databases has given impetus to research in computational linguistics towards the automatic handling of this information.<n>Huge amount of texts coming from heterogeneous sources revealed the need for robust ext classification tools.<n>Various types of style markers (i.e., countable linguistic features) have been proposed so far.',\n",
       " \"verbs is critical to a broad ra.nge of NI,I ) and l i t 1;asks, yet; ils mau us.1 (lel;('rmina.tion for la.rge numl)ers o[' verl)s is difficult aml resource intensive.\",\n",
       " 'Word-breaking is an unavoidable and crucial first step toward sentence analysis in Japanese.<n>In a sequential model of word-breaking and syntactic analysis without a feedback loop, the syntactic analyzer assumes that the results of word-breaking are correct.<n>Our approach contrasts with the previous approaches in that the word-breaker does not perform the selection of the best segmentation analysis at all.',\n",
       " \"Verbmobil is a speech to speech machine translation system.<n>Different translation methods are applied in parallel, thus increasing the system's robustness and tility.<n>We investigate a systematic solution to the various confidence values.\",\n",
       " 'The goal of machine translation is tile translation of a text given in some source language into a tar- gel: language.<n>Our approach uses word-to-word epen- dencies between source and target words.',\n",
       " 'adverbs of time, for example, tend to t)recede subjects, mM bunsetsus in a sentence that are modified by a long modifier tend to precede other bunsetsus in the sentence.<n>Knowl- edge of these word order tendencies would be useful in analyzing and generating sentences.',\n",
       " 'Phrase-representation summarization is a method to create the \"at-a-glance\" summary for the Japanese language.<n>In tiffs paper, Japanese words are represented in English as much as possible.',\n",
       " \"Sentence (1), for examl)le, is first recognized as a metonymy as an implicit term and 'Shakespeare' is replaced by 'works'\",\n",
       " 'This paper proposes methods for finding structural correspondences of parsed trees of a translation pair.<n>These structural correspondences are used as bases of translation patterns in corpus-based ap- proaches.',\n",
       " 'Prosodic prominence directs tile attention of the lis- tener to what is important for understanding and inteF pretation.<n>How should this principle be applied when words that are normally not very prominent, such as prollouns, are accented?<n>Pronouns are assumed to refer to tile most salient entity in lhc current discourse.',\n",
       " 'This paper proposes a method to align phrase-level correspondence using statistically prob- able dependency relations.<n>Our approach is based on the assumption that the word ordering and po- sitions may not coincide between the two languages.<n> dependency relations offer richer clues (syntactic information) and are effcctive for language pairs with different word ordering constraints.',\n",
       " 'Unsupervised learning of syntactic structure is one of the hardest 1)rol)lems in NLP.<n>We will describe an algorithm that finds the best structure in unstructured sentences.',\n",
       " 'We present the multi-stage a.rchitecture of the summa.rization system I)IMM which can deal with spo- ken di,dogues in English and Spa.nish.<n>Since it cannot rely on a.ny domain specific knowledge base, it uses shallow sta- tisticaJ approaches and presents (possibly modified) ca:lracts from the original text.',\n",
       " 'We describe the construction of VerbNet, a verb lexicon with explicitly stated syntactic and seman-tic information for individual exical items.<n>We use Lexicalized Tree Adjoining Grammar (LTAG) to capture the syntax for each verb class, and associate semantic predicates with each tree.',\n",
       " 'Machine translation by analogy lo pairs of corresponding expressions in the source and target languages, or \"example-based transhtlion\"<n>The HARONYM architecture for lky Ana aud rule-based chine translation of naturally_ occurring colloquial hmguabrid combines the adwmtages of both approaches.',\n",
       " 'This paper presents a simple approximation method for turning an HPSG into a context-free grmnmar.<n>The underlying idea is to generalize in a first step the set of all lexicon entries.',\n",
       " 'We present a pro- posal for a graph description language.<n>On the one hand, the language should be close to traditional linguistic de-scriptions languages.<n>On the other lmnd, the language should not preclude etlicient query eval- tion.',\n",
       " 'A parallel corpus is an important resource for corpus-based approaches to CLIR.<n>A bilingual comparable corpus is a set of texts in two different languages from the same do- main or on the same topic.<n>We show the possibility that the resulting bilingual text pairs can be useful for corpus-based CLIR approaches.',\n",
       " 'This paper describes a system for making extracts easier to read by revising them.<n>We first experimentally investigated the factors that make extracts hard to read.<n>We then classified the factors into five, most of which are related to cohesion.',\n",
       " 'This work was carried out as part of the research project \"Semantics of Natural Language Temporal Ques- tions and Interfaces to Temporal Database Systems\"<n>It is based on an independently moti- vated novel semantics of sentences modified by temporal Preposition Ph, rases (PPs)',\n",
       " 'We introduce several transtbrmations to the source string to improve translation re- suits.<n>We show how linguistic knowledge can improve translation re- suits.',\n",
       " 'We describe extensions to tile Hidden-Markov alignment model froln (Vogel et al, 1.996)<n>We compare tlmse to Models 1 - 4 of (Brown et al, 1993)',\n",
       " \"We will describe one of the two tasks in the IR.EX project.<n>The definition of NE's is given in an 18-page document, which is available through the II1EX homepage.\",\n",
       " 'In its sin> 1)lest version, examl)le-1)ased translat ion boils down to l l S i l lg a (tat;fl)ase of SOllrce sell(;el l(;es with their l;rmlslations.<n>Each transducer is a se of quadrut)les of the tbrm: label # source pal;t;ern # l;arget; tbr prol)er nmnes or numbers.',\n",
       " 'We will discuss experiments based on automatically extracted multilingual lexicons.<n>The hypotheses-testing methods use a generative device that produces a list of translation candidates.<n>The estimating approach is based on building from data a bitext model.',\n",
       " 'We use aword-to-word translation dictionary and corpusdata in the target language on the web to look for translation candidates.<n>In translation selection, we determine the possibletranslation(s) from among the candidates.<n>Experimental results indicate that our methodis very effective, and the coverage and top 3accuracy of translation at the final stage are 91.4% and 79.8%, respectively.',\n",
       " 'We use dependency treebanks semi-automatically to induce dependency-based sta-tistical models for parse selection.<n>A variety of different approaches have been takenfor robust extraction of relation/head/dependent tuples, or grammatical relations, from text.',\n",
       " 'Genetically related languages often exhibit recur-rent sound correspondences (henceforth referred tosimply as correspondences) in words with similarmeaning.<n>The determination of correspondences is the prin-cipal step of the comparative method of languagereconstruction.<n>A system able to perform this task automatically English Latint E n d e k e?ten?t u? d u o?two???<n>The experiments to be described in Sec-tion 6 show that the method is capable of determin-ing correspondences in bilingual wordlists in whichless than 30% of the pairs are cognates ',\n",
       " \"This paper explores the use of semantic and prag-matic information in the interfaced application's run-time en-vironment.<n>An existing pars-ing algorithm calculates and compares the de-notations of rival parse tree constituents.<n>It is extended to incor-porate a full set of logical operators into this calcu-lation so as to improve the accuracy ofparsing .\",\n",
       " 'A named entity recognizer (NER) is in many NLP applications such as informa-tion extraction, question answering, etc.<n>In MUC-6 and MUC-7, the named entity taskis defined as finding the following classes of names:person, organization, location, date, time, money, and percent.<n>We propose maximizing, where is the sequence of named-entity tags assigned to the words in the sentence.',\n",
       " 'We describe an in-depth study of answer reranking for definition questions in TREC-10.<n>Answers for 83% of 102 definition questions were ranked only 64% of them in the top 5.<n>If a perfect answer reranking function had been used, the best achievable MRR would have been 83% (an 84% increase over the original 45%)',\n",
       " 'This paper reports the development and im-plementation of a robust architecture for lan-guage processing in Bulgarian referred to asLINGUA.<n>LINGUA is a text processing framework forBulgarian which automatically performs tokeni-sation, sentence splitting, part-of-speech tag-ging, parsing, clause segmentation, section-heading identification and resolution for thirdperson personal pronouns.',\n",
       " 'This paper presents the implementation of a hybrid system for topic analysis called TOPICOLL.<n>It de-tects topic shifts and finds links between segments without delaying its decision, i.e., by only takinginto account the part of text that has been alreadyanalyzed.<n>It simultaneously achieves topic segmentation andlink detection, i.e. determining whether two seg-ments discuss the same topic.',\n",
       " 'We show how to accomplish this task by applying machine learning techniques.<n>A comparison between English and German illustrates that it is possible in both languages to extrapose clausal material to the right periphery of a clause.',\n",
       " 'The classification of verbs based on their underlyingthematic structure involves distinguishing verbs that take the same number and category of arguments but assign different thematic roles to these argu-ments.<n>This is often termed as the classification ofverb diathesis roles or the lexical semantics of pred-icates in natural language.<n>The data we use is only passed through a part-of-speech tagger and a chunker which is used to iden-tify base phrasal categories.',\n",
       " 'TREC evaluations of QA systems require answers to be drawn from a given source corpus.<n>Use-Knowledge: extract query words from the input question.<n>Use-the-Web: extract likely answer-bearing sentences.',\n",
       " 'There is no blank to mark word boundaries in Chinese text.<n>It is difficult to identify unknown words in a text since all Chinese characters can either be a morpheme or a word.<n>It is not possible to list all of the proper names and compounds neither in a lexicon nor enumeration by morphological rules.',\n",
       " 'This paper presents two decoding methods, one is the right-to-left decoding based on the left-to-right beam search algorithm, which generates out-puts from the end of a sentence.<n>The second one isthe bidirectional decoding method which decodes inboth of the left-to-right and right-to-left directionsand merges the two hypothesized partial sentencesinto one.<n>The experimental results of Japanese and English translation indicated that the right-to-leftdecoding was better for English-to-Japanese trans-lation, while the left-to-right decoding was betterfor Japanese-to-English',\n",
       " 'Zero anaphora or zero pronouns (henceforth zeros) are referential noun phrases (NPs) that are not overtly expressed in Japanese discourse.<n>The use of zeros is common in Japanese and this poses a challenge for Japanese as a Second Lan-guage (JSL) learners.<n>This paper proposes a method of systemati-cally identifying the presence of zeros in order that teachers might provide effective instruction of zeros.',\n",
       " 'In English, nouns heading noun phrases are either countable or uncountable.<n>Countable nouns can be modified by denumerators, prototypicallynumbers, and have a morphologically markedplural form: one dog, two dogs.<n>Uncountablenouns cannot be modified by denumerators, butcan be modified by unspecific quantifiers suchas much.',\n",
       " 'This paper presents an important quadratic sen-tence extraction technique based on Support Vector Machines (SVMs)<n>SVM is a supervised learning algorithm for 2-class problems.<n>The number of important sen-tences in a document is determined by a sum-marization rate that is given at the test data.',\n",
       " 'In spoken language translation one of the keyissues is how to deal with unrestricted expres-sions in spontaneous utterances.<n>We have proposed a paraphrasing ap-proach in which the utterances are automati-cally paraphrased prior to transfer.',\n",
       " 'Word sense disambiguation (WSD) is an?intermedi-ate? task that is necessary for accomplishing mostnatural language processing tasks.<n>We have developed an unsu-pervised WSD method using bilingual comparablecorpora.',\n",
       " 'We present a rich semantic network based on a differential analysis.<n>We then detail implemented measures that take into account common and differential features between words.<n>In a last section, we describe some industrial applications.',\n",
       " 'Text generation is an important technique used for applications like machine translation, sum-marization, and human/computer dialogue.<n>In this paper, we describe a text-generation model and a gen-surface system that uses the model.',\n",
       " 'Cross-lingual naturallanguage processing such as machine translation(MT) and cross-lingual information retrieval(CLIR) is becoming more important.<n>We propose a method of measuring the similar-ity to acquire compound noun translations bycorpus information.',\n",
       " 'Information extraction (IE) is an important appli-cation for natural language processing.<n>IE systems depend on parsing tools and specializeddictionaries that are language specific, so they arenot easily portable across languages.<n>In this paper, we explore the idea of using an informationstatisticsextraction system designed for one language to au-tomatically create a comparable information extrac-tion system for a different language.',\n",
       " 'This paper presents a NLP system which integrates a linguistic PartofSpeech PoS tagger and chunker as opposed to datadriven as a preprocessing module of a broadunicationbased grammar of Spanish.',\n",
       " 'This paper deals with the problem of how to dis-ambiguate the readings of sentences, analyzed by agiven unification-based grammar (UBG)<n>The kernel of our novel disam-biguation method for UBGs consists of a context-free approximation for a givenUBG (Kiefer and Krieger, 2000) and the exploita-tion of the standard probability model for CFGs.',\n",
       " 'Anaphora resolution is crucial in natural lan-guage processing (NLP)<n>In other languages such as Japanese and Spanish, anaphoric expressions are often omit-ted.<n>Ellipses related to obligatory cases are usu-ally termed zero pronouns.<n>Since zero pronounsare not expressed in discourse, they have to bedetected prior to identifying their antecedents.',\n",
       " 'In Chinese, there is no white space to delimit the words, where a word is defined as consisting of one or more characters representing a linguistic token.<n>In this paper, we consider a new approach of employing a multi-agent framework to tackle the Chinese NE recognition problem.',\n",
       " 'The classification of named entities in Korean is a little more difficult than in English.<n>This paper proposes an unsupervised learning model that uses a small-scale named entity dictionary and an unlabeled corpus for classifiying named entities.',\n",
       " 'More than 100 Chinese input methods have been created in the past.<n>Phonetic input method requires little training because Chinese are taught to write the corresponding syllable of each Chinese character in primary school.<n>An intelligent syllable-to-word (STW) conversion for Chinese is very important.',\n",
       " 'Machine-readable thesauri are now an indispen-sable part for a wide range of NLP applications.<n>Recent NLP research has been aiming to develop ways to automatically acquire lexical knowledge from corpus data.<n>We address the problem of large-scale augmenting a thesaurus with new lexical items.',\n",
       " 'Most text-to-speech systems use statistical models to find appropriate loca-tions for prosodic phrase breaks.<n>We develop a computational model which assignsprosodic structure to unrestricted text.',\n",
       " 'N-gram language modeling techniques have been embedded in a number of natural lan-guage processing applications.<n>N-gram based techniques rely on the assumption that the large majority ofwords to be predicted have also occurred in the cor-pus used to train the models.<n>A model of this sort will be able to predict newlyformed compounds that never occurred in the train-ing corpus.',\n",
       " 'In Korean, many technical terms in a domain specific text, especially science and engineering are from foreign origin.<n>Sometimes they are written in their original forms and sometimes they are transliterated into Korean words in various forms.<n>This makes difficult to handle them in natural language processing.',\n",
       " 'In general, corpora are annotatedby hand, and therefore are error-prone.<n>In this paper, we focus on detection of er-rors in corpora annotated with POS tags, andpropose a method for corpus error detection us-particularing support vector machines (SVMs)',\n",
       " 'We present a formalism relying on constraints that constitutes a possible answer to this problem.<n>The idea consists then in implementing a technique that can make use of some constraints and the entire set of them for deep analysis.<n>One of the main interests in using constraints comes from the fact that it becomes possible to represent any kind of information by means of a device.',\n",
       " 'Supervised learning has become the most successful paradigm for Word Sense Disambiguation (WSD)<n>This paper explores the contribution of a broad set of syntactically motivated features that ranges from the presence of complements and adjuncts to the detection of subcategorization frames.<n>The performance of the syntactic features is measured in isolation and in combination with a basic set of local and topical features.',\n",
       " 'Many applica-tions such as Word-Sense Disambiguation, In-formation Extraction and Speech Recognition require lexicons.<n>Coverage of hand-built lexical resources such as WordNet has increased dramatically in re-cent years, but leaves several problems andchallenges.<n>This paper describes a method for arrangingsemantic information into a graph, where the nodes are words and the edges represent relationships be-tween words.',\n",
       " 'Word sense disambiguation (WSD) is an openresearch eld in natural language processing(NLP)<n>This paper presents a system that implements a corpus-based method of WSD.<n>It has been im-plemented using a supervised learning methodthat consists of building word-sense classi ersusing a semantically tagged corpus.',\n",
       " 'The law of Zipf (1949) for word tokens in a corpus states that if f is the frequency of a word in the corpus and r is the rank, then: rkf = (1) where k is a constant for the corpus.<n>Zipf?s discovery was followed by a large body of literature reviewed in a series of papers edited by Guiter and Arapov (1982).<n>It continues to stimulate interest today (Samuelson, 1996; Montermurro, 2002; Ferrer and Sol?, 2002) and, for example, it has been applied to citations Silagadze (1997) and to DNA sequences.',\n",
       " 'It is difficult to construct a case frame dictio-nary by hand.<n>This paper proposes a method of fertiliz-ing the case frame dictionary to handle complicated expressions.',\n",
       " 'Measuring the representativeness (i.e., the informativeness or domain specificity) of a term? is essential to various tasks in natural language processing (NLP) and information retrieval (IR)<n>This paper proposes a novel and effective measure of term representativeness that reflects the bias of the words co-occurring with a term.',\n",
       " 'This paper proposes a new, fairly simplesyntax for the identification and transformation ofnode labels.<n>The ultimate goal of this work is to mini-mize the human effort needed when adapting a pars-ing model to a new domain.',\n",
       " 'We show how different classification and learning algorithms can be employed to automatically subcategorize person names in text.<n>In doing this we examine how to automatically generate training for use with supervised learning algorithms, and how to handle inconsistencies between instances of the same person.',\n",
       " 'This paper focuses on evaluating probabilisticmodels of verb-argument structure in terms of howwell they model unseen test data.<n>We will examine maximum likelihoodbigram and trigram models, clustering models based on those of Rooth et al (1999), and a newprobabilistic model designed to capture alternationsin verb-argument structure.',\n",
       " 'This paper describes the characteristic fea-tures of Japanese spoken language on the ba-sis of investigating a large-scale spoken dialoguecorpus.<n>It proposes a method of dependencyparsing by taking account of such the features.<n>The method acquires in advance the probabilities of dependencies from a spoken dialoguecorpus tagged with dependency structures.',\n",
       " 'We show that eachof SPoT and FERGUS can be ported to differ-ent domains with little manual effort.<n>We then show the on-line integration of FERGUS with a dialog system.',\n",
       " 'There is no easy way of looking up the componentcharacters of new words in a dictionary.<n>This research attempts toalleviate the dictionary look-up bottleneck by wayof a comprehensive dictionary interface.<n>We will focus exclusively on a Japanese?English dictionary interface.',\n",
       " 'Word Sense Disambiguation (WSD) is a centralopen problem at the lexical level of Natural Lan-guage Processing (NLP)<n>This paper reports on our experiments on au-tomatic WSD using a maximum entropy approach for both English and Chinese verbs.',\n",
       " 'We propose a clustering-rithm, CBC (Clustering By Committee), in which the centroid of a cluster is constructed by averaging the feature vectors of a subset of the cluster members.<n>By carefully choosing committee members, the features of the centroid tend to be the more typical features of the target class.',\n",
       " 'The Penn Chinese Treebank project aims to create a segmented Chinese corpus annotated with POS tags and syntactic brackets.<n>The firstinstallment of the project consists ofXinhua newswire between the years 1994 and 1998 totaling 100,000 words.<n>The second installment of the project, the400,000-word CTB-II is being developed and is expected to be completed early in the year 2003.',\n",
       " 'This paper develops a novel framework for recognizing entities and relations together.<n>Separate clas-sifiers are first trained for entities and relations.<n>Our global inference approach accepts as input probabilities which are the outcomes of?lo-cal? classifiers.',\n",
       " 'We address a dialogue strategy to nd the users intended item from theretrieved result which is initiated by a spontaneous query utterance.<n>We propose a conrmation strategy by making use of a tree structure of the manual and dene three cost functions for selecting question nodes.',\n",
       " 'The XTAG Project aims at the development of natural resources based on Tree Adjoining Gram-mars (TAGs)<n>An LTAG is a set of lexicalized elementary trees that can be combined, through the operations of treeadjunction and tree substitution, to derive syntacticstructures for sentences.<n>This paper describes how we combined Becker?s metarules with a hierarchy of rule application to generate the verbtree templates in the XTAG English grammar.',\n",
       " 'This research grew out of the Integrated Feasi-bility Experiment on Biological Infectious Out-breaks (IFE-BIO)<n>This particular scenario requiresa comprehensive list of disease names.<n>Otherrequisite classes of names include: biologicalagents causing disease, such as viruses and bac-teria; vectors|organisms or animals capable oftransmitting infection; and possibly names ofdrugs.',\n",
       " 'Structured language models (SLMs) were proposed for understanding the dictation results.<n>Theirpredictive powers are reported to be slightly higher than an orthodox word tri-gram model.<n>The most popular language model for spoken language understanding is the Structured Language Model (SLM)',\n",
       " 'This research addresses the generation of lexical paraphrases for queries posed to the Internet.<n>We use WordNet andpart-of-speech information to propose these syn-onyms, and build candidate paraphrases from com-binations of these synonyms.<n>The resultant para-phrases are then scored using word co-occurrence information obtained from a corpus, and the high-est scoring paraphrases are retained.',\n",
       " 'Sandglass Translation Model is designed so that the system can gener-ate a translation through source language para-phrasing.<n>It is easy to construct an MT for a new language, since our model depends only on source lan-guage.<n>It does not require design of interlin-gua/controlled language.',\n",
       " 'We focus on the Infectious Dis-ease Outbreak scenario (Grishman et al, 2002), and the Natural Disaster scenario (Hirschmanet al, 1999) collectively called the Nature\" sce-narios.<n>During the customization of the IE sys-tem to the Nature scenarios, we encounteredproblems that did not arise in the traditionalscenarios of the Message Understanding Con-ferences (MUCs)<n>We identify two structural factors that con-tribute to the complexity of a scenario: rst, thescattering of events in text, and second, inclu-sion relationships between events.',\n",
       " 'We show how previously proposed methods can be extended to and improved for specialized domains.<n>We rely in this work on two main linguistic resources: a general bilingual dictionary and a specialized multilingual thesaurus.',\n",
       " 'No dictionary can ever be complete since new words are being coined constantly and the properties of existing words can change over time.<n>Traditional way to make a dictionary more complete is to edit the dictionary itself, either by hand or through batch updates using data obtained from other sources.<n>This paper discusses an alternative approach where, instead of editing a static dictionary, we acquire lexical information dynamically during sentence analysis.',\n",
       " 'Detection of abbreviations in a text corpus forms one of the initial steps in tokenization.<n>We will consider the classification of the period as either an abbreviation mark or a punctuation mark.',\n",
       " 'It is true that NLP technologies arenot perfect, but some of the diculties result from ambiguities in HTML.<n>If linguis-tic information is added to source texts, it greatlyhelps NLP programs to produce better results.',\n",
       " 'The Institute of Computational Linguistics (ICL), Peking University, has launched the Project CCD (Chinese Concept Dictionary)<n>It should carry the main relations already defined in WordNet with more or less updates to reflect the reality of contemporary Chinese.<n>Such a bilingual WordNet-like lexicon Chinese-English concepts can largely meet our need of applications.',\n",
       " 'The?Spontaneous Speech: Corpusand Processing Technology? project was imple-mented in 1999 to overcome this problem.<n>Tagging the spontaneous speech corpus withmorphological information such as word seg-mentation and parts-of-speech is one of thegoals of the project.<n>This paper describes a model which estimateshow likely a string is to be a morpheme.',\n",
       " 'Cross-language information retrieval relies on some form of bilinguallexicon.<n>We aim at identifying French-English translation candidates from comparable medicalcorpora.',\n",
       " 'ATT-Meta is an uncertainrule-based system operating by backchaining.<n>It performsreasoning, but does not yet interface directly to natural language.<n>Mixed metaphors need not feature cases of conflict but can includegraceful combinations of metaphors.',\n",
       " 'The idea behind it is torepresent the near-identities that closely related lan-guages such as Dutch, English and German so oftenshare.<n>While they have significantly differ-ent vowel, their consonant invento-ries overlap greatly.<n>Unlike vowels, consonants can oc-cur in clusters at either the beginning or end ofsyllables.',\n",
       " 'This paper describes an indexing substrate for typed feature structures (ISTFS)<n>The ultimate purpose of the substrate is aimed at the construction of large-scale intelligent NLP systems.',\n",
       " 'We present an efficient algorithm to analyze dependency structures of head final languages such as Japanese.<n>The proposed algorithm allows us to analyze dependency structuresof a sentence in linear-time while keeping a state-of-the-art accuracy.',\n",
       " 'A Hidden Markov Model (HMM) is a model where a sequence of observations is generated in addition to the Markov state sequence.<n>Traditionally, a HMM segments and labels sequential data in a generative way, assigning a joint probability to paired observation and state sequences.<n>The main reasons behind these problems are the strong context independent assumption and the generative nature in modeling data.',\n",
       " 'A central component of the statistical trans-lation models is the lexicon.<n>The EM algorithm is used to trainthe free lexicon parameters.<n>We will evaluate these methods on the Verbmobil task and the French?English Canadian Hansards task.',\n",
       " 'This paper focuses exclusively on inferring high-level structure.<n>We investigate ways to auto-matically determine the correct attachment site forparagraph and multi-paragraph segments.<n>We use machine learning to build a complex of segment relatedness that combines wordco-occurrence with other information.',\n",
       " 'Type-inheritancey Categorial Gram-mar (TCCG) is a type-inheritance, unification-based CCG of the English fragment in Sag and Wa-sow (1999)<n>I adopt thetype hierarchies of HPSG wholesale into TCCG, ex-ploring directly the theoretical advantages this hy-brid approach yields.',\n",
       " 'This paper presents a new type of dependency parsing based on a treebank of Swedish sentences.<n>It uses a deterministic parsing algorithm in combination with a classifier induced from a treebank.<n>The results show a dependency accuracy of 84.7% and a labeled accuracy of 80.6%.<n>The algorithm used in this paper combines bottom-up and top-down processing in a single pass in order to achieve incrementality.',\n",
       " 'The class of context-free grammars(CFGs) is by far the best understood and mostwidely used.<n>Regular expressions, with their proceduralcounter-part of finite automata (FAs), are notable to describe hierarchical, tree-shaped struc-ture.<n>Such appli-cations can for example be found in real-timespeech recognition systems.',\n",
       " 'Regular languages are widely used in Natural Language processing, for various dif-ferent tasks.<n>Existing al-gorithms for learning binary automata have onlyguarantees of identification in the limit.',\n",
       " 'Examples of machine translation (MT) meth-ods have been proposed that automatically ac-quire their knowledge or models from the cor-pora.<n>This paper presents an example-based MT method based on syntactic transfer, which selectsthe best translation by using models of statisti-cal MT.',\n",
       " 'This paper introduces two kinds of expressionthat can filter information.<n>First, we define a per-spective expression to be the minimal span of textthat denotes the presence of an explicit opinion.<n>Second,speech expressions simply convey the words of an-other individual and by the choice of words, the writer filters the original source?s intent.',\n",
       " 'The PRECISE system is an instance of a well known machine learning algorithm.<n>The PRECISE architecture and its coretheory are described.',\n",
       " 'We investigate thepossibility of determining the structure of fac-tored language models by a data-driven search procedure, viz. Genetic Algorithms (GAs)<n>GAs lead to better models than ei-ther knowledge-inspired manual search or ran-dom search.',\n",
       " 'BitPar is based on a bit-vector implementation of the Cocke-Younger-Kasami (CKY)algorithm.<n>Viterbi parses large context-free grammars extracted from tree-banks.',\n",
       " 'This paper introduces a grammar format that sup-ports a direct encoding of linearization-based HPSGtheories.<n>The ID/LP grammar format integrates the word order do-mains and constraints into the parsing process.',\n",
       " 'A key assumption of traditional syntax-semantics interfaces is that the mapping from syntax to semantics is functional.<n>This paper introduces a completely relational syntax-semantics interface, building upon theunderspecification approach.<n>XDG is a description-based formalismfor dependency grammar.',\n",
       " 'In statistical machine translation, we are given a source language (?French?) sentence fJ1 =f1.<n>FJ1 is to be translated into a target language (?English?) sentence eI1 =e1.<n>E?I1 = argmaxeI1Pr(eI1|fJ1 )Pr(eI1|fJ1 )',\n",
       " 'Word alignment is the task of identifying trans-lational relations between words.<n>It is used in machine translation and multi-lingual lex-icography.<n>Several approaches have been pro-posed for the automatic alignment of words andphrases.',\n",
       " 'Word-aligned bilingual corpora provide im-portant knowledge for many natural languageprocessing tasks.<n>We will present a wordalignment algorithm which avoids the con-straint and produces symmetric word align-ments.',\n",
       " 'Sluicing?bare wh-phrases exhibit a sentential meaning?constitutesan empirically important construction.<n>Most theoret-ical analyses focus on embedded sluices consideredout of any dialogue context.<n>In this paper we applymachine learning techniques to extract rules forsluice classification in dialogue.',\n",
       " 'Distributional Similarity measures com-pare a pair of weighted feature vectors that characterize two words.<n>It is assumed that different words that occur within similar contexts are semantically similar.<n>In this paper we adapt this new criterion, termed meaning entailing substitutability, as a direct evaluation criterion for the \"correctness\" of the output of word similarity measures.',\n",
       " 'We show that the accuracy of the dependency can be improved by adding a base-NP chunker, a Root-Node Finder, and a Prepositional Phrase Resolver.',\n",
       " 'Supertag-ging was introduced for Lexical-ized Tree Adjoining Grammar (LTAG) and Com-binatory Categorial Grammar (CCG)<n>Supertagging accuracy is relatively high for man-ually constructed LTAGs.<n>We show that CCG supertagging accuracy is not only suffi-cient for accurate and robust parsing.',\n",
       " 'The notion of polarity comes from CategorialGrammars (Moortgat, 1996) which ground syn-tactic composition on the resource sensitivity ofnatural languages.<n>Polarization of a grammatical formalism Fconsists in adding polarities to its syntacticstructures to obtain a polarized formalism Fpolin which neutralization of polarities is used for controlling syntactic composition.',\n",
       " 'In statistical machine translation, a translationmodel Pr(fJ1 |eI1) describes the correspondences between the words in the source language sen-tence fJ1 and the words in the target languagesentence eI1.<n>We propose an approach to im-prove the quality of the statistical alignmentsby taking into account the interdependencies ofdifferent derivations of the words.',\n",
       " 'Some users permit only perfect translations, while otherusers permit even translations with flawed grammar.<n>Unsatisfactory MT outputs are those whose transla-tion quality is worse than the level the user can per-mit.<n>The confidence measures1 indicatehow perfect/satisfactory the MT outputs are.',\n",
       " 'The purpose of discourse segmentation is to split a text into elementary discourse units (edus)<n>The discourse analyzer at the sentence-level is presented in Section 2.1.1.<n>In doing so, two main tasks need to be identified: dis-course segmentation and discourse parsing.',\n",
       " 'The importance of learning to manipulate monolingual paraphrase relationships has been highlighted.<n>One approach involves identifying anchor points--pairs of words linked in a known way--and collecting the strings that intervene.<n>We show that although the edit distance corpus is well-suited as training data for the alignment algorithms currently used in SMT, it is an incomplete source of information.',\n",
       " 'We present a novel methodology to create a semantically annotated corpus by exploiting information contained in an already annotated corpus.<n>The methodology has been applied in the creation of the MultiSemCor corpus.<n>We evaluate the performance of a new version of the word alignment system and the final quality of the annotations transferred from English to Italian.',\n",
       " 'The detailed linguistic analyses generated by deep parsing are an essential component of spoken dia-log systems.<n>The TRIPS collaborative dialog assistantrelies on the representation produced by its corpus.<n>In this paper we explore whether twopreprocessing with a shallow generator can improve thespeed and accuracy of deep parsing.',\n",
       " 'We propose a formal model for selecting and packing information across multiple text units.<n>We provide a unified framework for addressing content overlap that doesnot require external measures of similarity between units.<n>The model is application- and task-dependent, allowing for dif-ferent applications to operate on text pieces of dif-ferent granularity.',\n",
       " 'Language models (LM) are applied in many natural language processing applications, such as speech recognition and machine translation.<n>In statistical machine translation we have a similar situation, i.e. estimate the model parameter from some data, and use the system to translate sentences which may not be well covered by the training data.<n>The potential of adaptation techniques needs to be explored for machine translation applications.',\n",
       " 'A number of syntactically motivated ap-proaches to statistical machine translation have beenproposed.<n>These approaches assign a parallel treestructure to the two sides of each sentence pair.<n>Tree-basedapproach allows us to represent the fact that syn-tactic constituents tend to move as unit.',\n",
       " 'In our corpus of newspaper commentaries, we found that 35% of the coherence relations aresignalled by a connective.<n>Our proposal is to splitthe annotation process into two parts:1.<n>ConAno can export the anno-tated text in the?rs3? format that serves as in-put to O?Donnell?s RST Tool (O?Donnell, 1997)',\n",
       " 'Large-scale corpora are useful for evaluating sentence extraction systems.<n>It is clear that the correspondence among thesentences is very complex.<n>We combine two methods to achieve such alignment.',\n",
       " 'A word segmentation pro-cess is a prerequisite for natural language process-ing (NLP) of non-segmented language family.<n>Unknown word processing in non-segmented language can follow oneof either approaches: modular or embedded.<n>We propose a general-purpose unknown word based on character-based chunking inorder to address these shortcomings.',\n",
       " 'We propose a hybrid method for word segmentation in Chinese and Japanese.<n>The methodutilizes both word-level and character-level processing.<n>It achieves high accuracy with low computational cost.',\n",
       " 'Bag-of-Words (BoW) is the most common rep-resentational scheme in text categorization.<n>We introduce a new method for producing concept-based represen-tations for natural language data.<n>Our goal is to investigate whether there are spe-cific categories in a standard text categorization for which using concept-based repre-sentations is more appropriate.',\n",
       " 'Sentiment analysis (SA) is a task to obtain writers? feelings as ex-pressed in positive or negative comments, questions, and requests.<n>This paper describes a method to extract a setof sentiment units from sentences.',\n",
       " 'To evaluate machine translations, the machine translation community recently adopted an n-gram co-occurrence scoring procedure BLEU.<n>A similar metric, NIST, used by NIST (NIST 2002) in a couple of machine translation evaluations in the past two years is based on BLEU.<n>With so many different automatic metrics available, it is necessary to have a common and objective way to evaluate these metrics.',\n",
       " 'Multiple document summarization is now a central issue for text summarization research.<n>We detail the corpus construction and evaluation measures used at the Text Summa-rization Challenge 3.',\n",
       " 'We propose a weakly supervised IE framework which takes advantages of both soft and hard matching pattern rules in both the training and test phases.<n>In the test phase, soft pattern rules are expected to cover more unseen instances, which are likely to be missed by hard-matching rules.<n>Experiments show that the bootstrapping scheme with two cascaded pattern rule learners could achieve a performance close to that obtained by fully supervised learning.',\n",
       " 'This paper provides the first comprehensive comparison of methods for unsupervised part-of-speech tagging.<n>We explore an HMM approach to tagging that uses context on both sides of the word to be tagged.<n>Second, we describe a method for sequential unsupervised training of tag sequence and lexical probabilities in an HMM.',\n",
       " 'Authorship identification has been a long stand-ing topic in the field of stylometry.<n>Issue of style, genre and authorship are about the?form? of a text.<n>In this paper, we demonstrate that a combination of features based on shallow linguistic analysis (function word frequencies, part of speech trigrams) and a set of deep linguistic analysis features (context free grammar production frequencies and features derived from semantic graphs) yields very high accuracy in attributing a short random text sample to one of the three Bront sisters as its au-thor.',\n",
       " 'We propose a new approach for the task of mining new word translations from comparable corpora.<n>The accuracy of our combined approach is better than the accuracy of using just context or translitera-tion information alone.<n>Our method is general and applicable to other language pairs.',\n",
       " 'A machine translation model is trained with a word-aligned parallel corpus where the source language side consists of dependency trees.<n>To translate a sentence, we first parse it and extract a set of paths from its dependency tree S.<n>We then find a set of transfer rules that cover S and produce a set of tree fragments obtained to form a tree T* such that T*=argmaxT P(T|S)<n>The output sentence can then simply be read off T*.',\n",
       " 'Decoding is a discrete problem whosesearch space is large.<n>By breaking the decoding problem intotwo simpler search problems, we are able to pro-vide that translations are 50words long in about 5 seconds.',\n",
       " 'Existing encyclo-pedias often lack new terms and new definitions forexisting terms.<n>The World Wide Web (the Web) containsan enormous volume of up-to-date information.<n>We have compiled an ency-clopedic corpus for approximately 600,000 Japaneseterms.',\n",
       " 'Our research is carried out within the Amalgam broad coverage sentence realization system.<n>Amalgam has an explicit ordering stage that determines the order of constituents and their daughters.<n>Our ultimate goal is to develop a model that handles all ordering phenomena in a unified and elegant way across typologically diverse languages.',\n",
       " 'Cross Language Information Retrieval (CLIR)is increasingly relevant as network-based re-sources become commonplace.<n>Historically, the most traditional approach to IR in gen-eral and to multilingual retrieval in particular,uses a controlled vocabulary for indexing andretrieval.<n>A second approach to multilingual interroga-tion is to use existing machine translation(MT) systems to automatically translate thequeries.<n>A third approach receiving increasing attentionis to automatically establish associations be-tween queries and documents independent of differences.',\n",
       " 'This paper is the first attempt of Chinese- SCF auto-acquisition based on real Chinese corpus.<n>The application program consists of 6 parts as shown in the following paragraphs.',\n",
       " 'Most popular methods of sentence reduc-tion for text summarization are corpus basedmethods.<n>Support Vector Machines (Vapnik 95) are strong learning methods in com-parison with decision tree learning and otherlearning methods.<n>We describe a novel deterministic method for sentence reduction using SVMs and a two-stage method using pairwise coupling.',\n",
       " 'It is essential to pay attention to sentence orderingin case of multi-document summarization.<n>We propose an approach to co-herent text structuring for summarizing news-paper articles.',\n",
       " 'We develop a system for automatically generating summaries of conversational speech.<n>Our system employs a set of semantic similar-ity metrics which utilize WordNet as a knowledgesource.',\n",
       " 'In the last decade, we have seen an explosion in the amount of available digital text resources.<n>Many NLP algorithms tap into only megabytes or gigabytes of this information.<n>We present an algorithm for extracting is-a relations, designed for the terascale.',\n",
       " 'WSD refers to the resolution of lexical semanticambiguity and its goal is to attribute the correctsense(s) to words in a certain context.<n>The WSD system for Dutch1 presented here is acorpus-based supervised algorithm combining stat-istical classification with various kinds of linguisticinformation.<n>The linguistic information in-cludes lemmas, part-of-speech (PoS), and the con-text around the ambiguous word.',\n",
       " 'In transliteration, a word in one language is converted into a character string of another language expressing how it is pronounced.<n>Here, the italic alphabets are romanized Japanese katakana characters.<n>Transliterated words such as personal names or technical terms in katakana are not al-ways listed in dictionaries.',\n",
       " 'Software companies receive high volumes of electronic customer feedback every day.<n>It is desirable to provide intelligent and automatic classification of the feedback.<n>The results we present in this paper are based on customer feedback data from web surveys.',\n",
       " 'We propose a method tostrengthen the lexical knowledge for Named Entitytagging by using synchronicity of names in com-parable documents.<n>Named in comparable documents haveone notable characteristic: they tend to be preserved across comparable documents.',\n",
       " 'This paper focuses on the development of a cross-lingual information extraction system.<n>The system is called QDIE (Query-Driven InformationExtraction) system.<n>It consists of threephases to learn extraction patterns from the source for a scenario specified by the user.',\n",
       " 'We present work on the detection ofquestion and answer pairs in email threads.<n>Email is a written medium of asyn-chronous multi-party communication.<n>About 20% of all email threads focus pri-marily on a question-answer exchange.',\n",
       " 'Syntactic simplification is an NLP task, the goal of which is to rewrite sentences to reduce their gram-matical complexity while preserving their meaningand information content.<n>We explore the use of syntactic simplificationin multi-document summarization.',\n",
       " 'This paper describes a new model for the acquisi-tion and exploitation of selectional preferences forpredicates from natural language corpora.<n>Our goal is to construct a computational lexical database ofrich selectional contexts.<n>Such a resource promises to have applications for a number of NLP tasks, including word-sense disam-biguation.',\n",
       " 'We propose to automatically construct a bilingual lexical semantic network with word sense and semantic role mapping between English and Chinese.<n>We estimate the semantic transfer likelihoods between English FrameNet lexical entries and the Chinese word senses in HowNet.<n>We induce Chinese example sentences automatically to match English sentences provided in the FrameNet.',\n",
       " 'An evaluation strategy classifies thecandidates accepted by a ranking method into?good? ones (true positives, TP) and?bad? ones(false positives, FP)<n>A widely-used evaluation strategy classifies thecandidates accepted by a ranking method into?good? ones (true positives, TP) and?bad? ones(false positives, FP)',\n",
       " 'The aim of our work is to provide an automati-cally generated overview over the major news of each day (midnight to midnight) in the languages English, German, French, Spanish and Italian.',\n",
       " 'We will focus on the appropriateness of the data in the light of a specific application or research goal.<n>The present study is motivated by the fact that for many uses the (near-)nativeness of the data is a critical factor in the development of adequate resources.',\n",
       " 'Natural language is an open and very flexible com-munication system.<n>Natural language speakers usually enjoy an enor-mous degree of freedom to express the content theywant to convey.<n> collocations can be characterized by at least threerecurrent and prominent properties.',\n",
       " 'Similarity-based smoothing is an intuitivelyappealing approach to a problem where prob-abilities of unseen co-occurrences are estimated.<n>Other potential applications apply the hy-pothesised relationship between distributional similarity and semantic similar-ity.<n>We present ten distributional simi-larity measures that have been proposed for use in NLP.',\n",
       " 'We present two types of models for word co-occurrence: functional models and distance mod-els.<n>The choice of the termterm co-occurrence frequency estimates had a big-ger impact on the results than the actual choice of similarity measure.<n>We discuss practical applications of our frameworkin section 4, which also provides validation of the framework.',\n",
       " 'Sentence-aligned parallel corpus is an important resource for machine translation.<n>Many different methods have been proposed to mine parallel sentences from multilingual corpora.<n>Our challenge is to find matching bilingual sentences from documents that might or might not be on the same topic.',\n",
       " 'Developing morphological analyzer for a new language byhand can be costly and time-consuming.<n>Supervised learning methods, on the other hand, re-quire annotated data, which is often scarce or non-existent, and is also costly to develop.<n>This paper addresses a key task for unsuper-vised morphological analysis: word segmentation,segmenting words into their most basic meaning-ful constituents.',\n",
       " 'We develop an algorithm which automatically aligns translationally equivalent tree fragments in a fast and consistent fashion.<n>Our algorithm identifies sub-structural translationalequivalences with 73.7% precision and 67.84% re-call.<n>We use data aligned by our novel al-gorithm and evaluate the output.',\n",
       " 'We con-centrate on adjectives, which have received less at-tention.<n>We compare the results with a set of ad-jectives classified by human judges according to se-mantic characteristics.',\n",
       " 'Google?s PageRank link-analysis algorithm (Brinand Page, 1998), and variants like Kleinberg?s HITSalgorithm (Kleinberg, 1999), have been used for an-alyzing the link-structure of the World Wide Web.<n>This paper explores the applicability ofPageRank to semantic networks, and show that suchgraph-based ranking algorithms can be successfullyused in language processing applications.',\n",
       " 'Multi-lingual ontario is very important for natural language processing.<n>Ontario maps the keyword set one language to another language.<n>Ontario can increase semantic coverage by aligning two or more domains.',\n",
       " 'This paper presents an algorithm which usesa dictionary as a network of lexical items.<n>It takes into account the whole topology of thedictionary instead of just the entry of targetwords.<n>Preliminary results are quite encour-aging considering that the method does not re-quire any prior data.',\n",
       " 'In Thai language, characters are written withoutexplicit word boundaries.<n>Longest matching is the most popular approach to Thai word segmentation.<n>We propose a two-step processto word segmentation.',\n",
       " 'We find at least six different spellings of?spaghetti? in 38 years of Japanese newspaper articles.<n>We propose an automatic method to construct JapaneseKATAKANA variant list from large corpus.',\n",
       " 'An NLP applicationcomputing over word senses is faced with extra ambiguity.<n>We use an unsupervised method to rankword senses from an inventory according to preva-lence.<n>We demonstrate that the majority ofsenses identified by the method do not occur in thesegold-standards.',\n",
       " 'We build semantic parsing based on FrameNet, treating it as a classification problem.<n>Top-five final outputs provide an F-score of 76.2% for the correct frame element identification and semantic role tagging.<n>The performance of the single best output is 61.5% F-score.',\n",
       " 'We show how to construct first-order representations from CCGs using the?-calculus.<n>We demonstrate that semantic representations can be produced for over 97% of the sentences in unseen WSJWSJ text.',\n",
       " 'We argue that integrated mod-els enable systems to calculate useful, fine-grainedutterance interpretations from radically underspec-ified semantic forms.<n>We focus in particular onvague scalar predicates like small or long.<n>We implement a theoretically-model of vagueness which is unique in treatingvague predicates as genuinely vague and genuinelycontext-sensitive.',\n",
       " 'We present an archi-tecture for a principle-based syntax-semantics in-terface for RMRS construction from shallow gram-mars.<n>We present RMRS semantics con-struction principles that can be applied to flat syn-tactic structures with various degrees of partiality.',\n",
       " 'In semantic role labeling (SRL) the goal is to group sequences of words together and classify them by using semantic labels.<n>We believe that a highly accurate extraction of this structure is vital for high performance in many NLP tasks.<n>We introduce another approach that we refer to as the relation-by-relation (R-by-R) se-mantic role labeling.',\n",
       " 'The aim of this paper is to address the recall problem by using extraction methods that are linguistically more sophisticated than surface pattern matching.<n>A small set of hand-built syntactic patterns allows usto detect relevant semantic information.',\n",
       " 'Our objective in HITIQA is to allow the user to submit exploratory, analytical questions.<n> analytical questions are often underspecified, thus casting a broad net on a space of possible answers.<n>We argue that the semantics of an analytical question is more likely to be deduced from the information that is considered relevant to the question.',\n",
       " 'The research ispart of a project to construct a fundamentalvocabulary knowledge-base of Japanese.<n>In this paper we describe the auto-matic acquisition of a thesaurus from the dic-tionary definition sentences.',\n",
       " 'One of the first roles of a semantic resource is discrimi-nating and characterizing the senses of a set of words.<n>Main semantic resources with a wide coverage that can be exploited by computers are lexico-semantic networks such as WordNet.<n>One of the solutions for solving this problem consists in automatically discovering the senses of words from corpora.',\n",
       " 'We study semantic role labeling (SRL)<n>For each verb ina sentence, the goal is to identify all constituentsthat fill a semantic role.<n>The PropBank project provides a large human-annotated corpus of verb-argument relations.',\n",
       " 'We propose a new method to answer definition questions.<n>It combines and extends the technique of Prager et al (2001, 2002), which relied on WordNet hypernyms.<n>Experiments indicate that our method clearly outperforms the techniques it builds upon in the task we considered.',\n",
       " 'We describe an opinion as a quadruple [Topic, Holder, Claim, Sentiment] in which the Holder believes a Claim about the Topic.<n>We identify just expressions of positive, negative, or neutral sentiments, together with their holders.<n>For sentences that do not express a sentiment but simply state that some sentiment(s) exist(s), return these sentences in a separate set.',\n",
       " 'We employ PropBank for the evaluation of the accu-racy of HPSG parsing.<n>By eliminating the effect of HPSG parsing, we can directly evaluate the accuracy of deep linguistic analysis.',\n",
       " 'We present the first large-scale ex-perimentation with a supervised machine learningclassification algorithm for disambiguating verbinstances to their VN classes.<n>We use rich syntacticfeatures extracted from a treebank-style parse tree,and utilize a learning algorithm capable of imposing class membership constraints.',\n",
       " 'In many Natural Language Processing (NLP)tasks we find that a large collection of manually-annotated text is used to train and test supervisedmachine learning models.<n>This paper explores how this abilityof SVD can be applied to the domain-adaptation of Word Sense Disambiguation (WSD)<n>We show that SVD and unla-beled data improve the results of two state-of-the-art WSD systems (k-NN and SVM)',\n",
       " 'The ability to detect deceptive statements in text and speech has broad applications in law en-forcement and intelligence gathering.<n>The goal of our research is to develop and implement a system for automatically identifying deceptive and truthful statements.',\n",
       " 'Noun compounds hide a remarkable depth of conceptual machinery behind a simple syntactic form, Noun-Noun.<n> compounds provide a highly compressed picture of the workings of concept combination.<n>An understanding of noun-compounds requires an understanding of how lexical concepts can be used and connected to others.',\n",
       " 'Dependency parsing aims to build the dependencyrelations between words in a sentence.<n>The experimental results showthat our approach significantly outperforms base-line system and current state of the art techniques.',\n",
       " 'Automatic sentence compression can be broadlydescribed as the task of creating a summary of a single sentence with minimal in-formation loss.<n>We present a noveltree-to-tree extraction method which ac-quires paraphrases from bilingual corpora.<n>We also develop a num-ber of loss functions suited to the abstractive com-pression task.',\n",
       " 'We explore the correlation between ROUGE and the human metrics of responsive-ness and linguistic quality.<n>There is a significant gapin responsiveness between humans and systems which is not accounted for by the ROUGE metrics.<n>We propose a new evaluation method, which we call ROSE(ROUGE Optimal Summarization Evaluation), to maximize correlation with human re-sponsiveness.',\n",
       " 'Hundreds of person-years havebeen invested in the development of wordnets forvarious languages.<n>WordNet grew from 103,445 to 235,402 semanticrelations.<n>A knowledge net or KnowNet is several times larger than WordNet.',\n",
       " 'Prepositions and determiners are known to be oneof the most frequent sources of error for L2 En-glish speakers.<n>This paper gives a brief overview of the prob-lems posed by these POS and of related work.<n>We use a corpus of t-ically correct English to train a maximum entropy-classifier on examples of correct usage.',\n",
       " 'Category induction techniques generally rely on local contexts, i.e., surrounding words, to clusterword types together.<n>Disambiguating a word?s category in context has been explored in other situations, especially POS tagging.<n>In this paper we investigate which rep-resentations are effective for category disambigua-tion.',\n",
       " 'This paper describes the current state-of-the-art in phrase-based statistical machine translation (PSMT)<n>It shows that there is progress towards integrating syntactic infor-mation with the statistical approach to reorder-ing.<n>Several approaches do deterministic reordering.These do not integrate the reordering in the PSMTsystem; instead they place it outside the systemby first reordering the source language.<n>We show that we can provide the decoder with multiple source reorderings. But instead of scoring the input word order, we score the order ofthe output.',\n",
       " 'In many languages, a concept can be expressedwith several different linguistic expressions.<n>The technology for identifying para-phrases would play an important role in aggregat-ing the wealth of uninhibited opinions about prod-ucts and services that are available on the Web.',\n",
       " 'In the past few years, there was a growing inter-est in mining opinions in the user-generated con-tent (UGC) on the Web, e.g., customer reviews, forum posts, and blogs.<n>This paper aims to solve this problem, which is useful in many ap-plications because the preferred entity is the key piece of information in a comparative opinion.',\n",
       " 'This paper reports on the integration of aunification-based semantics into a Feature-BasedLTAG for French which consists of around 6 000trees.<n>We show how this formalism can be used tosupport a compact and principled encoding of thesemantic information.',\n",
       " 'Information extraction (IE)is commonly employed to (semi-) automate such atask.c? 2008.<n>In this paper we present an approach to identifying fine-grained categories based on a method successfullyemployed in lexical recognition.',\n",
       " 'Surface realisation is the problem of producing syni-cally, morphologically, and orthographically cor-rect sentences.<n>Most general-purpose realisation systems de-ped to date transform the input into sur-face form via the application of a set of gram-mar rules.<n>Probability models have become widely used in the field of natural lan-guage generation.',\n",
       " 'In statistical machine translation, a translation rule consists of a left-hand-side (LHS) 1and a right-hand-side (RHS)<n>Transla-tion rules can be learned automatically from par-allel corpus.<n>In this paper, we propose a lexicalized approachfor rule selection for syntax-based statistical ma-chine translation.',\n",
       " 'We evaluate how im-provements in part-of-speech tag induction affects grammar induction.<n>Part-of-speech tag induction can be thought of as aclustering problem where, given a corpus of words,we aim to group word tokens into syntactic classes.',\n",
       " 'We introduce a new framework for recognizing entailment which depends on extraction of discourse commitments.<n>We show that a commitment-based arithms can provide state-of-the-art results.',\n",
       " 'The algorithmsneed to adapt to various dependency structureconstraints according to target languages.<n>Most Japanese dependency algorithms are based onbunsetsu units, which are similar concept to En-glish base phrases.<n>We propose a model that takes a focused-on pair of buns andtwo candidate heads into consideration and se-lects the better candidate head out of those two.',\n",
       " 'Discriminative models have the advantage of flexi-bility in representing features.<n>Joint S&T can achieve higher accuracy notonly on segmentation but also on POS tagging.<n>We propose word latticereranking, a strategy that reranks the pruned wordlattice outputted by a baseline classifier.',\n",
       " 'dependency-based systems learn faster than their constituent-based counterparts.<n> dependency-based systems learn faster than their constituent-based counterparts.<n>We show that dependency-based systems learn faster than their constituent-based counterparts.',\n",
       " 'This paper presents a contribution to thework on relation extraction by combining statisti-cal information with string distance measures.<n>In 2006, we propose to use a local alignment ker-nel to detect relations.',\n",
       " 'Co-ordination is fundamental to natu-ral language understanding.<n>Previous studies oncoordination disambiguation suggested that con-juncts in coordinate structures have syntactic orsemantic similarities.<n>We present a method of coordination disam-biguation without using similarities.',\n",
       " 'A Noun Phrase (np) is a referring expression if its communicative purpose is to identify anobject to a hearer.<n>This paper examines how ambiguities should dealwith structural ambiguity, focussing on ambi-guity of the form the Adj Noun1 and Noun2, also known as coordination ambiguity.',\n",
       " 'The rapid dissemination of electronic communi-cation devices has triggered the emergence of newforms of written texts.<n>These messages arecharacterised by massive and systematic devia-tions from the orthographic norm.<n>These newtypes of texts nonetheless share a lot of common-alities.',\n",
       " 'Major progress has been made on informationretrieval and on the extraction of specific rela-tions frombiomedical texts.<n>Researchers have recently begun to use deeperNLP techniques (e.g. statistical parsing) for im-c? 2008.',\n",
       " 'This work forecasts day-to-day changes in pub-lic perception of political candidates from dailynews.<n>We use features fromsyntactic dependency parses of the news and auser-defined set of market entities.<n>System receives objective news, not subjective opinions,and learns what events will impact public opinion.',\n",
       " 'The model takes 77 CPU days to compute and consumes nearly aterabyte of external storage.<n>We show howto solve the problem with a previously developed pattern matching technique.<n>Results extend previous findings and shed light on the improved performance of phrase-based models.',\n",
       " 'A computational model of natural logic characterizes valid pat-terns of inference in terms of syntactic forms re-521sembling natural language as much as possible.<n>A natural logic system can thusachieve the expressivity and precision needed tohandle a great variety of simple logical inferences.',\n",
       " 'This research has been carried out in the frame-work of a customer project for PSA PeugeotCitro?en.<n>The final goal of the project is a re-duction and terminological unification process ofPSA?s database.<n>All French entries have beentranslated to some extent into the twenty differentlanguages that are part of the customer?s portfolio.',\n",
       " 'In many studies on lexical-ized grammar, the accuracy of the pars-ing results is evaluated in terms of the accuracy of the semantic representations.<n>We use an automatic tree converter based on astochastic synchronous grammar in order to make the PTB-CFG trees from the analyses based on alexicalized grammar.',\n",
       " 'In self-training, first we train a model on the parsed data and use that model to label the unla-beled data.<n>We present andtest four hypotheses of why self-training helps inSection 4 and conclude with discussion and futurework.',\n",
       " 'Disfluency is one obstacle preventing speechrecognition systems from recog-nizing spontaneous speech.<n>This paper will describe a system which ap-plies a syntactic model of speech repair to a time.',\n",
       " 'Och (2003) introduced minimum error rate train-ing (MERT) for optimizing feature weights in machine translation (SMT) models.<n>Och?s method produces higher translationquality scores than maximizing the conditionallikelihood of a maximum entropy model.',\n",
       " 'A large number of regular patterns are observed across the sound inventories of human languages.<n>The self-organization of the consonant inven-tories emerges due to an interaction of differentforces acting upon them.<n>The basic framework for the cur-rent study develops around two such complex net-works namely, the Phoneme-Language Networkor PlaNet and its one-mode projection, the Phoneme-Phoneme Networkor PhoNet.',\n",
       " 'We train a Support Machine (SVM) using a variety of term,lexical and additional event based features to en-code each train/test instance.<n>We adopt a prob-abilistic language modeling approach that captureshow text within sentences that describe event in-stances is likely to be generated.',\n",
       " 'Pronoun resolution is the task of determining theantecedent of an anaphoric pronoun, or a pro-noun pointing back to some previously mentioned item in a text.<n>We have built a machine learning-based pronoun resolver and observed the contribu-tions of different features in the pronoun resolution process.',\n",
       " 'Abbreviations present two major challenges in natural language processing.<n> Associating abbreviationsand their full forms is useful for various applications.<n>We formalize the task of abbreviation recognition as a sequential logistic regression to combine nine features.',\n",
       " 'This paper focuses exclusively on Relation Detection and characterization (RDC) task.<n>RDC detects and classifies semantic relationships between prede-fined types of entities in the ACE corpus.<n>This paper proposes a new approach to dy-namically determine the tree span for relation extraction by exploiting constituent dependencies.',\n",
       " 'Unsupervised learning of grammar from text is of great theoretical andpractical importance.<n>It can shed light on language by humans and on the general structureof language.<n>The representation of the resulting induced gram-c? 2008 is presented.',\n",
       " 'We will apply user logs to the prob-lem of the?word mismatch? or?lexical chasm? between user queries and documents.<n>Our approach is to look at the?word mismatch?problem as a problem of translating from a source of queries into a target language of docu-ments, represented as snippets.',\n",
       " 'Most rich syntac-tic modeling approaches involve heavy pruning,pipelining or both.<n> Pipeline systems make use of simpler models with more efficient iteration to re-duce the search space of the full model.<n>We consider building straightforward classifiers that more directly address the problem of??chart cells to entries.',\n",
       " 'Event frames are linguistic specifications concerning the be-haviour of verbs and nominalised verbs.<n>For each event, semantic arguments that occur within the same sentence are marked and labelled with semantic roles.',\n",
       " 'In English, def-inite noun phrases such as the company and overtpronouns such as he are anaphors that refer to pre-ceding entities (antecedents)<n>On the other hand, in Japanese, anaphors are often omitted and theseomissions are called zero pronouns.<n>We focuson zero anaphora resolution of Japanese web cor-pus, in which anaphors are often omitted and zeroanaphora resolution plays an important role in dis-course analysis.',\n",
       " 'A Hidden-Markov-Model part-of-speech tagger computes the most probablePOS tag sequence?tN1=?t1,...,?tNfor a given word wN1.?tN1= argmaxtN1p(tN1, wN1)<n>For languages with a rich morphol-ogy such as German or Czech, more fine-grainedtagsets are often considered more appropriate.',\n",
       " 'This paper de-scribes a relatively simple model of language as afactored statistical time-series process.<n>It presentscorpus evidence that this model is sufficient to naturally occurring sentences using human-like bounds on memory.',\n",
       " 'We propose a scheme of opinion frames, which consist of two opinions that are related byvirtue of having united or opposed targets.<n> recognizing opinion frames will pro-vide more opinion information for NLP applica-tions than recognizing individual opinions alone.',\n",
       " 'Supervised ap-proaches to Word Sense Disambiguation (WSD) have been shown to perform better than unsuper-vised ones.<n>However they requireexamples of ambiguous words used in context an-notated with the appropriate sense.<n>This paper presents a novel approach to the data acquisi-tion bottleneck.<n>It is applied to a setof ambiguous terms in biomedical texts.',\n",
       " 'This paper addresses the problem of topic iden-tification for fine-grained opinion analysis of gen-eral text.<n>We provide a new, opera-tional definition of opinion topic in which the topicof an opinion depends on the context in whichits associated opinion expression occurs.<n>We present a novel method for general-purpose opin-ion topic identification that, following our new def-inition, treats the problem as an exercise in topiccoreference resolution.',\n",
       " 'subjectivity analysis focuses on de-termining whether a language unit expresses a private state,opinion or attitude.<n>This paper explores the auto-matic detection of the subjectivity of word senses.<n>We use a subset of WordNet senses that are manually an-notated for subjectivity as test set.',\n",
       " 'Shallow parsing identifies the non-recursive cores of various phrase types in text.<n>In this paper, we model latent-dynamics inshallow parsing by extending the Latent-DynamicConditional Random Fields (LDCRFs)<n>We propose an exact inference algorithm,the Best Label Path inference, to efficiently pro-duce the optimal label sequence on LDCRFs.',\n",
       " 'In many NLP applications, such as Question An-swering (QA) and Information Extraction (IE), it is crucial to recognize whether a specific targetmeaning is inferred from a text.<n>An important type of knowledge needed for inference is entailment rules.<n>In this paper we focus on unsupervised learn-ing of unary entailment rules.',\n",
       " 'In China alone as many as 300 million peo-ple are currently studying English as a second lan-guage.<n>Usage errors involving prepositionsare among the most common types seen in thewriting of non-native English speakers.<n>Errors can involve in-correct selection (?we arrived to the station?), ex-traneous use (?he went to outside?), and omission(?we are fond null beer)?',\n",
       " 'It appears that these are four dis-tinct semantic classes, requiring distinct NLP al-gorithms, but we propose a uniform approach toall four.<n>We saythat X and Y are antonyms when the pair X:Yis analogous to the pair black:white, X and Yare synonyms when they are analogous to the pairlevied:imposed, and X and Y are associated whenthey are analogous to the pair doctor:hospital.<n>The accuracy of the algorithm is competi-tive with other systems, but the strength of the al-gorithm is that it is able',\n",
       " 'We show the impact of gazetteers in attribute extraction as well as the filtering of unary class attributes.<n>Extraction is based entirely on instancesand not the class labels themselves.<n>EPI-LOG is under current development as a platform forstudying a notion of explicit self-awareness.',\n",
       " 'metaphor serves two important roles in language.<n>One mightdescribe a burqa as a suit of armor, as a shield againstprying eyes or, depending on one?s communi-cation goal, as a wearable cage.<n>Each of theseroles is a manifestation of the same underlyingmechanism for combining concepts.',\n",
       " 'State-of-the-art statistical machine translation (SMT) systems are trained on large collections of bilingual corpora for the?C 2008.<n>For some spe-cific domains, it is difficult to obtain a bilingual corpus.<n>In this paper, we address the problem of domain-specific SMT, where only domain-specific dic-tionaries and/or monolingual corpora exist.',\n",
       " 'Chinese sentences are written in form of a se-quence of Chinese characters, and words are not separated by white spaces.<n>It is difficult to define?correct? Chinese wordsegmentation (CWS) and various definitions havebeen proposed.<n>In this work, we explore the ideathat the best segmentation depends on the task, and develop a CWS method for machine translation.',\n",
       " 'We propose a new type of Chinese case structure, which is different from those presented in previous work.<n>Case structures represent what arguments can be attached to a predicate.<n>Case element remembers the bi-lexical relation between all types of head-modifier pairs.',\n",
       " 'We derive an optimal, linear-timealgorithm for decomposing an ar-bitrary word-level alignment into SCFG rules.<n>Extracting suchphrases is a common feature of state-of-the-art machine translation systems.',\n",
       " 'We compare the expressive 1097abilities of various grammars and translation models through linguistically-based synchronous parsing and a real translation platform.<n>By syn-chronous parsing, we aim to study which gram-mar can well explain translation data (i.e. transla-tional equivalence alignment) while by the real translation platform, we expect to investigate which model can achieve better translation per-formance.',\n",
       " 'In recent years much effort has been made to make use of syntactic information in statistical machine translation (MT) systems.<n>This has led to increased in-terest in the development of parallel treebanks as the source for such syntactic data.<n>We present a novel platform for the automatic generation of parallel treebanks from parallel corpora.',\n",
       " 'This paper makes a comprehensive analy-sis on some confidence-based stopping criteria, including max-confidence, min-error and overall-uncertainty.<n>It proposes a new stopping criterion, classifi-cation-change, which considers the potential ability of each unlabeled example on changing decision boundaries.<n> Experimental results show that these proposed stopping criteria work well on evaluation data sets.',\n",
       " 'Probabilistic synchronous context-free grammar(PSCFG) models define weightedrules that are automatically learned from paralleltraining data.<n> PSCFG approaches augment eachcontiguous (in source and target words) phrasepair with a left-hand-side symbol.<n>We extend our PSCFG decoder to efficiently han-dle the high order LMs typically applied in state-of-the-art phrase based translation systems.',\n",
       " 'In Section Machine Translation (MT), there is tradition of combining multiple machinetranslations.<n>In this paper we look at a specific type of MT, the output of which uses syntactic reordering as pre-processing.<n>We take such an approach as a starting point for developing comparatorifiers to indicate problematic source and target sides.',\n",
       " 'New meth-ods aim to assign fine-grained affect labels based on various psychological theories.<n>To get an accurate appraisal of opin-ion in texts, NLP systems have to go beyond pos-itive/negative classification.<n>We categorize opinion expressions using a typol-ogy of four top-level categories.',\n",
       " 'Multi-utteranceturns are the norm in natural dialogues.<n>In this paper, we define the task of incrementalor 0-lag utterance segmentation.',\n",
       " 'Analogical learning be-longs to the family of lazy learning techniques(Aha, 1997).<n>It allows to map forms belong-ing to an input space I into forms of an outputspace O.<n>We propose a data-structure and algorithms thatallow control of the balance between speed andrecall.',\n",
       " 'We propose an alternative approach to reviewsearch, one that is unsupervised and that doesnot rely on pre-existing dictionaries.<n>Itin essence simply re-ranks the top k topic-basedc? 2008.<n>The idea is based in part on the as-sumption that the initial search engine is of rel-atively high quality, so that many of the search-set documents probably are, in fact, subjective.',\n",
       " 'discourse relations between textual units are con-sidered key for the ability to interpret text.<n>Discourse relations can also be implicit, inferredby the context of the utterance and general world knowledge.<n>Penn Treebank (PDTB) is the first corpus to systematically annotated discourse relations.',\n",
       " 'We propose to use lexical resources for motion predi-cates to integrate two existing annotation schemes,SpatialML and TimeML.<n>This work is part of a larger effort to approach au-tomate such annotation and reasoning over natural documents using symbolic and machinelearning methods.',\n",
       " 'In the generation of referring expressions humans do not necessarily produce the most effective expres-sions in a computational sense.<n>The TUNA-corpus1 was developed at Aberdeen University as part of theTUNA project.<n>This corpus provides information on the referring expressionshumans produced.',\n",
       " 'This report surveys a two-dimensional classification of DP algorithms based on search space (rows) and propoga-tion ordering (columns)<n>We first study two types of search spaces (rows): the semir-ing framework (Mohri, 2002) when the underlying representation is a di-rected graph as in finite-state machines.<n>We study two types of DP algorithms (rows) with contrasting order of vis-iting nodes: the Viterbi style topological-order algorithms (Viterbi, 1967),and the Dijkstra-Knuth style best-first algorithms (Dijkstra, 1959; Knu',\n",
       " \"The emphasis has been, and continues to be, on the under- standing of well-formed inputs.<n>A requirement for any natural language interface must be that, when faced with ill-formed input, the system ei- ther intelligently guesses at a user's intent.\",\n",
       " 'semant ics provides l ist ings of mean ing components.<n>Proto type-semant ics al lows for the (pag- mal, Synagmatical, or else) iden- t i f icat ion of a term as part of a l inguist ic express ion.',\n",
       " 'The role of the lexicon cannot be adequately understood un- less the scope is widened.<n>Computer-based lexicology should rank high as a branch of computational and theoretical lin- guistics.',\n",
       " \"We present the first results of a research project aimed at developing a new approach to automatic abstracting.<n>We present an experimental system which is currently being implemented on VAX-11/780 at the University of Udine (Italy)<n>The system is conceived to accept in input a natural language text together with the user's requirements and to produce as output a summary of the specified kind.\",\n",
       " \"lexical databases are exceedingly expensive.<n>The mmmal labour involved with the coding of entries is time-consuming.<n>The control over consistency is much more efficient and also easier to maintain if both'static' and 'dynamic' information are coded within the database.\",\n",
       " 'This paper describes parallel model for natural language parsing.<n>It gives a design for its implementa- tion.<n>We base our parallel model on the Definite Definite Clause Granmars of Pereira [PerVerbeiravp] Np.',\n",
       " 'Non-SVO word order helps the reader (or listener) to construct a discourse representation.<n>It is a linguistic device used for changing the discourse focus.<n>It consists of a label, which is a (syntactic and semantic) parse 2 of the first constituent cncd, followed by a parse of the whole sentence.',\n",
       " 'I will introduce the basic notions of CUGs and demonstrate them through examples in PATR notation.<n>The paper concludes with a brief discussion of possible CUG approaches to long-distance d pendencies.',\n",
       " 'Generalized Phrase Structure Grammar, Definite Clause Grammar, Lexical Functional Grammar, Functional Unification Gammar, and others.<n>Main difficulty for the computer application of unification grammars lies in their complexity.<n>Dependency Representat ion Language (DRL) Grammar formalisms and computer languages are usually developed independently.',\n",
       " \"This paper discusses the relations between Tree Adjoin- ing Grammars (TAG's) and :Head Grammars (HG's)<n>TAG's deal with a set of elementary trees which are com- posed by means of an operation called ad jo in ing.<n>HG's are like Context-free Grammars, except for the fact that besides concatenation of strings, s t r ing wrapp ing operations are permitted.\",\n",
       " 'The theory of generalized phrase structure grammar (GPSG) has described language axiomati- cally.<n>In this paper we examine the possibility that simpler descrip- tions of the same theory can be achieved through a slightly dif- ferent, albeit still axiomatic, method.',\n",
       " 'Speech synthes is )p the der ivat ion of a cor rec t and natura l - sound ing pronunc ia t ion and in tonat ion must be prov ided for.<n>GRAPHON has boon deve loped to conver t any g iven German text in to i ts phonet ic t ranscr ip t ion (I.P.A.) enr iched by some prosod ic markers.',\n",
       " 'The paper describes a system for achieving high accuracy in the Kana-Kanji translation of non-segmented input Kana sentences.<n>A Bunsetsu is a Japanese syntactic unit which usually consists of an independent word followed by a sequence of dependent words.',\n",
       " 'XTRA is a system for a natural-language access to expert systems currently under development at the University of Saarbrficken.<n>It is intended to assist a user in filling out his/her annual withhold- ing tax adjustment form.',\n",
       " 'Linguistic literature describes numerous forms of non-singular concept that can be found in discourse.<n>Not all of these approaches could properly capture the distinction between singular and non-singular interpretation of linguis- tic descriptions.',\n",
       " 'It was generally accepted that certain words, or word sets, would not produce meaningful content identifiers.<n>It has been suggested that the ori- ginal document vocabulary be expanded by adding related or associated terms not originally present in the available text samples.<n>The performance of a manually con- structed thesaurus is compared with a content analysis system based on weighted word stems extracted from document and query texts.',\n",
       " 'This paper shows some aspects of a com- puter dictionary geared towards the natural anguage com- ponent of an expert system.<n>The dictionary is organized as a database to integrate tile various aspects of lexicographic work.',\n",
       " 'In everyday l i fe we are continously forced to accept various conclusions which we are pre- pared to reject when our knowledge increases.<n>The ability of drawing such cancellableinferences, beliefs in AI terminology, makes common sense reasoning nonmonotonic.',\n",
       " 'Partial success in generation systems is often achieved by applying linguistic knowledge to particular domains.<n>A key element is to facilitate the exploitation of generalizations while still providing for specialized uses.',\n",
       " 'A spoken message can be produced either to utter a written text (text-to-speech system), or to communi- cate orally the information given in a semantic repre- sentation (semantic-representation-to-speech system)<n>Our system has been designed for French but It could be extended to other languages.',\n",
       " 'This paper introduces a new approach to knowledge-based machine translation.<n>It integrates entity-oriented parsing and functional grammar formalisms.<n>It is particularly well suited for machine translation, where knowledge of multiple languages must be represented in a uniform manner.',\n",
       " 'Prototype capable of translating IBM computer manuals into Japanese.<n>System is based on a transfer approach in which the transfer process consists of English transformation and English-Japanese conversion.',\n",
       " 'The project SEMSYN is a Japanese/German translation system.<n>The first step is to transform the net delivered by FUJITSU into the semantic expression of our own frame representation language.<n>The second step is to decide on which way the content o f the semant ic represensen as German text.',\n",
       " \"We present a model of anaphorie dependencies based on Kamp's theory of Discourse Representation (DRT)<n>Unlike the standard DRT approach to constructing discourse representations, our model avoids any iaention of left-to-right processing.\",\n",
       " 'Tree Adjoining Grammar (TAG) was introduced by/Joshi et al 1975/ as a formalism for linguistic description.<n>A TAG comprises of two kinds of elementary trees: initial trees (a), which are complete structures, usually rooted in S, with preterminals on all their leaves, and aux- iliary trees (fl)<n>Because trees, and not categories, are considered ms the units of the grammar, TAGs have a broader domain of locality than usual phrase structure rules.',\n",
       " 'In knowledge-based natural language understanding systems the role of syntax is by no means self-evident.<n>We need an understanding of context in order to find a referent for a referring expression.<n>A more interesting fact is that we often need an understanding of context in order to get at the information which is relevant for determining the referent.',\n",
       " \"The examples in this paper have been drawn from English orthography.<n>I presented a formalism for two-level phonological (or orthographic) rules very similar to Kosken- neimi's [8]<n>There were problems with both my formalism and Koskenniemi's that could have been solved with the device of negative rule features.\",\n",
       " \"This paper explores how the linguistic theory known as Unification Categorial Grammar can be adapted to the general methodology ofMachine Translation.<n>Landsbergen's work on Isomorphic Grammars follows Monta-gue's approach of having a one-to-one correspondence b tween syntactic and semantic rules.\",\n",
       " 'We present a formal semantics for feature graphs by assigning to each feature graph G an equational ADT speci f icat ion (G), cal led fg---specification.<n>We show that the model - theoret ic consistency character izat ions for G are equivalent to the presence resp. absence of certain types of equations in this reduced normal form.',\n",
       " 'We will outline an approach to automatic translation that utilizes techniques of statistical information extraction from large data bases.<n>Our approach eschews the use of an internmdiate,nechalfism (language) that would encode the \"meaning\" of tile source text.',\n",
       " 'An MT system must be based on a linguistically justified theory of grammar.<n>GPSG has been tested for its usefulness for MT [ttauenschild/Busemann 1988]<n>The rest of the paper concentrates onGPSG and its use for processing of representations of natural anguage sentences.',\n",
       " 'Anaphora is a pervasive phenomenon in natural language communication.<n>No truly comprehensive computational approaches for anaphora resolution have been proposed.<n>This paper addresses the problem of intersentential anaphora resolution, integrating caseframe semantics.',\n",
       " \"Chomsky's Binding Theol T Binding theory defines the syntactic onstraints on coreferenee that exist between the noun phrases in a sentence.<n>The retrential possibilities of a noun phrase depend on the fimetional type of the NP and the Binding conditions for that type.\",\n",
       " \"This paper represents a theoretical adaptation of Chomsky's subset of theories to the practical results obtained from and designed for SCD parsing.<n>It is mainly designed for Romanian, this strategy proved to be effect- ive (with some peculiarities) also for English.\",\n",
       " 'A generation system can be modularized into a sequence of components.<n>The first one makes the conceptual decisions.<n>The following ones make the linguistic decisions.<n>The last one handles the morphological operations.',\n",
       " 'Current machine translation (MT) systems deal only su- perficially, if at all, with the translation of style.<n>Our focus is the development of stylistics that will provide the basis for an English and French stylis-tic tics.',\n",
       " 'The influence of the criterion \"Aktionsart\" with respect the temporal relations of temporal entities often seems to be overemphasized.<n>An approach is preseuted based on a two-step analLs of a text.',\n",
       " 'We have designed a system which can detect errors as opposed to one which can only process well-formed input.<n>The ovel feature of our system is that it is based on an integration at different levels of the knowledge of French.',\n",
       " 'Key problem of precision is correct expression of quantifier type and scope.<n>New pract ical method to express quantification i a precise and natural way.<n> portable written French generator called Hermbs to be integrated in a portable natural anguage interface.',\n",
       " 'We present methods for a primary pragmatic analysis of.<n>Jingle utterances to construct user model entries.<n>Our investigations involve problems which are not currently well understood.',\n",
       " 'Bidirectional system performs both tusks using as much shaxed knowledge as possible.<n>The main issue to beidered here is wt,at information mst be included in this lexicon and how bidirectional lexiea./knowledge should be structured.',\n",
       " 'The ambiguity and imprecision of language are the key prob- lems in building language understanding programs.<n>The idea of TRUMP is to use a combination of \"core\" knowledge about language and certain specialized knowledge to produce a complete semantic interpretation.',\n",
       " 'Systemic grammar (SG) provides an explicit representation of features that determine how a sentence functions.<n>SG has been used directly as the basis for several computer tex generation programs [Mann 82], but it has only been used indirectly for computational Indicas.',\n",
       " \"Computational linguists find thought-provoking examples of thought-provoking questions.<n> verbs show the same entail- ments as dress.<n>We show how these restore2['] to attain a broader English lexical organization.\",\n",
       " 'The aim of this study is error-correction of non-native speakers written Englh text.<n>The difference between previous approaches and this one is the method of recognizing an ill-formed sentence.',\n",
       " 'This paper reports on a prototype news analysis system which classifies and indexes news stories in real time.<n>The system receiving reports from a newswire is capable of classifying the reports and constructing an index.<n>Once a news item is classified, it can then be routed to users for whom the story is pertinent.',\n",
       " 'It is often necessary in practical situations to attempt parsing an incorrect or incomplete input.<n>It may take many forms: e.g. missing or spurious words, misspelled or misunderstood or oth-erwise unknown words [28], missing or unidentified word bound- aries [22,27]<n>Techniques limited to non-cyclic grammars cannot deal with this problem.',\n",
       " 'Error ant i c ipat ion is a key issue so far, as systems for computeP ass i s ted language learn ing are to be enhanced with d iagnost i c and exp lanatory capabi l i t ies.',\n",
       " \"We adopt the position that reading a narrative, like taking part in a eowersation, is a form of soci',d interaction.<n>We conceive of discourse segments (DSs) as continuous stretches of text corresponding to relatively monolithic pieces of internal representation.\",\n",
       " 'A real-time on-line communication system including automatic translation was realized by combining a keyboard conversation function with an English-Japanese bi-directional machine translation system implemented on a workstation.<n>Using a satellite connection, bilingual conversations were held between members of this laboratory in Japan and visitors to the 5th World Telecommunications Exhibition Telecom 87, held in Geneva from 20th to 27th October in 1987.',\n",
       " 'We argue that there are various types of polysemy, some more accessible to grammatical phenom- ena than others.<n>In particular, we look at a classification of relational nouns, paying particular attention to those exhibiting polysemous behavior.',\n",
       " 'We make a step towards a formal, integrated description of the surface structure and semantic interpretation of discourse.<n>We introduce a formalism which uses augmented context free rules for specifying discourse grammars.<n>We discuss the issue of parsing discourse in a semi-deterministic left-to-right fashion.',\n",
       " 'It is proposed to describe how we deal with agreement, syntactic and semantic errors within a German language tutoring system.<n>By using a feature grammar it is possible to describe various types of errors in a uniform framework.',\n",
       " 'The use of a single grammar for both parsing and generation is an idea.<n>In particular, parsing and genea :an be viewed as two processes engaged in by a single parameterized ;heorem prover for the logical interpretation of the formalism.',\n",
       " 'Deeodifying the vocal signal is a process that must take into account phenomena such as the eoarticulatory processes typical of continuous peech.<n>We consider two dif ferent thresholds for the l ikel ihoods: the word hypotheses with score above the higher threshold are to he / considere \"very reliable\"',\n",
       " 'We discuss the differences of dialogue translation systems and textual translation systems.<n>The important consideration is how to design feasible MT systems which can be used in actual, rather specific, translation environments.',\n",
       " 'This paper defines two gener- ation algorithms for LFGs.<n>The first permits the construction of generators which generate sentences from fimetional structures.<n>The second constructs generators which generate sentences from semantic structures.',\n",
       " 'Machine readable dictionaries (MRDs) contain knowledge about language and the world essential for tasks in natural language process- ing (NLP)<n>This paper discusses three different but related large,scale compu- tational methods for the transformation f MRDs into MTDs.<n>The products of these tools are /VlTDs which are resources useful not just for NLP tasks but for artificial intelligence (AI) gen- erally.',\n",
       " 'DLT (Distributed Language Translation) is the name of a principle, a design philosophy and a project.<n>DLT is a concentrated high-tech effort to attain a product line of language translation modules in the 1990s.',\n",
       " 'The project ran from October 1984 to December 1987.<n>The two prototypes, although very different in some aspects of their linguistic and computational pproaches, share an important and distinctive design philosophy.<n>Both are interactive, and, unlike present commercially available machine (occurrence) translation systems, both are designed for end use by a monolingual speaker of English.',\n",
       " 'Key idea of the model is topic, something being talked about in the discourse.<n>Investigation of simulated Japanese inter-terminal dialogues and their English tanslation has revealed that out of 53 occurrences of personal pronouns in English, 51 correspond to zero pronouns in Japanese text.',\n",
       " 'We show how grammar rules can be wrilten in a form which abstractes away from details of tim semantic representation.<n>We believe that the approach elps clarify the relationship between apparently disparate theories of semantic representation.',\n",
       " 'Two text processing problems rely heavily on co-occurrence patterns.<n>Co-occurrence information can assist in the \"bracketing\" of noun groups.<n>Co-occurrence r lations can provide evidence of semantic information for thematic-role assignment.',\n",
       " 'Style is selection of certain words, phrases, sentences or structures out of a set of grammatically correct words.<n>Group based means that these style markers have equal characteristics within a certain group of texts.<n>Style markers are more universal and can be 1 79 used in different languages too.',\n",
       " 'The aim of our research is to discover what kinds of knowledge can be reliably acquired through tile use.<n>We employ a more expressive lexical semantics for encoding lexical knowledge.<n>Our focus is on nominals, for both pragmatic and theoretical reasons.',\n",
       " 'Chinese is a highly flexible language, The same meaning may be represented in many different Chinese patterns.<n>This paper proposes a Government-Binding approach to deal with these highly flexible and context-sensitive languages.',\n",
       " 'The goal of the system was to synthesize speech utterances starting from a conceptual representation of the knowledge to be uttered.<n>In contrast to text-to-speech synthesis, our approach allows for easier integration of prosodic elements.',\n",
       " \"We present a generation algorithm for Uni-  Categorial Grammar [6] (, ca )<n>An interesting upshot of the strategy we propose is that it allows :['or language independent generation.\",\n",
       " 'In any system for Natural Language Processing having a dictionary, the question arises which entries are included in it.<n>I will assume the environment of a mnltilingual MT system based on a linguistic analysis and trans- fer architecture.',\n",
       " 'Unification is defined as extension of context-flee grmnms.<n>The idea arises to replace the context-free grammar in a Unification Grammar by ;t TAG.',\n",
       " \"A generation algorithm based ou the Early's method has proposed, which is capable of analyzing and generating sentences in a uniform architecture.<n>The identity semantic problem and the lexical indexing problem are some of the same problem noted in principle-based grammars.<n>I propose a bottom-up generation algorithm for principle-based grammars, which makes use of the same grammar as a constraint.\",\n",
       " 'The correct program reads a list of misspelled words from the input stream (stdin).<n>It prints a set of candidate corrections for each word on the output stream (stdout)',\n",
       " 'DMDIALOG project is a research project o develop aspeech-to-speech dialog translation system with simultaneous interpreta- tion capability.',\n",
       " \"Words and phrases that may directly mark the structure of a discourse have been termed CUE PttR.ASES, CLUE WORDS, DISCOURSE MAI:tKERS arid DISCOURSE PARTICLES [3, 4, 14, 17, 19]<n>Some exarn- pies are 'now', which marks the introduction of a new subtopic or return to a previous one.<n>We propose that such discourse and sentential uses of cue phrases can be disambiguated intonationally.\",\n",
       " 'We develop an interactive Japanese syn- tactic analysis system, JAWB, for a Japanese-to-English machine translation system.<n>It can produce very reliable.<n>,yntactie structures with the help of a human user.',\n",
       " 'We present a computa-tional model for generating explanations involving complex physical devices.<n>Our investigation suggests that the organizational strate- gies currently employed for structuring short explanations are inadequate for generating the high-level structure characteristic of that found in naturally- occurring extended explanations.',\n",
       " 'bottleneck of sentence analysis, structural ambi- guity, occurs when a sentence has several alternatives for modifier-modifiee relationships (dependencies) between words or phrases.<n>This kind of ambiguity cannot be re- solved merely by applying grammatical knowledge.<n>knowledge must be large=scale, since natural anguage semantics hould have a broad coverage of lexical items.<n>System translates phrase structures into dependency attributes that explicitly represent modifier-modifiee r lation- ships between words.',\n",
       " 'This paper describes the principles of representation and processing of syntactic knowledge in the natural anguage generation system POPEL-HOW.<n>The syntactic knowledge is represented by a unification-based head-driven grammar that is linguistically based on dependency grammar.<n>Because of the dynamic behaviour of an incremental multi-level and parallel system, syntactic structures should not only cooperate but also compete during generation.',\n",
       " 'I will show how to use such bidirec- tional unification grammars to build a completely re- versible, multi l ingual, MT system.',\n",
       " 'A PROLOG literal can be marked as either \"in\" \"out\" depending on whether they are bound at the time the literal is completed.<n>An argument X of pred ([eat, [np, [n, John] ] ) on the head literal L = pred ([eat, [n, John] ] ) is \"in\" in the head literal L = pred.<n>An argument X of pred ([eat, [np, [n, John] ',\n",
       " 'This paper describes a means tor automatically building Very Large Neural Networks (VLNNs) from definition texts in machine-readable dictionaries.<n>Our method brings together two earlier, independent approaches to word sense disambiguation.<n>The authors would like to acknowledge the contributions ofStphanc tlari6 and Gavin Huntlcy.',\n",
       " 'This paper presents a method for facilitating the development and maintenance of NLP systems by automating the discovery and acquisition of linguistic rules.<n>The method was implemented in a morphological processor called XMAS as a part of the English-Korean machine translation project KSHALT.',\n",
       " 'We present CLG(2), the latest prototype of the CLG(n) family, a formalism which was influenced by the HPSG grammar model.<n>The data types defined are variables, constants, typed feature structures, list and sets of typed feature structures.<n>The main novel feature of CLG(2) is its constraint language I., a slightly constrained form of first order predicate logic.',\n",
       " 'Two-level phonologi- cal granntmars have been written for a dozen or more languages.<n>Koskenniemi proposed using two-level phonol- ogy in computational morphological nalysis in 1983.',\n",
       " 'Extraction and representation f text meaning is a central concern of natural language application developers.<n>In this paper we describe an environment facilitating human involvement in semantic and pragmatic analysis.',\n",
       " 'This paper describes the approach taken to the.<n>fication of disjunctive feature structures in an exper- imental bottom-up shift.<n> Propane, for Prolog.',\n",
       " 'We show the feasibility of phonological knowledge base system with a uriification-based formalism.<n>The Korean syllable structure has two types: one is the type of consonant and vowel group(CV type : 71- : ga), and the other is the type of consonant, vowel and consonant group(CVC type : 7-1- : gak)',\n",
       " 'Several parsing techniques can be applied to this problem; we will be concerned here with a top-down parsing approach directly implementable through a standard Prologological interpreter.',\n",
       " 'The choice of target language realizations in ma-chine translation or in multilingual generation is con- ditioned by constraints involving different levels of linguistic description for individual anguages.<n>It is desirable to be able to keep these different levels separate.<n>The use of \"codescriptions\" hu been proposed which allows for statements about the coexistence of partial linguistic constraints.',\n",
       " 'The input to the algorithm consists of English syntax.<n>The steps of the al- gorithm retrace steps through a truth definition for the input language.<n>The algorithm is also sound and complete with re spect to English, if you agree that the input 1They acknowledge mediate[Keller 1986] as a similar solution 190 English speakers.',\n",
       " 'Definability is characterized precisely for the first time.<n>Two theories expressed in the same language, such as L = (+,*,=, ,1), can have completely different properties.<n>The expressive power of a logical theory depends on four factors.',\n",
       " 'Coordiuation is a particularly troublesome phe- nomenon to account for in theories of syntax based upon phrase structure rules.<n>Axiomatic Grammar avoids the problem of spu- rious ambiguity by avoiding the need to assign cat- egories to conjuncts.',\n",
       " 'This paper describes the NETgram, which is a neural network for word category prediction i text.<n>The NETgram is constructed by a trained Bigram network with two hidden layers, so that each bidden layer can learn the coarse-coded features of the input or output word category.',\n",
       " 'MBT2 is the second prototype system in our Memory-based Translation Project.<n>MBT2 does bi-directional mnslation between an English word-dependency tree and a Japanese word- dependency tree.',\n",
       " \"We present a varimt of TAGs, called synchronous TAGs, which characterize correstxmdences between languages.<n>The formalism's intended usage is to relate expressions of natural anguages to their asso- ciated semantics represented in a logical form language.\",\n",
       " 'This paper discusses treatments of chart pars- ing [5], euse analyses, and interpretation of Japanese noun phrases.<n>The basic inf0rence rules are prediction and completion.<n>The process of deciding which arguments are valid is carried out using defeat rules.',\n",
       " \"'Expert' system can play role of an 'intelligeut secretm-y with knowledge of the toreign language'<n>Such a system does not require the user (the writer) to prepare full source texts in advance.\",\n",
       " 'This paper focuses on the problem of incremental parsing (and to some extent interpretation)<n>In particular, how reason-maintenance techniques can be used to achieve a strong notion of incrementality.',\n",
       " 'Authors describe these extensions as \"inheritance grammars\"<n>These formalisms exhibit, to various degrees, one or several of the following properties.',\n",
       " 'The motivation for this phenomenon is given by the theory of Cognitive Grammar.<n>We design a semantic interpretation process for intportant relations in which our translation system uses semantic features.',\n",
       " \"The project suggests an alternative to the traditional model, based on auto-matic acquisition of constraints 149 fl'om a large corpus.<n>The constraints are used also to resolve syntactic am- biguities, but this will not be described here.\",\n",
       " 'Arabic grammar exists cmly in a descriptive form.<n>There is no comprehensive formal rep resentation for it so far.<n>We have used the grammatical catego- ries together with the functional roles to define the syntactic structures.',\n",
       " 'Weather forecasts (WF) are the subject of various manipulations.<n>Evolving as sets of numerical data and qual i tat ive estimations they grow into complete images of expected meteorological situations.<n>Then the WF could be translated f rom one language to another, transformed from verbal to p ictor ia l form or vice versa, etc.',\n",
       " 'A long English sentence, from the parsing point of view, is defined as a sentence which has complicated syntactic structure or has too many words in it.<n>Some factors which may contribute to the syntactic complication are words with multiple part-of-speeches, conjunctions, prepositional phrases, and commas.<n>It is not easy for a machine translation system to pick a right syntactic structure, based on syntactic knowledge and a little semantic knowledge.',\n",
       " 'HmTis (1988) has called for a \"hyper-bitext\" ool for professional translators.<n>The translator\\'s previous output would be stored as hyper- text.<n>A search for a given expression or term would display, for each occurrence in the corpus, a chunk of source language context ogett:er with the correspond- ing fragment in the target language.',\n",
       " 'It has become increasingly appar- ent that dialog and text understanding systems must account Ior connectivity relations that extend over sen- tence boundaries.<n>We make an alternative alld conlpt|tationa[ly more tractable l)rolx)sal on how it) deal wifll global text structures at the text coherei1ce level.',\n",
       " 'Ag ghfl+inalive langua.ges is a class called \"ag ghfl+inalive langua.ges\"<n>\"Ag ghfl+inalive langua.ges\" is a class called \"ag ghfl+inalive langua.ges\"',\n",
       " 'Nalks typically organize their de- scriptinns of the inflectiomd morphology of a langtmge in terms of paradigms.<n>This paper presents uch a notation, called PDL (for Description l.au- guage), which we are using as the basis of the morpho- logical andyzer for A1-STARS.',\n",
       " 'Constraim-based approach to phonology abandons complex derivational accounts of phono- logical well-formedness in favour of systems of gen- eralised constraints.<n>Main barrier to the incor- poration of phonology into constraint-based grammar frameworks has now disappeared.',\n",
       " 'The basic unit for sentence parsing and understanding is word.<n>Most of the current Chinese natural language processing systems include a processor for word iden- tification.<n>In this paper, we like to raise the ptxblems and the difficulties in identifying words and suggest the possible solutions.',\n",
       " 'The rules below provide a nat- ural deduction formulation of L, where dots above a type represent a proof of that type.<n>A convention of left association is used, Bo that, e.g. ((tnp)/pp)/np may be written snp/pp/np. tion discharged must be the rightmost (resp. leftmost) undischarged assumption in the proof.',\n",
       " 'One of the dominant paradignls ill cnrrell| coln- putat.ional l inguistics is l)rovided by unification- based grammar formalisms.<n>The work reported in this paper has.<n>[eature terms (i.e., fnrnlaliss for describing halure stru(:) do not always pro- vide a perspicuous format for representing strllc- t II re.',\n",
       " 'The present forbids finite-state approach to syntax should not be confused with regular 1. Esprit 11 project No. 2083, Structured information Management: Proceaalng and Retrieval.<n>Instead of using t rees as a means of representlng structures, we use syntactic tags associated with words, and the finite-state rules constrain choice of tags.',\n",
       " 'It is difficult to get a proper analysis of a sentence whose length is more than fifty Japanese characters.<n>For tbc successful analysis of a long Japanese sen- tence, parallel phrases and clauses, including Renyoh chuushi-ho, must be recognized correctly.',\n",
       " 'We introduce the notion of granularity, and suggest mc-graued phrase structure rules, in which morph.syutactic specifications in the teature.<n>descriptious are expallded into phrase structure rules.<n>We claim that it reduce the computational loads of unification without intractably increasing tim lmulber of rules.',\n",
       " 'We show that the psychological plausibility argument hinges on the operation of composition and not left-corner pre- diction per se.<n>In particular, we show that the psychological plausibility argument hinges on the operation of composition and not left-corner pre- diction per se.',\n",
       " 'A large volume of text, perhaps a gigabyte or more, would contain as many as 7 million sentences.<n>Average parsing time varied between 0.4 sec/sentence and 0.7 see/sentence, or between 1600 and 2600 words per minute.',\n",
       " 'The current implementation of the LTAG for English comprises over 800 sentential tree frames.<n>Each one of these frames includes a part that corre spond to the rule S --4 NP VP.<n>Any small change to some aspect of the design of the grammar could necessitate making changes to possibly hundreds of trees manually.',\n",
       " 'It is not true that (1) entails that Mary has any relationship to the set of all peaches.<n>A more sophisticated approach treats them as de- noting properties.<n>It would surely be better to express this systematic relation in the semantics of the bare plural NPs.',\n",
       " \"The term'referring expression' has been used by dif- ferent people to mean different things.<n>In this paper we define a referring expression i intentional terms: a noun phrase is considered to be a referring expres- sion if and only if its only communicative purpose is to identify an object to the hearer.\",\n",
       " \"Domain, problem-solving, and discourse actions should be captured by a model of task-oriented ialogue.<n>We develop a plan-based model of dialogue and have incorporated into it Grosz and Sidner's claim that linguistic, contextual, and world knowledge should be combined in recogniz- ing the role of an utterance in a discourse.\",\n",
       " 'Kuno said in [7] that in Japanese discourses we have to omit as many components in a sentence as possible unless we get any ambi- guity.<n>From the computational viewpoint identifying the antecedent of zero pronoun, which is the omitted part of sentence, is re- ally needed.',\n",
       " 'The uncertainty problem in linguistic phenomena is resolved on a more solid basis if a probabilistic approach is adopted.<n>Uniform proba- bilistic score function has been successfully applied in spoken language processing.<n>Discrimination-oriented adaptive learning is proposed to enhance the capability of discrimination and robustness of those proposed score function.',\n",
       " 'The problem of word-sense disambi- guation is central to text processing.<n>Several promising computational methods have been suggested.<n>Results have been based on experiments which repeatedly disambiguate a single word.',\n",
       " 'The parsing problem with a context-live gram- mar is decidable, i.e. there exists an algorithm which de- termineshex a given string is accepted or not by the grammar.<n>Most parsing algorithms are not strongly stable s, a notable x being the \"Earley deduction\" algorithm [7]<n>A class of offline-parsable grammars--is the class of DCGs whose context free skeleton is a proper context-free grammar.',\n",
       " 'We present a general framework for parallel parsing algorithms.<n>Parsing ean be seen as a process in which a set of partial parse trees is recognized.',\n",
       " 'We show that building dependency structures gives an other kind of semantics for the Lambek Calculus.<n>The correspondance proposed between these two aspects provides us with a method of parsing related to the conception of \"parsing as deduction\"',\n",
       " 'There are several reasons performance measure is required while building machine translation systems.<n>Most conventional pproaches evaluate system lxr- fonnance by human inspection and subjective measures.<n>To get significant statistics on the real system performance, a large volume of text must be provided.',\n",
       " 'Graph unification renlains the most ex- pensive part of parsing, both in t ime and space.<n>75 to 95 percent of t ime is consumed by graph copying fune- ti(ms. 1 Qusi-Destruetive (Q-D) Graph Unification.',\n",
       " 'A common need in natural language information re- trieval is to identify the information in free-form texts using a selected set of canonical terms.<n>String matching is a straightforward solution to auto- matic mapping from texts to canonical terms.<n>Human-defined synonyms or terminology thesauri have been tried as a semantic solution for the \"too little\" problem.',\n",
       " \"The Editor's Assistant is a rule-based system which assists a copy editor in massag- ing a text to conform to a house style.<n>The system is therefore an experiment in what we call inte l l igent text process ing.\",\n",
       " 'Projects that center around ex- tracting lexical information from Machine Readable Dictionaries (MRDs) have shown much success but are inherently limited.<n>For this purpose, we view a text corpus not only as a source of information, but also as a source of information about the language itis written in.<n>Instead of interpreting everything in the text in great detail, we can searcil for specific lexical relations that are expressed in well-known ways.',\n",
       " 'Japan Elec- tronic Dictionary Research Institute (El)R.) is now compiling conceptual dictionaries[5] by hand with the help of software tools.<n>IPAL has 861 entries for Jalranese verbs.',\n",
       " 'A system must determine which arguments o include in a paragraph, ow to organize them in a structured Immgraph, and how to phrase ach piece of the argument.<n>Content planning is performed using two levels of argumentative relations - evaluation functions and topoi.<n>Surface realization takes advantage of the output of the paragraph stracturer to perform lexical choice at all levels of the clause.',\n",
       " 'This paper proposes a method called Transfer-Driven Machine Translation (TDMT)<n>The integration of transfer and analysis in an example-based framework is i)roposed as a method for achieving TDMT.',\n",
       " \"Declarative Frameworks for expressing Bi-lingual Knowledge.<n> Integration of Knowledge-based Processing and Contextual Processing with the Translation pro cess.<n> Effective Exploitation of Domain/' l'xt Type- Specificity (or Sublauguageness) in MT.\",\n",
       " 'The need to generate un-ambiguous tterances is also relevant for the development of natural language generation systems.<n>In this paper we describe an approach for self-monitoring which allows to generate un- ambiguous utterances.',\n",
       " 'Lexical choice cannot be made dining text generation taking into account linguistic context.<n>A textnal element T is an attaphor with reslmct to an antecexlent A.<n>We show that correct lexicalization in context reqnires access to both the ctntcepnml relmence and the linguistic prolmrties of preceding text.',\n",
       " 'The transfer process in macbine translatiou systems is more complicated than the processes of linguistic analysis.<n>Case-based or example-based MT [4] [10] [11] is used in this paper.<n>In the similarity-driven t,unsfer system (Simlmn) we have developed, both translation examples and existing transfer knowledge are treated uniformly as trauslation pattern%.',\n",
       " 'This work first identifies a number of aspects of task-oriented dialogue along which agents can make choices.<n>It then identifies a number of recovery strategies which agents use when risky hehaviour has led to a failure in the dialogue.',\n",
       " 'This paper presents an initial model that accomplinhes these tasks for one class of argumentative dialogs.<n>Each di- alog respouses a belief that justifies or con- tradicts a belief provided earlier in the dialog.',\n",
       " 'One important problem with al most all existing linguistic resources i that the intergramma stratal mappings between, for example, strings and semantics, are anything but simple.<n>Systemic-functional grammars [4] offer significant solutions to this deficiency by imposing a higher degree of stratification.<n>In this paper we present a for realization of the tile information strata of the system and their interstratal mappiugs in terms of feature structures.',\n",
       " 'Shalt2 is a research prototype of a knowledge-based, multi-domain/multi-lingual MT system.<n>It has two predecessors, SHALT [31 (1982-90) and KBMT-89131 (1987-89), which brought us valuable lessons we re- flected in the design and implementation f Shalt2.',\n",
       " 'Large-scale research project on automated Chinese text abstraction has entered its third year.<n>Prototype known as Machine-Aided Chinese Text Abstraction System (MACTAS)',\n",
       " 'Generalized 1,R (GLR) parsing towatrds interactive speech under- standing.<n>Table constructed from the context-flee grammar ules in advance.',\n",
       " 'We convert electronic valency dictionaries for Dutch and French as coded by the PROTON project.<n>Valency characterizations can be used to discriminate different readings of a sentence during analysis.<n>The conversion was a non-trivial exercise in computational lexicography.',\n",
       " 'We have used techniques to construct a network of rialto senses autoluatically from tile Longman Dic-tionary of Coutenlporaly Falglish (LDOCE)<n>The disautbiguation algorithm presented th (Guthrie et al 1990) utilized three factors in deter- mmmg the correct gcnns sense.',\n",
       " 'We show how sophisticated and well structured adverb exicon can help NLP systems to handle adverbs.<n>Our lexicon builds on the work of several linguists.',\n",
       " 'IBM Scientific Center Heidelberg is develop- ing a large vocabulary speech recognition sys- tem for German.<n>The system needs for each word of its reference vocabulary two types of reference patterns.<n>Up to now the transcriptions were generated for each orthographic word of the reference vocabulary by an automatic procedure.',\n",
       " 'We will deal with the problem of un- known words, especially personal names.<n>Title-driven name recognition and adaptive dynamic word tbrmation are proposed.',\n",
       " \"It is widely known that the word formation mech- anism of compounding is highly productive, in Ger man as well as in English, and that efficient strategies have to bc,lcvelopcd to dcal with this linguistic phe nomenon in any kind of NI,1  system.<n>Here we show how to solve the probh:m in a satisfactory aud ade,lnatc way ((:f..<n>[,qundta 1[)!91]), we don't use a billugual corl,u,\",\n",
       " 'Interpretive Map- ping refers to the relationship between predicate conceptual structures and syntactic structures.<n>We have developed a shared hierarchical structure for lex- ical knowledge.',\n",
       " \"T rans la t ion aM is another kind of machine trans- lation.<n>A quick-retrieval bilingual corpus is also usefifl, specifically when it h,'s the flexihle (best match) retrieval- anism.<n>This paper proposes re-t r ieva l method, specifically for Japanese texts.\",\n",
       " \"In this process, tree will use many kinds of infitrma- Lion.<n>The natm'a bulguge descr ipt i tms conta in st)Ill(lll, it is vm'y illl),ort, allL to extl'itct and use tmnl.\",\n",
       " \"This paper introduces the work on Knowledge acquisition and Chinese parsing based on corpus.<n>Take out a total of 500 sentences from geography text book of middle school to form a small Chinese corpus.<n> Input analyzed corpus into the computer and form u matrix f'de for every sentence in the corpus.<n>Extract he knowledge from the matrix f'de and form a knowledge base.\",\n",
       " 'In Japanese, noun phrases are not normally marked with respect to number.<n>Japanese nouns have no equivalent to the English singular and plural forms.<n>In order to generate English correctly, it is necessary to know whether a given noun phrase is countable or uncountable.',\n",
       " \"This paper describes a specific evaluation method and its application to the KANT system, developed at CMU's Center for Machine Translation (Mitamura, et al 1991)<n> Behavioral black-box evaluations are best suited to measure different aspects of an MT system.\",\n",
       " 'EBMT is based on the idea of performing translation by imitating translation examples of similar sentences.<n>There are three key issues which pertain to example-based translation.<n>It is believed that the potential of EBMT lies on the exploitation of fragments of text snualler that sentences and the combination of such fragments to produce the translation of whole sentences.',\n",
       " \"It is essential to effectively integrate an example-based method anti source language analysis.<n>One wily to reduce tilt load of source langua!,,c analysis ix to directly apply trallSl'cr knowledge to all input siring.<n>A constiLuonl boundary parsing method using nuitorn-niatching, and shows its effeclivonoss for spoken langnago translation.\",\n",
       " \"LIDIA project aims at studying the concept of 'Personal Machine Translalion', or more precisely, I)BMT for monolingual authors.<n>We have now completed the first imlflemcutalion of it mock-up, I,I1)IA-1.\",\n",
       " \"This paper presents an algorithm for automatically extracting the discriminative f atures from a cor- pus.<n>It shows that the proposed model reduces the error rate of the top 10 error dominant words fi'om 5.71% to 4.35%.<n>It also reduces the error rate to 4.67% (18.21% error reduction rate)\",\n",
       " \"Stlpertag disalnl)iguation technilues are often used to eliminat, (or sul>sl;an- tlally reduce) the lm.rt-of-spee.<n>The ta.ggel's are all local hi the sense that they use informtion front a limited context in deciding which tag(s) to choose for each word.\",\n",
       " \"'l'he present article describes it probabillstic tagger based on a hidden Marl(or model) (Rabiner, 1990)<n>Our feature structure tagger esthnates these prob- abilities by connecting contextual probabilities of the single fealvre-wdue-pai,'s (rv-pairs) of the tags.\",\n",
       " 'We will introduce a part-of-speech (POS)-based alignment algorithm.<n>Ten Chinese-English texts are investigated to check the effectiveness of the Imstulation.',\n",
       " 'A part-of-speech tagger is a system which ically assigns the part of speech to words using con- textual information.<n>Potential applications for part-of-speech taggers exist in many areas inclnding speech recognition, speech synthesis, machine translation and information retrieval.<n>A third and rather new approach is tagging with artificial neural networks.',\n",
       " 'We present a computational mor- phology model which can handle the non-linear phenomenon of Semitic morphology.<n>To achieve this, we made all lexieal expressions n-tuple regular expressions.<n>For the latte.r cats(:, we propose, an au?iliary finite-state transduce.r into which multi-tape two-level rules can be co-replied.',\n",
       " 'It is not easy to input Japanese sentences written by optical cha.racter teal- ets (OCR) or speech recognition devices.<n>The sentences input through an OCR. or a speech recognition device usuMly contain erroneous character strings.<n>The methods are based on the idea about the relation between the types of errors and the length of a chain in which the wdnes of Markov joint probability remain small.',\n",
       " 'We show that a Japanese morphological nalyzer offers approxi- mately 95% accuracy on a statistical language model- ing technique.<n>We propose a novel search strategy for getting the N best nalysis hypotheses for the in- put sentence.',\n",
       " 'This paper is on dividing non-separated language sentences into words(morphemes) without using any grammatical information.<n>It uses the statistic information between morphenws to select best ways of segmenting sentences in non- separated languages.',\n",
       " 'The acquisition and representation of lexical knowl- edge from machine-readable dictionaries and text cor-pora have become major concerns in Lexicography/Lexi.',\n",
       " 'Wc are developing a Lexical l)atabase Management SyslcIn, NADIA, based on an inlerlingual approach.<n>We give an overview of the project, beginning with its lexical organization.<n>We present our current work: the definition and prolotyping of a specialized system for the management of acception-based MLDBs.',\n",
       " 'When vocabulary cm be found in bil ingual dictionaries, it is f reqnendy obt;ain(;d by using a l:hird language as an intermediary.',\n",
       " \"A reference network of the words in a dictionary is used to measure the distance between words.<n>A word wetor is defined its list of distances from a word to a certain word, which we call origins.<n>In our exleriments we used mi(Idle fi'equency words: the 51st to 1050th most frequent words in the refer- ence Collins English I)ictiotmry (CI';D), the distance wctors are expected to depend very weakly on the particular source dic- tionary.\",\n",
       " 'This paper describes the enhancements made to the LKB system [6] in order to support linking of lexical entries to their translation equivalents.<n>We will first describe the tlink mechanism in the LKB and then outline how some of these more complex equivalences can be represented.',\n",
       " \"A text planner for l,h,' w,rlmlizt- tion of natural deduction (ND) st, yle proofs [Gm,:Uq.<n>System EXPOUND of D. (Thesl.er [Che76] call I>e characterized as an exatnl+le of direct translatio'a: Al- though a sophisticated linearizatioii is applied on the input ND proofs, the steps are then I:ranslated loc- ally in a template driven way.\",\n",
       " 'A computational theory for ana- lyzing linguistic discourse structure and its practical procedure must be established.<n>We have developed a computational rnodel of discourse for Japanese xpository writings.<n>In our model, discourse structure is deiined,as the rhetorical structure, i.e., the compound of rhetorical relations between sen- tences in text.',\n",
       " \"Natural Language Generation, i.e., the pro- cess of building an adequate utterance for some given content, is by nature a decision making problem.<n>In Japanese, negation is specified at the end of the sentence while in English, it has to be specified ill ['rent of the finite verb.\",\n",
       " 'We propose a grammar model that combines lexical organization of grammatical knowledge with lexi- calized conlrol of the corresponding control.<n>The proposed grammar can be considered as an attempt to replace the static, global-control paradigm of natural language processing.',\n",
       " 'Natural languages exhibit significant word order (WO) variation and intricate ordering rules.<n>The vast majority of world languages lie somewhere in-between these two extremes.<n>We need general grammar formalism, capable of processing \"flexible\" WO.',\n",
       " 'intermediate architecture, in which components are integrated under a coordinator, may be written in various programming languages.<n>Managers handle the conversions between internal (server) and external (client) data formats.',\n",
       " \"We show how a finite state device can be used to represent large lexical g.ra[ri[nars.<n>The device has ah'eady proved very efliclent hi niorl/hohlgical analysis [8], that provides both hierar- chical representations and efllady hi ;t shnple and natural way.\",\n",
       " 'Principle-based grammars, such as Govern- ment-Binding (GB) theory, offer many advantages over rule-based and unification-based grammars.<n>This paper describes an efficient, principle-based, called PRIN- CIPAR.<n>It applies principles to descriptions o17 X- bar structures rather than the structures them- selves.',\n",
       " \"We build upon recent developments in the lield of linguistic grammar the- ory by assigning full procedural auton- omy to lexical units.<n>We treat lexic,'ll items as active lexieal processes commtnticating with each other by message passing.<n>We introduce a behavioral description in terms of event ype networks which rcpresent interrelations at the level of actor definitions.\",\n",
       " 'A technical lexicon consists of simple as well as complex lexical units.<n>Complex lexical units are mainly compounds, character-ized by a set of syntactic and semantic criteria.<n>The constitution of a list of technical terms from a specific domain is an important issue in Nat- urM Language Processing.',\n",
       " 'A classifier has a significant use in Thai language tbr construction of noun or verb to express quantity, determination, pronoun, etc.<n>In many existing natural anguage processing systems, tile list of available classifiers lk3r each noun is attached to a lexicon base.<n>We introduce a hierarchy of semantic class for tile induction of a classifier class when they are employed to construct with nouns which belong to the same class of meaning.',\n",
       " \"10 million words b;ttch of lw:trl.tlp coded run- ning text in ASCII format.<n>Every new batch is lh'st scanned by the EN(TI'WOI, lexi eel and rnorphological nalyser [Koskentdetni, 1!183] in filtering rhode for the purpose of detecting words not inchaled in the present lexicon.\",\n",
       " 'In the Gemini system, the domain-specific knowledge base includes a sort hi- erarchy and a set ot\" sort rules.<n>The sort rules are generally entered by a linguist, by hand, from the study of a corpus and while tuning the grammar.',\n",
       " \"This design has already shown some promise in produc- ing significmtly better performance than the base statisti-tkst and robust extraction system (Strzdkowski, 1993)<n>Advanced NLP module is inserted between the textuld input (new documeuts, user queries) and the databJse search engine (in our case, NIST's PRISE system)\",\n",
       " \"Claude E. Shannon estal)lished tile in foH.at io, the- ory in 19d8 [1].<n>Iris theory included the co,lcept tlutt  hmgnage could be a,pproximated by an n- th order Markov model by n to l)e extended t( infinity.<n>Since his proposal there were ma.ny tri- tls to ea.h:ulate n-grams (statistics of 'n c,ara.(:ter strings of a language) lbr a big\",\n",
       " 'A technique is proposed for classifying word meanings and determining relationships between words or between sentences.<n>The semantic attributes that become the key factors in analyzing the flow of sentences constitute important knowledge.<n>These semantic attributes are used in defining the method of semantic use of each verb in Japanese to English transfer pattern dictionaries.',\n",
       " 'All syntacticsel[ianl.ic.ic. and pi:ag.ag t,%ion is the following topic: interprc.nl.eccounts for 1. interprc.nl.eccounts for 1.',\n",
       " 'We will familiarity with the framework of generative lexicon theory, as out- lined in [16, 18, 1]<n>In order to help characterize the generative power of natura.l languages, it is natural to think in terms of senla.ntic systenls with increasing functional power.',\n",
       " 'This paper considers a problem with the standard approach to handling polysemy.<n>We show that a great deal of potentially useful information about a word\\'s meaning may be missed if the task involves isolating a single \"correct\" sense.<n>We describe an approach to the construction of an MRD-derived lexical database that helps overcome some of these difficulties.',\n",
       " 'Improvement of cow, rage in practical domains is one of the most important issues in the area of example- based systems.<n>It is an oi)en question how many examl)les are required for disambiguating sentences in a specific domain.<n>This paper proposes two methods for ilnprov ing the coverage of exantplebases.',\n",
       " 'Selectional constraints pecify what combinations of words are acceptable or meaningful in particular syn- tactic relations.<n>Several research groups have attempted to automate this process by collecting co-occurrence patterns from a large training corpus.<n>These patterns are then used as the source of seleetional constraints in attalyzing new text.',\n",
       " 'A text is not a mere set of unrelated sentences. Rather, sentences in a text are about the same thing and connected to each other.<n>Cohesion is a surface relationship among words iu a text and more accessible than coherence.',\n",
       " 'Polysemy can only be recognised by hunmn intuition and different linguists often identify a different number of senses in the same word.<n>We propose an clustering method which automatically reeognises polysemous words.',\n",
       " \"'FILe parsing system we introdtced 1,11 allply our grammar lbrlnalism is a sysl,enl called SAX.<n>'FILe parsing system we introdtced 1,11 allply our grammar lbrlnalism is a sysl,enl called SAX.\",\n",
       " 'In Japanese, no spaces are placed betwem, words.<n>The accuracy of their method is 73% in identify correct structures of Japanese compound nouns with average length 4.2 characters.',\n",
       " 'Over l;he last lb.w years, eonsl;raint-based grammar tbrmalisms have become the predominmt t)ar;tdigm in natural language processing uld (:oulptltal;iollal linguistics.<n>Their success stems from tim feet that I ;hey eLIl be seen as ;t ttt ioltoLoIt i ( :, highqe.vel re l ) resew- I;ation language for linguistic knowledge.',\n",
       " 'Unification lbrmMism ma.y be either un typed (DCCs, PATRII, 1,F(;) or typed (npsG).',\n",
       " \"Spontaneonsly spoken utterances differ considerably from written sentences.<n>It is not possible to analyze them syntactically and seman- tically when using a grammar for written sentences.<n>We develop a computational model called L'n-semble Model.\",\n",
       " \"In Alice's Adventures in Wonderland many of Alice's friends have names that consists of two words, for example: the March Hare, the Mock Turtle, and the Cheshire Cat.<n>The goal of this paper is to propose a statistic that measures the strength ol7 such glue between words in a sampled text.\",\n",
       " 'We present results concerning the theory and practice of classification schemes t)ased on word frequencies.<n>In an experiment the scheme was ud to classify two types of documents, and was found to work very well indeed.',\n",
       " 'Bilingnal (or parallel) texts are useful as resources of linguistic knowledge as well as in applications uch as machine translation.<n>This paper describes a unilied frame- work for bilingual text matching by combining exist- ing hand-written bilingual dictionaries and statistical techniques.',\n",
       " 'We describe a language- and domain-independent discourse module within our text underslanding system.<n>The discourse mchitecture is motiwtted by our need to port our text uuderstmlding system to diflcrent languages.',\n",
       " 'A person sometimes has to refer to an object that is not previously known to the other participant.<n>A reference of this sort is often achieved through a collaboration between the conversants.',\n",
       " \"SelIloIIC()S are c()nlhine,.[ and whal, I,:ind of i',hltiolls (c(ih,.!reiic)) they hay Vorl on I)S has ul;17nly [bclld Oll SllCll (lileSl.ions ;is;d, kin(I of kliowl('rg' should he einiloyed, and how inl))ren('e Iilty \",\n",
       " 'We describe a method for discovering coherent texts from the unstructured corpus.<n>It derives a linguistic motivation front the view that discourse consists of what we call discourse seg- ments.<n>For the semantics of a discourse segment, Nomoto and Nitta (1993) observes an inter- esting tendency that zero (elliptical) anapl,ora occur- ring within the segment do not refer across the segment boundary.',\n",
       " 'Resolving t>ronoun reference is a diifieult task that requires consideration of both linguistic and cognitive aspects of a language.<n>In this paper we introduce three effective factors in the selection of an antecedent from candi date noun phra.ses.',\n",
       " 'Anaphora resolution is a complicated problem in computational linguistics.<n>No complete theory has emerged which offers a resolution procedure with success guaranteed.<n>ANAPttORA resolution model includes modules containing different types of knowledge.',\n",
       " \"The lthetorieal Strucl;ure The(,ry (lIST) by Mann and Thompson [Manu and Thoml)SOn, 1.)87] is a t;hcory of int,er-sml,eni,ial (or inter:clausal) )'elationships in a text.\",\n",
       " \"This paper focuses on the elfects of comnm- nicative actions on the particil)ant's model of the situ- at, ion.<n>It provides a represen- tation of natural language utterances that is uniform with that used in general facilities for planning and action.\",\n",
       " 'This paper describes a new rule-based ap- proach to prepositional phrase attachment, disam- biguation.<n>A set of silnple rules is learned au- tomatically to try to prediet proper attachment based on any of a number of possible contextual giles.',\n",
       " 'A discourse slralegy is a strategy for communicaling with another agent.<n>No choice a COllVelSitliOllal i:lgelll lnllst make is whether ltl utterance sholdd include some relevml, but Olllional.',\n",
       " 'Definite clause grammars (DCGs) are one of the most widely used unification grammar for- malisms.<n>The corresponding problem for DCGs is in general an- decidable.<n>This paper proposes a simple trans- formation lbr an arbitrary OP DCG putt ing it into a form which leads to the completeness of the direct top-down interpretation.',\n",
       " \"Processing (7hincsc texts is spccifi('ally dif-ficult in its computation because liol'mally sentc.nces in Chinese texts arc rcp:rcscnt(;d as strings of Chiucse characters without spacc's tot.<n>This (;auscs a problem for Chinese machine translation> sl, a- tistical analysis of (Jhincse corpora, (lhincse informal;ion rctrieva,l, ct(:.; a.s usually these projects axe I)es on the\",\n",
       " \"Describing objects is one of several purposes for which l inguists use fe.at, ul:e structures.<n>I tailor the semantics of [KNG 1 989] to suit the typed feature structures [CAII.I'F, NTFA 1 992]<n>I then use this interpretion to define the notion of a satisfiable feature structure.\",\n",
       " \"The recognition and generation of word tbrms does not require the application of any mor- phological rules at runtime.<n>The task of building a morphological analyzer for t language such as Korean or.<n>I apanese is a much higher challenge than it is for l';uglish and French.\",\n",
       " 'We use a segmentation dictionary, in which every word is marked with its word category, to complete segmentation and initial tagging simultaneously.<n>It integrates nde-based approach with statistics-based approach in category tagging.',\n",
       " 'Recently various methods for automatically con- structing a thesaurus (hierarchically clustering words) based on corpus data have been proposed.<n>We propose a new method for automatic onstruction of thesauri based on the blinimum Description Length (MDL) Principle.<n>Our results indicate that combining an auto-matically constructed thesaurus and a hand made thesaurus widens the coverage 1 of our disambigua-tion method.',\n",
       " 'We address the problem of automatically acquir- ing case frame patterns (selectional patterns) from large corpus data.<n>In this paper, we propose a method of learn- ing dependencies between case frame slots.',\n",
       " 'ICE is an implementation of a channel-oriented, multi- architecture, multi- communication mod- ule for large, A l-systems.<n> Verbmobil is a large research project tbr automatic speech-to-speech translation.',\n",
       " 'Tim increased inl;erest in collocation ext;raetion comes from t;hu faeI; l;hal, t;hey can be used for many NLP at)plical;ions uch as machine transla- (;ion, maehilw, aids R)r t;ra.nslal,ion, dictionary con- sl;ru(:i;ion, and secon(1 language learning, t.o mmm a few.',\n",
       " \"Spanish l'arb(,l:HI)('(ch ( I ) ()S) 'l'a.g:g(r which al)l)lies and extends Ih'ill's alg(,rilJu for unSUl)crvised l('a.ug ( l lr i l l, l.q!),5) to cr(a.l;e a. set of rules (;hal, r((luce the aml)iguil.y of I'()S tags on words)\",\n",
       " \"A representative example-based method for verb sense disambiguation was proposed by Kuro- hashi and Nagao.<n>The method interprets the verb in the input by computing semantic similarity between the input and exalnples.<n>The database gives one or more case frame(s) associ- ated with tilt', verbs for each of their senses.\",\n",
       " \"The first challenge is morpho- tactic: whereas most languages construct words out of morphemes which are justd one after another, as in un-t-failing-t-ly.<n>The Arabic examples in this paper were produced using the Arab package for TEX and :I'EX by : Klaus Lagally.\",\n",
       " \"N()m I)hras(',s in Ja.pmms(' difl'(!r from l,hos( in l';n- gl ish in two ilnt)orl;mll; ways.<n>[n English, comltal)l(()); nouns can ])t; directly m()dili(!d l)y a mun(!ral: 2 dog,s.\",\n",
       " \"We address the treatment of metonymie expressions from a knowledge representation per- spe(:tive)<n>We focus in this patter on the part of the se- mantic analyser that deals with semantic ('ore- position)\",\n",
       " 'This article will exploit one of these theories, The Generative Lezicon (GL: Pustejovsky, 1995), and extend it for the treatment of French mental adjectives.',\n",
       " \"Panl'3BMT is one of the translation engines used by Pangloss.<n>PanEBMT uses essentially no knowledge about its source or target languages.<n>The corpus used by PanEBMT consists of a set of source/target sentence, pairs, and is flflly indexed on t, he source-language s ntences.\",\n",
       " \"The correct attaching point of a 1'1 ) in a sentence is determined by l,he nmnber of nodes in a pursing tree.<n>The real attaching point llulst S;'l..tist r some constraints, e.g., wrb ligatures.\",\n",
       " 'This paper deals with three kinds of proper nouns - say, Chinese personal names, transliterated personal names and organization ames.<n>To test the performance of language models, a good testing corpus is also necessary.',\n",
       " \"This article describes three techniques for producing multiscntential text.<n>The techniques are semi-automatic non- linguistic fill-in-the-blank intcrlhcing, atut(matic linguistic-and-tentphtte hybrid gerlct'ation, and human wril:ing.\",\n",
       " \"Pronunciation-by-analogy (PbA) is an influential psy- chological model of the process of reading aloud.<n>In PbA, most words are pronounced by retrieving their phonemic form from the readers' lexicon, or diction- ary.<n>The pronunciation for a 'novel' word not in the lexicon, however, is derived not by the application of abstract letter-to-sound rules hut is 'assembled'\",\n",
       " \"The paper reports on a text handling component, Two Level morphology, word structure, phrase structure, semantics and very importanly the interaction of these components.<n>The project started with a corpus investigation of 150 newspaper articles from the Ger- man 'Die ZEIT'\",\n",
       " 'The work presented in this article was developed within the Verbmobil project.<n>The application domain is spontaneous poken language in face-to-face dialogs.<n>The languages involved are English, German and Japanese.',\n",
       " 'This paper addresses the issue of word-sense ambigu- ity in extraction from machine-readable resources for the construction of large-scale knowledge sources.<n>We show that we can provide effective acquisition techniques for novel word senses using a combination of online sources.',\n",
       " 'This paper describes research done within the Sonderforschunsbereich 30 at IMS.<n>As can be seen from the example, the contextual ing not only is needed for understand- ing the text, but is a prerequisite for high quality translation.',\n",
       " 'A novel algorithm rescues 340 l() from a certain criticisins: \"l)ependency granl-Depenncy granl-Depenncy granl-Depenncy granl-Depenncy granl-Depenncy granl-Depenncy Granl-Depenncy Granl-Depenncy Granl-Depenncy Granl-Depenncy Granl-Depenncy Granl-Depenncy Granl-Depenncy Granl-Depenncy Granl-Depenncy Granl-Depenncy Granl-Depenncy Granl-De',\n",
       " 'An instructor is required not only to prescribe the ap- propriate actions to the reader, but also to pre- vent the reader from executing the inappropriate and potentially dangerous alternatives.<n>Such expressions can in- dicate actions that the agent should not perform, or manners of execution that the agent should not adopt.',\n",
       " 'I show that those hypotheses are basically supported.<n>I extend my previous analysis by also discussing the centering functions of full NPs in subject position.',\n",
       " 'A system which processes poken language must address all of the ambiguities arising when pro-cessing written language.<n>These include derived from speech disflu- encies, speech recognition errors, and the lack of clearly marked sentence boundaries.<n>This work has been carried out in the automaton of Enthusi- ast, a Spanish-to-English speech-to-speech trans- lation system.',\n",
       " 'In many cases, no surface information is available to deduce the relation.<n>We propose a model of interpretation rules which account for productive patterns of interpretation, indepen- dently of any domain.<n>Our model of interpreta- tion of nominal compounds will be used to enrich im formation retrieval in a system that is open-domaln.',\n",
       " \"The.<n>syste, n works on the I)a, sis of a set o[' st.ra.ightforwa.rd a]m.logy-lm.sed 1)tin -ciples whi(re-h ha.ve I)e(m used for a wide range of NLI)licatio,s (I)ir el.l., 1!).\",\n",
       " 'We describe a prototype completion system for English to l?ench translation.<n>It is based on simple statistical MT techniques, att(t give mea- Stlitating a minimum of interface paraphernalia beyond those of a word processor.',\n",
       " 'A system dealing with spoken language requires a quick response in order to provide smooth com- munication between humans or between a hu- man and a computer.<n>We have proposed Transfer-Driven Ma-chine Translation (TDMT) for efficient and ro- bust spoken-language translation.<n>This paper proposes TDMT using an incremen- tal strategy for achieving efficient ranslation of a lengthy input or one having a lot of structural ambiguity.',\n",
       " \"Proper names are not found in dictionaries, are very large in number, come and go every day, and appear in many alias forms.<n>This paper presents an approach to proper name recognition that uses ma-chine learning and a language independent fi'ame- work.\",\n",
       " 'We argue that Higher Order Uni-fication (HOU) provides a linguistically adequate tool for modeling the semantics of focus.<n>We show that HOU yields a transparent analysis while avoiding under- and over-generation.',\n",
       " 'We describe the current design and perfor- mance of the machine translation module of our system.<n>The analysis of spontaneous speech re-quires dealing with problenls such as speech dis- fluencies, looser notions of grammaticality and the lack of clearly marked sentence boundaries.<n>We present our most recent Spanish-to-English performance evaluation results.',\n",
       " 'This paper introduces all etficient normal tbrm for processing disjunctive constraints and an operation for compilation into this normal form.<n>The modularization algorithm presented in this paper takes existing dependent disjunctions and ions into independent groups.',\n",
       " 'Two-level formalisins based on that introduced by (Koskenniemi, 1983) (see also (Ritchie et al, 1992) and (Kaplan and Kay, 1994)) are widely used in practical NLP systems.<n>There is at least one serious rival two-level notation in existence, developed in response to practical difficulties encountered in writing large-scale mor- phological descriptions.',\n",
       " 'COMLEX Syntax is a moderately-broad-coverage English lexicon.<n>It includes 92 different subcategoriza- tion features for verbs, 14 for adjectives, and 9 for nouns.',\n",
       " \"This paper reports on research done in our group which belongs to Vcrbmobil's subproject on system architectures (TP15)<n>Our specific research areas are the construction of acoustics for spontaneous speech, investigations in the paral- lelization of parsing and to contribute to the de-velopment of a flexible architec- ture with distributed control.\",\n",
       " 'Textual forms of ellipsis and anaphora re a challenging issue for the design of text understanding systems.<n>The resolu- tion of text-level nominal (and pronominal) anaphora contributes to the construction of referentially valid text knowledge bases.<n>The solution we propose is embedded within the centering model.',\n",
       " 'We will consider a framework for par-constrained allel natural anguage parsing which summarizes the experiences we have made during the development of a concurrent, object-oriented parsing system.',\n",
       " 'Determination of semantic similarity between words is an important component of linguis- tic tasks.<n>This article describes a new method of similarity nmtehing, in herited feature based similarity matching (IFSM) which integrates these two approaches.',\n",
       " 'Centering theory claims that a discourse always has a single topic, or center.<n>In Dynamic Semantics, a discourse is viewed as a monotonic increase in information.<n>I will implement a simplified version of the centering theory in a dynamic system.',\n",
       " 'A number of studies haw> aJ.tetnpte(I to extract bilinguaJ collocations from paralM corpora.<n>The most cru- cial knowledge for MT is tnorc COmllex corres[,Oll(teltces atHI senl.et,\\'e-hwe[ orrespotldences. It seems di[[icutt I.o extend these statistical l lethods to N l\\'s o sillglc\" words.',\n",
       " \"This t)al)er present;s a method appl ical le to pars- ing a. range of cal;egorial grammu' formalisms, in pa.rl;ieulm ones Lhal; l';tll wil;hin l;he %yt>e-logieal' t;ra.dition, of which Lhe (associa.l;ive) l,mnbek cal- culus L is l;he most; familiar rcl)re.qenLal;iw; (l,am- be\",\n",
       " 'This paper argues that 11ypoth- esis A should be rejected on empirical grounds.<n>We discuss a number of Lls that have been used in IIPSG analyses of German.',\n",
       " \"I discuss ma-chine translation (MT) of English text into 2hrk- ish.<n>I argue for a more generative approach: a particular in- formation structure (IS) can be determined from contextual information.<n>I present algorithms for determining the topic and the focus, and show that we can generate con- textually appropriate word orders in '[/rkish.\",\n",
       " 'There are five principal factors in Bantu languages which contribute to ambiguous analysis of word- tbrms.<n>Nouns are grouped into more than ten marked noun classes.<n> verbs inflect stem- initially and mark the subject, object, and rela- tive referent by prefixes.<n>The majority of Bantu languages have a tone system, but rarely this is indicated in writing.<n>Various functions of word-forms are also a source of ambiguity.',\n",
       " 'In machine translation, there are many expres- sions that are difficult to be translated literally.<n>It is required to identify phrases of high frequency and patterns of expres- sions from the corpora.<n>It was not easy to identify and extract expressions ofarbitrary lengths and high frequency of appearance from very large corpora.',\n",
       " 'We propose a method to extract lexi- cal translations using two corpora which are not aligned in the source and target language.<n>Our method is proposed as the extension of the frame- work to solve the problem of choosing the trans- lation according to the context.',\n",
       " 'Two approaches can be distinguished in dialogue management: the structural approach and the intention-based approach.<n>We present the Constructive Dialogue Model as a new approach to plan system responses.',\n",
       " 'Most contemporary s stems imply strip out punctuation i input text, and do not put any marks into generated texts.<n>Several studies have already shown the potential for using punctuation within NLP.<n>It is necessary to develop a new theory of punctuation, that is suitable for compu- tational implementation.',\n",
       " 'Natural language/analyser is essential for advanced functions in document processing systems.<n>QJP is portable, fast and robust.<n>It can analyze a 100-word sentence on a PC in less than one second, while using less than half of a megabyte of memory.',\n",
       " 'A replacement expression specifies that a given symbol or a sequence of symbols hould be replaced by another one.<n>A replacement relation consists of pairs of strings that are related to one another in the manner sketched below.<n>We have incorporated the new replacement ex- pressions into our implementation of the finite-state calculus.',\n",
       " 'A sign is a structure incorporating information from all levels of linguistic analysis, such as phonology, syntax, and semantics.<n>Such a concept of linguistic description is attractive for several reasons.<n>It supports the use of common formalisms and data structures on all linguistic levels.',\n",
       " 'More than 10 million documents are accessible on World-Wide Web.<n>Each language community uses its own coding sys- tem which is optimal for internal communication.<n>This paper presents an algorithm that identi- fies the coding system and the language of a given text.',\n",
       " 'The purpose of this pa- per is to demonstrate how non-linear operations motivated by prosody can be de- scribed within this framework.<n>Morphemes are represented in braces, , and surface forms in solidi, / /.<n>In listings of gram- mars and lexica, variables begin with a capital letter.',\n",
       " 'Dependency and constituency frameworks define different syntactic structures.<n>Dependency grammars describe the structure of a sentence in terms of binary head-modifier (also called dependency) relations on the words of the sentence.',\n",
       " 'Sentences ranked by our definition as more complex are generally more difficult for humans to process than otherwise sim- ilar sentences.<n>Extrapositions, uch as heavy-NP shift and PP extractions are reduced by reducing omplexity.',\n",
       " 'MULTITALE has been developed as part of an EU project (LAPM 93-04) which has been started in 1994 and has been completed recently.<n>It distinguishes the following concept types: CC_Surgical Deed (indicating the surgical intervention), CC_Anatomy (indicating anatomical concepts), CC Pathology (indicating pathological concepts), CC Equipment (indicating the instrument), CC Combi.',\n",
       " 'ADOMIT is an algorithm for Automatic Detec- tion of OMissions in Translations.<n>ADOMIT rests on principles of geometry, and uses no linguis- tic information.',\n",
       " 'Part-of-speech (pos) taggers are programs which assign a single pos-tag to a word-token.<n>Most taggers are supplied with a word-guessing component for dealing with un- known words.',\n",
       " 'We have to have a computer assisted system tbr processing Japanese manual sentences.<n>A large number of researchers have gotten to grip with the method of understanding some types of instructionuals.',\n",
       " 'spelling correction is one of the signillcant unsolved researcil problems in computational linguistics.<n>It is impossible to apply these \"isolated word error correction\" techniques to Japanese.',\n",
       " 'In Japanese-to-English machine translation systems, it is necessary to identify case elements omitted from the original Japanese.<n>We propose a method to determine the deictic referents of Japanese zero pronouns using semantic onstraints uch as verbal semantic at- tributes and pragmatic onstraints uch as types of conjunctions and modal expressions.',\n",
       " 'We address the problem of word alignments for a bilingual corpus.<n>Key component of this approach is to make the probabilities dependent not on the absolute position of the word.<n>We present some experimental results and compare our model with the conventional model.',\n",
       " 'GIST consortium includes academic and in- dustrial partners -IRST (Trento, Italy), ITRI (Uni- versity of Brighton, Great Britain), OFAI (Vienna, Austria), Quinary (Milano, Italy), Universidade Com- plutense de Madrid (Spain)<n> expressions for automatically generated multilin- gum (English, German, Italian) instructions in the pension domain.',\n",
       " \"ZCl'O I)l'()II()llll Ctll l)(t (xmsidei'cd as a noun [)hra.se which is of an oblig- atory case and which is not (:xprossed but (:xprossed but (:xprossed but (:xprossed but (:xprossed but (:xprossed but (:xprossed but (:xprossed but (:xprossed but (:xprossed but (:xpross\",\n",
       " \"A consistent labelling problem consists of, giwm a set of variables, assigning to each variable a la- bc'l compatible with the labels of the other ones.<n>Many problems can be stated as a labelling problem: the travelling salesman problen 4 n- queens, corner and edge recognition, image smoothing, etc.<n>We will try to make a first, insight into applying relaxation labelling to avoid that natural lan- guage processing.\",\n",
       " 'Sparse data is a perennial problem when applying statistical techniques to natural anguage proces- sing.<n>One of two main ideas behind these techniques i that complex contexts can be generalized.<n>Data from more general contexts can be used to improve the probability estimates for more specific contexts.',\n",
       " 'Natural language discourse is ambiguous and open to a wide variety of in- terpretations.<n>Several approaches to underspecifica|ion axe emantic Grammar)le.<n>Parse forests/charts is a semantic grammar of a certain kind.<n>System works on parse forests and presut)toses 907 a semantic grammar of a certain kind.',\n",
       " 'cache language mode.l is a dynamic language model which ul,ilizes the partially dictated document (\"cache.\") in order to predict the next word.<n>In essence, it is based on the ol)se.rvation l;ll&(; ; wor(t whi(:h has ah\\'cady al)- 1)care(1 in a (locum(.,nt has ;m incr(;ased i)rol)ability of r(;at)ticaring.',\n",
       " 'This paper describes a new generation method that produces multiple paraphrases from a semantic input which may contain ambiguities.<n>The focus in this presentation is on generating multiple paraphrases and the ability to operate on logical forms that contain more than one semantic analysis.',\n",
       " 'hlentifying concepts in natural language text is an important intbrmation extraction task.<n>Various single- Imrpose spotters have been developed for specific types of conce.pts.<n>We take a somewht different approach to iden- tify various types of text entities.',\n",
       " 'It is widely agreed that tile process of resolving anaphors in natural anguage text is sup ported by strategies employing differ- kinds of knowledge.<n>The same holds for preferences applie, d in the antecedent selection process.',\n",
       " 'We introduce an extended thesaurus, LASA-1, which can handle structured attributes in an optimmn way.<n>We first present an algorithm called T*, which can solve the sub-problem for structured attributes.<n>Finally, we report an application of our new algorithm to verbal case frame acquisition and show its effec-lemtiveness.',\n",
       " \"English thesauruses ttch as Roger's The- saurus and WordNet [4] are.<n>Most existing the- sa.tlrttses are hand-crafted by ol.<n>The structure of thesauruses is subjec-- hive. The depth and (lensity of nodes it, (tree-llke.) thesauruses directly a:[lct tilt', calculated distances between words.<n>Viewpoints are features that distinguish a node from other nodes in the thesaurus, and are good (:lues for estimating the area to which\",\n",
       " 'Utsuro et al (1993) proposed a method for ac-quiring surface case frames of Japanese verbs from Japanese-English parallel corpora.<n> Clues to sense classification are found us- ing English verbs and case labels, as well as the sense distribution of the Japanese case element.',\n",
       " 'An abstract can be considered to be a con-cise text giving an outline of the original text.<n>The strategy for generating an abstract depends on the type of target text.',\n",
       " \"Most texts are rich in multi-word expressions that cannot be properly understood.<n>Such expressions range from idioms (to rack one's brains over sth) to phrasal verbs (to come up with)\",\n",
       " 'Dictionaries are indispensable in NLP, but the couous increase of new words and technical terms make unknown words an ongoing problem.<n>We propose a method that uses distributional analysis to extract words from a corpus and estimate the probability distribution of their usc a.s ditferent parts of speech.',\n",
       " 'World-With: Web (WWW) has b(:(:tt tit(: most phe- rtom(:na.l invention of tit(: la.st d(:ca.de in the (:t)mlnH;ing (;nvironnwnt)',\n",
       " \"It is expected t;l-lit classes of words are Mso usefiil for NI,P tasks ill such a wiy that statistics oil (:]sses ;tre used whenever stal;istics oil individua, l words il, i'e una,vaihdlle or unreli&i)le.<n>We will consider i tree representtl, ion of MI the words in t,he vocM)uhry in which the root; node l:ei)resenl;s the whole \",\n",
       " 'In summarisation, a compression mechanism could improve the con-ciseness of the generated summaries.<n>Sentence compression aims to crecationate a shorter document rather than a single document.<n>We employ our model to perform discourse-related compression throughout a whole document.',\n",
       " 'semantic roles offer an important first step to deeper text understanding.<n> FrameNet lists the surface syntacticrealizations of semantic roles.<n>We propose an answer extractionmodel which effectively incorporates FrameNet-style semantic role information.',\n",
       " 'State-of-the-art QA systems are extremely complex.<n>Answers to factoid ques-tions (e.g., Who, When, Where) are usually singlewords or short phrases.<n>In thiswork, we fix the granularity of an answer to a singlesentence.',\n",
       " 'We explore an approach to improve word alignments using multi-lingual, par-allel (or multi-parallel) corpora.<n>In particular, we aim to improve an Arabic-to-English (Ar-En) system using multi-parallel data from Spanish (Es), French (Fr), Rus-sian (Ru) and Chinese (Zh)<n>This paper gives specific recipes for using a bridge to construct a word alignment and for com-bining word alignments produced by multiple statis-tical alignment models.',\n",
       " 'This paper describes a new generative model which directly models M-to-N translational non-word alignments.<n>Details of the unsupervised training procedure are described.<n>Experi-ments show improvements in word alignment accuracy.',\n",
       " 'We present first results with anew architecture that integrates a state-of-the-art WSD model into phrase-based SMT.<n>We show that this new WSD approach not onlyproduces gains across all available Chinese-EnglishINISTT06 test sets, but also producesstatistically significant gains on the much larger Chinese-English task.',\n",
       " 'We present a text-to-text rewriting73model that scales to non-isomorphic cases.<n>We show how such a grammar can be in-duced from a parallel corpus and propose a large-margin model for the rewriting task.',\n",
       " 'Generation of Referring Colour (GRE) is a well-studied sub-task of microplanning in Natural Generation.<n>Most algorithms in this areaview GRE as a content determination problem, thatis, their emphasis is on the construction of a se-mantic representation which is eventually mappedto a linguistic realisation (i.e. a noun phrase)',\n",
       " 'This paper is concerned with the task of predict-ing whether a sentence contains a grammatical er-ror.<n>We implement n-gram-based approach which is tested on a very large test set containing four different types of error.<n>We show that combining both methods im-proves upon the individual methods.',\n",
       " 'A dependency graph of a sentence repre-sents each word and its syntactic modifier through directed arcs.<n>Data-driven approaches learn to produce de-pendency graphs for sentences solely from an anno-tated corpus.<n>There are currently two dominant models for data-driven dependency parsing.',\n",
       " 'We consider weighted dependency parsingmodels that can be used to define well-formed con-ditional distributions p(y | x), for dependencytrees y and a sentence x.<n>We propose a model most similar to the conditional random fields?of Lafferty et al(2001), which are now widely used for sequence la-beling.',\n",
       " 'This paper describes inside-outside-style algo-rithms for the case of directed spanning trees.<n>These structures are equivalent to non-projective depen-dency parses.<n>We show how to implement two popular supervised learning approaches for this task.',\n",
       " 'English words and phrases are frequently bor-rowed by other languages.<n>This is an instance of lan-guage mixing, whereby inclusions from other lan-guages appear in an otherwise monolingual text.<n>In this paper we focus on the impact of En-glish inclusions on the parsing of German text.',\n",
       " 'We propose an algorithm called LEDIR for LEarning Di-rectionality of Inference Rules.<n>Our algorithm identifies the di-rectionality of the correct ones.',\n",
       " 'One of the important factors that lead to poor search results is misspelled query terms.<n>In this paper we propose to use web search re-sults to further improve the performance of query spelling correction models.',\n",
       " 'This paper addresses the problem of automatically separating sets of news documents generated by queries containing per-sonal names into coherent partitions.<n>The approach we present here combines unsu-pervised clustering methods with robust syntactic and semantic processing.<n>The methods are effective with both, but error analyses reveal in-teresting differences between the two languages.',\n",
       " 'This paper will describe two methods of com-pressing trigram language models: HashTBO and ZipTBO.<n>HashTBO was developed for contextual spelling in Microsoft Office 2007.<n>ZipTBO is a baseline compression me-thod that is commonly used in many applications.',\n",
       " 'This paper considers parsing for morphologicallyrich languages, with Hebrew as a test case.<n>Mor-phology and syntax are two levels of linguistic de-sequence that interact.<n>We show new ways to do joint inference for this taskthat does not involve a computational blow-up.',\n",
       " 'This paper proposes a new boot-strapping approach to unsupervised POS induction.<n>It aims to improve the quality of the seed clusters by employing seed words that are both distributionally and morphologically reli-able.<n>In particular, we present a novel method for combining morphological and distributional infor-mation for seed selection.',\n",
       " 'We introduce an information extrac-tion approach to identify sentences in text that in-dicate an interaction relation between two proteins.<n>This extractenables us to make more syntax-awareabout the roles of the proteins in a sentence com-pared to the classical pattern-matching information extraction methods.',\n",
       " 'We describe a new sequence alignment model based on the averaged perceptron.<n>We show how it can be adapted to adapt to a range of prob-lems.',\n",
       " 'This paper is concerned with sentence genera-tion from Lexical-Functional Grammar (LFG) f-structures.<n>We present improve-ments in previous LFG-based generation models.<n>We also present work on utilising named entities and other multi-word units to improve generation results.',\n",
       " 'Machine translation (MT) frameworks have been developed, including rule-based transfer MT,corpus-based MT (statistical MT and example-based MT) and the hybrid, statisticalMT augmented with syntactic structures.<n>It is beneficialto design a framework that combines the decodingstrategies of multiple systems as well as their out-puts and produces better translations.',\n",
       " 'Existing RBMT systems are usually pro-vided as a black box.<n>We pro-pose a method using the existing RBMT system as a black box to produce a synthetic bilingual corpus.<n>In our experiments, the synthetic model achieves a relative improvement of 11.7% over the best RBMT system.',\n",
       " 'We focus on first-order Hid-den Markov Models (HMMs) in which the hiddenstate is interpreted as a POS tag.<n>We show that EM performs poorly when evaluated using a?1-to-1 accuracy? evalua-tion.<n>We explain this by observing that the distribu-tion of hidden states to words proposed by the EM-estimated HMMs is relatively uniform.<n>We show that a similar increase in accuracy can beachieved by reducing the number of hidden states inthe models estimated by EM.',\n",
       " 'Coordinate structures are a potential source of syn-tactic ambiguity in natural language.<n>Coordination disambiguation consists of the fol-lowing two tasks:? the detection of coordinate conjunctions,? and finding the scope of coordinate structures.<n>This paper proposes a method for integrating co-ordination by syntactic/semantic par-allelism in large-scale case frames.',\n",
       " 'We propose a new perceptron algorithm that can use non-local features along with lo-cal features.<n>We firstran the A* search only using local features to gen-erate n-best candidates.<n>We then explain our algorithm for non-local features in Section 4.',\n",
       " 'Large-scale semantic lexicons are important re-sources for many natural language processing (NLP) tasks.<n>Existing Chinese lexical re-sources are often based on language use in one particular region.<n>The current study aims at taking an existing Chinese thesaurus namely the Tongyici Cilin.',\n",
       " 'We define a standard specification to measure the quality of product reviews.<n>We then manually annotate a set of ground-truth with real world product review data conforming to the speci-fication.<n> Experimental results show that the proposed ap-proach can discriminate low-quality reviews from high-quality ones effectively.',\n",
       " 'V-measure is an entropy-based measure which ex-plicitly measures how successfully the criteria of ho-mogeneity and completeness have been satisfied.<n>We present two applications of V-measure, ondocument clustering and on pitch accent type clus-tering.',\n",
       " 'This paper presents a morphologi-cal disambiguation module for Hebrew using a sophisticated combination of classifiers.<n>Our sys-tem achieves over 91% accuracy on the full disam-biguation task, reducing the error rate of the pre-vious state of the art by 25%.',\n",
       " 'Automatic summarization was first studied almost50 years ago by Luhn (Luhn, 1958) and has contin-ued to be a steady subject of research.<n>In this paper, we focus on producing fully automated single-document extract sum-maries of newswire articles.',\n",
       " 'In contact centers, analysts try to get insights for im-proving business processes from stored customer contact data.<n> Gigabytes of customer contact recordsare produced every day in the form of audio record-ings of speech, transcripts, call summaries, email, etc.<n>This paper proposes a method to identify im-portant segments of textual data for analysis fromfull transcripts of conversations.',\n",
       " 'We use the Bloom filter to compute smoothed con-ditional n-gram probabilities on the fly.<n>The space requirements of a Bloom filter are quitespectacular, falling significantly below information-theoretic error-free lower bounds.<n>To train the filterwe hash each item in the set k times using distincthash functions h1, h2,..., hk.',\n",
       " 'The annotation of corpora has become a crucial pre-requisite for NLP utilities.<n>Active learning is based on the idea to let the learner have control over the ex-amples to be manually labeled.<n>We show that feature sets being used for trainingscan be enhanced without invalidating corpus annota-tions generated on the basis of AL.',\n",
       " 'AAC system consists of typing messages by means of symbols (words, letters or icons) where the user selects desired items.<n>Main weakness of AAC systems results from the slowness of message composition.<n>Two complementary approaches are possible to speed up communication.<n>System tries to predict the words which are likely to occur just after the end of the conversation.',\n",
       " 'We will compare a variety of training criteria for statisti-cal machine translation.<n>In particular, we are consid-ering criteria for the log-linear parameters or modelscaling factors.<n>We will show that someachieve significantly better results than the standardminimum error rate training.',\n",
       " 'A prominent phenomenon in Chinese coreferenceresolution is the prevalence of zero pronouns.<n>Our work is the first to per-form both identification and resolution of Chinese zero pronouns using a machine learning approach.',\n",
       " 'Accurately estimating the semantic distance be-tween concepts or between words in context has per-vasive applications in computational linguistics.<n>Applying algorithms for semantic dis-tance to most languages is hindered by the lack oflinguistic resources.<n>We propose anew method that allows us to compute semantic dis-tance in a possibly resource-poor language by seam-lessly combining its text with a knowledge source.',\n",
       " 'Several kinds of Natural Language Processing systems need measures of semantic relatedness for arbitrary wordpairs.<n>The central challenge of these algorithms is to compute relatedness scores for arbitrary word pairs giventhat few pairs are directly connected.<n>This paper presents the application of random walk chain theory to measuring lexical semantic re-latedness.',\n",
       " 'Semantic Role Labeling (SRL) aims to identify andlabel all the arguments for each predicate occurringin a sentence.<n>It involves identifying constituents inthe sentence that represent the predicate?s argumentsand assigning pre-specified semantic roles to them.',\n",
       " 'Coordination, along with prepositional phrase at-tachment, is a major source of syntactic ambiguity in natural language.<n>Previous work on coordinations includes (Agarwal and Boggess, 1992; Chantree et al, 2005; Kuro-?Equal contribution.hashi and Nagao, 1994; Nakov and Hearst,Okumura and Muraki, 1994; Resnik, 1999)',\n",
       " 'We use Conditional Random Fields (CRFs) for NE categorization in Wikipedia.<n>CRFs define the con-ditional probability of a state assignment given anobservation set.p(y|x) = 1Z(x)?c?C?(xc,yc)<n>We train graph-basedCRFs to obtain probabilistic models to estimate cat-egories for NEs in Wikipedia.',\n",
       " 'We use MavenRank to identify authoritative speak-ers who control the spread of ideas within a topic.<n>Speakercentrality can be thought of as a measure of relative importance or influence in the US legislative process.<n>We take advantage of the natural measures ofprestige in Senate committees that suggest that com-mittee membership is not determined at random.',\n",
       " 'The hierarchical Dirichlet process PCFG (HDP-PCFG) is a nonparametric model of syntactic tree structures based on Dirichlet processes.<n>We present an efficient variational inference algorithm for the HDP-PCFG based on a structured mean-field ap-proximation of the true posterior over parameters.<n>We develop an extension of the HDP-PCFG for grammar refinement (HDP-PCFG-GR)',\n",
       " 'Gazetteers, or entity dic-tionaries, are important for improving the perfor-mance of named entity recognition.<n>We demon-strate in this paper that category labels extracted from the first sentence of a Wikipedia article are really useful to improve theaccuracy of NER.<n>We use category labels as well as matching informa-tion as features of a CRF-based NE tagger.',\n",
       " 'The ability to identify the named entities (such as people and locations) has been established as an important task in several areas.<n>Similar named entity rec-ognition tasks have been defined, among which CoNLL (e.g., Tjong Kim Sang and De Meulder, 2003) and ACE (Doddington et al, 2004)',\n",
       " 'We propose an alternative ap-proach to information extraction (IE) that decouples the tasks of finding a rel-evant region of text and finding a desired extraction.<n>Our approach first identifies relevant re-gions of a document that describes relevant events,and then applies extraction patterns only in these rel-evant regions.<n>Our results show that this approach workswell, often outperforming the AutoSlog-TS IE sys-tem which benefits from human review.',\n",
       " 'This paper describes a syntactic reordering ap-proach for translation from Chinese to English.<n>A series of transformations is then applied to the resulting parse tree.<n>The reordering process is used to prepro-cess both the training and test data used within an statistical machine translation system.',\n",
       " 'This paper explores the generalization abil-ity of simple binarization methods like left-, right-, and head-binarization, and also their combinations.<n>Binarizing the syntax trees for syntax-based ma-chine translation is similar in spirit to generalizingparsing models via markovization.',\n",
       " 'It is unclear which of these important willbest explain human translation data, as each has ad-vantages and disadvantages.<n>A strength of phrasemodels is that they can acquire all phrase pairs con-sistent with computed word alignments.<n>An advan-tage of syntax-based models is that outputs tend tobe syntactically well-formed.',\n",
       " 'Word sense ambiguity is a major obstacle to accu-rate information extraction, summarization, and machine translation.<n>This paper adopts two strategies: max-confidence and min-error, and sug-gests a prediction solution by considering max-confidence as the upper bound and min-error as the lower bound for the stopping conditions.',\n",
       " 'query tokens are not independent, unordered symbols to be matched on a web document but rather ordered words and phrases withsyntactic relationships.<n>We propose a data-driven, machine-learned approach to query segmentation.',\n",
       " 'Many text types are inherently more or less structured, for example,classified advertisements for appartments, medical records, or logs of archaeological finds or zoologicalspecimens collected during expeditions.<n>These descriptions in turn typically consist of different seg-ments (or fields) which contain information of a spe-cific type drawn from a more or less given inven-tory.<n>In this paper we explore twoapproaches which require no or only a very smallamount of manually labelled training data.',\n",
       " 'We present a study to extract data records and attributes from the biomedical research literature.<n>This is part of an effort to develop a Knowledge Base Management System to benefit research.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_dm = pd.read_csv('aan_data_cnn_dailymail_summaries_r1.csv')\n",
    "sum_cnndm = []\n",
    "for i in cnn_dm['Summary']:\n",
    "    sum_cnndm.append(i.replace('×',','))\n",
    "sum_cnndm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare summaries\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1','rouge2', 'rougeL','rougeLsum'], use_stemmer=True)\n",
    "scores = []\n",
    "for i in range(len(sum_cnndm)):\n",
    "\n",
    "    s = scorer.score(df.Abstract[i], sum_cnndm[i][0])\n",
    "    \n",
    "    #simpler flat structure\n",
    "    x = {\n",
    "        \"rouge1:precision\":s[\"rouge1\"][0],\n",
    "        \"rouge1:recall\":s[\"rouge1\"][1],\n",
    "        \"rouge1:fmeasure\":s[\"rouge1\"][2],\n",
    "        \"rouge2:precision\":s[\"rouge2\"][0],\n",
    "        \"rouge2:recall\":s[\"rouge2\"][1],\n",
    "        \"rouge2:fmeasure\":s[\"rouge2\"][2],\n",
    "        \"rougeL:precision\":s[\"rougeL\"][0],\n",
    "        \"rougeL:recall\":s[\"rougeL\"][1],\n",
    "        \"rougeL:fmeasure\":s[\"rougeL\"][2],\n",
    "        \"rougeLsum:precision\":s[\"rougeLsum\"][0],\n",
    "        \"rougeLsum:recall\":s[\"rougeLsum\"][1],\n",
    "        \"rougeLsum:fmeasure\":s[\"rougeLsum\"][2],\n",
    "        \n",
    "    }\n",
    "    scores.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1:precision</th>\n",
       "      <th>rouge1:recall</th>\n",
       "      <th>rouge1:fmeasure</th>\n",
       "      <th>rouge2:precision</th>\n",
       "      <th>rouge2:recall</th>\n",
       "      <th>rouge2:fmeasure</th>\n",
       "      <th>rougeL:precision</th>\n",
       "      <th>rougeL:recall</th>\n",
       "      <th>rougeL:fmeasure</th>\n",
       "      <th>rougeLsum:precision</th>\n",
       "      <th>rougeLsum:recall</th>\n",
       "      <th>rougeLsum:fmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.149327</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149327</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.149327</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.003037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.356629</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.007921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356629</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.007921</td>\n",
       "      <td>0.356629</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.007921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rouge1:precision  rouge1:recall  rouge1:fmeasure  rouge2:precision  \\\n",
       "count        817.000000     817.000000       817.000000             817.0   \n",
       "mean           0.149327       0.001536         0.003037               0.0   \n",
       "std            0.356629       0.004016         0.007921               0.0   \n",
       "min            0.000000       0.000000         0.000000               0.0   \n",
       "25%            0.000000       0.000000         0.000000               0.0   \n",
       "50%            0.000000       0.000000         0.000000               0.0   \n",
       "75%            0.000000       0.000000         0.000000               0.0   \n",
       "max            1.000000       0.024390         0.047619               0.0   \n",
       "\n",
       "       rouge2:recall  rouge2:fmeasure  rougeL:precision  rougeL:recall  \\\n",
       "count          817.0            817.0        817.000000     817.000000   \n",
       "mean             0.0              0.0          0.149327       0.001536   \n",
       "std              0.0              0.0          0.356629       0.004016   \n",
       "min              0.0              0.0          0.000000       0.000000   \n",
       "25%              0.0              0.0          0.000000       0.000000   \n",
       "50%              0.0              0.0          0.000000       0.000000   \n",
       "75%              0.0              0.0          0.000000       0.000000   \n",
       "max              0.0              0.0          1.000000       0.024390   \n",
       "\n",
       "       rougeL:fmeasure  rougeLsum:precision  rougeLsum:recall  \\\n",
       "count       817.000000           817.000000        817.000000   \n",
       "mean          0.003037             0.149327          0.001536   \n",
       "std           0.007921             0.356629          0.004016   \n",
       "min           0.000000             0.000000          0.000000   \n",
       "25%           0.000000             0.000000          0.000000   \n",
       "50%           0.000000             0.000000          0.000000   \n",
       "75%           0.000000             0.000000          0.000000   \n",
       "max           0.047619             1.000000          0.024390   \n",
       "\n",
       "       rougeLsum:fmeasure  \n",
       "count          817.000000  \n",
       "mean             0.003037  \n",
       "std              0.007921  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              0.000000  \n",
       "max              0.047619  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = [\n",
    "     \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
    "]\n",
    "\n",
    "model_name = 'google/pegasus-xsum'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "summar = pd.read_csv('aan_data_xsum_summaries_r1.csv')\n",
    "summar2 = pd.read_csv('aan_data_xsum_summaries_downstream_r1.csv')\n",
    "cnn_dm = pd.read_csv('aan_data_cnn_dailymail_summaries_r1.csv')\n",
    "s1,s2,sum_cnndm = [],[],[]\n",
    "for i in cnn_dm['Summary']:\n",
    "    sum_cnndm.append(i.replace('×',','))\n",
    "for i in summar['Summary']:\n",
    "    s1.append(i.replace('×',','))\n",
    "for i in summar2['Summary']:\n",
    "    s2.append(i.replace('×',','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "11\n",
      "21\n",
      "31\n",
      "41\n",
      "51\n",
      "61\n",
      "71\n",
      "81\n",
      "91\n",
      "101\n",
      "111\n",
      "121\n",
      "131\n",
      "141\n",
      "151\n",
      "161\n",
      "171\n",
      "181\n",
      "191\n",
      "201\n",
      "211\n",
      "221\n",
      "231\n",
      "241\n",
      "251\n",
      "261\n",
      "271\n",
      "281\n",
      "291\n",
      "301\n",
      "311\n",
      "321\n",
      "331\n",
      "341\n",
      "351\n",
      "361\n",
      "371\n",
      "381\n",
      "391\n",
      "401\n",
      "411\n",
      "421\n",
      "431\n",
      "441\n",
      "451\n",
      "461\n",
      "471\n",
      "481\n",
      "491\n",
      "501\n",
      "511\n",
      "521\n",
      "531\n",
      "541\n",
      "551\n",
      "561\n",
      "571\n",
      "581\n",
      "591\n",
      "601\n",
      "611\n",
      "621\n",
      "631\n",
      "641\n",
      "651\n",
      "661\n",
      "671\n",
      "681\n",
      "691\n",
      "701\n",
      "711\n",
      "721\n",
      "731\n",
      "741\n",
      "751\n",
      "761\n",
      "771\n",
      "781\n",
      "791\n",
      "801\n",
      "811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['A parallel corpus is a collection of parallel texts offered in a serviceable form.'],\n",
       " ['The use of \"polite\" people for dialogue translation has been proposed as a way to improve the accuracy of translation systems.'],\n",
       " ['We have developed a dialogue management system for intelligent tutoring systems called Atlas.'],\n",
       " ['corpus-based techniques for paraphrasing Korean phrases and sentences into English structures.'],\n",
       " ['In this paper, we introduce a new type of information extraction system for extracting relations and events.'],\n",
       " ['Dialogue systems have been proposed as an alternative to directed dialog systems.'],\n",
       " ['The aim of this paper is to improve the performance of spoken dialogue systems.'],\n",
       " ['A formal representation language for natural language generation systems has been proposed in this paper.'],\n",
       " ['A prototype of a computer aided translation tool has been developed in our laboratory.'],\n",
       " ['The goal of this paper is to develop a machine translation system that predicts which words a human translator will type next, based on the source text under translation and some prefix of the target text that has already been typed.'],\n",
       " ['Coreference r so-lution is a pervasive discourse phenomenon causing performance impediments in current Internet Explorer systems.'],\n",
       " ['We have developed a query-selection system for information retrieval.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Sharmila Tagore looks at the role of natural language in information retrieval.'],\n",
       " ['Decision trees have been used to identify common nouns, pronouns, and various types of names.'],\n",
       " [\"Question-answering systems that allow users to pose questions of any type and in any language, without domain restrictions, remain beyond the scope of today's text-processing systems.\"],\n",
       " ['The aim of this project is to extract information about chemokines from biomedical literature.'],\n",
       " ['The aim is to investigate how corpus-based grammar compilation techniques can reduce overgeneration of spurious d ambiguity.'],\n",
       " ['The ro- bust lexicon problem is one of the most challenging natural language processing problems.'],\n",
       " ['A Markov-based part-of-speech tagger, TnT, is the most accurate and fastest.'],\n",
       " ['morphological analysis of natural anguage, a type of seaweed, has been the subject of much controversy.'],\n",
       " ['The aim of this paper is to investigate the robustness of current text extraction systems against a range of different language processing strategies.'],\n",
       " ['Tagging named entities using gazetteer lists is a complex task and high-performance systems are required in order to be practically usable.'],\n",
       " ['An Entity Indexing project has been evaluated from a single user perspective.'],\n",
       " ['Dependency relations have been found to be useful in information extraction (Culotta and Sorensen, 2004; Yangarber et al.'],\n",
       " ['A number of Natural Language Recognition systems have been proposed and tested.'],\n",
       " ['The ability to answer specific questions is a foundation for improving information-retrieval systems.'],\n",
       " ['In this paper, we investigate the use of sentence simplification systems to produce summaries from extracted sentences.'],\n",
       " ['The performance of named entity extraction systems on online text has been investigated.'],\n",
       " ['In this paper, we show how to update the representation of dialogue in a discourse management system.'],\n",
       " ['Text-to-speech systems have been around since the 1970s, but their performance has been poor.'],\n",
       " ['Pronominalisation is an area of research that has received little attention in the literature.'],\n",
       " ['LetSum Thematic is a research project in the Department of Computer Science at the University of South Korea.'],\n",
       " ['A word-for-word glossing algorithm based on the Moby Thesaurus has been proposed.'],\n",
       " ['We have developed a speech recognition component based on Human Machine Learning (HMMs).'],\n",
       " ['syntactic analysis of subordinate clauses in Japanese.'],\n",
       " ['In this paper, we show how a small treebank of only a thousand sentences can be used to develop a basic machine learning algorithm.'],\n",
       " ['The aim of our research is to improve the performance of Natural Language Processing (NLP) by incorporating addi-tional information into the learning process.'],\n",
       " ['We study the problem of grammar errors in essays written by non-native learners of English.'],\n",
       " ['corpus error detection is an important problem in corpus linguistics.'],\n",
       " ['A number of methods have been proposed for \"unification-based grammars\".'],\n",
       " ['This paper presents a new method for the generation of dependency trees on a lattice of textual corpora.'],\n",
       " ['The goal of automatic summaries is to produce summaries that are as concise and coherent as human-written abstracts.'],\n",
       " ['The acoustic features of spoken lan- guage have been the subject of a number of papers in recent years.'],\n",
       " ['This paper presents a natural language generator designed to generate news stories from the Wall Street Journal corpus.'],\n",
       " ['A spoken dialogue system that automatically adapts dia- logue strategies is presented.'],\n",
       " [\"Artificial intelligence (AI) can be used to predict problems in spoken dialogue interaction by train- ing a problematic dialogue predictor on a corpus of 4774 dialogues collected in an experimental trial of AT;T's How May I Help You (HMIHY).\"],\n",
       " ['One of the central tasks of the dialogue manager in most current spoken dialogue systems (SDSs) is error handling.'],\n",
       " ['A new approach to information extraction has been reported.'],\n",
       " ['We present a new method for assigning function tags to constituents identified by the Penn treebank.'],\n",
       " ['In our series of letters from around the world, we look at word segmentation in Japanese.'],\n",
       " ['A paper on context-free grammars has been published in the Journal of Machine Learning.'],\n",
       " ['We propose a method to acquire knowledge of alternation partic- ipation directly from corpora.'],\n",
       " ['In our series of letters from African journalists, filmmaker and columnist Ahmed Rashid looks at the role of sentence boundary disam- biguators in text processing.'],\n",
       " ['In this paper, we investigate a parsing algorithm for a class of probabilistic grammars that, in their probabilistic versions, have been widely adopted as real language models.'],\n",
       " ['The role of acknowledgments andpoliteness in human-human dialogue has been hotly debated.'],\n",
       " ['Natural language reduplication is an important problem in the study of morphology.'],\n",
       " ['A new method for converting graphemes to phoneme strings has been proposed.'],\n",
       " ['This paper presents a new approach to semantic interpretation of the verb \"to deliver\".'],\n",
       " ['This paper presents the open problems and what we have learned as did the EUFID group when they accomplished their system.'],\n",
       " ['We have developed a system for critiquing written material on points of grammar and style.'],\n",
       " ['Sentence fragments and ill-formedness have been studied in a number of areas.'],\n",
       " ['The LRC Machine Translation System uses a \"phrasal analysis\" technique to construct a \"phrasal analysis\" of ungrammatical input.'],\n",
       " ['Natural language processing techniques can be used to improve the processing of text.'],\n",
       " ['The anaphora resolution system proposed in this paper is based on the syntax-based Lucy system.'],\n",
       " ['In this talk, I will describe some of the research we are doing in the area of natural language processing.'],\n",
       " ['The problem of representing scope ambiguities in natural language understanding systems is addressed in this paper.'],\n",
       " ['Text-free grammars are increasingly being used in computer programming.'],\n",
       " ['A set of tools and grammars for creating a lexical data base representation (LDB) for lexical information, a set of tools and grammars for converting machine readable dictionary (MRD) type tapes to the LDB representation, and a Lexical Language (LQL) for specifying storage and A set of'],\n",
       " ['The purpose of this paper is to investigate the use of thesaurus information to improve information retrieval systems.'],\n",
       " ['The aim of this work is to develop a text-processing system that is easy to learn and easy to use.'],\n",
       " [\"We have received a grant from the National Institute of Standards and Technology's (NIA) National Science Foundation (NSF) to develop a new kind of query language for on-line dictionaries.\"],\n",
       " ['A natural language interface to a knowledge base has been proposed and developed over the past 30 years.'],\n",
       " ['We present CRIT, a large-scale natural language text processing system that identifies grammar and style errors in English text.'],\n",
       " ['This paper describes improvements made to current name search techniques used to access large databases of proper names.'],\n",
       " ['The aim of this paper is to provide a better foundation for parsing text by the use of simple fmitary and computational methods.'],\n",
       " ['The two-level morphology of Slocum (1988) is represented by the so-called paradigm matrix of Humor systems.'],\n",
       " ['Syntactic Ambiguity: Some of the most common types of syntactic ambiguity, including prepositional phrase and other attachment ambiguities, can be converted into constrained coreference problems (see Bear and Hobbs, 1988).'],\n",
       " ['combinatorial problems in natural language processing.'],\n",
       " ['In our previous papers we have proposed a new design paradigm for the connection of two or more pieces of pipe, one of which is a polypropylene (PP) pipe and the other a polyethylene (PE) pipe.'],\n",
       " ['Abductive inference has a long history in plan recognition, text understanding and discourse processing.'],\n",
       " ['A cross-modal presentation system for 3D images has been proposed.'],\n",
       " ['A natural language-based interface to information systems is the aim of this paper.'],\n",
       " ['A number of approaches have been proposed in the area of machine read- able dictionaries.'],\n",
       " [\"The ACQUILI'X l,exicon l)evelopment Environmen| is a large scale lexicon which can be used by Natural Language Processing (NLP) systems.\"],\n",
       " ['The relationship between word relations in computational lexicons is well known.'],\n",
       " ['The aim of this paper is to provide an overview of the current state-of-the-art in statistics-based methods for learning linguistic requirements.'],\n",
       " ['The DILEMMA-2 project aims to develop a Translational Language for medical English.'],\n",
       " ['Natural anguage processing systems can provide cost-effective solutions to business problems.'],\n",
       " ['In our last paper we looked at the design of a system that can extract information from large amounts of text.'],\n",
       " ['The problem of anaphoral resolution in machine translation systems has been reported by Nakaiwa and Ikehara, Nakaiwa and Ikehara, Nakalwa and Ikehara, Nakaiwa and Ikehara, Nakaiwa and Ikehara, Nakaiwa and Ikehara, Nakaiwa and Ikehara, Nakaiwa and Ike'],\n",
       " ['Dialogue management is an area of interest in computer science.'],\n",
       " ['We have developed a number of statistical systems for the management of telecommunications equipment.'],\n",
       " [\"In today's world of text-based information, how- ever, not all sources of text will be character coded.\"],\n",
       " ['We have been investigating the use of word shape tokens for document content identification since the 1990s.'],\n",
       " ['Syntactic analysis of English coordinate sentences is one of the most difficult problems for machine translation (MT) systems.'],\n",
       " ['Part-of-speech disambiguators have been proposed as a means of resolving ambiguity in speech.'],\n",
       " ['We train part-of-speech taggers without the need for a manually annotated corpus.'],\n",
       " ['The corpus of knowledge is one of the most important sources of information in computer science.'],\n",
       " ['In this paper, we aim to develop a system which automatically learns grammars based on parsing failures.'],\n",
       " ['Sentence boundaries have been used to improve the navigation of documents for many years.'],\n",
       " ['We present a novel approach to machine translation, which combines multiple machine translations through a Multi-Engine MT architecture.'],\n",
       " ['The aim of this paper is to design a natural anguage interface system that can deal with ill-formed utterances.'],\n",
       " ['A new knowledge-based terminological extraction method called FASTR (FAST + PATR-H) has been developed.'],\n",
       " ['Morphology-based point-of-service (POS) taggers have been proposed and tested in a number of languages.'],\n",
       " ['Itowevcr is a natural language processing system for the processing of medical discharge summaries.'],\n",
       " ['The homophone problem is one of the major problems in Japanese computer science.'],\n",
       " ['A probabilistic model for automatic text categorization has been proposed.'],\n",
       " [\"The term 'term-based information retrieval' (TREC) has been used to describe the process of retrieving documents from large databases.\"],\n",
       " ['This paper describes the development and use of the Forecast Generator (FoG) at Environment Canada.'],\n",
       " ['Part-of-speech recognition has been a promising area of research for many years.'],\n",
       " ['Sentence splitting, using mxterminator, is a difficult case even for sentence boundary systerns which are built for exactly that purpose, i.e., to decide whether a capitalized word which follows an abbreviation is attached it or whether there is a sentence boundary between them.'],\n",
       " ['A scheduling agent system is a computer program that allows a client to schedule an appointment with a scheduling agent.'],\n",
       " ['The so-called dialogue act is a set of rules that govern the exchange of information between people.'],\n",
       " ['We have been working on the constructions of rule-based full dependency grammars.'],\n",
       " ['A new approach for robust parsing of corpus analysis sentences has been proposed.'],\n",
       " ['syntactic language model is combined with statistical information using relaxation labelling.'],\n",
       " [\"syntactically annotated grammar corpora ('treebanks') for grammar induction.\"],\n",
       " [\"The relationship between natural language processing systems and text types is well known, but the notion of text 'domain' has been seen as a constraint on the applicability of the knowledge.\"],\n",
       " ['morphonological rules for word formation in Dutch'],\n",
       " ['Speech recognition is one of the major areas of research in computer science.'],\n",
       " ['The aim of this research project is to develop tools for instant understanding of English.'],\n",
       " ['In this paper we investigate the construction of Lisplike Exicons.'],\n",
       " ['Grammar checking has been an area of interest for computer scientists since the 1960s.'],\n",
       " ['IBM has announced that it is developing a grammar-checking system for computers.'],\n",
       " ['A new method for correcting spelling errors has been proposed in this paper.'],\n",
       " ['This paper is copyrighted by Educational Testing Service.'],\n",
       " ['Hidden Markov Models (HMMs) and Entropy Models (MaxEnt) have been used to train speech recognition systems.'],\n",
       " ['Information extraction ( IE) is one of the most promising areas of research in computer science.'],\n",
       " ['This paper aims to provide an overview of the state-of-the-art in table layout research.'],\n",
       " ['In our work on news summarization at Columbia University (McKeown and Radev, 1995; Radev, 1996), information is extracted from news articles (MUC, 1992; Grishman et al, 1992 and is analyzed by a generation com- ponent o produce a summary that shows'],\n",
       " ['A corpus-based NLP architecture based on the SGML language semantics is presented.'],\n",
       " ['An example of a text-based natural language processing pipeline architecture, which provides a software infrastructure on top of which heterogeneous NLP processing modules may be evaluated and refined individually, or may be combined into larger application systems.'],\n",
       " ['A TIPSTER-compliant architecture for natural language processing has been implemented in Java.'],\n",
       " ['In the early 1990s, researchers at the Massachusetts Institute of Technology (MIT) developed CogentHelp, an on-line help system.'],\n",
       " ['The generation of quantified expressions for speech-to-text systems has been a major area of research in recent years.'],\n",
       " ['The aim of this paper is to provide an overview of the best methods for finding the major topics of texts.'],\n",
       " ['Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy Fuzzy'],\n",
       " ['syntactic query/corpus parsing for information retrieval.'],\n",
       " ['The aim of our work is to build lists of web pages with descriptive names.'],\n",
       " ['The acquisition of translation lexicons is an important issue in the field of cross-lingual text retrieval.'],\n",
       " ['Soft decision-making is a key feature of the Alembic toolkit for natural language processing (NLP).'],\n",
       " ['A machine-readable subcategorization dictionary for English.'],\n",
       " ['The problem of extracting knowledge of verbs from Japanese data has been investigated in a number of papers over the years.'],\n",
       " ['The problem of word generalisation is one of the most important in the study of language.'],\n",
       " ['The problem of word-sense in natural language processing is well known, and a number of comparative studies have all reported that no method achieves significantly greater accuracy than the Naive Bayesian classifier.'],\n",
       " ['Selection restrictions are typically used to capture facts about the world that are generally, but not necessarily, true.'],\n",
       " ['The goal of statis- tical tagger is to learn and tune tags based on their semantics.'],\n",
       " ['The use of rankers to generate grammars in natural anguage is well known.'],\n",
       " ['Two machine learning models for sentence processing have been proposed.'],\n",
       " ['Shorter derivations involving fewer rules tend to have higher probabilities, ahnost regardless of the training data.'],\n",
       " ['In English, uncountable nouns cannot be modified by numerals, instead the noun nmst be embedded in a noun phrase headed by a classi- tier.'],\n",
       " ['Software engineering is a branch of computer science that deals with the design, development, and maintenance of software.'],\n",
       " ['This paper presents a new semantic disambiguator for English.'],\n",
       " ['The Prague Dependency Treebank (PDT) PDT is a corpus ( a part of the Czech Na.tional Cortms) PDT is a corpus ( a part of the Czech Na.tional Cortms) PDT is a corpus ( a part of the Czech Na.tional Cortms)'],\n",
       " ['Multiword terms are used in a wide range of contexts.'],\n",
       " ['This paper presents a new approach for word sense classification that addresses the ambiguity problems arising from Levins classification.'],\n",
       " ['This paper presents a news clustering system for extracting information from tile news stories.'],\n",
       " ['In this paper, we propose a representation model for automatic classification of unknown words in Chinese.'],\n",
       " [\"The likelihood of a word appearing in a document's history is one of the most important questions in language research.\"],\n",
       " ['We study the sense of ate-with and the sense of strawberries-with.'],\n",
       " ['In our series of letters from leading scientists, we look at the use of natural language processing (NLP) and artificial intelligence (AI) for the extraction of biological named entities (NEs).'],\n",
       " ['This paper presents a novel system for resolving anaphors in a corpus of English.'],\n",
       " ['In this article, we present a new learning system which uses theory refinement in order to learn non-reeursive noun phrases (also called base norm t)hrases and non-recursive verbal 1)hrases.'],\n",
       " [\"An al3pl'oacll to a spec views an dorctmlcnt as a mixture of wee-like strttctre, expressed througll balanced labelled parentheses (tim lags), and of sul:face, expressed llu'ough free lexi interspersed\"],\n",
       " ['The aim of this paper is to develop a text mining tool for the extraction of answers from texts.'],\n",
       " ['The aim of this paper is to explore the use of semantic features in discourse processing.'],\n",
       " ['Pronominalization is a major problem in the development of natural language generation algorithms.'],\n",
       " ['A new method for measuring the representativeness of a term is one of the most important issues in language research.'],\n",
       " ['The art of statistical parsing is one of the most important areas of research in machine learning.'],\n",
       " ['This paper presents a new method for transforming left-recursive grammars into right-recursive grammars.'],\n",
       " ['This paper is concerned with the relationship between spoken language parsing and multimodal systems in which multimodal integration strategies are specified declaratively in a unification-based grammar formalism.'],\n",
       " ['Multimodal interfaces for mobile devices are a major challenge.'],\n",
       " ['Transliteration of a name, for the purpose of this work, is defined as its transcription in a different language, preserving the phonetics in a different orthography.'],\n",
       " ['Thesauri asaurus is an important part of the corpus of a language.'],\n",
       " ['dependency analysis is one of the most important areas of research in machine learning.'],\n",
       " ['The aim of this paper is to develop an automatic translit- eration system for Korean technical documents.'],\n",
       " [\"A context-fl'ee language is a language that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar that includes a grammar\"],\n",
       " ['A case frame dictionary is a dictionary that describes the case structure of verbs in a language.'],\n",
       " ['We show how one can associate one single structure, which we call hypertag, and which contains the same information as a set of supertags.'],\n",
       " ['Texts with noisy remaining contexts are a major problem for machine learning.'],\n",
       " ['In this paper, we present a new class of semantics, ambiguit ies - ambiguities.'],\n",
       " ['This paper proposes a method to manage speech recognition errors using confidence measures.'],\n",
       " ['A system to automatically generate instructional texts in the languages of Eastern Europe has been proposed as part of the Drafter project.'],\n",
       " ['We propose a method to identify and discard sentences that contain no or few signature terms.'],\n",
       " ['The development of ecient dialogue systems is a major challenge.'],\n",
       " ['The acquisition of new knowledge from textual documents is a basic step in the automated acquisition of knowledge.'],\n",
       " ['Multiword translation units (MWTUs) can be used to map words between two languages.'],\n",
       " ['In my previous papers I have shown how to implement standard parsing algorithms directly in a constraint system.'],\n",
       " ['In this paper, we investigate the use of wordbased language in speech recognition.'],\n",
       " ['We have proposed a Monte Carlo approach to retrieve parses licensed by a grmnmar.'],\n",
       " ['Conjuncts/disjuncts are one of the most complex forms of sentence construction.'],\n",
       " ['This paper presents a new system for learning the problem of tagging.'],\n",
       " ['It is widely acknowledged that human translators can benefit from a wide range of applications in computational linguistics, including Machine Translation (Carl and Way, 2003).'],\n",
       " ['We study the problem of generating correct grammars in type logical grmnmars.'],\n",
       " ['A syntax-based model for machine translation has been proposed to address the following problems:'],\n",
       " ['The aim of this paper is to describe the formal theory of document structure that we have developed as part of the ICONOCLAST system.'],\n",
       " ['A Verb Class can be used to classify ambiguous text.'],\n",
       " ['A probabilistic probabilistic translation system based on Verbmobil is presented.'],\n",
       " ['We present a new dependency model for the segmentation of DNA sequences into nuclei.'],\n",
       " ['This paper deals with the automatic acquisition of subcategorization frames for verbs in English.'],\n",
       " ['In this paper, we introduce a variable context length model for Japanese named entity identification task and perform better results.'],\n",
       " [\"The verb seman(;ic) (Levlass of l&h, icle Names coni, a verbs like lmlloo'n, bicycle, ca.'n, oe, skate, ski which agree in (;they prol)erties (1)-(4)ehaviour XI\"],\n",
       " [\"The dependency structure of words in a language is usually represented by the relationship between phrasal units called 'bunsetsu'.\"],\n",
       " ['In this paper, we present three methods for dependency analysis of natural lan- guage sentences.'],\n",
       " ['The UNL project of network-oriented multilinguat communication has proposed a standard for encoding the meaning of natural language utterances as semantic hypergraphs intended to be used as pivots in information and communication systems.'],\n",
       " ['An automatic word-extraction algorithm for the Thai language has been proposed.'],\n",
       " ['The aim of this paper is to describe the current state-of-the-art in text classification.'],\n",
       " ['verbs can be classi- lied according to the diathesis aJterna.'],\n",
       " ['This paper presents a new approach to word-breaking in sentence analysis.'],\n",
       " ['Speech to speech machine translation (SMT) is one of the most promising areas of research in machine learning.'],\n",
       " ['The goal of machine translation is tile translation of a text given in some source language into tar- gel: language.'],\n",
       " ['We show how word order can be used to generate surface text in a natural order.'],\n",
       " ['Reading a document can be a stressful experience, especially if the information is spread across multiple sentences and paragraphs.'],\n",
       " ['The metonymy of lnetonylny is defined as: In this paper, we investigate the metonymy of lnetonylny in a corpus of Japanese words.'],\n",
       " ['Machine translation using corpus-based ap- proaches is one of the major challenges in machine learning.'],\n",
       " ['A word normally would be pronominal is often not, as in this example:'],\n",
       " ['We have proposed a method for automatically extracting translation pairs between words in English and Japanese.'],\n",
       " ['A number of studies are related to the work we presented, most specifically work on parallel-text based information projection for parsing (Hwa et al.'],\n",
       " ['In this paper, we present a multi-stage a.rchitecture of the summa.rization system I)IMM which can deal with spo- ken di,dogues in English and Spa.nish.'],\n",
       " ['verb lexicons are an important part of natural language research.'],\n",
       " ['A machine translation system based on an example-based machine translation architecture has been developed at the University of Tokyo.'],\n",
       " ['A context-free grmnmar is a grammar rule with a context-free feature structure.'],\n",
       " ['A graph description language should be close to traditional linguistic de-scriptions languages.'],\n",
       " ['Text pairs in colnparable corpus can be useful for corpus-based CLIR approaches when we use them as training data instead of a parallel corpus.'],\n",
       " ['Extracts from books are often difficult to read.'],\n",
       " ['The translation of natural language from one language to another is one of the most challenging tasks in computer science.'],\n",
       " ['The goal of the translation process in statistical machine translation can l)e fornmlated as tbl- lows: A source language string.'],\n",
       " ['In this paper we will describe extensions to tile Hidden-Markov alignment model froln (Vogel et al, 1.996) and compare tlmse to Models 1 - 4 of (Brown et al, 1993).'],\n",
       " ['The IR.EX project aims to create a common platform for the research and development of IR and IE technologies.'],\n",
       " ['The corpus of words can be used to generate a hierarchical machine translation (T) system that automatically derives a hierarchical T from a corpus of words.'],\n",
       " ['The aim of this paper is to present a new approach to the development of translation models and translation lexica.'],\n",
       " ['The translation of base noun phrases is a major problem in computer science.'],\n",
       " ['The use of relation/head/dependents in large-scale language-processing tasks has been discussed in previous papers.'],\n",
       " ['The linguistic significance of sound correspondences between languages is well-known.'],\n",
       " ['The goal of this paper is to improve the performance of speech-to-text systems.'],\n",
       " ['We propose a maximum entropy named entity recognition system, where is the sequence of named-entity tags assigned to the words in the sentence.'],\n",
       " ['This paper presents an in-depth study of answer reranking for definition questions in the Question Answering Challenge (NTCIR).'],\n",
       " ['A text processing system for Bulgarian has been developed and tested in this paper.'],\n",
       " ['The study of topics in texts is one of the most important areas of research in linguistics.'],\n",
       " ['Sentences are one of the most challenging problems in machine learning.'],\n",
       " ['verbs and their underlying argu-ments.'],\n",
       " ['Question Answering has emerged as a key area in natural language processing (NLP) to apply question parsing, information extraction, and language generation techniques.'],\n",
       " ['unknown word extraction is a branch of linguistics which deals with the problem of word identification.'],\n",
       " ['This paper presents two methods for de-coding English-to-Japanese translation, where English takes the structure that places emphasis at the beginning of a sentence, hence prefers left-to-right de-coding.'],\n",
       " ['The use of zeros in second language learning has received little attention in the literature.'],\n",
       " ['Several researchers have explored automatically learning the countability of English nouns.'],\n",
       " ['Support Vector Machines (SVMs) are robust even when the number of features is large.'],\n",
       " ['We have proposed a paraphrasing ap-proach in which the utterances are automati-cally paraphrased prior to transfer.'],\n",
       " ['Two new methods for unsupervised word-sense translation have been proposed in this paper.'],\n",
       " ['We present a rich semantics network based on a differential analysis.'],\n",
       " ['Text generation from corpus data is an important technique used for applications like machine translation, sum-marization, and human/computer dialogue.'],\n",
       " ['The translation of electronic documents is increasingly being carried out in parallel with the translation of paper documents.'],\n",
       " ['Cross-lingual information extraction is an area of interest in machine learning.'],\n",
       " ['This paper presents a NLP system which integrates a linguistic PartofSpeech PoS tagger and chunker as opposed to datadriven as a preprocessing module of a broadunicationbased grammar of Spanish.'],\n",
       " ['A new model for the analysis of English sentences based on the unification-based grammar is presented.'],\n",
       " ['The resolution of anaphoric expressions is a major problem in natural language processing.'],\n",
       " ['In this paper, we consider a new approach of employing a multi-agent framework to tackle the Chinese named entity recognition problem.'],\n",
       " ['We study the classification of named entities in Korean.'],\n",
       " ['Phonetic input method requires little training because Chinese are taught to write the corresponding syllable of each Chinese character in primary school.'],\n",
       " ['The aim of our research is to develop methods for automatically augmenting a thesaurus with new lexical items.'],\n",
       " ['The prosodic structure of a sentence can be modelled using ProL, a language for constructing sentences.'],\n",
       " ['We have shown that N-gram language models can predict the clustering of German words in a training corpus.'],\n",
       " ['A machine system that automatically converts English words into Korean words has been developed by Oh and Choi (2002).'],\n",
       " ['We present a new method for error detection in corpus-based systems.'],\n",
       " ['The properties of Property Grammars have been proposed as a possible solution to the problem of text-to-speech systems.'],\n",
       " ['The aim of this paper is to develop a new type of word recognition system, Word Sense Disambiguation (WSD).'],\n",
       " ['We have developed a concept discovery algorithm for hand-built lexicons.'],\n",
       " ['A corpus-based machine learning method for word search has been proposed.'],\n",
       " ['The law of word tokens in a corpus was discovered by Zipf (1949) for word tokens in a corpus states that if f is the frequency of a word in the corpus and r is the rank, then: rkf = (1) where k is a constant for the corpus.'],\n",
       " ['A case frame dictionary is a dictionary that contains case information about an expression.'],\n",
       " ['A term co-occurring with another word co-occurring with another word co-occurring with another word co-occurring with another word co-occurring with another word co-occurring with another word co-occurring with another word co-occurring with another word co-occurring with another word co-occurring with another word'],\n",
       " ['The goal of this work is to mini-mize the human effort needed when adapting a pars-ing model to a new domain.'],\n",
       " ['Fine-grained classification of named entities is fundamental for improving accuracy and reducing the amount of training data in many natural language tasks.'],\n",
       " ['The goal of this project is to develop a unified probabilistic model of verb ar-gument structure alternation behavior.'],\n",
       " ['dependency parsing of large-scale spoken dialoguecorpus has been proposed in this paper.'],\n",
       " ['The goal of this paper is to investigate how different components of a natural language system can be made to work together, whether they can easily be ported to other domains, and whether they can be inte-grated in a real-time dialog system.'],\n",
       " ['The Japanese writing system consists of the three orthographies of hiragana, katakana and kanji.'],\n",
       " ['A word sense classifier is used to identify difficult verbs.'],\n",
       " ['The aim of this paper is to improve word coreference systems by clustering nouns to derivesemantic classes.'],\n",
       " ['The Penn Chinese Treebank project aims to create a segmented Chinese corpus annotated with POS tags and syntactic brackets.'],\n",
       " ['This paper is a follow-up to Roth and Yih (2002), who developed a novel probabilistic framework for recognizing entities and relations together.'],\n",
       " ['The aim of this paper is to address the problem of dialogue management of information retrieval systems.'],\n",
       " ['The XTAG Project aims at the development of natural resources based on Tree Adjoining Gram-mars.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Farai Sevenzo looks at the challenges of identifying disease names.'],\n",
       " ['The goal of this research is to improve the predictive power of speech recognizers.'],\n",
       " ['Re paraphrasing is a well-established technique for improving information retrieval (IR).'],\n",
       " ['We have proposed a new machine translation model that is more similar to the human translation model than other MT systems.'],\n",
       " ['Information extraction is one of the most challenging problems in machine learning.'],\n",
       " ['The extraction of bilingual lexicons from non-parallel but comparable corpora has been studied by a number of researchers.'],\n",
       " ['A dictionary is a collection of thousands of words that can be searched and stored in a database.'],\n",
       " ['In this paper, an opinion on the detection of abbreviations in a corpus is presented.'],\n",
       " ['In our series of letters from African journalists, film-maker, and columnist Ahmedou Ould-Abdallah looks at some of the linguistic ob-stacles faced by machine translation (MT) systems.'],\n",
       " ['The Chinese Concept Dictionary (CCD) is a WordNet-like Chinese lexicon, which carries the main relations defined in WordNet with more or less updates to reflect the reality of contemporary Chinese.'],\n",
       " ['The aim of this paper is to investigate the accuracy of speech recognition systems developed for corpus-based processing of spoken language.'],\n",
       " ['The aim of this study is to show how a general bilingual dictionary can be used as a spatio-temporal translator (SWT) for medical texts.'],\n",
       " ['We have developed an AI system for metaphor interpretation that employs reasoning within the terms of the source domain using various sources of information including world and linguistic knowledge.'],\n",
       " ['Phoneme corre-spondences are closely related to crosslinguistic phoneme correspondences.'],\n",
       " ['The retrieval of typed feature structures is an area of interest in machine learning.'],\n",
       " ['dependency analysis of sentences is one of the most important tasks in machine learning.'],\n",
       " ['Markov models have been used in many applications, such as word sense tagging and chunking, in supervised, semisupervised, and in unsupervised settings (Banko and Moore, 2004; Goldwater and Griffiths, 2007; Johnson, 2007; Zhou, 2004).'],\n",
       " ['The aim of this work is to improve the quality of word-aligned bilingual corpora.'],\n",
       " ['We study the syntactic structure of the Rhetorical Supplement to the Discourse (RST-DT).'],\n",
       " ['A new type-inheritance grammar that combines the structure of the English fragment in Sag and Wa-sow with the structure of the English fragment in HPSG has been used for a variety of tasks, such as wide-coverage parsing and sentence realization.'],\n",
       " ['Dependency parsing is a branch of machine learning that deals with the problem of determining the relationship between words in a sentence.'],\n",
       " ['The context-free grammar is an important tool in the study of language.'],\n",
       " ['A new al-gorithm for learning regular languages.'],\n",
       " ['Machine translation (MT) is a branch of computer science that aims to improve the performance of human translators.'],\n",
       " ['expressions of point of view in newswire andnarrative text.'],\n",
       " ['The aim of this paper is to develop a system to query the GEOQUERY corpus of spoken language.'],\n",
       " ['A language model-ing approach, called factored language models, has been developed.'],\n",
       " ['A new architecture for parsing treebanks has been described in this paper.'],\n",
       " ['The Generalized ID/LP grammar formalism was developed to serve as a processing backbone for linearization-HPSG grammars, separating the declaration of the constituent structure from the declaration of word order domains.'],\n",
       " ['The syntax-semantics interface is one of the most important areas of research in computer science.'],\n",
       " ['In this paper, we decompose the source-channel ap-proach to statistical machine translation into two knowledges: the lan-guage model and thetranslation model Pr(eI1).'],\n",
       " ['In our series of letters from African journalists, novelist and writer Saul Bellow looks at word alignment.'],\n",
       " ['Word-aligned bilingual corpora provide im-portant knowledge for many natural languageprocessing tasks.'],\n",
       " ['Sluicing in corpus dialogue is one of the most important problems in discourse analysis.'],\n",
       " ['Distributional similarity measures have been used to extract meaning from speech.'],\n",
       " ['In this paper, we study word dependency analysis of English sen-tences without phrase labels.'],\n",
       " ['The parsing of man-ually constructed grammars is a major problem in machine learning.'],\n",
       " ['Ex-act parsing with large scale lexicalized gram-mars: a new formalism Fabs for ex-act parsing with large scale lexicalized gram-mars.'],\n",
       " ['This paper presents a new approach to the problem of machine translation.'],\n",
       " ['The accuracy of machine translation (MT) depends on the quality of the translation.'],\n",
       " ['A discourseparser that can extract a better discourse from a text has been proposed and tested.'],\n",
       " ['Paraphrasing is one of the most common problems in machine learning.'],\n",
       " ['We present a novel methodology to create a semantically annotated corpus by exploiting information contained in an already annotated corpus, using word alignment as a bridge.'],\n",
       " ['The aim of this work is to improve the accuracy and speed of deep parsing systems.'],\n",
       " ['Natural language processing is one of the most important areas of research in computer science.'],\n",
       " ['The use of language models in statistical machine translation has been explored in a number of papers.'],\n",
       " ['A number of syntactically motivated ap-proaches to statistical machine translation have been presented in this paper.'],\n",
       " ['In our corpus of newspaper commentaries, we found that 35% of the coherence relations aresignalled by a connective.'],\n",
       " ['It is well known that the summation of sentences is not adequate when dealing with complex questions whose answers are expressed by long and articulated sentences or even paragraphs.'],\n",
       " ['unknown words are difficult to identify in morphological analysis of non-segmented language.'],\n",
       " ['The aim of this paper is to improve word segmentation methods in Chinese and Japanese.'],\n",
       " ['We present a new method for producing concept-based representations for natural language data.'],\n",
       " ['Machine translation methods for sentiment analysis have been reported in the past.'],\n",
       " ['The performance of machine translation can be affected by a number of factors, including the quality of the translation, the complexity of the text, and the number of words used.'],\n",
       " ['Text summarization is one of the major problems in computer science.'],\n",
       " ['We focus on the problem of implicit entity recall ( IE ) by introducing a new approach to this problem.'],\n",
       " ['First, we describe a method for unsupervised training of tag sequence and lexical probabilities in a closed-class lexicon.'],\n",
       " ['In this paper, we use stylistic features suggested in the literature to identify the authors of text messages.'],\n",
       " ['This paper presents a novel probabilistic translation lexicon based on web anchor texts and their linking structure.'],\n",
       " ['A machine translation model is trained with a word-aligned parallel corpus where the source language side consists of dependency trees.'],\n",
       " ['Text-to-speech translation is one of the most important areas of research in machine learning.'],\n",
       " ['A corpus of Japanese term descriptions extracted from the World Wide Web.'],\n",
       " ['The goal of our research is to develop a model that handles all ordering phenomena in a unified and elegant way across typologically diverse languages.'],\n",
       " ['Cross language information retrieval is increasingly relevant as network-based re-sources become commonplace.'],\n",
       " ['In this paper, we propose a new type of Chinese case structure, which is different from those presented in previous work.'],\n",
       " ['The goal of sentence compression is to reduce the number of words in a sentence by learning the correspondences between long and short sentences in a supervised manner, typically using a rich feature space induced from parse trees.'],\n",
       " ['Sentence ordering is a major problem in the study of text structure.'],\n",
       " ['We develop a system for automatically generating summaries of conversational speech.'],\n",
       " ['The discovery of semantic relations from large corpuses of text has been a major challenge for many years.'],\n",
       " ['The word sense disambiguation system (WSD) has been proposed as an alternative to the traditional word sense system.'],\n",
       " ['Transliterated words are useful for cross-language information retrieval.'],\n",
       " ['Opinion mining is a branch of computer science that deals with the analysis of customer feedback.'],\n",
       " ['corpus-specific Named Entity recognition is a major problem in machine learning.'],\n",
       " ['Cross-lingual information extraction is an emerging area of research in machine learning.'],\n",
       " ['We present work on the detection of interrogative questions and their answers in email threads.'],\n",
       " ['The aim of this paper is to investigate the use of sentence clustering to reduce the complexity of human summaries.'],\n",
       " ['The acquisition of selectional preferences for verbs is one of the most challenging NLP tasks.'],\n",
       " ['We have previously proposed methods to map FrameNets into bilingual BiFrameNets (Fung and Chen 2004).'],\n",
       " ['In this paper, I will focus on the use of ranking methods to select the most use-ful items from an all too often overwhelming list of candidates.'],\n",
       " ['The NewsExplorer is a web-based tool for gathering and analysing news.'],\n",
       " ['The aim of this paper is to investigate the appropriateness of data for the task of text classification (van Halteren and Oostdijk, 2004; van Halteren and Oostdijk, 2004; van We will focus on the appropriateness of the data in the light of a specific application or research goal).'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmedou Ould-Abdallah considers expres-sions in natural language.'],\n",
       " ['Distributional similarity measures have been proposed for use in Natural Language Processing (NLP).'],\n",
       " ['The search distance for frequent words is a fundamental problem in Natural Language Processing.'],\n",
       " ['Sentence-aligned parallel corpus is an important resource for machine translation.'],\n",
       " ['The search for a new language has become increasingly important.'],\n",
       " ['We investigate tree-structured translation models that automatically align tree fragments in a fast and consistent fashion, and which requires no knowledge of the language pair.'],\n",
       " ['adjectives are often classified as either basic or event adjectives.'],\n",
       " ['This paper explores the applicability ofPageRank to semantic networks, and show that suchgraph-based ranking algorithms can be successfully used in language processing applications.'],\n",
       " ['The goal of this paper is to provide an overview of the state-of-the-art knowledge domains.'],\n",
       " ['This paper presents a new approach to the problem of finding the right sense in a corpus of words by using dictionaries as network of lexical items or senses.'],\n",
       " ['The problem of word segmentation in Thai language has been widely discussed in the literature.'],\n",
       " ['The corpus of loan words is an important area of research in machine learning.'],\n",
       " ['The evaluation of word senses is one of the most challenging areas of computer science.'],\n",
       " ['Machine learning systems need to be able to understand the semantics of data.'],\n",
       " ['A method to derive semantic representations from parse trees has been proposed.'],\n",
       " ['We have been investigating the meaning of language in the real world.'],\n",
       " ['Recursion-based semantics (RMRS) has emerged as an important area of research in the field of Natural Language Processing (NLP).'],\n",
       " ['In our group we are developing a new type of Natural Language Processing (NLP) technique called semantic role labeling.'],\n",
       " ['A common problem with corpus-based question answering is the problem of recall.'],\n",
       " ['We have developed HITIQA, a web-based tool for automated question answering, as part of the ARDA AQUAINT project.'],\n",
       " ['The Goi-Taikei dictionary is one of the most popular dictionaries in Japan.'],\n",
       " ['This paper presents the results of a study of word sense inference on a corpus of English language content.'],\n",
       " ['verb-argument relations: a machine learning problem.'],\n",
       " ['Work definition extraction is an important NLP task, most frequently a subtask of terminology extraction.'],\n",
       " ['The aim of this paper is to develop a method to identify subjectivity in text.'],\n",
       " ['grammar for-malisms parsing (HPSG) has been widely used to search for grammar for-malisms in corpus of Japanese.'],\n",
       " ['verb classes (VNs) are an important part of the corpus of word-semantics.'],\n",
       " ['Agirre and Lopez de Lacalle, 2008; Agirre and Lopez de Lacalle, 2008; Agirre and Lopez de Lacalle, 2008; Agirre and Lopez de Lacalle, 2008; Agirre and Lopez de Lacalle, 2008; Agirre and Lopez de Lacalle, 2008; Agir'],\n",
       " ['Our research aims to develop and implement a system for detecting deceptive and truthful statements.'],\n",
       " ['The aim of this project is to develop techniques for the processing of Noun compounds in the context of machine learning.'],\n",
       " ['Dependency parsing is one of the main areas of research in machine learning.'],\n",
       " ['A model free approach to sentence compression, which grew out of ideas from Nomoto, and examines how it compares to a state-of-art model intensive approach known as Tree-to-Tree, or T3 (Cohn and Lapata, 2008).'],\n",
       " ['In this paper, we propose a new evaluation method, which we call ROUGE Optimalrization, to maximize correlation with human re-sponsiveness.'],\n",
       " ['In our series of letters from leading scientists, Prof Wolfgang Vossen looks at the state-of-the-art of NLP advanced ap-plications.'],\n",
       " ['Prepositions and determiners are one of the most common sources of error for L2 En-glish speakers, a finding supported by our analysis of a small error-tagged corpus we created (deter-miners 17% of errors, prepositions 12%).'],\n",
       " ['The use of frames in word tagging has been well-known for some time (e.g., Dickinson and Jochim, 2008).'],\n",
       " ['reordering words in statistical machine translation.'],\n",
       " ['The development of paraphrase knowledge is one of the major areas of research in machine learning.'],\n",
       " ['In the past few years, there was a growing inter-est in mining opinions in the user-generated con-tent (UGC) on the Web, e.g., customer reviews, forum posts, and blogs.'],\n",
       " ['This paper reports on the integration of aunification-based semantics into a Feature-BasedLTAG for French which consists of around 6 000trees.'],\n",
       " ['This paper presents an instancebased learning algorithm for fine-grained named entity classification based on syntactic features (wordorder, case-marking, agreement, verb tenses, etc.).'],\n",
       " ['The aim of this paper is to investigate the use of probabilistic models for natural lan-guage generation.'],\n",
       " ['In statistical machine translation, a translation rule consists of a left-hand-side (LHS) 1 and a right-hand-side (RHS)'],\n",
       " ['Web-based frameworks for evaluating part-of-speech tag induction.'],\n",
       " ['We show how to derive a textual entailment from a set of discourse commitments.'],\n",
       " ['Sentence parsing is one of the most challenging tasks in machine learning.'],\n",
       " ['We have developed a discriminative model for word segmentation and point-of-sale ( POS) tagging in a joint process.'],\n",
       " ['We show that dependency-based systems learn faster than their constituent-based counterparts.'],\n",
       " ['This paper presents a contribution to the field of Natural Language Processing by combining statisti-cal information with string distance measures.'],\n",
       " ['The construction of coordinate structures is a major problem in the study of language.'],\n",
       " ['This paper presents the design and implementation of a pa-per for predicting referring expressions in natural language.'],\n",
       " ['The rapid dissemination of electronic communi-cation devices has triggered the emergence of newforms of written texts.'],\n",
       " ['In our series of papers on natural language processing, we focus on the development of tools to automatically locate, organise and man-age biomedical texts.'],\n",
       " ['This work forecasts day-to-day changes in pub-lic perception of political candidates from daily news.'],\n",
       " ['We have previously shown that phrase-based translation models are more accurate than phrase-based models when training German-to-English translation.'],\n",
       " ['There are two ways to deal with the problem of entailment relations in textualentailment systems.'],\n",
       " ['French and English are two of the most widely spoken languages in the world.'],\n",
       " [\"In this paper, we compare the performance of two approaches to grammar parsing: Matsuzaki and Tsujii's CCGbank (Clark and Curran, 2007; Matsuzaki and Tsujii, 2008) and the PTB (Clark and Curran, 2007; Matsuzaki and Tsujii, 2008).\"],\n",
       " ['Parsing is one of the most intensive areas of machine learning, and its performance has been widely reported.'],\n",
       " ['The goal of this paper is to improve the accuracy and expressiveness of speech recognition systems.'],\n",
       " ['The performance of machine translation algorithms is under increasing scrutiny.'],\n",
       " ['Consonant inven-tories in human languages have been studied in the framework of complex networks.'],\n",
       " ['Event-based sentence classification has been proposed as an alternative to traditional approaches to sentence classification.'],\n",
       " ['We have developed a machine learning-based system to resolve anaphora links in biomedical texts.'],\n",
       " ['Abbreviation recognition is a major problem in natural language processing.'],\n",
       " ['The American Council on Education (ACE) corpus is a large-scale corpus of academic material.'],\n",
       " ['This paper presents a new learning algorithm for unsupervised learning of grammar from text.'],\n",
       " ['The problem of query similarity between documents and user queries has been addressed in a number of papers.'],\n",
       " ['In Roark and Hollingshead (2007), we extended methods from Roark and Hollingshead (2008) for reducing the worst-case complexity of a context-free parsing pipeline via hard constraints derived from finite-state tagging pre-processing.'],\n",
       " ['The aim of this project is to improve the annotation of gene regulation events.'],\n",
       " ['In English, anaphors are often omitted and theseomissions are called zero pronouns.'],\n",
       " ['Part-of-speech taggers are trained oncorpora with a large number of tags.'],\n",
       " ['Parsing sentences using natural language processing has been a challenge.'],\n",
       " ['We propose a scheme of opinion frames, which consist of two opinions that are related byvirtue of having united or opposed targets.'],\n",
       " ['The problem of word sense annotation is a major bottleneck in the development of Natural Language Processing (NLP) applications.'],\n",
       " ['Opinion analysis is one of the most important areas of research in machine learning.'],\n",
       " ['subjectivity-ambiguity is a major problem in machine learning.'],\n",
       " ['In this paper, we present a new paradigmatic approach to the paradigmatic syntactic parsing problem of noun phrase chunking.'],\n",
       " ['We present a new framework for natural language processing based on unary templates.'],\n",
       " ['The accuracy of English as a second language (ESL) systems in the detection and correction of errors involving prepositions has been widely reported.'],\n",
       " ['We have proposed an algorithm to deal with four different types of seman-tics: a pair of words (petrify:stone) is analogous to an-other pair (vaporize:gas) when the semantic re-lations between the words in the first pair are similar to the relations in the'],\n",
       " ['gazetteers have been used to identify and extract attributes from a variety of data sources.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmed Rashid considers the role of metaphor in language.'],\n",
       " ['For some spe-cific domains, it is difficult to obtain a bilingual corpus.'],\n",
       " ['The aim of this paper is to provide an overview of the state-of-the-art in Chinese word segmentation.'],\n",
       " ['In this paper, we report a new type of Chinese case structure, which is different from those presented in previous work.'],\n",
       " ['In this paper, we develop an algorithm for reducing the size of rules in a Synchronous Context-Free Grammar (SCFG).'],\n",
       " ['The study of translation is one of the most important areas of research in machine learning.'],\n",
       " ['The automatic generation of parallel treebanks from paral-lel corpora is a major area of research in machine learning.'],\n",
       " ['We show how to decide when to stop active learning in WebKB.'],\n",
       " ['The use of context-free grammars in machine learning has been proposed as a way to reduce our set of rules.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmedou Ould-Abdallah looks at the problem of deciding between whole sentence levels of problematic translations.'],\n",
       " ['This paper presents a discourse-based opinion analysis scheme for interpreting opinions with discourse relations.'],\n",
       " ['We have shown that it is possible to partition a speech stream into utterance units using only left-context information.'],\n",
       " ['The task of translating speech is one of the most challenging in computer science.'],\n",
       " ['An unsupervised approach to reviewsearch, one that is unsupervised and that does not rely on pre-existing dictionaries.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmed Rashid considers discourse relations.'],\n",
       " ['The recognition of spatial entities in natural language text is an important part of understanding natural language.'],\n",
       " ['The aim of this research is to develop an efficient-rithm for selection of attributes that approximates human selection.'],\n",
       " ['Dynamic programming systems are increasingly being used to solve complex problems in computer science.'],\n",
       " ['We develop a method for selecting the most appropriate test case for the problem of ill-formed input to natural language interfaces.'],\n",
       " ['The study of vague word meanings in natural language texts is a difficult task.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmed Rashid considers the role of the lexicon in human language.'],\n",
       " [\"The SmSum system is a computer simulation of human summanzmg that automatically generates summaries of different content depending on the user's goals and needs.\"],\n",
       " ['The aim of the ISSCO 1 project is to develop a new approach to the modelling of LandCubed Bridges.'],\n",
       " ['This paper deals with the decomposition of natural language into its constituent parts, i.e.'],\n",
       " ['Non-SVO word order helps the reader (or listener) to construct a discourse representation.'],\n",
       " ['A new class of grammars called Categorial Unification Grammars (CUGs).'],\n",
       " ['Dependency grammar is a branch of formalism that deals with the representation of syntactic analyses in computer languages.'],\n",
       " ['The formal relationship between two systems of grammars has been investigated in a number of papers.'],\n",
       " ['The theory of general phrase structure grammar has been heavily criticised for its difficulty in dealing with complex feature structures.'],\n",
       " [\"Morphology is a study of a language's morphology.\"],\n",
       " ['lattices have been used for many years in the translation of Japanese text typed in kana (syllabic symbols) to kanji.'],\n",
       " ['The aim of this work is to investigate the use of deictic gestures to identify objects in natural language dialog systems.'],\n",
       " ['This paper presents a translation rule for translating non-singular concepts into English.'],\n",
       " ['The purpose of this paper is to investigate the feasibility of a thesaurus as an information retrieval tool.'],\n",
       " ['The aim of our project is to design and implement a natural language based knowledge acquisition and query system and to build a legal expert system on its basis.'],\n",
       " ['A discourse-oriented nonmonotonic formalism has been proposed for the resolution of anaphora.'],\n",
       " ['Natural language generation is a promising area of research.'],\n",
       " ['Speech-to-speech systems have been developed to produce spoken messages.'],\n",
       " ['This paper presents a new approach to knowledge-based machine translation.'],\n",
       " ['A machine translation system capable of translating English-Japanese computer manuals has been developed.'],\n",
       " ['SEMSYN is a project aimed at improving access to Japanese material in Germany.'],\n",
       " ['The study of anaphora has been a central issue in both theoretical linguistics and computational linguistics, but recent work by Hans Kamp suggests that it is possible to describe some important aspects of inter-sentential naphora while still respecting the con- straints of intra-sentential anaphora.'],\n",
       " ['Lexicalized Tree Adjoining Grammar (LTAG) is an attractive formalism for linguistic description mainly because cff its extended domain of locality and its factoring out from the domain of local dependencies.'],\n",
       " ['syntax and semantics in knowledge-based natural language understanding systems This paper presents a semantics-based knowledge representation of temporal periods and phases.'],\n",
       " ['We present a new formalism for the finite element system, which allows for more elegant descriptions of strings.'],\n",
       " ['The paper is published in the Journal of Machine Translation.'],\n",
       " ['A new algorithm for feature graphs has been proposed.'],\n",
       " ['This talk will focus on automatic translation of large corpuses of English and French.'],\n",
       " ['A multi-lingual (MT) system must be able to deal with different grammars for different languages.'],\n",
       " ['Anaphora is a pervasive phenomenon in natural language communication.'],\n",
       " ['This paper presents three proposals for the integration of binding constraints into rules that already satisfies the syntactic onstraints on coreferenee.'],\n",
       " ['A new strategy for the parsing of non-tensed verbal groups is presented.'],\n",
       " ['A generation system that synthesizes \"clause templates\" into clauses by a \"syntactic omponent\" is a major problem in computer science.'],\n",
       " [\"We are developing a machine translation system that produces a style appropriate to the target language and preserves the original author's tylistic intent.\"],\n",
       " ['Temporal relations are an important area of study in philosophy.'],\n",
       " ['The aim of our project is to develop a text analysis system capable of correcting errors in French.'],\n",
       " ['A new method to express quantification i a precise and natural way in natural anguage has been proposed.'],\n",
       " ['It has been proposed that utterances should be mapped to user model entries in order to infer inference processes at the higher level, and that utterances should be mapped to attitude model entries in order to infer inference processes at the deeper level.'],\n",
       " ['This paper describes the development of a reM language that performs both syntactic anMysis and natural anguage.'],\n",
       " ['A good semantic interpreter must be able to derive the real or intended sense of each phrase without excessive computation or specialized knowledge.'],\n",
       " ['We have developed a systemic grammar that can be used as part of a text generation system.'],\n",
       " ['The question \"Did you eat?\" and the question \"Did David dress?\"'],\n",
       " ['The aim of this study is error-correction of non-native speakers written ish text.'],\n",
       " ['A news analysis system is a computer program that classifies and indexes news stories in real time.'],\n",
       " ['The idea of infinite grammar was first proposed by Lounsbury in 1974 as a solution to the problem of parsing a sentence with unknown words.'],\n",
       " ['In our series of letters from African journalists, novelist and writer Germaine Greer looks at the issue of error ant i c ipat ion in second language learn ing.'],\n",
       " [\"In our paper, we adopt the position that reading a narrative, like taking part in a eowersation, is a form of soci',d interaction.\"],\n",
       " ['A real-time on-line communication system including automatic translation was realized by combining a keyboard conversation function with an English-Japanese bi-directional machine system implemented on a workstation [Amano 1987].'],\n",
       " ['The concept of polysemy is an important area of research in the field of semantics.'],\n",
       " ['The aim of this thesis is to develop a formal grammar for discourse.'],\n",
       " ['We have developed a new system for parsing German language sentences.'],\n",
       " ['In our work, we exploit the formal MRL grammar for parsing and generation of logical forms.'],\n",
       " ['The aim of this work is to develop a method for the recognition of continuous speech, that is, a process that does not require the use of \"high level\" knowledge sources.'],\n",
       " ['We consider the implications of machine translation research for the study of human-computer interaction.'],\n",
       " ['The LFG-framework is a framework for the derivation of sentences from functional and/or semantic structures.'],\n",
       " ['Machine readable dictionaries can be used to derive some domain knowledge from large text corpora.'],\n",
       " ['The Distributed Language Translation (DLT) project at the British Science Organisation (BSO) has been experimenting with bilingual corpora as a potential knowledge source for the machine translation system.'],\n",
       " ['The Alvey Directorate at the University of Manchester has published a paper on its research into machine translation.'],\n",
       " ['A machine translation system for Japanese-Engl ish telephone and inter- terminal dialogue has been proposed.'],\n",
       " ['The study of grammars has traditionally focused on the analysis of attribute-value systems.'],\n",
       " ['We develop a program to extract co-occurrence patterns from corpus data.'],\n",
       " ['The aim of the SIMSA project is to develop a multi-lingual tool to check the style of texts.'],\n",
       " ['The aim of our research is to discover what kinds of knowledge can be reliably acquired through tile use.'],\n",
       " ['Chinese is a highly flexible language, the same meaning may be represented in many different Chinese patterns.'],\n",
       " ['We have developed a speech synthesis system based on stress and intonation markers.'],\n",
       " ['There are many criticisms of the grammar G algorithm.'],\n",
       " ['The use of box codes in mnltilingual systems has attracted considerable attention.'],\n",
       " ['Tree Adjoining Grammars with Unification: Harbusch (1990).'],\n",
       " ['The generation of strings from logical forms was stud- ied intensively by [Shi88,89][Ca189], and the study of this problem shed light not only on the efficiency and soundness of generation algorithms, but also on the appropriateness of grammar itself.'],\n",
       " ['The correct program reads a list of misspelled words the input stream (stdin), and prints a set of corrections for each word on the output stream (stdout).'],\n",
       " ['The aim of this project is to develop a speech-to-speech translation system with simultaneous interpreta tion capability.'],\n",
       " ['The role of cue phrases in under- standing discourse is discussed in this paper.'],\n",
       " ['Morphological analysis of natural language sentences is one of the most challenging areas of computer science.'],\n",
       " ['Text structure is an important issue in the study of extended explanations.'],\n",
       " ['We have developed a system to resolve ambiguities in sentence analysis.'],\n",
       " ['The generation and processing of knowledge is one of the most important areas of research in artificial intelligence.'],\n",
       " ['I have been working on multi language translation for many years.'],\n",
       " ['This paper presents the results of an augmented grammar compilation procedure.'],\n",
       " ['Dictionary-based neural networks have been proposed many times over the past 30 years.'],\n",
       " ['The development and maintenance of Natural Language Processing (NLP) systems can be a challenge.'],\n",
       " ['A family of constraint logic grammars has been developed by Balari and Damas.'],\n",
       " ['Two-level morphology has come a long way in the last 30 years.'],\n",
       " ['The role of the human in the translation process has been hotly debated for many years.'],\n",
       " ['The use of disjunctive feature structures in natural grammars has led to the development of a wide range of analysis and translation systems.'],\n",
       " ['The Korean syllable structure grammar (KLSG) is a new grammar theory for the Korean language and follows a unification-based grammar such as GPSG and HPSG.'],\n",
       " ['The problem of parsing auds has been well-known for many years.'],\n",
       " ['This paper presents a new approach to the problem of linguistic description in multilingual generation.'],\n",
       " ['The scoped algorithm (QLF) is a well-known tool for dealing with complex noun phrases.'],\n",
       " ['This paper presents a formal account of the elusive concept of expressive power with respect to the kinds of categories and constructions that a grammar (of a given type) can reflect.'],\n",
       " ['This paper presents a new formalism for the study of Coordi:uation.'],\n",
       " ['The word category is one of the most difficult words to predict in natural language processing.'],\n",
       " ['The second prototype of example-based machine translation system (MBT2) is presented.'],\n",
       " ['Tree-adjoining rammars constitute a grammat-ical formalism with attractive properties for the strong characterization of the syntax of natural angtmges, that is, characterization of the analysis trees of the expres- sions in the language (Kroch and Joshi, 1985).'],\n",
       " ['Sentence analysis hould be treated as defeasible reasoning, and presents treatments of chart pars-ing [5], euse analyses, and interpretation of Japanese noun phrases with adnominal particles.'],\n",
       " ['The translation of text from one language to another is one of the most challenging tasks in computer science.'],\n",
       " ['The aim of this paper is to explore the use of reason-maintenance techniques to support incremental parsing and interpretation of human language.'],\n",
       " ['A new class of formalisms has been proposed in the area of object-oriented grammars.'],\n",
       " ['We study the intportant relations between parts of speech.'],\n",
       " ['The resolution of anaphora references has been one of the hotly contested areas of linguistic research in recent years.'],\n",
       " ['The syntax of Arabic sentences in Definite Clause Grammar is well known.'],\n",
       " ['Weather forecasts are the subject of various manipulations.'],\n",
       " ['Sentence segmentation is one of the most challenging problems in machine translation.'],\n",
       " ['In our series of letters from leading scientists, Prof Paul Harris looks at the potential of bilingual corpora as a knowledge source for machine translation.'],\n",
       " ['The study of text understanding systems based on Natural Language Processing (NLP) is not widespread.'],\n",
       " ['Whal agglutinative languages contain words of COnlllexity, and parsing such languages necessitates a thorough morphological analysis.'],\n",
       " ['The morphology of langtmge is often conceptualized in terms of paradigms.'],\n",
       " ['The integration of phonology into Head-driven Phrase Grammar is a major challenge.'],\n",
       " ['Most of the current Chinese natural language processing systems include a processor for word iden-tification.'],\n",
       " ['Rules for constructing a proof of a type in a Categorial Grammar.'],\n",
       " ['The study of phonological features is an important area of research in the fields of linguistics and computer science.'],\n",
       " ['A new approach to represent syntactic structures in large text corpora has been proposed.'],\n",
       " ['This paper presents a method for the analysis of a long Japanese sentence based on similarity of form.'],\n",
       " ['Un unification of uriitication-ba.sed parsing systems is a major problem in Haskell.'],\n",
       " ['In our series of letters from leading academics, novelists and other writers, novelists and other writers, novelists and other writers, novelists and other writers, novelists and other writers, novelists and other writers, novelists and other writers, novelists and other writers, novelists and other writers'],\n",
       " ['This paper is part of a series of papers on natural language processing.'],\n",
       " [\"The fully lexicMized grammar formalism I_'rAG 1 is based on a non-monotonic approach to grammar development and maintenance.\"],\n",
       " ['The semantics of bare plural NPs are well known, but a more sophisticated approach treats them as de- noting properties.'],\n",
       " ['The generation of quantified expressions in the context of a natural language generation system is a major area of research in machine learning.'],\n",
       " ['A model of dialogue that captures the role of utterances in a dialogue is well known, but the role of utterances in a dialogue should be captured by a model of task-oriented ialogue.'],\n",
       " ['In our series of letters from African journalists, Prof.'],\n",
       " ['The left context symbol is one of the most commonly used symbols in spoken language processing.'],\n",
       " ['The aim of this paper is to introduce a new type of word-sense recognition that combines several sources of knowledge such as lexicon information heuristics and others.'],\n",
       " ['The parsing problem with an offline-parsable grammar is undecidable.'],\n",
       " ['We present a novel parsing algorithm, which is capable of building a structure from two independent parts (a head and a single part).'],\n",
       " ['The formalisms of Categorial Grammars and Dependency Grammars have become very popular in recent years.'],\n",
       " ['The performance of machine translation systems is an important consideration for system designers.'],\n",
       " [\"We propose a data-structure-sharing version of Wroblewski's quasi-destructive unification algorithm, Copy.\"],\n",
       " ['A common need in natural language information re- trieval is to identify the information in free-form texts using a selected set of canonical terms.'],\n",
       " ['Extragrammatical input into unification-based grammars is a common problem.'],\n",
       " ['A corpus of terms and ex- pressions that are not defined in a dictionary has been developed.'],\n",
       " ['In our series of letters from Japanese journalists, Shouichi YTLYAMA, I, and Prof.'],\n",
       " ['argumentative paragraphs are often used in advising classes.'],\n",
       " ['Transfer-Driven Machine Translation (TDMT) performs efficient and robust spoken-language translation using various kinds of strategies to be able to treat diverse input.'],\n",
       " ['This paper proposes a formal framework for declarative representation of bi-lingual knowledge in machine translation systems.'],\n",
       " ['The need to generate un-ambiguous utterances is relevant for the development of natural language generation systems.'],\n",
       " ['The choice of anaphor for a word is one of the most important decisions a linguist can make.'],\n",
       " ['Transfer-based machine translation has been used for many years to improve the performance of human translators.'],\n",
       " ['The relationship between agents and their dialogue styles is one of the most important issues in the field of artificial intelligence.'],\n",
       " ['The goal of this paper is to develop a system for collaborative negotiation in which agents are solely interested in winning an argument and thus exhibit different behavior from collaborative agents.'],\n",
       " ['The aim of my research is to improve the state-of-the-art in natural language processing by introducing new approaches to stratification of linguistic resources.'],\n",
       " ['The Shalt2 system has been designed and implemented as a symmetric multi-lingual translation (MT) system with conceptual representation.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmedou Ould-Abdallah looks at a research project on automated Chinese text abstraction.'],\n",
       " ['Speech recognition is a branch of computer science that deals with the recognition of speech.'],\n",
       " ['We have been working on a large-seale verb dictionary for Dutch and French as coded by the PROTON project.'],\n",
       " ['The disautbiguation of fire sanses has been one of the most hotly debated areas of linguistics in recent years.'],\n",
       " ['The adverbial lexicon contains many different classes of adverbs.'],\n",
       " ['The problem of Chinese sentence tokenization has been the focus of considerable research efforts, and significant advancements have been made.'],\n",
       " ['Un- known words are a major problem in machine learning.'],\n",
       " ['We present a new approach for machine translation of compound words.'],\n",
       " ['We have developed a hierarchical structure for lex- ical knowledge which can capture significant linguistic gen- eralizations, eliminate rexlundancy, and facilitate both knowl- edge acquisition and efficient processing.'],\n",
       " ['Corpus-based approaches based on bilingual texts are promising for various applications.'],\n",
       " ['There are many ways in which trees can be improved.'],\n",
       " ['In our previous papers, we have proposed a corpus-based approach to corpus-based machine learning.'],\n",
       " ['noun phrase countability and number in English for machine translation into Japanese.'],\n",
       " [\"The KANT system, developed by CMU's Center for Machine Translation (Mitamura et al 1991), is a text-to-speech system that has been widely used in research into machine translation.\"],\n",
       " ['Examples of example-based translation have been presented in a number of papers.'],\n",
       " ['Examples of machine translation systems have been developed over the years.'],\n",
       " ['The aim of this paper is to introduce a new approach to the translation of tiles, one based on the DBMT Interactive MT system.'],\n",
       " ['The aim of this paper is to explore the use of probabilistic models to train speech taggers.'],\n",
       " ['In our paper, we address the problem of supertag assignnmnt ambigu ity by using ta.ggels reduce the supertag assignnmnt ambigu ity.'],\n",
       " ['A feature structure tagger is a machine-learning technique for tagging words with feature structures.'],\n",
       " ['A corpus of Chinese-English texts is one of the most important parts of linguistic research.'],\n",
       " ['Part-of-speech taggers are an important area of research in machine learning.'],\n",
       " ['Multi-tape two-level morphology is one of the most challenging problems in phology.'],\n",
       " ['It is not easy to input Japanese sentences written by optical cha.racter teal- ets (OCR) or speech recognition devices.'],\n",
       " ['A morphological nalyzer that offers approxi- mately 95% accuracy on a statistical language model-ing technique and an efficient two-pass N-best search strategy is proposed.'],\n",
       " ['Morphemes are the smallest spaces in a string of charction words.'],\n",
       " ['This paper considers the use of lexical rules to generate different uses of words for uovel uses of words.'],\n",
       " ['A standard way to properly manage large multilingual lexical databases is to do a clear distinction among terms and their interlingual acceptions (orxies).'],\n",
       " ['In our series of letters from African journalists, filmmaker and columnist Farai Sevenzo looks at the meaning of vocabulary.'],\n",
       " ['The meaning of a word can be determined by a number of methods: dictionary-based, corpus-based, hand-encoded, light parsing, etc.'],\n",
       " ['In the 1980s and 1990s, a large number of dictionaries were developed, some of them bilingual.'],\n",
       " ['The PROVERB text planning framework has been developed at the University of California, Berkeley.'],\n",
       " ['The aim of this paper is to develop a domain-independent abstract generation system for the analysis of discourse structure.'],\n",
       " ['We show how a natural language generation system can be improved by defaulting to a more natural language.'],\n",
       " ['A new method for controlling the construction of functional labels on the basis of pre-chunked input has been proposed.'],\n",
       " ['We need a grammar formalism capable of processing \"flexible\" word order in natural languages.'],\n",
       " ['Speech translation systems have been proposed and demonstrated in a number of areas, including:'],\n",
       " ['finite-state transducers have been used to represent context-free grammars for many years.'],\n",
       " ['Principle-based grammars offer many advantages over rule-based and unification-based grammars.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmedou Ould-Abdallah looks at some of the key issues in African journalism.'],\n",
       " ['The terminol-ogy extraction of English and French technical terms has been an area of interest for many years.'],\n",
       " ['This paper presents an algorithm for selecting an appropriate classifier for a noun in Thai.'],\n",
       " ['The English National Dictionary of Klingon (ENGCG) has been updated to include 10 million words.'],\n",
       " ['The Gemini system is a set of rules that can be used to train an unsupervised learning system.'],\n",
       " [\"We use the term '(RISE)' instead of 'StrumeingAdvanced' in our approach to information retrieval.\"],\n",
       " ['A new method of sorting sul)strings of a text has been developed.'],\n",
       " ['A technique is proposed for classifying word meanings and determining relationships between words or between sentences.'],\n",
       " ['Cilough Ei lial, il- rM la, llglltg(:: l i it(|ersi,all(l i,,g ()11o ilillrLalll, and ll(IC-m:y Cilough Ei, ll'],\n",
       " ['generative lexicons have been proposed as a way to support automatic sense shifts and to prevent a proliferation of senses in the semantic lexicon.'],\n",
       " ['This paper considers a problem with the standard approach to polysemy, arguing that in many cases this kind of \"forced-choice\" approach to formation leads to arbitrary decisions which have negative consequences for NLP systems.'],\n",
       " ['The aim of this paper is to provide an example-based system for disambiguating sentences in a practical domain.'],\n",
       " ['The acquisition of selectional constraints is one of the most challenging tasks in machine learning.'],\n",
       " ['Text segmentation has become one of the major areas of research in machine learning.'],\n",
       " ['The acquisition of word sense is one of the most challenging problems in computer science.'],\n",
       " ['We propose a new approach to linguistic knowledge acquisi- tion, which is a combination of symbolic and statistical approaches.'],\n",
       " ['The structure of compound nouns is one of the major problems in language-processing systems.'],\n",
       " ['In our series of letters from African journalists, novelists, and writers, novelist and writer Ahmedou Ould-Abdallah looks at the changing role of grammar tbrmalisms in natural language processing.'],\n",
       " ['Forma,lism is a type of feature structure which has a signature which can be inferned from any other type of forma,lism.'],\n",
       " ['A rule for constructing a grammar of spontaneously spoken language is proposed.'],\n",
       " ['This paper proposes a statistic that measures the strength of glue between words in a sampled text.'],\n",
       " ['This paper presents a method for document classification based on hard clustering of words.'],\n",
       " ['This paper presents a method for automatically aligning Japanese and English sentences from bilingual corpora.'],\n",
       " ['A discourse module for a text underslanding system is described.'],\n",
       " ['The use of referring expressions in conversation has been investigated by a number of researchers.'],\n",
       " ['2 Anaphora Resolution System 4.1 Procedure Before referents are determined sentences are transformed into a case structure by the ce structure (Kurohashi and Nagao 1994).'],\n",
       " ['This paper presents a new approach to the problem of text segmentation.'],\n",
       " ['An anaphor resolution is a technique for selecting correct antecedents from a large number of candi- date noun phrases.'],\n",
       " ['The problem of anaphora resolution in Natural Language Processing (NLP) has been hotly debated for many years.'],\n",
       " ['The rhel;orieal relal,ion delinil,ions causes problems, Our elaim is thai, the main cause'],\n",
       " ['This paper presents a new model of dialogue, one based on the idea of \"grounding\".'],\n",
       " ['We have previously reported on a rule-based ap- proach to prepositional phrase attachment, disambiguating between prepositional attachent to the main verb and to the object nonn phrase.'],\n",
       " ['A discourseralegy is a strategy for communicaling with another agent.'],\n",
       " ['A new class of grammars, the unification-based grammar (I)CG, is proposed.'],\n",
       " ['This paper presents a complete system for highaccuracy Chinese segmentation.'],\n",
       " ['The Haskell programming language is well known for its use of feature structures to describe objects.'],\n",
       " ['Two lexical transducers for Korean have been built at Xe- rox PARC within a tamework nown as two- level Inorpho logy.'],\n",
       " ['The classification of Chinese language sentences is one of the major challenges in the field of artificial intelligence.'],\n",
       " ['We present a new method for automatic onstruction of thesauri based on corpus data.'],\n",
       " ['We address the problem of automatically acquir- ing case frame patterns (selectional patterns) from large corpus data.'],\n",
       " ['In this paper, we present a Verbmobil Research Prototype for a multi- communication architecture for large, A l-systems, which is particularly use-ful for systems speech and language processing.'],\n",
       " ['A new way of dealing with corpus problems in NLP has been proposed.'],\n",
       " [\"A version of Brill's tagger is used for tagging Spanish texts, which includes unknown words.\"],\n",
       " ['verb sense disamibiguation in English text retrieval by (:orlms-based)roache.'],\n",
       " ['The morphology of words in Arabic has been studied by a number of researchers over the years.'],\n",
       " ['The use of floating quantifiers in machine translation has been widely accepted for many years.'],\n",
       " ['We propose a novel approach to processing metonymy by building meaning representations of wholes.'],\n",
       " ['The treatment of mental adjectives in French has been an area of interest for many years.'],\n",
       " ['An example of an example-based translation system is presented, where outputs from Transfer Machine Translation (MT), Knowledge-based MT and Example-based MT are combined on the chart during parsing.'],\n",
       " ['Prepositional phrases are usually attached to verbs according to text corpora.'],\n",
       " ['Proper nouns can be identified using corpus-based and rule-based methods (Chen and Lee, 1996; Chen, Ding and Tsai, 1998).'],\n",
       " ['The production of multisentential text has become an increasingly important topic in computer science.'],\n",
       " ['The performance of a text-to-speech program is investigated in the context of a psychological theory of reading aloud.'],\n",
       " ['Application-oriented grammar development has to take into account the following parameters:'],\n",
       " ['The aim of this paper is to describe a transfer-based approach to machine translation of spontaneous poken language in face-to-face dialogs.'],\n",
       " ['In this paper, we propose a novel methodology for learning fine-grained grammatmal knowledge from corpus data.'],\n",
       " ['This paper describes research done within the Sonderforschunsbereich 30 at IMS.'],\n",
       " ['A description of some of the algorithms used to parse words.'],\n",
       " ['The use of preventative expressions in teaching has been explored in the fields of politeness and intentionality.'],\n",
       " ['In this paper I present a new theory of Italian referential expressions, that is based on the assumption that Italian referential expressions can be explained by the following:'],\n",
       " ['Speech processing is one of the most challenging areas of computer science.'],\n",
       " ['The translation of nominal compounds is one of the most challenging NLP problems.'],\n",
       " ['We are going to look at how to carry out WSD on the basis of distributional evidence.'],\n",
       " ['The aim of this work is to develop a new type of machine translation, interactive translation.'],\n",
       " ['The translation of spoken language is one of the most challenging tasks in computer science.'],\n",
       " [\"This paper presents an approach to proper name recognition that uses ma-chine learning and a language independent fi'ame- work.\"],\n",
       " ['In this paper, we show that higher-order unification can be used to model the interpretation of focus and its interaction with focus sensitive operators, adverbial quantifiers and second occurrence expressions.'],\n",
       " ['The US System (US) is a large scale multi-lingual speech-to-speech translation system designed to facilitate communication between two parties engaged in a spontaneous conversation in a limited domain.'],\n",
       " ['This paper presents a new method for processing disjunctions in natural language grammars.'],\n",
       " [\"This paper presents a serious rival to the two-level formalisin Koskenniemi, developed in response to practical difficulties encountered in writing large-scale mor- phological descriptions using Koskenniemi's nota-tion.\"],\n",
       " ['The COMLEX Syntax has been used by linguists for more than 20 years.'],\n",
       " ['A speech-to-text (S2T) system is being developed at the University of California, Los Angeles (UCLA) and the University of California, Berkeley.'],\n",
       " ['The resolution of anaphora and ellipses in English texts is a major problem in the area of semantics.'],\n",
       " ['parsing of natural language texts.'],\n",
       " ['Two well-known methods for similaritytehing are herited feature-based similarity matching and the generation of lexical hierarchies from large text corpora.'],\n",
       " ['The theory of \"sloppy identity\" has been the subject of much research in recent years.'],\n",
       " ['corpus-based methods for retrieving bilinguals from large corpora.'],\n",
       " [\"The development of ensming, correcl, int'crelming, is an area of interest for many vmiotts.\"],\n",
       " ['This paper deals with a question that has received little attention: What conditions should an IR be applicable to a given lexical entry (henceforth: LE)?'],\n",
       " ['The aim of this paper is to show how to generate word orders in the target language based on contextual information.'],\n",
       " ['Morphological analysis of word- tbrms in Bantu languages is a challenge.'],\n",
       " ['The extraction and mining of strings from corpus has been a major area of research for many years.'],\n",
       " ['Co-occurrence information between words and words in the same sentence has been used in phrase translation.'],\n",
       " ['The Constructive Dialogue Model is a radical new approach to dialogue management.'],\n",
       " ['The importance of punctuation in natural language processing has been debated for many years.'],\n",
       " ['In this paper we describe a portable, fast and robust natural language/analyser for advanced document processing systems.'],\n",
       " ['This paper presents the formalism of a replacement expression, which can be composed with transducers that encode: correction rules for the most frequent tagging errors which are automatically generated (Brill, 1992; Roche and Schabes, 1995) or manually written (Chanod and Tapanainen, 1995), in order to'],\n",
       " ['This paper presents a study of the modularity of codescriptive grammars.'],\n",
       " ['This paper presents an algorithm that identi- fies the coding system and the language of a given text.'],\n",
       " ['Multi-tape two-level morphology has been used to describe non-linear phenomena in the domain of non-linear morphology.'],\n",
       " ['Dependency grammars describe the structure of a sentence in terms of binary head-modifier (also called dependency) relations on the words of the sentence.'],\n",
       " ['Sentences ranked by our definition as more complex are generally more difficult for humans to process than otherwise sim- ilar sentences.'],\n",
       " ['The aim of this project is to develop a semantics-based system for the classification and coding of medical procedures.'],\n",
       " ['In machine translation, word order is not always essential.'],\n",
       " [\"A cascading word-Pos guesser is reported to achieve higher guessing accuracy than quoted be- fore which in average was about by 8-9% better than that of the Xerox guesser and by 6-7% bet- ter than that of Brill's guesser, reaching 87-92% tagging accuracy on unknown words\"],\n",
       " ['We have to have a computer assisted system tbr processing Japanese manual sentences.'],\n",
       " ['The aim of this paper is to develop a method for correcting the spelling error in the languages that have no word boundary.'],\n",
       " ['Anaphora resolution of Japanese zero pronouns has been investigated by Hiromi Nakaiwa and Satoshi Shirai (1996).'],\n",
       " ['The goal of word alignments for a bilingual corpus is the translation of a text given in some language F into a target language E.'],\n",
       " ['The General Information System for Pensions (GIST) aims to improve the quality of information about the pension system in Europe.'],\n",
       " ['Conjunctive postpositions have been used in Japanese discourse for many years.'],\n",
       " ['The aim of this paper is to evaluate the relaxation labelling algorithm described in Section 2.'],\n",
       " ['The smoothing of the transition probabilities between known and unknown words is one of the most important tasks in machine learning.'],\n",
       " ['The aim of this paper is to provide an overview of the state-of-the-art in natural language processing.'],\n",
       " ['The aim of this paper is to develop a method for selecting a suitable sentence from a speech recognition system using a statistical language model.'],\n",
       " ['A new generation method that produces multiple paraphrases encodes a semantic input which may contain ambiguities.'],\n",
       " ['The goal of this paper is to develop a method for learning concepts belonging to a given semantic class.'],\n",
       " ['Anaphor resolution is one of the most challenging problems in the study of language.'],\n",
       " ['The verbal case frame is an important area of research in machine learning.'],\n",
       " ['Most existing thesauruses are hand-crafted by ol.'],\n",
       " ['The acquisition of word sense definitions has been widely used in computer science for many years.'],\n",
       " ['Sentence selection is one of the most important problems in computer science.'],\n",
       " ['The multiword lexeme is one of the most commonly used expressions in natural language processing.'],\n",
       " ['The problem of identifying unknown words from a corpus of speech is well known.'],\n",
       " ['The word \"ta\" means \"toward\" or \"towards\" or \"towards\" or \"towards\" or \"towards\" or \"towards\" or \"towards\" or \"towards\" or \"towards\" or \"towards\" or \"towards\" or \"towards\" or \"towards\" or \"towards\"'],\n",
       " ['In our series of letters from Irish writers, novelists and poets, novelist and writer Michael Morpurgo looks at the use of words in NI,P.'],\n",
       " ['Sentence compression systems have been tested on corpus data from the Ziff-Davis (ZD, henceforth) by Knight and Marcu (2000), general news articles by Clarke and Lapata (CL, henceforth) corpus (2007) and biomedical articles (Lin and Wilbur, 2007).'],\n",
       " ['Recent studies have shown the potential improvement that FrameNet can bring on the performance of Question Answering (QA) systems.'],\n",
       " ['The question of how to select the most likely answer from a corpus of documents is one of the most frequently asked in computer science.'],\n",
       " ['A number of approaches to word alignment have been proposed, including triangulation, bridge-building and com-bining.'],\n",
       " ['We study the quality of Chinese-English and ArabicEnglish translation tasks using f-measure, a discriminative method for alignment.'],\n",
       " ['We present first results with anew architecture that integrates a state-of-the-art word sense model into phrase-based machine translation.'],\n",
       " ['Text-to-text rewriting is one of the most exciting areas of computer science.'],\n",
       " ['This talk will focus on the generation of natural language using ASGRE algorithms.'],\n",
       " ['The problem of automatic error de-tection is one of the most challenging in machine learning.'],\n",
       " ['Data-driven approaches learn to produce de-pendency graphs for sentences solely from anno-tated corpus.'],\n",
       " ['dependency parsing is one of the most computationally challenging algorithms in computer science, and its performance is often poor.'],\n",
       " ['Semi-supervised dependency-parsing methods for structured data are emerging.'],\n",
       " ['In this paper we study the impact of En-glish inclusions on the parsing of German text.'],\n",
       " ['Di-rectionality of Inference Rules is a well-known method for learning textual entailment rules.'],\n",
       " ['We present a discriminative model for identifying misspelled web search terms.'],\n",
       " ['This paper presents a new approach to the problem of automatically separating sets of news documents generated by queries containing per-sonal names into coherent partitions.'],\n",
       " ['The use of trigram language models in spel-ling correction has been discussed elsewhere, but the use of contextual language models in spel-ling correction has been so success-ful that they are beginning to be rolled out to appli-cations with millions and millions of users.'],\n",
       " ['Morphological segmentation is one of the most challenging NLP tasks.'],\n",
       " ['In particular, we present a novel method for combining morphology and distributional infor-mation for seed selection.'],\n",
       " ['The extraction of pro-tein interaction information from biomedical texts is an important area of research.'],\n",
       " ['The goal of this paper is to improve the accuracy of sequence alignment algorithms used in computer science.'],\n",
       " ['Sentence generation is a major problem in corpus linguistics.'],\n",
       " ['Machine translation is a major challenge in the field of computer science and engineering.'],\n",
       " ['We have developed a synthetic corpus for training machine translation systems.'],\n",
       " ['Markov Models can be used to improve the performance of Expectation-Maximization (EM) in tag-ging.'],\n",
       " ['We have previously proposed a new method for resolving coordinate structures in Japanese.'],\n",
       " ['In this paper, we investigate the use of global features for structured prediction problem in Natural Language Processing (NLP).'],\n",
       " ['The Tongyici Cilin Chinese thesaurus is one of the largest of its kind in the world.'],\n",
       " ['The aim of this paper is to develop a novel method to detect low-quality product reviews on shopping sites.'],\n",
       " ['A new entropy-based external evaluation measure for clustering is presented.'],\n",
       " ['Morphological analysis is the study of morphology in a language.'],\n",
       " ['The goal of this paper is to develop a fully automated single-document extract sum-marie of newswire articles.'],\n",
       " ['Customer contact records are produced every day in the form of audio record-ings of speech, transcripts, call summaries, email, etc.'],\n",
       " ['The Bloom filter is one of the most well-known filters in computer science, and its use in language modelling is a major challenge.'],\n",
       " ['In recent years active learning has attracted a lot of research interest, and has been studied in many natural language processing (NLP) tasks, such as text classification (TC) (Lewis and Gale, 1994), chunking (Ngai and Yarowsky, 2000), annotation of corpora has become a crucial pre-'],\n",
       " ['The aim of this paper is to investigate the use of natural language processing (NLP) for augmented and alternative communication systems.'],\n",
       " ['The statisti-cal machine translation (SMT) is one of the most popular machine translation techniques.'],\n",
       " ['Our work is the first to per-form both identification and resolution of Chinese zero pronouns using a machine learning approach.'],\n",
       " ['The aim of this work is to develop a method that allows us to compute semantic dis-tance in a possibly resource-poor language by seam-lessly combining its text with a knowledge source.'],\n",
       " ['The aim of this paper is to develop a new method for measuring semantic relatedness for wordpairs based on random walkMarkov chain theory.'],\n",
       " ['Role Labeling (SRL) is one of the most challenging tasks in Natural Language Processing (NLP).'],\n",
       " ['We present a new learning model for detecting disambiguating coor-dinate conjunctions.'],\n",
       " ['We use Conditional Random Fields (CRFs) for NE categorization in Wikipedia.'],\n",
       " ['We present a new method for dynamically ranking speakers in a discussion.'],\n",
       " ['We develop an extension of the hierarchical Dirichlet process PCFG for grammar refinement (HDP-PCFG-GR) based on a structured mean-field ap-proximation of the true posterior over parameters.'],\n",
       " ['A method to extract high-quality gazetteers from Wikipedia is proposed in this paper.'],\n",
       " ['The use of Wikipedia as a knowledge source for various language processing tasks has recently been used as a knowledge source for taxonomy construction (Ponzetto and Strube, 2007a), coreference resolution (Ponzetto and Strube, 2007b), and English NER (e.g., Bunescu and'],\n",
       " ['Information extraction is one of the most computationally intensive tasks in terrorism research.'],\n",
       " ['syntactic reordering of ap-proach for translation from Chinese to English.'],\n",
       " ['Syntax-based translation models can be used to produce desirable translations.'],\n",
       " ['The study of machine translation has become a major area of research in the fields of computer science and linguistics.'],\n",
       " ['In this paper, we study active learning with resampling methods addressing the class imbalance problem for word sense disam-biguation.'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmed Rashid considers the meaning of query tokens.'],\n",
       " ['The aim of this paper is to train a language model for a text database.'],\n",
       " ['This research is part of an effort to develop a Knowledge Base Management System to benefit research.']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_downstream_combined2 = []\n",
    "k=0\n",
    "for i in range(len(sum_cnndm)):\n",
    "    string = s1[i] + \" \" + s2[i] + \" \" + sum_cnndm[i] + \" \" + df.Citations[i]\n",
    "    k+=1\n",
    "    \n",
    "    batch = tokenizer(string, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    translated = model.generate(**batch)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "\n",
    "    f = open('aan_data_xsum_and_cnndailymail_summaries_downstream_r2.csv','a')\n",
    "    f.write(tgt_text[0])\n",
    "    f.write('\\n') \n",
    "    f.close()\n",
    "    \n",
    "    summaries_downstream_combined2.append(tgt_text)\n",
    "    if k % 10 == 1:\n",
    "        print(k)\n",
    "summaries_downstream_combined2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare summaries\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1','rouge2', 'rougeL','rougeLsum'], use_stemmer=True)\n",
    "scores = []\n",
    "for i in range(len(summaries_downstream_combined2)):\n",
    "\n",
    "    s = scorer.score(df.Abstract[i], summaries_downstream_combined2[i][0])\n",
    "    \n",
    "    #simpler flat structure\n",
    "    x = {\n",
    "        \"rouge1:precision\":s[\"rouge1\"][0],\n",
    "        \"rouge1:recall\":s[\"rouge1\"][1],\n",
    "        \"rouge1:fmeasure\":s[\"rouge1\"][2],\n",
    "        \"rouge2:precision\":s[\"rouge2\"][0],\n",
    "        \"rouge2:recall\":s[\"rouge2\"][1],\n",
    "        \"rouge2:fmeasure\":s[\"rouge2\"][2],\n",
    "        \"rougeL:precision\":s[\"rougeL\"][0],\n",
    "        \"rougeL:recall\":s[\"rougeL\"][1],\n",
    "        \"rougeL:fmeasure\":s[\"rougeL\"][2],\n",
    "        \"rougeLsum:precision\":s[\"rougeLsum\"][0],\n",
    "        \"rougeLsum:recall\":s[\"rougeLsum\"][1],\n",
    "        \"rougeLsum:fmeasure\":s[\"rougeLsum\"][2],\n",
    "        \n",
    "    }\n",
    "    scores.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1:precision</th>\n",
       "      <th>rouge1:recall</th>\n",
       "      <th>rouge1:fmeasure</th>\n",
       "      <th>rouge2:precision</th>\n",
       "      <th>rouge2:recall</th>\n",
       "      <th>rouge2:fmeasure</th>\n",
       "      <th>rougeL:precision</th>\n",
       "      <th>rougeL:recall</th>\n",
       "      <th>rougeL:fmeasure</th>\n",
       "      <th>rougeLsum:precision</th>\n",
       "      <th>rougeLsum:recall</th>\n",
       "      <th>rougeLsum:fmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>817.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.509185</td>\n",
       "      <td>0.096425</td>\n",
       "      <td>0.154848</td>\n",
       "      <td>0.122177</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.035571</td>\n",
       "      <td>0.370250</td>\n",
       "      <td>0.068906</td>\n",
       "      <td>0.110859</td>\n",
       "      <td>0.370250</td>\n",
       "      <td>0.068906</td>\n",
       "      <td>0.110859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.164687</td>\n",
       "      <td>0.055432</td>\n",
       "      <td>0.071397</td>\n",
       "      <td>0.139990</td>\n",
       "      <td>0.030686</td>\n",
       "      <td>0.044920</td>\n",
       "      <td>0.139383</td>\n",
       "      <td>0.041426</td>\n",
       "      <td>0.053538</td>\n",
       "      <td>0.139383</td>\n",
       "      <td>0.041426</td>\n",
       "      <td>0.053538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.059880</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.075472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.144330</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.100840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.132701</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.132701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.448980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rouge1:precision  rouge1:recall  rouge1:fmeasure  rouge2:precision  \\\n",
       "count        817.000000     817.000000       817.000000        817.000000   \n",
       "mean           0.509185       0.096425         0.154848          0.122177   \n",
       "std            0.164687       0.055432         0.071397          0.139990   \n",
       "min            0.000000       0.000000         0.000000          0.000000   \n",
       "25%            0.394737       0.059880         0.105263          0.000000   \n",
       "50%            0.500000       0.085106         0.144330          0.086957   \n",
       "75%            0.611111       0.120690         0.195652          0.166667   \n",
       "max            1.000000       0.434783         0.448980          1.000000   \n",
       "\n",
       "       rouge2:recall  rouge2:fmeasure  rougeL:precision  rougeL:recall  \\\n",
       "count     817.000000       817.000000        817.000000     817.000000   \n",
       "mean        0.022147         0.035571          0.370250       0.068906   \n",
       "std         0.030686         0.044920          0.139383       0.041426   \n",
       "min         0.000000         0.000000          0.000000       0.000000   \n",
       "25%         0.000000         0.000000          0.272727       0.043011   \n",
       "50%         0.013889         0.022989          0.357143       0.059701   \n",
       "75%         0.028846         0.048000          0.444444       0.081395   \n",
       "max         0.272727         0.425532          1.000000       0.434783   \n",
       "\n",
       "       rougeL:fmeasure  rougeLsum:precision  rougeLsum:recall  \\\n",
       "count       817.000000           817.000000        817.000000   \n",
       "mean          0.110859             0.370250          0.068906   \n",
       "std           0.053538             0.139383          0.041426   \n",
       "min           0.000000             0.000000          0.000000   \n",
       "25%           0.075472             0.272727          0.043011   \n",
       "50%           0.100840             0.357143          0.059701   \n",
       "75%           0.132701             0.444444          0.081395   \n",
       "max           0.448980             1.000000          0.434783   \n",
       "\n",
       "       rougeLsum:fmeasure  \n",
       "count          817.000000  \n",
       "mean             0.110859  \n",
       "std              0.053538  \n",
       "min              0.000000  \n",
       "25%              0.075472  \n",
       "50%              0.100840  \n",
       "75%              0.132701  \n",
       "max              0.448980  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 Domain Dependency of Words The domain dependency of words that how strongly a word features a given set of data (documents) contributes to event extraction, as we previously reported (Fukumoto et al.: 1997).'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Citations[136]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We will describe a method which automatically searches for parallel texts on the Web.<n>We will discuss the text mining algorithm we adopted, some issues in trans- lation model training using the generated parallel corpus.',\n",
       " 'This paper describes a method of \"polite- ness\" selection according to a participant\\'s so- cial role.<n>It is possible to use a \"participant\\'s so- cial role\" to appropriately make the translation results \"polite\"',\n",
       " 'The Atlas project is to enlarge the scope of student interaction in an intelligent tutoring system.<n>A key component of Atlas is APE, the Atlas Planning Engine.<n>APE could also be used to manage other types of human-computer conversation.',\n",
       " 'We present a linguistically motivated framework for uniform lexico- structural processing.<n>It has been used for transformations of conceptual and syntactic structures during generation i monolingual nd multilingual natural language generation (NLG) and for transfer in machine translation (MT)<n>Our work extends directions taken in systems such as Ariane (Vauquois and Boitet, 1985), FoG (Kittredge and Polgu6re, 1991), JOYCE (Rainbow and Korelsky, 1992), and LFS (Iordanskaja et al, 1992)',\n",
       " 'State-of-the-art information extraction systems extract a small number of relations and events.<n>Our goal is to develop an IE system which scales up to extract as many types of relations and events as possible.<n>Currently, REES handles 100 types of relations and events, and it does so in a modular and scalable manner.',\n",
       " 'We describe MIMIC, a voice-enabled telephone-based dialogue system.<n>MIMIC adapts dialogue strategies based on participant roles, characteristics of the current utterance, and dia- logue history.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_cnndm[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['In this paper, we will describe a method which automatically searches for parallel texts on the Web.'],\n",
       " ['The aim of this paper is to develop a method for selecting \"polite\" participants for dialogue translation systems.'],\n",
       " ['We have developed a dialogue management system for intelligent tutoring systems called Atlas.'],\n",
       " ['Natural language processing (NLP) and machine translation (MT) are two of the fastest growing areas of research in computer science.'],\n",
       " ['The Relation and Event Extraction System (REES) is a state-of-the-art information extraction system for extracting relations and events.'],\n",
       " ['In this paper, we describe a spoken dialogue system that automatically adapts dialogue strategies based on actual dialogue interactions.']]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['We will describe a method which automatically searches for parallel texts on the Web.<n>We will discuss the text mining algorithm we adopted, some issues in trans- lation model training using the generated parallel corpus.'],\n",
       " ['This paper describes a method of \"polite- ness\" selection according to a participant\\'s so- cial role.<n>It is possible to use a \"participant\\'s so- cial role\" to appropriately make the translation results \"polite\"'],\n",
       " ['The Atlas project is to enlarge the scope of student interaction in an intelligent tutoring system.<n>A key component of Atlas is APE, the Atlas Planning Engine.<n>APE could also be used to manage other types of human-computer conversation.'],\n",
       " ['We present a linguistically motivated framework for uniform lexico- structural processing.<n>It has been used for transformations of conceptual and syntactic structures during generation i monolingual nd multilingual natural language generation (NLG) and for transfer in machine translation (MT)<n>Our work extends directions taken in systems such as Ariane (Vauquois and Boitet, 1985), FoG (Kittredge and Polgu6re, 1991), JOYCE (Rainbow and Korelsky, 1992), and LFS (Iordanskaja et al, 1992)'],\n",
       " ['State-of-the-art information extraction systems extract a small number of relations and events.<n>Our goal is to develop an IE system which scales up to extract as many types of relations and events as possible.<n>Currently, REES handles 100 types of relations and events, and it does so in a modular and scalable manner.'],\n",
       " ['We describe MIMIC, a voice-enabled telephone-based dialogue system.<n>MIMIC adapts dialogue strategies based on participant roles, characteristics of the current utterance, and dia- logue history.']]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_arxvi[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_arxvi_downstream = []\n",
    "k=0\n",
    "for i in range(len(summaries_arxvi)):\n",
    "    string = summaries_arxvi[i][0] + \" \" + df.Citations[i]\n",
    "    k+=1\n",
    "    \n",
    "    batch = tokenizer(string, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    translated = amodel.generate(**batch)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "\n",
    "    f = open('aan_data_arxiv_summaries_downstream_r1.csv','a')\n",
    "    f.write(tgt_text[0])\n",
    "    f.write('\\n') \n",
    "    f.close()\n",
    "    \n",
    "    summaries_arxvi_downstream.append(tgt_text)\n",
    "    if k % 10 == 1:\n",
    "        print(k)\n",
    "summaries_arxvi_downstream "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d083f05b09c4854ab7273570858cb16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1912529.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ae7b264c8e4c2a9afa72662a54bccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=65.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa346756e0b4ba6a5635db430c9d831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6dd9c4ba0e4b8596a9419e759b078a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1120.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2492af6da11f43f29588c27f84209c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=2275327883.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['high temperatures and low relative humidity in the western united states over the last few days have resulted in widespread wildfire risk. <n> utility companies in several states have been activated to respond to power shutoffs caused by drought. in illinois, <n> the state public utility commission has declared a state of emergency for all new power shutoffs caused by drought. in the united states, <n> the national institute of environmental health sciences ( niehs ) has declared a state of emergency for all new power shutoffs caused by drought. in the united states <n>, the utility commission has also declared a state of emergency for all new power shutoffs caused by drought. <n> the niehs has declared a state of emergency for all new power shutoffs caused by drought in illinois, missouri, kentucky, pennsylvania, and iowa. <n> the niehs has also declared a state of emergency for all new power shutoffs caused by drought in minnesota. in the united states, <n> the national institute of environmental health sciences ( niehs ) has declared a state of emergency for all new power shutoffs caused by drought. <n> the ']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text = [\n",
    "     \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
    "]\n",
    "\n",
    "model_name = 'google/pegasus-reddit_tifu'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "bmodel = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "translated = bmodel.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "summaries_pub = []\n",
    "k=0\n",
    "for i in df.Body[0:6]:\n",
    "    k+=1\n",
    "    batch = tokenizer(i, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    translated = bmodel.generate(**batch)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    \n",
    "    #f = open('aan_data_cnn_dailymail_summaries_r1.csv','a')\n",
    "    #f.write(tgt_text[0])\n",
    "    #f.write('\\n') \n",
    "    #f.close()\n",
    "    \n",
    "    summaries_pub.append(tgt_text)\n",
    "    if k % 10 == 1:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the aim of this paper is to describe a new method of text mining, which is based on the inked model. <n> inked model is a probabilistic model, which is used to estimate the odds of a text to be found in another language. <n> the aim of this paper is to describe a new method of text mining, which is based on the inked model. <n> it is a probabilistic model, which is used to estimate the odds of a text to be found in another language. <n> the aim of this paper is to describe a new method of text mining, which is based on the inked model. <n> it is a probabilistic model, which is used to estimate the odds of a text to be found in another language. <n> the aim of this paper is to describe a new method of text mining, which is based on the inked model. <n> it is a probabilistic model, which is used to estimate the odds of a text to be found in another language.imagesfigure 1.figure 2.figure 3.figure 4.figure 5.figure 6.figure 7.figure 8.figure 9.figure 10.figure 11.figure 12.figure 13.figure 14'],\n",
       " ['abstractthe aim of this paper is to introduce a new kind of interaction, in which a clerk or a person from the source language ( e.g. japanese ) or another person from the source language ( e.g. spanish ) or another person from the source language ( e.g. chinese ) or another person from the source language ( e.g. japanese ) or another person from the source language ( e.g. spanish ) or another person from the source language ( e.g. chinese ) or another person from the source language ( e.g. japanese ) or another person from the source language ( e.g. spanish ) or another person from the source language ( e.g. japanese ) or another person from the source language ( e.g. spanish ) or another person from the source language ( e.g. japanese ) or another person from the source language ( e.g. spanish ) or another person from the source language ( e.g. japanese ) or another person from the source language ( e.g. spanish ) or another person from the source language ( e.g. japanese ) or another person from the source language ( e'],\n",
       " ['background : the aim of this paper is to discuss the rationale for the use of reactive planning approach in education.materials and methods : a literature review was carried out to identify the literature on the use of the reactive planning approach in education.results:the use of the reactive planning approach in education can be divided into three parts. <n> the first part is the use of the dialogue approach. <n> the second part is the use of the dialogue approach. <n> the third part is the use of the dialogue approach. <n> the fourth part is the use of the dialogue approach.conclusion:the use of the reactive planning approach in education can be divided into three parts. <n> the first part is the use of the dialogue approach. <n> the second part is the use of the dialogue approach. <n> the third part is the use of the dialogue approach. <n> the fourth part is the use of the dialogue approach. <n> the fifth part is the use of the dialogue approach.conclusion:the use of the reactive planning approach in education can be divided into three parts. <n> the first part is the use of the dialogue approach. <n> the second part is the use'],\n",
       " ['this paper presents a framework for lexico dependency processing which consists of three steps : ( 1 ) generation of syntactic or or orgnathic modules, ( 2 ) ordering of modules, ( 3 ) mapping of modules, and ( 4 ) mapping of modules into trees. <n> the framework consists of portable environment for building syntactic or orgnathic modules. <n> it was developed by co - authors.'],\n",
       " ['on the basis of the results of a study by the university of ryerson, it has been determined that, in the general population of the city of ryerson, the concentration of total suspended particles ( tsp ) in the air is higher than that in the general population of the city of ryerson. <n> the concentrations of tsp in the general population of the city of ryerson are higher than those in the general population of the city of ryerson, but the difference is not significant. <n> the concentrations of tsp in the general population of the city of ryerson are higher than those in the general population of the city of ryerson, but the difference is not significant. <n> the concentrations of tsp in the general population of the city of ryerson are higher than those in the general population of the city of ryerson, but the difference is not significant. <n> the concentrations of tsp in the general population of the city of ryerson are higher than those in the general population of the city of ryerson, but the difference is not significant. <n> the concentrations of tsp in the general population of the city of ryerson are'],\n",
       " ['this paper describes the development of a portable dialogue system that enables the user to perform a task in a theater- like environment. <n> the aim of the dialogue system is to enable the user to perform a task in a theater- like environment, while acting as a dialogue system that enables the user to perform a dialogue task in a theater- like environment, while acting as a dialogue system that enables the user to perform a dialogue task in a theater- like environment. <n> the dialogue system consists of two modules. <n> the first module is a portable dialogue system that enables the user to perform a task in a theater- like environment, while acting as a dialogue system that enables the user to perform a dialogue task in a theater- like environment. <n> the second module is a portable dialogue system that enables the user to perform a dialogue task in a theater- like environment, while acting as a dialogue system that enables the user to perform a dialogue task in a theater- like environment. <n> the aim of the dialogue system is to enable the user to perform a task in a theater- like environment, while acting as a dialogue system that enables the user to perform a dialogue task in a theater- like environment ']]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline pegasus-xsum results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = [\n",
    "     \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
    "]\n",
    "\n",
    "model_name = 'google/pegasus-xsum'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The superfield formalism of the Becchi-Rouet-StoraTyutin (BRST) and anti-BRST symmetry in the Lagrangian densities of the four (3 + 1)-dimensional (4D) (non-)Abelian 1-form gauge theories within the framework of the superfield']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/xsum/arxiv.0704.0064.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-42875550908c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#save the summary to disk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/xsum/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/xsum/arxiv.0704.0064.json'"
     ]
    }
   ],
   "source": [
    "#generate xsum summaries\n",
    "ts = time.time()\n",
    "summaries = []\n",
    "limit = 10000\n",
    "for i,p in enumerate(papers):\n",
    "    \n",
    "    #skip inference on already summarized papers\n",
    "    f = filenames[i]\n",
    "    if os.path.exists(\"data/xsum/\"+f):\n",
    "        #load summary from disk\n",
    "        with open(\"data/xsum/\"+f) as inf:\n",
    "            tgt = json.load(inf)\n",
    "            summaries.append(tgt)\n",
    "        continue\n",
    "    \n",
    "    #body_sents = p[\"fulltext\"].split(\"\\n\\n\")\n",
    "    bts = time.time()\n",
    "    #start with a batch size of 1\n",
    "    batch = tokenizer(p[\"fulltext\"], truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    translated = model.generate(**batch)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    \n",
    "    #save the summary to disk\n",
    "    with open(\"data/xsum/\"+f, \"w\") as out:\n",
    "        json.dump(tgt_text, out)\n",
    "    \n",
    "    summaries.append(tgt_text)\n",
    "    bte = time.time()\n",
    "    \n",
    "    \n",
    "te = time.time()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9998\n"
     ]
    }
   ],
   "source": [
    "print(len(summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of 1.7711542308461692 seconds per summary\n"
     ]
    }
   ],
   "source": [
    "print(\"Average of {} seconds per summary\".format(int(te-ts)/len(summaries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Skewed parton distributions for simple, model wave-functions in a truncated two-body Fock space.']\n",
      "***\n",
      "The basic mechanism responsible for the widespread condensation of MgS in the\n",
      "outflows from carbon rich stars on the tip of the AGB is discussed with the aim\n",
      "of developing a condensation model that can be applied in model calculations of\n",
      "dust formation in stellar winds.\n",
      "  The different possibilities how MgS may be formed in the chemical environment\n",
      "of outflows from carbon stars are explored by some thermochemical calculations\n",
      "and by a detailed analysis of the growth kinetics of grains in stellar winds.\n",
      "The optical properties of core-mantle grains with a MgS mantle are calculated\n",
      "to demonstrate that such grains reproduce the structure of the observed 30\n",
      "$\\mu$m feature. These considerations are complemented by model calculations of\n",
      "circumstellar dust shells around carbon stars.\n",
      "  It is argued that MgS is formed via precipitation on silicon carbide grains.\n",
      "This formation mechanism explains some of the basic observed features of MgS\n",
      "condensation in dust shells around carbon stars. A weak secondary peak at about\n",
      "33 ... 36 $\\mu$m is shown to exist in certain cases if MgS forms a coating on\n",
      "SiC.\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(summaries[idx])\n",
    "print(\"***\")\n",
    "print(papers[idx][\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare summaries\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1','rouge2', 'rougeL','rougeLsum'], use_stemmer=True)\n",
    "scores = []\n",
    "for i,p in enumerate(papers):\n",
    "    if i >= len(summaries):\n",
    "        break\n",
    "    s = scorer.score(p[\"summary\"], summaries[i][0])\n",
    "    \n",
    "    #simpler flat structure\n",
    "    x = {\n",
    "        \"rouge1:precision\":s[\"rouge1\"][0],\n",
    "        \"rouge1:recall\":s[\"rouge1\"][1],\n",
    "        \"rouge1:fmeasure\":s[\"rouge1\"][2],\n",
    "        \"rouge2:precision\":s[\"rouge2\"][0],\n",
    "        \"rouge2:recall\":s[\"rouge2\"][1],\n",
    "        \"rouge2:fmeasure\":s[\"rouge2\"][2],\n",
    "        \"rougeL:precision\":s[\"rougeL\"][0],\n",
    "        \"rougeL:recall\":s[\"rougeL\"][1],\n",
    "        \"rougeL:fmeasure\":s[\"rougeL\"][2],\n",
    "        \"rougeLsum:precision\":s[\"rougeLsum\"][0],\n",
    "        \"rougeLsum:recall\":s[\"rougeLsum\"][1],\n",
    "        \"rougeLsum:fmeasure\":s[\"rougeLsum\"][2],\n",
    "        \n",
    "    }\n",
    "    scores.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1:precision': 0.21739130434782608,\n",
       " 'rouge1:recall': 0.024875621890547265,\n",
       " 'rouge1:fmeasure': 0.044642857142857144,\n",
       " 'rouge2:precision': 0.0,\n",
       " 'rouge2:recall': 0.0,\n",
       " 'rouge2:fmeasure': 0.0,\n",
       " 'rougeL:precision': 0.17391304347826086,\n",
       " 'rougeL:recall': 0.01990049751243781,\n",
       " 'rougeL:fmeasure': 0.03571428571428571,\n",
       " 'rougeLsum:precision': 0.21739130434782608,\n",
       " 'rougeLsum:recall': 0.024875621890547265,\n",
       " 'rougeLsum:fmeasure': 0.044642857142857144}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1:precision</th>\n",
       "      <th>rouge1:recall</th>\n",
       "      <th>rouge1:fmeasure</th>\n",
       "      <th>rouge2:precision</th>\n",
       "      <th>rouge2:recall</th>\n",
       "      <th>rouge2:fmeasure</th>\n",
       "      <th>rougeL:precision</th>\n",
       "      <th>rougeL:recall</th>\n",
       "      <th>rougeL:fmeasure</th>\n",
       "      <th>rougeLsum:precision</th>\n",
       "      <th>rougeLsum:recall</th>\n",
       "      <th>rougeLsum:fmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.690436</td>\n",
       "      <td>0.144746</td>\n",
       "      <td>0.222224</td>\n",
       "      <td>0.455679</td>\n",
       "      <td>0.097808</td>\n",
       "      <td>0.148836</td>\n",
       "      <td>0.594981</td>\n",
       "      <td>0.126543</td>\n",
       "      <td>0.193401</td>\n",
       "      <td>0.659299</td>\n",
       "      <td>0.138010</td>\n",
       "      <td>0.211909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300222</td>\n",
       "      <td>0.133742</td>\n",
       "      <td>0.161530</td>\n",
       "      <td>0.342651</td>\n",
       "      <td>0.128792</td>\n",
       "      <td>0.162442</td>\n",
       "      <td>0.302202</td>\n",
       "      <td>0.131228</td>\n",
       "      <td>0.160169</td>\n",
       "      <td>0.299202</td>\n",
       "      <td>0.130872</td>\n",
       "      <td>0.158718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.067335</td>\n",
       "      <td>0.118829</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.020051</td>\n",
       "      <td>0.034859</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.053691</td>\n",
       "      <td>0.094250</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.063202</td>\n",
       "      <td>0.112676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.113980</td>\n",
       "      <td>0.191781</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.056864</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.150741</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.107007</td>\n",
       "      <td>0.181534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.177597</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.123263</td>\n",
       "      <td>0.203580</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.151465</td>\n",
       "      <td>0.244847</td>\n",
       "      <td>0.915761</td>\n",
       "      <td>0.168675</td>\n",
       "      <td>0.269741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rouge1:precision  rouge1:recall  rouge1:fmeasure  rouge2:precision  \\\n",
       "count       2002.000000    2002.000000      2002.000000       2002.000000   \n",
       "mean           0.690436       0.144746         0.222224          0.455679   \n",
       "std            0.300222       0.133742         0.161530          0.342651   \n",
       "min            0.000000       0.000000         0.000000          0.000000   \n",
       "25%            0.500000       0.067335         0.118829          0.136364   \n",
       "50%            0.777778       0.113980         0.191781          0.411765   \n",
       "75%            0.944444       0.177597         0.285714          0.777778   \n",
       "max            1.000000       1.000000         1.000000          1.000000   \n",
       "\n",
       "       rouge2:recall  rouge2:fmeasure  rougeL:precision  rougeL:recall  \\\n",
       "count    2002.000000      2002.000000       2002.000000    2002.000000   \n",
       "mean        0.097808         0.148836          0.594981       0.126543   \n",
       "std         0.128792         0.162442          0.302202       0.131228   \n",
       "min         0.000000         0.000000          0.000000       0.000000   \n",
       "25%         0.020051         0.034859          0.375000       0.053691   \n",
       "50%         0.056864         0.098200          0.607143       0.089286   \n",
       "75%         0.123263         0.203580          0.875000       0.151465   \n",
       "max         1.000000         1.000000          1.000000       1.000000   \n",
       "\n",
       "       rougeL:fmeasure  rougeLsum:precision  rougeLsum:recall  \\\n",
       "count      2002.000000          2002.000000       2002.000000   \n",
       "mean          0.193401             0.659299          0.138010   \n",
       "std           0.160169             0.299202          0.130872   \n",
       "min           0.000000             0.000000          0.000000   \n",
       "25%           0.094250             0.461538          0.063202   \n",
       "50%           0.150741             0.727273          0.107007   \n",
       "75%           0.244847             0.915761          0.168675   \n",
       "max           1.000000             1.000000          1.000000   \n",
       "\n",
       "       rougeLsum:fmeasure  \n",
       "count         2002.000000  \n",
       "mean             0.211909  \n",
       "std              0.158718  \n",
       "min              0.000000  \n",
       "25%              0.112676  \n",
       "50%              0.181534  \n",
       "75%              0.269741  \n",
       "max              1.000000  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We prove that weighted majority functions of n independent unbiased 1-valued variables are uniformly stable under noise.']\n",
      "********************************************************************************\n",
      "Benjamini, Kalai and Schramm (2001) showed that weighted majority functions\n",
      "of $n$ independent unbiased bits are uniformly stable under noise: when each\n",
      "bit is flipped with probability $\\epsilon$, the probability $p_\\epsilon$ that\n",
      "the weighted majority changes is at most $C\\epsilon^{1/4}$. They asked what is\n",
      "the best possible exponent that could replace 1/4. We prove that the answer is\n",
      "1/2. The upper bound obtained for $p_\\epsilon$ is within a factor of\n",
      "$\\sqrt{\\pi/2}+o(1)$ from the known lower bound when $\\epsilon \\to 0$ and\n",
      "$n\\epsilon\\to \\infty$.\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "print(summaries[idx])\n",
    "print(\"*\"*80)\n",
    "print(papers[idx][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline pegasus-arxiv results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = [\n",
    "     \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
    "]\n",
    "\n",
    "model_name = 'google/pegasus-arxiv'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "amodel = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "translated = amodel.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate summaries\n",
    "ts = time.time()\n",
    "asummaries = []\n",
    "limit = 1000\n",
    "for i,p in enumerate(papers):\n",
    "    #body_sents = p[\"fulltext\"].split(\"\\n\\n\")\n",
    "    \n",
    "    #skip inference on already summarized papers\n",
    "    f = filenames[i]\n",
    "    if os.path.exists(\"data/pegasus_arxiv/\"+f):\n",
    "        #load summary from disk\n",
    "        with open(\"data/pegasus_arxiv/\"+f) as inf:\n",
    "            tgt = json.load(inf)\n",
    "            asummaries.append(tgt)\n",
    "        continue\n",
    "    \n",
    "    bts = time.time()\n",
    "    #start with a batch size of 1\n",
    "    batch = tokenizer(p[\"fulltext\"], truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    translated = amodel.generate(**batch)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    asummaries.append(tgt_text)\n",
    "    bte = time.time()\n",
    "    \n",
    "    #save the summary to disk\n",
    "    with open(\"data/pegasus_arxiv/\"+f, \"w\") as out:\n",
    "        json.dump(tgt_text, out)\n",
    "    \n",
    "te = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascores = []\n",
    "for i,p in enumerate(papers):\n",
    "    if i >= len(asummaries):\n",
    "        break\n",
    "    s = scorer.score(p[\"summary\"], summaries[i][0])\n",
    "    \n",
    "    #simpler flat structure\n",
    "    x = {\n",
    "        \"rouge1:precision\":s[\"rouge1\"][0],\n",
    "        \"rouge1:recall\":s[\"rouge1\"][1],\n",
    "        \"rouge1:fmeasure\":s[\"rouge1\"][2],\n",
    "        \"rouge2:precision\":s[\"rouge2\"][0],\n",
    "        \"rouge2:recall\":s[\"rouge2\"][1],\n",
    "        \"rouge2:fmeasure\":s[\"rouge2\"][2],\n",
    "        \"rougeL:precision\":s[\"rougeL\"][0],\n",
    "        \"rougeL:recall\":s[\"rougeL\"][1],\n",
    "        \"rougeL:fmeasure\":s[\"rougeL\"][2],\n",
    "        \"rougeLsum:precision\":s[\"rougeLsum\"][0],\n",
    "        \"rougeLsum:recall\":s[\"rougeLsum\"][1],\n",
    "        \"rougeLsum:fmeasure\":s[\"rougeLsum\"][2],\n",
    "        \n",
    "    }\n",
    "    ascores.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1:precision</th>\n",
       "      <th>rouge1:recall</th>\n",
       "      <th>rouge1:fmeasure</th>\n",
       "      <th>rouge2:precision</th>\n",
       "      <th>rouge2:recall</th>\n",
       "      <th>rouge2:fmeasure</th>\n",
       "      <th>rougeL:precision</th>\n",
       "      <th>rougeL:recall</th>\n",
       "      <th>rougeL:fmeasure</th>\n",
       "      <th>rougeLsum:precision</th>\n",
       "      <th>rougeLsum:recall</th>\n",
       "      <th>rougeLsum:fmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1002.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "      <td>1002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.683712</td>\n",
       "      <td>0.140633</td>\n",
       "      <td>0.217190</td>\n",
       "      <td>0.449862</td>\n",
       "      <td>0.093938</td>\n",
       "      <td>0.144174</td>\n",
       "      <td>0.589455</td>\n",
       "      <td>0.122371</td>\n",
       "      <td>0.188390</td>\n",
       "      <td>0.653081</td>\n",
       "      <td>0.133835</td>\n",
       "      <td>0.206797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302874</td>\n",
       "      <td>0.127867</td>\n",
       "      <td>0.157005</td>\n",
       "      <td>0.340083</td>\n",
       "      <td>0.121041</td>\n",
       "      <td>0.155497</td>\n",
       "      <td>0.304572</td>\n",
       "      <td>0.124171</td>\n",
       "      <td>0.154270</td>\n",
       "      <td>0.300739</td>\n",
       "      <td>0.124504</td>\n",
       "      <td>0.153503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.066336</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.033946</td>\n",
       "      <td>0.360909</td>\n",
       "      <td>0.053070</td>\n",
       "      <td>0.093842</td>\n",
       "      <td>0.450403</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.109631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.185499</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.056259</td>\n",
       "      <td>0.096515</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.146924</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.104707</td>\n",
       "      <td>0.177345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.172733</td>\n",
       "      <td>0.281480</td>\n",
       "      <td>0.766176</td>\n",
       "      <td>0.115623</td>\n",
       "      <td>0.197734</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.145739</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.166322</td>\n",
       "      <td>0.265256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rouge1:precision  rouge1:recall  rouge1:fmeasure  rouge2:precision  \\\n",
       "count       1002.000000    1002.000000      1002.000000       1002.000000   \n",
       "mean           0.683712       0.140633         0.217190          0.449862   \n",
       "std            0.302874       0.127867         0.157005          0.340083   \n",
       "min            0.000000       0.000000         0.000000          0.000000   \n",
       "25%            0.500000       0.066336         0.118387          0.133333   \n",
       "50%            0.769231       0.111111         0.185499          0.400000   \n",
       "75%            0.937500       0.172733         0.281480          0.766176   \n",
       "max            1.000000       1.000000         1.000000          1.000000   \n",
       "\n",
       "       rouge2:recall  rouge2:fmeasure  rougeL:precision  rougeL:recall  \\\n",
       "count    1002.000000      1002.000000       1002.000000    1002.000000   \n",
       "mean        0.093938         0.144174          0.589455       0.122371   \n",
       "std         0.121041         0.155497          0.304572       0.124171   \n",
       "min         0.000000         0.000000          0.000000       0.000000   \n",
       "25%         0.019512         0.033946          0.360909       0.053070   \n",
       "50%         0.056259         0.096515          0.608696       0.088235   \n",
       "75%         0.115623         0.197734          0.875000       0.145739   \n",
       "max         1.000000         1.000000          1.000000       1.000000   \n",
       "\n",
       "       rougeL:fmeasure  rougeLsum:precision  rougeLsum:recall  \\\n",
       "count      1002.000000          1002.000000       1002.000000   \n",
       "mean          0.188390             0.653081          0.133835   \n",
       "std           0.154270             0.300739          0.124504   \n",
       "min           0.000000             0.000000          0.000000   \n",
       "25%           0.093842             0.450403          0.060606   \n",
       "50%           0.146924             0.722222          0.104707   \n",
       "75%           0.236842             0.904762          0.166322   \n",
       "max           1.000000             1.000000          1.000000   \n",
       "\n",
       "       rougeLsum:fmeasure  \n",
       "count         1002.000000  \n",
       "mean             0.206797  \n",
       "std              0.153503  \n",
       "min              0.000000  \n",
       "25%              0.109631  \n",
       "50%              0.177345  \n",
       "75%              0.265256  \n",
       "max              1.000000  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascores_df = pd.DataFrame(ascores)\n",
    "ascores_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLITTING PARAGRAPHS\n",
    "# SPLITTING PARAGRAPHS\n",
    "# SPLITTING PARAGRAPHS\n",
    "# SPLITTING PARAGRAPHS\n",
    "# SPLITTING PARAGRAPHS\n",
    "# SPLITTING PARAGRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Body</th>\n",
       "      <th>Citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A major obstacle to the construction ofa pro...</td>\n",
       "      <td>Parallel texts have been used in a number of...</td>\n",
       "      <td>A compilation of parallel texts offered in a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This paper proposes a way to improve the tran...</td>\n",
       "      <td>Recently, various dialogue translation syste...</td>\n",
       "      <td>We plan to improve the accuracy obtained so fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This paper describes an application of APE (t...</td>\n",
       "      <td>The purpose of the Atlas project is to enlarg...</td>\n",
       "      <td>Computer dialogue is now used at production st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this paper we describe an implemented fram...</td>\n",
       "      <td>In this paper we present a linguistically mot...</td>\n",
       "      <td>From this viewpoint, research on paraphrasing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This paper reports on a large-scale, end-to- ...</td>\n",
       "      <td>One major goal of information extraction (IE)...</td>\n",
       "      <td>For example, Aone and Ramos-Santacruz (2000) p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>We present in this paper an unsupervised meth...</td>\n",
       "      <td>Development of electronic morphological resou...</td>\n",
       "      <td>Next along the spectrum of orthographic simila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>This paper presents an unsupervised method fo...</td>\n",
       "      <td>Choosing the correct translation of a content...</td>\n",
       "      <td>For comparable corpora, previous bilingual sen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>In this paper we report on an unsupervised a...</td>\n",
       "      <td>In this paper we discuss a potential solutio...</td>\n",
       "      <td>Watkinson and Manandhar (1999) present an unsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>This paper presents results from a study comp...</td>\n",
       "      <td>In evaluating the state of technology for ext...</td>\n",
       "      <td>It may be noted that \"correctly\" is a problema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>Over the past few years, HNC has developed a ...</td>\n",
       "      <td>While the current MatchPlus learning law has ...</td>\n",
       "      <td>As such a matrix reduction, we utilized a lear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4273 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Abstract  \\\n",
       "0       A major obstacle to the construction ofa pro...   \n",
       "1      This paper proposes a way to improve the tran...   \n",
       "2      This paper describes an application of APE (t...   \n",
       "3      In this paper we describe an implemented fram...   \n",
       "4      This paper reports on a large-scale, end-to- ...   \n",
       "...                                                 ...   \n",
       "4268   We present in this paper an unsupervised meth...   \n",
       "4269   This paper presents an unsupervised method fo...   \n",
       "4270    In this paper we report on an unsupervised a...   \n",
       "4271   This paper presents results from a study comp...   \n",
       "4272   Over the past few years, HNC has developed a ...   \n",
       "\n",
       "                                                   Body  \\\n",
       "0       Parallel texts have been used in a number of...   \n",
       "1       Recently, various dialogue translation syste...   \n",
       "2      The purpose of the Atlas project is to enlarg...   \n",
       "3      In this paper we present a linguistically mot...   \n",
       "4      One major goal of information extraction (IE)...   \n",
       "...                                                 ...   \n",
       "4268   Development of electronic morphological resou...   \n",
       "4269   Choosing the correct translation of a content...   \n",
       "4270    In this paper we discuss a potential solutio...   \n",
       "4271   In evaluating the state of technology for ext...   \n",
       "4272   While the current MatchPlus learning law has ...   \n",
       "\n",
       "                                              Citations  \n",
       "0     A compilation of parallel texts offered in a s...  \n",
       "1     We plan to improve the accuracy obtained so fa...  \n",
       "2     Computer dialogue is now used at production st...  \n",
       "3     From this viewpoint, research on paraphrasing ...  \n",
       "4     For example, Aone and Ramos-Santacruz (2000) p...  \n",
       "...                                                 ...  \n",
       "4268  Next along the spectrum of orthographic simila...  \n",
       "4269  For comparable corpora, previous bilingual sen...  \n",
       "4270  Watkinson and Manandhar (1999) present an unsu...  \n",
       "4271  It may be noted that \"correctly\" is a problema...  \n",
       "4272  As such a matrix reduction, we utilized a lear...  \n",
       "\n",
       "[4273 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load our 10k data into a dataframe\n",
    "papers = []\n",
    "filenames = [] #keep a reference for later transformations\n",
    "\n",
    "abstracts2, bodys2, cits2 =[],[],[]\n",
    "\n",
    "for root, dirs, files in os.walk(DATASET_PATH):\n",
    "    for f in files:\n",
    "        fn = root+\"/\"+f\n",
    "        if \"abstract\" in fn:            \n",
    "            in_file = open(fn, 'r')\n",
    "            file = in_file.readlines()\n",
    "\n",
    "            new_list = [''.join(file[i*4:(i+1)*4]) for i in range(int(len(file)/4))]\n",
    "            list_no_n = [item.replace('\\n','') for item in new_list]\n",
    "\n",
    "            string = ''\n",
    "            for item in list_no_n:\n",
    "                string = string + item            \n",
    "            abstracts2.append(string)\n",
    "            \n",
    "        elif \"body\" in fn:\n",
    "            in_file = open(fn, 'r')\n",
    "            file = in_file.readlines()\n",
    "\n",
    "            new_list = [''.join(file[i*4:(i+1)*4]) for i in range(int(len(file)/4))]\n",
    "            \n",
    "            list_no_n = [item.replace('. \\n','@@@@@').replace('\\n','').replace('- ','').replace(\"\\'\", \"\") for item in new_list]\n",
    "            #list_no_n = [item for item in new_list]\n",
    "            string = ''\n",
    "            for item in list_no_n:\n",
    "                string = string + item            \n",
    "            bodys2.append(string)\n",
    "        \n",
    "        elif \"CS\" in fn:\n",
    "            in_file = open(fn, 'r')\n",
    "            file = in_file.readlines()\n",
    "            string = [''.join(file) for i in file]\n",
    "            if len(string) > 0: \n",
    "                string = [''.join(file) for i in file][0].replace('\\n','')\n",
    "            cits2.append(string)\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #    with open(fn) as jsonfile:\n",
    "    #        d = json.load(jsonfile)\n",
    "    #    papers.append(d)\n",
    "    #    filenames.append(f)\n",
    "\n",
    "df2 = pd.DataFrame({'Abstract':abstracts2,'Body':bodys2,'Citations':cits2})\n",
    "df2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Parallel texts have been used in a number of studies in computational linguistics. Brown et al (1993) defined a series of probabilistic translation models for MT purposes. While people may question the effectiveness of using these models for a full-blown MT system, the models are certainly valuable for developing translation assistance tools. For example, we can use such a translation model to help complete target ext being drafted by a human translator (Langlais et al, 2000)@@@@@Another utilization is in cross-language information retrieval (CLIR) where queries have to be translated from one language to another language in which the documents are written. In CLIR, the quality requirement for translation is relatively low. For example, the syntactic aspect is irrelevant. Even if the translated word is not a true translation but is strongly related to the original query, it is still helpful. Therefore, CLIR is a suitable application for such a translation model@@@@@However, a major obstacle to this approach is the lack of parallel corpora for model training. Only a few such corpora exist, including the Hansard English-French corpus and the HKUST EnglishChinese corpus (Wu, 1994). In this paper, we will describe a method which automatically searches for parallel texts on the Web. We will discuss the text mining algorithm we adopted, some issues in translation model training using the generated parallel corpus, and finally the translation models performance in CLIR@@@@@2 Para l le l  Text  M in ing  A lgor i thm The PTMiner system is an intelligent Web agent that is designed to search for large amounts of parallel text on the Web. The mining algorithm is largely language independent. It can thus be adapted to other language pairs with only minor modifications@@@@@Taking advantage ofWeb search engines as much as possible, PTMiner implements he following steps (illustrated in Fig. 1): 1 Search for candidate sites Using existing Web search engines, search for the candidate sites that may contain parallel pages; 2 File name fetching For each candidate site, fetch the URLs of Web pages that are indexed by the search engines; 3 Host crawling Starting from the URLs collected in the previous tep, search through each candidate site separately for more URLs; 4 Pair scan From the obtained URLs of each site, scan for possible parallel pairs; 5 Download and verifying Download the parallel pages, determine file size, language, and character set of each page, and filter out non-parallel pairs@@@@@2.1 Search for candidate Sites We take advantage of the huge number of Web sites indexed by existing search engines in determining candidate sites. This is done by submitting some particular equests to the search engines. The requests are determined according to the following observations. In the sites where parallel text exists, there are normally some pages in one language containing links to the parallel version in the other language. These are usually indicated by those links anchor texts 1. For example, on some English page there may be a link to its Chinese version with the anchor text \"Chinese Version\" or \"in Chinese\"@@@@@1An anchor text  is a piece of text on a Web page which, when clicked on, will take you to another linked page. To be helpful, it usual ly  contains the key information about the l inked page@@@@@21 Figure 1: The workflow of the mining process@@@@@The same phenomenon can be observed on Chinese pages. Chances are that a site with parallel texts will contain such links in some of its documents@@@@@This fact is used as the criterion in searching for candidate sites@@@@@Therefore, to determine possible sites for EnglishChinese parallel texts, we can request an English document containing the following anchor: anchor : \"engl ish version H \\\\[\"in english\", ...\\\\]@@@@@Similar requests are sent for Chinese documents@@@@@From the two sets of pages obtained by the above queries we extract wo sets of Web sites. The union of these two sets constitutes then the candidate sites@@@@@That  is to say, a site is a candidate site when it is found to have either an English page linking to its Chinese version or a Chinese page linking to its English version@@@@@2.2 File Name Fetching We now assume that a pair of parallel texts exists on the same site. To search for parallel pairs on a site, PTMiner first has to obtain all (or at least part of) the HTML file names on the site. From these names pairs are scanned. It is possible to use a Web crawler to explore the candidate sites completely. However, we can take advantage of the search engines again to accelerate the process. As the first step, we submit the following query to the search engines: host : hostname to fetch the Web pages that they indexed from this site. If we only require a small amount of parallel texts, this result may be sufficient. For our purpose, however, we need to explore the sites more thoroughly using a host crawler. Therefore, we continue our search for files with a host crawler which uses the documents found by the search engines as the starting point@@@@@2.3 Host Crawling A host crawler is slightly different from a Web crawler. Web crawlers go through innumerable pages and hosts on the Web. A host crawler is a Web crawler that crawls through documents on a given host only. A breadth-first crawling algorithm is applied in PTMiner as host crawler. The principle is that when a link to an unexplored ocument on the same site is found in a document, it is added to a list that will be explored later. In this way, most file names from the candidate sites are obtained@@@@@2.4 Pair Scan After collecting file names for each candidate site, the next task is to determine the parallel pairs@@@@@Again, we try to use some heuristic rules to guess which files may be parallel texts before downloading them. The rules are based on external features of the documents. By external feature, we mean those features which may be known without analyzing the contents of the file, such as its URL, size, and date@@@@@This is in contrast with the internal features, such as language, character set, and HTML structure, which cannot be known until we have downloaded the page and analyzed its contents@@@@@The heuristic criterion comes from the following observation: We observe that parallel text pairs usually have similar name patterns. The difference between the names of two parailel pages usually lies in a segment which indicates the language. For example, \"file-ch.html\" (in Chinese) vs. \"file-en.html\" (in English). The difference may also appear in the path, such as \".../chinese/.../fi le.html\" vs. \".../english/.../f i le.html. The name patterns described above are commonly used by webmasters to help organize their sites. Hence, we can suppose that a pair of pages with this kind of pattern are probably parallel texts@@@@@22First, we establish four lists for English prefixes, English suffixes, Chinese prefixes and Chinese suffixes. For example: Engl ish P re f ix  = {e, en, e_, en_, e ,  en ,  ...}. For each file in one language, if a segment in its name corresponds to one of the language affixes, several new names are generated by changing the segment to the possible corresponding affixes of the other language. If a generated name corresponds to an existing file, then the file is considered as a candidate parallel document of the original file@@@@@2.5 Filtering Next, we further examine the contents of the paired files to determine if they are really parallel according to various external and internal features. This may further improve the pairing precision. The following methods have been implemented in our system@@@@@2.5.1 Text Length Parallel files often have similar file lengths. One simple way to filter out incorrect pairs is to compare the lengths of the two files. The only problem is to set a reasonable threshold that will not discard too many good pairs, i.e. balance recall and precision@@@@@The usual difference ratio depends on the language pairs we are dealing with. For example, ChineseEnglish parallel texts usually have a larger difference ratio than English-French parallel texts. The filtering threshold had to be determined empirically, from the actual observations. For Chinese-English, a difference up to 50% is tolerated@@@@@2.5.2 Language and  Character Set It is also obvious that the two files of a pair have to be in the two languages of interest. By automatically identifying language and character set, we can filter out the pairs that do not satisfy this basic criterion. Some Web pages explicitly indicate the language and the character set. More often such information is omitted by authors. We need some language identification tool for this task@@@@@SILC is a language and encoding identification system developed by the RALI laboratory at the University of Montreal. It employs a probabilistic model estimated on tri-grams. Using these models, the system is able to determine the most probable language and encoding of a text (Isabelle et al, 1997)@@@@@2.5.3 HTML Structure and Alignment In the STRAND system (Resnik, 1998), the candidate pairs are evaluated by aligning them according to their HTML structures and computing confidence values. Pairs are assumed to be wrong if they have too many mismatching markups or low confidence values@@@@@Comparing HTML structures seems to be a sound way to evaluate candidate pairs since parallel pairs usually have similar HTML structures. However, we also noticed that parallel texts may have quite different HTML structures. One of the reasons is that the two files may be created using two HTML editors. For example, one may be used for English and another for Chinese, depending on the language handling capability of the editors. Therefore, caution is required when measuring structure difference numerically@@@@@Parallel text alignment is still an experimental area. Measuring the confidence values of an alignment is even more complicated. For example, the alignment algorithm we used in the training of the statistical translation model produces acceptable alignment results but it does not provide a confidence value that we can \"confidently\" use as an evaluation criterion. So, for the moment his criterion is not used in candidate pair evaluation@@@@@3 Generated  Corpus  and Trans la t ion  Mode l  Tra in ing  In this section, we describe the results of our parallel text mining and translation model training@@@@@3.1 The Corpus Using the above approach for Chinese-English, 185 candidate sites were searched from the domain hk@@@@@We limited the mining domain to hk because Hong Kong is a bilingual English-Chinese city where high quality parallel Web sites exist. Because of the small number of candidate sites, the host crawler was used to thoroughly explore each site. The resulting corpus contains 14820 pairs of texts including 117.2Mb Chinese texts and 136.5Mb English texts. The entire mining process lasted about a week. Using length comparison and language identification, we refined the precision of the corpus to about 90%. The precision is estimated by examining 367 randomly picked pairs@@@@@3.2 Statistical Translation Model Many approaches in computational linguistics try to extract ranslation knowledge from previous translation examples. Most work of this kind establishes probabilistic models from parallel corpora. Based on one of the statistical models proposed by Brown et al (1993), the basic principle of our translation model is the following: given a corpus of aligned sentences, if two words often co-occur in the source and target sentences, there is a good likelihood that they are translations of each other. In the simplest case (model 1), the model earns the probability, p(tls), of having a word t in the translation of a sentence containing a word s. For an input sentence, the model then calculates a sequence of words that are most probable to appear in its translation. Using a similar statistical model, Wu (1995) extracted a largescale English-Chinese l xicon from the HKUST cor23  <s id=\"00~\"> <HTML> <HEAD> <META HTrP-EQUIV=\"Content-type\" CONTENT=\"text/html; charset--iso-8859-1\"> <META HTIP-EQUIV=\"Content-language\" CONTENT=\"Western\"> </s> <s id=\"0001\"> <TITLE>Journal of Primary Education 1996, VoI., No. l&2, pp. 19-27 </TITLE> </HEAD> </s> <s id=\"0002\"> <BODY BACKGROUND=\".Jgif/pejbg.jpg\" TEXT=\"#000(3(O\" BGCOLOR=\"#ffffff\"> <CENTER> </s> <s id=\"0003\"> <HI>Journal of Primary Education </HI> </s> <s id=\"0004\"> <HR> <B>Volume 6, No l&2, pp. 19-27 (May, 1996) </B> <HR> </s> <s id=\"0005\"> <H3>Principles for Redesigning Teacher Education </H3> Alan TOM </CENTER> </s> <s id=\"0006\"> <P> <B> <I> Abstract </I> </B> </s> <s id=\"0000\"> <HTML> <HEAD> <META HITP-EQUW=\"Content-type\" CONTENT=\"text/html; charset=bigS\"> <META HTTP-EQUIV=\"Content-language\" CONTENT=\"zh\"> <Is> <s id=\"0001\"> <TITLE> Journal of Primary Education 1996, Vol., No. l&2, Page 19-27 </TITLE> </HEAD> </s> <s id=\"0002\"> <BODY BACKGROUND=\".Jgif/pejbg.jpg\" TEXT=\"#000000\" BGCOLOR=\"#ffffff\"> <A HREF=\"/erdpej/b2g__pej.phtml?URL=%2fen%2fp ej%2f0601%2f0601019c.htm\"> <IMG SRC=\"/en/gif/kan.gif\" ALT=\"~\"  BORDER=0 ALIGN=R IGHT> </A> <CENTER> </s> <s id=\"0003\"> <H2>~ ~ 11I ~ O.</H2> </s> <s id=\"0004\"> <HR> (~:~h-fv-c?.JLJl) ~,-\\\\]?~.@@@@@</s> <s id=\"0005\"> ~ 19-27\\\\]~ <I-1R> </s> Figure 2: An alignment example using pure length-based method@@@@@pus which is built manually. In our case, the probabilistic translation model will be used for CLIR@@@@@The requirement on our translation model may be less demanding: it is not absolutely necessary that a word t with high p(tls ) always be a true translation of s. It is still useful if t is strongly related to s. For example, although \"railway\" is not a true translation of \"train\" (in French), it is highly useful to include \"railway\" in the translation of a query on \"train\". This is one of the reasons why we think a less controlled parallel corpus can be used to train a translation model for CLIR@@@@@3.3 Parallel Text Al ignment Before the mined documents can be aligned into parallel sentences, the raw texts have to undergo a series of some preprocessing, which, to some extent, is language dependent. For example, the major operations on the Chinese-English corpus include encoding scheme transformation (for Chinese), sentence level segmentation, parallel text alignment, Chinese word segmentation (Nie et al, 1999) and English expression extraction@@@@@The parallel Web pages we collected from various sites are not all of the same quality. Some are highly parallel and easy to align while others can be very noisy. Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages. A number of alignment techniques have been proposed, varying from statistical methods (Brown et al, 1991; Gale and Church, 1991) to lexical methods (Kay and RSscheisen, 1993; Chen, 1993). The method we adopted is that of Simard et al (1992). Because it considers both length similarity and cognateness as alignment criteria, the method is more robust and better able to deal with noise than pure length-based methods@@@@@Cognates are identical sequences of characters in corresponding words in two languages. They are commonly found in English and French. In the case of English-Chinese alignment, where there are no cognates shared by the two languages, only the HTML markup in both texts are taken as cognates. Because the HTML structures of parallel pages are normally similar, the markup was found to be helpful for alignment@@@@@To illustrate how markup can help with the alignment, we align the same pair with both the pure length-based method of Gale & Church (Fig. 2), and the method of Simard et al (Fig. 3). First of all, we observe from the figures that the two texts are 24<s id=\"0000\"> <HTML> <HEAD> <META HTTP-EQUIV=\"Content-type\" CONTENT=\"text/html; charset=iso-8859-1 \"> <META HTTP-EQUIV=\"Content-language\" CONTENT=\"Westem\"> </s> <s id=\"0001\"> <TITLE>Journal of Primary Education 1996, Vol., No. l&2, pp. 19-27 </TITLE> </HEAD> </s> <s id=\"0002\"> <BODY BACKGROUND=-\". Jgif/pejbg.jpg\" TEXT=\"#000000\" BGCOLOR=\"#ffffff\"> <CENTER> </s> <s id=\"0003\"> <H 1 >Journal of Primary Education </H 1 > <Is> <s id=\"0004\"> <HR> <B>Volume 6,No l&2, pp. 19-27 (May, 1996) </B> <HR> </$> <s id=\"0000\"> <HTML> <HEAD> <META HTrP-EQUIV=\"Content-type\" CONTENT=\"text/html; charset=big5\"> <META HlTP-EQUIV=\"Content-language\" CONTENT=\"zh\"> <Is> <s id=\"0001\"> :<TITLE> Journal of Primary Education 1996, Vol., No. l&2, Page 19-27 </TITLE> </HEAD> </s> <s id=\"0002\"> <BODY BACKGROUND=-\". Jgiffpejbg.jpg\" TEXT=\"#O00000\" BGCOLOR=\"#fffffff> <A HREF=\"/ergpej/b2g_pej.phtml?URL=%2fen%2fp ej %2f0601%2 f0601019c.htm\"> <IMG SRC=\"/erdgif/kan.gif\" ALT=\"~k\" BORDER={) ALIGN=R IGHT> </A> <CEHTEIL~ </s> <s id=\"0003\"> <H2>~k ~ ~ ~\\\\[1.</H2> </s> <s id=\"0004\"> <HR> (~t~-~?-#cJL.~) ,-~?~@@@@@</s> <s id=\"0005\"> ~ $ ~  19-27 \\\\]~ <HR> <\\\\]s> <s id=\"0005\"> <s id=\"0006\"> <H3>Principles for Redesigning Teacher <H3>.~ k~4Vt ~~ ~ ~J </H3> Alan TOM Education </H3> Alan TOM </CENTER> </CENTER> <Is> <Is> <s id=\"0006\"> <s id=\"0007\"> <P> <B> <I> Abstract </I> </B> <P> <I> <B> ~4\\\\[</B> </I> <P> </s> </s> Figure 3: An alignment example considering cognates@@@@@divided into sentences. The sentences are marked by <s id=\"xxxx\"> and </s>.  Note that we determine sentences not only by periods, but also by means of HTML markup@@@@@We further notice that it is difficult to align sentences 0002. The sentence in the Chinese page is much longer than its counterpart in the English page because some additional information (font) is added@@@@@The length-based method thus tends to take sentence 0002, 0003, and 0004 in the English page as the translation of sentence 0002 in the Chinese page (Fig. 2), which is wrong. This in turn provocated the three following incorrect alignments. As we can see in Fig. 3, the cognate method did not make the same mistake because of the noise in sentence 0002@@@@@Despite their large length difference, the two 0002 sentences are still aligned as a 1-1 pair, because the sentences in the following 4 alignments (0003 0003; 0004 0004, 0005; 0005 0006; 0006 0007) have rather similar HTML markups and are taken by the program to be the most likely alignments@@@@@Beside HTML markups, other criteria may also be incorporated. For example, it would be helpful to consider strong correspondence b tween certain English and Chinese words, as in (Wu, 1994). We hope to implement such correspondences in our future research@@@@@3.4 Lex icon  Eva luat ion  To evaluate the precision of the English-Chinese translation model trained on the Web corpus, we examined two sample lexicons of 200 words, one in each direction. The 200 words for each lexicon were randomly selected from the training source. We examined the most probable translation for each word@@@@@The Chinese-English lexicon was found to have a precision of 77%. The English-Chinese l xicon has a higher precision of 81.5%. Part of the lexicons are shown in Fig. 4, where t / f  indicates whether a translation is true or false@@@@@These precisions seem to be reasonably high@@@@@They are quite comparable to that obtained by Wu (1994) using a manual Chinese-English parallel corpus@@@@@3.5 Effect  o f  S topwords  We also found that stop-lists have significant effect on the translation model. Stop-list is a set of the most frequent words that we remove from the train2fi English word a .n l .  access adaptation add adopt agent agree airline amendment , appliance apply attendance auditor ,average base_on t/f t f t t t t t t t t t t f t f Translmion Probability Chinese word ~~0.201472 ~t l :  ~\"  0.071705 \"~\"  ~f~.,~ 0.179633 JllL~ 0.317435 ~ 0.231637 ~.~ 1~tA~ 0.224902 4J~~ 0.36569 0.344001 0.367518 J~ 4~ 0.136319 i~.~I 0.19448 J~  ~,1~ 0.171769 ,~JJ~ *~ 0.15011 -~-~ ~~ 0.467646 * *~ 0.107304 Figure 4: Part of the evaluation lexicons@@@@@t/f t t t t t f t f t t t t t t t Translation Probability office 0.375868 protection 0.343071 report 0.358592 prepare 0.189513 loca l  0.421837 follow 0.023685 standard 0.445453 adu l t  0.044959 inadequate 0.093012 part 0.313676 financial 0.16608 visit 0.309642 bill 0.401997 vehicle 0.467034 saving 0.176695 Figure 5: Effect of stop lists in C-E translation@@@@@ing source. Because these words exist in most alignments, the statistical model cannot derive correct translations for them. More importantly, their existence greatly affects the accuracy of other translations. They can be taken as translations for many words@@@@@A priori, it would seem that both the English and Chinese stop-lists hould be applied to eliminate the noise caused by them. Interestingly, from our observation and analysis we concluded that for better precision, only the stop-list of the target language should be applied in the model training@@@@@We first explain why the stop-list of the target language has to be applied. On the left side of Fig. 5, if the Chinese word C exists in the same alignments with the English word E more than any other Chinese words, C will be the most probable translation for E. Because of their frequent appearance, some Chinese stopwords may have more chances to be in the same alignments with E. The probability of the translation E --+ C is then reduced (maybe ven less than those of the incorrect ones). This is the reason why many English words are translated to \"~   (of) by the translation model trained without using the Chinese stop-list@@@@@We also found that it is not necessary to remove the stopwords of the source language. In fact, as illustrated on the right side of Fig. 5, the existence of the English stopwords has two effects on the probability of the translation E -~ C: 1 They may often be found together with the Chinese word C. Owing to the Expectation Maximization algorithm, the probability of E -~ C may therefore be reduced@@@@@2 On the other hand, there is a greater likelihood that English stopwords will be found together with the most frequent Chinese words. Here, we use the term \"Chinese frequent words\" instead of \"Chinese stopwords\" because ven if a stop-list is applied, there may still remain some common words that have the same effect as the stopwords. The coexistence ofEnglish and Chinese frequent words reduces the probability that the Chinese frequent words are the translations of E, and thus raise the probability of E -+ C@@@@@The second effect was found to be more significant than the first, since the model trained without the English stopwords has better precision than the model trained with the English stopwords. For the correct ranslations given by both models, the model 26Mono-Lingual IR Translation Model Dictionary C-E CLIR 0.3861 0.1504 (39.0%mono) 0.1530 (39.6%mono) 0.2583 (66.9%mono) E-C CLIR 0.3976 0.1841 (46.3%mono) 0.1427 (35.9%mono) 0.2232 (56.1%mono) Table 1: CLIR results@@@@@trained without considering the English stopwords gives higher probabilities@@@@@4 Eng l i sh -Ch inese  CL IR  Resu l ts  Our final goal was to test the performance of the translation models trained on the Web parallel corpora in CLIR. We conducted CLIR experiments u ing the Smart IR system@@@@@4.1 Results  The English test corpus (for C-E CLIR) was the AP corpus used in TREC6 and TREC7. The short English queries were translated manually into Chinese and then translated back to English by the translation model. The Chinese test corpus was the one used in the TREC5 and TREC6 Chinese track@@@@@It contains both Chinese queries and their English translations@@@@@Our experiments on these two corpora produced the results hown in Tab. 1. The precision of monolingual IR is given as benchmark. In both E-C and C-E CLIR, the translation model achieved around 40% of monolingual precision. To compare with the dictionary-based approach, we employed a ChineseEnglish dictionary, CEDICT (Denisowski, 1999), and an English-Chinese online dictionary (Anonymous, 1999a) to translate queries. For each word of the source query, all the possible translations given by the dictionary are included in the translated query. The Chinese-English dictionary has about the same performace as the translation model, while the English-Chinese dictionary has lower precision than that of the translation model@@@@@We also tried to combine the translations given by the translation model and the dictionary. In both C-E and E-C CLIR, significant improvements were achieved (as shown in Tab. 1). The improvements show that the translations given by the translation model and the dictionary complement each other well for IR purposes. The translation model may give either exact ranslations orincorrect but related words. Even though these words are not correct in the sense of translation, they are very possibly related to the subject of the query and thus helpful for IR purposes. The dictionary-based approach expands a query along another dimension. It gives all the possible translations for each word including those that are missed by the translation model@@@@@4.2 Comparison Wi th  MT Systems One advantage of a parallel text-based translation model is that it is easier to build than an MT system@@@@@Now that we have examined the CLIR performance of the translation model, we will compare it with two existing MT systems. Both systems were tested in E-C CLIR@@@@@4.2.1 Sunshine WebTran Server Using the Sunshine WebTran server (Anonymous, 1999b), an online Engiish-Chinese MT system, to translate the 54 English queries, we obtained an average precision of 0.2001, which is 50.3% of the mono-lingual precision. The precision is higher than that obtained using the translation model (0.1804) or the dictionary (0.1427) alone, but lower than the precison obtained using them together (0.2232)@@@@@4.2.2 Transperfect Kwok (1999) investigated the CLIR performance ofan English-Chinese MT software called Transperfect, using the same TREC Chinese collection as we used in this study. Using the MT software alone, Kwok achieved 56% of monolingual precision. The precision is improved to 62% by refining the translation with a dictionary. Kwok also adopted pretranslation query expansion, which further improved the precison to 70% of the monolingual results@@@@@In our case, the best E-C CLIR precison using the translation model (and dictionary) is 56.1%. It is lower than what Kwok achieved using Transperfect, however, the difference is not large@@@@@4.3 Further  Problems The Chinese-English translation model has a fax lower CLIR performance than that of the EnglishFrench model established using the same method (Nie et al, 1999). The principal reason for this is the fact that English and Chinese are much more different than English and French. This problem surfaced in many phases of this work, from text alignment to query translation. Below, we list some further factors affecting CLIR precision@@@@@? The Web-collected corpus is noisy and it is difficult to align English-Chinese t xts. The alignment method we employed has performed more poorly than on English-French alignment. This in turn leads to poorer performance of the translation model. In general, we observe a higher 27 variability in Chinese-English translations than in English-French translations@@@@@? For E-C CLIR, although queries in both languages were provided, the English queries were not strictly translated from the original Chinese ones. For example, A Jg ,~ (human right situation) was translated into human right issue. We cannot expect he translation model to translate issue back to ~ (situation)@@@@@? The training source and the CLIR collections were from different domains. The Web corpus are retrieved from the parallel sites in Hong Kong while the Chinese collection is from Peoples Daily and Xinhua News Agency, which are published in mainland China. As the result, some important erms such as ~$ $ (mostfavored-nation) and --I!! ~ ~ (one-nation-twosystems) in the collection are not known by the model@@@@@5 Summary  The goal of this work was to investigate he feasibility of using a statistical translation model trained on a Web-collected corpus to do English-Chinese CLIR@@@@@In this paper, we have described the algorithm and implementation we used for parallel text mining, translation model training, and some results we obtained in CLIR experiments. Although further work remains to be done, we can conclude that it is possible to automatically construct a Chinese-English parallel corpus from the Web. The current system can be easily adapted to other language pairs. Despite the noisy nature of the corpus and the great difference in the languages, the evaluation lexicons generated by the translation model produced acceptable precision. While the current CLIR results are not as encouraging asthose of English-French CLIR, they could be improved in various ways, such as improving the alignment method by adapting cognate definitions to HTML markup, incorporating a lexicon and/or removing some common function words in translated queries@@@@@We hope to be able to demonstrate in the near future that a fine-tuned English-Chinese translation model can provide query translations for CLIR with the same quality produced by MT systems@@@@@Re ferences  Anonymous. 1999a. Sunrain.net English-Chinese dictionary, http://sunrain.net/r_ecdict _e.htm@@@@@Anonymous. 1999b. Sunshine WebTran server@@@@@http://www.readworld.com/translate.htm@@@@@P. F. Brown, J. C. Lai, and R. L. Mercer. 1991@@@@@Aligning sentences in parallel corpora. In 29th Annual Meeting of the Association for Computational Linguistics, pages 89-94, Berkeley, Calif@@@@@P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer. 1993. The mathematics of machine translation: Parameter estimation. Computational Linguistics, 19:263-311@@@@@S. F. Chen. 1993. Aligning sentences in bilingual corpora using lexical information. In Proceedings of the 31th Annual Meeting of the Association for Computational Linguistics, pages 9-16, Columbus, Ohio@@@@@Paul Denisowski. 1999. Cedict (chinese-english dictionary) project, http://www.mindspring.com/ paul_denisowski/cedict.html@@@@@William A. Gale and Kenneth W. Church. 1991. A program for aligning sentences in bilingual corpora. In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, pages 177-184, Berkeley, Calif@@@@@P. Isabelle, G. Foster, and P. Plamondon@@@@@1997. SILC: un syst~me didentification de la langue et du codage, http://wwwrali.iro.umontreal.ca/ProjetSILC.en.html@@@@@M. Kay and M. RSscheisen. 1993. Text-translation alignment. Computational Linguistics, 19:121142@@@@@K. L. Kwok. 1999. English-chinese cross-language retrieval based on a translation package. In Workshop of Machine Translation for Cross Language Information Retrieval, Machine Translation Summit VII, Singapore@@@@@P. Langlais, G. Foster, and G. Lapalme. 2000. Unit completion for a computer-aided translation typing system. In Applied Natural Language Processing Conference (ANLP), Seattle, Washington, May@@@@@Jianyun Nie, Michel Simard, Pierre Isabelle, and Richard Durand. 1999. Cross-language information retrieval based on parallel texts and automatic mining parallel texts from the Web. In ACM SIGIR 99, pages 74-81, August@@@@@Philip Resnik. 1998. Parallel stands: A preliminary investigation i to mining the Web for bilingual text. In AMTA 98, October@@@@@Michel Simard, George F. Foster, and Pierre Isabelle. 1992. Using cognates to align sentences in bilingual corpora. In Proceedings of TMI-92, Montreal, Quebec@@@@@Dekai Wu. 1994. Aligning a parallel EnglishChinese corpus statistically with lexical criteria@@@@@In ACL-9$: 32nd Annual Meeting of the Assoc@@@@@for Computational Linguistics, pages 80-87, Las Cruces, NM, June@@@@@Dekai Wu. 1995. Large-scale automatic extraction '"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.Body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Parallel texts have been used in a number of studies in computational linguistics. Brown et al (1993) defined a series of probabilistic translation models for MT purposes. While people may question the effectiveness of using these models for a full-blown MT system, the models are certainly valuable for developing translation assistance tools. For example, we can use such a translation model to help complete target ext being drafted by a human translator (Langlais et al, 2000)@@@@@Another utilization is in cross-language information retrieval (CLIR) where queries have to be translated from one language to another language in which the documents are written. In CLIR, the quality requirement for translation is relatively low. For example, the syntactic aspect is irrelevant. Even if the translated word is not a true translation but is strongly related to the original query, it is still helpful. Therefore, CLIR is a suitable application for such a translation model@@@@@However, a major obstacle to this approach is the lack of parallel corpora for model training. Only a few such corpora exist, including the Hansard English-French corpus and the HKUST EnglishChinese corpus (Wu, 1994). In this paper, we will describe a method which automatically searches for parallel texts on the Web. We will discuss the text mining algorithm we adopted, some issues in translation model training using the generated parallel corpus, and finally the translation models performance in CLIR@@@@@2 Para l le l  Text  M in ing  A lgor i thm The PTMiner system is an intelligent Web agent that is designed to search for large amounts of parallel text on the Web. The mining algorithm is largely language independent. It can thus be adapted to other language pairs with only minor modifications@@@@@Taking advantage ofWeb search engines as much as possible, PTMiner implements he following steps (illustrated in Fig. 1): 1 Search for candidate sites Using existing Web search engines, search for the candidate sites that may contain parallel pages; 2 File name fetching For each candidate site, fetch the URLs of Web pages that are indexed by the search engines; 3 Host crawling Starting from the URLs collected in the previous tep, search through each candidate site separately for more URLs; 4 Pair scan From the obtained URLs of each site, scan for possible parallel pairs; 5 Download and verifying Download the parallel pages, determine file size, language, and character set of each page, and filter out non-parallel pairs@@@@@2.1 Search for candidate Sites We take advantage of the huge number of Web sites indexed by existing search engines in determining candidate sites. This is done by submitting some particular equests to the search engines. The requests are determined according to the following observations. In the sites where parallel text exists, there are normally some pages in one language containing links to the parallel version in the other language. These are usually indicated by those links anchor texts 1. For example, on some English page there may be a link to its Chinese version with the anchor text \"Chinese Version\" or \"in Chinese\"@@@@@1An anchor text  is a piece of text on a Web page which, when clicked on, will take you to another linked page. To be helpful, it usual ly  contains the key information about the l inked page@@@@@21 Figure 1: The workflow of the mining process@@@@@The same phenomenon can be observed on Chinese pages. Chances are that a site with parallel texts will contain such links in some of its documents@@@@@This fact is used as the criterion in searching for candidate sites@@@@@Therefore, to determine possible sites for EnglishChinese parallel texts, we can request an English document containing the following anchor: anchor : \"engl ish version H \\\\[\"in english\", ...\\\\]@@@@@Similar requests are sent for Chinese documents@@@@@From the two sets of pages obtained by the above queries we extract wo sets of Web sites. The union of these two sets constitutes then the candidate sites@@@@@That  is to say, a site is a candidate site when it is found to have either an English page linking to its Chinese version or a Chinese page linking to its English version@@@@@2.2 File Name Fetching We now assume that a pair of parallel texts exists on the same site. To search for parallel pairs on a site, PTMiner first has to obtain all (or at least part of) the HTML file names on the site. From these names pairs are scanned. It is possible to use a Web crawler to explore the candidate sites completely. However, we can take advantage of the search engines again to accelerate the process. As the first step, we submit the following query to the search engines: host : hostname to fetch the Web pages that they indexed from this site. If we only require a small amount of parallel texts, this result may be sufficient. For our purpose, however, we need to explore the sites more thoroughly using a host crawler. Therefore, we continue our search for files with a host crawler which uses the documents found by the search engines as the starting point@@@@@2.3 Host Crawling A host crawler is slightly different from a Web crawler. Web crawlers go through innumerable pages and hosts on the Web. A host crawler is a Web crawler that crawls through documents on a given host only. A breadth-first crawling algorithm is applied in PTMiner as host crawler. The principle is that when a link to an unexplored ocument on the same site is found in a document, it is added to a list that will be explored later. In this way, most file names from the candidate sites are obtained@@@@@2.4 Pair Scan After collecting file names for each candidate site, the next task is to determine the parallel pairs@@@@@Again, we try to use some heuristic rules to guess which files may be parallel texts before downloading them. The rules are based on external features of the documents. By external feature, we mean those features which may be known without analyzing the contents of the file, such as its URL, size, and date@@@@@This is in contrast with the internal features, such as language, character set, and HTML structure, which cannot be known until we have downloaded the page and analyzed its contents@@@@@The heuristic criterion comes from the following observation: We observe that parallel text pairs usually have similar name patterns. The difference between the names of two parailel pages usually lies in a segment which indicates the language. For example, \"file-ch.html\" (in Chinese) vs. \"file-en.html\" (in English). The difference may also appear in the path, such as \".../chinese/.../fi le.html\" vs. \".../english/.../f i le.html. The name patterns described above are commonly used by webmasters to help organize their sites. Hence, we can suppose that a pair of pages with this kind of pattern are probably parallel texts@@@@@22First, we establish four lists for English prefixes, English suffixes, Chinese prefixes and Chinese suffixes. For example: Engl ish P re f ix  = {e, en, e_, en_, e ,  en ,  ...}. For each file in one language, if a segment in its name corresponds to one of the language affixes, several new names are generated by changing the segment to the possible corresponding affixes of the other language. If a generated name corresponds to an existing file, then the file is considered as a candidate parallel document of the original file@@@@@2.5 Filtering Next, we further examine the contents of the paired files to determine if they are really parallel according to various external and internal features. This may further improve the pairing precision. The following methods have been implemented in our system@@@@@2.5.1 Text Length Parallel files often have similar file lengths. One simple way to filter out incorrect pairs is to compare the lengths of the two files. The only problem is to set a reasonable threshold that will not discard too many good pairs, i.e. balance recall and precision@@@@@The usual difference ratio depends on the language pairs we are dealing with. For example, ChineseEnglish parallel texts usually have a larger difference ratio than English-French parallel texts. The filtering threshold had to be determined empirically, from the actual observations. For Chinese-English, a difference up to 50% is tolerated@@@@@2.5.2 Language and  Character Set It is also obvious that the two files of a pair have to be in the two languages of interest. By automatically identifying language and character set, we can filter out the pairs that do not satisfy this basic criterion. Some Web pages explicitly indicate the language and the character set. More often such information is omitted by authors. We need some language identification tool for this task@@@@@SILC is a language and encoding identification system developed by the RALI laboratory at the University of Montreal. It employs a probabilistic model estimated on tri-grams. Using these models, the system is able to determine the most probable language and encoding of a text (Isabelle et al, 1997)@@@@@2.5.3 HTML Structure and Alignment In the STRAND system (Resnik, 1998), the candidate pairs are evaluated by aligning them according to their HTML structures and computing confidence values. Pairs are assumed to be wrong if they have too many mismatching markups or low confidence values@@@@@Comparing HTML structures seems to be a sound way to evaluate candidate pairs since parallel pairs usually have similar HTML structures. However, we also noticed that parallel texts may have quite different HTML structures. One of the reasons is that the two files may be created using two HTML editors. For example, one may be used for English and another for Chinese, depending on the language handling capability of the editors. Therefore, caution is required when measuring structure difference numerically@@@@@Parallel text alignment is still an experimental area. Measuring the confidence values of an alignment is even more complicated. For example, the alignment algorithm we used in the training of the statistical translation model produces acceptable alignment results but it does not provide a confidence value that we can \"confidently\" use as an evaluation criterion. So, for the moment his criterion is not used in candidate pair evaluation@@@@@3 Generated  Corpus  and Trans la t ion  Mode l  Tra in ing  In this section, we describe the results of our parallel text mining and translation model training@@@@@3.1 The Corpus Using the above approach for Chinese-English, 185 candidate sites were searched from the domain hk@@@@@We limited the mining domain to hk because Hong Kong is a bilingual English-Chinese city where high quality parallel Web sites exist. Because of the small number of candidate sites, the host crawler was used to thoroughly explore each site. The resulting corpus contains 14820 pairs of texts including 117.2Mb Chinese texts and 136.5Mb English texts. The entire mining process lasted about a week. Using length comparison and language identification, we refined the precision of the corpus to about 90%. The precision is estimated by examining 367 randomly picked pairs@@@@@3.2 Statistical Translation Model Many approaches in computational linguistics try to extract ranslation knowledge from previous translation examples. Most work of this kind establishes probabilistic models from parallel corpora. Based on one of the statistical models proposed by Brown et al (1993), the basic principle of our translation model is the following: given a corpus of aligned sentences, if two words often co-occur in the source and target sentences, there is a good likelihood that they are translations of each other. In the simplest case (model 1), the model earns the probability, p(tls), of having a word t in the translation of a sentence containing a word s. For an input sentence, the model then calculates a sequence of words that are most probable to appear in its translation. Using a similar statistical model, Wu (1995) extracted a largescale English-Chinese l xicon from the HKUST cor23  <s id=\"00~\"> <HTML> <HEAD> <META HTrP-EQUIV=\"Content-type\" CONTENT=\"text/html; charset--iso-8859-1\"> <META HTIP-EQUIV=\"Content-language\" CONTENT=\"Western\"> </s> <s id=\"0001\"> <TITLE>Journal of Primary Education 1996, VoI., No. l&2, pp. 19-27 </TITLE> </HEAD> </s> <s id=\"0002\"> <BODY BACKGROUND=\".Jgif/pejbg.jpg\" TEXT=\"#000(3(O\" BGCOLOR=\"#ffffff\"> <CENTER> </s> <s id=\"0003\"> <HI>Journal of Primary Education </HI> </s> <s id=\"0004\"> <HR> <B>Volume 6, No l&2, pp. 19-27 (May, 1996) </B> <HR> </s> <s id=\"0005\"> <H3>Principles for Redesigning Teacher Education </H3> Alan TOM </CENTER> </s> <s id=\"0006\"> <P> <B> <I> Abstract </I> </B> </s> <s id=\"0000\"> <HTML> <HEAD> <META HITP-EQUW=\"Content-type\" CONTENT=\"text/html; charset=bigS\"> <META HTTP-EQUIV=\"Content-language\" CONTENT=\"zh\"> <Is> <s id=\"0001\"> <TITLE> Journal of Primary Education 1996, Vol., No. l&2, Page 19-27 </TITLE> </HEAD> </s> <s id=\"0002\"> <BODY BACKGROUND=\".Jgif/pejbg.jpg\" TEXT=\"#000000\" BGCOLOR=\"#ffffff\"> <A HREF=\"/erdpej/b2g__pej.phtml?URL=%2fen%2fp ej%2f0601%2f0601019c.htm\"> <IMG SRC=\"/en/gif/kan.gif\" ALT=\"~\"  BORDER=0 ALIGN=R IGHT> </A> <CENTER> </s> <s id=\"0003\"> <H2>~ ~ 11I ~ O.</H2> </s> <s id=\"0004\"> <HR> (~:~h-fv-c?.JLJl) ~,-\\\\]?~.@@@@@</s> <s id=\"0005\"> ~ 19-27\\\\]~ <I-1R> </s> Figure 2: An alignment example using pure length-based method@@@@@pus which is built manually. In our case, the probabilistic translation model will be used for CLIR@@@@@The requirement on our translation model may be less demanding: it is not absolutely necessary that a word t with high p(tls ) always be a true translation of s. It is still useful if t is strongly related to s. For example, although \"railway\" is not a true translation of \"train\" (in French), it is highly useful to include \"railway\" in the translation of a query on \"train\". This is one of the reasons why we think a less controlled parallel corpus can be used to train a translation model for CLIR@@@@@3.3 Parallel Text Al ignment Before the mined documents can be aligned into parallel sentences, the raw texts have to undergo a series of some preprocessing, which, to some extent, is language dependent. For example, the major operations on the Chinese-English corpus include encoding scheme transformation (for Chinese), sentence level segmentation, parallel text alignment, Chinese word segmentation (Nie et al, 1999) and English expression extraction@@@@@The parallel Web pages we collected from various sites are not all of the same quality. Some are highly parallel and easy to align while others can be very noisy. Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages. A number of alignment techniques have been proposed, varying from statistical methods (Brown et al, 1991; Gale and Church, 1991) to lexical methods (Kay and RSscheisen, 1993; Chen, 1993). The method we adopted is that of Simard et al (1992). Because it considers both length similarity and cognateness as alignment criteria, the method is more robust and better able to deal with noise than pure length-based methods@@@@@Cognates are identical sequences of characters in corresponding words in two languages. They are commonly found in English and French. In the case of English-Chinese alignment, where there are no cognates shared by the two languages, only the HTML markup in both texts are taken as cognates. Because the HTML structures of parallel pages are normally similar, the markup was found to be helpful for alignment@@@@@To illustrate how markup can help with the alignment, we align the same pair with both the pure length-based method of Gale & Church (Fig. 2), and the method of Simard et al (Fig. 3). First of all, we observe from the figures that the two texts are 24<s id=\"0000\"> <HTML> <HEAD> <META HTTP-EQUIV=\"Content-type\" CONTENT=\"text/html; charset=iso-8859-1 \"> <META HTTP-EQUIV=\"Content-language\" CONTENT=\"Westem\"> </s> <s id=\"0001\"> <TITLE>Journal of Primary Education 1996, Vol., No. l&2, pp. 19-27 </TITLE> </HEAD> </s> <s id=\"0002\"> <BODY BACKGROUND=-\". Jgif/pejbg.jpg\" TEXT=\"#000000\" BGCOLOR=\"#ffffff\"> <CENTER> </s> <s id=\"0003\"> <H 1 >Journal of Primary Education </H 1 > <Is> <s id=\"0004\"> <HR> <B>Volume 6,No l&2, pp. 19-27 (May, 1996) </B> <HR> </$> <s id=\"0000\"> <HTML> <HEAD> <META HTrP-EQUIV=\"Content-type\" CONTENT=\"text/html; charset=big5\"> <META HlTP-EQUIV=\"Content-language\" CONTENT=\"zh\"> <Is> <s id=\"0001\"> :<TITLE> Journal of Primary Education 1996, Vol., No. l&2, Page 19-27 </TITLE> </HEAD> </s> <s id=\"0002\"> <BODY BACKGROUND=-\". Jgiffpejbg.jpg\" TEXT=\"#O00000\" BGCOLOR=\"#fffffff> <A HREF=\"/ergpej/b2g_pej.phtml?URL=%2fen%2fp ej %2f0601%2 f0601019c.htm\"> <IMG SRC=\"/erdgif/kan.gif\" ALT=\"~k\" BORDER={) ALIGN=R IGHT> </A> <CEHTEIL~ </s> <s id=\"0003\"> <H2>~k ~ ~ ~\\\\[1.</H2> </s> <s id=\"0004\"> <HR> (~t~-~?-#cJL.~) ,-~?~@@@@@</s> <s id=\"0005\"> ~ $ ~  19-27 \\\\]~ <HR> <\\\\]s> <s id=\"0005\"> <s id=\"0006\"> <H3>Principles for Redesigning Teacher <H3>.~ k~4Vt ~~ ~ ~J </H3> Alan TOM Education </H3> Alan TOM </CENTER> </CENTER> <Is> <Is> <s id=\"0006\"> <s id=\"0007\"> <P> <B> <I> Abstract </I> </B> <P> <I> <B> ~4\\\\[</B> </I> <P> </s> </s> Figure 3: An alignment example considering cognates@@@@@divided into sentences. The sentences are marked by <s id=\"xxxx\"> and </s>.  Note that we determine sentences not only by periods, but also by means of HTML markup@@@@@We further notice that it is difficult to align sentences 0002. The sentence in the Chinese page is much longer than its counterpart in the English page because some additional information (font) is added@@@@@The length-based method thus tends to take sentence 0002, 0003, and 0004 in the English page as the translation of sentence 0002 in the Chinese page (Fig. 2), which is wrong. This in turn provocated the three following incorrect alignments. As we can see in Fig. 3, the cognate method did not make the same mistake because of the noise in sentence 0002@@@@@Despite their large length difference, the two 0002 sentences are still aligned as a 1-1 pair, because the sentences in the following 4 alignments (0003 0003; 0004 0004, 0005; 0005 0006; 0006 0007) have rather similar HTML markups and are taken by the program to be the most likely alignments@@@@@Beside HTML markups, other criteria may also be incorporated. For example, it would be helpful to consider strong correspondence b tween certain English and Chinese words, as in (Wu, 1994). We hope to implement such correspondences in our future research@@@@@3.4 Lex icon  Eva luat ion  To evaluate the precision of the English-Chinese translation model trained on the Web corpus, we examined two sample lexicons of 200 words, one in each direction. The 200 words for each lexicon were randomly selected from the training source. We examined the most probable translation for each word@@@@@The Chinese-English lexicon was found to have a precision of 77%. The English-Chinese l xicon has a higher precision of 81.5%. Part of the lexicons are shown in Fig. 4, where t / f  indicates whether a translation is true or false@@@@@These precisions seem to be reasonably high@@@@@They are quite comparable to that obtained by Wu (1994) using a manual Chinese-English parallel corpus@@@@@3.5 Effect  o f  S topwords  We also found that stop-lists have significant effect on the translation model. Stop-list is a set of the most frequent words that we remove from the train2fi English word a .n l .  access adaptation add adopt agent agree airline amendment , appliance apply attendance auditor ,average base_on t/f t f t t t t t t t t t t f t f Translmion Probability Chinese word ~~0.201472 ~t l :  ~\"  0.071705 \"~\"  ~f~.,~ 0.179633 JllL~ 0.317435 ~ 0.231637 ~.~ 1~tA~ 0.224902 4J~~ 0.36569 0.344001 0.367518 J~ 4~ 0.136319 i~.~I 0.19448 J~  ~,1~ 0.171769 ,~JJ~ *~ 0.15011 -~-~ ~~ 0.467646 * *~ 0.107304 Figure 4: Part of the evaluation lexicons@@@@@t/f t t t t t f t f t t t t t t t Translation Probability office 0.375868 protection 0.343071 report 0.358592 prepare 0.189513 loca l  0.421837 follow 0.023685 standard 0.445453 adu l t  0.044959 inadequate 0.093012 part 0.313676 financial 0.16608 visit 0.309642 bill 0.401997 vehicle 0.467034 saving 0.176695 Figure 5: Effect of stop lists in C-E translation@@@@@ing source. Because these words exist in most alignments, the statistical model cannot derive correct translations for them. More importantly, their existence greatly affects the accuracy of other translations. They can be taken as translations for many words@@@@@A priori, it would seem that both the English and Chinese stop-lists hould be applied to eliminate the noise caused by them. Interestingly, from our observation and analysis we concluded that for better precision, only the stop-list of the target language should be applied in the model training@@@@@We first explain why the stop-list of the target language has to be applied. On the left side of Fig. 5, if the Chinese word C exists in the same alignments with the English word E more than any other Chinese words, C will be the most probable translation for E. Because of their frequent appearance, some Chinese stopwords may have more chances to be in the same alignments with E. The probability of the translation E --+ C is then reduced (maybe ven less than those of the incorrect ones). This is the reason why many English words are translated to \"~   (of) by the translation model trained without using the Chinese stop-list@@@@@We also found that it is not necessary to remove the stopwords of the source language. In fact, as illustrated on the right side of Fig. 5, the existence of the English stopwords has two effects on the probability of the translation E -~ C: 1 They may often be found together with the Chinese word C. Owing to the Expectation Maximization algorithm, the probability of E -~ C may therefore be reduced@@@@@2 On the other hand, there is a greater likelihood that English stopwords will be found together with the most frequent Chinese words. Here, we use the term \"Chinese frequent words\" instead of \"Chinese stopwords\" because ven if a stop-list is applied, there may still remain some common words that have the same effect as the stopwords. The coexistence ofEnglish and Chinese frequent words reduces the probability that the Chinese frequent words are the translations of E, and thus raise the probability of E -+ C@@@@@The second effect was found to be more significant than the first, since the model trained without the English stopwords has better precision than the model trained with the English stopwords. For the correct ranslations given by both models, the model 26Mono-Lingual IR Translation Model Dictionary C-E CLIR 0.3861 0.1504 (39.0%mono) 0.1530 (39.6%mono) 0.2583 (66.9%mono) E-C CLIR 0.3976 0.1841 (46.3%mono) 0.1427 (35.9%mono) 0.2232 (56.1%mono) Table 1: CLIR results@@@@@trained without considering the English stopwords gives higher probabilities@@@@@4 Eng l i sh -Ch inese  CL IR  Resu l ts  Our final goal was to test the performance of the translation models trained on the Web parallel corpora in CLIR. We conducted CLIR experiments u ing the Smart IR system@@@@@4.1 Results  The English test corpus (for C-E CLIR) was the AP corpus used in TREC6 and TREC7. The short English queries were translated manually into Chinese and then translated back to English by the translation model. The Chinese test corpus was the one used in the TREC5 and TREC6 Chinese track@@@@@It contains both Chinese queries and their English translations@@@@@Our experiments on these two corpora produced the results hown in Tab. 1. The precision of monolingual IR is given as benchmark. In both E-C and C-E CLIR, the translation model achieved around 40% of monolingual precision. To compare with the dictionary-based approach, we employed a ChineseEnglish dictionary, CEDICT (Denisowski, 1999), and an English-Chinese online dictionary (Anonymous, 1999a) to translate queries. For each word of the source query, all the possible translations given by the dictionary are included in the translated query. The Chinese-English dictionary has about the same performace as the translation model, while the English-Chinese dictionary has lower precision than that of the translation model@@@@@We also tried to combine the translations given by the translation model and the dictionary. In both C-E and E-C CLIR, significant improvements were achieved (as shown in Tab. 1). The improvements show that the translations given by the translation model and the dictionary complement each other well for IR purposes. The translation model may give either exact ranslations orincorrect but related words. Even though these words are not correct in the sense of translation, they are very possibly related to the subject of the query and thus helpful for IR purposes. The dictionary-based approach expands a query along another dimension. It gives all the possible translations for each word including those that are missed by the translation model@@@@@4.2 Comparison Wi th  MT Systems One advantage of a parallel text-based translation model is that it is easier to build than an MT system@@@@@Now that we have examined the CLIR performance of the translation model, we will compare it with two existing MT systems. Both systems were tested in E-C CLIR@@@@@4.2.1 Sunshine WebTran Server Using the Sunshine WebTran server (Anonymous, 1999b), an online Engiish-Chinese MT system, to translate the 54 English queries, we obtained an average precision of 0.2001, which is 50.3% of the mono-lingual precision. The precision is higher than that obtained using the translation model (0.1804) or the dictionary (0.1427) alone, but lower than the precison obtained using them together (0.2232)@@@@@4.2.2 Transperfect Kwok (1999) investigated the CLIR performance ofan English-Chinese MT software called Transperfect, using the same TREC Chinese collection as we used in this study. Using the MT software alone, Kwok achieved 56% of monolingual precision. The precision is improved to 62% by refining the translation with a dictionary. Kwok also adopted pretranslation query expansion, which further improved the precison to 70% of the monolingual results@@@@@In our case, the best E-C CLIR precison using the translation model (and dictionary) is 56.1%. It is lower than what Kwok achieved using Transperfect, however, the difference is not large@@@@@4.3 Further  Problems The Chinese-English translation model has a fax lower CLIR performance than that of the EnglishFrench model established using the same method (Nie et al, 1999). The principal reason for this is the fact that English and Chinese are much more different than English and French. This problem surfaced in many phases of this work, from text alignment to query translation. Below, we list some further factors affecting CLIR precision@@@@@? The Web-collected corpus is noisy and it is difficult to align English-Chinese t xts. The alignment method we employed has performed more poorly than on English-French alignment. This in turn leads to poorer performance of the translation model. In general, we observe a higher 27 variability in Chinese-English translations than in English-French translations@@@@@? For E-C CLIR, although queries in both languages were provided, the English queries were not strictly translated from the original Chinese ones. For example, A Jg ,~ (human right situation) was translated into human right issue. We cannot expect he translation model to translate issue back to ~ (situation)@@@@@? The training source and the CLIR collections were from different domains. The Web corpus are retrieved from the parallel sites in Hong Kong while the Chinese collection is from Peoples Daily and Xinhua News Agency, which are published in mainland China. As the result, some important erms such as ~$ $ (mostfavored-nation) and --I!! ~ ~ (one-nation-twosystems) in the collection are not known by the model@@@@@5 Summary  The goal of this work was to investigate he feasibility of using a statistical translation model trained on a Web-collected corpus to do English-Chinese CLIR@@@@@In this paper, we have described the algorithm and implementation we used for parallel text mining, translation model training, and some results we obtained in CLIR experiments. Although further work remains to be done, we can conclude that it is possible to automatically construct a Chinese-English parallel corpus from the Web. The current system can be easily adapted to other language pairs. Despite the noisy nature of the corpus and the great difference in the languages, the evaluation lexicons generated by the translation model produced acceptable precision. While the current CLIR results are not as encouraging asthose of English-French CLIR, they could be improved in various ways, such as improving the alignment method by adapting cognate definitions to HTML markup, incorporating a lexicon and/or removing some common function words in translated queries@@@@@We hope to be able to demonstrate in the near future that a fine-tuned English-Chinese translation model can provide query translations for CLIR with the same quality produced by MT systems@@@@@Re ferences  Anonymous. 1999a. Sunrain.net English-Chinese dictionary, http://sunrain.net/r_ecdict _e.htm@@@@@Anonymous. 1999b. Sunshine WebTran server@@@@@http://www.readworld.com/translate.htm@@@@@P. F. Brown, J. C. Lai, and R. L. Mercer. 1991@@@@@Aligning sentences in parallel corpora. In 29th Annual Meeting of the Association for Computational Linguistics, pages 89-94, Berkeley, Calif@@@@@P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer. 1993. The mathematics of machine translation: Parameter estimation. Computational Linguistics, 19:263-311@@@@@S. F. Chen. 1993. Aligning sentences in bilingual corpora using lexical information. In Proceedings of the 31th Annual Meeting of the Association for Computational Linguistics, pages 9-16, Columbus, Ohio@@@@@Paul Denisowski. 1999. Cedict (chinese-english dictionary) project, http://www.mindspring.com/ paul_denisowski/cedict.html@@@@@William A. Gale and Kenneth W. Church. 1991. A program for aligning sentences in bilingual corpora. In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, pages 177-184, Berkeley, Calif@@@@@P. Isabelle, G. Foster, and P. Plamondon@@@@@1997. SILC: un syst~me didentification de la langue et du codage, http://wwwrali.iro.umontreal.ca/ProjetSILC.en.html@@@@@M. Kay and M. RSscheisen. 1993. Text-translation alignment. Computational Linguistics, 19:121142@@@@@K. L. Kwok. 1999. English-chinese cross-language retrieval based on a translation package. In Workshop of Machine Translation for Cross Language Information Retrieval, Machine Translation Summit VII, Singapore@@@@@P. Langlais, G. Foster, and G. Lapalme. 2000. Unit completion for a computer-aided translation typing system. In Applied Natural Language Processing Conference (ANLP), Seattle, Washington, May@@@@@Jianyun Nie, Michel Simard, Pierre Isabelle, and Richard Durand. 1999. Cross-language information retrieval based on parallel texts and automatic mining parallel texts from the Web. In ACM SIGIR 99, pages 74-81, August@@@@@Philip Resnik. 1998. Parallel stands: A preliminary investigation i to mining the Web for bilingual text. In AMTA 98, October@@@@@Michel Simard, George F. Foster, and Pierre Isabelle. 1992. Using cognates to align sentences in bilingual corpora. In Proceedings of TMI-92, Montreal, Quebec@@@@@Dekai Wu. 1994. Aligning a parallel EnglishChinese corpus statistically with lexical criteria@@@@@In ACL-9$: 32nd Annual Meeting of the Assoc@@@@@for Computational Linguistics, pages 80-87, Las Cruces, NM, June@@@@@Dekai Wu. 1995. Large-scale automatic extraction '"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.Body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src_text = [\n",
    "     \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
    "]\n",
    "\n",
    "model_name = 'google/pegasus-xsum'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src_text = [\n",
    "     \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
    "]\n",
    "\n",
    "model_name = 'google/pegasus-arxiv'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "amodel = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "translated = amodel.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the goal of this paper is to explore the use of parallel texts in machine translation ( ). use of parallel texts in machine translation ( ) <n> is a promising method to train translation models. <n> text mining is a method to search for large amounts of parallel texts on the web-based tool engines that may contain parallel pages. <n> is a method to search for large amounts of parallel texts on the web-based tool engines that may contain parallel pages. <n> is a method to search for large amounts of parallel texts on the web-based tool engines that may contain parallel pages. <n> is a method to search for large amounts of parallel texts on the web-based tool engines that may contain parallel pages. <n> is a method to search for large amounts of parallel texts on the web-based tool engines that may contain parallel pages. <n> is a method to search for large amounts of parallel texts on the web-based tool engines that may contain parallel pages. <n> is a method to search for large amounts of parallel texts on the web-based tool engines that may contain parallel pages. <n> is a method to search for large amounts of parallel texts on the web-based tool engines']\n",
      "1\n",
      "['this paper, we propose a dialogue translation system that uses extra- nlinguistics. <n> our study found that speakers do not have to use polite expressions. <n> this paper begins with a series of letters from journalists, we take look at some common transfer rules. <n> this paper begins with a series of letters from journalists, we look at some common transfer rules. <n> this paper begins with a series of letters from journalists, we look at some common transfer rules. <n> this paper begins with a series of letters from journalists, we look at some common transfer rules. <n> this paper begins with a series of letters from journalists, we look at some common transfer rules. <n> this paper begins with a series of letters from journalists, we look at some common transfer rules. <n> this paper begins with a series of letters from journalists, we look at some common transfer rules. <n> this paper begins with a series of letters from journalists, we look at some common transfer rules. <n> this paper begins with a series of letters from journalists, we look at some common transfer rules. <n> this paper begins with a series of letters from']\n",
      "['this study is to have developed a dialogue management system for systems. purpose of this study is to have developed a dialogue management system for systems. <n> this study is to have developed a dialogue management system for systems. <n> this study is to have developed a dialogue management system for systems. <n> this study is to have developed a dialogue management system for systems. <n> this study is to have developed a dialogue management system for systems. <n> this study is to have developed a dialogue management system for systems. <n> this study is to have developed a dialogue management system for systems. <n> this study is to have developed a dialogue management system for systems. <n> this study is to have developed a dialogue management system for systems. <n> this study is to have developed a dialogue management system for systems. <n> this study is to have developed a dialogue management system for systems. <n> this study is to have developed a dialogue management system for systems. <n> this study is to have developed a dialogue management system for systems. <n> this study is to have developed a dialogue management system for systems. <n> this study is to have developed a dialogue management system for systems.']\n",
      "['this paper, we present an approach to the study of multinomial time series ( ). this talk, will show how to implement rules in declarative processing for applications. <n> this paper, we show how to implement rules in declarative processing for applications. <n> this talk, will show how to implement rules in declarative processing for applications. <n> this paper, we show how to implement rules in declarative processing for applications. <n> this talk, will show how to implement rules in declarative processing for applications. <n> this paper, we show how to implement rules in declarative processing for applications. <n> this talk, will show how to implement rules in declarative processing for applications. <n> this paper, we show how to implement rules in declarative processing for applications. <n> this talk, will show how to implement rules in declarative processing for applications. <n> this paper, we show how to define knowledge structures which can be transformed into knowledge structures which can be transformed into knowledge structures which can be transformed into knowledge structures which can be transformed into knowledge structures which can be transformed into knowledge structures which can be transformed into knowledge structures which can be transformed into knowledge structures which']\n",
      "4\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-ef40da4b1446>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'longest'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mindicator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'longest'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "summaries = []\n",
    "k=0\n",
    "for i in range(len(df2.Body)):\n",
    "    word_sum = []\n",
    "    string = df2.Body[i].split('@@@@@')\n",
    "    string.append(df.Citations[i])    \n",
    "    k+=1\n",
    "    indicator = 0\n",
    "    for sent in range(len(string)):\n",
    "        if indicator == 1:\n",
    "            indicator = 0\n",
    "        else:\n",
    "            if len(string[sent]) > 250:\n",
    "                batch = tokenizer(string[sent], truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "                indicator = 0\n",
    "            elif len(str(string[sent]+\" \"+string[sent+1])) > 250:\n",
    "                try:\n",
    "                    batch = tokenizer(str(string[sent]+\" \"+string[sent+1]), truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "                    indicator = 1\n",
    "                except:\n",
    "                    batch = tokenizer(string[sent], truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "                    indicator = 0\n",
    "            else: \n",
    "                try:\n",
    "                    batch = tokenizer(str(string[sent]+\" \"+string[sent+1]+\" \"+string[sent+2]), truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "                    indicator = 1\n",
    "                except:\n",
    "                    try:\n",
    "                        batch = tokenizer(str(string[sent]+\" \"+string[sent+1]), truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "                        indicator = 1\n",
    "                    except:\n",
    "                        batch = tokenizer(string[sent], truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "                        indicator = 0\n",
    "                        \n",
    "            try:\n",
    "                translated = model.generate(**batch)\n",
    "                tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "                word_sum.append(tgt_text)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    sum_this = ''\n",
    "    for x in word_sum:\n",
    "        sum_this = sum_this + x[0] + \" \"\n",
    "    \n",
    "    f = open('aan_data_xsum_summaries_of_each_paragraph_r2.csv','a')\n",
    "    f.write(sum_this)\n",
    "    f.write('\\n') \n",
    "    f.close()\n",
    "    \n",
    "    batch = tokenizer(sum_this, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "    translated = amodel.generate(**batch)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    print(tgt_text)\n",
    "    \n",
    "    f = open('aan_data_xsum_summary_ofsum_of_each_paragraph_r2.csv','a')\n",
    "    f.write(tgt_text[0])\n",
    "    f.write('\\n') \n",
    "    f.close()\n",
    "    \n",
    "    summaries.append(tgt_text)\n",
    "    if k % 3 == 1:\n",
    "        print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The goal of this paper is to explore the use of parallel texts in machine translation (MT).'],\n",
       " ['One use case of this paper is the translation of documents from one language to another.'],\n",
       " ['Text mining is a promising method to train translation models.'],\n",
       " ['PTMiner is a text mining system designed to search for large amounts of parallel text on the Web.'],\n",
       " ['PTMiner is a web-based tool that searches the web for candidate sites that may contain parallel pages.'],\n",
       " ['The following is a guide to search engines and how they work:'],\n",
       " ['In our series of letters from African journalists, film-maker and columnist Ahmedou Ould-Abdallah looks at the importance of anchor texts.'],\n",
       " ['When searching for English parallel texts on the web, it is advisable to look for links to English parallel texts that contain the word \"anchor\".'],\n",
       " ['We do not have any English-language Web sites for Chinese parallel texts.'],\n",
       " ['The following table shows the search results for the following Web sites:'],\n",
       " ['This article describes how to search for parallel texts using the search engines.'],\n",
       " ['PTMiner uses a host crawler to crawl documents on a given host.'],\n",
       " ['In this tutorial, you will learn how to identify parallel pairs between two files.'],\n",
       " ['In this paper, we show that the external features of a parailel page, such as its name and path, can be deduced from its internal features.'],\n",
       " ['In this paper, we decompose the file system into parallel documents.'],\n",
       " ['The following methods have been implemented in our system:'],\n",
       " ['In this tutorial I will show you how to filter out incorrect pairs between parallel files.'],\n",
       " ['The difference ratio is a measure of the difference between the number of words in a parallel text and the number of words in the main text.'],\n",
       " ['It is obvious that the two files of a pair have to be in the two languages of interest. 2.5.2 Language and Character Set It is also obvious that the two files of a pair have to be in the two languages of interest.'],\n",
       " ['In this paper, I present the results of a study on the probabilistic language and encoding system, the RALI language and encoding Corpus.'],\n",
       " ['The following is a list of the best candidate pairs.'],\n",
       " ['In this paper, we compare the HTML structures of two parallel texts.'],\n",
       " ['In our paper we show how to measure the confidence values of parallel text alignment.'],\n",
       " ['In this section, we describe the results of our parallel text mining and translation model training 3.1 The Corpus Using the above approach in Chinese-English, 185 candidate sites were searched from the domain hk.'],\n",
       " ['We have mined a corpus of Chinese and English texts from the Hong Kong (hk) Internet.']]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comparing HTML structures seems to be a sound way to evaluate candidate pairs since parallel pairs usually have similar HTML structures. However, we also noticed that parallel texts may have quite different HTML structures. One of the reasons is that the two files may be created using two HTML editors. For example, one may be used for English and another for Chinese, depending on the language handling capability of the editors. Therefore, caution is required when measuring structure difference numerically'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string[len(word_sum)+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The goal of this paper is to explore the use of parallel texts in machine translation (MT). One use case of this paper is the translation of documents from one language to another. Text mining is a promising method to train translation models. PTMiner is a text mining system designed to search for large amounts of parallel text on the Web. PTMiner is a web-based tool that searches the web for candidate sites that may contain parallel pages. The following is a guide to search engines and how they work: An anchor text is a piece of text that, when clicked on, will take you to another linked page. When searching for a website in English, you may notice that some pages contain links to other websites. We do not have any English parallel texts on our website. The following table shows the search results for the following Web sites: This article describes how to search for parallel texts using the search engines. PTMiner uses a host crawler to crawl documents on a given host. In this tutorial, I will show you how to find parallel pairs between two files. In this paper, we show that the external features of a parailel page, such as its name and path, can be deduced from its internal features. In this paper, we decompose the file system into parallel documents. The following methods have been implemented in our system: In this tutorial I will show you how to filter out incorrect pairs between parallel files. The difference ratio is a measure of the difference between the number of words in a parallel text and the number of words in the main text. It is obvious that the two files of a pair have to be in the two languages of interest. 2.5.2 Language and Character Set It is also obvious that the two files of a pair have to be in the two languages of interest. In this paper, I present the results of a study on the probabilistic language and encoding system, the RALI language and encoding Corpus. \n",
      "['In this paper, we decompose the file system into parallel documents.']\n"
     ]
    }
   ],
   "source": [
    "sum_this = ''\n",
    "for x in word_sum:\n",
    "    sum_this = sum_this + x[0] + \" \"\n",
    "print(sum_this)\n",
    "\n",
    "batch = tokenizer(sum_this, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "print(tgt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A compilation of parallel texts offered in a serviceable form is called a parallel corpus. Parallel corpora are very valuable resources in various fields of multilingual natural language processing such as statistical machinet ranslation(Brown et al. , 1990), cross-lingual IR (Chenand Nie, 2000), and construction of dictionary(Nagao, 1996).'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Citations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"BBC News takes a look at some of the key findings from this year's EU referendum.\"]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sum[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' In recent years, speech and natural anguage technologies have matured enough to enable the development ofspoken dialogue systems in limited domains. Most existing systems employ dialogue strategies pre-specified during the design phase of the dialogue manager without taking into account characteristics of actual dialogue interactions. More specifically, mixed initiative systems typically employ rules that specify conditions (generally based on local dialogue context) under which initiative may shift from one agent o the other. Previous research, on the other hand, has shown that changes in initiative strategies inhuman-human dialogues can be dynamically modeled in terms of characteristics of the user and of the on-going dialogue (Chu-Carroll and Brown, 1998) and that adaptability of initiative strategies in dialogue systems leads to better system performance (Litman and Pan, 1999). However, no previous dialogue system takes into account these dialogue characteristics or allows for initiative-oriented adaptation of dialogue strategies',\n",
       " 'In this paper, we describe MIMIC, a voice-enabled telephone-based dialogue system that provides movie showtime information, emphasizing its dialogue management aspects. MIMIC improves upon previous ystems along two dimensions. First, MIMIC automatically adapts dialogue strategies based on participant roles, characteristics of the current utterance, and dialogue history. This automatic adaptation allows appropriate dialogue strategies to be employed based on both local dialogue context and dialogue history, and has been shown to result in significantly better performance than non-adaptive systems. Second, MIMIC employs an initiative module that is decoupled from the goal selection process in the dialogue manager, while allowing the outcome of both components ojointly determine the strategies chosen for response generation. As a result, MIMIC can exhibit drastically different dialogue behavior with very minor adjustments o parameters in the initiative module, allowing for rapid development and comparison of experimental prototypes and resulting in general and portable dialogue systems',\n",
       " '2 Adaptive Mixed Initiative Dialogue Management 2.1 Motivation In naturally occurring human-human dialogues, peakers often adopt different dialogue strategies based on hearer characteristics, dialogue history, etc. For instance, the speaker may provide more guidance if the hearer is having difficulty making progress toward task completion, while taking a more passive approach when the hearer is an expert in the domain. Our main goal is to enable a spoken dialogue system to simulate such human behavior by dynamically adapting dialogue strategies during an interaction based on information that can be automatically detected from the dialogue. Figure 1 shows an excerpt from a dialogue between MIMIC and an actual user where the user is attempting to find the times at which the movie Analyze This playing at theaters in Montclair. S and U indicate system and user utterances, respectively, and the italicized utterances are the output of our automatic speech recognizer. In addition, each system turn is annotated with its task and dialogue initiative holders, where task initiative tracks the lead in the process toward achieving the dialogue participants domain goal, while dialogue initiative models the lead in determining the current discourse focus (Chu-Carroll and Brown, 1998). In our information query application domain, the system has task (and thus dialogue) initiative if its utterances provide helpful guidance toward achieving the users domain goal, as in utterances (6) and (7) where MIMIC provided valid response choices to its query intending to solicit a theater name, while the system has 97 dialogue but not task initiative if its utterances only specify the current discourse goal, as in utterance (4). i This dialogue illustrates everal features of our adaptive mixed initiative dialogue manager. First, MIMIC automatically adapted the initiative distribution based on information extracted from user utterances and dialogue history. More specifically, MIMIC took over task initiative in utterance (6), after failing to obtain a valid answer to its query soliciting a missing theater name in (4)',\n",
       " 'It retained task initiative until utterance (12), after the user implicitly indicated her intention to take over task initiative by providing a fully-specified query (utterance (11)) to a limited prompt (utterance (10)). Second, initiative distribution may affect the strategies MIMIC selects to achieve its goals. For instance, in the context of soliciting missing information, when MIMIC did not have task initiative, a simple information-seeking query was generated (utterance (4)). On the other hand, when MIMIC had task initiative, additional guidance was provided (in the form of valid response choices in utterance (6)), which helped the user successfully respond to the systems query. In the context of prompting the user for a new query, when MIMIC had task initiative, a limited prompt was selected to better constrain the users response (utterance (10)), while an open-ended prompt was generated to allow the user to take control of the problem-solving process otherwise (utterances (1) and (13))',\n",
       " 'In the next section, we briefly review a framework for dynamic initiative modeling. In Section 3, we discuss how this framework was incorporated into the dialogue management component of a spoken dialogue system to allow for automatic adaptation of dialogue strategies. Finally, we outline experiments evaluating the resulting system and show that MIMICs automatic adaptation capabilities resulted in better system performance',\n",
       " '2.2 An Evidential Framework for Modeling Initiative In previous work, we proposed a framework for modeling initiative during dialogue interaction (Chu-Carroll and Brown, 1998). This framework predicts task and dialogue initiative holders on a turn-by-turn basis in humanhuman dialogues based on participant roles (such as each dialogue agents level of expertise and the role that she plays in the application domain), cues observed in the current dialogue turn, and dialogue history. More specifically, we utilize the Dempster-Shafer theory (Shafer, 1976; Gordon and Shortliffe, 1984), and represent the current initiative distribution as two basic probability assignments (bpas) which indicate the amount of support for each dialogue participant having the task and dialogue initiatives. For instance, the bpa mt-cur({S}) =l Although the dialogues we collected in our experiments (Section 5) include cases in which MIMIC has neither initiative, such cases are rare in this application domain, and will not be discussed further in this paper',\n",
       " '0.3, mt-c~,r({U}) = 0.7 indicates that, with all evidence taken into account, there is more support (to the degree 0.7) for the user having task initiative in the current urn than for the system. At the end of each turn, the bpas are updated based on the effects that cues observed uring that turn have on changing them, and the new bpas are used to predict he next task and dialogue initiative holders',\n",
       " 'In this framework, cues that affect initiative distribution include NoNewlnfo, triggered when the speaker simply repeats or rephrases an earlier utterance, implicitly suggesting that the speaker may want to give up initiative, AmbiguousActions, triggered when the speaker proposes an action that is ambiguous in the application domain, potentially prompting the hearer to take over initiative to resolve the detected ambiguity, etc. The effects that each cue has on changing the current bpas are also represented asbpas, which were determined by an iterative training procedure using a corpus of transcribed ialogues where each turn was annotated with the task/dialogue initiative holders and the observed cues',\n",
       " 'The bpas for the next turn are computed by combining the bpas representing the current initiative distribution and the bpas representing the effects of cues observed during the current urn, using Dempsters combination rule (Gordon and Shortliffe, 1984). The task and dialogue initiative holders are then predicted based on the new bpas. This framework was evaluated using annotated dialogues from four task-oriented domains, achieving, on average, a correct prediction rate of 97% and 88% for task and dialogue initiative holders, respectively. In Section 3.2, we discuss how this predictive model is converted into a generative model by enabling the system to automatically detect cues that were previously labelled manually. We further discuss how the model is used by the dialogue manager for dynamic dialogue strategy adaptation',\n",
       " '3 MIMIC :  M ixed  Init iative Mov ie  In fo rmat ion  Consu l tant  MIMIC is a telephone-based dialogue system that provides movie showtime information. It consists of the following main components, implemented on a distributed, client-server a chitecture (Zhou et al, 1997): 1',\n",
       " '',\n",
       " 'Telephony server: this component detects rings and hang-ups, and enables treaming of audio data on channels of a telephony board',\n",
       " 'Speech recognizer: the recognizer receives audio data from the telephony server and generates the word string hypothesis that best matches the audio input. We used the Lucent Automatic Speech Recognizer (Reichl and Chou, 1998; Ortmanns et al, 1999), configured to use class-based probabilistic ngram language models to allow for rapid updates of movie/theater/town names',\n",
       " '_ql:l 98Utterance (1) S: Hello, this is MIMIC, the movie information system',\n",
       " '(2) How can I help you? (3) U: What time is Analyze This playing in Montclair? \\\\[what time is analyze this playing in montclair\\\\] (4) S: What theater would you like? User (5) U: Montclair',\n",
       " '\\\\[montclair\\\\] (6) S: Choices for theater are Wellmont Theater and Clearviews Screening Zone. System (7) What theater would you like? (8) U: Clearviews Screening Zone',\n",
       " '\\\\[urn movie screening zone\\\\] (9) S: Analyze This is playing at Clearviews Screening Zone in Montclair at l:15pm, 4:10pm, System and 6:30pm',\n",
       " '(10) Please say the name of the movie or theater or town you would like information about',\n",
       " '(11) U: What time is Analyze This playing at the Welimont Theater? \\\\[what time is analyze this playing at the wellmont theater\\\\] (12) S: Analyze This is playing at Wellmont Theater in Montclair at 3:15pm, 5:45pm, 8:20pm, User and lO:lOpm',\n",
       " '(13) Can I help you with anything else? Task Initiative User Dialogue Initiative System System System System System Figure 1: Excerpt of an Adaptive Mixed Initiative Dialogue 3. NLP/Dialogue component: this main applicationdependent component receives a user utterance hypothesis from the speech recognizer, and generates system utterance(s) in response. Three major tasks are carried out by this component: 1) semantic interpretation, which constructs frame-based semantic representations from user utterances, 2)dialogue management, where response strategies are selected based on the semantic representation f the users utterance, systems domain knowledge, and initiative distribution, and 3) utterance generation, where utterance templates are chosen and instantiated to realize the selected response strategies. These three tasks will be discussed in further detail in the rest of this section',\n",
       " '4. Text-to-speech engine: the TTS system receives the word string comprising the systems response from the dialogue component and converts the text into speech for output over the telephone. We used the Bell Labs TTS system (Sproat, 1998), which in addition to converting plain text into speech, accepts text strings annotated to override default pitch height, accent placement, speaking rate, etc. 2 3.1 Semantic Interpretation MIMIC utilizes a non-recursive frame-based semantic representation commonly used in spoken dialogue systems (e.g. (Seneff et al, 1991; Lamel, 1998)), which represents an utterance as a set of attribute-value pairs',\n",
       " 'Figure 2(a) shows the frame-based semantic representation for the utterance \"What time is Analyze This playing 2 See (Nakatani and Chu-Carroll, 2000) for how MIMICs dialoguelevel knowledge is used to override default prosodic assignments for concept-to-speech generation',\n",
       " 'Question-Type: When Movie: Analyze This Theater: null Town: Montclair (a) Semantic Representation Question-Type: When Movie: mandatory Theater: mandatory Town: optional (b) Task Specification Figure 2: Semantic Representation a d Task Specification in Montclair?\" MIMICs semantic representation is constructed by first extracting, for each attribute, a set of keywords from the user utterance. Using a vector-based topic identification process (Salton, 1971; Chu-Carroll and Carpenter, 1999), these keywords are used to determine a set of likely values (including null) for that attribute. Next, the utterance is interpreted with respect o the dialogue history and the systems domain knowledge. This allows MIMIC to handle elliptical sentences and anaphoric references, as well as automatically infer missing values and detect inconsistencies in the current representation',\n",
       " 'This semantic representation allows for decoupling of domain-dependent task specifications and domain99independent dialogue management s rategies. Each query type is specified by a template indicating, for each attribute, whether a value must, must not, or can optionally be provided in order for a query to be considered well-formed. Figure 2(b) shows that to solicit movie showtime information (question type when), a movie name and a theater name must be provided, whereas atown may optionally be provided. These specifications are determined based on domain semantics, and must be reconstructed when porting the system to a new domain',\n",
       " '3.2 Dialogue Management Given a semantic representation, the dialogue history and the systems domain knowledge, the dialogue manager selects a set of strategies that guides MIMICs response generation process. This task is carried out by three subprocesses: 1) initiative modeling, which determines the initiative distribution for the systems dialogue turn, 2) goal selection, which identifies a goal that MIMICs response attempts to achieve, and 3) strategy selection, which chooses, based on the initiative distribution, a set of dialogue acts that MIMIC will adopt in its attempt to realize the selected goal',\n",
       " '3.2.1 Initiative Modeling MIMICs initiative module determines the task and dialogue initiative holders for each system turn in order to enable dynamic strategy adaptation. It automatically detects cues triggered uring the current user turn, and combines the effects of these cues with the current initiative distribution to determine the initiative holders for the systems turn',\n",
       " 'Cue Detection The cues and the bpas representing their effects are largely based on a subset of those described in (Chu-Carroll and Brown, 1998), 3 as shown in Figures 3(a) and 3(b). Figure 3(a) shows that observation of TakeOverTask supports a task initiative shift to the speaker to the degree .35. The remaining support is assigned to O, the set of all possible conclusions (i.e., {speaker,hearer}), indicating that to the degree .65, observation of this cue does not commit to identifying which dialogue participant should have task initiative in the next dialogue turn',\n",
       " 'The cues used in MIMIC are classified into two categories, discourse cues and analytical cues, based on the types of knowledge needed to detect hem: I. Discourse cues, which can be detected by considering the semantic representation f the current utterance and dialogue history: ? TakeOverTask, an implicit indication that the user wants to take control of the problemsolving process, triggered when the user provides more information than the discourse xpectation',\n",
       " '3We selected only those cues that can be automatically detected in a spoken dialogue system with speech recognition errors and limited semantic interpretation capabilities',\n",
       " '? NoNewlnfo, an indication that the user is unable to make progress toward task completion, triggered when the semantic representations of two consecutive user turns are identical (a result of the user not knowing what to say or the speech recognizer failing to recognize the user utterances)',\n",
       " '2. Analytical cues, which can only be detected by taking into account MIMICs domain knowledge: ? lnvalidAction, an indication that the user made an invalid assumption about the domain, triggered when the system database lookup based on the users query returns null',\n",
       " '? lnvalidActionResolved, triggered when the previous invalid assumption is corrected',\n",
       " '? AmbiguousAction, an indication that the user query is not well-formed, triggered when a mandatory attribute is unspecified or when more than one value is specified for an attribute',\n",
       " '? AmbiguousActionResolved, triggered when the attribute in question is uniquely instantiated',\n",
       " 'Computing Initiative Distribution To determine the initiative distribution, the bpas representing the effects of cues detected in the current user utterance are instantiated (i.e., speaker~hearer in Figure 3 are instantiated as system~user accordingly). These effects are then interpreted with respect o the current initiative distribution by applying Dempsters combination rule (Gordon and Shortliffe, 1984) to the bpas representing the current initiative distribution and the instantiated bpas. This results in two new bpas representing the task and dialogue initiative distributions for the systems turn. The dialogue participant with the greater degree of support for having the task/dialogue initiative in these bpas is the task/dialogue initiative holder for the systems turn 4 (see Section 4 for an example)',\n",
       " '3.2.2 Goal Selection The goal selection module selects a goal that MIMIC attempts to achieve in its response by utilizing information from analytical cue detection as shown in Figure 4',\n",
       " 'MIMICs goals focus on two aspects of cooperative dialogue interaction: 1) initiating subdialogues to resolve anomalies that occur during the dialogue by attempting to instantiate an unspecified attribute, constraining an attribute for which multiple values have been specified, or correcting an invalid assumption i  the case of invalid 41n practice, this is the preferred initiative holder since practical reasons may prevent the dialogue participant from actually holding the initiative. For instance, if having task initiative dictates inclusion of additional helpful information, this can only be realized if M1M1Cs knowledge base provides uch information',\n",
       " '\"INN 100Cue Class Discourse Analytical Cue TakeOverTask NoNewlnfo InvalidAction lnvalidActionResolved AmbiguousAction AmbiguousActionResolved BPA mt-tot({speaker}) = 0.35; mr-tot(O) = 0.65 mt-,~ni({hearer}) = 0.35; mt-nn~(O) = 0.65 mt-i~({hearer}) = 0.35; mtia(O) = 0.65 mt-iar({hearer}) = 0.35; mtiar(O)  = 0.65 mt-aa({hearer}) = 0.35; mt-a~(O) = 0.65 mt . . . .  ({speaker}) = 0.35; mt . . . .  (O) = 0.65 (a)Task Initiative Cue Class Discourse Analytical Cue TakeOverTask NoNewlnfo lnvalidAction InvalidActionResolved AmbiguousAction AmbiguousActionResolved BPA md-tot({speaker}) = 0.35; ma-tot(O) = 0.65 md-nni({hearer}) = 0.35; md-nni(O) -~0.65 md-ia ({hearer}) = 0.7; md-ia (O) = 0.3 ma-iar({hearer}) = 0.7; ma-iar(O) = 0.3 ma-aa({hearer}) = 0.7; md_a~(O) = 0.3 ma . . . .  ({speaker}) = 0.7; md . . . .  (O) = 0.3 (b)Dialogue Initiative Figure 3: Cues and BPAs for Modeling Initiative in MIMIC Seleet-Goal(SemRep): (1) IfAmbiguousAction detected (2) ambiguous-attr +--get-ambiguous(SemRep) /* get name of ambiguous attribute */ (3) If (number-values(ambiguous-attr) == 0) /* attribute unspecified *,1 (4) Instantiate(ambiguous-attr) (5) Else/* more than one value specified */ (6) Constrain(ambiguous-attr) (7) Else if lnvalidAction detected (8) ProvideNegativeAnswer(SemRep) (9) Else/* well-formed query */ (10) answer +-database-query(SemRep) (11 ) ProvideAnswer(answer) Figure 4: Goal Selection Algorithm user queries (steps 1-8) 5 (van Beeket  al., 1993; Raskutti and Zukerman, 1993; Qu and Beale, 1999), and 2) providing answers to well-formed queries (steps 9-11)',\n",
       " '3.2.3 Strategy Selection Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction (Whittaker and Stenton, 1988; Walker and Whittaker, 1990; Chu-Carroll and Brown, 1998). Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution. Since task initiative models contribution to domain/problemsolving goals, while dialogue initiative affects the cur5An alternative strategy to step (4) is to perform adatabase lookup based on the ambiguous query and summarize the results (Litman et al., 1998), which we leave for future work',\n",
       " 'rent discourse goal, we developed alternative strategies for achieving the goals in Figure 4 based on initiative distribution, as shown in Table 1',\n",
       " 'The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems (e.g., (Bennacef et al, 1996; Stent et al., 1999)). To instantiate an attribute, MIMIC adopts the lnfoSeek dialogue act to solicit the missing information. In contrast, when MIMIC has both initiatives, it plays a more active role by presenting the user with additional information comprising valid instantiations of the attribute (GiveOptions). Given an invalid query, MIMIC notifies the user of the failed query and provides an openended prompt when it only has dialogue initiative. When MIMIC has both initiatives, however, in addition to NotifyFailure, it suggests an alternative close to the users original query and provides a limited prompt. Finally, when MIMIC has neither initiative, it simply adopts NotifyFailure, allowing the user to determine the next discourse goal',\n",
       " '3.3 Utterance Generat ion  MIMIC employs a simple template-driven utterance generation approach. Templates are associated with dialogue acts as shown in Table 2.6 The generation component receives from the dialogue manager the selected ialogue acts and the parameters needed to instantiate the templates. It then generates the system response, which is sent to the TTS module for spoken output synthesis',\n",
       " '6In most cases, there is a one-to-one-mapping between dialogue acts and templates. The exceptions are Answer, NotifyFailure, and SuggestAlternative, whose templates vary based on the question type',\n",
       " '101 Task + Dialogue Dialogue None Constrain Clarify Clarify Acknowledge Instantiate GiveOptions lnfoSeek Acknowledge InfoSeek ProvideAnswer Answer Answer Answer LimitedPrompt OpenPrompt ProvideNegativeAnswer NotifyFailure NotifyFailure NotifyFailure SuggestAltemative OpenPrompt LimitedPrompt Table 1: Strategy Selection Based on Goal and Initiative Distribution Dialogue Act Clarify Acknowledge GiveOptions InfoSeek Answer OpenPrompt LimitedPrompt NotifyFailure SuggestAltemative Template \"Did you say < valuel > .... or < valuen >.9\" \"Uh-huh.\" \"Choices for < attribute > are < valuex > ... < value, >7 \"What < attribute > would you like?\" E.g., \"< movie > is playing at < theater > at < time1 > ... < time,, >\" \"Can I help you with anything elseT \"Please say the name of the movie or theater or town you would like information about.\" E.g., \"< movie > is not playing at < theater >',\n",
       " 'E.g., \"< movie > is playing at < alternativetheater > at < timex > ... < timen >\" Table 2: Mappings Between Dialogue Acts and Utterance Templates 4 Examples To illustrate MIMICs adaptation capabilities, we return to the dialogue in Figure 1, which is repeated in Figure 5 and annotated with the cues detected in each user turn (in boldfaced italics) and the dialogue acts employed for response generation i each system turn (in boldface)',\n",
       " 'The bpas representing the initiative distribution for utterance (3) are the initial bpas, which, based on MIMICs role as an information provider, are mt-(3)({S}) = 0.3, mt-(3)({U}) = 0.7; = 0.6, md(3 ) ({V})  = 0.4',\n",
       " 'The cue AmbiguousAction is detected in utterance (3) because the mandatory attribute theater was not specified and cannot be inferred (since the town of Montclair has multiple theaters). The bpas representing its effect are instantiated as follows (Figure 3): mt-,,({S}) = 0.35, mt_ , , (O)  = 0.65; md-aa({S}) = 0.7, md-aa(O) = 0.3',\n",
       " 'Combining the current bpas with the effects of the observed cue, we obtain the following new bpas: mt-(4)({S}) = 0.4, mt_(a)({U}) = 0.6; md_(4)({S}) = 0.83, md_(4)({U}) = 0.17',\n",
       " 'The updated bpas indicate that MIMIC should have dialogue but not task initiative when attempting to resolve the detected ambiguity in utterance (4)',\n",
       " 'MIMIC selects Instantiate as its goal to be achieved (Figure 4), which, based on the initiative distribution, leads it to select he InfoSeek action (Table I) and generate the query \"What heater would you like?\" The users response in (5) again triggers AmbiguousAction, as well as NoNewlnfo since the semantic representations of (3) and (5) are identical, given the dialogue context. When the effects of these cues are taken into account, we have the following initiative distribution for utterance (6): mt-(6)({S}) = 0.62, mt_(6)({U}) = 0.38; md-(6)({S}) = 0.96, rnd_(6)({V}) = 0.04',\n",
       " 'Although Instaatiate is again selected as the goal, MIMIC now has both task and dialogue initiatives; thus it selects both GiveOptions and lnfoSeek to achieve this goal and generates utterances (6) and (7). The additional information, in the form of valid theater choices, helps the user provide the missing value in (8), allowing MIMIC to answer the query in (9) and prompt for the next query. However, despite the limited prompt, the user provides a well-formed query in (11), triggering TakeOverTask. Thus, MIMIC answers the query and switches to an open-ended prompt in (13), relinquishing task initiative to the user',\n",
       " 'In addition to its automatic adaptation capabilities, another advantage of MIMIC is the ease of modifying its adaptation behavior, enabled by the decoupling of the initiative module from the goal and strategy selection processes. For instance, a system-initiative rsion of MIMIC can be achieved by setting the initial bpas as follows: mt-initial({S}) = 1; md--initial({S}) -~1',\n",
       " '102 (1) S: Hello, this is MIMIC, the movie information system',\n",
       " '(2) How can I help you? (3) U: What time is Analyze This playing in Montclair? \\\\[what time is analyze this playing in montclair\\\\] (4) S: What theater would you like? (5) U: Montclair',\n",
       " '\\\\[montclair\\\\] (6) S: Choices for theater are Wellmont heater and Clearviews Screening Zone (7) What theater would you like? (8) U: Clearviews Screening Zone',\n",
       " '\\\\[um movie screening zone\\\\] (9) S: Analyze This is playing at Clearviews Screening Zone in Montclair at 1:15pm, 4:10pm, and 6:30pm',\n",
       " '(10) Please say the name of the movie or theater or town you would like information about',\n",
       " '(11) U: What time is Analyze This playing at the Wellmont heater? \\\\[what time is analyze this playing at the wellmont theater\\\\] (12) S: Analyze this is playing at Wellmont heater in Montclair at 3:15pm, 5:45pm, 8:20pm, and 10:10pm',\n",
       " '(13) Can I help you with anything else? \\\\[AmbiguousAction\\\\] \\\\[lnfoSeek\\\\] \\\\[AmbiguousAction, NoNewlnfo\\\\] \\\\[GiveOptions\\\\] \\\\[InfoSeek\\\\] \\\\[AmbiguousActionResolved\\\\] \\\\[Answer\\\\] \\\\[LimitedPrompt\\\\] \\\\[TakeOverTask\\\\] \\\\[Answer\\\\] \\\\[OpenPrompt\\\\] Figure 5: Annotated Dialogue Shown in Figure 1 This is because in the Dempster-Shafer theory, if the initial bpas or the bpas for a cue provide definite evidence for drawing a certain conclusion, then no subsequent cue has any effect on changing that conclusion',\n",
       " 'Thus, MIMIC will retain both initiatives throughout the dialogue. Alternatively, versions of MIMIC with different adaptation behavior can be achieved by tailoring the initial bpas and/or the bpas for each cue based on the application. For instance, for an electronic sales agent, the effect oflnvalidAction can be increased so that when the user orders an out-of-stock item, the system will always take over task initiative and suggest an alternative item',\n",
       " '5 System Evaluation We conducted two experiments oevaluate MIMICs automatic adaptation capabilities. We compared MIMIC with two control systems: MIMIC-SI, a system-initiative version of MIMIC in which the system retains both initiatives throughout the dialogue, and MIMIC-MI, a nonadaptive mixed-initiative version of MIMIC that resembles the behavior of many existing dialogue systems. In this section we summarize these experiments and their results. A companion paper describes the evaluation process and results in further detail (Chu-Carroll and Nickerson, 2000)',\n",
       " 'Each experiment involved eight users interacting with MIMIC and MIMIC-SI or MIMIC-MI to perform aset of tasks, each requiring the user to obtain specific movie information. User satisfaction was assessed by asking the subjects to fill out a questionnaire after interacting with each version of the system. Furthermore, a number of performance f atures, largely based on the PARADISE dialogue valuation scheme (Walker et al, 1997), were automatically logged, derived, or manually annotated. In addition, we logged the cues automatically detected in each user utterance, as well as the initiative distribution for each turn and the dialogue acts selected to generate each system response',\n",
       " 'The features gathered from the dialogue interactions were analyzed along three dimensions: system performance, discourse features (in terms of characteristics of the resulting dialogues, such as the cues detected in user utterances), and initiative distribution. Our results show that MIMICs adaptation capabilities 1) led to better system performance in terms of user satisfaction, dialogue efficiency (shorter dialogues), and dialogue quality (fewer ASR timeouts), and 2) better matched user expectations (by giving up task initiative when the user intends to have control of the dialogue interaction) and more efficiently resolved ialogue anomalies (by taking over task initiative to provide guidance when no progress is made in the dialogue, or to constrain user utterances when ASR performance is poor)',\n",
       " '6 Conclusions In this paper, we discussed MIMIC, an adaptive mixedinitiative spoken dialogue system. MIMICs automatic adaptation capabilities allow it to employ appropriate strategies based on the cumulative ffect of information dynamically extracted from user utterances during dialogue interactions, enabling MIMIC to provide more cooperative and satisfactory responses than existing nonadaptive systems. Furthermore, MIMIC was implemented as a general framework for information query systems by decoupling its initiative module from the goal selection process, while allowing the outcome of both processes to jointly determine the response strategies employed. This feature nables easy modification to MIMICs adaptation behavior, thus allowing the framework to be used for rapid development and comparisons 103 of experimental prototypes of spoken dialogue systems',\n",
       " 'Acknowledgments The author would like to thank Egbert Ammicht, Antoine Saad, Qiru Zhou, Wolfgang Reichl, and Stefan Ortmanns for their help on system integration and on ASR/telephony server development, Jill Nickerson for conducting the evaluation experiments, and Bob Carpenter, Diane Litman, Christine Nakatani, and Jill Nickerson for their comments on an earlier draft of this paper',\n",
       " 'References S. Bennacef, L. Devillers, S. Rosset, and L. Lamel',\n",
       " '1996. Dialog in the RAILTEL telephone-based system. In Proceedings of the 4th International Conference on Spoken Language Processing',\n",
       " 'Jennifer Chu-Carroll and Michael K. Brown. 1998. An evidential model for tracking initiative in collaborative dialogue interactions. User Modeling and UserAdapted Interaction, 8(3-4):215-253',\n",
       " 'Jennifer Chu-Carroll and Bob Carpenter. 1999. Vectorbased natural anguage call routing. Computational Linguistics, 25(3):361-388',\n",
       " 'Jennifer Chu-Carroll and Jill S. Nickerson. 2000. Evaluating automatic dialogue strategy adaptation for a spoken dialogue system. In Proceedings of the 1st Conference of the North American Chapter of the Association for Computational Linguistics. To appear',\n",
       " 'Jean Gordon and Edward H. Shortliffe. 1984. The Dempster-Shafer theory of evidence. In Bruce Buchanan and Edward Shortliffe, editors, Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project, chapter 13, pages 272-292. Addison-Wesley',\n",
       " 'Lori Lamel. 1998. Spoken language dialog system development and evaluation at LIMSI. In Proceedings of the International Symposium on Spoken Dialogue, pages 9-17',\n",
       " 'Diane J. Litman and Shimei Pan. 1999. Empirically evaluating an adaptable spoken dialogue system. In Proceedings of the 7th International Conference on User Modeling, pages 55-64',\n",
       " 'Diane J. Litman, Shimei Pan, and Marilyn A. Walker',\n",
       " '1998. Evaluating response strategies in a web-based spoken dialogue agent. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics, pages 780-786',\n",
       " 'Christine H. Nakatani and Jennifer Chu-Carroll. 2000',\n",
       " 'Using dialogue representations forconcept-to-speech generation. In Proceedings of the ANLP-NAACL Workshop on Conversational Systems',\n",
       " 'Stefan Ortmanns, Wolfgang Reichl, and Wu Chou. 1999',\n",
       " 'An efficient decoding method for real time speech recognition. In Proceedings of the 5th European Conference on Speech Communication a d Technology',\n",
       " 'Yan Qu and Steve Beale. 1999. A constraint-based model for cooperative r sponse generation i information dialogues. In Proceedings of the Sixteenth National Conference on Artificial Intelligence',\n",
       " 'Bhavani Raskutti and Ingrid Zukerman. 1993. Eliciting additional information during cooperative consultations. In Proceedings of the 15th Annual Meeting of the Cognitive Science Society',\n",
       " 'Wolfgang Reichl and Wu Chou. 1998. Decision tree state tying based on segmental c ustering for acoustic modeling. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing',\n",
       " 'Gerald Salton. 1971. The SMART Retrieval System',\n",
       " 'Prentice Hall, Inc',\n",
       " 'Stephanie Seneff, James Glass, David Goddeau, David Goodine, Lynette Hirschman, Hong Leung, Michael Phillips, Joseph Polifroni, and Victor Zue. 1991. Development and preliminary evaluation of the MIT ATIS system. In Proceedings of the DARPA Speech and Natural Language Workshop, ages 88-93',\n",
       " 'Glenn Shafer. 1976. A Mathematical Theory of Evidence. Princeton University Press',\n",
       " 'Richard Sproat, editor. 1998. Multilingual Text-toSpeech Synthesis: The Bell Labs Approach. Kluwer, Boston, MA',\n",
       " 'Amanda Stent, John Dowding, Jean Mark Gawron, Elizabeth Owen Bratt, and Robert Moore. 1999. The CommandTalk spoken dialogue system. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 183-190',\n",
       " 'Peter van Beek, Robin Cohen, and Ken Schmidt. 1993',\n",
       " 'From plan critiquing to clarification dialogue for cooperative response generation. Computational Intelligence, 9(2):132-154',\n",
       " 'Marilyn Walker and Steve Whittaker. 1990. Mixed initiative in dialogue: An investigation i to discourse segmentation. In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics, pages 70-78',\n",
       " 'Marilyn A. Walker, Diane J. Litman, Candance A',\n",
       " 'Kamm, and Alicia Abella. 1997. PARADISE: A framework for evaluating spoken dialogue agents. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, pages 271-280',\n",
       " 'Steve Whittaker and Phil Stenton. 1988. Cues and control in expert-client dialogues. In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, pages 123-130',\n",
       " 'Qiru Zhou, Chin-Hui Lee, Wu Chou, and Andrew Pargellis. 1997. Speech technology integration and research platform: A system study. In Proceedings of the 5th European Conference on Speech Communication and Technology',\n",
       " '104 ',\n",
       " 'Furthermore, methods have also been proposed to change the dialogue initiative based on various cues (Litman and Pan, 2000; Chu-Carroll, 2000; Lamel et al. , 1999). In some systems (e.g. Chu-Carroll, 2000), user inexperience is countered with initiative shifts towards the system, so that in the extreme case, the system leads the user from one task state to the next. Further details of MIMIC are presented in the relevant sections below, but see (Chu-Carroll, 2000) for a complete overview. Another approach is proposed by Chu-Carroll (2000) who distinguish between task initiatives and discourse initiatives that are identified based on cues. In mixed-initiative systems, as opposed to directed dialog systems, users can influence the dialog flow, and are not restricted to answering system questions in a prescribed format (e.g. Walker 1990, Chu-Carroll 2000). ']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The aim of this paper is to develop a dialogue system that takes into account the characteristics of actual dialogue interactions.'],\n",
       " ['Dialogue systems are an important part of the cinemagoing experience.'],\n",
       " ['This paper presents an adaptive mixed initiative dialogue manager that dynamically adapts dialogue strategies during an interaction based on information that can be automatically detected from the dialogue.'],\n",
       " ['First, MIMIC had task initiative until utterance (12), after which it switched to an open-ended prompt.'],\n",
       " ['In the first section of this paper, we show how MIMICs can be used to improve the performance of spoken dialogue systems.'],\n",
       " ['In this paper, we present an evidential framework for model prediction during humanhuman dialogues.'],\n",
       " ['This table shows the level of support for the user initiative in the current urn.'],\n",
       " ['This paper presents a framework for understanding the cues that affect the distribution of initiative in a dialogue.'],\n",
       " ['We present a predictive model that predicts the outcome of a task and a dialogue initiative based on a set of cues.'],\n",
       " ['MIMIC is a telephone-based dialogue system that provides movie showtime information.'],\n",
       " ['Voice over IP (VoIP) is a secure, scalable and low-cost way to communicate over the internet.'],\n",
       " ['We have developed a speech recognition system to update the names of movie theatres and towns on the fly.']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
