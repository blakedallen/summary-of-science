[
  {
    "citance_No": 1, 
    "citing_paper_id": "W95-0107", 
    "citing_paper_authority": 170, 
    "citing_paper_authors": "Lance A., Ramshaw | Mitchell P., Marcus", 
    "raw_text": "This technique has previously been used not only for part-of-speech tagging (Brill, 1994), but also for prepositional phrase attachment disambiguation (Brill and Resnik, 1994), and assigning unlabeled binary-branching tree structure to sentences (Brill, 1993a)", 
    "clean_text": "This technique has previously been used not only for part-of-speech tagging (Brill, 1994), but also for prepositional phrase attachment disambiguation (Brill and Resnik, 1994), and assigning unlabeled binary-branching tree structure to sentences (Brill, 1993a).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-3010", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Clayton, Greenberg", 
    "raw_text": "Brill and Resnik (1994) trained a transformation-based learning algorithm on 12,766 quadruples from WSJ, with modifications similar to those by Collins and Brooks (1995)", 
    "clean_text": "Brill and Resnik (1994) trained a transformation-based learning algorithm on 12,766 quadruples from WSJ, with modifications similar to those by Collins and Brooks (1995).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W99-0705", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Torbjorn, Lager", 
    "raw_text": "Since Eric Brill first introduced the method of Transformation-Based Learning (TBL) it has been used to learn rules for many natural anguage processing tasks, such as part-of-speech tagging [Brill, 1995], PPattachment disambiguation [Brill and Resnik, 1994], text chunking [Ramshaw and Marcus, 1995], spelling correction [Mangu and Brill, 1997], dialogue act tagging [Samuel et al, 1998] and ellipsis resolution [Hardt, 1998]", 
    "clean_text": "Since Eric Brill first introduced the method of Transformation-Based Learning (TBL) it has been used to learn rules for many natural anguage processing tasks, such as part-of-speech tagging [Brill, 1995], PP attachment disambiguation [Brill and Resnik, 1994], text chunking [Ramshaw and Marcus, 1995], spelling correction [Mangu and Brill, 1997], dialogue act tagging [Samuel et al, 1998] and ellipsis resolution [Hardt, 1998].", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P00-1017", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Alexander S., Yeh", 
    "raw_text": "This alternative, which we have yet to try, has the advantage of tting into the transformation-based error-driven paradigm (Brill and Resnik, 1994) more cleanly than having a translation stage", 
    "clean_text": "This alternative, which we have yet to try, has the advantage of fitting into the transformation-based error-driven paradigm (Brill and Resnik, 1994) more cleanly than having a translation stage.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "H05-1105", 
    "citing_paper_authority": 19, 
    "citing_paper_authors": "Preslav, Nakov | Marti A., Hearst", 
    "raw_text": "Brill and Resnik (1994) used the supervised transformation-based learning method and lexical and conceptual classes derived from WordNet, achieving 82% precision on 500 randomly selected examples", 
    "clean_text": "Brill and Resnik (1994) used the supervised transformation-based learning method and lexical and conceptual classes derived from WordNet, achieving 82% precision on 500 randomly selected examples.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "A97-1055", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Alessandro, Cucchiarelli | Paola, Velardi", 
    "raw_text": "For example, in (Brill and Resnik, 1994) clustering PP heads according to WordNetsynsets produced only a 1% improvement in a PP disambiguation task, with respect to the non-clustered method", 
    "clean_text": "For example, in (Brill and Resnik, 1994) clustering PP heads according to WordNetsynsets produced only a 1% improvement in a PP disambiguation task, with respect to the non-clustered method.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W01-0707", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Eric, Gaussier | Nicola, Cancedda", 
    "raw_text": "The results obtained in previous works re lying on semantic classes are above ours (around 0.82 3This huge number of tokens can be explained by the fact that the lexicon used for tokenization and tagging integrates many multi-word expressions which are not part of these mantic lexicon for (Brill and Resnik, 1994) and 0.77 for (LauerandDras, 1994)), but a direct comparison is difficult inasmuch as only three-word sequences (V N P, for (Brill and Resnik, 1994) and N N N for (Lauer and Dras, 1994)) were used for evaluation in those works, and the language studied is English", 
    "clean_text": "This huge number of tokens can be explained by the fact that the lexicon used for tokenization and tagging integrates many multi-word expressions which are not part of these mantic lexicon for (Brill and Resnik, 1994) and 0.77 for (LauerandDras, 1994)), but a direct comparison is difficult inasmuch as only three-word sequences (V N P, for (Brill and Resnik, 1994) and N N N for (Lauer and Dras, 1994)) were used for evaluation in those works, and the language studied is English.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W03-1604", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Fabio, Rinaldi | James, Dowdall | Kaarel, Kaljurand | Michael, Hess | Diego, Molla Aliod", 
    "raw_text": "This solves the first of the problems that we have identified in the introduction (? The Parsing Problem?) .In later stages of processing, a corpus-based approach (Brill and Resnik, 1994) is used to deal with ambiguities that can not be solved with syntactic information only, in particular attachments of prepositional phrases, gerunds and infinitive constructions", 
    "clean_text": "In later stages of processing, a corpus-based approach (Brill and Resnik, 1994) is used to deal with ambiguities that cannot be solved with syntactic information only, in particular attachments of prepositional phrases, gerunds and infinitive constructions.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W99-0606", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Steven, Abney | Robert E., Schapire | Yoram, Singer", 
    "raw_text": "For example, the sentence Congress accused the president of peccadillos is classified according to the attachment site of the prepositional phrase: attachment toN: accused [the president of peccadillos] attachment to V: (4) accused [the president] [of peccadillos] The UPenn Treebank-II Parsed Wall Street Journal corpus includes PP-attachment information, and PP-attachment classifiers based on this data have been previously described in Ratnaparkhi, Reynar, Roukos (1994), Brill and Resnik (1994), and Collins and Brooks (1995)", 
    "clean_text": "For example, the sentence Congress accused the president of peccadillos is classified according to the attachment site of the prepositional phrase: attachment toN: accused [the president of peccadillos] attachment to V: (4) accused [the president] [of peccadillos] The UPenn Treebank-II Parsed Wall Street Journal corpus includes PP-attachment information, and PP-attachment classifiers based on this data have been previously described in Ratnaparkhi, Reynar, Roukos (1994), Brill and Resnik (1994), and Collins and Brooks (1995).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P00-1014", 
    "citing_paper_authority": 19, 
    "citing_paper_authors": "Patrick, Pantel | Dekang, Lin", 
    "raw_text": "A non-statistical supervised approach by Brill and Resnik (1994) yielded 81.8% accuracy using a transformation-based approach (Brill, 1995) and incorporating word-class information", 
    "clean_text": "A non-statistical supervised approach by Brill and Resnik (1994) yielded 81.8% accuracy using a transformation-based approach (Brill, 1995) and incorporating word-class information.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P00-1014", 
    "citing_paper_authority": 19, 
    "citing_paper_authors": "Patrick, Pantel | Dekang, Lin", 
    "raw_text": "We describe the different classifiers below: cl base: the baseline described in Section 7.2clR1: uses a maximum entropy model (Ratnaparkhi et al, 1994 )clBR5: uses transformation-based learning (Brill and Resnik, 1994) cl CB: uses a backed-off model (Collins and Brooks, 1995 )clSN: induces a decision tree with a sense-tagged corpus, using a semantic dictionary (Stetina and Nagao, 1997 )clHR6: uses lexical preference (Hindle and Rooth, 1993 )clR2: uses a heuristic extraction of unambiguous attachments (Ratnaparkhi, 1998) cl Pl: uses the algorithm described in this paper Our classifier outperforms all previous unsupervised techniques and approaches the performance of supervised algorithm", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W99-0628", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Martha A., Alegre | Josep M., Sopena | Agusti, Lloberas", 
    "raw_text": "A very impor232 Author Best Hindle and Rooth (1993) 80.0% Resnik and Hearst (1993) 83.9% WN Resnik and Hearst (1993) 75.0% Ratnaparkhi et al (1994) 81.6% Brill and Resnik (1994) 81.8 Collins and Brooks (1995) 84.5 Stettina and Nagao (1997) 88.0 Sopena et al (1998) 86.2 Li and Abe (1998) 82.4 Table 1: Test and accuracy results%%%%% Classes Use of Ratnaparkhi set No No WN No No MIC Yes WN No No Yes WN Yes WN No WN No reported in previous works", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "H05-1035", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Marian, Olteanu | Dan, Moldovan", 
    "raw_text": "The difference in accuracy between a SVM model applied to RRR dataset (RRR-basic experiment) and the same experiment applied to TB2 dataset (TB2 278 Description Accuracy Data Extra Supervision Always noun 55.0 RRR Most likely for each P 72.19 RRR Most likely for each P 72.30 TB2 Most likely for each P 81.73 FN Average human, headwords (Ratnaparkhi et al, 1994) 88.2 RRR Average human, whole sentence (Ratnaparkhi et al, 1994) 93.2 RRR Maximum Likelihood-based (Hindle and Rooth, 1993) 79.7 AP Maximum entropy, words (Ratnaparkhi et al, 1994) 77.7 RRR Maximum entropy, words& amp; classes (Ratnaparkhi et al, 1994) 81.6 RRR Decision trees (Ratnaparkhi et al, 1994) 77.7 RRR Transformation-Based Learning (Brill and Resnik, 1994) 81.8 WordNet Maximum-Likelihood based (Collins and Brooks, 1995) 84.5 RRR Maximum-Likelihood based (Collins and Brooks, 1995) 86.1 TB2 Decision trees& amp; WSD (Stetina and Nagao, 1997) 88.1 RRR WordNet Memory-based Learning (Zavrel et al, 1997) 84.4 RRR LexSpace Maximum entropy, unsupervised (Ratnaparkhi, 1998) 81.9 Maximum entropy, supervised (Ratnaparkhi, 1998) 83.7 RRR Neural Nets (Alegre et al, 1999) 86.0 RRR WordNet Boosting (Abney et al, 1999) 84.4 RRR Semi-probabilistic (Pantel and Lin, 2000) 84.31 RRR Maximum entropy, ensemble (McLauchlan, 2001) 85.5 RRR LSA SVM (Vanschoenwinkel and Manderick, 2003) 84.8 RRR Nearest-neighbor (Zhao and Lin, 2004) 86.5 RRR DWS FN dataset ,w/o semantic features (FN-best-no-sem) 91.79 FN PR-WWW FN dataset ,w/ semantic features (FN-best-sem) 92.85 FN PR-WWW TB2 dataset, best feature set (TB2-best) 93.62 TB2 PR-WWW Table 5: Accuracy of PP-attachment ambiguity resolution (our results in bold) basic experiment) is 2.9%", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P06-2029", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Kilian A., Foth | Wolfgang, Menzel", 
    "raw_text": "Supervised training methods already applied to PP attachment range from stochastic maximum likelihood (Collins and Brooks, 1995) or maxi mum entropy models (Ratnaparkhi et al, 1994) to the induction of transformation rules (Brill and Resnik, 1994), decision trees (Stetina and Nagao, 1997) and connectionist models (Sopena et al, 1998)", 
    "clean_text": "Supervised training methods already applied to PP attachment range from stochastic maximum likelihood (Collins and Brooks, 1995) or maximum entropy models (Ratnaparkhi et al, 1994) to the induction of transformation rules (Brill and Resnik, 1994), decision trees (Stetina and Nagao, 1997) and connectionist models (Sopena et al, 1998).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W97-1016", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Jakub, Zavrel | Walter, Daelemans | Jorn, Veenstra", 
    "raw_text": "Brill and Resnik (1994 )appl! ed Error-Driven TransformationBased Learning, Ratnaparkhi, Reynar and Roukos (1994) applied a Maximum Entropy model, Franz (1996) used a Loglinear model, and Collins and Brooks (1995) obtained good results using a BackOff model", 
    "clean_text": "Brill and Resnik (1994) applied Error-Driven TransformationBased Learning, Ratnaparkhi, Reynar and Roukos (1994) applied a Maximum Entropy model, Franz (1996) used a Loglinear model, and Collins and Brooks (1995) obtained good results using a BackOff model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W97-1016", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Jakub, Zavrel | Walter, Daelemans | Jorn, Veenstra", 
    "raw_text": "The other methods for which results have been reported on this dataset include decision trees, Maximum Entropy (Ratnaparkhi, Reynar, and Roukos, 1994), and Error-Driven TransformationBased Learning (Brill and Resnik, 1994), 3 which were clearly outperformed by both IB1 and IBI-IG, even though e.g. Brill~ Resnik used more elaborate feature sets (words and WordNet classes)", 
    "clean_text": "The other methods for which results have been reported on this dataset include decision trees, Maximum Entropy (Ratnaparkhi, Reynar, and Roukos, 1994), and Error-Driven TransformationBased Learning (Brill and Resnik, 1994), which were clearly outperformed by both IB1 and IBI-IG, even though e.g. Brill~ Resnik used more elaborate feature sets (words and WordNet classes).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W97-1016", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Jakub, Zavrel | Walter, Daelemans | Jorn, Veenstra", 
    "raw_text": "Brill and Resnik (1994) applied Error-Driven Transformation-Based Learning to this task, using the verb ,nounl, preposition, and noun2 features", 
    "clean_text": "Brill and Resnik (1994) applied Error-Driven Transformation-Based Learning to this task, using the verb, noun1, preposition, and noun2 features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "C02-1004", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Martin, Volk", 
    "raw_text": "Supervised methods are as varied as the Back off approach by Collins and Brooks (1995) and the Transformation-based approach by Brill and Resnik (1994)", 
    "clean_text": "Supervised methods are as varied as the Back off approach by Collins and Brooks (1995) and the Transformation-based approach by Brill and Resnik (1994).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W97-1005", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Mehmet, Kayaalp | Ted, Pedersen | Rebecca F., Bruce", 
    "raw_text": "We use the PPA data created by (Brill and Resnik, 1994) and (Ratnaparkhi et al, 1994) to objectively compare the performances of the systems", 
    "clean_text": "We use the PPA data created by (Brill and Resnik, 1994) and (Ratnaparkhi et al, 1994) to objectively compare the performances of the systems.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W97-1005", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Mehmet, Kayaalp | Ted, Pedersen | Rebecca F., Bruce", 
    "raw_text": "I~ (A] B, C, D, E)= I (A, B, C, D)+ I (A, B, D, E)+] (A, C, D, E)] (B, C, D)+ I (B, D, E)+] (C, D, E) (12) f (A= 1) f (A= 2)& quot; 1 max f (A=~) +~=2) &apos; f (A -&apos;~) ~?~ -2) (10) The lower bound for the B& amp; R data is 63% (Brill and Resnik, 1994) and for the IBM data is 52% (Ratnaparkhi et al, 1994)", 
    "clean_text": "(10) The lower bound for the B&R data is 63% (Brill and Resnik, 1994) and for the IBM data is 52% (Ratnaparkhi et al, 1994).", 
    "keep_for_gold": 0
  }
]
