[
  {
    "citance_No": 1, 
    "citing_paper_id": "W07-0407", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Sriram, Venkatapathy | Aravind K., Joshi", 
    "raw_text": "(Moore, 2005) has proposed an approach which does not impose any restrictions on the form of model features", 
    "clean_text": "(Moore, 2005) has proposed an approach which does not impose any restrictions on the form of model features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W07-0407", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Sriram, Venkatapathy | Aravind K., Joshi", 
    "raw_text": "LLR and CLP are the word association statistics used in Moore? s work (Moore, 2005)", 
    "clean_text": "LLR and CLP are the word association statistics used in Moore's work (Moore, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W07-0407", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Sriram, Venkatapathy | Aravind K., Joshi", 
    "raw_text": "A variation of this feature was used by (Moore, 2005) in his paper", 
    "clean_text": "A variation of this feature was used by (Moore, 2005) in his paper.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "C10-1003", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Daniel, Andrade | Tetsuya, Nasukawa | Jun'ichi, Tsujii", 
    "raw_text": "Infact, LLR can still be used for extracting positive associations by filtering in a pre-processing step words with possibly negative associations (Moore, 2005)", 
    "clean_text": "In fact, LLR can still be used for extracting positive associations by filtering in a pre-processing step words with possibly negative associations (Moore, 2005).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "C10-1003", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Daniel, Andrade | Tetsuya, Nasukawa | Jun'ichi, Tsujii", 
    "raw_text": "Furthermore, to ensure that only positive association counts, we set the probability to zero if p (x, y) &lt; p (x)? p (y), where the probabilities are estimated using relative frequencies (Moore, 2005)", 
    "clean_text": "Furthermore, to ensure that only positive association counts, we set the probability to zero if p (x, y) < p (x) p (y), where the probabilities are estimated using relative frequencies (Moore, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P06-1065", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Robert C., Moore | Scott Wen-Tau, Yih | Andreas, Bode", 
    "raw_text": "The work cited above makes use of various training procedures and a wide variety of features. Indeed, whereas it can be difficult to design a factorization of a generative model that incorporates all the desired information, it is relatively easy to add arbitrary features to a discriminative model. We take advantage of this, building on our existing framework (Moore, 2005), to substantially reduce the alignment error rate (AER) we previously reported, given the same training and test data", 
    "clean_text": "We take advantage of this, building on our existing framework (Moore, 2005), to substantially reduce the alignment error rate (AER) we previously reported, given the same training and test data.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P06-1065", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Robert C., Moore | Scott Wen-Tau, Yih | Andreas, Bode", 
    "raw_text": "As in our previous work (Moore, 2005), we train two models we call stage 1 and stage 2, both inthe form of a weighted linear combination of feature values extracted from a pair of sentences and a proposed word alignment of them", 
    "clean_text": "As in our previous work (Moore, 2005), we train two models we call stage 1 and stage 2, both in the form of a weighted linear combination of feature values extracted from a pair of sentences and a proposed word alignment of them.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "C08-2014", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Adrien, Lardilleux | Yves, Lepage", 
    "raw_text": "Firstly, as denoted by Moore (2005), one needs to tune numerous parameters in order to optimize the results for a particular alignment task, which can be very time consuming", 
    "clean_text": "Firstly, as denoted by Moore (2005), one needs to tune numerous parameters in order to optimize the results for a particular alignment task, which can be very time consuming.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W06-1672", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Dmitry, Zelenko | Chinatsu, Aone", 
    "raw_text": "It will also be interesting to study the relationship between our discriminative alignment-free methods and recently proposed discriminative alignment-based methods for transliteration and translation (Taskar et al 2005a; Moore 2005)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P06-2014", 
    "citing_paper_authority": 23, 
    "citing_paper_authors": "Colin, Cherry | Dekang, Lin", 
    "raw_text": "d is an absolute discount parameter as in (Moore, 2005)", 
    "clean_text": "d is an absolute discount parameter as in (Moore, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P06-2014", 
    "citing_paper_authority": 23, 
    "citing_paper_authors": "Colin, Cherry | Dekang, Lin", 
    "raw_text": "(Moore, 2005) uses an averaged perceptron for training with a customized beam search", 
    "clean_text": "(Moore, 2005) uses an averaged perceptron for training with a customized beam search.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P10-1033", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Shujie, Liu | Chi-Ho, Li | Ming, Zhou", 
    "raw_text": "2) Conditional link probability (Moore, 2005)", 
    "clean_text": "2) Conditional link probability (Moore, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W10-2917", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Shujian, Huang | Kangxi, Li | Xinyu, Dai | Jiajun, Chen", 
    "raw_text": "For example, Moore (2005) uses statistics like log-likelihood-ratio and conditional likelihood-probability to measure word associations; Liu et al (2005) and Taskar et al (2005) use results from IBM Model 3 and Model 4, respectively", 
    "clean_text": "For example, Moore (2005) uses statistics like log-likelihood-ratio and conditional likelihood-probability to measure word associations; Liu et al (2005) and Taskar et al (2005) use results from IBM Model 3 and Model 4, respectively.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W10-2917", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Shujian, Huang | Kangxi, Li | Xinyu, Dai | Jiajun, Chen", 
    "raw_text": "d cooc (e, f) (2) where link (e, f) is the number of times e and f are linked in the aligned corpus ;cooc (e, f) is the number of times e and f appear inthe same sentence pair; d is a discounting constant which is set to 0.4 following Moore (2005)", 
    "clean_text": "d is a discounting constant which is set to 0.4 following Moore (2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W10-2917", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Shujian, Huang | Kangxi, Li | Xinyu, Dai | Jiajun, Chen", 
    "raw_text": "Moore (2005) proposes a similar framework, but with more features and a different search method", 
    "clean_text": "Moore (2005) proposes a similar framework, but with more features and a different search method.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "I08-4001", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Zhoujun, Li | Wen-Han, Chao | Yue-Xin, Chen", 
    "raw_text": "In order to obtain the word alignment satisfying the ITG constraint, Wu (1997) propose a DPalgorithm, and we (Chao and Li, 2007) have transferred the constraint to four simple position judgment procedures in an explicit way, so that we can incorporate the ITG constraint as a feature into a log linear word alignment model (Moore, 2005)", 
    "clean_text": "In order to obtain the word alignment satisfying the ITG constraint, Wu (1997) propose a DPalgorithm, and we (Chao and Li, 2007) have transferred the constraint to four simple position judgment procedures in an explicit way, so that we can incorporate the ITG constraint as a feature into a log linear word alignment model (Moore, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P14-1138", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Akihiro, Tamura | Taro, Watanabe | Eiichiro, Sumita", 
    "raw_text": "These models are roughly clustered into two groups: generative models, such as those pro posed by Brown et al (1993), Vogel et al (1996), and Och and Ney (2003), and discriminative mod els, such as those proposed by Taskar et al (2005), Moore (2005), and Blunsom and Cohn (2006)", 
    "clean_text": "These models are roughly clustered into two groups: generative models, such as those pro posed by Brown et al (1993), Vogel et al (1996), and Och and Ney (2003), and discriminative models, such as those proposed by Taskar et al (2005), Moore (2005), and Blunsom and Cohn (2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P10-1017", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Jason, Riesa | Daniel, Marcu", 
    "raw_text": "Unfortunately, as Moore (2005) points out, it is usually difficult to extend a given generative model with feature functions without changing the entire generative story", 
    "clean_text": "Unfortunately, as Moore (2005) points out, it is usually difficult to extend a given generative model with feature functions without changing the entire generative story.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P11-1042", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Chris, Dyer | Jonathan H., Clark | Alon, Lavie | Noah A., Smith", 
    "raw_text": "length model 1Moore (2005) likewise uses this example to motivate the need for models that support arbitrary, overlapping features", 
    "clean_text": "Moore (2005) likewise uses this example to motivate the need for models that support arbitrary, overlapping features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P06-1097", 
    "citing_paper_authority": 28, 
    "citing_paper_authors": "Alexander, Fraser | Daniel, Marcu", 
    "raw_text": "MODEL 4 REFINED 30.63 76.4 F/E EMD 2 REFINED 31.56 81.2 Table 8: Evaluation of Translation Quality with the baseline (with the exception of (Moore, 2005))", 
    "clean_text": "", 
    "keep_for_gold": 0
  }
]
