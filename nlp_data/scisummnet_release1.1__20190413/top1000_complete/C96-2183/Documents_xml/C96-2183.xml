<PAPER>
  <S sid="0" ssid="0">Mot ivat ions and Methods  tbr Text Simpli f icat ion R. Chandrasekar*  Chr ist ine Doran B. Srinivas Institute for Research in l)el)artm&lt;;nt of Deparl;mcnt of Cognitive, Science &amp; (]cntcr for [,inguistics (]Oml)uter $?</S>
  <S sid="1" ssid="1">the Advanced Study of hldia InlbrHlatioll Scienc(; University ot7 Pcnnsylwmia, lqfiladclphia, PA 19104 {ra?ckeyc, doran, sr in?</S>
  <S sid="2" ssid="2">upenn, edu Abst ract Lottg alld eolni)licated seltteltces prov(: to b(: a. stumbling block for current systems rely- ing on N[, input.</S>
  <S sid="3" ssid="3">These systenls stand to gaill frolil ntethods that syntacti&lt;:aHy sim- plily su&lt;:h sentences.</S>
  <S sid="4" ssid="4">]b simplify a sen= tence, we nee&lt;t an idea of tit(."</S>
  <S sid="5" ssid="5">structure of the sentence, to identify the &lt;:omponents o be separated out.</S>
  <S sid="6" ssid="6">Obviously a parser couhl be used to obtain the complete structure of the sentence.</S>
  <S sid="7" ssid="7">][owever, hill parsing is slow a+nd i)rone to fa.ilure, especially on &lt;:omph!x sentences.</S>
  <S sid="8" ssid="8">In this l)aper, we consider two alternatives to fu]l parsing which could be use&lt;l for simplification.</S>
  <S sid="9" ssid="9">The tirst al)l)roach uses a Finite State Grammar (FSG) to pro- dn&lt;:e noun and verb groups while the second uses a Superta.gging model to i)roduce de- pendency linkages.</S>
  <S sid="10" ssid="10">We discuss the impact of these two input representations on the sim- plification pro(:ess.</S>
  <S sid="11" ssid="11">1 Reasons  fo r  Text  S impl i f i ca t ion l ,ong and &lt;:oml)licatcd sentences prove to be a s tuml J ing  block for &lt;urrent systems which rely on natural  language input.</S>
  <S sid="12" ssid="12">llmsc systems stand to gain from metho&lt;ls that  preprocess uch sentences so as to make them simpler.</S>
  <S sid="13" ssid="13">Consider, for exam- ph;, the following sentence: ( l )  7he embattled Major government survived a crucial vole on coal pits closure as its last-minute concessions curbed the extent of lbry revolt over an issue that generated uausual heat in the l]ousc of Commons and brought the miners to London streets.</S>
  <S sid="14" ssid="14">Such sentences are not uncommon in newswire texts.</S>
  <S sid="15" ssid="15">(  ]ompare this with the mult i -sentence ver- sion which has been manual ly  simplif ied: (2) The embatlled Major governmcnl survived a crucial vote ou coal pits closure.</S>
  <S sid="16" ssid="16">Its last:minute conccssious curbed the cxlenl o]" *On leave flom the National Centre for Soft, ware Techno]ogy, (lulmohar (?ross Road No.</S>
  <S sid="17" ssid="17">9, Juhu, Bombay 4:0(/ (149, India Tory revolt over the coal-miue issue.</S>
  <S sid="18" ssid="18">Th.is issue generaled unusual heat in the ltousc of Commons.</S>
  <S sid="19" ssid="19">II also brought the miners to London streels.</S>
  <S sid="20" ssid="20">If coml&gt;lex text can be made simphx, sen- ten(-es beconae easier to process, both for In:O- grams and humans.</S>
  <S sid="21" ssid="21">Wc discuss a simplif ica- tion process which identifies components of a sen- tence that  may be separated out, and transforms each of these into f rec-sta ,d ing s impler sentences.</S>
  <S sid="22" ssid="22">(]learly, some mmnees of meaning from the origi- nal text may be lost in the simpli f ication process.</S>
  <S sid="23" ssid="23">Simplit ication is theretbre inappropr iate  for texts (such as legal docunlents) where it is importa.nt not to lose any nuance.</S>
  <S sid="24" ssid="24">I|owew;r, one c.~tl] COil- ceive of several areas of natura l  language process- ing where such simplit ication would be of great use.</S>
  <S sid="25" ssid="25">This is especially true in dolnains uch as Ina- chine translat ion,  which commonly  have a manual post-processing stage, where semantic  and prag- mat ic  repairs may be &lt;arried out if ne&lt;;essary.</S>
  <S sid="26" ssid="26">Parsing: Syntact ical ly  &lt;:omplex sentences arc likely to generate a large number of parses, and may cause parsers to fail altogether.</S>
  <S sid="27" ssid="27">Re- solving ambiguit ies in a t tachment  of con- st i tuents is non-tr ivial .</S>
  <S sid="28" ssid="28">This ambiguii, y is re- duced for simpler sentences in&lt;e they involve fewer constituents.</S>
  <S sid="29" ssid="29">Fhus s impler sentences lead to faster parsing and less parse aml)igu- ity.</S>
  <S sid="30" ssid="30">Once the i&gt;arses for the s impler sentences are obtained, the subparses can be assembled to form a full parse, or left as is, depending on the appl icat ion.</S>
  <S sid="31" ssid="31">Machine Translat ion (MT): As in the pars- ing case, s impli f ication results in s impler scn- tential  structures and reduced ambiguity.</S>
  <S sid="32" ssid="32">As argued in (Chandrasekar,  1994), this conld lead to improvements in the qual ity of ma- chine translat ion.</S>
  <S sid="33" ssid="33">In format ion Retrieval: IR systems usual ly re- trieve large segments  of texts of which only a part  n]ay bc reh~wml,.</S>
  <S sid="34" ssid="34">Wit | ,  simplif ied texts, it is possible to extract  Sl&gt;eCific phrases or simple sentences of relevance in response to queries.</S>
  <S sid="35" ssid="35">Summarization: With the overload of infor- mation that people face today, it would be very helpful to have text summarization tools that; reduce large bodies of text to the salient minimum.</S>
  <S sid="36" ssid="36">Simplification can be used to weed out irrelevant ext with greater precision, and thus aid in summarization.</S>
  <S sid="37" ssid="37">Clarity of Text: Assembly/use/maintenance manuals must be clear and simple to follow.</S>
  <S sid="38" ssid="38">Aircraft companies use a Simplified English for maintenance manuals precisely for this reason (Wojcik et M., 1993).</S>
  <S sid="39" ssid="39">However, it is not easy to create text in such an artifi- cially constrained language.</S>
  <S sid="40" ssid="40">Automatic (or semi-automatic ) simplification could be used to ensure that texts adhere to standards.</S>
  <S sid="41" ssid="41">We view simplification as a two stage process.</S>
  <S sid="42" ssid="42">The first stage provides a structural representa- tion for a sentence on which the second stage ap- plies a sequence of rules to identify and extract he components that can be simplified.</S>
  <S sid="43" ssid="43">One could use a parser to obtain the complete structure of the sentence.</S>
  <S sid="44" ssid="44">If all the constituents of the sentence along with the dependency relations are given, simplification is straightforward, ttowever, full parsing is slow and prone to failure, especially on complex sentences.</S>
  <S sid="45" ssid="45">To overcome the limitations of full parsers, researchers have adopted FSG based approaches to parsing (Abney, 1994; Hobbs et al., 1992; Grishman, 1995).</S>
  <S sid="46" ssid="46">These parsers are fast and reasonably robust; they produce sequences of noun and verb groups without any hierarchical structure.</S>
  <S sid="47" ssid="47">Section 3 discusses an FSG based ap- proach to simplification.</S>
  <S sid="48" ssid="48">An alternative approach which is both fast and yields hierarchical struc- ture is discussed in Section 4.</S>
  <S sid="49" ssid="49">In Section 5 we compare the two approaches, and address some general concerns for the simplification task in Sec- tion 6.</S>
  <S sid="50" ssid="50">2 The Basics of Simplification Text simplification uses the f~ct that complex texts typically contains complex syntax, some of which may be particular to specific domain of dis- course, such as newswire texts.</S>
  <S sid="51" ssid="51">We assume that the simplification system will process one sentence at a time.</S>
  <S sid="52" ssid="52">Interactions across sentences will not bc considered.</S>
  <S sid="53" ssid="53">Wc also assume that sentences have to be maximally simplified.</S>
  <S sid="54" ssid="54">2o simplify sentences, we nced to know where we can split them.</S>
  <S sid="55" ssid="55">We define articulation-points to be those points at which sentences may be log- ically split.</S>
  <S sid="56" ssid="56">Possible articulation points include the beginnings and ends of phrases, punctuation marks, subordinating and coordinating conjunc- tions, and relative pronouns.</S>
  <S sid="57" ssid="57">These articulation points are gcneral, and should apply to arbitrary English texts.</S>
  <S sid="58" ssid="58">These may, however, be augmented with domain-specific articulation points.</S>
  <S sid="59" ssid="59">We can use these articulation-points to define a set of rules which map froln given sentence patterns to sim- pler sentences patterns.</S>
  <S sid="60" ssid="60">These rules are repeat - edly applied on each sentence until they do not apply any more.</S>
  <S sid="61" ssid="61">For example, the sentence (3) with a relative clause can be simplified into two sentences (4).</S>
  <S sid="62" ssid="62">(3) Talwinder Singh, who masterminded the Kanishka crash in 198~, was killed in a fierce lwo-honr e~.connter... (4) Talwindcr Singh was killed in a .fierce two-hoar cncounler ... Talwinder Siugh masterminded the Kanishka crash in 198~.</S>
  <S sid="63" ssid="63">3 FSG based Simplification (Chandrasekar, 1994) discusses an approach that uses a FSG for text simplification as part of a machine aided translation prototype named Vaakya.</S>
  <S sid="64" ssid="64">In this approach, we consider sentences to be composed of sequence of word groups, or chunks.</S>
  <S sid="65" ssid="65">Chunk boundaries are regarded as poten- tial articulation-points.</S>
  <S sid="66" ssid="66">Chunking allows us to de- fine the syntax of a sentence and the structure of simplification rules at a coarser granularity, since we need no longer be concerned with the internal structure of the chunks.</S>
  <S sid="67" ssid="67">In this approach, we first tag each word with its part-of-speech.</S>
  <S sid="68" ssid="68">Chunks are then identified nsing a FSG.</S>
  <S sid="69" ssid="69">Each chunk is a word group consisting of a verb phrase or a noun phrase, with some attached modifiers.</S>
  <S sid="70" ssid="70">The noun phrase recognizer also marks the number (singular/plural) of the phrase.</S>
  <S sid="71" ssid="71">The verb phrase recognizer provides some information on tense, voice and aspect.</S>
  <S sid="72" ssid="72">Chunks identified by this mechanism include phrases uch as the extent of Tory ~evolt and have recently bcen finalizcd.</S>
  <S sid="73" ssid="73">The chunked sentences are then simplified using a set of ordered simplification rules.</S>
  <S sid="74" ssid="74">The orderi~g of the rules is decided manually, to take care of more frequent ransformations first, and to avoid unproductive rule interaction.</S>
  <S sid="75" ssid="75">An example rule that simplifies sentences with a relative pronoun is shown in (5).</S>
  <S sid="76" ssid="76">(5) X:tiP, ReXPron Y, Z --* X:tiP Z. X:tiP Y.</S>
  <S sid="77" ssid="77">The rule is interpreted as follows.</S>
  <S sid="78" ssid="78">If a sentence starts with a noun phrase (X:tiP), and is followed by a phrase with a relative pronoun, of the [orm ( , l%elPron Y ,) followed by soIne (Z), where Y and Z are arbitrary sequences of words, then the sentence may be simplified into two sentences, namely the sequence (X) followed by (Z), and (X) followed by (Y).</S>
  <S sid="79" ssid="79">The resulting sen];ences are then recursively simplified, to the extent possible.</S>
  <S sid="80" ssid="80">The system has been tested on news text, and performs well on certain classes of sentences.</S>
  <S sid="81" ssid="81">See (Chandrasekar and R, amani, 1996) ibr details of quantitative valuation of the system, including an evaluation of the acceptability of the resulting 1042 sentences.</S>
  <S sid="82" ssid="82">A set of news stories, consist, ing of 224 sentences, was simplitied by the prototype system, resulting in 369 simplified sentences.</S>
  <S sid="83" ssid="83">Ilowever, there are certain weMenesses in this system, caused mostly by the relatively simple mechanisms used to detect phrases and attach- meats.</S>
  <S sid="84" ssid="84">Sentences which include long distance or crossed del)enden(ies, and sentences which have malt|ply stacked appositives are not handled llrOl)erly; nor are sentences with atnbiguous or un- ch.ar attachnwnts.</S>
  <S sid="85" ssid="85">Some of these prol)]oms can be handhd I)y augmenting the ruh set but what is ieally require(I is ntorc syntactic firel)ower.</S>
  <S sid="86" ssid="86">4 A Dependency-based model A second a.I)l)roaeh to simplification is to use ri(:her syntactic in[brmation, in terms of both con- stituency inlbrmation and dependency informa- tion.</S>
  <S sid="87" ssid="87">We use partial parsing and simple depen-.</S>
  <S sid="88" ssid="88">dency attachment techniques as an alternative to the FSG I)ased simpliiication.</S>
  <S sid="89" ssid="89">This ~no(M (the I)SM) is based on a sinq)le dependency tel)r(&gt; sentation provided l)y I,exicalized Tree.</S>
  <S sid="90" ssid="90">Adjoining (Ira.tmnar (I/FAG) and uses the "SUl&gt;ertaggiug" l;echniques described in (Josh| and Srinivas, 1994).</S>
  <S sid="91" ssid="91">4.1 Br ie f  Ovt;rvlt;w of LTAGs The primitive elements el LTA(~ formalism are (.l- ( : lnentary  trees.</S>
  <S sid="92" ssid="92">Elementary trees are of two types: initial frees and au,iliary trees.</S>
  <S sid="93" ssid="93">Initial /;rees are minimal linguistic structures that con- tain no recurs|on, such as sitnph; sentences, N Ps, l)Ps etc.</S>
  <S sid="94" ssid="94">Auxiliary trees are recursive stru&lt;-turcs which represent constituents that arc adjuncts to basic structure (e.g.</S>
  <S sid="95" ssid="95">relative clauses, sentential adjuncts, a(Iw.rbials).</S>
  <S sid="96" ssid="96">For a more R)rmal and (le- taile(I (lescription of l,lA(]s see (Schabes et M., J988).</S>
  <S sid="97" ssid="97">4.2 SuI)(*xl;agging Tlte elemmttary trees of LTAG localize dependen- (-ies, including hmg distance dependencies, by re- quiring that all and only the dependent elements be present within the same tree.</S>
  <S sid="98" ssid="98">As a result of this localization, a lexical item may be (and al- most alwws is) associated with more than one eL- ementary tree, We call these elementary trees su- pcrlags, since they conttdn more information (such as sul)categorization a d agreement information) than standard part -of  speech tags.</S>
  <S sid="99" ssid="99">Henc.e, each word is associated with more than one supertag.</S>
  <S sid="100" ssid="100">At the end of a complete l)arse, each word is asso- ciated with just one supertag (assuming there is no global ambiguity), and the supertags of all the words in a sentence are combined by sul)stitution and adjunct|on.</S>
  <S sid="101" ssid="101">As in standard part-of-speech disambiguation, we can use local statistical information in the form of N-gram models based on the distribution of sn- l)ertags ill a LTAG parsed corl)us for disamhigua- tion.</S>
  <S sid="102" ssid="102">use a trigram model to disambiguate ile supcrtags o as to assign one SUl)ertag tbr each word, in a process termed supertagging.</S>
  <S sid="103" ssid="103">[he tri- gram model of supcrtagging is very efficient (in linear time) and robust (Josh| and Srinivas, ] 994).</S>
  <S sid="104" ssid="104">1o establish the dependency links among the words of the sentence, we (xph)it the dei)endency information present in the supertags.</S>
  <S sid="105" ssid="105">Each su- perl;ag associated with a word allocates lots for the arguments o1 the word.</S>
  <S sid="106" ssid="106">These slots have a polarity value re[lecting their orientation wii;h re- Sl)ect to the anchor o[ the SUl)ertag.</S>
  <S sid="107" ssid="107">Also asso- (iated with a supertag is a list of internal nodes (hmluding the root node) thai, appear in the su- pertag.</S>
  <S sid="108" ssid="108">Using I;his information, a simple algo- rithnt may be used to annotate the sentence with d(,pe.ndency links.</S>
  <S sid="109" ssid="109">4.3 Simpl i f i cat ion  w i th  DeI ) (mden( y  l inks Tlte output provide([ by t, he dellendency analyzer not only contains depen(hmcy links annmg words but also in(lical,cs the constituent strncture as cn- code(I by snpertags.</S>
  <S sid="110" ssid="110">The constituent information is used to identify whether a supertag contains a clausal constituent and the dependency links are used to identify the span of the clause.</S>
  <S sid="111" ssid="111">Thus, embedded clauses can easily be identified and ex- tracte(t, akmg with their arguments.</S>
  <S sid="112" ssid="112">])nnctuation can be used to identify constituents such as appos- itives which can also 1)e sel)arate(I ont.</S>
  <S sid="113" ssid="113">As with the finite-state al)l)roach, the resulting segments may 1)e incomplete as indelltndetlt clauses.</S>
  <S sid="114" ssid="114">I[ the segments are to I)e reassembhd, no further pro- cessing need be done on them.</S>
  <S sid="115" ssid="115">l?igme 1 shows a rule [br extracting relative (lauses, in dependency notation.</S>
  <S sid="116" ssid="116">We tits| iden- tify the relative clause tree (Z), and then extract the verb which anchors it along with all of its (te- pendents.</S>
  <S sid="117" ssid="117">The right hand side shows the two re- suiting trees.</S>
  <S sid="118" ssid="118">The gap in the relative clause (Y) need only be tilled if the clauses are not going to bc reconlbined.</S>
  <S sid="119" ssid="119">Examples (6) and (7) show a sen- tence belbre and after this rule has applied.</S>
  <S sid="120" ssid="120">X:S Y:NP W Z: RelClause =&gt; yZ:S :NP Y:NP W/ Figure 1: R,ule for extracting relative clauses (6) .</S>
  <S sid="121" ssid="121">an issue [that generated  unnsnal heat in the IIouse of Commons ] .</S>
  <S sid="122" ssid="122">(7) An issne  [generated  unusnal heat in the Ilouse of Commons ].</S>
  <S sid="123" ssid="123">1043 5 Evaluat ion The objective of the evaluation is to examine the advantages of the DSM over the FSG-based model for simplification.</S>
  <S sid="124" ssid="124">In the FSG approach since the input to the simplifier is a set of noun and verb groups, the rules for the simplifier have to identify basic predicate argument relations to ensure that the right chunks remain together in the output.</S>
  <S sid="125" ssid="125">The simplifier in the DSM has access to infor- mation about argument structure, which makes it much easier to specify simplification patterns involving complete constituents.</S>
  <S sid="126" ssid="126">Consider exam- pie 8, (8) Th.e creator of Air India, Mr. JRD 7hta, believes that the airline, which celebrated 60 years today, could return to its old days of glory.</S>
  <S sid="127" ssid="127">qhe FSG-based model fails to recognize the rel- ative clause on the embedded subject the airline in example (8), because Rule 5 looks for matrix subject NPs.</S>
  <S sid="128" ssid="128">On the other hand, the DSM cor- rectly identifies the relative clause using the rule shown in Figure 1, which holds for relative clauses in all positions.</S>
  <S sid="129" ssid="129">Other differences are in the areas of modifier at- tachment and rule generality.</S>
  <S sid="130" ssid="130">In contrast o the /)SM approach, the FSG output does not have all modifiers attached, so the bulk of attachment de- cisions must be made by the simplification rules.</S>
  <S sid="131" ssid="131">The FSG approach is forced to enumerate all pos- sible variants of the LHS of each simplification rule (eg.</S>
  <S sid="132" ssid="132">Subject versus Object relatives, singular versus plural NPs) whereas in the DSM approach, the rules, encoded in supertags and the associated constituent types, are more general.</S>
  <S sid="133" ssid="133">Preliminary results using the DSM model are very promising.</S>
  <S sid="134" ssid="134">Using a corpus of newswire data, and only considering relative clause and apposi- tive simplification, we correctly recovered 25 out of 28 relative clauses and i4 of 14 appositives.</S>
  <S sid="135" ssid="135">We generated 1 spurious relative clause and 2 spuri- ous appositives.</S>
  <S sid="136" ssid="136">A version of the FSG model on the same data  recovered 17 relative clauses and 3 appositives.</S>
  <S sid="137" ssid="137">6 Discuss ion Simplification can be used for two general (:lasses of tasks.</S>
  <S sid="138" ssid="138">The first is as a preprocessor to a flfll parser so as to reduce ];he parse ambiguity for the parser.</S>
  <S sid="139" ssid="139">Tile second class of tasks demands that the output of the simplifier be free-standing sen- tences.</S>
  <S sid="140" ssid="140">Maintaining the coherence of the simpli- fied text raises the fbllowing problems: ?</S>
  <S sid="141" ssid="141">Determining the relative order of the simpli- fied sentences, which impacts the choice of referring expressions to be used and the over- all coherence of the text.</S>
  <S sid="142" ssid="142">Choosing referring expressions: For instance, when separating relative clauses fiom the nouns they modify, copying the head noun into the relative clause is simple, but leads to quite awkward sounding texts.</S>
  <S sid="143" ssid="143">IIowever, choosing an appropriate pronoun or choosing between definite and indefinite NPs involves knowledge of complex discourse information.</S>
  <S sid="144" ssid="144">Selecting the right tense when creating new sentences presents imilar problems.</S>
  <S sid="145" ssid="145">No matter how sophisticated the simplifica- tion heuristics, the subtleties of meaning in- tended by the author may be diluted, if not lost altogether.</S>
  <S sid="146" ssid="146">For many computer appli- cations, this disadvantage is outweighed by the advantages of simplification (i.e.</S>
  <S sid="147" ssid="147">gains of speed and/or accuracy), or may be corrected with the use of human l)ost-processiug.</S>
  <S sid="148" ssid="148">Acknowledgements This work is partially supported by NSF grant NSF- STC SBR 8920230, ARPA grant N00014-94 and All.</S>
  <S sid="149" ssid="149">() grant DAAH04-94-G0426.</S>
  <S sid="150" ssid="150">References Steven Abney.</S>
  <S sid="151" ssid="151">I)epcndency Grammars and Context-Free Grammars.</S>
  <S sid="152" ssid="152">Manuscript, University of Tubingen, March.</S>
  <S sid="153" ssid="153">R. Chandrasekar and S. Ramani.</S>
  <S sid="154" ssid="154">Auto- matic Simplifica.tion of Natural Language Text.</S>
  <S sid="155" ssid="155">M~muscript, National Centre for So[tware Technol: ogy, Bombay.</S>
  <S sid="156" ssid="156">R. Chandrasekar.</S>
  <S sid="157" ssid="157">A Hybrid Approach to Ma- chine Translation using Man Machine Communica- tion.</S>
  <S sid="158" ssid="158">Ph.D. thesis, Pata Institute of I"undamcnta] Research/University of Bombay, Bombay.</S>
  <S sid="159" ssid="159">Ralph Grishman.</S>
  <S sid="160" ssid="160">Wheres the Syntax?</S>
  <S sid="161" ssid="161">The New York University M UC-6 System.</S>
  <S sid="162" ssid="162">[n P~occe(g ings of the Sixth Message Understanding Confer- ence, Columbia, Maryland.</S>
  <S sid="163" ssid="163">Jerry Hobbs, Doug Appelt, John Bear, ])avid Israel, and W. Mary Tyson.</S>
  <S sid="164" ssid="164">FAST(IS: a system, for extracting information from natural anguage text.</S>
  <S sid="165" ssid="165">Technical Report 519, SRI.</S>
  <S sid="166" ssid="166">Aravind K. Joshi and B. Srinivas.</S>
  <S sid="167" ssid="167">Disam- biguation of Super Parts of Speech (or Supertags): Almost Parsing.</S>
  <S sid="168" ssid="168">In Proceedings of the 17 th Inter- national Conference on Computational Linguistics (COLING 94), Kyoto, Japan, August.</S>
  <S sid="169" ssid="169">Yves Schabes, Anne Abeilld, and Aravind K. Joshi.</S>
  <S sid="170" ssid="170">Parsing strategies with lexicMized gram- mars: Application to Tree Adjoining Grammars.</S>
  <S sid="171" ssid="171">In Proceedings of the 12 th International Co@rencc on Computational Linguistics (COL1NG88), Bu- dapest, Ilungm:y, August.</S>
  <S sid="172" ssid="172">Wojcik, Philip tIarrison, rod John Bremer.</S>
  <S sid="173" ssid="173">Using bracketed parses to evMuate a grain- mar checking ;rpplication.</S>
  <S sid="174" ssid="174">In Proceedings of the 31~t Conference of Association of Computational Lin- guistics, Ohio State University, Columbus, Ohio.</S>
</PAPER>
