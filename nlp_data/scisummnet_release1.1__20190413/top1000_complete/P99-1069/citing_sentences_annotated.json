[
  {
    "citance_No": 1, 
    "citing_paper_id": "P00-1061", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "Stefan, Riezler | Detlef, Prescher | Jonas, Kuhn | Mark, Johnson", 
    "raw_text": "In previous work on log-linear models for LFG by Johnson et al (1999), pseudo likelihood estimation from annotated corpora has been introduced and experimented with on a small scale", 
    "clean_text": "In previous work on log-linear models for LFG by Johnson et al (1999), pseudo likelihood estimation from annotated corpora has been introduced and experimented with on a small scale.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P00-1061", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "Stefan, Riezler | Detlef, Prescher | Jonas, Kuhn | Mark, Johnson", 
    "raw_text": "The basic 190 properties employed in our models are similar to the properties of Johnson et al (1999) which incorporate general linguistic principles into a log-linear model", 
    "clean_text": "The basic properties employed in our models are similar to the properties of Johnson et al (1999) which incorporate general linguistic principles into a log-linear model.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P00-1061", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "Stefan, Riezler | Detlef, Prescher | Jonas, Kuhn | Mark, Johnson", 
    "raw_text": "The most direct points of comparison of our method are the approaches of Johnson et al (1999) and Johnson and Riezler (2000)", 
    "clean_text": "The most direct points of comparison of our method are the approaches of Johnson et al (1999) and Johnson and Riezler (2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D11-1148", 
    "citing_paper_authority": 23, 
    "citing_paper_authors": "Sze-Meng Jojo, Wong | Mark, Dras", 
    "raw_text": "For these we use the 13 feature schemas described in Charniak and Johnson (2005), which were inspired by earlier work in discriminative estimation techniques, such as Johnson et al (1999) and Collins (2000)", 
    "clean_text": "For these we use the 13 feature schemas described in Charniak and Johnson (2005), which were inspired by earlier work in discriminative estimation techniques, such as Johnson et al (1999) and Collins (2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P04-1086", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Michelle L., Gregory | Yasemin, Altun", 
    "raw_text": "To overcome this problem, we penalize the objective function by adding a Gaussian prior (a term proportional to the squared norm ||? ||2) as suggested in (Johnson et al, 1999)", 
    "clean_text": "To overcome this problem, we penalize the objective function by adding a Gaussian prior (a term proportional to the squared norm as suggested in (Johnson et al, 1999)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P02-1034", 
    "citing_paper_authority": 111, 
    "citing_paper_authors": "Michael John, Collins | Nigel, Duffy", 
    "raw_text": "The method is related to the boosting approach to ranking problems (Freund et al. 1998), the Markov Random Field methods of (Johnson et al 1999), and the boosting approaches for parsing in (Collins 2000)", 
    "clean_text": "The method is related to the boosting approach to ranking problems (Freund et al. 1998), the Markov Random Field methods of (Johnson et al 1999), and the boosting approaches for parsing in (Collins 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "N06-1020", 
    "citing_paper_authority": 88, 
    "citing_paper_authors": "David, McClosky | Eugene, Charniak | Mark, Johnson", 
    "raw_text": "It does this using the re ranking methodology described in Collins (2000), using a Maxi mum Entropy model with Gaussian regularization as described in Johnson et al (1999)", 
    "clean_text": "It does this using the re ranking methodology described in Collins (2000), using a Maximum Entropy model with Gaussian regularization as described in Johnson et al (1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W03-1013", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Stephen, Clark | James R., Curran", 
    "raw_text": "features (Johnson et al, 1999)", 
    "clean_text": "A Gaussian prior also handles the problem of \"pseudo-maximal\" features (Johnson et al, 1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P04-1015", 
    "citing_paper_authority": 84, 
    "citing_paper_authors": "Michael John, Collins | Brian, Roark", 
    "raw_text": "For example, Johnson et al (1999) and Riezler et al (2002) use all parses generated by an LFG parser as input to an MRF approach? given the level of ambiguity in natural language, this set can presumably become extremely large", 
    "clean_text": "For example, Johnson et al (1999) and Riezler et al (2002) use all parses generated by an LFG parser as input to an MRF approach given the level of ambiguity in natural language, this set can presumably become extremely large.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W07-2207", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Yi, Zhang | Stephan, Oepen | John, Carroll", 
    "raw_text": "Following (Johnson et al, 1999), a conditional ME model of the probabilities of trees {t1..", 
    "clean_text": "Following (Johnson et al, 1999), a conditional ME model of the probabilities of trees {t1 ... tn} for a string s, and assuming a set of feature functions {f1 ... fm} with corresponding weights {\u03bb1 ... \u03bbm}, is defined as.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "N04-1012", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Miles, Osborne | Jason, Baldridge", 
    "raw_text": "As is now standard for feature-based grammars, we use log-linear models for parse selection (Johnson et al, 1999)", 
    "clean_text": "As is now standard for feature-based grammars, we use log-linear models for parse selection (Johnson et al, 1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W04-3202", 
    "citing_paper_authority": 19, 
    "citing_paper_authors": "Jason, Baldridge | Miles, Osborne", 
    "raw_text": "As is now standard for feature-based grammars, we mainly use log-linear models for parse selection (Johnson et al, 1999)", 
    "clean_text": "As is now standard for feature-based grammars, we mainly use log-linear models for parse selection (Johnson et al, 1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "C02-1075", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Bernd, Kiefer | Hans-Ulrich, Krieger | Detlef, Prescher", 
    "raw_text": "All approaches have in common that they try to model a probability distribution over the readings of the UBG, which can be used to rank the competing analyses of a given sentence; see ,e.g., Briscoe and Carroll (1993), Eisele (1994), Brew (1995), Abney (1997), Goodman (1997), Bod and Kaplan (1998), Johnson et al (1999), Riezler et al", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "C02-1075", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Bernd, Kiefer | Hans-Ulrich, Krieger | Detlef, Prescher", 
    "raw_text": "The most direct points of comparison of our method are the approaches of Johnson et al (1999) and Riezler et al (2000), esp. since they use the same evaluation criteria than we use", 
    "clean_text": "The most direct points of comparison of our method are the approaches of Johnson et al (1999) and Riezler et al (2000), esp. since they use the same evaluation criteria than we use.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W06-1661", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Erik, Velldal | Stephan, Oepen", 
    "raw_text": "likelihood of the training data X p (Johnson et al, 1999), computed as L (w)= Q Ni=1 p w (r i js i)", 
    "clean_text": "L(w) is the 'conditionalized' likelihood of the training data X p (Johnson et al, 1999), computed as L (w)= lQ Ni=1 p w (r i js i).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "C02-1077", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Iain, Bancarz | Miles, Osborne", 
    "raw_text": "When statistically modelling linguistic phenomena of one sort or another, researchers typically t log linear models to the data (for example (Johnson et al., 1999))", 
    "clean_text": "When statistically modelling linguistic phenomena of one sort or another, researchers typically train log linear models to the data (for example (Johnson et al., 1999)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W07-1203", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Martin, Forst", 
    "raw_text": "(Johnson et al., 1999)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W03-1019", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Yasemin, Altun | Mark, Johnson | Thomas R., Hofmann", 
    "raw_text": "The results we report are with the Gaussian prior regularization term described in (Johnson et al, 1999) .Our goal in this paper is not to build the best tagger or recognizer, but to compare different loss functions and optimization methods", 
    "clean_text": "The results we report are with the Gaussian prior regularization term described in (Johnson et al, 1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W02-2030", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Kristina, Toutanova | Christopher D., Manning", 
    "raw_text": ",tk, the conditional probability for analysis ti is given by: P (ti|s)= exp (? m j=1 fj (ti)? j)? k i? =1 exp (? m j=1 fj (ti?)? j) (1) As in Johnson et al (1999) we trained the model by maximizing the conditional likelihood of the preferred analyses and using a Gaussian prior for smoothing (Chen and Rosenfeld, 1999)", 
    "clean_text": "As in Johnson et al (1999) we trained the model by maximizing the conditional likelihood of the preferred analyses and using a Gaussian prior for smoothing (Chen and Rosenfeld, 1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W02-2030", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Kristina, Toutanova | Christopher D., Manning", 
    "raw_text": "((Johnson et al, 1999) add features measuring parallelism)", 
    "clean_text": "This disambiguation decision seems to require common world knowledge or it might be addressable with addition of knowledge about parallel structures ((Johnson et al, 1999) add features measuring parallelism).", 
    "keep_for_gold": 0
  }
]
