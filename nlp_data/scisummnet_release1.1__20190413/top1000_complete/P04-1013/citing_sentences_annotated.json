[
  {
    "citance_No": 1, 
    "citing_paper_id": "P05-1023", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "James B., Henderson | Ivan, Titov", 
    "raw_text": "1For example, see (Henderson, 2004) for a discussion of why generative models are better than models parameterized to estimate the a posteriori probability directly", 
    "clean_text": "For example, see (Henderson, 2004) for a discussion of why generative models are better than models parameterized to estimate the a posteriori probability directly.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-2133", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Jacob, Andreas | Dan, Klein", 
    "raw_text": "There certainly exist competitive parsers that internally represent lexical items as real-valued vectors, such as the neural network-based parser of Henderson (2004), and even parsers which use pre-trained word embed dings to represent the lexicon, such as Socher et al", 
    "clean_text": "There certainly exist competitive parsers that internally represent lexical items as real-valued vectors, such as the neural network-based parser of Henderson (2004), and even parsers which use pre-trained word embeddings to represent the lexicon, such as Socher et al.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P14-2133", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Jacob, Andreas | Dan, Klein", 
    "raw_text": "First, these parsers are among the best in the literature, with a test performance of 90.7 F 1 for the baseline Berkeley parser on the Wall Street Journal corpus (compared to 90.4 for Socher et al (2013) and 90.1 for Henderson (2004))", 
    "clean_text": "First, these parsers are among the best in the literature, with a test performance of 90.7 F1 for the baseline Berkeley parser on the Wall Street Journal corpus (compared to 90.4 for Socher et al (2013) and 90.1 for Henderson (2004)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P07-1071", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Ronan, Collobert | Jason, Weston", 
    "raw_text": "We focus our experimental study on the semantic role labeling problem (Palmer et al,2005): being able to give a semantic role to a syn1Even though some parsers effectively exhibit linear behavior in sentence length (Ratnaparkhi, 1997), fast statistical parsers such as (Henderson, 2004) still take around 1.5 seconds for sentences of length 35 in tests that we made", 
    "clean_text": "Even though some parsers effectively exhibit linear behavior in sentence length (Ratnaparkhi, 1997), fast statistical parsers such as (Henderson, 2004) still take around 1.5 seconds for sentences of length 35 in tests that we made.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P07-1080", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Ivan, Titov | James B., Henderson", 
    "raw_text": "For example, the discriminative training techniques successfully applied in (Henderson, 2004) to the feed-forward neural network model canbe directly applied to the mean field model proposed in this paper", 
    "clean_text": "For example, the discriminative training techniques successfully applied in (Henderson, 2004) to the feed-forward neural network model can be directly applied to the mean field model proposed in this paper.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P06-1055", 
    "citing_paper_authority": 227, 
    "citing_paper_authors": "Slav, Petrov | Leon, Barrett | Romain, Thibaux | Dan, Klein", 
    "raw_text": "2Other techniques are also possible; Henderson (2004) uses neural networks to induce latent left-corner parser states", 
    "clean_text": "Other techniques are also possible; Henderson (2004) uses neural networks to induce latent left-corner parser states.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P08-1067", 
    "citing_paper_authority": 94, 
    "citing_paper_authors": "Liang, Huang", 
    "raw_text": "type system F1% D Collins (2000) 89.7 Henderson (2004) 90.1 Charniak and Johnson (2005) 91.0 updated (Johnson, 2006) 91.4 this work 91.7 G Bod (2003) 90.7Petrov and Klein (2007) 90.1 S McClosky et al (2006) 92.1 Table 4: Comparison of our final results with other best-performing systems on the whole Section 23", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D08-1091", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Slav, Petrov | Dan, Klein", 
    "raw_text": "867 In addition, we exhibit the best parsing numbers on several metrics, for several domains and languages. Discriminative parsing has been investigated be fore, such as in Johnson (2001), Clark and Curran (2004), Henderson (2004), Koo and Collins (2005), Turian et al (2007), Finkel et al (2008), and, most similarly, in Petrov and Klein (2008)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P08-1109", 
    "citing_paper_authority": 44, 
    "citing_paper_authors": "Jenny Rose, Finkel | Alex, Kleeman | Christopher D., Manning", 
    "raw_text": "Stochastic optimization methods have proven to be extremely efficient for the training of models involving computationally expensive objective functions like those encountered with our task (Vishwanathan et al, 2006) and, in fact, the on-line backpropagationlearning used in the neural network parser of Henderson (2004) is a form of stochastic gradient descent", 
    "clean_text": "Stochastic optimization methods have proven to be extremely efficient for the training of models involving computationally expensive objective functions like those encountered with our task (Vishwanathan et al, 2006) and, in fact, the on-line backpropagation learning used in the neural network parser of Henderson (2004) is a form of stochastic gradient descent.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W07-2218", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Ivan, Titov | James B., Henderson", 
    "raw_text": "In particular, the neural network constituent parsers in (Henderson, 2003) and (Henderson, 2004) can be regarded as coarse approximations to their corresponding ISBN model", 
    "clean_text": "In particular, the neural network constituent parsers in (Henderson, 2003) and (Henderson, 2004) can be regarded as coarse approximations to their corresponding ISBN model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W07-2218", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Ivan, Titov | James B., Henderson", 
    "raw_text": "Also, as with any generative model, it may be easy to improve the parser? s accuracy by using discriminative retraining techniques (Henderson, 2004) or data-defined kernels (Henderson and Titov, 2005), with or even with out introduction of any additional linguistic features. In addition, there are some applications, such as language modeling, which require generative models", 
    "clean_text": "Also, as with any generative model, it may be easy to improve the parser's accuracy by using discriminative retraining techniques (Henderson, 2004) or data-defined kernels (Henderson and Titov, 2005), with or even with out introduction of any additional linguistic features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W07-2218", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Ivan, Titov | James B., Henderson", 
    "raw_text": "These results suggest that our generative model is quite competitive with respect to the best models, which are both discriminative.5 We would expect further improvement of ISBN results if we applied discriminative retraining (Henderson, 2004) or re ranking with data-defined kernels (Henderson and Titov, 2005), even without introduction of any additional features", 
    "clean_text": "We would expect further improvement of ISBN results if we applied discriminative retraining (Henderson, 2004) or reranking with data-defined kernels (Henderson and Titov, 2005), even without introduction of any additional features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P06-1110", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Joseph P., Turian | I. Dan, Melamed", 
    "raw_text": "Henderson (2004) finds that discriminative training was too slow, and reports accuracy higher than generative models by discriminatively re ranking the output of his generative model", 
    "clean_text": "Henderson (2004) finds that discriminative training was too slow, and reports accuracy higher than generative models by discriminatively reranking the output of his generative model.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P06-1110", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Joseph P., Turian | I. Dan, Melamed", 
    "raw_text": "Henderson, 2004)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D07-1099", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Ivan, Titov | James B., Henderson", 
    "raw_text": "Also, as with any generative model, it should be easy to improve the parser? s accuracy with discriminative re ranking, such as disc rim inative retraining techniques (Henderson, 2004) or data-defined kernels (Henderson and Titov, 2005), with or even without the introduction of any additional linguistic features", 
    "clean_text": "Also, as with any generative model, it should be easy to improve the parser's accuracy with discriminative reranking, such as discriminative retraining techniques (Henderson, 2004) or data-defined kernels (Henderson and Titov, 2005), with or even without the introduction of any additional linguistic features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P13-1045", 
    "citing_paper_authority": 28, 
    "citing_paper_authors": "Richard, Socher | John, Bauer | Christopher D., Manning | Andrew Y., Ng", 
    "raw_text": "Other related work includes (Henderson, 2004), who discriminatively trains a parser based on synchrony networks and (Titov and Henderson, 2006), who use an SVM to adapt a generative parser to different domains. Costa et al (2003) apply recursive neural net works to re-rank possible phrase attachments in an incremental parser", 
    "clean_text": "Other related work includes (Henderson, 2004), who discriminatively trains a parser based on synchrony networks and (Titov and Henderson, 2006), who use an SVM to adapt a generative parser to different domains.", 
    "keep_for_gold": 0
  }
]
