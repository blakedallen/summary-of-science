Soft Syntactic Constraints For Word Alignment Through Discriminative Training
Word alignment methods can gain valuable guidance by ensuring that their alignments maintain cohesion with respect to the phrases specified by a monolingual dependency tree.
However, this hard constraint can also rule out correct alignments, and its utility decreases as alignment models become more complex.
We use a publicly available structured output SVM to create a max-margin syntactic aligner with a soft cohesion constraint.
The resulting aligner is the first, to our knowledge, to use a discriminative learning method to train an ITG bitext parser.
We use dependency structures as soft constraints to improve word alignment in an ITG framework.
We introduce soft syntactic ITG (Wu, 1997) constraints into a discriminative model, and use an ITG parser to constrain the search for a Viterbi alignment.
