Distant supervision for relation extraction without labeled data
Modern models of relation extraction for tasks like ACE are based on supervised learning of relations from small hand-labeled corpora.
We investigate an alternative paradigm that does not require labeled corpora, avoiding the domain dependence of ACE-style algorithms, and allowing the use of corpora of any size.
Our experiments use Freebase, a large semantic database of several thousand relations, to provide distant supervision. For each pair of entities that appears in some Freebase relation, we find all sentences containing those entities in a large un-labeled corpus and extract textual features to train a relation classifier.
Our algorithm combines the advantages of supervised IE (combining 400,000 noisy pattern features in a probabilistic classifier) and unsupervised IE (extracting large numbers of relations from large corpora of any domain).
Our model is able to extract 10,000 instances of 102 relations at a precision of 67.6%.
We also analyze feature performance, showing that syntactic parse features are particularly helpful for relations that are ambiguous or lexically distant in their expression.
Additionally, researchers have tried to automatically extract examples for supervised learning from resources such as Wikipedia (Weld et al,2008) and databases (Mintz et al, 2009), or attempted open information extraction (IE) (Banko et al, 2007) to extract all possible relations.
Distant supervision (DS) can automatically gather labeled data by heuristically aligning entities in text with those in a knowledge base.
