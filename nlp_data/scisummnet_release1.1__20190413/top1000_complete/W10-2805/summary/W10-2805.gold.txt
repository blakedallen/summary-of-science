A Regression Model of Adjective-Noun Compositionality in Distributional Semantics
In this paper we explore the computational modelling of compositionality in distributional models of semantics.
In particular, we model the semantic composition of pairs of adjacent English Adjectives and Nouns from the British National Corpus.
We build a vector-based semantic space from a lemmatised version of the BNC, where the most frequent A-N lemma pairs are treated as single tokens.
We then extrapolate three different models of compositionality: a simple additive model, a pointwise-multiplicative model and a Partial Least Squares Regression (PLSR) model.
We propose two evaluation methods for the implemented models.
Our study leads to the conclusion that regression-based models of compositionality generally out-perform additive and multiplicative approaches, and also show a number of advantages that make them very promising for future research.
Our approach to the semantic composition of adjectives with nouns draws on the classical analysis of adjectives within the Montagovian tradition of formal semantic theory (Montague, 1974), on which they are treated as higher order predicates, and model adjectives as matrices of weights that are applied to noun vectors.
Our main innovation is to use the co-occurrence vectors of corpus-observed ANs to train a supervised composition model.
We look at corpus-harvested phrase vectors to learn composition functions that should derive such composite vectors automatically.
