[
  {
    "citance_No": 1, 
    "citing_paper_id": "D10-1052", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Hendra, Setiawan | Chris, Dyer | Philip, Resnik", 
    "raw_text": "For translation experiments, we used cdec (Dyeret al, 2010), a fast implementation of hierarchical phrase-based translation models (Chiang, 2005), which represents a state-of-the-art translation sys tem. We constructed the list of function words in English manually and in Chinese from (Howard, 2002) .Punctuation marks were added to the list, resulting in 883 and 359 tokens in the Chinese and English lists, respectively", 
    "clean_text": "For translation experiments, we used cdec (Dyer et al, 2010), a fast implementation of hierarchical phrase-based translation models (Chiang, 2005), which represents a state-of-the-art translation system.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-2127", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Kai, Zhao | Liang, Huang | Haitao, Mi | Abe, Ittycheriah", 
    "raw_text": "Ourimplementation is mostly in Python on top of the cdecsystem (Dyer et al, 2010) via the pycdec interface (Chahuneau et al, 2012)", 
    "clean_text": "Our implementation is mostly in Python on top of the cdec system (Dyer et al, 2010) via the pycdec interface (Chahuneau et al, 2012).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "E12-3008", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Jan A., Botha", 
    "raw_text": "The full English German bi text was filtered to exclude sentences longer than 50, resulting in 1.7 million parallel sentences; word alignments were inferred from this using the Berkeley Aligner (Liang et al, 2006) and used as basis from which to extract a Hiero-style synchronous CFG (Chiang, 2007) .The weights of the log-linear translation mod els were tuned towards the BLEU metric on development data using cdec? s (Dyer et al, 2010) implementation of MERT (Och, 2003) .For this, the set news-test2008 (2051 sentences) was used, while final case-insensitive BLEU scores are measured on the official test set newstest2011 (3003 sentences)", 
    "clean_text": "The weights of the log-linear translation models were tuned towards the BLEU metric on development data using cdec's (Dyer et al, 2010) implementation of MERT (Och, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P12-2058", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Andrea, Gesmundo | James B., Henderson | Giorgio, Satta", 
    "raw_text": "We implement Linear CP (LCP) on top of Cdec (Dyer et al, 2010), a widely-used hierarchical MT system that includes implementations of standardCP and FCP algorithms", 
    "clean_text": "We implement Linear CP (LCP) on top of Cdec (Dyer et al, 2010), a widely-used hierarchical MT system that includes implementations of standard CP and FCP algorithms.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W11-2160", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Jonathan, Weese | Juri, Ganitkevitch | Chris, Callison-Burch | Matt, Post | Adam, Lopez", 
    "raw_text": "In modern machine translation systems such as Joshua (Li et al, 2009) and cdec (Dyer et al, 2010), a translation model is represented as a synchronous context-free grammar (SCFG)", 
    "clean_text": "In modern machine translation systems such as Joshua (Li et al, 2009) and cdec (Dyer et al, 2010), a translation model is represented as a synchronous context-free grammar (SCFG).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W11-2160", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Jonathan, Weese | Juri, Ganitkevitch | Chris, Callison-Burch | Matt, Post | Adam, Lopez", 
    "raw_text": "In addition to phrasal and lexical probabilities, this extractor implements several other features that are also described in section 2.4.Finally, the cdec decoder (Dyer et al, 2010) includes a grammar extractor that performs well only when all rules can be held in memory", 
    "clean_text": "Finally, the cdec decoder (Dyer et al, 2010) includes a grammar extractor that performs well only when all rules can be held in memory.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P14-1006", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Karl Moritz, Hermann | Philip, Blunsom", 
    "raw_text": "We use the cdec decoder (Dyer et al, 2010) with default settings for this purpose", 
    "clean_text": "We use the cdec decoder (Dyer et al, 2010) with default settings for this purpose.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W11-2139", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Chris, Dyer | Kevin, Gimpel | Jonathan H., Clark | Noah A., Smith", 
    "raw_text": "Our translation system is based on a hierarchical phrase-based translation model (Chiang, 2007), as implemented in the cdec decoder (Dyer et al, 2010)", 
    "clean_text": "Our translation system is based on a hierarchical phrase-based translation model (Chiang, 2007), as implemented in the cdec decoder (Dyer et al, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D11-1083", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Andrea, Gesmundo | James B., Henderson", 
    "raw_text": "Because our model is implemented in the Forest Rescoring framework (e.g. Huang and Chiang (2007), Dyer et al (2010), Li et al (2009)), local Cost (??, l) can be efficiently computed exactly", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "D11-1083", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Andrea, Gesmundo | James B., Henderson", 
    "raw_text": "We implemented UD on top of a widely-used HMT open-source system ,cdec (Dyer et al, 2010) .We compare with cdec Cube Pruning BD", 
    "clean_text": "We implemented UD on top of a widely-used HMT open-source system, cdec (Dyer et al, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P11-1130", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Preslav, Nakov | Hwee Tou, Ng", 
    "raw_text": "6We also tried the word segmentation model of Dyer (2009) as implemented in the cdec decoder (Dyer et al, 2010), which learns word segmentation lattices from raw text in an unsupervised manner", 
    "clean_text": "We also tried the word segmentation model of Dyer (2009) as implemented in the cdec decoder (Dyer et al, 2010), which learns word segmentation lattices from raw text in an unsupervised manner.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W11-2140", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Vladimir, Eidelman | Kristy, Hollingshead | Philip, Resnik", 
    "raw_text": "(Dyer et al., 2010)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P13-2058", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Felix, Hieber | Laura, Jehl | Stefan, Riezler", 
    "raw_text": "Like Ture et al (2012a; 2012) we achieved best retrieval performance when translation probabilities are calculated as an interpolation between (context-free) lexical translation probabilities Plex estimated on symmetrized word alignments, and (context-aware) translation probabilities Pnbest es ti mated on the n-best list of an SMT decoder: P (t|q)=? Pnbest (t|q)+ (1??) Plex (t|q) (1) Pnbest (t|q) is the decoder? s confidence to trans late q into t within the context of query Q. Letak (t, q) be a function indicating an alignment of target term t to source term q in the k-th derivation of query Q. Then we can estimate Pnbest (t|q) as follows: Pnbest (t|q)=? n k=1 ak (t, q) D (k, Q)? n k=1 ak (?, q) D (k, Q) (2) D (k, Q) is the model score of the k-th derivation in the n-best list for query Q. In our work, we use hierarchical phrase-based translation (Chiang, 2007), as implemented in the cdec framework (Dyer et al, 2010)", 
    "clean_text": "In our work, we use hierarchical phrase-based translation (Chiang, 2007), as implemented in the cdec framework (Dyer et al, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W12-6219", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Aurelien, Waite | Graeme, Blackwood | William, Byrne", 
    "raw_text": "? The work reported in this paper was carried out while the author was at the University of Cambridge.It has been noted that line optimisation over a lattice can be implemented as a semiring of sets of linear functions (Dyer et al, 2010)", 
    "clean_text": "The work reported in this paper was carried out while the author was at the University of Cambridge.It has been noted that line optimisation over a lattice can be implemented as a semi-ring of sets of linear functions (Dyer et al, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W12-3160", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Vladimir, Eidelman", 
    "raw_text": "Gram mars were extracted from the resulting parallel text and used in our hierarchical phrase-based system using cdec (Dyer et al, 2010) as the decoder", 
    "clean_text": "Grammars were extracted from the resulting parallel text and used in our hierarchical phrase-based system using cdec (Dyer et al, 2010) as the decoder.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "N12-1046", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Ferhan, Ture | Douglas W., Oard | Philip, Resnik", 
    "raw_text": "We have evaluated the one-translation-per-discourse feature using the cdecMT system (Dyer et al, 2010) .We started by building a baseline system using standard features in cdec: lexical and phrase translation probabilities in both directions, word and arity penalty features, and a 5-gram language model", 
    "clean_text": "We have evaluated the one-translation-per-discourse feature using the cdecMT system (Dyer et al, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P13-1110", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Vladimir, Eidelman | Yuval, Marton | Philip, Resnik", 
    "raw_text": "This motivates an on line gradient-based optimization approach? an approach that is particularly attractive because its simple update is well suited for efficiently processing structured objects with sparse features (Crammer et al, 2012) .The contributions of this paper include (1) introduction of a loss function for structured RMMin the SMT setting, with surrogate reference translations and latent variables; (2) an on line gradient based solver, RM, with a closed-form parameter update to optimize the relative margin loss; and (3) an efficient implementation that integrates well with the open source cdec SMT system (Dyer et al., 2010) .1 In addition, (4) as our solution is not dependent on any specific QP solver, it can be easily incorporated into practically any gradient based learning algorithm", 
    "clean_text": "An efficient implementation that integrates well with the open source cdec SMT system (Dyer et al., 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P13-1110", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Vladimir, Eidelman | Yuval, Marton | Philip, Resnik", 
    "raw_text": "We used cdec (Dyer et al, 2010) as our hierarchical phrase-based decoder, and tuned the parameters of the system to optimize BLEU (Papineni et al, 2002) on the NIST MT06 corpus", 
    "clean_text": "We used cdec (Dyer et al, 2010) as our hierarchical phrase-based decoder, and tuned the parameters of the system to optimize BLEU (Papineni et al, 2002) on the NIST MT06 corpus.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "N12-1079", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Ferhan, Ture | Jimmy, Lin", 
    "raw_text": "In all experiments, our MT system learned a synchronous context-free grammar (Chiang, 2007), using GIZA++ for word alignments, MIRA for parameter tuning (Crammer et al, 2006) ,cdec for decoding (Dyer et al, 2010), a 5-gram SRILM for language modeling, and single-reference BLEU for evaluation", 
    "clean_text": "In all experiments, our MT system learned a synchronous context-free grammar (Chiang, 2007), using GIZA++ for word alignments, MIRA for parameter tuning (Crammer et al, 2006) ,cdec for decoding (Dyer et al, 2010), a 5-gram SRILM for language modeling, and single-reference BLEU for evaluation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P12-3004", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Qiang, Li | Tong, Xiao | Jingbo, Zhu | Hao, Zhang", 
    "raw_text": "To date, several open-source SMT systems (based on either phrase based models or syntax-based models) have been developed, such as Moses (Koehn et al, 2007), Joshua (Li et al, 2009), SAMT (Zollmann and Venugopal, 2006), Phrasal (Cer et al, 2010) ,cdec (Dyer et al, 2010), Jane (Vilar et al, 2010) and SilkRoad 2, and offer good references for the development of the NiuTrans toolkit", 
    "clean_text": "To date, several open-source SMT systems (based on either phrase based models or syntax-based models) have been developed, such as Moses (Koehn et al, 2007), Joshua (Li et al, 2009), SAMT (Zollmann and Venugopal, 2006), Phrasal (Cer et al, 2010), cdec (Dyer et al, 2010), Jane (Vilar et al, 2010) and SilkRoad, and offer good references for the development of the NiuTrans toolkit.", 
    "keep_for_gold": 0
  }
]
