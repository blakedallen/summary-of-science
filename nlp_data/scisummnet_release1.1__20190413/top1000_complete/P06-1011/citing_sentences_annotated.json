[
  {
    "citance_No": 1, 
    "citing_paper_id": "W08-1911", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Aur&eacute;lien, Max | Michael, Zock", 
    "raw_text": "(Munteanu and Marcu, 2006))", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P13-1140", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Jiajun, Zhang | Chengqing, Zong", 
    "raw_text": "We employ the same algorithm used in (Munteanu and Marcu, 2006) which first use the GI ZA++ (with grow-diag-final-and heuristic) to obtain the word alignment between source and target words, and then calculate the association strength between the aligned words", 
    "clean_text": "We employ the same algorithm used in (Munteanu and Marcu, 2006) which first use the GI ZA++ (with grow-diag-final-and heuristic) to obtain the word alignment between source and target words, and then calculate the association strength between the aligned words.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P13-1140", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Jiajun, Zhang | Chengqing, Zong", 
    "raw_text": "Munteanu and Marcu (2006) first extract the candidate parallel sentences from the comparable corpora and further extract the accurate sub-sentential bilingual fragments from the candidate parallel sentences using the in-domain probabilistic bilingual lexicon", 
    "clean_text": "Munteanu and Marcu (2006) first extract the candidate parallel sentences from the comparable corpora and further extract the accurate sub-sentential bilingual fragments from the candidate parallel sentences using the in-domain probabilistic bilingual lexicon.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P13-1140", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Jiajun, Zhang | Chengqing, Zong", 
    "raw_text": "They are neither parallel nor comparable because we can not even extract a small number of parallel sentence pairs from this monolingual data using the method of (Munteanu and Marcu, 2006)", 
    "clean_text": "They are neither parallel nor comparable because we cannot even extract a small number of parallel sentence pairs from this monolingual data using the method of (Munteanu and Marcu, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "C08-1030", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Fumiyo, Fukumoto | Yoshimi, Suzuki | Kazuyuki, Yamashita", 
    "raw_text": "Munteanu and Marcu (2006) proposed a method for extracting parallel sub sentential fragments from very non-parallel bilingual corpora", 
    "clean_text": "Munteanu and Marcu (2006) proposed a method for extracting parallel sub sentential fragments from very non-parallel bilingual corpora.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W11-1214", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Anja, Belz | Eric, Kow", 
    "raw_text": "Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or sub sentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora", 
    "clean_text": "Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or sub sentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P11-2083", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Bo, Li | Eric, Gaussier | Akiko, Aizawa", 
    "raw_text": "Some works like (Munteanu et al, 2004) and (Munteanu and Marcu, 2006) propose methods to extract parallel fragments from comparable corpora", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "C10-1073", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Bo, Li | Eric, Gaussier", 
    "raw_text": "Similarly, MunteanuandMarcu (2006) propose a method to extract sub sentential fragments from non-parallel corpora", 
    "clean_text": "Similarly, Munteanu and Marcu (2006) propose a method to extract sub sentential fragments from non-parallel corpora.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W11-1213", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Drahom&iacute;ra Johanka, Spoustov&aacute; | Miroslav, Spousta", 
    "raw_text": "The articles (Munteanu et al, 2004), (Munteanu and Marcu, 2005) and (MunteanuandMarcu, 2006) are introducing algorithms for extracting parallel sentences and sub-sententional fragments from comparable corpora and using the automatically extracted parallel data for improving statistical machine translation algorithms performance", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W10-4217", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Anja, Belz | Eric, Kow", 
    "raw_text": "Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or sub sentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora", 
    "clean_text": "Other approaches aim to identify pairs of sentences (Munteanu and Marcu, 2005) or sub sentential fragments (Munteanu and Marcu, 2006) that are parallel within comparable corpora.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W12-3153", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Laura, Jehl | Felix, Hieber | Stefan, Riezler", 
    "raw_text": "The approach that is closest to our work is that of Munteanu and Marcu (2006): Theyuse standard information retrieval together with simple word-based translation for CLIR, and extract phrases from the retrieval results using a clean bilingual lexicon and an averaging filter", 
    "clean_text": "The approach that is closest to our work is that of Munteanu and Marcu (2006): They use standard information retrieval together with simple word-based translation for CLIR, and extract phrases from the retrieval results using a clean bilingual lexicon and an averaging filter.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W12-3153", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Laura, Jehl | Felix, Hieber | Stefan, Riezler", 
    "raw_text": "We con ducted experiments using different constraints on the number of alignment points required for a pair to be considered as well as the value of N. Our first technique resembles the technique of Munteanu and Marcu (2006) who also perform phrase extraction by combining clean alignment lexica for initial signals with heuristics to smooth alignments for final fragment extraction. While we obtained some gains using our heuristics, we are aware that our method is severely restricted in that it only learns new words which are in the vicinity of known words", 
    "clean_text": "Our first technique resembles the technique of Munteanu and Marcu (2006) who also perform phrase extraction by combining clean alignment lexica for initial signals with heuristics to smooth alignments for final fragment extraction.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W11-1209", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Sanjika, Hewavitharana | Stephan, Vogel", 
    "raw_text": "The first attempt to detect sub-sentential fragments from comparable sentences is (Munteanuand Marcu, 2006)", 
    "clean_text": "The first attempt to detect sub-sentential fragments from comparable sentences is (Munteanuand Marcu, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "N12-1061", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Jason, Riesa | Daniel, Marcu", 
    "raw_text": "Munteanu and Marcu (2006), and later Quirk et al (2007), extend the state-of-the-art for this task to parallel fragments. In this paper, we present a novel method for detecting parallel fragments in large, existing and potentially noisy parallel corpora using existing ma 538chinery and show significant improvements to two state-of-the-art MT systems", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D12-1084", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Michaela, Regneri | Rui, Wang", 
    "raw_text": "Munteanu and Marcu (2006) extract sub sentential translation pairs from comparable corpora using the log-likelihood-ratio of word translation probability", 
    "clean_text": "Munteanu and Marcu (2006) extract sub sentential translation pairs from comparable corpora using the log-likelihood-ratio of word translation probability.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D12-1084", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Michaela, Regneri | Rui, Wang", 
    "raw_text": "We mainly follow our previous approach (Wang and CallisonBurch, 2011), which is a modified version of an approach by Munteanu and Marcu (2006) on translation fragment extraction", 
    "clean_text": "We mainly follow our previous approach (Wang and CallisonBurch, 2011), which is a modified version of an approach by Munteanu and Marcu (2006) on translation fragment extraction.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W12-0102", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Fangzhong, Su | Bogdan, Babych", 
    "raw_text": "It also can be quantified as the rate of successful extraction of translation equivalents by automated tools, such as proposed in Munteanu and Marcu (2006) .Still, successful detection of translation equivalents from comparable corpora very much de 10 pends on the quality of these corpora, specifically on the degree of their textual equivalence and successful alignment on various text units", 
    "clean_text": "It also can be quantified as the rate of successful extraction of translation equivalents by automated tools, such as proposed in Munteanu and Marcu (2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P08-1049", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Zhifei, Li | David, Yarowsky", 
    "raw_text": "To the best of our knowledge, our work is the first to systematically model Chineseabbreviation expansion to improve machine translation. The idea of using a bridge (i.e., full-form) to obtain translation entries for unseen words (i.e. ,abbreviation) is similar to the idea of using paraphrases in MT (see Callison-Burch et al (2006) and references therein) as both are trying to introduce generalization into MT. At last, the goal that we aim to exploit monolingual corpora to help MT is in-spirit similar to the goal of using non-parallel corpora to help MT as aimed in a large amount of work (see Munteanu and Marcu (2006) and references therein)", 
    "clean_text": "At last, the goal that we aim to exploit monolingual corpora to help MT is in-spirit similar to the goal of using non-parallel corpora to help MT as aimed in a large amount of work (see Munteanu and Marcu (2006) and references therein).", 
    "keep_for_gold": 0
  }
]
