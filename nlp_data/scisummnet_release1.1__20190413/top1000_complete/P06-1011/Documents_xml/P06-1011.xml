<PAPER>
  <S sid="0">Extracting Parallel Sub-Sentential Fragments From Non-Parallel Corpora</S>
  <ABSTRACT>
    <S sid="1" ssid="1">We present a novel method for extracting parallel sub-sentential fragments from comparable, non-parallel bilingual corpora.</S>
    <S sid="2" ssid="2">By analyzing potentially similar sentence pairs using a signal processinginspired approach, we detect which segments of the source sentence are translated into segments in the target sentence, and which are not.</S>
    <S sid="3" ssid="3">This method enables us to extract useful machine translation training data even from very non-parallel corpora, which contain no parallel sentence pairs.</S>
    <S sid="4" ssid="4">We evaluate the quality of the extracted data by showing that it improves the performance of a state-of-the-art statistical machine translation system.</S>
  </ABSTRACT>
  <SECTION title="1 Introduction" number="1">
    <S sid="5" ssid="1">Recently, there has been a surge of interest in the automatic creation of parallel corpora.</S>
    <S sid="6" ssid="2">Several researchers (Zhao and Vogel, 2002; Vogel, 2003; Resnik and Smith, 2003; Fung and Cheung, 2004a; Wu and Fung, 2005; Munteanu and Marcu, 2005) have shown how fairly good-quality parallel sentence pairs can be automatically extracted from comparable corpora, and used to improve the performance of machine translation (MT) systems.</S>
    <S sid="7" ssid="3">This work addresses a major bottleneck in the development of Statistical MT (SMT) systems: the lack of sufficiently large parallel corpora for most language pairs.</S>
    <S sid="8" ssid="4">Since comparable corpora exist in large quantities and for many languages &#8211; tens of thousands of words of news describing the same events are produced daily &#8211; the ability to exploit them for parallel data acquisition is highly beneficial for the SMT field.</S>
    <S sid="9" ssid="5">Comparable corpora exhibit various degrees of parallelism.</S>
    <S sid="10" ssid="6">Fung and Cheung (2004a) describe corpora ranging from noisy parallel, to comparable, and finally to very non-parallel.</S>
    <S sid="11" ssid="7">Corpora from the last category contain &#8220;... disparate, very nonparallel bilingual documents that could either be on the same topic (on-topic) or not&#8221;.</S>
    <S sid="12" ssid="8">This is the kind of corpora that we are interested to exploit in the context of this paper.</S>
    <S sid="13" ssid="9">Existing methods for exploiting comparable corpora look for parallel data at the sentence level.</S>
    <S sid="14" ssid="10">However, we believe that very non-parallel corpora have none or few good sentence pairs; most of their parallel data exists at the sub-sentential level.</S>
    <S sid="15" ssid="11">As an example, consider Figure 1, which presents two news articles from the English and Romanian editions of the BBC.</S>
    <S sid="16" ssid="12">The articles report on the same event (the one-year anniversary of Ukraine&#8217;s Orange Revolution), have been published within 25 minutes of each other, and express overlapping content.</S>
    <S sid="17" ssid="13">Although they are &#8220;on-topic&#8221;, these two documents are non-parallel.</S>
    <S sid="18" ssid="14">In particular, they contain no parallel sentence pairs; methods designed to extract full parallel sentences will not find any useful data in them.</S>
    <S sid="19" ssid="15">Still, as the lines and boxes from the figure show, some parallel fragments of data do exist; but they are present at the sub-sentential level.</S>
    <S sid="20" ssid="16">In this paper, we present a method for extracting such parallel fragments from comparable corpora.</S>
    <S sid="21" ssid="17">Figure 2 illustrates our goals.</S>
    <S sid="22" ssid="18">It shows two sentences belonging to the articles in Figure 1, and highlights and connects their parallel fragments.</S>
    <S sid="23" ssid="19">Although the sentences share some common meaning, each of them has content which is not translated on the other side.</S>
    <S sid="24" ssid="20">The English phrase reports the BBC&#8217;s Helen Fawkes in Kiev, as well Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 81&#8211;88, Sydney, July 2006. c&#65533;2006 Association for Computational Linguistics as the Romanian one De altfel, vorbind inaintea aniversarii have no translation correspondent, either in the other sentence or anywhere in the whole document.</S>
    <S sid="25" ssid="21">Since the sentence pair contains so much untranslated text, it is unlikely that any parallel sentence detection method would consider it useful.</S>
    <S sid="26" ssid="22">And, even if the sentences would be used for MT training, considering the amount of noise they contain, they might do more harm than good for the system&#8217;s performance.</S>
    <S sid="27" ssid="23">The best way to make use of this sentence pair is to extract and use for training just the translated (highlighted) fragments.</S>
    <S sid="28" ssid="24">This is the aim of our work.</S>
    <S sid="29" ssid="25">Identifying parallel subsentential fragments is a difficult task.</S>
    <S sid="30" ssid="26">It requires the ability to recognize translational equivalence in very noisy environments, namely sentence pairs that express different (although overlapping) content.</S>
    <S sid="31" ssid="27">However, a good solution to this problem would have a strong impact on parallel data acquisition efforts.</S>
    <S sid="32" ssid="28">Enabling the exploitation of corpora that do not share parallel sentences would greatly increase the amount of comparable data that can be used for SMT.</S>
  </SECTION>
  <SECTION title="2 Finding Parallel Sub-Sentential Fragments in Comparable Corpora" number="2">
    <S sid="33" ssid="1">The high-level architecture of our parallel fragment extraction system is presented in Figure 3.</S>
    <S sid="34" ssid="2">The first step of the pipeline identifies document pairs that are similar (and therefore more likely to contain parallel data), using the Lemur information retrieval toolkit' (Ogilvie and Callan, 2001); each document in the source language is translated word-for-word and turned into a query, which is run against the collection of target language documents.</S>
    <S sid="35" ssid="3">The top 20 results are retrieved and paired with the query document.</S>
    <S sid="36" ssid="4">We then take all sentence pairs from these document pairs and run them through the second step in the pipeline, the candidate selection filter.</S>
    <S sid="37" ssid="5">This step discards pairs which have very few words that are translations of each other.</S>
    <S sid="38" ssid="6">To all remaining sentence pairs we apply the fragment detection method (described in Section 2.3), which produces the output of the system.</S>
    <S sid="39" ssid="7">We use two probabilistic lexicons, learned automatically from the same initial parallel corpus.</S>
    <S sid="40" ssid="8">The first one, GIZA-Ler, is obtained by running the GIZA++2 implementation of the IBM word alignment models (Brown et al., 1993) on the initial parallel corpus.</S>
    <S sid="41" ssid="9">One of the characteristics of this lexicon is that each source word is associated with many possible translations.</S>
    <S sid="42" ssid="10">Although most of its high-probability entries are good translations, there are a lot of entries (of non-negligible probability) where the two words are at most related.</S>
    <S sid="43" ssid="11">As an example, in our GIZA-Ler lexicon, each source word has an average of 12 possible translations.</S>
    <S sid="44" ssid="12">This characteristic is useful for the first two stages of the extraction pipeline, which are not intended to be very precise.</S>
    <S sid="45" ssid="13">Their purpose is to accept most of the existing parallel data, and not too much of the non-parallel data; using such a lexicon helps achieve this purpose.</S>
    <S sid="46" ssid="14">For the last stage, however, precision is paramount.</S>
    <S sid="47" ssid="15">We found empirically that when using GIZA-Ler, the incorrect correspondences that it contains seriously impact the quality of our results; we therefore need a cleaner lexicon.</S>
    <S sid="48" ssid="16">In addition, since we want to distinguish between source words that have a translation on the target side and words that do not, we also need a measure of the probability that two words are not translations of each other.</S>
    <S sid="49" ssid="17">All these are part of our second lexicon, LLR-Ler, which we present in detail in Section 2.2.</S>
    <S sid="50" ssid="18">Subsequently, in Section 2.3, we present our algorithm for detecting parallel sub-sentential fragments.</S>
    <S sid="51" ssid="19">Our method for computing the probabilistic translation lexicon LLR-Ler is based on the the LogLikelihood-Ratio (LLR) statistic (Dunning, 1993), which has also been used by Moore (2004a; 2004b) and Melamed (2000) as a measure of word association.</S>
    <S sid="52" ssid="20">Generally speaking, this statistic gives a measure of the likelihood that two samples are not independent (i.e. generated by the same probability distribution).</S>
    <S sid="53" ssid="21">We use it to estimate the independence of pairs of words which cooccur in our parallel corpus.</S>
    <S sid="54" ssid="22">If source word and target word are independent (i.e. they are not translations of each other), we would expect that .</S>
    <S sid="55" ssid="23">Thus, we can split the set of cooccurring word pairs into positively and negatively associated pairs, and obtain a measure for each of the two association types.</S>
    <S sid="56" ssid="24">The first type of association will provide us with our (cleaner) lexicon, while the second will allow us to estimate probabilities of words not being translations of each other.</S>
    <S sid="57" ssid="25">Before describing our new method more formally, we address the notion of word cooccurrence.</S>
    <S sid="58" ssid="26">In the work of Moore (2004a) and Melamed (2000), two words cooccur if they are present in a pair of aligned sentences in the parallel training corpus.</S>
    <S sid="59" ssid="27">However, most of the words from aligned sentences are actually unrelated; therefore, this is a rather weak notion of cooccurrence.</S>
    <S sid="60" ssid="28">We follow Resnik et. al (2001) and adopt a stronger definition, based not on sentence alignment but on word alignment: two words cooccur if they are linked together in the word-aligned parallel training corpus.</S>
    <S sid="61" ssid="29">We thus make use of the significant amount of knowledge brought in by the word alignment procedure.</S>
    <S sid="62" ssid="30">We compute ,the LLR score for words and , using the formula presented by Moore (2004b), which we do not repeat here due to lack of space.</S>
    <S sid="63" ssid="31">We then use these values to compute two conditional probability distributions: , the probability that source word trans, i.e. the distribution of given that is present is the same as the distribution of when is not present.</S>
    <S sid="64" ssid="32">The LLR statistic gives a measure of the likelihood of this hypothesis.</S>
    <S sid="65" ssid="33">The LLR score of a word pair is low when these two distributions are very similar (i.e. the words are independent), and high otherwise (i.e. the words are strongly associated).</S>
    <S sid="66" ssid="34">However, high LLR scores can indicate either a positive association (i.e. lates into target word , and , the probability that does not translate into .</S>
    <S sid="67" ssid="35">We obtain the distributions by normalizing the LLR scores for each source word.</S>
    <S sid="68" ssid="36">The whole procedure follows: Word-align the parallel corpus.</S>
    <S sid="69" ssid="37">Following Och and Ney (2003), we run GIZA++ in both directions, and then symmetrize the alignments using the refined heuristic.</S>
    <S sid="70" ssid="38">Compute all LLR scores.</S>
    <S sid="71" ssid="39">There will be an LLR score for each pair of words which are linked at least once in the word-aligned corpus Divide all terms by the corresponding normalizing factors to obtain .</S>
    <S sid="72" ssid="40">Divide all terms by the corresponding normalizing factors to obtain .</S>
    <S sid="73" ssid="41">In order to compute the distributions, we reverse the source and target languages and repeat the procedure.</S>
    <S sid="74" ssid="42">As we mentioned above, in GIZA-Lex the average number of possible translations for a source word is 12.</S>
    <S sid="75" ssid="43">In LLR-Lex that average is 5, which is a significant decrease.</S>
    <S sid="76" ssid="44">Intuitively speaking, our method tries to distinguish between source fragments that have a translation on the target side, and fragments that do not.</S>
    <S sid="77" ssid="45">In Figure 4 we show the sentence pair from Figure 2, in which we have underlined those words of each sentence that have a translation in the other sentence, according to our lexicon LLR-Lex.</S>
    <S sid="78" ssid="46">The phrases &#8220;to focus on the past year&#8217;s achievements, which,&#8221; and &#8220;sa se concentreze pe succesele anului trecut, care,&#8221; are mostly underlined (the lexicon is unaware of the fact that &#8220;achievements&#8221; and &#8220;succesele&#8221; are in fact translations of each other, because &#8220;succesele&#8221; is a morphologically inflected form which does not cooccur with &#8220;achievements&#8221; in our initial parallel corpus).</S>
    <S sid="79" ssid="47">The rest of the sentences are mostly not underlined, although we do have occasional connections, some correct and some wrong.</S>
    <S sid="80" ssid="48">The best we can do in this case is to infer that these two phrases are parallel, and discard the rest.</S>
    <S sid="81" ssid="49">Doing this gains us some new knowledge: the lexicon entry (achievements, succesele).</S>
    <S sid="82" ssid="50">We need to quantify more precisely the notions of &#8220;mostly translated&#8221; and &#8220;mostly not translated&#8221;.</S>
    <S sid="83" ssid="51">Our approach is to consider the target sentence as a numeric signal, where translated words correspond to positive values (coming from the distribution described in the previous Section), and the others to negative ones (coming from the distribution).</S>
    <S sid="84" ssid="52">We want to retain the parts of the sentence where the signal is mostly positive.</S>
    <S sid="85" ssid="53">This can be achieved by applying a smoothing filter to the signal, and selecting those fragments of the sentence for which the corresponding filtered values are positive.</S>
    <S sid="86" ssid="54">The details of the procedure are presented below, and also illustrated in Figure 5.</S>
    <S sid="87" ssid="55">Let the Romanian sentence be the source sentence , and the English one be the target, .</S>
    <S sid="88" ssid="56">We compute a word alignment by greedily linking each English word with its best translation candidate from the Romanian sentence.</S>
    <S sid="89" ssid="57">For each of the linked target words, the corresponding signal value is the probability of the link (there can be at most one link for each target word).</S>
    <S sid="90" ssid="58">Thus, if target word is linked to source word , the signal value corresponding to is (the distribution described in Section 2.2), i.e. the probability that is the translation of .</S>
    <S sid="91" ssid="59">For the remaining target words, the signal value should reflect the probability that they are not Figure 5: Our approach for detecting parallel fragments.</S>
    <S sid="92" ssid="60">The lower part of the figure shows the source and target sentence together with their alignment.</S>
    <S sid="93" ssid="61">Above are displayed the initial signal and the filtered signal.</S>
    <S sid="94" ssid="62">The circles indicate which fragments of the target sentence are selected by the procedure. translated; for this, we employ the distribution.</S>
    <S sid="95" ssid="63">Thus, for each non-linked target word , we look for the source word least likely to be its nontranslation: .</S>
    <S sid="96" ssid="64">If exists, we set the signal value for to ; otherwise, we set it to .</S>
    <S sid="97" ssid="65">This is the initial signal.</S>
    <S sid="98" ssid="66">We obtain the filtered signal by applying an averaging filter, which sets the value at each point to be the average of several values surrounding it.</S>
    <S sid="99" ssid="67">In our experiments, we use the surrounding 5 values, which produced good results on a development set.</S>
    <S sid="100" ssid="68">We then simply retain the &#8220;positive fragments&#8221; of , i.e. those fragments for which the corresponding filtered signal values are positive.</S>
    <S sid="101" ssid="69">However, this approach will often produce short &#8220;positive fragments&#8221; which are not, in fact, translated in the source sentence.</S>
    <S sid="102" ssid="70">An example of this is the fragment &#8220;, reports&#8221; from Figure 5, which although corresponds to positive values of the filtered signal, has no translation in Romanian.</S>
    <S sid="103" ssid="71">In an attempt to avoid such errors, we disregard fragments with less than 3 words.</S>
    <S sid="104" ssid="72">We repeat the procedure in the other direction ( ) to obtain the fragments for , and consider the resulting two text chunks as parallel.</S>
    <S sid="105" ssid="73">For the sentence pair from Figure 5, our system will output the pair: people to focus on the past year&#8217;s achievements, which, he says sa se concentreze pe succesele anului trecut, care, printre</S>
  </SECTION>
  <SECTION title="3 Experiments" number="3">
    <S sid="106" ssid="1">In our experiments, we compare our fragment extraction method (which we call FragmentExtract) with the sentence extraction approach of Munteanu and Marcu (2005) (SentenceExtract).</S>
    <S sid="107" ssid="2">All extracted datasets are evaluated by using them as additional MT training data and measuring their impact on the performance of the MT system.</S>
    <S sid="108" ssid="3">We perform experiments in the context of Romanian to English machine translation.</S>
    <S sid="109" ssid="4">We use two initial parallel corpora.</S>
    <S sid="110" ssid="5">One is the training data for the Romanian-English word alignment task from the Workshop on Building and Using Parallel Corpora3 which has approximately 1M English words.</S>
    <S sid="111" ssid="6">The other contains additional data from the Romanian translations of the European Union&#8217;s acquis communautaire which we mined from the Web, and has about 10M English words.</S>
    <S sid="112" ssid="7">We downloaded comparable data from three online news sites: the BBC, and the Romanian newspapers &#8220;Evenimentul Zilei&#8221; and &#8220;Ziua&#8221;.</S>
    <S sid="113" ssid="8">The BBC corpus is precisely the kind of corpus that our method is designed to exploit.</S>
    <S sid="114" ssid="9">It is truly nonparallel; as our example from Figure 1 shows, even closely related documents have few or no parallel sentence pairs.</S>
    <S sid="115" ssid="10">Therefore, we expect that our extraction method should perform best on this corpus.</S>
    <S sid="116" ssid="11">The other two sources are fairly similar, both in genre and in degree of parallelism, so we group them together and refer to them as the EZZ corpus.</S>
    <S sid="117" ssid="12">This corpus exhibits a higher degree of parallelism than the BBC one; in particular, it contains many article pairs which are literal translations of each other.</S>
    <S sid="118" ssid="13">Therefore, although our subsentence extraction method should produce useful data from this corpus, we expect the sentence extraction method to be more successful.</S>
    <S sid="119" ssid="14">Using this second corpus should help highlight the strengths and weaknesses of our approach.</S>
    <S sid="120" ssid="15">Table 1 summarizes the relevant information concerning these corpora.</S>
    <S sid="121" ssid="16">On each of our comparable corpora, and using each of our initial parallel corpora, we apply both the fragment extraction and the sentence extraction method of Munteanu and Marcu (2005).</S>
    <S sid="122" ssid="17">In order to evaluate the importance of the LLRLex lexicon, we also performed fragment extraction experiments that do not use this lexicon, but only GIZA-Lex.</S>
    <S sid="123" ssid="18">Thus, for each initial parallel corpus and each comparable corpus, we extract three datasets: FragmentExtract, SentenceExtract, and Fragment-noLLR.</S>
    <S sid="124" ssid="19">The sizes of the extracted datasets, measured in million English tokens, are presented in Table 2.</S>
    <S sid="125" ssid="20">We evaluate our extracted corpora by measuring their impact on the performance of an SMT system.</S>
    <S sid="126" ssid="21">We use the initial parallel corpora to train Baseline systems; and then train comparative systems using the initial corpora plus: the FragmentExtract corpora; the SentenceExtract corpora; and the FragmentExtract-noLLR corpora.</S>
    <S sid="127" ssid="22">In order to verify whether the fragment and sentence detection method complement each other, we also train a Fragment+Sentence system, on the initial corpus plus FragmentExtract and SentenceExtract.</S>
    <S sid="128" ssid="23">All MT systems are trained using a variant of the alignment template model of Och and Ney (2004).</S>
    <S sid="129" ssid="24">All systems use the same 2 language models: one trained on 800 million English tokens, and one trained on the English side of all our parallel and comparable corpora.</S>
    <S sid="130" ssid="25">This ensures that differences in performance are caused only by differences in the parallel training data.</S>
    <S sid="131" ssid="26">Our test data consists of news articles from the Time Bank corpus, which were translated into Romanian, and has 1000 sentences.</S>
    <S sid="132" ssid="27">Translation performance is measured using the automatic BLEU (Papineni et al., 2002) metric, on one reference translation.</S>
    <S sid="133" ssid="28">We report BLEU% numbers, i.e. we multiply the original scores by 100.</S>
    <S sid="134" ssid="29">The 95% confidence intervals of our scores, computed by bootstrap resampling (Koehn, 2004), indicate that a score increase of more than 1 BLEU% is statistically significant.</S>
    <S sid="135" ssid="30">The scores are presented in Figure 6.</S>
    <S sid="136" ssid="31">On the BBC corpus, the fragment extraction method produces statistically significant improvements over the baseline, while the sentence extraction method does not.</S>
    <S sid="137" ssid="32">Training on both datasets together brings further improvements.</S>
    <S sid="138" ssid="33">This indicates that this corpus has few parallel sentences, and that by going to the sub-sentence level we make better use of it.</S>
    <S sid="139" ssid="34">On the EZZ corpus, although our method brings improvements in the BLEU score, the sentence extraction method does better.</S>
    <S sid="140" ssid="35">Joining both extracted datasets does not improve performance; since most of the parallel data in this corpus exists at sentence level, the extracted fragments cannot bring much additional knowledge.</S>
    <S sid="141" ssid="36">The Fragment-noLLR datasets bring no translation performance improvements; moreover, when the initial corpus is small (1M words) and the comparable corpus is noisy (BBC), the data has a negative impact on the BLEU score.</S>
    <S sid="142" ssid="37">This indicates that LLR-Lex is a higher-quality lexicon than GIZALex, and an important component of our method.</S>
  </SECTION>
  <SECTION title="4 Previous Work" number="4">
    <S sid="143" ssid="1">Much of the work involving comparable corpora has focused on extracting word translations (Fung and Yee, 1998; Rapp, 1999; Diab and Finch, 2000; Koehn and Knight, 2000; Gaussier et al., 2004; Shao and Ng, 2004; Shinyama and Sekine, 2004).</S>
    <S sid="144" ssid="2">Another related research effort is that of Resnik and Smith (2003), whose system is designed to discover parallel document pairs on the Web.</S>
    <S sid="145" ssid="3">Our work lies between these two directions; we attempt to discover parallelism at the level of fragments, which are longer than one word but shorter than a document.</S>
    <S sid="146" ssid="4">Thus, the previous research most relevant to this paper is that aimed at mining comparable corpora for parallel sentences.</S>
    <S sid="147" ssid="5">The earliest efforts in this direction are those of Zhao and Vogel (2002) and Utiyama and Isahara (2003).</S>
    <S sid="148" ssid="6">Both methods extend algorithms designed to perform sentence alignment of parallel texts: they use dynamic programming to do sentence alignment of documents hypothesized to be similar.</S>
    <S sid="149" ssid="7">These approaches are only applicable to corpora which are at most &#8220;noisy-parallel&#8221;, i.e. contain documents which are fairly similar, both in content and in sentence ordering.</S>
    <S sid="150" ssid="8">Munteanu and Marcu (2005) analyze sentence pairs in isolation from their context, and classify them as parallel or non-parallel.</S>
    <S sid="151" ssid="9">They match each source document with several target ones, and classify all possible sentence pairs from each document pair.</S>
    <S sid="152" ssid="10">This enables them to find sentences from fairly dissimilar documents, and to handle any amount of reordering, which makes the method applicable to truly comparable corpora.</S>
    <S sid="153" ssid="11">The research reported by Fung and Cheung (2004a; 2004b), Cheung and Fung (2004) and Wu and Fung (2005) is aimed explicitly at &#8220;very non-parallel corpora&#8221;.</S>
    <S sid="154" ssid="12">They also pair each source document with several target ones and examine all possible sentence pairs; but the list of document pairs is not fixed.</S>
    <S sid="155" ssid="13">After one round of sentence extraction, the list is enriched with additional documents, and the system iterates.</S>
    <S sid="156" ssid="14">Thus, they include in the search document pairs which are dissimilar.</S>
    <S sid="157" ssid="15">One limitation of all these methods is that they are designed to find only full sentences.</S>
    <S sid="158" ssid="16">Our methodology is the first effort aimed at detecting sub-sentential correspondences.</S>
    <S sid="159" ssid="17">This is a difficult task, requiring the ability to recognize translationally equivalent fragments even in non-parallel sentence pairs.</S>
    <S sid="160" ssid="18">The work of Deng et. al (2006) also deals with sub-sentential fragments.</S>
    <S sid="161" ssid="19">However, they obtain parallel fragments from parallel sentence pairs (by chunking them and aligning the chunks appropriately), while we obtain them from comparable or non-parallel sentence pairs.</S>
    <S sid="162" ssid="20">Since our approach can extract parallel data from texts which contain few or no parallel sentences, it greatly expands the range of corpora which can be usefully exploited.</S>
  </SECTION>
  <SECTION title="5 Conclusion" number="5">
    <S sid="163" ssid="1">We have presented a simple and effective method for extracting sub-sentential fragments from comparable corpora.</S>
    <S sid="164" ssid="2">We also presented a method for computing a probabilistic lexicon based on the LLR statistic, which produces a higher quality lexicon.</S>
    <S sid="165" ssid="3">We showed that using this lexicon helps improve the precision of our extraction method.</S>
    <S sid="166" ssid="4">Our approach can be improved in several aspects.</S>
    <S sid="167" ssid="5">The signal filtering function is very simple; more advanced filters might work better, and eliminate the need of applying additional heuristics (such as our requirement that the extracted fragments have at least 3 words).</S>
    <S sid="168" ssid="6">The fact that the source and target signal are filtered separately is also a weakness; a joint analysis should produce better results.</S>
    <S sid="169" ssid="7">Despite the better lexicon, the greatest source of errors is still related to false word correspondences, generally involving punctuation and very common, closed-class words.</S>
    <S sid="170" ssid="8">Giving special attention to such cases should help get rid of these errors, and improve the precision of the method.</S>
  </SECTION>
  <SECTION title="Acknowledgements" number="6">
    <S sid="171" ssid="1">This work was partially supported under the GALE program of the Defense Advanced Research Projects Agency, Contract No.</S>
    <S sid="172" ssid="2">HR001106-C-0022.</S>
  </SECTION>
</PAPER>
