[
  {
    "citance_No": 1, 
    "citing_paper_id": "P08-1102", 
    "citing_paper_authority": 33, 
    "citing_paper_authors": "Wenbin, Jiang | Liang, Huang | Qun, Liu | Yajuan, L&uuml;", 
    "raw_text": "On the three corpora, it also outperformed the word-based perceptron model of Zhang and Clark (2007)", 
    "clean_text": "On the three corpora, it also outperformed the word-based perceptron model of Zhang and Clark (2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-1028", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Wenzhe, Pei | Tao, Ge | Baobao, Chang", 
    "raw_text": "The idea of feature embeddings is similar to that of character embeddings described in section 2.1. 5https: //code.google.com/p/word2vec/ Model PKU MSRA Best05 (Chen et al, 2005) 95.0 96.0 Best05 (Tseng et al, 2005) 95.0 96.4 (Zhang et al, 2006) 95.1 97.1 (Zhang and Clark, 2007) 94.5 97.2 (Sun et al, 2009) 95.2 97.3 (Sun et al, 2012) 95.4 97.4 (Zhang et al, 2013) 96.1 97.4 MMTNN 94.0 94.9 MMTNN +bigram 95.2 97.2 Table 6: Comparison with state-of-the-art systems Formally, we assume the extracted features form a feature dictionary D f. Then each feature f? D. f is represented by a d-dimensional vector which is called feature embedding", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "D10-1082", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Yue, Zhang | Stephen, Clark", 
    "raw_text": "Moreover, our model is based on our previous work, in line with Zhang and Clark (2007), which does not treat word segmentation as character sequence labeling", 
    "clean_text": "Moreover, our model is based on our previous work, in line with Zhang and Clark (2007), which does not treat word segmentation as character sequence labeling.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "C10-1132", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Kun, Wang | Chengqing, Zong | Keh-Yih, Su", 
    "raw_text": "This category includes (Zhang et al., 2006) (Zhang06), (Zhang and Clark, 2007) (Z& amp; C07) and (Jiang et al, 2008) (Jiang08)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "C10-1132", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Kun, Wang | Chengqing, Zong | Keh-Yih, Su", 
    "raw_text": "(Zhang and Clark, 2007) uses perceptron (Collins, 2002) to generate word candidates with both word and character features", 
    "clean_text": "(Zhang and Clark, 2007) uses perceptron (Collins, 2002) to generate word candidates with both word and character features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "C10-1132", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Kun, Wang | Chengqing, Zong | Keh-Yih, Su", 
    "raw_text": "All of the above models, except (Zhang and Clark, 2007), adopt the character-based discriminative approach", 
    "clean_text": "All of the above models, except (Zhang and Clark, 2007), adopt the character-based discriminative approach.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "C10-1132", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Kun, Wang | Chengqing, Zong | Keh-Yih, Su", 
    "raw_text": "It shows that both our joint-plus model and joint model exceed (or are comparable to) almost all e state-of-the-art systems across all corpora, except (Zhang and Clark, 2007) at PKU (ucvt.)", 
    "clean_text": "It shows that both our joint-plus model and joint model exceed (or are comparable to) almost all e state-of-the-art systems across all corpora, except (Zhang and Clark, 2007) at PKU (ucvt.).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "C10-1132", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Kun, Wang | Chengqing, Zong | Keh-Yih, Su", 
    "raw_text": "In that special case, (Zhang and Clark, 2007) 4 We are not sure whether (Asahara et al, 2005) and", 
    "clean_text": "In that special case, (Zhang and Clark, 2007) outperforms the joint-plus model by 0.3% on F score (0.4% for the joint model).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P12-1027", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Xu, Sun | Houfeng, Wang | Wenjie, Li", 
    "raw_text": "Pre Rec F-score MSR Best05 (Tseng et al, 2005)? 96.2 96.6 96.4 CRF+ rule-system (Zhang et al, 2006)? 97.2 96.9 97.1 Semi-Markovperceptron (Zhang and Clark, 2007)? N/A N/A 97.2 Semi-Markov CRF (Gao et al, 2007)? N/A N/A 97.2 Latent-variable CRF (Sun et al, 2009b)? 97.3 97.3 97.3 Our method (A Single CRF)? 97.6 97.2 97.4 CU Best05 (Tseng et al, 2005)? 94.1 94.6 94.3 CRF+ rule-system (Zhang et al, 2006)? 95.2 94.9 95.1 Semi-perceptron (Zhang and Clark, 2007)? N/A N/A 95.1 Latent-variable CRF (Sun et al, 2009b)? 94.7 94.4 94.6 Our method (A Single CRF)? 94.8 94.7 94.8 PKU Best05 (Chen et al, 2005) N/A 95.3 94.6 95.0 CRF+ rule-system (Zhang et al, 2006)? 94.7 95.5 95.1semi-perceptron (Zhang and Clark, 2007)? N/A N/A 94.5 Latent-variable CRF (Sun et al, 2009b)? 95.6 94.8 95.2 Our method (A Single CRF)? 95.8 94.9 95.4 Table 3: Comparing our method with the state-of-the-art CWS systems", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P14-2032", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mengqiu, Wang | Rob, Voigt | Christopher D., Manning", 
    "raw_text": "More recently, Zhang and Clark (2007) reported success using a linear model trained with the average perceptron algorithm (Collins, 2002)", 
    "clean_text": "More recently, Zhang and Clark (2007) reported success using a linear model trained with the average perceptron algorithm (Collins, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P14-2032", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mengqiu, Wang | Rob, Voigt | Christopher D., Manning", 
    "raw_text": "We use the publicly available Stan ford CRFsegmenter (Tseng et al, 2005) 2 as our character-based baseline model, and reproduce the perceptron-based segmenter from Zhang and Clark (2007) as our word-based baseline model", 
    "clean_text": "We use the publicly available Stanford CRF segmenter (Tseng et al, 2005) as our character-based baseline model, and reproduce the perceptron-based segmenter from Zhang and Clark (2007) as our word-based baseline model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P14-2032", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mengqiu, Wang | Rob, Voigt | Christopher D., Manning", 
    "raw_text": "We adopted the development setting from (Zhang and Clark, 2007), and used CTBsections1270 for training and sections 400931 for development in hyper-parameter setting; for all results given in tables, the models are trained and evaluated on the standard train/test split for the given dataset", 
    "clean_text": "We adopted the development setting from (Zhang and Clark, 2007), and used CTB sections 1-270 for training and sections 400-931 for development in hyper-parameter setting; for all results given in tables, the models are trained and evaluated on the standard train/test split for the given dataset.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P14-2032", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mengqiu, Wang | Rob, Voigt | Christopher D., Manning", 
    "raw_text": "Z& amp; C 07 refers to Zhang and Clark (2007)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "C10-2139", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Weiwei, Sun", 
    "raw_text": "For decoding, Zhang and Clark (2007) used abeam search algorithm to get approximate solutions, and Sarawagi and Cohen (2004) introduced a Viterbi style algorithm for exact inference", 
    "clean_text": "For decoding, Zhang and Clark (2007) used a beam search algorithm to get approximate solutions, and Sarawagi and Cohen (2004) introduced a Viterbi style algorithm for exact inference.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "C10-2139", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Weiwei, Sun", 
    "raw_text": "This is different from the experiments reported in (Zhang and Clark, 2007)", 
    "clean_text": "This is different from the experiments reported in (Zhang and Clark, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "C10-2139", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Weiwei, Sun", 
    "raw_text": "AS CU MSR PKU (Zhang et al, 2006) 95.1 95.1 97.1 95.1 (Zhang and Clark, 2007) 94.6 95.1 97.2 94.5 (Sun et al, 2009b) N/A 94.6 97.3 95.2 This paper 95.2 95.6 96.9 95.2 Table 5: Segmentation performance presented in previous work and of our combination model", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P13-2031", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Xiaodong, Zeng | Derek F., Wong | Lidia S., Chao | Isabel, Trancoso", 
    "raw_text": "For the decoding, a beam search decoding method (Zhang and Clark, 2007) is used", 
    "clean_text": "For the decoding, a beam search decoding method (Zhang and Clark, 2007) is used.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P13-2031", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Xiaodong, Zeng | Derek F., Wong | Lidia S., Chao | Isabel, Trancoso", 
    "raw_text": "The feature templates in (Zhao et al, 2006) and (Zhang and Clark, 2007) are used in train-ingthe CRFs model and Perceptrons model, respectively", 
    "clean_text": "The feature templates in (Zhao et al, 2006) and (Zhang and Clark, 2007) are used in training the CRFs model and Perceptrons model, respectively.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P08-1101", 
    "citing_paper_authority": 30, 
    "citing_paper_authors": "Yue, Zhang | Stephen, Clark", 
    "raw_text": "We built a two-stage baseline system, using the per ceptron segmentation model from our previous work (Zhang and Clark, 2007) and the perceptron POS tagging model from Collins (2002)", 
    "clean_text": "We built a two-stage baseline system, using the per ceptron segmentation model from our previous work (Zhang and Clark, 2007) and the perceptron POS tagging model from Collins (2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P08-1101", 
    "citing_paper_authority": 30, 
    "citing_paper_authors": "Yue, Zhang | Stephen, Clark", 
    "raw_text": "We use baseline system to refer to the system which performs segmentation first, followed by POS tagging (using the single-best segmentation); baseline segment or to re fer to the segment or from (Zhang and Clark, 2007) which performs segmentation only; and baselinePOStagger to refer to the Collins tagger which per forms POS tagging only (given segmentation)", 
    "clean_text": "We use baseline system to refer to the system which performs segmentation first, followed by POS tagging (using the single-best segmentation); baseline segment or to refer to the segment or from (Zhang and Clark, 2007) which performs segmentation only; and baseline POStagger to refer to the Collins tagger which performs POS tagging only (given segmentation).", 
    "keep_for_gold": 0
  }
]
