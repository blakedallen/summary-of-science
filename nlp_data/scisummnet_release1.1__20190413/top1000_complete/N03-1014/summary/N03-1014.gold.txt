Inducing History Representations For Broad Coverage Statistical Parsing
We present a neural network method for inducing representations of parse histories and using these history representations to estimate the probabilities needed by a statistical left-corner parser.
The resulting statistical parser achieves performance (89.1% F-measure) on the Penn Treebank which is only 0.6% below the best current parser for this task, despite using a smaller vocabulary size and less prior linguistic knowledge.
Crucial to this success is the use of structurally determined soft biases in inducing the representation of the parse history, and no use of hard independence assumptions.
Of the previous work on using neural net works for parsing natural language, the most empirically successful has been our work using Simple Synchrony Networks.
We test the effect of larger input vocabulary on SSN performance by changing the frequency cut-off that selects the input tag-word pairs.
