[
  {
    "citance_No": 1, 
    "citing_paper_id": "W06-1633", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Cristina, Nicolae | Gabriel, Nicolae", 
    "raw_text": "(Ng, 2005) treats co reference resolution as a problem of ranking candidate partitions generated by a set of co reference systems", 
    "clean_text": "(Ng, 2005) treats coreference resolution as a problem of ranking candidate partitions generated by a set of coreference systems.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W06-1633", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Cristina, Nicolae | Gabriel, Nicolae", 
    "raw_text": "The main difference between this approach and ours is that (Ng, 2005)? s approach takes co reference resolution one step further, by comparing the results of multiple systems, while our system is a single resolver; fur therm ore, he emphasizes the global optimization of ranking clusters obtained locally, whereas our focus is on globally optimizing the clusterization method inside the resolver", 
    "clean_text": "The main difference between this approach and ours is that (Ng, 2005)'s approach takes coreference resolution one step further, by comparing the results of multiple systems, while our system is a single resolver; furthermore, he emphasizes the global optimization of ranking clusters obtained locally, whereas our focus is on globally optimizing the clusterization method inside the resolver.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W12-4508", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Xingwei, Liao | Xinxin, Li | Xuan, Wang", 
    "raw_text": "There are many different training example generation algorithms ,e.g., McCarthy and Lehnert? s method, Soon et als method, Ng and Cardies method (Ng, 2005)", 
    "clean_text": "There are many different training example generation algorithms, e.g., McCarthy and Lehnert's method, Soon et als method, Ng and Cardies method (Ng, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P07-1131", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Hongyan, Jing | Nanda, Kambhatla | Salim, Roukos", 
    "raw_text": "Similar to many previous works on co-reference (Ng, 2005), we cast the problem as a classification task and solve it in two steps: (1) train a classifier to determine whether two mentions are co-referent or not, and (2) use a clustering algorithm to partition the mentions into clusters, based on the pairwise predictions. We added many features to our model specifically designed for conversational speech, and significantly improved the agglomerative clustering used for co-reference, including integrating relations as constraints, and designing better cluster linkage methods and clustering stopping criteria", 
    "clean_text": "Similar to many previous works on co-reference (Ng, 2005), we cast the problem as a classification task and solve it in two steps: (1) train a classifier to determine whether two mentions are co-referent or not, and (2) use a clustering algorithm to partition the mentions into clusters, based on the pairwise predictions.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "N07-1011", 
    "citing_paper_authority": 38, 
    "citing_paper_authors": "Aron, Culotta | Michael, Wick | Andrew, McCallum", 
    "raw_text": "feature for cluster xj. To our knowledge, the best results on this dataset were obtained by the meta-classification scheme of Ng (2005)", 
    "clean_text": "To our knowledge, the best results on this dataset were obtained by the meta-classification scheme of Ng (2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "N07-1011", 
    "citing_paper_authority": 38, 
    "citing_paper_authors": "Aron, Culotta | Michael, Wick | Andrew, McCallum", 
    "raw_text": "Although our train-test splits may differ slightly, the best B-Cubed F1 score reported in Ng (2005) is 69.3%, which is considerably lower than the 79.3% obtained with our method", 
    "clean_text": "Although our train-test splits may differ slightly, the best B-Cubed F1 score reported in Ng (2005) is 69.3%, which is considerably lower than the 79.3% obtained with our method.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "N07-1011", 
    "citing_paper_authority": 38, 
    "citing_paper_authors": "Aron, Culotta | Michael, Wick | Andrew, McCallum", 
    "raw_text": "Ng (2005) learns a meta-classifier to choose the best prediction from the output of several co reference systems", 
    "clean_text": "Ng (2005) learns a meta-classifier to choose the best prediction from the output of several coreference systems.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "N07-1011", 
    "citing_paper_authority": 38, 
    "citing_paper_authors": "Aron, Culotta | Michael, Wick | Andrew, McCallum", 
    "raw_text": "This could be incorporated in a ranking scheme, as in Ng (2005)", 
    "clean_text": "This could be incorporated in a ranking scheme, as in Ng (2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P07-1067", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Xiaofeng, Yang | Jian, Su", 
    "raw_text": "The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure of about 62% for the same data set. The rest lines of Table 1 are for the systems using the pattern based information", 
    "clean_text": "The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure of about 62% for the same data set.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "D08-1069", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Pascal, Denis | Jason, Baldridge", 
    "raw_text": "Morton (2000) and Ng (2005b) propose different classifiers models for different NPs for co reference resolution and pronoun resolution, respectively", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "D08-1069", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Pascal, Denis | Jason, Baldridge", 
    "raw_text": "For example, Ng (2005b) learns models for each set of anaphors that are lexically identical (e.g., I, he, they, etc.)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "D08-1069", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Pascal, Denis | Jason, Baldridge", 
    "raw_text": "MUC and B3 metrics (Ng, 2005a)", 
    "clean_text": "MUC and B3 metrics (Ng, 2005a).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "N07-1030", 
    "citing_paper_authority": 45, 
    "citing_paper_authors": "Pascal, Denis | Jason, Baldridge", 
    "raw_text": "(2004) using Bell trees, and McCallum and Wellner (2004) using conditional random fields, and Ng (2005) using re rankers", 
    "clean_text": "Recent work has examined such models; Luo et al. (2004) using Bell trees, and McCallum and Wellner (2004) using conditional random fields, and Ng (2005) using rerankers.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "N07-1030", 
    "citing_paper_authority": 45, 
    "citing_paper_authors": "Pascal, Denis | Jason, Baldridge", 
    "raw_text": "A third global approach is offered by Ng (2005), who proposes a global re ranking over partitions generated by different co reference systems", 
    "clean_text": "A third global approach is offered by Ng (2005), who proposes a global reranking over partitions generated by different coreference systems.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P08-2012", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Jenny Rose, Finkel | Christopher D., Manning", 
    "raw_text": "45 opposed to pairwise models) has included: Luo et al (2004) who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; McCallum and Wellner (2004) who defined several conditional random field-based models; Ng (2005) who took a re ranking approach; and Culotta et al (2006) who use a probabilistic first-order logic model", 
    "clean_text": "Other work on global models of coreference (as opposed to pairwise models) has included: Luo et al (2004) who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; McCallum and Wellner (2004) who defined several conditional random field-based models; Ng (2005) who took a reranking approach; and Culotta et al (2006) who use a probabilistic first-order logic model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D12-1068", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Ivor Wai-Hung, Tsang | Qiao Liang, Xiang | Qi, Mao | Jian Bo, Yang | Kian Ming A., Chai | Hai Leong, Chieu", 
    "raw_text": "Similarly, the method of (Ng, 2005) ranks base models according to their performance on separate tuning set, and then uses the highest-ranked base model for predicting on test documents", 
    "clean_text": "Similarly, the method of (Ng, 2005) ranks base models according to their performance on separate tuning set, and then uses the highest-ranked base model for predicting on test documents.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P08-1096", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Xiaofeng, Yang | Jian, Su | Jun, Lang | Chew Lim, Tan | Ting, Liu | Sheng, Li", 
    "raw_text": "The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure ranging in 50-60 %forthe same data set", 
    "clean_text": "The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure ranging in 50-60% for the same data set.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "S10-1022", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Giuseppe, Attardi | Maria, Simi | Stefano, Dei Rossi", 
    "raw_text": "According to Ng (2005), most learning based co reference systems can be defined by four elements: the learning algorithm used to train the co reference classifier, the method of creating training instances for the learner, the feature set used to represent a training or test instance, and the clustering algorithm used to coordinate the co reference classification decisions", 
    "clean_text": "According to Ng (2005), most learning based coreference systems can be defined by four elements: the learning algorithm used to train the coreference classifier, the method of creating training instances for the learner, the feature set used to represent a training or test instance, and the clustering algorithm used to coordinate the coreference classification decisions.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "S10-1022", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Giuseppe, Attardi | Maria, Simi | Stefano, Dei Rossi", 
    "raw_text": "This strategy has been described as best-first clustering by Ng (2005)", 
    "clean_text": "This strategy has been described as best-first clustering by Ng (2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "C10-1147", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Shanheng, Zhao | Hwee Tou, Ng", 
    "raw_text": "In contrast to Ng (2005), Ng and Cardie (2002a) proposed a rule-induction system with rule pruning", 
    "clean_text": "In contrast to Ng (2005), Ng and Cardie (2002a) proposed a rule-induction system with rule pruning.", 
    "keep_for_gold": 0
  }
]
