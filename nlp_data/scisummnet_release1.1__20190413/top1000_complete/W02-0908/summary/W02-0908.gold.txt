Improvements In Automatic Thesaurus Extraction
The use of semantic resources is common in modern NLP systems, but methods to extract lexical semantics have only recently begun to perform well enough for practical use.
We evaluate existing and new similarity metrics for thesaurus extraction, and experiment with the trade-off between extraction performance and efficiency.
We propose an approximation algorithm, based on canonical attributes and coarse and fine-grained matching, that reduces the time complexity and execution time of thesaurus extraction with only a marginal performance penalty.
We show that synonymy extraction for lexical semantic resources using distributional similarity produces continuing gains in accuracy as the volume of input data increases.
We demonstrate that dramatically increasing the quantity of text used to extract contexts significantly improves synonym quality.
We find the JACCARD measure and the TTEST weight to have the best performance in our comparison of distance measures.
