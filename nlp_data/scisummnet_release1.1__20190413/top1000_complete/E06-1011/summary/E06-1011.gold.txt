Online Learning Of Approximate Dependency Parsing Algorithms
In this paper we extend the maximum spanning tree (MST) dependency parsing framework of McDonald et al. (2005c) to incorporate higher-order feature representations and allow dependency structures with multiple parents per word.
We show that those extensions can make the MST framework computationally intractable, but that the intractability can be circumvented with new approximate parsing algorithms.
We conclude with experiments showing that discriminative online learning using those approximate algorithms achieves the best reported parsing accuracy for Czech and Danish.
We propose a second-order graph-based dependency parsing model which incorporates features from the two kinds of subtrees.
We use the Viterbi decoding algorithm to achieve O (n3) parsing time.
We show that non-projective dependency parsing with horizontal Markovization is FNP-hard.
We define a second-order dependency parsing model in which interactions between adjacent siblings are allowed.
