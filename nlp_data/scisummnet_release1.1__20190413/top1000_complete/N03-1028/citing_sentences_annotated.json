[
  {
    "citance_No": 1, 
    "citing_paper_id": "P03-1064", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Libin, Shen | Aravind K., Joshi", 
    "raw_text": "(Abney, 1991) proposed a two-phase parsing model which includes chunking and attaching. (Ramshaw and Marcus, 1995) approached chucking by using Transformation Based Learning (TBL) .Many machine learning techniques have been successfully applied to chunking tasks, such as Regularized Winnow (Zhang et al, 2001), SVMs (Kudo and Matsumoto, 2001), CRFs (Sha and Pereira, 2003), Maximum Entropy Model (Collins, 2002), Memory Based Learning (Sang, 2002) and SNoW (Mun? oz et al., 1999)", 
    "clean_text": "Many machine learning techniques have been successfully applied to chunking tasks, such as Regularized Winnow (Zhang et al, 2001), SVMs (Kudo and Matsumoto, 2001), CRFs (Sha and Pereira, 2003), Maximum Entropy Model (Collins, 2002), Memory Based Learning (Sang, 2002) and SNoW (Munoz et al., 1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-2062", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Dirk, Hovy | Barbara, Plank | Anders, S\u00c3\u00b8gaard", 
    "raw_text": "For chunking, we follow Sha and Pereira (2003) for the set of features, including token and POS information", 
    "clean_text": "For chunking, we follow Sha and Pereira (2003) for the set of features, including token and POS information.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W06-1670", 
    "citing_paper_authority": 35, 
    "citing_paper_authors": "Massimiliano, Ciaramita | Yasemin, Altun", 
    "raw_text": "7: end if 8: w= 1T ?twt 9: end for 10: return w the perceptron performance is comparable to that of Conditional Random Field models (ShaandPereira, 2003), The tendency to over fit of the perceptron can be mitigated in a number of ways including regularization and voting", 
    "clean_text": "the perceptron performance is comparable to that of Conditional Random Field models (ShaandPereira, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P10-1040", 
    "citing_paper_authority": 133, 
    "citing_paper_authors": "Joseph P., Turian | Lev, Ratinov | Yoshua, Bengio", 
    "raw_text": "The linear CRFchunker of Sha and Pereira (2003) is a standard near-state-of-the-art baselinechunker", 
    "clean_text": "The linear CRF chunker of Sha and Pereira (2003) is a standard near-state-of-the-art baseline chunker.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P10-1040", 
    "citing_paper_authority": 133, 
    "citing_paper_authors": "Joseph P., Turian | Lev, Ratinov | Yoshua, Bengio", 
    "raw_text": "In fact, many off-the-shelf CRFimplementations now replicate Sha and Pereira (2003), including their choice of feature set:? CRF++ by Taku Kudo (http: //crfpp", 
    "clean_text": "In fact, many off-the-shelf CRF implementations now replicate Sha and Pereira (2003), including their choice of feature set.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W04-3230", 
    "citing_paper_authority": 39, 
    "citing_paper_authors": "Taku, Kudo | Kaoru, Yamamoto | Yuji, Matsumoto", 
    "raw_text": "Thisevaluation was also used in (Sha and Pereira, 2003)", 
    "clean_text": "This evaluation was also used in (Sha and Pereira, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P08-1076", 
    "citing_paper_authority": 28, 
    "citing_paper_authors": "Jun, Suzuki | Hideki, Isozaki", 
    "raw_text": "As regards the TIP 1The second-order encoding used in our NER experiments is the same as that described in (Sha and Pereira, 2003) except removing IOB-tag of previous position label", 
    "clean_text": "The second-order encoding used in our NER experiments is the same as that described in (Sha and Pereira, 2003) except removing IOB-tag of previous position label.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P05-1002", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Trevor, Cohn | Andrew E., Smith | Miles, Osborne", 
    "raw_text": "CRFs have been applied with impressive empirical results to the tasks of named entity recognition (McCallum and Li, 2003), simplified part-of-speech (POS) tagging (Lafferty et al, 2001), noun phrase chunking (Sha and Pereira, 2003) and extraction of tabular data (Pinto et al, 2003), among other tasks", 
    "clean_text": "CRFs have been applied with impressive empirical results to the tasks of noun phrase chunking (Sha and Pereira, 2003).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W06-2918", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Andrew E., Smith | Miles, Osborne", 
    "raw_text": "In recent years discriminative probabilistic model shave been successfully applied to a number of information extraction tasks in natural language processing (NLP), such as named entity recognition (NER) (McCallum and Li, 2003), noun phrase chunking (Sha and Pereira, 2003) and information extraction from research papers (Peng and McCallum, 2004)", 
    "clean_text": "In recent years discriminative probabilistic model shave been successfully applied to a number of information extraction tasks in natural language processing (NLP), such as named entity recognition (NER) (McCallum and Li, 2003), noun phrase chunking (Sha and Pereira, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "E09-1090", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Yoshimasa, Tsuruoka | Jun'ichi, Tsujii | Sophia, Ananiadou", 
    "raw_text": "Since the task is basically identical to shallow parsing by CRFs, we follow the feature sets used in the previous work by Sha and Pereira (2003)", 
    "clean_text": "Since the task is basically identical to shallow parsing by CRFs, we follow the feature sets used in the previous work by Sha and Pereira (2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "E09-1090", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Yoshimasa, Tsuruoka | Jun'ichi, Tsujii | Sophia, Ananiadou", 
    "raw_text": "The difference between our CRFchunker and that in (Sha and Pereira, 2003) is that we could not use second-order CRF models, hence we could not use trigram features on the BIO states", 
    "clean_text": "The difference between our CRF chunker and that in (Sha and Pereira, 2003) is that we could not use second-order CRF models, hence we could not use trigram features on the BIO states.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "E09-1090", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Yoshimasa, Tsuruoka | Jun'ichi, Tsujii | Sophia, Ananiadou", 
    "raw_text": "Although not directly comparable, Sha and Pereira (2003) report almost the same level of accuracy (94.38%) on noun phrase recognition, using a much smaller training set", 
    "clean_text": "Although not directly comparable, Sha and Pereira (2003) report almost the same level of accuracy (94.38%) on noun phrase recognition, using a much smaller training set.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W10-3020", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Nobuyuki, Shimizu | Hiroshi, Nakagawa", 
    "raw_text": "To fit the weight vector w using the training set{ (xi ,yi) }ni=1, we use a standard gradient-descent method to find the weight vector that maximizes the log likelihood? n i log P (yi|xi) (Sha and Pereira, 2003)", 
    "clean_text": "we use a standard gradient-descent method to find the weight vector that maximizes the log likelihood n i log P (yi|xi) (Sha and Pereira, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "H05-1094", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Charles, Sutton | Andrew, McCallum", 
    "raw_text": "For more information on current training methods for CRFs, see Sha and Pereira (2003)", 
    "clean_text": "For more information on current training methods for CRFs, see Sha and Pereira (2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "N09-2062", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Joseph P., Turian | James, Bergstra | Yoshua, Bengio", 
    "raw_text": "NP F1 Prc Rcl F1 AZ05 94.70 94.57 94.20 94.39 KM01 94.39 93.89 93.92 93.91 I-T-W-W-O 94.44 93.72 93.91 93.81 CM03 94.41 94.19 93.29 93.74SP03 94.38- Mc03 93.96- AZ05- 93.83 93.37 93.60 ZDJ02 93.89 93.54 93.60 93.57 Table 3: Test set results for Ando and Zhang (2005), Kudo and Matsumoto (2001), our I-T-W-W-O model, Carreras and Ma`rquez (2003), Sha and Pereira (2003), McCallum (2003), Zhang et al (2002), and our best I-O model", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "N10-1128", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Chris, Dyer | Philip, Resnik", 
    "raw_text": "? i? 2The form of the objective and gradient are quite similar to the traditional fully observed training scenario for CRFs (Sha and Pereira, 2003)", 
    "clean_text": "The form of the objective and gradient are quite similar to the traditional fully observed training scenario for CRFs (Sha and Pereira, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "C08-1113", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Yuta, Tsuboi | Hisashi, Kashima | Shinsuke, Mori | Hiroki, Oda | Yuji, Matsumoto", 
    "raw_text": "Although this non-concavity prevents efficient global maximization of equation (3), it still allows us to incorporate incomplete an notations using gradient ascent iterations (Sha and Pereira, 2003)", 
    "clean_text": "Although this non-concavity prevents efficient global maximization of equation (3), it still allows us to incorporate incomplete an notations using gradient ascent iterations (Sha and Pereira, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W10-3217", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Thepchai, Supnithi | Chanon, Onman | Peerachet, Porkaew | Taneth, Ruangrajitpakorn | Kanokorn, Trakultaweekoon | Asanee, Kawtrakul", 
    "raw_text": "Chunking approach in this paper is closely similar to the work of Sha and Pereira (2003)", 
    "clean_text": "Chunking approach in this paper is closely similar to the work of Sha and Pereira (2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W10-4113", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Xingjun, Xu | Guanglu, Sun | Yi, Guan | Xishuang, Dong | Sheng, Li", 
    "raw_text": "In the field of English text chunking (Sha and Pereira, 2003), the step 1, 3, and 4 have been studied sufficiently, whereas the step 2, how to select optimal feature template subset efficiently, will be the main topic of this paper", 
    "clean_text": "In the field of English text chunking (Sha and Pereira, 2003), the step 1, 3, and 4 have been studied sufficiently, whereas the step 2, how to select optimal feature template subset efficiently, will be the main topic of this paper.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P05-1001", 
    "citing_paper_authority": 36, 
    "citing_paper_authors": "Rie Kubota, Ando | Tong, Zhang", 
    "raw_text": "Comparison with previous best results: KM01 (Kudoh and Matsumoto, 2001), CM03 (Carreras and Marquez, 2003), SP03 (Sha and Pereira, 2003), ZDJ02 (Zhang et al, 2002)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }
]
