[
  {
    "citance_No": 1, 
    "citing_paper_id": "W06-2920", 
    "citing_paper_authority": 228, 
    "citing_paper_authors": "Sabine, Buchholz | Erwin, Marsi", 
    "raw_text": "The pseudo-projective approach (Nivre and Nilsson, 2005): Transform non-projective training trees to projective ones but encode the information necessary to make the inverse transformation in the DEPREL, so that this in verse transformation can also be carried out on the test trees (Nivre et al, 2006)", 
    "clean_text": "The pseudo-projective approach (Nivre and Nilsson, 2005): Transform non-projective training trees to projective ones but encode the information necessary to make the inverse transformation in the DEPREL, so that this inverse transformation can also be carried out on the test trees (Nivre et al, 2006).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W06-2920", 
    "citing_paper_authority": 228, 
    "citing_paper_authors": "Sabine, Buchholz | Erwin, Marsi", 
    "raw_text": "Table 5 shows the official results for submitted parser outputs.31 The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006)", 
    "clean_text": "Table 5 shows the official results for submitted parser outputs. The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W06-2920", 
    "citing_paper_authority": 228, 
    "citing_paper_authors": "Sabine, Buchholz | Erwin, Marsi", 
    "raw_text": "Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences", 
    "clean_text": "Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P14-1019", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Yuan, Zhang | Tao, Lei | Regina, Barzilay | Tommi, Jaakkola | Amir, Globerson", 
    "raw_text": "Firstto Third-Order Features The feature templates of first to third-order features are mainly drawn from previous work on graph based parsing (McDonald and Pereira, 2006), transition-based parsing (Nivre et al, 2006) and dual decomposition-based parsing (Martins et al, 2011)", 
    "clean_text": "Firstto Third-Order Features The feature templates of first to third-order features are mainly drawn from previous work on graph based parsing (McDonald and Pereira, 2006), transition-based parsing (Nivre et al, 2006) and dual decomposition-based parsing (Martins et al, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P14-1019", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Yuan, Zhang | Tao, Lei | Regina, Barzilay | Tommi, Jaakkola | Amir, Globerson", 
    "raw_text": "includes the most accurate parsers among Nivre et al (2006), McDonald et al (2006), Martins et al (2010), Martins et al (2011), Martins et al (2013), Koo et al (2010), Rush and Petrov (2012), Zhang and McDonald (2012) and Zhang et al (2013)", 
    "clean_text": "includes the most accurate parsers among Nivre et al (2006), McDonald et al (2006), Martins et al (2010), Martins et al (2011), Martins et al (2013), Koo et al (2010), Rush and Petrov (2012), Zhang and McDonald (2012) and Zhang et al (2013).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "C10-1093", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Peter, Nilsson | Pierre, Nugues", 
    "raw_text": "Both methods are sometimes combined (Nivre et al, 2006b)", 
    "clean_text": "Both methods are sometimes combined (Nivre et al, 2006b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "C10-1093", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Peter, Nilsson | Pierre, Nugues", 
    "raw_text": "Neighbors We represented features with a parameter format partly inspired by MaltParser (Nivre et al, 2006a)", 
    "clean_text": "We represented features with a parameter format partly inspired by MaltParser (Nivre et al, 2006a).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "C10-1093", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Peter, Nilsson | Pierre, Nugues", 
    "raw_text": "These parameters are identical to Nivre et al (2006b) to enable a comparison of the scores. We evaluated the feature candidates on a development set using the labeled and unlabeled attachment scores (LAS and UAS) that we computed with the eval.pl script from CoNLL-X", 
    "clean_text": "These parameters are identical to Nivre et al (2006b) to enable a comparison of the scores. We evaluated the feature candidates on a development set using the labeled and unlabeled attachment scores (LAS and UAS) that we computed with the eval.pl script from CoNLL-X.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D07-1099", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Ivan, Titov | James B., Henderson", 
    "raw_text": "Following (Nivre et al, 2006), the encoding scheme called Head in (Nivre and Nilsson, 2005) was used to en code the original non-projective dependencies in the labels of the projectivized dependency tree", 
    "clean_text": "Following (Nivre et al, 2006), the encoding scheme called Head in (Nivre and Nilsson, 2005) was used to encode the original non-projective dependencies in the labels of the projectivized dependency tree.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "D07-1099", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Ivan, Titov | James B., Henderson", 
    "raw_text": "We used the base feature model defined in (Nivre et al, 2006) for all the languages but Arabic, Chinese, Czech, and Turkish", 
    "clean_text": "We used the base feature model defined in (Nivre et al, 2006) for all the languages but Arabic, Chinese, Czech, and Turkish.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "D07-1099", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Ivan, Titov | James B., Henderson", 
    "raw_text": "For Arabic, Chinese, and Czech, we used the same feature models used in the CoNLL-X 948 shared task by (Nivre et al, 2006), and for Turkish we used again the base feature model but extended it with a single feature: the part-of-speech tag of the token preceding the current top of the stack", 
    "clean_text": "For Arabic, Chinese, and Czech, we used the same feature models used in the CoNLL-X 948 shared task by (Nivre et al, 2006), and for Turkish we used again the base feature model but extended it with a single feature: the part-of-speech tag of the token preceding the current top of the stack.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W08-2104", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Lilja, &Oslash;vrelid", 
    "raw_text": "Talbanken05 is a Swedish tree bank converted to dependency format, containing both written and spoken language (Nivre et al, 2006a) .1 For each token, Talbanken05 contains information on word form, part of speech, head and dependency relation, as well as various morphosyntactic and/orlexical semantic features", 
    "clean_text": "Talbanken05 is a Swedish tree bank converted to dependency format, containing both written and spoken language (Nivre et al, 2006a). For each token, Talbanken05 contains information on word form, part of speech, head and dependency relation, as well as various morphosyntactic and/orlexical semantic features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W08-2104", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Lilja, &Oslash;vrelid", 
    "raw_text": "As our baseline, we use the settings optimized for Swedish in the CoNLL-X shared task (Nivre et al,2006b), where this parser was the best performing parser for Swedish", 
    "clean_text": "As our baseline, we use the settings optimized for Swedish in the CoNLL-X shared task (Nivre et al,2006b), where this parser was the best performing parser for Swedish.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "C10-2129", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Wolfgang, Seeker | Bernd, Bohnet | Lilja, &Oslash;vrelid | Jonas, Kuhn", 
    "raw_text": "1127ing, the graph-based and transition-based approaches, may be combined and subsequently learn to complement each other to achieve improved parsing results for different languages.MaltParser (Nivre et al, 2006) is a language independent system for data-driven dependency parsing which is freely available.7 It is based on a deterministic parsing strategy in combination with tree bank-induced classifiers for predicting parsing actions", 
    "clean_text": "MaltParser (Nivre et al, 2006) is a language independent system for data-driven dependency parsing which is freely available. It is based on a deterministic parsing strategy in combination with tree bank-induced classifiers for predicting parsing actions.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "C10-2129", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Wolfgang, Seeker | Bernd, Bohnet | Lilja, &Oslash;vrelid | Jonas, Kuhn", 
    "raw_text": "For the training of the Malt parser model that we use in the stacking experiments, we use learner and parser settings identical to the ones optimized for Ger man in the CoNLL-X shared task (Nivre et al, 2006)", 
    "clean_text": "For the training of the Malt parser model that we use in the stacking experiments, we use learner and parser settings identical to the ones optimized for German in the CoNLL-X shared task (Nivre et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W07-2034", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Yuhang, Guo | Wanxiang, Che | Yuxuan, Hu | Wei, Zhang | Ting, Liu", 
    "raw_text": "We use Nivre et al, (2006)? s dependency parser", 
    "clean_text": "We use Nivre et al, (2006)'s dependency parser.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P11-2033", 
    "citing_paper_authority": 62, 
    "citing_paper_authors": "Yue, Zhang | Joakim, Nivre", 
    "raw_text": "Uni gram label information has been used in MaltParser (Nivre et al, 2006a; Nivre, 2006)", 
    "clean_text": "Unigram label information has been used in MaltParser (Nivre et al, 2006a; Nivre, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "D12-1029", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Daniel, Fern&Atilde;&iexcl;ndez-Gonz&Atilde;&iexcl;lez | Carlos, G&oacute;mez-Rodr&iacute;guez", 
    "raw_text": "In principle, it is restricted to projective dependency forests, but it can be used in conjunction with the pseudo-projective transformation (Nivre et al2006) in order to capture a restricted subset of non projective forests", 
    "clean_text": "In principle, it is restricted to projective dependency forests, but it can be used in conjunction with the pseudo-projective transformation (Nivre et al2006) in order to capture a restricted subset of non projective forests.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "D12-1029", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Daniel, Fern&Atilde;&iexcl;ndez-Gonz&Atilde;&iexcl;lez | Carlos, G&oacute;mez-Rodr&iacute;guez", 
    "raw_text": "86.92 90.58 87.60 91.22 Swedish 82.81 88.03 84.58 89.50 Turkish 64.33 74.73 65.68 75.82 Table 4: Comparison of the parsing accuracy (LAS and UAS, excluding punctuation) of Nivre? s arc-eager parser with projective buffer transitions (NE+LBA/RBA) and the parser with the pseudo-projective transformation (Nivre et al2006) decide between both with the restricted feature in formation available for buffer nodes", 
    "clean_text": "Table 4: Comparison of the parsing accuracy (LAS and UAS, excluding punctuation) of Nivre's arc-eager parser with projective buffer transitions (NE+LBA/RBA) and the parser with the pseudo-projective transformation (Nivre et al2006) decide between both with the restricted feature in formation available for buffer nodes.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D12-1029", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Daniel, Fern&Atilde;&iexcl;ndez-Gonz&Atilde;&iexcl;lez | Carlos, G&oacute;mez-Rodr&iacute;guez", 
    "raw_text": "To further put the obtained results into context, Table 4 compares the performance of the arc-eager parser with the projective buffer transition most suit able for each dataset with the results obtained by the parser with the pseudo-projective transformation by Nivre et al2006) in the CoNLL-X shared task, one of the top two performing systems in that event", 
    "clean_text": "To further put the obtained results into context, Table 4 compares the performance of the arc-eager parser with the projective buffer transition most suitable for each dataset with the results obtained by the parser with the pseudo-projective transformation by Nivre et al2006) in the CoNLL-X shared task, one of the top two performing systems in that event.", 
    "keep_for_gold": 0
  }
]
