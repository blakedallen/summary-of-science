[
  {
    "citance_No": 1, 
    "citing_paper_id": "N07-1025", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "Rada, Mihalcea", 
    "raw_text": "is an example of a sentence in Wikipedia containing links to the articles United States ,educationalist, and Hartford, Con1In the experiments reported in this paper, we use a download from March 2006 of the English Wikipedia, with approximately 1 million articles, and more than 37 millions hyper links", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "N07-1025", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "Rada, Mihalcea", 
    "raw_text": "Finally, the grow pace of Wikipedia is much faster than other more task focused and possibly less-engaging activities such as Open Mind Word Expert, and therefore has the potential to lead to significantly higher coverage. With respect to the use of Wikipedia as a re source for natural language processing tasks, the work that is most closely related to ours is perhaps the name entity disambiguation algorithm pro posed in (Bunescu and Pasca, 2006), where an SVM kernel is trained on the entries found in Wikipediafor ambiguous named entities", 
    "clean_text": "With respect to the use of Wikipedia as a resource for natural language processing tasks, the work that is most closely related to ours is perhaps the name entity disambiguation algorithm proposed in (Bunescu and Pasca, 2006), where an SVM kernel is trained on the entries found in Wikipediafor ambiguous named entities.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "N07-1025", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "Rada, Mihalcea", 
    "raw_text": "Other language processing tasks with recently proposed solutions relying on Wikipedia are co-reference resolution using Wikipedia-based measures of word similarity (Strube and Ponzetto, 2006), enhanced text classification using encyclopedic knowledge (Gabrilovich 202and Markovitch, 2006), and the construction of com parable corpora using the multilingual editions of Wikipedia (Adafre and de Rijke, 2006)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P14-2013", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Ayman, Alhelbawy | Robert J., Gaizauskas", 
    "raw_text": "The first approach in this line was Bunescu and Pasca (2006), who measure similarity between the textual context of the NE mention and the Wikipediacategories of the candidate", 
    "clean_text": "The first approach in this line was Bunescu and Pasca (2006), who measure similarity between the textual context of the NE mention and the Wikipedia categories of the candidate.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P10-1154", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Simone Paolo, Ponzetto | Roberto, Navigli", 
    "raw_text": "However, it has been demonstrated that the amount of lexical and semantic information contained in such resources is typically insufficient for high-performance WSD (CuadrosandRigau, 2006)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P10-1154", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Simone Paolo, Ponzetto | Roberto, Navigli", 
    "raw_text": "Our proposal builds on previous insights from Bunescu and Pas? ca (2006) and Mihalcea (2007) that pages in Wikipediacanbe taken as word senses", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P09-2046", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Chau, Q. Nguyen | Tuoi, T. Phan", 
    "raw_text": "Based on the aforementioned resources of information, we follow the method presented in (Bunescu and Pasca, 2006) to build a dictionary called ViDic", 
    "clean_text": "Based on the aforementioned resources of information, we follow the method presented in (Bunescu and Pasca, 2006) to build a dictionary called ViDic.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P09-2046", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Chau, Q. Nguyen | Tuoi, T. Phan", 
    "raw_text": "In our system, we have proposed a hybrid model for the problem of Vietnamese POS Tagging (Chau and Tuoi, 2006)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P09-1047", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Jian, Huang | Sarah M., Taylor | Jonathan L., Smith | Konstantinos A., Fotiadis | C. Lee, Giles", 
    "raw_text": "The test collection consists of three sets of 10 different names, sampled from ambiguous names from English Wikipedia (famous people), participants of the ACL 2006 conference (computer scientists) and common names from the US Census data, respectively", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P09-1047", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Jian, Huang | Sarah M., Taylor | Jonathan L., Smith | Konstantinos A., Fotiadis | C. Lee, Giles", 
    "raw_text": "(Bunescu and Pasca, 2006) showed that external information from Wikipedia can improve the disambiguation performance", 
    "clean_text": "(Bunescu and Pasca, 2006) showed that external information from Wikipedia can improve the disambiguation performance.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W12-0508", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Rosa, Stern | Beno&icirc;t, Sagot | Fr&eacute;d&eacute;ric, Bechet", 
    "raw_text": "After the task of EL was initiated with Wikipedia-based works on entity disambiguation, in particular by Cucerzan (2007) and Bunescu and Pasca (2006), numerous systems have been developed, encouraged by the TAC 2009 KB population task (McNamee and Dang, 2009)", 
    "clean_text": "After the task of EL was initiated with Wikipedia-based works on entity disambiguation, in particular by Cucerzan (2007) and Bunescu and Pasca (2006), numerous systems have been developed, encouraged by the TAC 2009 KB population task (McNamee and Dang, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W12-0508", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Rosa, Stern | Beno&icirc;t, Sagot | Fr&eacute;d&eacute;ric, Bechet", 
    "raw_text": "This is addressed by various methods, such as setting a threshold of minimal similarity for an entity selection (Bunescu and Pasca, 2006), or training a separate binary classifier to judge whether the returned top candidate is the actual denotation (Zheng et al, 2010)", 
    "clean_text": "This is addressed by various methods, such as setting a threshold of minimal similarity for an entity selection (Bunescu and Pasca, 2006), or training a separate binary classifier to judge whether the returned top candidate is the actual denotation (Zheng et al, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "I08-1062", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Jessica, Ram&iacute;rez | Masayuki, Asahara | Yuji, Matsumoto", 
    "raw_text": "Strube and Ponzetto (2006) present some experiments using Wikipedia for the computing semantic relatedness of words (a measure of degree to which two concepts are related in a taxonomy measured using all semantic relations), and com pare the results with WordNet", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "I08-1062", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Jessica, Ram&iacute;rez | Masayuki, Asahara | Yuji, Matsumoto", 
    "raw_text": "files retrieved in April of 2006, and English WordNet version 2.1", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D12-1082", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Thomas, Lin | Mausam,  | Oren, Etzioni", 
    "raw_text": "A key challenge in machine reading (Etzioni et al 2006) is to identify the entities mentioned in text, and associate them with appropriate background in formation such as their type", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D12-1082", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Thomas, Lin | Mausam,  | Oren, Etzioni", 
    "raw_text": "We then employ standard entity linking techniques including string matching, prominence priors (Fader et al2009), and context matching (Bunescu and Pas? ca, 2006) to link the noun phrase subjects into Wikipedia", 
    "clean_text": "We then employ standard entity linking techniques including string matching, prominence priors (Fader et al2009), and context matching (Bunescu and Pasca, 2006) to link the noun phrase subjects into Wikipedia.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "D12-1082", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Thomas, Lin | Mausam,  | Oren, Etzioni", 
    "raw_text": "One application of this research is to increase the yield of applications such as Typed Question Answering (Buscaldi and Rosso, 2006)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "E09-1035", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Nikesh, Garera | David, Yarowsky", 
    "raw_text": "Culotta et al (2006) deal with learning contextual patterns for extracting family relation ships from Wikipedia", 
    "clean_text": "Culotta et al (2006) deal with learning contextual patterns for extracting family relation ships from Wikipedia.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "E09-1035", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Nikesh, Garera | David, Yarowsky", 
    "raw_text": "Ruiz-Casado et al (2006) learn contextual patterns for biographic facts and apply them to Wikipedia pages", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P12-1086", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Wagner, Meira Jr. | Alberto, Laender | Altigran, Soares | Adriano, Veloso | Alexandre, Davis", 
    "raw_text": "In this case, well-established classifiers, such as SVMs (Joachims, 2006), have to be learned entirely from scratch, replicating work by large", 
    "clean_text": "", 
    "keep_for_gold": 0
  }
]
