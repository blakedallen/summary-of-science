[
  {
    "citance_No": 1, 
    "citing_paper_id": "W99-0632", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Mirella, Lapata | Chris, Brew", 
    "raw_text": "We rely on Gsearch to provide moderately accurate information about verb frames in the same way that Hindle and Rooth (1993) relied on Fidditch to provide moderately accurate information about syntactic structure, and Ratnaparkhi (1998) relied on simple heuristics defined over part-of-speech tags to deliver information early as useful as that provided by Fidditch", 
    "clean_text": "We rely on Gsearch to provide moderately accurate information about verb frames in the same way that Hindle and Rooth (1993) relied on Fidditch to provide moderately accurate information about syntactic structure, and Ratnaparkhi (1998) relied on simple heuristics defined over part-of-speech tags to deliver information early as useful as that provided by Fidditch.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W06-2112", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Martin, Volk", 
    "raw_text": "(Ratnaparkhi, 1998) first assumes noun attachment for all of-PPs and then applies his disambiguation methods to all remaining PPs", 
    "clean_text": "(Ratnaparkhi, 1998) first assumes noun attachment for all of-PPs and then applies his disambiguation methods to all remaining PPs.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "H05-1035", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Marian, Olteanu | Dan, Moldovan", 
    "raw_text": "The difference in accuracy between a SVM model applied to RRR dataset (RRR-basic experiment) and the same experiment applied to TB2 dataset (TB2 278 Description Accuracy Data Extra Supervision Always noun 55.0 RRR Most likely for each P 72.19 RRR Most likely for each P 72.30 TB2 Most likely for each P 81.73 FN Average human, headwords (Ratnaparkhi et al, 1994) 88.2 RRR Average human, whole sentence (Ratnaparkhi et al, 1994) 93.2 RRR Maximum Likelihood-based (Hindle and Rooth, 1993) 79.7 AP Maximum entropy, words (Ratnaparkhi et al, 1994) 77.7 RRR Maximum entropy, words& amp; classes (Ratnaparkhi et al, 1994) 81.6 RRR Decision trees (Ratnaparkhi et al, 1994) 77.7 RRR Transformation-Based Learning (Brill and Resnik, 1994) 81.8 WordNet Maximum-Likelihood based (Collins and Brooks, 1995) 84.5 RRR Maximum-Likelihood based (Collins and Brooks, 1995) 86.1 TB2 Decision trees& amp; WSD (Stetina and Nagao, 1997) 88.1 RRR WordNet Memory-based Learning (Zavrel et al, 1997) 84.4 RRR LexSpace Maximum entropy, unsupervised (Ratnaparkhi, 1998) 81.9 Maximum entropy, supervised (Ratnaparkhi, 1998) 83.7 RRR Neural Nets (Alegre et al, 1999) 86.0 RRR WordNet Boosting (Abney et al, 1999) 84.4 RRR Semi-probabilistic (Pantel and Lin, 2000) 84.31 RRR Maximum entropy, ensemble (McLauchlan, 2001) 85.5 RRR LSA SVM (Vanschoenwinkel and Manderick, 2003) 84.8 RRR Nearest-neighbor (Zhao and Lin, 2004) 86.5 RRR DWS FN dataset ,w/o semantic features (FN-best-no-sem) 91.79 FN PR-WWW FN dataset ,w/ semantic features (FN-best-sem) 92.85 FN PR-WWW TB2 dataset, best feature set (TB2-best) 93.62 TB2 PR-WWW Table 5: Accuracy of PP-attachment ambiguity resolution (our results in bold) basic experiment) is 2.9%", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "C02-1004", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Martin, Volk", 
    "raw_text": "The most prominent unsupervised methods are the Lexical Association score by Hindle and Rooth (1993) and the co occurrence values by Ratnaparkhi (1998)", 
    "clean_text": "The most prominent unsupervised methods are the Lexical Association score by Hindle and Rooth (1993) and the co occurrence values by Ratnaparkhi (1998).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "C02-1004", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Martin, Volk", 
    "raw_text": "The co occurrence values for verb V and noun N1 correspond to the prob ability estimates in (Ratnaparkhi, 1998) except that Ratnaparkhi includes a back-off to the uniform distribution for the zero denominator case", 
    "clean_text": "The co occurrence values for verb V and noun N correspond to the probability estimates in (Ratnaparkhi, 1998) except that Ratnaparkhi includes a back-off to the uniform distribution for the zero denominator case.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P00-1014", 
    "citing_paper_authority": 19, 
    "citing_paper_authors": "Patrick, Pantel | Dekang, Lin", 
    "raw_text": "The current unsupervised state of the art achieves 81.9% attachment accuracy (Ratnaparkhi, 1998)", 
    "clean_text": "The current unsupervised state of the art achieves 81.9% attachment accuracy (Ratnaparkhi, 1998).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P00-1014", 
    "citing_paper_authority": 19, 
    "citing_paper_authors": "Patrick, Pantel | Dekang, Lin", 
    "raw_text": "As in (Ratnaparkhi, 1998), we constructed a training data set consisting of only unambiguous Table 2", 
    "clean_text": "As in (Ratnaparkhi, 1998), we constructed a training data set consisting of only unambiguous.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P00-1014", 
    "citing_paper_authority": 19, 
    "citing_paper_authors": "Patrick, Pantel | Dekang, Lin", 
    "raw_text": "We describe the different classifiers below: cl base: the baseline described in Section 7.2clR1: uses a maximum entropy model (Ratnaparkhi et al, 1994 )clBR5: uses transformation-based learning (Brill and Resnik, 1994) cl CB: uses a backed-off model (Collins and Brooks, 1995 )clSN: induces a decision tree with a sense-tagged corpus, using a semantic dictionary (Stetina and Nagao, 1997 )clHR6: uses lexical preference (Hindle and Rooth, 1993 )clR2: uses a heuristic extraction of unambiguous attachments (Ratnaparkhi, 1998) cl Pl: uses the algorithm described in this paper Our classifier outperforms all previous unsupervised techniques and approaches the performance of supervised algorithm", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P00-1014", 
    "citing_paper_authority": 19, 
    "citing_paper_authors": "Patrick, Pantel | Dekang, Lin", 
    "raw_text": "Accuracy of our reconstruction of (Hindle& amp; Rooth, 1993) and (Ratnaparkhi, 1998)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "I05-1017", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Daisuke, Kawahara | Sadao, Kurohashi", 
    "raw_text": "PP-Attachment Accuracies of Previous Work method accuracy our method SVM 87.25% supervised Ratnaphakhi et al, 1994 ME 81.6% Brill and Resnik, 1994 TBL 81.9% Collins and Brooks, 1995 back-off 84.5% Zavrel et al, 1997 NN 84.4% Stetina and Nagao, 1997 DT 88.1% Abney et al, 1999 boosting 84.6% Vanschoenwinkel and Manderick, 2003 SVM 84.8% Zhao and Lin, 2004 NN 86.5% unsupervised Ratnaparkhi, 1998 81.9% Pantel and Lin, 2000 84.3% ME: Maximum Entropy, TBL: Transformation-Based Learning, DT: Decision Tree, NN: Nearest Neighbor configurations (McNemar? s test; p &lt; 0.05)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "H05-1105", 
    "citing_paper_authority": 19, 
    "citing_paper_authors": "Preslav, Nakov | Marti A., Hearst", 
    "raw_text": "More recently, Ratnaparkhi (1998) developed an unsupervised method that collects statistics from text annotated with part-of-speech tags and morphological base forms", 
    "clean_text": "More recently, Ratnaparkhi (1998) developed an unsupervised method that collects statistics from text annotated with part-of-speech tags and morphological base forms.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "H05-1105", 
    "citing_paper_authority": 19, 
    "citing_paper_authors": "Preslav, Nakov | Marti A., Hearst", 
    "raw_text": "A test for statistical significance reveals that our results are as strong as those of the leading unsuper 3Ratnaparkhi (1998) notes that the test set contains errors, but does not correct them", 
    "clean_text": "Ratnaparkhi (1998) notes that the test set contains errors, but does not correct them.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "H05-1105", 
    "citing_paper_authority": 19, 
    "citing_paper_authors": "Preslav, Nakov | Marti A., Hearst", 
    "raw_text": "Using an adaptation of the algorithm proposed by Ratnaparkhi (1998) for PP-attachment, she achieves P=72% (baseline P=64%), R=100.00% .Agarwal and Boggess (1992) focus on the identification of the conjuncts of coordinate conjunctions. Using POS and case labels in a deterministic algorithm, they achieve P=81.6%", 
    "clean_text": "Using an adaptation of the algorithm proposed by Ratnaparkhi (1998) for PP-attachment, she achieves P=72% (baseline P=64%), R=100.00%.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W01-0707", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Eric, Gaussier | Nicola, Cancedda", 
    "raw_text": "A second model relevant to our discussion is the one proposed in (Ratnaparkhi,1998), addressing the problem of unsupervised learning for PP attachment resolution in VERB NOUN PP sequences", 
    "clean_text": "A second model relevant to our discussion is the one proposed in (Ratnaparkhi,1998), addressing the problem of unsupervised learning for PP attachment resolution in VERB NOUN PP sequences.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W01-0707", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Eric, Gaussier | Nicola, Cancedda", 
    "raw_text": "We thus can view our model as a generalization of model L since we can handle PP attachment and take into account indirect independencies. The model proposed in (Ratnaparkhi, 1998) is similar to a version of our model based solely on equation (9), with no semantic information", 
    "clean_text": "The model proposed in (Ratnaparkhi, 1998) is similar to a version of our model based solely on equation (9), with no semantic information.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W01-0707", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Eric, Gaussier | Nicola, Cancedda", 
    "raw_text": "In fact, by adding to the set of prepositions an empty preposition, e, the counts of which are estimated from unsafe configurations (that is J\u0013\u00055fgQ1HUh \u0006\u0015jilk\u0013mSn\u0002k J\u0013\u00054f &apos; Q\u0013HUhU\u0010\u0007\u001aIHUQ; \u001a \u0006& amp; o J\u0013\u00055fgQ1HUhU\u0010pe\u0006), equation (9) captures both the contribution from the random variable used in (Ratnaparkhi, 1998) to denote the presence or absence of any preposition that is unambiguously attached to the noun or the verb in question, and the contribution from the conditional probability that a particular preposition will occur as unambiguous attachment to the verb or to the noun", 
    "clean_text": "equation (9) captures both the contribution from the random variable used in (Ratnaparkhi, 1998) to denote the presence or absence of any preposition that is unambiguously attached to the noun or the verb in question, and the contribution from the conditional probability that a particular preposition will occur as unambiguous attachment to the verb or to the noun.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P06-2029", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Kilian A., Foth | Wolfgang, Menzel", 
    "raw_text": "(Ratnaparkhi, 1998) solved this problem by regarding only prepositions in syntactically unambiguous configurations", 
    "clean_text": "(Ratnaparkhi, 1998) solved this problem by regarding only prepositions in syntactically unambiguous configurations.", 
    "keep_for_gold": 0
  }
]
