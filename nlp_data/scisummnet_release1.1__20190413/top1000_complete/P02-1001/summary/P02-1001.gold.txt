Parameter Estimation For Probabilistic Finite-State Transducers
Weighted finite-state transducers suffer from the lack of a training algorithm.
Training is even harder for transducers that have been assembled via finite-state operations such as composition, minimization, union, concatenation, and closure, as this yields tricky parameter tying.
We formulate a “parameterized FST” paradigm and give training algorithms for it, including a general bookkeeping trick (“expectation semirings”) that cleanly and efficiently computes expectations and gradients.
We use finite-state operations such as composition, which do combine weights entirely within the expectation semiring before their result is passed to the forward-backward algorithm.
We claim that parsing under an expectation semiring is equivalent to the Inside-Outside algorithm for PCFGs.
We give a general EM algorithm for parameter estimation in probabilistic finite-state transducers.
We describe the expectation semiring for parameter learning.
