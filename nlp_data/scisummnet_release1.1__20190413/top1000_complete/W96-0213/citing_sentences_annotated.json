[
  {
    "citance_No": 1, 
    "citing_paper_id": "W96-0111", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "Ratnaparkhi, 1996), a single inconsistency in a test set tree will very likely yield a zero percent parse accuracy for the particular test set sentence", 
    "clean_text": "Since the raw Penn Treebank data contains many inconsistencies in its annotations (cf. Ratnaparkhi, 1996), a single inconsistency in a test set tree will very likely yield a zero percent parse accuracy for the particular test set sentence.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-2131", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Mohit, Bansal | Kevin, Gimpel | Karen, Livescu", 
    "raw_text": "10For both tree banks, we convert from constituent to dependency format using pennconverter (Johansson and Nugues, 2007), and generate POS tags using the MXPOST tagger (Ratnaparkhi, 1996)", 
    "clean_text": "For both tree banks, we convert from constituent to dependency format using pennconverter (Johansson and Nugues, 2007), and generate POS tags using the MXPOST tagger (Ratnaparkhi, 1996).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W00-1308", 
    "citing_paper_authority": 61, 
    "citing_paper_authors": "Kristina, Toutanova | Christopher D., Manning", 
    "raw_text": "We started with a maximum entropy based tagger that uses features very similar to the ones proposed in Ratnaparkhi (1996)", 
    "clean_text": "We started with a maximum entropy based tagger that uses features very similar to the ones proposed in Ratnaparkhi (1996).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W00-1308", 
    "citing_paper_authority": 61, 
    "citing_paper_authors": "Kristina, Toutanova | Christopher D., Manning", 
    "raw_text": "Ratnaparkhi (1996: 134) suggests use of an approximation summing over the training data, which does not sum over possible tags:& quot; h E f j= 2 P (~) p (ti lhi) f j (hi, ti )i=1 However, we believe this passage is in error: such an estimate is ineffective in the iterative scaling algorithm", 
    "clean_text": "Ratnaparkhi (1996: 134) suggests use of an approximation summing over the training data, which does not sum over possible tags:& quot; h E f j= 2 P (~) p (ti lhi) f j (hi, ti )i=1 However, we believe this passage is in error: such an estimate is ineffective in the iterative scaling algorithm.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W00-1308", 
    "citing_paper_authority": 61, 
    "citing_paper_authors": "Kristina, Toutanova | Christopher D., Manning", 
    "raw_text": "The features that define the constraints on the model are obtained by instantiation of feature templates as in Ratnaparkhi (1996)", 
    "clean_text": "The features that define the constraints on the model are obtained by instantiation of feature templates as in Ratnaparkhi (1996).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W00-1308", 
    "citing_paper_authority": 61, 
    "citing_paper_authors": "Kristina, Toutanova | Christopher D., Manning", 
    "raw_text": "They are a subset of the features used in Ratnaparkhi (1996)", 
    "clean_text": "They are a subset of the features used in Ratnaparkhi (1996).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W00-1308", 
    "citing_paper_authority": 61, 
    "citing_paper_authors": "Kristina, Toutanova | Christopher D., Manning", 
    "raw_text": "The feature templates in Ratnaparkhi (1996) that were left out were the ones that look at the previous word, the word two positions before the current, and the word two positions after the current", 
    "clean_text": "The feature templates in Ratnaparkhi (1996) that were left out were the ones that look at the previous word, the word two positions before the current, and the word two positions after the current.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W00-1308", 
    "citing_paper_authority": 61, 
    "citing_paper_authors": "Kristina, Toutanova | Christopher D., Manning", 
    "raw_text": "Model Overall Unknown Word Accuracy Accuracy Baseline, 96.72% 84.5% J Ratnaparkhi 96.63% 85.56% (1996) Table 3 Baseline model performance This table also shows the results reported in Ratnaparkhi (1996: 142) for COnvenience", 
    "clean_text": "Model Overall Unknown Word Accuracy Accuracy Baseline, 96.72% 84.5% J Ratnaparkhi 96.63% 85.56% (1996) Table 3 Baseline model performance This table also shows the results reported in Ratnaparkhi (1996: 142) for Convenience.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W00-1308", 
    "citing_paper_authority": 61, 
    "citing_paper_authors": "Kristina, Toutanova | Christopher D., Manning", 
    "raw_text": "This may stem from the differences between the two models &apos; feature templates, thresholds, and approximations of the expected values for the features, as discussed in the beginning of the section, or may just reflect differences in the choice of training and test sets (which are not precisely specified in Ratnaparkhi (1996))", 
    "clean_text": "This may stem from the differences between the two models &apos; feature templates, thresholds, and approximations of the expected values for the features, as discussed in the beginning of the section, or may just reflect differences in the choice of training and test sets (which are not precisely specified in Ratnaparkhi (1996)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W00-1308", 
    "citing_paper_authority": 61, 
    "citing_paper_authors": "Kristina, Toutanova | Christopher D., Manning", 
    "raw_text": "One conclusion that we can draw is that at present he additional word features used in Ratnaparkhi (1996) looking at words more than one position away from the current do not appear to be helping the overall performance of the models", 
    "clean_text": "One conclusion that we can draw is that at present the additional word features used in Ratnaparkhi (1996) looking at words more than one position away from the current do not appear to be helping the overall performance of the models.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W00-1308", 
    "citing_paper_authority": 61, 
    "citing_paper_authors": "Kristina, Toutanova | Christopher D., Manning", 
    "raw_text": "Some are the result of inconsistency in labeling in the training data (Ratnaparkhi 1996), which usually reflects a lack of linguistic clarity or determination of the correct part of speech in context", 
    "clean_text": "Some are the result of inconsistency in labeling in the training data (Ratnaparkhi 1996), which usually reflects a lack of linguistic clarity or determination of the correct part of speech in context.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P07-1104", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Jianfeng, Gao | Galen, Andrew | Mark, Johnson | Kristina, Toutanova", 
    "raw_text": "Followingprevious work (Ratnaparkhi, 1996), we assume that the tag of a word is independent of the tags of all preceding words given the tags of the previous two words (i.e.,? =2 in the equation above)", 
    "clean_text": "Following previous work (Ratnaparkhi, 1996), we assume that the tag of a word is independent of the tags of all preceding words given the tags of the previous two words (i.e.,? =2 in the equation above).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "E12-1050", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Georgi, Georgiev | Valentin, Zhikov | Kiril, Simov | Petya, Osenova | Preslav, Nakov", 
    "raw_text": "A number of different sequential learning frameworks have been tried, yielding 96-97% accuracy: Lafferty et al (2001) experimented with conditional random fields (CRFs) (95.7% accuracy), Ratnaparkhi (1996) used a maximum entropy sequence classifier (96.6% accuracy), Brants (2000) employed a hidden Markov model (96.6% accuracy), Collins (2002) adopted an averaged perception discriminative sequence model (97.1% accuracy)", 
    "clean_text": "A number of different sequential learning frameworks have been tried, yielding 96-97% accuracy: Lafferty et al (2001) experimented with conditional random fields (CRFs) (95.7% accuracy), Ratnaparkhi (1996) used a maximum entropy sequence classifier (96.6% accuracy), Brants (2000) employed a hidden Markov model (96.6% accuracy), Collins (2002) adopted an averaged perception discriminative sequence model (97.1% accuracy).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "E12-1050", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Georgi, Georgiev | Valentin, Zhikov | Kiril, Simov | Petya, Osenova | Preslav, Nakov", 
    "raw_text": "Feature templates as in (Ratnaparkhi, 1996),", 
    "clean_text": "Feature templates as in (Ratnaparkhi, 1996),.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "N03-2027", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Leonid, Peshkin | Avi, Pfeffer | Virginia, Savova", 
    "raw_text": "The best result known to us is achieved by Toutanova [2002] by enriching the feature representation of the MaxEnt approach [Ratnaparkhi, 1996]", 
    "clean_text": "The best result known to us is achieved by Toutanova [2002] by enriching the feature representation of the MaxEnt approach [Ratnaparkhi, 1996].", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W03-0806", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "James R., Curran", 
    "raw_text": "For instance, implementing an efficient version of the MXPOST POS tagger (Ratnaparkhi, 1996) will simply involve composing and configuring the appropriate text file reading component, with the sequential tagging component, the collection of feature extraction components and the maximum entropy model component", 
    "clean_text": "For instance, implementing an efficient version of the MXPOST POS tagger (Ratnaparkhi, 1996) will simply involve composing and configuring the appropriate text file reading component, with the sequential tagging component, the collection of feature extraction components and the maximum entropy model component.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "I08-4024", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Ka Seng, Leong | Fai, Wong | Yi-Ping, Li | Ming-Chui, Dong", 
    "raw_text": "In this bakeoff, our basic model is based on the framework described in the work of Ratnaparkhi (1996) which was applied for English POS tagging", 
    "clean_text": "In this bakeoff, our basic model is based on the framework described in the work of Ratnaparkhi (1996) which was applied for English POS tagging.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P02-1042", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Stephen, Clark | Julia, Hockenmaier | Mark, Steedman", 
    "raw_text": "Wehave explained elsewhere (Clark, 2002) how suit able features can be defined in terms of the \u0012 word ,pos-tag \u0014pairs in the context, and how maximum entropy techniques can be used to estimate the probabilities, following Ratnaparkhi (1996) .We assume that each argument slot in the category sequence is filled independently, and write P \u0002 D& quot; C \u0013 S \u0004 as follows: (9) P \u0002 D& quot; C \u0013 S \u0004% fl? mi (1 P \u0002hai& quot; C \u0013 S \u0004 where hai is the head word filling the argument slot of the ith dependency, and m is the number of dependencies entailed by the category sequence C. 3.1 Estimating the dependency probabilities", 
    "clean_text": "We have explained elsewhere (Clark, 2002) how suitable features can be defined in terms of the \u0012 word ,pos-tag \u0014pairs in the context, and how maximum entropy techniques can be used to estimate the probabilities, following Ratnaparkhi (1996).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "H05-1107", 
    "citing_paper_authority": 14, 
    "citing_paper_authors": "Chenhai, Xi | Rebecca, Hwa", 
    "raw_text": "Given the parallel corpus, we tagged the English words with a publicly available maximum entropy tagger (Ratnaparkhi, 1996), and we used an implementation of the IBM translation model (Al Onaizan et al, 1999) to align the words", 
    "clean_text": "Given the parallel corpus, we tagged the English words with a publicly available maximum entropy tagger (Ratnaparkhi, 1996), and we used an implementation of the IBM translation model (Al Onaizan et al, 1999) to align the words.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P10-1036", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Jonathan K., Kummerfeld | Jessika, Roesner | Tim, Dawborn | James, Haggerty | James R., Curran | Stephen, Clark", 
    "raw_text": "The C& amp; C super tagger is similar to the Ratnaparkhi (1996) tagger, using features based on words and POS tags in a five-word window surrounding the target word, and defining a local probability distribution over super tags for each word in the sentence, given the previous two super tags", 
    "clean_text": "The C&C supertagger is similar to the Ratnaparkhi (1996) tagger, using features based on words and POS tags in a five-word window surrounding the target word, and defining a local probability distribution over supertags for each word in the sentence, given the previous two super tags.", 
    "keep_for_gold": 0
  }
]
