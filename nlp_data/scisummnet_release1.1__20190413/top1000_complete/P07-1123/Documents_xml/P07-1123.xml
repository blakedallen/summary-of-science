<PAPER>
  <S sid="0">Learning Multilingual Subjective Language via Cross-Lingual Projections</S>
  <ABSTRACT>
    <S sid="1" ssid="1">This paper explores methods for generating subjectivity analysis resources in a new language by leveraging on the tools and resources available in English.</S>
    <S sid="2" ssid="2">Given a bridge between English and the selected target language (e.g., a bilingual dictionary or a parallel corpus), the methods can be used to rapidly create tools for subjectivity analysis in the new language.</S>
  </ABSTRACT>
  <SECTION title="1 Introduction" number="1">
    <S sid="3" ssid="1">There is growing interest in the automatic extraction of opinions, emotions, and sentiments in text (subjectivity), to provide tools and support for various natural language processing applications.</S>
    <S sid="4" ssid="2">Most of the research to date has focused on English, which is mainly explained by the availability of resources for subjectivity analysis, such as lexicons and manually labeled corpora.</S>
    <S sid="5" ssid="3">In this paper, we investigate methods to automatically generate resources for subjectivity analysis for a new target language by leveraging on the resources and tools available for English, which in many cases took years of work to complete.</S>
    <S sid="6" ssid="4">Specifically, through experiments with cross-lingual projection of subjectivity, we seek answers to the following questions.</S>
    <S sid="7" ssid="5">First, can we derive a subjectivity lexicon for a new language using an existing English subjectivity lexicon and a bilingual dictionary?</S>
    <S sid="8" ssid="6">Second, can we derive subjectivity-annotated corpora in a new language using existing subjectivity analysis tools for English and a parallel corpus?</S>
    <S sid="9" ssid="7">Finally, third, can we build tools for subjectivity analysis for a new target language by relying on these automatically generated resources?</S>
    <S sid="10" ssid="8">We focus our experiments on Romanian, selected as a representative of the large number of languages that have only limited text processing resources developed to date.</S>
    <S sid="11" ssid="9">Note that, although we work with Romanian, the methods described are applicable to any other language, as in these experiments we (purposely) do not use any language-specific knowledge of the target language.</S>
    <S sid="12" ssid="10">Given a bridge between English and the selected target language (e.g., a bilingual dictionary or a parallel corpus), the methods can be applied to other languages as well.</S>
    <S sid="13" ssid="11">After providing motivations, we present two approaches to developing sentence-level subjectivity classifiers for a new target language.</S>
    <S sid="14" ssid="12">The first uses a subjectivity lexicon translated from an English one.</S>
    <S sid="15" ssid="13">The second uses an English subjectivity classifier and a parallel corpus to create target-language training data for developing a statistical classifier.</S>
  </SECTION>
  <SECTION title="2 Motivation" number="2">
    <S sid="16" ssid="1">Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al., 2005; Balog et al., 2006), review classification (Turney, 2002; Pang et al., 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al., 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003).</S>
    <S sid="17" ssid="2">While much recent work in subjectivity analysis focuses on sentiment (a type of subjectivity, namely positive and negative emotions, evaluations, and judgments), we opt to focus on recognizing subjectivity in general, for two reasons.</S>
    <S sid="18" ssid="3">First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005; Kim and Hovy, 2006).</S>
    <S sid="19" ssid="4">In fact, the problem of distinguishing subjective versus objective instances has often proved to be more difficult than subsequent polarity classification, so improvements in subjectivity classification promise to positively impact sentiment classification.</S>
    <S sid="20" ssid="5">This is reported in studies of manual annotation of phrases (Takamura et al., 2006), recognizing contextual polarity of expressions (Wilson et al., 2005), and sentiment tagging of words and word senses (Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2006).</S>
    <S sid="21" ssid="6">Second, an NLP application may seek a wide range of types of subjectivity attributed to a person, such as their motivations, thoughts, and speculations, in addition to their positive and negative sentiments.</S>
    <S sid="22" ssid="7">For instance, the opinion tracking system Lydia (Lloyd et al., 2005) gives separate ratings for subjectivity and sentiment.</S>
    <S sid="23" ssid="8">These can be detected with subjectivity analysis but not by a method focused only on sentiment.</S>
    <S sid="24" ssid="9">There is world-wide interest in text analysis applications.</S>
    <S sid="25" ssid="10">While work on subjectivity analysis in other languages is growing (e.g., Japanese data are used in (Takamura et al., 2006; Kanayama and Nasukawa, 2006), Chinese data are used in (Hu et al., 2005), and German data are used in (Kim and Hovy, 2006)), much of the work in subjectivity analysis has been applied to English data.</S>
    <S sid="26" ssid="11">Creating corpora and lexical resources for a new language is very time consuming.</S>
    <S sid="27" ssid="12">In general, we would like to leverage resources already developed for one language to more rapidly create subjectivity analysis tools for a new one.</S>
    <S sid="28" ssid="13">This motivates our exploration and use of cross-lingual lexicon translations and annotation projections.</S>
    <S sid="29" ssid="14">Most if not all work on subjectivity analysis has been carried out in a monolingual framework.</S>
    <S sid="30" ssid="15">We are not aware of multi-lingual work in subjectivity analysis such as that proposed here, in which subjectivity analysis resources developed for one language are used to support developing resources in another.</S>
  </SECTION>
  <SECTION title="3 A Lexicon-Based Approach" number="3">
    <S sid="31" ssid="1">Many subjectivity and sentiment analysis tools rely on manually or semi-automatically constructed lexicons (Yu and Hatzivassiloglou, 2003; Riloff and Wiebe, 2003; Kim and Hovy, 2006).</S>
    <S sid="32" ssid="2">Given the success of such techniques, the first approach we take to generating a target-language subjectivity classifier is to create a subjectivity lexicon by translating an existing source language lexicon, and then build a classifier that relies on the resulting lexicon.</S>
    <S sid="33" ssid="3">Below, we describe the translation process and discuss the results of an annotation study to assess the quality of the translated lexicon.</S>
    <S sid="34" ssid="4">We then describe and evaluate a lexicon-based target-language classifier.</S>
    <S sid="35" ssid="5">The subjectivity lexicon we use is from OpinionFinder (Wiebe and Riloff, 2005), an English subjectivity analysis system which, among other things, classifies sentences as subjective or objective.</S>
    <S sid="36" ssid="6">The lexicon was compiled from manually developed resources augmented with entries learned from corpora.</S>
    <S sid="37" ssid="7">It contains 6,856 unique entries, out of which 990 are multi-word expressions.</S>
    <S sid="38" ssid="8">The entries in the lexicon have been labeled for part of speech, and for reliability &#8211; those that appear most often in subjective contexts are strong clues of subjectivity, while those that appear less often, but still more often than expected by chance, are labeled weak.</S>
    <S sid="39" ssid="9">To perform the translation, we use two bilingual dictionaries.</S>
    <S sid="40" ssid="10">The first is an authoritative EnglishRomanian dictionary, consisting of 41,500 entries,1 which we use as the main translation resource for the lexicon translation.</S>
    <S sid="41" ssid="11">The second dictionary, drawn from the Universal Dictionary download site (UDP, 2007) consists of 4,500 entries written largely by Web volunteer contributors, and thus is not error free.</S>
    <S sid="42" ssid="12">We use this dictionary only for those entries that do not appear in the main dictionary.</S>
    <S sid="43" ssid="13">There were several challenges encountered in the translation process.</S>
    <S sid="44" ssid="14">First, although the English subjectivity lexicon contains inflected words, we must use the lemmatized form in order to be able to translate the entries using the bilingual dictionary.</S>
    <S sid="45" ssid="15">However, words may lose their subjective meaning once lemmatized.</S>
    <S sid="46" ssid="16">For instance, the inflected form of memories becomes memory.</S>
    <S sid="47" ssid="17">Once translated into Romanian (as memorie), its main meaning is objective, referring to the power of retaining information as in Iron supplements may improve a woman&#8217;s memory.</S>
    <S sid="48" ssid="18">Second, neither the lexicon nor the bilingual dictionary provides information on the sense of the individual entries, and therefore the translation has to rely on the most probable sense in the target language.</S>
    <S sid="49" ssid="19">Fortunately, the bilingual dictionary lists the translations in reverse order of their usage frequencies.</S>
    <S sid="50" ssid="20">Nonetheless, the ambiguity of the words and the translations still seems to represent an important source of error.</S>
    <S sid="51" ssid="21">Moreover, the lexicon sometimes includes identical entries expressed through different parts of speech, e.g., grudge has two separate entries, for its noun and verb roles, respectively.</S>
    <S sid="52" ssid="22">On the other hand, the bilingual dictionary does not make this distinction, and therefore we have again to rely on the &#8220;most frequent&#8221; heuristic captured by the translation order in the bilingual dictionary.</S>
    <S sid="53" ssid="23">Finally, the lexicon includes a significant number (990) of multi-word expressions that pose translation difficulties, sometimes because their meaning is idiomatic, and sometimes because the multi-word expression is not listed in the bilingual dictionary and the translation of the entire phrase is difficult to reconstruct from the translations of the individual words.</S>
    <S sid="54" ssid="24">To address this problem, when a translation is not found in the dictionary, we create one using a word-by-word approach.</S>
    <S sid="55" ssid="25">These translations are then validated by enforcing that they occur at least three times on the Web, using counts collected from the AltaVista search engine.</S>
    <S sid="56" ssid="26">The multi-word expressions that are not validated in this process are discarded, reducing the number of expressions from an initial set of 990 to a final set of 264.</S>
    <S sid="57" ssid="27">The final subjectivity lexicon in Romanian contains 4,983 entries.</S>
    <S sid="58" ssid="28">Table 1 shows examples of entries in the Romanian lexicon, together with their corresponding original English form.</S>
    <S sid="59" ssid="29">The table also shows the reliability of the expression (weak or strong) and the part of speech &#8211; attributes that are provided in the English subjectivity lexicon.</S>
    <S sid="60" ssid="30">We want to assess the quality of the translated lexicon, and compare it to the quality of the original English lexicon.</S>
    <S sid="61" ssid="31">The English subjectivity lexicon was evaluated in (Wiebe and Riloff, 2005) against a corpus of English-language news articles manually annotated for subjectivity (the MPQA corpus (Wiebe et al., 2005)).</S>
    <S sid="62" ssid="32">According to this evaluation, 85% of the instances of the clues marked as strong and 71.5% of the clues marked as weak are in subjective sentences in the MPQA corpus.</S>
    <S sid="63" ssid="33">Since there is no comparable Romanian corpus, an alternate way to judge the subjectivity of a Romanian lexicon entry is needed.</S>
    <S sid="64" ssid="34">Two native speakers of Romanian annotated the subjectivity of 150 randomly selected entries.</S>
    <S sid="65" ssid="35">Each annotator independently read approximately 100 examples of each drawn from the Web, including a large number from news sources.</S>
    <S sid="66" ssid="36">The subjectivity of a word was consequently judged in the contexts where it most frequently appears, accounting for its most frequent meanings on the Web.</S>
    <S sid="67" ssid="37">The tagset used for the annotations consists of S(ubjective), O(bjective), and B(oth).</S>
    <S sid="68" ssid="38">A W(rong) label is also used to indicate a wrong translation.</S>
    <S sid="69" ssid="39">Table 2 shows the contingency table for the two annotators&#8217; judgments on this data.</S>
    <S sid="70" ssid="40">Without counting the wrong translations, the agreement is measured at 0.80, with a Kappa &#954; = 0.70, which indicates consistent agreement.</S>
    <S sid="71" ssid="41">After the disagreements were reconciled through discussions, the final set of 123 correctly translated entries does include 49.6% (61) subjective entries, but fully 23.6% (29) were found in the study to have primarily objective uses (the other 26.8% are mixed).</S>
    <S sid="72" ssid="42">Thus, this study suggests that the Romanian subjectivity clues derived through translation are less reliable than the original set of English clues.</S>
    <S sid="73" ssid="43">In several cases, the subjectivity is lost in the translation, mainly due to word ambiguity in either the source or target language, or both.</S>
    <S sid="74" ssid="44">For instance, the word fragile correctly translates into Romanian as fragil, yet this word is frequently used to refer to breakable objects, and it loses its subjective meaning of delicate.</S>
    <S sid="75" ssid="45">Other words, such as one-sided, completely lose subjectivity once translated, as it becomes in Romanian cu o singura latur&#728;a, meaning with only one side (as of objects).</S>
    <S sid="76" ssid="46">Interestingly, the reliability of clues in the English lexicon seems to help preserve subjectivity.</S>
    <S sid="77" ssid="47">Out of the 77 entries marked as strong, 11 were judged to be objective in Romanian (14.3%), compared to 14 objective Romanian entries obtained from the 36 weak English clues (39.0%).</S>
    <S sid="78" ssid="48">Starting with the Romanian lexicon, we developed a lexical classifier similar to the one introduced by (Riloff and Wiebe, 2003).</S>
    <S sid="79" ssid="49">At the core of this method is a high-precision subjectivity and objectivity classifier that can label large amounts of raw text using only a subjectivity lexicon.</S>
    <S sid="80" ssid="50">Their method is further improved with a bootstrapping process that learns extraction patterns.</S>
    <S sid="81" ssid="51">In our experiments, however, we apply only the rule-based classification step, since the extraction step cannot be implemented without tools for syntactic parsing and information extraction not available in Romanian.</S>
    <S sid="82" ssid="52">The classifier relies on three main heuristics to label subjective and objective sentences: (1) if two or more strong subjective expressions occur in the same sentence, the sentence is labeled Subjective; (2) if no strong subjective expressions occur in a sentence, and at most two weak subjective expressions occur in the previous, current, and next sentence combined, then the sentence is labeled Objective; (3) otherwise, if none of the previous rules apply, the sentence is labeled Unknown.</S>
    <S sid="83" ssid="53">The quality of the classifier was evaluated on a Romanian gold-standard corpus annotated for subjectivity.</S>
    <S sid="84" ssid="54">Two native Romanian speakers (Rol and Roe) manually annotated the subjectivity of the sentences of five randomly selected documents (504 sentences) from the Romanian side of an EnglishRomanian parallel corpus, according to the annotation scheme in (Wiebe et al., 2005).</S>
    <S sid="85" ssid="55">Agreement between annotators was measured, and then their differences were adjudicated.</S>
    <S sid="86" ssid="56">The baseline on this data set is 54.16%, which can be obtained by assigning a default Subjective label to all sentences.</S>
    <S sid="87" ssid="57">(More information about the corpus and annotations are given in Section 4 below, where agreement between English and Romanian aligned sentences is also assessed.)</S>
    <S sid="88" ssid="58">As mentioned earlier, due to the lexicon projection process that is performed via a bilingual dictionary, the entries in our Romanian subjectivity lexicon are in a lemmatized form.</S>
    <S sid="89" ssid="59">Consequently, we also lemmatize the gold-standard corpus, to allow for the identification of matches with the lexicon.</S>
    <S sid="90" ssid="60">For this purpose, we use the Romanian lemmatizer developed by Ion and Tufis&#184; (Ion, 2007), which has an estimated accuracy of 98%.2 Table 3 shows the results of the rule-based classifier.</S>
    <S sid="91" ssid="61">We show the precision, recall, and F-measure independently measured for the subjective, objective, and all sentences.</S>
    <S sid="92" ssid="62">We also evaluated a variation of the rule-based classifier that labels a sentence as objective if there are at most three weak expressions in the previous, current, and next sentence combined, which raises the recall of the objective classifier.</S>
    <S sid="93" ssid="63">Our attempts to increase the recall of the subjective classifier all resulted in significant loss in precision, and thus we kept the original heuristic.</S>
    <S sid="94" ssid="64">In its original English implementation, this system was proposed as being high-precision but low coverage.</S>
    <S sid="95" ssid="65">Evaluated on the MPQA corpus, it has subjective precision of 90.4, subjective recall of 34.2, objective precision of 82.4, and objective recall of 30.7; overall, precision is 86.7 and recall is 32.6 (Wiebe and Riloff, 2005).</S>
    <S sid="96" ssid="66">We see a similar behavior on Romanian for subjective sentences.</S>
    <S sid="97" ssid="67">The subjective precision is good, albeit at the cost of low recall, and thus the classifier could be used to harvest subjective sentences from unlabeled Romanian data (e.g., for a subsequent bootstrapping process).</S>
    <S sid="98" ssid="68">The system is not very effective for objective classification, however.</S>
    <S sid="99" ssid="69">Recall that the objective classifier relies on the weak subjectivity clues, for which the transfer of subjectivity in the translation process was particularly low.</S>
  </SECTION>
  <SECTION title="4 A Corpus-Based Approach" number="4">
    <S sid="100" ssid="1">Given the low number of subjective entries found in the automatically generated lexicon and the subsequent low recall of the lexical classifier, we decided to also explore a second, corpus-based approach.</S>
    <S sid="101" ssid="2">This approach builds a subjectivity-annotated corpus for the target language through projection, and then trains a statistical classifier on the resulting corpus (numerous statistical classifiers have been trained for subjectivity or sentiment classification, e.g., (Pang et al., 2002; Yu and Hatzivassiloglou, 2003)).</S>
    <S sid="102" ssid="3">The hypothesis is that we can eliminate some of the ambiguities (and consequent loss of subjectivity) observed during the lexicon translation by accounting for the context of the ambiguous words, which is possible in a corpus-based approach.</S>
    <S sid="103" ssid="4">Additionally, we also hope to improve the recall of the classifier, by addressing those cases not covered by the lexicon-based approach.</S>
    <S sid="104" ssid="5">In the experiments reported in this section, we use a parallel corpus consisting of 107 documents from the SemCor corpus (Miller et al., 1993) and their manual translations into Romanian.3 The corpus consists of roughly 11,000 sentences, with approximately 250,000 tokens on each side.</S>
    <S sid="105" ssid="6">It is a balanced corpus covering a number of topics in sports, politics, fashion, education, and others.</S>
    <S sid="106" ssid="7">3The translation was carried out by a Romanian native speaker, student in a department of &#8220;Foreign Languages and Translations&#8221; in Romania.</S>
    <S sid="107" ssid="8">Below, we begin with a manual annotation study to assess the quality of annotation and preservation of subjectivity in translation.</S>
    <S sid="108" ssid="9">We then describe the automatic construction of a target-language training set, and evaluate a classifier trained on that data.</S>
    <S sid="109" ssid="10">Annotation Study.</S>
    <S sid="110" ssid="11">We start by performing an agreement study meant to determine the extent to which subjectivity is preserved by the cross-lingual projections.</S>
    <S sid="111" ssid="12">In the study, three annotators &#8211; one native English speaker (En) and two native Romanian speakers (Ro1 and Ro2) &#8211; first trained on 3 randomly selected documents (331 sentences).</S>
    <S sid="112" ssid="13">They then independently annotated the subjectivity of the sentences of two randomly selected documents from the parallel corpus, accounting for 173 aligned sentence pairs.</S>
    <S sid="113" ssid="14">The annotators had access exclusively to the version of the sentences in their language, to avoid any bias that could be introduced by seeing the translation in the other language.</S>
    <S sid="114" ssid="15">Note that the Romanian annotations (after all differences between the Romanian annotators were adjudicated) of all 331 + 173 sentences make up the gold standard corpus used in the experiments reported in Sections 3.2 and 4.1.</S>
    <S sid="115" ssid="16">Before presenting the results of the annotation study, we give some examples.</S>
    <S sid="116" ssid="17">The following are English subjective sentences and their Romanian translations (the subjective elements are shown in bold).</S>
    <S sid="117" ssid="18">[en] The desire to give Broglio as many starts as possible.</S>
    <S sid="118" ssid="19">[ro] Dorint&#184;a de a-i da lui Broglio c&#710;at mai multe starturi posibile.</S>
    <S sid="119" ssid="20">[en] Suppose he did lie beside Lenin, would it be permanent ?</S>
    <S sid="120" ssid="21">[ro] S&#728;a presupunem c&#728;a ar fi as&#184;ezat al&#728;aturi de Lenin, oare va fi pentru totdeauna?</S>
    <S sid="121" ssid="22">The following are examples of objective parallel sentences.</S>
    <S sid="122" ssid="23">[en]The Pirates have a 9-6 record this year and the Redbirds are 7-9.</S>
    <S sid="123" ssid="24">[ro] Pirat&#184;ii au un palmares de 9 la 6 anul acesta si P&#728;as&#728;arile Ros&#184;ii au 7 la 9.</S>
    <S sid="124" ssid="25">[en] One of the obstacles to the easy control of a 2-year old child is a lack of verbal communication.</S>
    <S sid="125" ssid="26">[ro] Unul dintre obstacolele in controlarea unui copil de 2 ani este lipsa comunic&#728;arii verbale.</S>
    <S sid="126" ssid="27">The annotators were trained using the MPQA annotation guidelines (Wiebe et al., 2005).</S>
    <S sid="127" ssid="28">The tagset consists of S(ubjective), O(bjective) and U(ncertain).</S>
    <S sid="128" ssid="29">For the U tags, a class was also given; OU means, for instance, that the annotator is uncertain but she is leaning toward O.</S>
    <S sid="129" ssid="30">Table 4 shows the pairwise agreement figures and the Kappa (K) calculated for the three annotators.</S>
    <S sid="130" ssid="31">The table also shows the agreement when the borderline uncertain cases are removed.</S>
    <S sid="131" ssid="32">Annotations performed by three annotators: one native English speaker (En) and two native Romanian speakers (Rol and Roe) When all the sentences are included, the agreement between the two Romanian annotators is measured at 0.83 (K = 0.67).</S>
    <S sid="132" ssid="33">If we remove the borderline cases where at least one annotator&#8217;s tag is Uncertain, the agreement rises to 0.89 with K = 0.77.</S>
    <S sid="133" ssid="34">These figures are somewhat lower than the agreement observed during previous subjectivity annotation studies conducted on English (Wiebe et al., 2005) (the annotators were more extensively trained in those studies), but they nonetheless indicate consistent agreement.</S>
    <S sid="134" ssid="35">Interestingly, when the agreement is conducted cross-lingually between an English and a Romanian annotator, the agreement figures, although somewhat lower, are comparable.</S>
    <S sid="135" ssid="36">In fact, once the Uncertain tags are removed, the monolingual and cross-lingual agreement and K values become almost equal, which suggests that in most cases the sentence-level subjectivity is preserved.</S>
    <S sid="136" ssid="37">The disagreements were reconciled first between the labels assigned by the two Romanian annotators, followed by a reconciliation between the resulting Romanian &#8220;gold-standard&#8221; labels and the labels assigned by the English annotator.</S>
    <S sid="137" ssid="38">In most cases, the disagreement across the two languages was found to be due to a difference of opinion about the sentence subjectivity, similar to the differences encountered in monolingual annotations.</S>
    <S sid="138" ssid="39">However, there are cases where the differences are due to the subjectivity being lost in the translation.</S>
    <S sid="139" ssid="40">Sometimes, this is due to several possible interpretations for the translated sentence.</S>
    <S sid="140" ssid="41">For instance, the following sentence: [en] They honored the battling Billikens last night.</S>
    <S sid="141" ssid="42">[ro] Ei i-au celebrat pe Billikens seara trecut&#728;a. is marked as Subjective in English (in context, the English annotator interpreted honored as referring to praises of the Billikens).</S>
    <S sid="142" ssid="43">However, the Romanian translation of honored is celebrat which, while correct as a translation, has the more frequent interpretation of having a party.</S>
    <S sid="143" ssid="44">The two Romanian annotators chose this interpretation, which correspondingly lead them to mark the sentence as Objective.</S>
    <S sid="144" ssid="45">In other cases, in particular when the subjectivity is due to figures of speech such as irony, the translation sometimes misses the ironic aspects.</S>
    <S sid="145" ssid="46">For instance, the translation of egghead was not perceived as ironic by the Romanian annotators, and consequently the following sentence labeled Subjective in English is annotated as Objective in Romanian.</S>
    <S sid="146" ssid="47">[en] I have lived for many years in a Connecticut commuting town with a high percentage of [...] business executives of egghead tastes.</S>
    <S sid="147" ssid="48">[ro] Am tr&#728;ait mult&#184;i ani intr-un oras&#184; din apropiere de Connecticut ce avea o mare proport&#184;ie de [...] oameni de afaceri cu gusturi intelectuale.</S>
    <S sid="148" ssid="49">To further validate the corpus-based projection of subjectivity, we developed a subjectivity classifier trained on Romanian subjectivity-annotated corpora obtained via cross-lingual projections.</S>
    <S sid="149" ssid="50">Ideally, one would generate an annotated Romanian corpus by translating English documents manually annotated for subjectivity such as the MPQA corpus.</S>
    <S sid="150" ssid="51">Unfortunately, the manual translation of this corpus would be prohibitively expensive, both timewise and financially.</S>
    <S sid="151" ssid="52">The other alternative &#8211; automatic machine translation &#8211; has not yet reached a level that would enable the generation of a highquality translated corpus.</S>
    <S sid="152" ssid="53">We therefore decided to use a different approach where we automatically annotate the English side of an existing EnglishRomanian corpus, and subsequently project the annotations onto the Romanian side of the parallel corpus across the sentence-level alignments available in the corpus.</S>
    <S sid="153" ssid="54">For the automatic subjectivity annotations, we generated two sets of the English-side annotations, one using the high-precision classifier and one using the high-coverage classifier available in the OpinionFinder tool.</S>
    <S sid="154" ssid="55">The high-precision classifier in OpinionFinder uses the clues of the subjectivity lexicon to harvest subjective and objective sentences from a large amount of unannotated text; this data is then used to automatically identify a set of extraction patterns, which are then used iteratively to identify a larger set of subjective and objective sentences.</S>
    <S sid="155" ssid="56">In addition, in OpinionFinder, the high-precision classifier is used to produce an English labeled data set for training, which is used to generate its Naive Bayes high-coverage subjectivity classifier.</S>
    <S sid="156" ssid="57">Table 5 shows the performance of the two classifiers on the MPQA corpus as reported in (Wiebe and Riloff, 2005).</S>
    <S sid="157" ssid="58">Note that 55% of the sentences in the MPQA corpus are subjective &#8211; which represents the baseline for this data set.</S>
    <S sid="158" ssid="59">The two OpinionFinder classifiers are used to label the training corpus.</S>
    <S sid="159" ssid="60">After removing the 504 test sentences, we are left with 10,628 sentences that are automatically annotated for subjectivity.</S>
    <S sid="160" ssid="61">Table 6 shows the number of subjective and objective sentences obtained with each classifier.</S>
    <S sid="161" ssid="62">Next, the OpinionFinder annotations are projected onto the Romanian training sentences, which are then used to develop a probabilistic classifier for the automatic labeling of subjectivity in Romanian sentences.</S>
    <S sid="162" ssid="63">Similar to, e.g., (Pang et al., 2002), we use a Naive Bayes algorithm trained on word features cooccurring with the subjective and the objective classifications.</S>
    <S sid="163" ssid="64">We assume word independence, and we use a 0.3 cut-off for feature selection.</S>
    <S sid="164" ssid="65">While recent work has also considered more complex syntactic features, we are not able to generate such features for Romanian as they require tools currently not available for this language.</S>
    <S sid="165" ssid="66">We create two classifiers, one trained on each data set.</S>
    <S sid="166" ssid="67">The quality of the classifiers is evaluated on the 504-sentence Romanian gold-standard corpus described above.</S>
    <S sid="167" ssid="68">Recall that the baseline on this data set is 54.16%, the percentage of sentences in the corpus that are subjective.</S>
    <S sid="168" ssid="69">Table 7 shows the results. fier using training data obtained via projections from data automatically labeled by OpinionFinder (OF).</S>
    <S sid="169" ssid="70">Our best classifier has an F-measure of 67.85, and is obtained by training on projections from the high-coverage OpinionFinder annotations.</S>
    <S sid="170" ssid="71">Although smaller than the 74.70 F-measure obtained by the English high-coverage classifier (see Table 5), the result appears remarkable given that no language-specific Romanian information was used.</S>
    <S sid="171" ssid="72">The overall results obtained with the machine learning approach are considerably higher than those obtained from the rule-based classifier (except for the precision of the subjective sentences).</S>
    <S sid="172" ssid="73">This is most likely due to the lexicon translation process, which as mentioned in the agreement study in Section 3.1, leads to ambiguity and loss of subjectivity.</S>
    <S sid="173" ssid="74">Instead, the corpus-based translations seem to better account for the ambiguity of the words, and the subjectivity is generally preserved in the sentence translations.</S>
  </SECTION>
  <SECTION title="5 Conclusions" number="5">
    <S sid="174" ssid="1">In this paper, we described two approaches to generating resources for subjectivity annotations for a new language, by leveraging on resources and tools available for English.</S>
    <S sid="175" ssid="2">The first approach builds a target language subjectivity lexicon by translating an existing English lexicon using a bilingual dictionary.</S>
    <S sid="176" ssid="3">The second generates a subjectivity-annotated corpus in a target language by projecting annotations from an automatically annotated English corpus.</S>
    <S sid="177" ssid="4">These resources were validated in two ways.</S>
    <S sid="178" ssid="5">First, we carried out annotation studies measuring the extent to which subjectivity is preserved across languages in each of the two resources.</S>
    <S sid="179" ssid="6">These studies show that only a relatively small fraction of the entries in the lexicon preserve their subjectivity in the translation, mainly due to the ambiguity in both the source and the target languages.</S>
    <S sid="180" ssid="7">This is consistent with observations made in previous work that subjectivity is a property associated not with words, but with word meanings (Wiebe and Mihalcea, 2006).</S>
    <S sid="181" ssid="8">In contrast, the sentence-level subjectivity was found to be more reliably preserved across languages, with cross-lingual inter-annotator agreements comparable to the monolingual ones.</S>
    <S sid="182" ssid="9">Second, we validated the two automatically generated subjectivity resources by using them to build a tool for subjectivity analysis in the target language.</S>
    <S sid="183" ssid="10">Specifically, we developed two classifiers: a rulebased classifier that relies on the subjectivity lexicon described in Section 3.1, and a machine learning classifier trained on the subjectivity-annotated corpus described in Section 4.1.</S>
    <S sid="184" ssid="11">While the highest precision for the subjective classification is obtained with the rule-based classifier, the overall best result of 67.85 F-measure is due to the machine learning approach.</S>
    <S sid="185" ssid="12">This result is consistent with the annotation studies, showing that the corpus projections preserve subjectivity more reliably than the lexicon translations.</S>
    <S sid="186" ssid="13">Finally, neither one of the classifiers relies on language-specific information, but rather on knowledge obtained through projections from English.</S>
    <S sid="187" ssid="14">A similar method can therefore be used to derive tools for subjectivity analysis in other languages.</S>
  </SECTION>
</PAPER>
