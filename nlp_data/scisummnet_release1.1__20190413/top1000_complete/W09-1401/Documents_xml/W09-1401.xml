<PAPER>
  <S sid="0">Overview of BioNLP&amp;rsquo;09 Shared Task on Event Extraction</S>
  <ABSTRACT>
    <S sid="1" ssid="1">The paper presents the design and implementation of the BioNLP&#8217;09 Shared Task, and reports the final results with analysis.</S>
    <S sid="2" ssid="2">The shared task consists of three sub-tasks, each of which addresses bio-molecular event extraction at a different level of specificity.</S>
    <S sid="3" ssid="3">The data was developed based on the GENIA event corpus.</S>
    <S sid="4" ssid="4">The shared task was run over 12 weeks, drawing initial interest from 42 teams.</S>
    <S sid="5" ssid="5">Of these teams, 24 submitted final results.</S>
    <S sid="6" ssid="6">The evaluation results are encouraging, indicating that state-of-the-art performance is approaching a practically applicable level and revealing some remaining challenges.</S>
  </ABSTRACT>
  <SECTION title="1 Introduction" number="1">
    <S sid="7" ssid="1">The history of text mining (TM) shows that shared tasks based on carefully curated resources, such as those organized in the MUC (Chinchor, 1998), TREC (Voorhees, 2007) and ACE (Strassel et al., 2008) events, have significantly contributed to the progress of their respective fields.</S>
    <S sid="8" ssid="2">This has also been the case in bio-TM.</S>
    <S sid="9" ssid="3">Examples include the TREC Genomics track (Hersh et al., 2007), JNLPBA (Kim et al., 2004), LLL (N&#180;edellec, 2005), and BioCreative (Hirschman et al., 2007).</S>
    <S sid="10" ssid="4">While the first two addressed bio-IR (information retrieval) and bio-NER (named entity recognition), respectively, the last two focused on bio-IE (information extraction), seeking relations between bio-molecules.</S>
    <S sid="11" ssid="5">With the emergence of NER systems with performance capable of supporting practical applications, the recent interest of the bio-TM community is shifting toward IE.</S>
    <S sid="12" ssid="6">Similarly to LLL and BioCreative, the BioNLP&#8217;09 Shared Task (the BioNLP task, hereafter) also addresses bio-IE, but takes a definitive step further toward finer-grained IE.</S>
    <S sid="13" ssid="7">While LLL and BioCreative focus on a rather simple representation of relations of bio-molecules, i.e. protein-protein interactions (PPI), the BioNLP task concerns the detailed behavior of bio-molecules, characterized as bio-molecular events (bio-events).</S>
    <S sid="14" ssid="8">The difference in focus is motivated in part by different applications envisioned as being supported by the IE methods.</S>
    <S sid="15" ssid="9">For example, BioCreative aims to support curation of PPI databases such as MINT (Chatr-aryamontri et al., 2007), for a long time one of the primary tasks of bioinformatics.</S>
    <S sid="16" ssid="10">The BioNLP task aims to support the development of more detailed and structured databases, e.g. pathway (Bader et al., 2006) or Gene Ontology Annotation (GOA) (Camon et al., 2004) databases, which are gaining increasing interest in bioinformatics research in response to recent advances in molecular biology.</S>
    <S sid="17" ssid="11">As the first shared task of its type, the BioNLP task aimed to define a bounded, well-defined bioevent extraction task, considering both the actual needs and the state of the art in bio-TM technology and to pursue it as a community-wide effort.</S>
    <S sid="18" ssid="12">The key challenge was in finding a good balance between the utility and the feasibility of the task, which was also limited by the resources available.</S>
    <S sid="19" ssid="13">Special consideration was given to providing evaluation at diverse levels and aspects, so that the results can drive continuous efforts in relevant directions.</S>
    <S sid="20" ssid="14">The paper discusses the design and implementation of the BioNLP task, and reports the results with analysis.</S>
  </SECTION>
  <SECTION title="2 Task setting" number="2">
    <S sid="21" ssid="1">To focus efforts on the novel aspects of the event extraction task, is was assumed that named entity recognition has already been performed and the task was begun with a given set of gold protein annotation.</S>
    <S sid="22" ssid="2">This is the only feature of the task setting that notably detracts from its realism.</S>
    <S sid="23" ssid="3">However, given that state-of-the-art protein annotation methods show a practically applicable level of performance, i.e.</S>
    <S sid="24" ssid="4">88% F-score (Wilbur et al., 2007), we believe the choice is reasonable and has several advantages, including focus on event extraction and effective evaluation and analysis.</S>
    <S sid="25" ssid="5">Table 1 shows the event types addressed in the BioNLP task.</S>
    <S sid="26" ssid="6">The event types were selected from the GENIA ontology, with consideration given to their importance and the number of annotated instances in the GENIA corpus.</S>
    <S sid="27" ssid="7">The selected event types all concern protein biology, implying that they take proteins as their theme.</S>
    <S sid="28" ssid="8">The first three types concern protein metabolism, i.e. protein production and breakdown.</S>
    <S sid="29" ssid="9">Phosphorylation is a representative protein modification event, and Localization and Binding are representative fundamental molecular events.</S>
    <S sid="30" ssid="10">Regulation (including its sub-types, Positive and Negative regulation) represents regulatory events and causal relations.</S>
    <S sid="31" ssid="11">The last five are universal but frequently occur on proteins.</S>
    <S sid="32" ssid="12">For the biological interpretation of the event types, readers are referred to Gene Ontology (GO) and the GENIA ontology.</S>
    <S sid="33" ssid="13">The failure of p65 translocation to the nucleus ... As shown in Table 1, the theme or themes of all events are considered primary arguments, that is, arguments that are critical to identifying the event.</S>
    <S sid="34" ssid="14">For regulation events, the entity or event stated as the cause of the regulation is also regarded as a primary argument.</S>
    <S sid="35" ssid="15">For some event types, other arguments detailing of the events are also defined (Secondary Args. in Table 1).</S>
    <S sid="36" ssid="16">From a computational point of view, the event types represent different levels of complexity.</S>
    <S sid="37" ssid="17">When only primary arguments are considered, the first five event types require only unary arguments, and the task can be cast as relation extraction between a predicate (event trigger) and an argument (Protein).</S>
    <S sid="38" ssid="18">The Binding type is more complex in requiring the detection of an arbitrary number of arguments.</S>
    <S sid="39" ssid="19">Regulation events always take a Theme argument and, when expressed, also a Cause argument.</S>
    <S sid="40" ssid="20">Note that a Regulation event may take another event as its theme or cause, a unique feature of the BioNLP task compared to other event extraction tasks, e.g.</S>
    <S sid="41" ssid="21">ACE.</S>
    <S sid="42" ssid="22">In the BioNLP task, events are expressed using three different types of entities.</S>
    <S sid="43" ssid="23">Text-bound entities (tentities hereafter) are represented as text spans with associated class information.</S>
    <S sid="44" ssid="24">The t-entities include event triggers (Localization, Binding, etc), protein references (Protein) and references to other entities (Entity).</S>
    <S sid="45" ssid="25">A t-entity is represented by a pair, (entitytype, text-span), and assigned an id with the prefix &#8220;T&#8221;, e.g.</S>
    <S sid="46" ssid="26">T1&#8211;T3 in Figure 1.</S>
    <S sid="47" ssid="27">An event is expressed as an n-tuple of typed t-entities, and has a id with prefix &#8220;E&#8221;, e.g.</S>
    <S sid="48" ssid="28">E1.</S>
    <S sid="49" ssid="29">An event modification is expressed by a pair, (predicate-negationor-speculation, event-id), and has an id with prefix &#8220;M&#8221;, e.g.</S>
    <S sid="50" ssid="30">M1.</S>
    <S sid="51" ssid="31">The BioNLP task targets semantically rich event extraction, involving the extraction of several different classes of information.</S>
    <S sid="52" ssid="32">To facilitate evaluation on different aspects of the overall task, the task is divided to three sub-tasks addressing event extraction at different levels of specificity.</S>
    <S sid="53" ssid="33">Task 1.</S>
    <S sid="54" ssid="34">Core event detection detection of typed, text-bound events and assignment of given proteins as their primary arguments.</S>
    <S sid="55" ssid="35">Task 2.</S>
    <S sid="56" ssid="36">Event enrichment recognition of secondary arguments that further specify the events extracted in Task 1.</S>
    <S sid="57" ssid="37">Task 3.</S>
    <S sid="58" ssid="38">Negation/Speculation detection detection of negations and speculation statements concerning extracted events.</S>
    <S sid="59" ssid="39">Task 1 serves as the backbone of the shared task and is mandatory for all participants.</S>
    <S sid="60" ssid="40">Task 2 involves the recognition of Entity type t-entities and assignment of those as secondary event arguments.</S>
    <S sid="61" ssid="41">Task 3 addresses the recognition of negated or speculatively expressed events without specific binding to text.</S>
    <S sid="62" ssid="42">An example is given in Fig.</S>
    <S sid="63" ssid="43">1.</S>
  </SECTION>
  <SECTION title="3 Data preparation" number="3">
    <S sid="64" ssid="1">The BioNLP task data were prepared based on the GENIA event corpus.</S>
    <S sid="65" ssid="2">The data for the training and development sets were derived from the publicly available event corpus (Kim et al., 2008), and the data for the test set from an unpublished portion of the corpus.</S>
    <S sid="66" ssid="3">Table 2 shows statistics of the data sets.</S>
    <S sid="67" ssid="4">For data preparation, in addition to filtering out irrelevant annotations from the original GENIA corpus, some new types of annotation were added to make the event annotation more appropriate for the purposes of the shared task.</S>
    <S sid="68" ssid="5">The following sections describe the key changes to the corpus.</S>
    <S sid="69" ssid="6">The named entity (NE) annotation of the GENIA corpus has been somewhat controversial due to differences in annotation principles compared to other biomedical NE corpora.</S>
    <S sid="70" ssid="7">For instance, the NE annotation in the widely applied GENETAG corpus (Tanabe et al., 2005) does not differentiate proteins from genes, while GENIA annotation does.</S>
    <S sid="71" ssid="8">Such differences have caused significant inconsistency in methods and resources following different annotation schemes.</S>
    <S sid="72" ssid="9">To remove or reduce the inconsistency, GENETAG-style NE annotation, which we term gene-or-gene-product (GGP) annotation, has been added to the GENIA corpus, with appropriate revision of the original annotation.</S>
    <S sid="73" ssid="10">For details, we refer to (Ohta et al., 2009).</S>
    <S sid="74" ssid="11">The NE annotation used in the BioNLP task data is based on this annotation.</S>
    <S sid="75" ssid="12">The GENIA event annotation was made based on the GENIA event ontology, which uses a loose typing system for the arguments of each event class.</S>
    <S sid="76" ssid="13">For example, in Figure 2(a), it is expressed that the binding event involves two proteins, TRAF2 and CD40, and that, in the case of CD40, its cytoplasmic domain takes part in the binding.</S>
    <S sid="77" ssid="14">Without constraints on the type of theme arguments, the following two annotations are both legitimate: The two can be seen as specifying the same event at different levels of specificity1.</S>
    <S sid="78" ssid="15">Although both alternatives are reasonable, the need to have consistent training and evaluation data requires a consistent choice to be made for the shared task.</S>
    <S sid="79" ssid="16">Thus, we fix the types of all non-event primary arguments to be proteins (specifically GGPs).</S>
    <S sid="80" ssid="17">For GENIA event annotations involving themes other than proteins, additional argument types were introduced, for example, as follows: Note that the protein, CD40, and its domain, cytoplasmic domain, are associated by argument numbering.</S>
    <S sid="81" ssid="18">To resolve issues related to the mapping between proteins and related entities systematically, we introduced partial static relation annotation for relations such as Part-Whole, drawing in part on similar annotation of the BioInfer corpus (Pyysalo et al., 2007).</S>
    <S sid="82" ssid="19">For details of this part of the revision process, we refer to (Pyysalo et al., 2009).</S>
    <S sid="83" ssid="20">Figure 2 shows some challenging cases.</S>
    <S sid="84" ssid="21">In (b), the site GATA motifs is not identified as an argument of the binding event, because the protein containing it is not stated.</S>
    <S sid="85" ssid="22">In (c), among the two sites (PEBP2 site and promoter) of the gene GM-CSF, only the more specific one, PEBP2, is annotated.</S>
    <S sid="86" ssid="23">Alternative names for the same object are frequently introduced in biomedical texts, typically through apposition.</S>
    <S sid="87" ssid="24">This is illustrated in Figure 3(a), where the two expressions B cell transcription factor and BSAP are in apposition and refer to the same protein.</S>
    <S sid="88" ssid="25">Consequently, in this case the following two annotations represent the same event: In the GENIA event corpus only one of these is annotated, with preference given to shorter names over longer descriptive ones.</S>
    <S sid="89" ssid="26">Thus of the above example events, the latter would be annotated.</S>
    <S sid="90" ssid="27">However, as both express the same event, in the shared task evaluation either alternative was accepted as correct extraction of the event.</S>
    <S sid="91" ssid="28">In order to implement this aspect of the evaluation, expressions of equivalent entities were annotated as follows: Eq (B cell transcription factor, BSAP) The equivalent entity annotation in the revised GENIA corpus covers also cases other than simple apposition, illustrated in Figure 3.</S>
    <S sid="92" ssid="29">A frequent case in biomedical literature involves use of the slash symbol (&#8220;/&#8221;) to state synonyms.</S>
    <S sid="93" ssid="30">The slash symbol is ambiguous as it is used also to indicate dimerized proteins.</S>
    <S sid="94" ssid="31">In the case of p50/p50, the two p50 are annotated as equivalent because they represent the same proteins at the same state.</S>
    <S sid="95" ssid="32">Note that although rare, also explicitly introduced aliases are annotated, as in Figure 3(e).</S>
  </SECTION>
  <SECTION title="4 Evaluation" number="4">
    <S sid="96" ssid="1">For the evaluation, the participants were given the test data with gold annotation only for proteins.</S>
    <S sid="97" ssid="2">The evaluation was then carried out by comparing the annotation predicted by each participant to the gold annotation.</S>
    <S sid="98" ssid="3">For the comparison, equality of annotations is defined as described in Section 4.1.</S>
    <S sid="99" ssid="4">The evaluation results are reported using the standard recall/precision/f-score metrics, under different criteria defined through the equalities.</S>
    <S sid="100" ssid="5">Equality of events is defined as follows: Event Equality equality holds between any two events when (1) the event types are the same, (2) the event triggers are the same, and (3) the arguments are fully matched.</S>
    <S sid="101" ssid="6">A full matching of arguments between two events means there is a perfect 1-to-1 mapping between the two sets of arguments.</S>
    <S sid="102" ssid="7">Equality of individual arguments is defined as follows: Argument Equality equality holds between any two arguments when (1) the role types are the same, and (2-1) both are t-entities and equality holds between them, or (2-2) both are events and equality holds between them.</S>
    <S sid="103" ssid="8">Due to the condition (2-2), event equality is defined recursively for events referring to events.</S>
    <S sid="104" ssid="9">Equality of t-entities is defined as follows: T-entity Equality equality holds between any two t-entities when (1) the entity types are the same, and (2) the spans are the same.</S>
    <S sid="105" ssid="10">Any two text spans (beg1, end1) and (beg2, end2), are the same iff beg1 = beg2 and end1 = end2.</S>
    <S sid="106" ssid="11">Note that the event triggers are also t-entities thus their equality is defined by the t-entity equality.</S>
    <S sid="107" ssid="12">Various evaluation modes can be defined by varying equivalence criteria.</S>
    <S sid="108" ssid="13">In the following, we describe three fundamental variants applied in the evaluation.</S>
    <S sid="109" ssid="14">Strict matching The strict matching mode requires exact equality, as defined in section 4.1.</S>
    <S sid="110" ssid="15">As some of its requirements may be viewed as unnecessarily precise, practically motivated relaxed variants, described in the following, are also applied.</S>
    <S sid="111" ssid="16">Approximate span matching The approximate span matching mode is defined by relaxing the requirement for text span matching for t-entities.</S>
    <S sid="112" ssid="17">Specifically, a given span is equivalent to a gold span if it is entirely contained within an extension of the gold span by one word both to the left and to the right, that is, beg1 &#8805; ebeg2 and end1 &#8804; eend2, where (beg1, end1) is the given span and (ebeg2, eend2) is the extended gold span.</S>
    <S sid="113" ssid="18">Approximate recursive matching In strict matching, for a regulation event to be correct, the events it refers to as theme or cause must also be be strictly correct.</S>
    <S sid="114" ssid="19">The approximate recursive matching mode is defined by relaxing the requirement for recursive event matching, so that an event can match even if the events it refers to are only partially correct.</S>
    <S sid="115" ssid="20">Specifically, for partial matching, only Theme arguments are considered: events can match even if referred events differ in non-Theme arguments.</S>
  </SECTION>
  <SECTION title="5 Schedule" number="5">
    <S sid="116" ssid="1">The BioNLP task was held for 12 weeks, from the sample data release to the final submission.</S>
    <S sid="117" ssid="2">It included 5 weeks of system design period with sample data, 6 weeks of system development period with training and development data, and a 1 week test period.</S>
    <S sid="118" ssid="3">The system development period was originally planned for 5 weeks but extended by 1 week due to the delay of the training data release and the revision.</S>
    <S sid="119" ssid="4">Table 3 shows key dates of the schedule.</S>
  </SECTION>
  <SECTION title="6 Supporting Resources" number="6">
    <S sid="120" ssid="1">To allow participants to focus development efforts on novel aspects of event extraction, we prepared publicly available BioNLP resources readily available for the shared task.</S>
    <S sid="121" ssid="2">Several fundamental BioNLP tools were provided through U-Compare (Kano et al., 2009)2, which included tools for tokenization, sentence segmentation, part-of-speech tagging, chunking and syntactic parsing.</S>
    <S sid="122" ssid="3">Participants were also provided with the syntactic analyses created by a selection of parsers.</S>
    <S sid="123" ssid="4">We applied two mainstream Penn Treebank (PTB) phrase structure parsers: the Bikel parser3, implementing Collins&#8217; parsing model (Bikel, 2004) and trained on PTB, and the reranking parser of (Charniak and Johnson, 2005) with the self-trained biomedical parsing model of (McClosky and Charniak, 2008)4.</S>
    <S sid="124" ssid="5">We also applied the GDep5, native dependency parser trained on the GENIA Treebank (Tateisi et al., 2005), and a version of the C&amp;C CCG deep parser6 adapted to biomedical text (Rimell and Clark, 2008).</S>
    <S sid="125" ssid="6">The text of all documents was segmented and tokenized using the GENIA Sentence Splitter and the GENIA Tagger, provided by U-Compare.</S>
    <S sid="126" ssid="7">The same segmentation was enforced for all parsers, which were run using default settings.</S>
    <S sid="127" ssid="8">Both the native output of each parser and a representation in the popular Stanford Dependency (SD) format (de Marneffe et al., 2006) were provided.</S>
    <S sid="128" ssid="9">The SD representation was created using the Stanford tools7 to convert from the PTB scheme, the custom conversion introduced by (Rimell and Clark, 2008) for the C&amp;C CCG parser, and a simple format-only conversion for GDep.</S>
  </SECTION>
  <SECTION title="7 Results and Discussion" number="7">
    <S sid="129" ssid="1">In total, 42 teams showed interest in the shared task and registered for participation, and 24 teams submitted final results.</S>
    <S sid="130" ssid="2">All 24 teams participated in the obligatory Task 1, six in each of Tasks 2 and 3, and two teams completed all the three tasks.</S>
    <S sid="131" ssid="3">Table 4 shows a profile of the 22 final teams, excepting two who wished to remain anonymous.</S>
    <S sid="132" ssid="4">A brief examination on the team organization (the Org column) shows a computer science background (C) to be most frequent among participants, with less frequent participation from bioinformaticians (BI), biologists (B) and liguists (L).</S>
    <S sid="133" ssid="5">This may be attributed in part to the fact that the event extraction task required complex computational modeling.</S>
    <S sid="134" ssid="6">The role of computer scientists may be emphasized in part due to the fact that the task was novel to most participants, requiring particular efforts in framework design and implementation and computational resources.</S>
    <S sid="135" ssid="7">This also suggests there is room for improvement from more input from biologists.</S>
    <S sid="136" ssid="8">The final evaluation results of Task 1 are shown in Table 5.</S>
    <S sid="137" ssid="9">The results on the five event types involving only a single primary theme argument are shown in one merged class, &#8220;Simple Event&#8221;.</S>
    <S sid="138" ssid="10">The broad performance range (31%&#8211;70%) indicates even the extraction of simple events is not a trivial task.</S>
    <S sid="139" ssid="11">However, the top-ranked systems show encouraging performance, achieving or approaching 70% f-score.</S>
    <S sid="140" ssid="12">The performance ranges for Binding (5%&#8211;44%) and Regulation (1%&#8211;40%) events show their extraction to be clearly more challenging.</S>
    <S sid="141" ssid="13">It is interesting that while most systems show better performance for binding over regulation events, the systems [ConcordU] and [UT+DBCLS] are better for regulation, showing somewhat reduced performance for Binding events.</S>
    <S sid="142" ssid="14">This is in particular contrast to the following two systems, [ViBGhent] and [UTokyo], which show far better performance for Binding than Regulation events.</S>
    <S sid="143" ssid="15">As one possible explanation, we find that the latter two differentiate binding events by their number of themes, while the former two give no specific treatment to multi-theme binding events.</S>
    <S sid="144" ssid="16">Such observations and comparisons are a clear benefit of a community-wide shared task.</S>
    <S sid="145" ssid="17">Table 6 shows the evaluation results for the teams who participated in Task 2.</S>
    <S sid="146" ssid="18">The &#8220;All&#8221; column shows the overall performance of the systems for Task 2, while the &#8220;All Second Args.&#8221; column shows the performance of finding only the secondary arguments.</S>
    <S sid="147" ssid="19">The evaluation results show considerable differences between the criteria.</S>
    <S sid="148" ssid="20">For example, the system [Team 24] shows performance comparable to the top ranked system in finding secondary arguments, although its overall performance for Task 2 is more limited.</S>
    <S sid="149" ssid="21">Table 6 also shows the three systems, [UT+DBCLS], [Team 24] and [CNBMadrid], show performance at a practical level in particular in finding specific sites of phosphorylation.</S>
    <S sid="150" ssid="22">As shown in Table 7, the performance range for Task 3 is very low although the representation of the task is as simple as the simple events.</S>
    <S sid="151" ssid="23">We attribute the reason to the fact that Task 3 is the only task of which the annotation is not bound to textual clue, thus no text-bound annotation was provided.</S>
    <S sid="152" ssid="24">Figure 4 shows a scatter plot of the performance of the participating systems during the system development period.</S>
    <S sid="153" ssid="25">The performance evaluation comes from the log of the online evaluation system on the development data.</S>
    <S sid="154" ssid="26">It shows the best performance and the average performance of the participating systems were trending upwards up until the deadline of final submission, which indicates there is still much potential for improvement.</S>
    <S sid="155" ssid="27">Table 8 shows experimental results of a system ensemble using the final submissions.</S>
    <S sid="156" ssid="28">For the experiments, the top 3&#8211;10 systems were chosen, and the output of each system treated as a weighted vote8.</S>
    <S sid="157" ssid="29">Three weighting schemes were used; &#8220;Equal&#8221; weights each vote equally; &#8220;Averaged&#8221; weights each vote by the overall f-score of the system; &#8220;Event Type&#8221; weights each vote by the f-score of the system for the specific event type.</S>
    <S sid="158" ssid="30">The best score, 55.96%, was obtained by the &#8220;Event Type&#8221; weighting scheme, showing a 4% unit improvement over the best individual system.</S>
    <S sid="159" ssid="31">While using the final scores for weighting uses data that would not be available in practice, similar weighting could likely be obtained e.g. using performance on the development data.</S>
    <S sid="160" ssid="32">The experiment demonstrates that an f-score better than 55% can be achieved simply by combining the strengths of the systems.</S>
  </SECTION>
  <SECTION title="8 Conclusion" number="8">
    <S sid="161" ssid="1">Meeting with the community-wide participation, the BioNLP Shared Task was successful in introducing fine-grained event extraction to the domain.</S>
    <S sid="162" ssid="2">The evaluation results of the final submissions from the participants are both promising and encouraging for the future of this approach to IE.</S>
    <S sid="163" ssid="3">It has been revealed that state-of-the-art performance in event extraction is approaching a practically applicable level for simple events, and also that there are many remaining challenges in the extraction of complex events.</S>
    <S sid="164" ssid="4">A brief analysis suggests that the submitted data together with the system descriptions are rich resources for finding directions for improvements.</S>
    <S sid="165" ssid="5">Finally, the experience of the shared task participants provides an invaluable basis for cooperation in facing further challenges.</S>
  </SECTION>
  <SECTION title="Acknowledgments" number="9">
    <S sid="166" ssid="1">This work was partially supported by Grant-in-Aid for Specially Promoted Research (MEXT, Japan) and Genome Network Project (MEXT, Japan).</S>
  </SECTION>
</PAPER>
