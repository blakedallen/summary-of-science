[
  {
    "citance_No": 1, 
    "citing_paper_id": "D10-1113", 
    "citing_paper_authority": 26, 
    "citing_paper_authors": "Georgiana, Dinu | Mirella, Lapata", 
    "raw_text": "More recently, Reisinger and Mooney (2010) present a method that uses clustering to pro duce multiple sense-specific vectors for each word. Specifically, a word? s contexts are clustered to produce groups of similar context vectors", 
    "clean_text": "More recently, Reisinger and Mooney (2010) present a method that uses clustering to produce multiple sense-specific vectors for each word.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "D10-1113", 
    "citing_paper_authority": 26, 
    "citing_paper_authors": "Georgiana, Dinu | Mirella, Lapata", 
    "raw_text": "The best LDA model also uses the scalar product, has K= 1200 topics, and? set to 50K. Following Reisinger and Mooney (2010), we also evaluated mixture models that combine the output of models with varying parameter settings", 
    "clean_text": "Following Reisinger and Mooney (2010), we also evaluated mixture models that combine the output of models with varying parameter settings.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "D10-1113", 
    "citing_paper_authority": 26, 
    "citing_paper_authors": "Georgiana, Dinu | Mirella, Lapata", 
    "raw_text": "As can be seen, the LSA model improves slightly, whereas NMF and LDA perform worse than their best individual models.3 Overall, we observe that NMF and LDA yield significantly (p &lt; 0.01) better correlations than LSA and the sim 3It is difficult to relate our results to Reisinger and Mooney (2010), due to differences in the training data and the vector representations it gives rise to", 
    "clean_text": "It is difficult to relate our results to Reisinger and Mooney (2010), due to differences in the training data and the vector representations it gives rise to.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D10-1113", 
    "citing_paper_authority": 26, 
    "citing_paper_authors": "Georgiana, Dinu | Mirella, Lapata", 
    "raw_text": "As a comparison, a baseline con fig uration with tf-idf weighting and the cosine similarity measure yields a correlation of 0.38 with our data and 0.49 in Reisinger and Mooney (2010)", 
    "clean_text": "As a comparison, a baseline configuration with tf-idf weighting and the cosine similarity measure yields a correlation of 0.38 with our data and 0.49 in Reisinger and Mooney (2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P14-2035", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Dimitri, Kartsaklis | Nal, Kalchbrenner | Mehrnoosh, Sadrzadeh", 
    "raw_text": "1In general, our approach is quite close to the multi prototype models of Reisinger and Mooney (2010)", 
    "clean_text": "In general, our approach is quite close to the multi prototype models of Reisinger and Mooney (2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P12-1092", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "Eric H., Huang | Andrew Y., Ng | Christopher D., Manning | Richard, Socher", 
    "raw_text": "Reisinger and Mooney (2010b) introduced a multi-prototype VSM where word sense discrimination is first applied by clustering contexts, and then prototypes are built using the contexts of the sense-labeled words", 
    "clean_text": "Reisinger and Mooney (2010b) introduced a multi-prototype VSM where word sense discrimination is first applied by clustering contexts, and then prototypes are built using the contexts of the sense-labeled words.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P12-1092", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "Eric H., Huang | Andrew Y., Ng | Christopher D., Manning | Richard, Socher", 
    "raw_text": "Instead of using only one representation per word, Reisinger and Mooney (2010b) proposed the multi prototype approach for vector-space models, which uses multiple representations to capture different senses and usages of a word", 
    "clean_text": "Instead of using only one representation per word, Reisinger and Mooney (2010b) proposed the multi prototype approach for vector-space models, which uses multiple representations to capture different senses and usages of a word.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P12-1092", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "Eric H., Huang | Andrew Y., Ng | Christopher D., Manning | Richard, Socher", 
    "raw_text": "Prunedtf-idf (Reisinger and Mooney, 2010b) and ESA (Gabrilovich and Markovitch, 2007) are also included", 
    "clean_text": "Pruned tf-idf (Reisinger and Mooney, 2010b) and ESA (Gabrilovich and Markovitch, 2007) are also included.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P12-1092", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "Eric H., Huang | Andrew Y., Ng | Christopher D., Manning | Richard, Socher", 
    "raw_text": "Reisinger and Mooney (2010b) found pruning the low-value tf-idf features helps performance", 
    "clean_text": "Reisinger and Mooney (2010b) found pruning the low-value tf-idf features helps performance.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P12-1092", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "Eric H., Huang | Andrew Y., Ng | Christopher D., Manning | Richard, Socher", 
    "raw_text": "By using distributed representations of 3We first tried movMF as in Reisinger and Mooney (2010b), but were unable to get decent results (only 31.5)", 
    "clean_text": "We first tried movMF as in Reisinger and Mooney (2010b), but were unable to get decent results (only 31.5).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P12-1092", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "Eric H., Huang | Andrew Y., Ng | Christopher D., Manning | Richard, Socher", 
    "raw_text": "Reisinger and Mooney (2010b) combined the two approaches and applied them to vector-space mod els, which was further improved in Reisinger and Mooney (2010a)", 
    "clean_text": "Reisinger and Mooney (2010b) combined the two approaches and applied them to vector-space models, which was further improved in Reisinger and Mooney (2010a).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P13-1055", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Olivier, Ferret", 
    "raw_text": "and Lapata, 2007), the multi-prototype (Reisinger and Mooney, 2010) or examplar-based models (Erk and Pado, 2010), the Deep Learning approach of (Huang et al, 2012) or the redefinition of the distributional approach in a Bayesian framework (Kazama et al, 2010) can be classified into this second category", 
    "clean_text": "The multi-prototype (Reisinger and Mooney, 2010) or examplar-based models (Erk and Pado, 2010), the Deep Learning approach of (Huang et al, 2012) or the redefinition of the distributional approach in a Bayesian framework (Kazama et al, 2010) can be classified into this second category.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P13-1055", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Olivier, Ferret", 
    "raw_text": "We plan to extend this work by taking into account the notion of word sense as it is done in (Reisinger and Mooney, 2010) or (Huang et al, 2012): since werely on occurrences of words in texts, this extension should be quite straightforward by turning our word-in-context classifiers into true word sense classifiers", 
    "clean_text": "We plan to extend this work by taking into account the notion of word sense as it is done in (Reisinger and Mooney, 2010) or (Huang et al, 2012): since we rely on occurrences of words in texts, this extension should be quite straightforward by turning our word-in-context classifiers into true word sense classifiers.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "N12-1076", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Soeren, Laue | Georgiana, Dinu | Stefan, Thater", 
    "raw_text": "(2010), Reisinger and Mooney (2010) and Reddy et al (2011), who make use of token vectors for individual occurrences of a word, rather than using the already mixed type vectors", 
    "clean_text": "A different approach has been taken by Erk and Pad\u00f3 (2010), Reisinger and Mooney (2010) and Reddy et al. (2011), who make use of token vectors for individual occurrences of a word, rather than using the already mixed type vectors.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "E12-1005", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Jackie Chi Kit, Cheung | Gerald, Penn", 
    "raw_text": "The top-down multi-prototype approach determines a number of senses for each word, and then clusters the occurrences of the word (Reisinger and Mooney, 2010) into these senses", 
    "clean_text": "The top-down multi-prototype approach determines a number of senses for each word, and then clusters the occurrences of the word (Reisinger and Mooney, 2010) into these senses.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P13-1171", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Scott Wen-Tau, Yih | Ming-Wei, Chang | Christopher, Meek | Andrzej, Pastusiak", 
    "raw_text": "Contextual term-vectors created using the Wikipedia corpus have shown to perform well on measuring word similarity (Reisinger and Mooney, 2010)", 
    "clean_text": "Contextual term-vectors created using the Wikipedia corpus have shown to perform well on measuring word similarity (Reisinger and Mooney, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W11-1310", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Siva, Reddy | Diana, McCarthy | Suresh, Manandhar | Spandana, Gella", 
    "raw_text": "Related work to ours is (Reisinger and Mooney, 2010) where exemplars of a word are first clustered and then prototype vectors are built", 
    "clean_text": "Related work to ours is (Reisinger and Mooney, 2010) where exemplars of a word are first clustered and then prototype vectors are built.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "N12-1077", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Scott Wen-Tau, Yih | Vahed, Qazvinian", 
    "raw_text": "618 Spearman? s? Method WS-353 WS-sim WS-rel MC-30 RG-65 MTurk-287 (Radinsky et al, 2011) 0.80-- 0.63 (Reisinger and Mooney, 2010) 0.77-- (Agirre et al, 2009) 0.78 0.83 0.72 0.92 0.96 (Gabrilovich and Markovitch, 2007) 0.75-- 0.59 (Hughes and Ramage, 2007) 0.55- 0.90 0.84 Web Search 0.56 0.56 0.54 0.48 0.44 0.44 Wikipedia 0.73 0.80 0.73 0.87 0.83 0.62 Bloomsbury 0.45 0.60 0.60 0.71 0.78 0.29 WordNet 0.37 0.49 0.49 0.79 0.78 0.25 Combining VSMs 0.81 0.87 0.77 0.89 0.89 0.68 Table 1: The performance of the state-of-the-art methods and different vector space models on measuring semantic word relatedness using the cosine similarity", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "N12-1077", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Scott Wen-Tau, Yih | Vahed, Qazvinian", 
    "raw_text": "Al though in previous work, researchers try to capture word senses using different vectors (Reisinger and Mooney, 2010) from the same text corpus, this is in fact difficult in practice", 
    "clean_text": "Although in previous work, researchers try to capture word senses using different vectors (Reisinger and Mooney, 2010) from the same text corpus, this is in fact difficult in practice.", 
    "keep_for_gold": 0
  }
]
