Discriminative Reordering Models For Statistical Machine Translation
We present discriminative reordering models for phrase-based statistical machine translation.
The models are trained using the maximum entropy principle.
We use several types of features: based on words, based on word classes, based on the local context.
We evaluate the overall performance of the reordering models as well as the contribution of the individual feature types on a word-aligned corpus.
Additionally, we show improved translation performance using these reordering models compared to a state-of-the-art baseline system.
Despite their high perplexities, reordered LMs yield some improvements when integrated to a PSMT baseline that already includes a discriminative phrase orientation model.
To lexicalize reordering, a discriminative reordering model (Zens and Ney, 2006a) is used.
We use clustered word classes in a discriminate reordering model, and show that they reduce the classification error rate.
