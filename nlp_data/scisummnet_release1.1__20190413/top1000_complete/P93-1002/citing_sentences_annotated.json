[
  {
    "citance_No": 1, 
    "citing_paper_id": "C94-2178", 
    "citing_paper_authority": 30, 
    "citing_paper_authors": "Pascale, Fung | Kenneth Ward, Church", 
    "raw_text": "There have been quite a number of recent papers on parallel text: Brown et al (1990, 1991, 1993), Chen (1993), Church (1993), Church et al (1993), Dagan et al (1993), Gale and Church (1991, 1993), Isabelle (1992), Kay and Rgsenschein (1993), Klavans and Tzoukermann (1990), Kupiec (1993), Matsumoto (1991), Ogden and Gonzales (1993), Shemtov (1993), Simard et al (1992), WarwickArmstrong and Russell (1990), Wu (to appear)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P13-1061", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Xiaojun, Quan | Chunyu, Kit | Yan, Song", 
    "raw_text": "As shown in Chen (1993) and Wu (1994), however, sentence length based methods suffer when the texts to be aligned contain small passages, or the languages involved share few cognates", 
    "clean_text": "As shown in Chen (1993) and Wu (1994), however, sentence length based methods suffer when the texts to be aligned contain small passages, or the languages involved share few cognates.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "C94-1026", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Kuang-Hua, Chen | Hsin-Hsi, Chen", 
    "raw_text": "Other translation-based alignments (Kay, 199l; Chen, 1993) show the difficulty in determining the word correspondence and are very complex", 
    "clean_text": "Other translation-based alignments (Kay, 199l; Chen, 1993) show the difficulty in determining the word correspondence and are very complex.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P97-1038", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Jason S., Chang | Mathis H., Chen", 
    "raw_text": "As Chen (1993) points out, dynamic programming is particularly susceptible to deletions occurring in one of the two languages", 
    "clean_text": "As Chen (1993) points out, dynamic programming is particularly susceptible to deletions occurring in one of the two languages.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W05-0816", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Anil Kumar, Singh | Samar, Husain", 
    "raw_text": "Simard and Plamondon (Simard and Plamondon, 1998) used a composite method in which the first pass does alignment at the level of characters asin (Church, 1993) (itself based on cognate matching) and the second pass uses IBM Model-1, fol lowing Chen (Chen, 1993)", 
    "clean_text": "Simard and Plamondon (Simard and Plamondon, 1998) used a composite method in which the first pass does alignment at the level of characters asin (Church, 1993) (itself based on cognate matching) and the second pass uses IBM Model-1, following Chen (Chen, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W01-1406", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Arul, Menezes | Stephen D., Richardson", 
    "raw_text": "(The problem of aligning parallel corpora at the sentence level has been addressed by Meyers (1998b) Chen (1993) and others and is beyond the scope of this paper)", 
    "clean_text": "(The problem of aligning parallel corpora at the sentence level has been addressed by Meyers (1998b) Chen (1993) and others and is beyond the scope of this paper).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "D08-1053", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Lei, Shi | Ming, Zhou", 
    "raw_text": "By adopting the IBM model 1, (Chen 1993) used word translation probabilities, which he showed gives better accuracy than the sentence length based method", 
    "clean_text": "By adopting the IBM model 1, (Chen 1993) used word translation probabilities, which he showed gives better accuracy than the sentence length based method.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D08-1053", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Lei, Shi | Ming, Zhou", 
    "raw_text": "(Simard and Plamondon 1996) used a two-pass approach, where the first pass performs length-based alignment at the character level as in (Gale and Church 1993) and the second pass uses IBM Model 1, following (Chen 1993)", 
    "clean_text": "(Simard and Plamondon 1996) used a two-pass approach, where the first pass performs length-based alignment at the character level as in (Gale and Church 1993) and the second pass uses IBM Model 1, following (Chen 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D08-1053", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Lei, Shi | Ming, Zhou", 
    "raw_text": "Each type of the web page sentence aligner makes use of three conventional sentence alignment models, one is the length based model fol lowing (Brown 1991), one is the lexicon based model following (Chen 1993), and the other one is the hybrid model presented in (Zhao 2002)", 
    "clean_text": "Each type of the web page sentence aligner makes use of three conventional sentence alignment models, one is the length based model following (Brown 1991), one is the lexicon based model following (Chen 1993), and the other one is the hybrid model presented in (Zhao 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P98-1042", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Nigel, Collier | Kenji, Ono | Hideki, Hirakawa", 
    "raw_text": "Various methods have been developed for sentence alignment which we can categorise as either lexical such as (Chen, 1993), based on a large-scale bilingual lexicon; statistical such as (Brown et al, 1991) (Church, 1993) (Gale and Church, 1903) (Kay and RSsheheisen, 1993), based on distributional regularities of words or byte-length ratios and possibly inducing a bilingual exicon as a by-product, or hybrid such as (Utsuro et al, 1994) (Wu, 1994), based on some combination of the other two", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W05-0808", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Niraj, Aswani | Robert J., Gaizauskas", 
    "raw_text": "Other examples of lexical methods are Warwick et al (1989), Mayers et al (1998), Chen (1993) and Haruno and Yamazaki (1996)", 
    "clean_text": "Other examples of lexical methods are Warwick et al (1989), Mayers et al (1998), Chen (1993) and Haruno and Yamazaki (1996).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W05-0808", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Niraj, Aswani | Robert J., Gaizauskas", 
    "raw_text": "Chen (1993) constructs a simple word-to-word translation model and then takes the alignment that maximizes the likelihood of generating the corpus given the translation model", 
    "clean_text": "Chen (1993) constructs a simple word-to-word translation model and then takes the alignment that maximizes the likelihood of generating the corpus given the translation model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W11-1217", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Radu, Ion | Alexandru, Ceau&scedil;u | Elena, Irimia", 
    "raw_text": "Another case study of sentence alignment that we will present here is that of Chen (1993)", 
    "clean_text": "Another case study of sentence alignment that we will present here is that of Chen (1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W11-1217", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Radu, Ion | Alexandru, Ceau&scedil;u | Elena, Irimia", 
    "raw_text": "EMACC finds only 1:1 textual units alignments in its present form but a document pair can be easily extended to a document bead following the example from (Chen, 1993)", 
    "clean_text": "EMACC finds only 1:1 textual units alignments in its present form but a document pair can be easily extended to a document bead following the example from (Chen, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "C10-2010", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Fabienne, Braune | Alexander, Fraser", 
    "raw_text": "Asshown in (Chen, 1993) the accuracy of sentence length based methods decreases drastically when aligning texts containing small deletions or free translations", 
    "clean_text": "Asshown in (Chen, 1993) the accuracy of sentence length based methods decreases drastically when aligning texts containing small deletions or free translations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "C10-2010", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Fabienne, Braune | Alexander, Fraser", 
    "raw_text": "The approaches by (Chen, 1993), (Ceausu et al, 2006) or (Fattah et al, 2007) need manually aligned pairs of sentences in order to train the used alignment models", 
    "clean_text": "The approaches by (Chen, 1993), (Ceausu et al, 2006) or (Fattah et al, 2007) need manually aligned pairs of sentences in order to train the used alignment models.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W02-1211", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Le, Sun | Song, Xue | Weimin, Qu | Xiaofeng, Wang | Yufang, Sun", 
    "raw_text": "There are basically three kinds of approaches on sentence alignment: the length-based approach (Gale& amp; Church 1991 and Brown et al 1991), the lexical approach (key& amp; Roscheisen 1993), and the combination of them (Chen 1993, Wu 1994 and Langlais 1998, etc.)", 
    "clean_text": "There are basically three kinds of approaches on sentence alignment: the length-based approach (Gale and Church 1991 and Brown et al 1991), the lexical approach (Roscheisen 1993), and the combination of them (Chen 1993, Wu 1994 and Langlais 1998, etc.).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W02-1211", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Le, Sun | Song, Xue | Weimin, Qu | Xiaofeng, Wang | Yufang, Sun", 
    "raw_text": "Chen (1993) combines the length-based approach and lexicon-based approach together", 
    "clean_text": "Chen (1993) combines the length-based approach and lexicon-based approach together.", 
    "keep_for_gold": 0
  }
]
