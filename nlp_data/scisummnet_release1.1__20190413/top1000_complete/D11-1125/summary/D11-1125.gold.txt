Tuning as Ranking
We offer a simple, effective, and scalable method for statistical machine translation parameter tuning based on the pairwise approach to ranking (Herbrich et al., 1999).
Unlike the popular MERT algorithm (Och, 2003), our pairwise ranking optimization (PRO) method is not limited to a handful of parameters and can easily handle systems with thousands of features.
Moreover, unlike recent approaches built upon the MIRA algorithm of Crammer and Singer (2003) (Watanabe et al., 2007; Chiang et al., 2008b), PRO is easy to implement.
It uses off-the-shelf linear binary classifier software and can be built on top of an existing MERT framework in a matter of hours.
We establish PROâ€™s scalability and effectiveness by comparing it to MERT and MIRA and demonstrate parity on both phrase-based and syntax-based systems in a variety of language pairs, using large scale data scenarios.
PRO casts the problem of tuning as a ranking problem between pairs of translation candidates.
We optimize ranking in n-best lists, but learn parameters in an online fashion.
We minimize logistic loss sampled from the merged n-bests, and sentence-BLEU is used for determining ranks.
