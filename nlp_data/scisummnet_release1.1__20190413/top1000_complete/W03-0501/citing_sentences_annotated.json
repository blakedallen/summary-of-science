[
  {
    "citance_No": 1, 
    "citing_paper_id": "P06-1139", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Radu, Soricut | Daniel, Marcu", 
    "raw_text": "A more common, extractive approach operates top-down, by starting from an extracted sentence that is compressed (Dorr et al, 2003) and annotated with additional information (Zajic et al, 2004)", 
    "clean_text": "A more common, extractive approach operates top-down, by starting from an extracted sentence that is compressed (Dorr et al, 2003) and annotated with additional information (Zajic et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P06-1139", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Radu, Soricut | Daniel, Marcu", 
    "raw_text": "HedgeTrimmer \u0006 is our implementation of the Hedge Trimer system (Dorr et al, 2003), and Topiary \u0007 is our implementation of the Topiary system (Zajicet al, 2004)", 
    "clean_text": "HedgeTrimmer is our implementation of the Hedge Trimer system (Dorr et al, 2003), and Topiary is our implementation of the Topiary system (Zajicet al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P13-1122", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Enrique, Alfonseca | Daniele, Pighin | Guillermo, Garrido", 
    "raw_text": "For this reason, most early headline generation work focused on either extracting and reordering n-grams from the document to be summarized (Banko et al., 2000), or extracting one or two informative sentences from the document and performing linguistically-motivated transformations to them in order to reduce the summary length (Dorr et al., 2003)", 
    "clean_text": "For this reason, most early headline generation work focused on either extracting and reordering n-grams from the document to be summarized (Banko et al., 2000), or extracting one or two informative sentences from the document and performing linguistically-motivated transformations to them in order to reduce the summary length (Dorr et al., 2003).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P11-3021", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Fahad, Alotaiby", 
    "raw_text": "Hedge Trimmer (Dorr et al, 2003) is a system that creates a headline for an English newspaper story using linguistically-motivated heuristics to choose a potential headline", 
    "clean_text": "Hedge Trimmer (Dorr et al, 2003) is a system that creates a headline for an English newspaper story using linguistically-motivated heuristics to choose a potential headline.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "E09-1048", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Itamar, Kastner | Christof, Monz", 
    "raw_text": "The algorithm used by Dorr et al (2003) removes subordinate clauses, to name one example", 
    "clean_text": "The algorithm used by Dorr et al (2003) removes subordinate clauses, to name one example.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W09-1801", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Andre, Martins | Noah A., Smith", 
    "raw_text": "Compressionratio ,i.e., the fraction of words included in the com pressed sentences, is 69.32% (micro-averaged over the training partition) .For comparison, two baselines were implemented: a simple compressor based on Hedge Trim mer, the headline generation system of Dorr et al (2003) and Zajic et al (2006) ,8 and the discrimina7Notice that this evaluation score is not able to properly capture the grammaticality of the compression; this is a known is sue that typically is addressed by requiring human judgments.8Hedge Trimmer applies a deterministic compression procedure whose first step is to identify the lowest leftmost S node in the parse tree that contains a NP and a VP; this node is taken as the root of the compressed sentence (i.e., all words that are not spanned by this node are discarded)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P13-1136", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Lu, Wang | Hema, Raghavan | Vittorio, Castelli | Radu, Florian | Claire, Cardie", 
    "raw_text": "Our compression models are compared with Hedge Trimmer (Dorr et al, 2003), a discriminative model proposed by McDonald (2006) and a 1391 System C Rate UniPrec UniRec UniF1 RelF1 HedgeTrimmer 57.64% 0.72 0.65 0.64 0.50 McDonald (2006) 70.95% 0.77 0.78 0.77 0.55 Martins and Smith (2009) 71.35% 0.77 0.78 0.77 0.56 Rule-based 87.65% 0.74 0.91 0.80 0.63 Sequence 70.79% 0.77 0.80 0.76 0.58 Tree (BASIC) 69.65% 0.77 0.79 0.75 0.56 Tree (CONTEXT) 67.01% 0.79 0.78 0.76 0.57 Tree (HEAD) 68.06% 0.79 0.80 0.77 0.59 Table 7: Sentence compression comparison", 
    "clean_text": "", 
    "keep_for_gold": 0
  }
]
