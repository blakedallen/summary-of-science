<PAPER>
	<S sid="0">Extracting Aspect-Evaluation and Aspect-Of Relations in Opinion Mining</S><ABSTRACT>
		<S sid="1" ssid="1">The technology of opinion extraction allowsusers to retrieve and analyze people?s opinions scattered over Web documents.</S>
		<S sid="2" ssid="2">We define an opinion unit as a quadruple consist ing of the opinion holder, the subject being evaluated, the part or the attribute in which the subject is evaluated, and the value of theevaluation that expresses a positive or neg ative assessment.</S>
		<S sid="3" ssid="3">We use this definition as the basis for our opinion extraction task.</S>
		<S sid="4" ssid="4">We focus on two important subtasks of opinion extraction: (a) extracting aspect-evaluationrelations, and (b) extracting aspect-of re lations, and we approach each task usingmethods which combine contextual and sta tistical clues.</S>
		<S sid="5" ssid="5">Our experiments on Japaneseweblog posts show that the use of contex tual clues improve the performance for both tasks.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number="1">
			<S sid="6" ssid="6">The explosive increase in Web communication hasattracted increasing interest in technologies for automatically mining personal opinions from Web doc uments such as product reviews and weblogs.</S>
			<S sid="7" ssid="7">Such technologies would benefit users who seek reviews on certain consumer products of interest.Previous approaches to the task of mining a large scale document collection of customer opinions (or ? Currently, NTT Cyber Space Laboratories, 1-1, Hikarinooka, Yokosuka, Kanagawa, 239-0847 Japanreviews) can be classified into two approaches: Doc ument classification and information extraction.</S>
			<S sid="8" ssid="8">Theformer is the task of classifying documents or pas sages according to their semantic orientation such aspositive vs. negative.</S>
			<S sid="9" ssid="9">This direction has been form ing the mainstream of research on opinion-sensitive text processing (Pang et al, 2002; Turney, 2002, etc.).</S>
			<S sid="10" ssid="10">The latter, on the other hand, focuses on the task of extracting opinions consisting of informationabout, for example, ?who feels how about which as pect of what product?</S>
			<S sid="11" ssid="11">from unstructured text data.In this paper, we refer to this information extraction oriented task as opinion extraction.</S>
			<S sid="12" ssid="12">In contrast to sentiment classification, opinion extraction aims atproducing richer information and requires an in depth analysis of opinions, which has only recently been attempted by a growing but still relatively small research community (Yi et al, 2003; Hu and Liu, 2004; Popescu and Etzioni, 2005, etc.).Most previous work on customer opinion ex traction assumes the source of information to be customer reviews collected from customer review sites (Popescu and Etzioni, 2005; Hu and Liu, 2004;Liu et al, 2005).</S>
			<S sid="13" ssid="13">In contrast, in this paper, we con sider the task of extracting customer opinions fromunstructured weblog posts.</S>
			<S sid="14" ssid="14">Compared with extrac tion from review articles, extraction from weblogs is more challenging because weblog posts tend toexhibit greater diversity in topics, goals, vocabulary, style, etc. and are much more likely to include descriptions irrelevant to the subject in question.</S>
			<S sid="15" ssid="15">In this paper, we first describe our task set ting of opinion extraction.</S>
			<S sid="16" ssid="16">We conducted a corpusstudy and investigated the feasibility of the task def 1065 inition by showing the statistics and inter-annotator agreement of our corpus annotation.</S>
			<S sid="17" ssid="17">Next, we showthat the crucial body of the above opinion extraction task can be decomposed into two kinds of relation extraction, i.e. aspect-evaluation relation extraction and aspect-of relation extraction.</S>
			<S sid="18" ssid="18">For exam ple, the passage ?I went out for lunch at the Deli and ordered a curry with chicken.</S>
			<S sid="19" ssid="19">It was pretty good?</S>
			<S sid="20" ssid="20">has an aspect-evaluation relation ?curry with chicken, was good?</S>
			<S sid="21" ssid="21">and an aspect-of relation ?The Deli, curry with the chicken?.</S>
			<S sid="22" ssid="22">The former task can be regarded as a special type of predicate-argument structure analysis or semantic role labeling.</S>
			<S sid="23" ssid="23">Thelatter, on the other hand, can be regarded as bridg ing reference resolution (Clark, 1977), which is the task of identifying relations between definite noun phrases and discourse-new entities implicitly related to some previously mentioned entities.</S>
			<S sid="24" ssid="24">Most of the previous work on customer opinionextraction, however, does not adopt the state-of-theart techniques in those fields, relying only on sim ple proximity-based or pattern-based methods.</S>
			<S sid="25" ssid="25">Inthis context, this paper empirically shows that incor porating machine learning-based techniques devisedfor predicate-argument structure analysis and bridg ing reference resolution improve the performanceof both aspect-evaluation and aspect-of relation extraction.</S>
			<S sid="26" ssid="26">Furthermore, we also show that combin ing contextual clues with a common co-occurrencestatistics-based technique for bridging reference resolution makes a significant improvement on aspect of relation extraction.</S>
	</SECTION>
	<SECTION title="Opinion extraction: Task design. " number="2">
			<S sid="27" ssid="1">Our present goal is to build a computational model to extract opinions from Web documents in such a form as: Who feels how on which aspects of which subjects.</S>
			<S sid="28" ssid="2">Given the passage presented in Figure 1, for example, the opinion we want to extract is: ?the writer feels that the colors of pictures taken with Powershot (product) are beautiful.?</S>
			<S sid="29" ssid="3">As suggested by this example, we consider it reasonable to start with an assumption that most evaluative opinionscan be structured as a frame composed of the fol lowing constituents:Opinion holder The person who is making an eval uation.</S>
			<S sid="30" ssid="4">An opinion holder is typically the first </S></SECTION></PAPER>
