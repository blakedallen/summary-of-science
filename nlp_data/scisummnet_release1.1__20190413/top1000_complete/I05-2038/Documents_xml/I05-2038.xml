<PAPER>
	<S sid="0">Syntax Annotation for the GENIA Corpus</S><ABSTRACT>
		<S sid="1" ssid="1">Linguistically annotated corpus based on texts in biomedical domain has been constructed to tune natural language processing (NLP) tools for bio textmining.</S>
		<S sid="2" ssid="2">As the focus of information extraction is shifting from "nominal" information such as named entity to "verbal" information such as function and interaction of substances, applica tion of parsers has become one of the key technologies and thus the corpus annotated for syntactic structure of sen tences is in demand.</S>
		<S sid="3" ssid="3">A subset of the GENIA corpus consisting of 500 MEDLINE abstracts has been annotated for syntactic structure in an XML based format based on Penn Treebank II (PTB) scheme.</S>
		<S sid="4" ssid="4">Inter-annotator agreement test indicated that the writ ing style rather than the contents of the research abstracts is the source of the difficulty in tree annotation, and that annotation can be stably done by linguists without much knowledge of bi ology with appropriate guidelines regarding to linguistic phenomena par ticular to scientific texts.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number="1">
			<S sid="5" ssid="5">Research and development for information extraction from biomedical literature (bio textmining) has been rapidly advancing due to demands caused by information overload in the genome-related field.</S>
			<S sid="6" ssid="6">Natural language process ing (NLP) techniques have been regarded as useful for this purpose.</S>
			<S sid="7" ssid="7">Now that focus of in formation extraction is shifting from extraction of ?nominal?</S>
			<S sid="8" ssid="8">information such as named entity to ?verbal?</S>
			<S sid="9" ssid="9">information such as relations of enti ties including events and functions, syntactic analysis is an important issue of NLP application in biomedical domain.</S>
			<S sid="10" ssid="10">In extraction of rela tion, the roles of entities participating in the relation must be identified along with the verb that represents the relation itself.</S>
			<S sid="11" ssid="11">In text analysis, this corresponds to identifying the subjects, ob jects, and other arguments of the verb.</S>
			<S sid="12" ssid="12">Though rule-based relation information ex traction systems using surface pattern matching and/or shallow parsing can achieve high precision (e.g. Koike et al, 2004) in a particular target domain, they tend to suffer from low recall due to the wide variation of the surface ex pression that describe a relation between a verb and its arguments.</S>
			<S sid="13" ssid="13">In addition, the portability of such systems is low because the system has to be re-equipped with different set of rules when different kind of relation is to be extracted.</S>
			<S sid="14" ssid="14">One solution to this problem is using deep parsers which can abstract the syntactic variation of a relation between a verb and its arguments repre sented in the text, and constructing extraction rule on the abstract predicate-argument structure.</S>
			<S sid="15" ssid="15">To do so, wide-coverage and high-precision parsers are required.</S>
			<S sid="16" ssid="16">While basic NLP techniques are relatively general and portable from domain to domain, customization and tuning are inevitable, especially in order to apply the techniques effec tively to highly specialized literatures such as research papers and abstracts.</S>
			<S sid="17" ssid="17">As recent advances in NLP technology depend on machine learning techniques, annotated corpora from which system can acquire rules (including grammar rules, lexicon, etc.) are indispensable 220 resources for customizing general-purpose NLP tools.</S>
			<S sid="18" ssid="18">In bio-textmining, for example, training on part-of-speech (POS)-annotated GENIA cor pus was reported to improve the accuracy of JunK tagger (English POS tagger) (Kazama et al., 2001) from 83.5% to 98.1% on MEDLINE abstracts (Tateisi and Tsujii, 2004), and the FraMed corpus (Wermter and Hahn, 2004) was used to train TnT tagger on German (Brants, 2000) to improve its accuracy from 95.7% to 98% on clinical reports and other biomedical texts.</S>
			<S sid="19" ssid="19">Corpus annotated for syntactic structures is expected to play a similar role in tuning parsers to biomedical domain, i.e., similar improve ment on the performance of parsers is expected by using domain-specific treebank as a resource for learning.</S>
			<S sid="20" ssid="20">For this purpose, we construct GENA Treebank (GTB), a treebank on research abstracts in biomedical domain.</S>
	</SECTION>
	<SECTION title="Outline of the Corpus. " number="2">
			<S sid="21" ssid="1">The base text of GTB is that of the GENIA cor pus constructed at University of Tokyo (Kim et al., 2003), which is a collection of research ab stracts selected from the search results of MEDLINE database with keywords (MeSH terms) human, blood cells and transcription factors.</S>
			<S sid="22" ssid="2">In the GENIA corpus, the abstracts are en coded in an XML scheme where each abstract is numbered with MEDLINE UID and contains title and abstract.</S>
			<S sid="23" ssid="3">The text of title and abstract is segmented into sentences in which biological terms are annotated with their semantic classes.</S>
			<S sid="24" ssid="4">The GENIA corpus is also annotated for part-of speech (POS) (Tateisi and Tsujii, 2004), and coreference is also annotated in a part of the GENIA corpus by MedCo project at Institute for Infocomm Research, Singapore (Yang et al 2004).</S>
			<S sid="25" ssid="5">GTB is the addition of syntactic information to the GENIA corpus.</S>
			<S sid="26" ssid="6">By annotating various linguistic information on a same set of text, the GENIA corpus will be a resource not only for individual purpose such as named entity extrac tion or training parsers but also for integrated systems such as information extraction using deep linguistic analysis.</S>
			<S sid="27" ssid="7">Similar attempt of con structing integrated corpora is being done in University of Pennsylvania, where a corpus of MEDLINE abstracts in CYP450 and oncology domains where annotated for named entities, POS, and tree structure of sentences (Kulick et al, 2004).</S>
			<S sid="28" ssid="8">2.1 Annotation Scheme.</S>
			<S sid="29" ssid="9">The annotation scheme basically follows the Penn Treebank II (PTB) scheme (Beis et al 1995), encoded in XML.</S>
			<S sid="30" ssid="10">A non-null constituent is marked as an element, with its syntactic cate gory (which may be combined with its function tags indicating grammatical roles such as -SBJ, -PRD, and -ADV) used as tags.</S>
			<S sid="31" ssid="11">A null constitu ent is marked as a childless element whose tag corresponds to its categories.</S>
			<S sid="32" ssid="12">Other function tags are encoded as attributes.</S>
			<S sid="33" ssid="13">Figure 1 shows an ex ample of annotated sentence in XML, and the corresponding PTB notation.</S>
			<S sid="34" ssid="14">The label ?S? means ?sentence?, ?NP?</S>
			<S sid="35" ssid="15">noun phrase, ?PP?</S>
			<S sid="36" ssid="16">prepositional phrase, and ?VP?</S>
			<S sid="37" ssid="17">verb phrase.</S>
			<S sid="38" ssid="18">The label ?NP-SBJ?</S>
			<S sid="39" ssid="19">means that the element is an NP that serves as the subject of the sentence.</S>
			<S sid="40" ssid="20">A null element, the trace of the object of ?stud ied?</S>
			<S sid="41" ssid="21">moved by passivization, is denoted by ? &lt;NP NULL="NONE" ref="i55"/&gt;?</S>
			<S sid="42" ssid="22">in XML and ?*-55?</S>
			<S sid="43" ssid="23">in PTB notation.</S>
			<S sid="44" ssid="24">The number ?55?</S>
			<S sid="45" ssid="25">which refers to the identifier of the moved ele ment, is denoted by ?id? and ?ref?</S>
			<S sid="46" ssid="26">attributes in XML, and is denoted as a part of a label in PTB.</S>
			<S sid="47" ssid="27">In addition to changing the encoding, we made some modifications to the scheme.</S>
			<S sid="48" ssid="28">First, analysis within the noun phrase is simplified.</S>
			<S sid="49" ssid="29">Second, semantic division of adverbial phrases such as ??TMP?</S>
			<S sid="50" ssid="30">(time) and ??MNR?</S>
			<S sid="51" ssid="31">(manner) are not used: adverbial constituents other than ?ADVP?</S>
			<S sid="52" ssid="32">(adverbial phrases) or ?PP?</S>
			<S sid="53" ssid="33">used ad verbially are marked with ?ADV tags but not with semantic tags.</S>
			<S sid="54" ssid="34">Third, a coordination struc ture is explicitly marked with the attribute SYN=?COOD?</S>
			<S sid="55" ssid="35">whereas in the original PTB scheme it is not marked as such.</S>
			<S sid="56" ssid="36">In our GTB scheme, ?NX?</S>
			<S sid="57" ssid="37">(head of a com plex noun phrase) and ?NAC?</S>
			<S sid="58" ssid="38">(a certain kind of nominal modifier within a noun phrase) of the PTB scheme are not used.</S>
			<S sid="59" ssid="39">A noun phrase is gen erally left unstructured.</S>
			<S sid="60" ssid="40">This is mainly in order to simplify the process of annotation.</S>
			<S sid="61" ssid="41">In case of biomedical abstracts, long noun phrases often involve multi-word technical terms whose syn tactic structure is difficult to determine without deep domain knowledge.</S>
			<S sid="62" ssid="42">However, the structure of noun phrases are usually independent of the structure outside the phrase, so that it would be 221 easier to analyze the phrases involving such terms independently (e.g. by biologists) and later merge the two analysis together.</S>
			<S sid="63" ssid="43">Thus we have decided that we leave noun phrases unstructured in GTB annotation unless their analy sis is necessary for determining the structure outside the phrase.</S>
			<S sid="64" ssid="44">One of the exception is the cases that involves coordination where it is nec essary to explicitly mark up the coordinated constituents.</S>
			<S sid="65" ssid="45">In addition, we have added special attributes ?TXTERR?, ?UNSURE?, and ?COMMENT?</S>
			<S sid="66" ssid="46">for later inspection.</S>
			<S sid="67" ssid="47">The ?TXTERR?</S>
			<S sid="68" ssid="48">is used when the annotator suspects that there is a grammatical error in the original text; the ?UNSURE?</S>
			<S sid="69" ssid="49">attribute is used when the annotator is not confident; and the ?COMMENT?</S>
			<S sid="70" ssid="50">is used for free comments (e.g. reason of using ?UNSURE?)</S>
			<S sid="71" ssid="51">by the annotator.</S>
			<S sid="72" ssid="52">2.2 Annotation Process.</S>
			<S sid="73" ssid="53">The sentences in the titles and abstracts of the base text of GENIA corpus are annotated manu ally using an XML editor used for the Global Document Annotation project (Hasida 2000).</S>
			<S sid="74" ssid="54">Although the sentence boundaries were adopted from the corpus, the tree structure annotation was done independently of POS- and term- an notation already done on the GENIA corpus.</S>
			<S sid="75" ssid="55">The annotator was a Japanese non-biologist who has previously involved in the POS annotation of the GENIA corpus and accustomed to the style of research abstracts in English.</S>
			<S sid="76" ssid="56">Manually annotated abstracts are automatically converted to the PTB format, merged with the POS annota tion of the GENIA corpus (version 3.02).</S>
	</SECTION>
	<SECTION title="Annotation Results. " number="3">
			<S sid="77" ssid="1">So far, 500 abstracts are annotated and converted to the merged PTB format.</S>
			<S sid="78" ssid="2">In the merg ing process, we found several annotation errors.</S>
			<S sid="79" ssid="3">The 500 abstracts with correction of these errors are made publicly available as ?The GENIA Treebank Beta Version?</S>
			<S sid="80" ssid="4">(GTB-beta).</S>
			<S sid="81" ssid="5">For further clean-up, we also tried to parse the corpus by the Enju parser (Miyao and Tsujii 2004), and identify the error of the corpus by investigating into the parse errors.</S>
			<S sid="82" ssid="6">Enju is an HPSG parser that can be trained with PTB-type corpora which is reported to have 87% accuracy on Wall Street Journal portion of Penn Treebank corpus.</S>
			<S sid="83" ssid="7">Currently the accuracy of the parser drops down to 82% on GTB-beta, and although proper quantitative analysis is yet to be done, it was found that the mismatches between labels of the treebank and the GENIA POS corpus (e.g. an ?ing form labeled as noun in the POS corpus and as the head of a verb phrase in the tree corpus) are a major source of parse error.</S>
			<S sid="84" ssid="8">The cor rection is complicated because several errors in the GENIA POS corpus were found in this cleaning-up process.</S>
			<S sid="85" ssid="9">When the cleaning-up process is done, we will make the corpus pub licly available as the proper release.</S>
			<S sid="86" ssid="10">&lt;S&gt;&lt;PP&gt;In &lt;NP&gt;the present paper &lt;/NP&gt;&lt;/PP&gt;, &lt;NP-SBJ id="i55"&gt;&lt;NP&gt;the binding &lt;/NP&gt;&lt;PP&gt;of &lt;NP&gt;a [125I]-labeled aldosterone derivative &lt;/NP&gt;&lt;/PP&gt;&lt;PP&gt;to &lt;NP&gt;&lt;NP&gt;plasma membrane rich fractions &lt;/NP&gt;&lt;PP&gt;of HML &lt;/PP&gt;&lt;/NP&gt;&lt;/PP&gt;&lt;/NP-SBJ&gt;&lt;VP&gt;was &lt;VP&gt;studied &lt;NP NULL="NONE" ref="i55"/&gt;&lt;/VP&gt; &lt;/VP&gt;.&lt;/S&gt;</S>
	</SECTION>
	<SECTION title="Inter-Annotator Agreement. " number="4">
			<S sid="87" ssid="1">We have also checked inter-annotator agreement.</S>
			<S sid="88" ssid="2">Although the PTB scheme is popular among natural language processing society, applicabil ity of the scheme to highly specialized text such as research abstract is yet to be discussed.</S>
			<S sid="89" ssid="3">Espe cially, when the annotation is done by linguists, lack of domain knowledge might decrease the stability and accuracy of annotation.</S>
			<S sid="90" ssid="4">A small part of the base text set (10 ab stracts) was annotated by another annotator.</S>
			<S sid="91" ssid="5">The 10 abstracts were chosen randomly, had 6 to 17 sentences per abstract (total 108 sentences).</S>
			<S sid="92" ssid="6">The new annotator had a similar background as the first annotator that she is a Japanese non biologist who has experiences in translation of (S (PP In (NP the present paper)), (NP-SBJ-55 (NP the binding) (PP of (NP a [125I]-labeled aldosterone derivative)) (PP to (NP (NP plasma membrane rich fractions) (PP of HML)))) (VP was (VP studied * 55)).)</S>
			<S sid="93" ssid="7">Figure 1.</S>
			<S sid="94" ssid="8">The sentence ?In the present paper, the binding of a [125I]-labeled aldosterone derivative to plasma mem brane rich fractions of HML was studied?</S>
			<S sid="95" ssid="9">annotated in XML and PTB formats.</S>
			<S sid="96" ssid="10">222 technical documents in English and in corpus annotation of English texts.</S>
			<S sid="97" ssid="11">The two results were examined manually, and there were 131 disagreements.</S>
			<S sid="98" ssid="12">Almost every sentence had at least one disagreement.</S>
			<S sid="99" ssid="13">We have made the ?gold standard?</S>
			<S sid="100" ssid="14">from the two sets of abstracts by resolving the disagreements, and the accuracy of the annotators against this gold standard were 96.7% for the first annotator and 97.4% for the second annotator.</S>
			<S sid="101" ssid="15">Of the disagreement, the most prominent were the cases involving coordination, espe cially the ones with ellipsis.</S>
			<S sid="102" ssid="16">For example, one annotator annotated the phrase ?IL-1- and IL-18 mediated function?</S>
			<S sid="103" ssid="17">as in Figure 2a, the other annotated as Figure 2b.</S>
			<S sid="104" ssid="18">Such problem is addressed in the PTB guideline and both formats are allowed as alter natives.</S>
			<S sid="105" ssid="19">As coordination with ellipsis occurs rather frequently in research abstracts, this kind of phenomena has higher effect on decrease of the agreement rate than in Penn Treebank.</S>
			<S sid="106" ssid="20">Of the 131 disagreements, 25 were on this type of coordination.</S>
			<S sid="107" ssid="21">Another source of disagreement is the at tachment of modifiers such as prepositional phrases and pronominal adjectives.</S>
			<S sid="108" ssid="22">However, most are ?benign ambiguity?</S>
			<S sid="109" ssid="23">where the difference of the structure does not affect on interpre tation, such as ?high expression of STAT in monocytes?</S>
			<S sid="110" ssid="24">where the prepositional phrase ?in monocytes?</S>
			<S sid="111" ssid="25">can attach to ?expression?</S>
			<S sid="112" ssid="26">or ?STAT?</S>
			<S sid="113" ssid="27">without much difference in meaning, and ?is augmented when the sensitizing tumor is a genetically modified variant?</S>
			<S sid="114" ssid="28">where the whclause can attach to ?is augmented?</S>
			<S sid="115" ssid="29">or ?aug mented?</S>
			<S sid="116" ssid="30">without changing the meaning.</S>
			<S sid="117" ssid="31">The PTB guideline states that the modifier should be attached at the higher level in the former case and at the lower case in the latter.</S>
			<S sid="118" ssid="32">In the annota tion results, one annotator consistently attached the modifiers in both cases at the higher level, and the other consistently at the lower level, in dicating that the problem is in understanding the scheme rather than understanding the sentence.</S>
			<S sid="119" ssid="33">Only 15 cases were true ambiguities that needed knowledge of biology to solve, in which 5 in volved coordination (e.g., the scope of ?various?</S>
			<S sid="120" ssid="34">in ?various T cell lines and peripheral blood cells?)</S>
			<S sid="121" ssid="35">Although the number was small, there were disagreements on how to annotate a mathematical formula such as ?n=2?</S>
			<S sid="122" ssid="36">embedded in the sen tence, since mathematical formulae were outside the scope of the original PTB scheme.</S>
			<S sid="123" ssid="37">One annotator annotated this kind of phrase consis tently as a phrase with ?=?</S>
			<S sid="124" ssid="38">as an adjective, the other annotated as phrase with ?=?</S>
			<S sid="125" ssid="39">as a verb.</S>
			<S sid="126" ssid="40">There were 6 such cases.</S>
			<S sid="127" ssid="41">Another disagreement particular to abstracts is a treatment of labeled sentences.</S>
			<S sid="128" ssid="42">There were 8 sentences in two ab stracts where there is a label like ?Background:?.</S>
			<S sid="129" ssid="43">One annotator included the colon (?:?)</S>
			<S sid="130" ssid="44">in the la bel, while the other did not.</S>
			<S sid="131" ssid="45">Yet another is that one regarded the phrase ?Author et al as coor dination, and the other regarded ?et al as a modifier.</S>
			<S sid="132" ssid="46">&lt;NP SYN="COOD"&gt; &lt;NP&gt;&lt;ADJP&gt;IL-1- &lt;ADJP NULL="QSTN"/&gt;&lt;/ADJP&gt; &lt;NP NULL="RNR" ref="i20"/&gt;&lt;/NP&gt; and &lt;NP&gt;IL-18-mediated &lt;NP NULL="RNR" ref="i20"/&gt;&lt;/NP&gt; &lt;NP id="i20"&gt;function &lt;/NP&gt; Other disagreements are more general type such as regarding ?-ed?</S>
			<S sid="133" ssid="47">form of a verb as an ad jective or a participle, miscellaneous errors such as omission of a subtype of label (such as ? PRD?</S>
			<S sid="134" ssid="48">or ?-SBJ) or the position of &lt;PRN&gt; tags &lt;NP&gt; &lt;ADJP SYN="COOD"&gt; &lt;ADJP&gt;IL-1- &lt;ADJP NULL="QSTN"/&gt;&lt;/ADJP&gt; and &lt;ADJP&gt;IL-18-mediated &lt;/ADJP&gt;&lt;/ADJP&gt; function &lt;/NP&gt; NP ADJP Function ADJP and ADJP IL-1 * IL-18 mediated Figure 2a.</S>
			<S sid="135" ssid="49">Annotation of a coordinated phrase by the first annotator.</S>
			<S sid="136" ssid="50">A* denotes a null constituent.</S>
			<S sid="137" ssid="51">&lt;/NP&gt; NP NP And NP ADJP *20 IL-18 meidiated NP IL-1 * function20 Figure 2b.</S>
			<S sid="138" ssid="52">Annotation of the same phrase as in Figure 2a by the second annotator.</S>
			<S sid="139" ssid="53">A * denotes a null constituent and ?20?</S>
			<S sid="140" ssid="54">denotes coindexing.</S>
			<S sid="141" ssid="55">223 with regards to ?,?</S>
			<S sid="142" ssid="56">for the inserted phrase, or the errors which look like just ?careless?.</S>
			<S sid="143" ssid="57">Such dis agreements and mistakes are at least partially eliminated when reliable taggers and parsers are available for preprocessing</S>
	</SECTION>
	<SECTION title="Discussion. " number="5">
			<S sid="144" ssid="1">The result of the inter-annotator agreement test indicates that the writing style rather than the contents of the research abstracts is the source of the difficulty in tree annotation.</S>
			<S sid="145" ssid="2">Con trary to the expectation that the lack of domain knowledge causes a problem in annotation on attachments of modifiers, the number of cases where annotation of modifier attachment needs domain knowledge is small.</S>
			<S sid="146" ssid="3">This indicates that linguists can annotate most of syntactic structure without an expert level of domain knowledge.</S>
			<S sid="147" ssid="4">A major source of difficulty is coordination, especially the ones involving ellipsis.</S>
			<S sid="148" ssid="5">Coordination is reported to be difficult phenomena in an notation of different levels in the GENIA corpus (Tateisi and Tsujii, 2004), (Kim et al, 2003).</S>
			<S sid="149" ssid="6">In addition to the fact that this is the major source of inter-annotator agreement, the annotator often commented the coordinated structure as ?unsure?.</S>
			<S sid="150" ssid="7">The problem of coordination can be divided into two with different nature: one is that the annota tion policy is still not well-established for the coordination involving ellipsis, and the other is an ambiguity when the coordinated phrase has modifiers.</S>
			<S sid="151" ssid="8">Syntax annotation of coordination with ellipsis is difficult in general but the more so in an notation of abstracts than in the case of general texts, because in abstracts authors tend to pack information in limited number of words.</S>
			<S sid="152" ssid="9">The PTB guideline dedicates a long section for this phenomena and allows alternatives in annotation, but there are still cases which are not well covered by the scheme.</S>
			<S sid="153" ssid="10">For example, in addition to the disagreement, the phrase illustrated in Figure 2a and Figure 2b shows another problem of the annotation scheme.</S>
			<S sid="154" ssid="11">Both annotators fail to indicate that it is ?mediated?</S>
			<S sid="155" ssid="12">that was to be after ?IL-1?</S>
			<S sid="156" ssid="13">because there is no mechanism of coindexing a null element with a part of a token.</S>
			<S sid="157" ssid="14">This problem of ellipsis can frequently occur in research abstracts, and it can be argued that the tokenization criteria must be changed for texts in biomedical domain (Yamamoto and Sa tou, 2004) so that such fragment as ?IL-18?</S>
			<S sid="158" ssid="15">and ?mediated?</S>
			<S sid="159" ssid="16">in ?IL-18-ediated?</S>
			<S sid="160" ssid="17">should be regarede as separate tokens.</S>
			<S sid="161" ssid="18">The Pennsylvania biology corpus (Kulick et al, 2004) partially solves this problem by separating a token where two or more subtokens are connected with hyphens, but in the cases where a shared part of the word is not separated by a hyphen (e.g. ?metric?</S>
			<S sid="162" ssid="19">of ?ste reo- and isometric alleles?)</S>
			<S sid="163" ssid="20">the word including the part is left uncut.</S>
			<S sid="164" ssid="21">The current GTB follows the GENIA corpus that it retains the tokeniza tion criteria of the original Penn Treebank, but this must be reconsidered in future.</S>
			<S sid="165" ssid="22">For analysis of coordination with ellipsis, if the information on full forms is available, one strategy would be to leave the inside structure of coordination unannotated in the treebank corpus (and in the phase of text analysis the structure is not established in the phase of parsing but with a different mechanism) and later merge it with the coordination structure annotation.</S>
			<S sid="166" ssid="23">The GENIA term corpus annotates the full form of a techni cal term whose part is omitted in the surface as an attribute of the ?&lt;cons&gt;?</S>
			<S sid="167" ssid="24">element indicating a technical term (Kim et al, 2003).</S>
			<S sid="168" ssid="25">In the above mentioned Pennsylvania corpus, a similar mechanism (?chaining?)</S>
			<S sid="169" ssid="26">is used for recovering the full form of named entities.</S>
			<S sid="170" ssid="27">However, in both corpora, no such information is available outside the terms/entities.</S>
			<S sid="171" ssid="28">The cases where scope of modification in coordinated phrases is problematic are few but they are more difficult in abstracts than in gen eral texts because the resolution of ambiguity needs domain knowledge.</S>
			<S sid="172" ssid="29">If term/entity annota tion is already done, that information can help resolve this type of ambiguity, but again the problem is that outside the terms/entities such information is not available.</S>
			<S sid="173" ssid="30">It would be practi cal to have the structure flat but specially marked when the tree annotators are unsure and have a domain expert resolve the ambiguity, as the sentences that needs such intervention seems few.</S>
			<S sid="174" ssid="31">Some cases of ambiguity in modifier at tachment (which do not involve coordination) can be solved with similar process.</S>
			<S sid="175" ssid="32">We believe that other type of disagreements can be solved with supplementing criteria for linguistic phenomena not well-covered by the scheme, and annotator training.</S>
			<S sid="176" ssid="33">Automatic pre processing by POS taggers and parsers can also help increase the consistent annotation.</S>
			<S sid="177" ssid="34">224</S>
	</SECTION>
	<SECTION title="Conclusion. " number="6">
			<S sid="178" ssid="1">A subset of the GENIA corpus is annotated for syntactic (tree) structure.</S>
			<S sid="179" ssid="2">Inter-annotator agreement test indicated that the annotation can be done stably by linguists without much knowledge in biology, provided that proper guideline is established for linguistic phenomena particular to scientific research abstracts.</S>
			<S sid="180" ssid="3">We have made the 500-abstract corpus in both XML and PTB formats and made it publicly available as ?the GENIA Treebank beta version?</S>
			<S sid="181" ssid="4">(GTB beta).</S>
			<S sid="182" ssid="5">We are in further cleaning up process of the 500-abstract set, and at the same time, initial annotation of the remaining abstracts is being done, so that the full GENIA set of 2000 ab stracts will be annotated with tree structure.</S>
			<S sid="183" ssid="6">For parsers to be useful for information ex traction, they have to establish a map between syntactic structure and more semantic predicate argument structure, and between the linguistic predicate-argument structures to the factual relation to be extracted.</S>
			<S sid="184" ssid="7">Annotation of various in formation on a same set of text can help establish these maps.</S>
			<S sid="185" ssid="8">For the factual relations, we are annotating relations between proteins and genes in cooperation with a group of biologists.</S>
			<S sid="186" ssid="9">For predicate-argument annotation, we are in vestigating the use of the parse results of the Enju parser.</S>
			<S sid="187" ssid="10">Acknowledgments The authors are grateful to annotators and colleagues that helped the construction of the corpus.</S>
			<S sid="188" ssid="11">This work is partially supported by Grant in-Aid for Scientific Research on Priority Area C ?Genome Information Science?</S>
			<S sid="189" ssid="12">from the Min istry of Education, Culture, Sports, Science and Technology of Japan.</S>
	</SECTION>
</PAPER>
