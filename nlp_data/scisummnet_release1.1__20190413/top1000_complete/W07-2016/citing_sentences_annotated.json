[
  {
    "citance_No": 1, 
    "citing_paper_id": "P08-1063", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Be&ntilde;at, Zapirain | Eneko, Agirre | Llu&iacute;s, M&agrave;rquez", 
    "raw_text": "because the SemEval-2007 competition (Pradhan et al, 2007) was performed using this configuration. Being aware that, in a real scenario, the sense information will not be available, we devised the second setting (? CoNLL?), where the hand-annotated verb sense information was discarded", 
    "clean_text": "We call this setting 'SemEval' because the SemEval-2007 competition (Pradhan et al, 2007) was performed using this configuration.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-2087", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Tong, Wang | Graeme, Hirst", 
    "raw_text": "Various aspects of the model discussed in Section 3 are evaluated in the English lexical sample tasks from Senseval2 (Edmonds and Cotton, 2001) and SemEval2007 (Pradhan et al, 2007)", 
    "clean_text": "Various aspects of the model discussed in Section 3 are evaluated in the English lexical sample tasks from Senseval2 (Edmonds and Cotton, 2001) and SemEval2007 (Pradhan et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "E09-1073", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Marius, Pa&scedil;ca", 
    "raw_text": "Second ,choosing the first sense from WordNet is sometimes better than more intelligent disambiguation techniques (Pradhan et al, 2007)", 
    "clean_text": "Various aspects of the model discussed in Section 3 are evaluated in the English lexical sample tasks from Senseval2 (Edmonds and Cotton, 2001) and SemEval2007 (Pradhan et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "E09-1006", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Eneko, Agirre | Oier, L&oacute;pez de Lacalle", 
    "raw_text": "Given that the WSD literature shows that all features are necessary for optimal performance (Pradhan et al, 2007), we propose the following alternative to construct the matrix", 
    "clean_text": "Given that the WSD literature shows that all features are necessary for optimal performance (Pradhan et al, 2007), we propose the following alternative to construct the matrix.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W09-2410", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Weiwei, Guo | Mona, Diab", 
    "raw_text": "We experiment with all the standard data sets, namely, Senseval 2 (SV2) (M. Palmer and Dang, 2001), Senseval 3 (SV3) (Snyder and Palmer, 2004), and SEMEVAL (SM) (Pradhan et al, 2007) English All Words data sets", 
    "clean_text": "We experiment with all the standard data sets, namely, Senseval 2 (SV2) (M. Palmer and Dang, 2001), Senseval 3 (SV3) (Snyder and Palmer, 2004), and SEMEVAL (SM) (Pradhan et al, 2007) English All Words data sets.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "C10-1013", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Bernard, Brosseau-Villeneuve | Jian-Yun, Nie | Noriko, Kando", 
    "raw_text": "English Lexical Sample The Semeval workshop holds WSD tasks such as the English Lexical Sample (ELS) (Pradhan et al, 2007)", 
    "clean_text": "English Lexical Sample The Semeval workshop holds WSD tasks such as the English Lexical Sample (ELS) (Pradhan et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "C10-1013", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Bernard, Brosseau-Villeneuve | Jian-Yun, Nie | Noriko, Kando", 
    "raw_text": "It outperforms most of the systems participating in the task (Pradhan et al., 2007)", 
    "clean_text": "It outperforms most of the systems participating in the task (Pradhan et al., 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W10-2309", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Christian, Biemann", 
    "raw_text": "Experimental results are provided for two datasets: the Semeval-2007 lexical sample task (Pradhanetal., 2007) and the Turk bootstrap Word Sense Inventory (TWSI1, (Biemann and Nygaard, 2010))", 
    "clean_text": "Experimental results are provided for two datasets: the Semeval-2007 lexical sample task (Pradhanetal., 2007) and the Turk bootstrap Word Sense Inventory (TWSI1, (Biemann and Nygaard, 2010)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W10-2309", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Christian, Biemann", 
    "raw_text": "On the 204 ambiguous words (595 total senses with 46 sentences per sense on average) of the TWSI only, the best system was found at k=5 with a System F1 NUS-ML 88.7%? 1.2top3 cluster, optimal F1 88.0%? 1.2top3 cluster, max recall 87.8%? 1.2 baseline, optimal F1 87.5%? 1.2 baseline, max recall 87.3%? 1.2 UBC-ALM 86.9%? 1.2Table 1: Cluster co-occurrence features and base line in comparison to the best two systems in the SemEval 2007 Task 17 Lexical Sample evaluation (Pradhan et al, 2007)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "N10-1053", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mark, Stevenson | Yikun, Guo", 
    "raw_text": "In this paper the relevance feedback approach described by Stevenson et al (2008a) is evaluated using three data sets: the NLM-WSD corpus (Weeber et al, 2001) which Stevenson et al (2008a) used for their experiments, the Senseval-3 lexical sample task (Mihalcea et al, 2004) and the coarse grained version of the SemEval English lexical sample task (Pradhan et al, 2007)", 
    "clean_text": "In this paper the relevance feedback approach described by Stevenson et al (2008a) is evaluated using three data sets: the NLM-WSD corpus (Weeber et al, 2001) which Stevenson et al (2008a) used for their experiments, the Senseval-3 lexical sample task (Mihalcea et al, 2004) and the coarse grained version of the SemEval English lexical sample task (Pradhan et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "D11-1051", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Weiwei, Guo | Mona, Diab", 
    "raw_text": "We prefer SemCor to all-words datasets available in Senseval-3 (Snyder and Palmer, 2004) or SemEval-2007 (Pradhan et al, 2007), since it includes many more documents than either set (350 versus 3) and therefore allowing more reliable results", 
    "clean_text": "We prefer SemCor to all-words datasets available in Senseval-3 (Snyder and Palmer, 2004) or SemEval-2007 (Pradhan et al, 2007), since it includes many more documents than either set (350 versus 3) and therefore allowing more reliable results.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "S10-1084", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Bernard, Brosseau-Villeneuve | Noriko, Kando | Jian-Yun, Nie", 
    "raw_text": "Lexical Sample The Semeval workshop holds WSD tasks such as the English Lexical Sample (ELS) (Pradhan et al, 2007)", 
    "clean_text": "Lexical Sample The Semeval workshop holds WSD tasks such as the English Lexical Sample (ELS) (Pradhan et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "S10-1084", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Bernard, Brosseau-Villeneuve | Noriko, Kando | Jian-Yun, Nie", 
    "raw_text": "Theimprovements seen using our system are substantial, beating most of the systems originally pro posed for the task (Pradhan et al, 2007)", 
    "clean_text": "The improvements seen using our system are substantial, beating most of the systems originally proposed for the task (Pradhan et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W10-2803", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Katrin, Erk", 
    "raw_text": "The use of coarse-grained sense groups (Palmer et al, 2007) has led to considerable advances in WSD performance, with accuracies of around 90% (Pradhan et al, 2007)", 
    "clean_text": "The use of coarse-grained sense groups (Palmer et al, 2007) has led to considerable advances in WSD performance, with accuracies of around 90% (Pradhan et al, 2007).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "C08-1003", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Eneko, Agirre | Oier, L&oacute;pez de Lacalle", 
    "raw_text": "Given that the WSDliterature has shown that all features, including local and syntactic features, are necessary for optimal performance (Pradhan et al, 2007), we propose the following alternative to construct the matrix", 
    "clean_text": "Given that the WSD literature has shown that all features, including local and syntactic features, are necessary for optimal performance (Pradhan et al, 2007), we propose the following alternative to construct the matrix.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D09-1029", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Sara, Tonelli | Claudio, Giuliano", 
    "raw_text": "The algorithm proved effective at Senseval-3 (Mihalcea and Edmonds, 2004) and, nowadays, it still represents the state-of-the-art in WSD (Pradhan et al, 2007) .Specifically, they addressed these issues: (i) independently modeling domain and syntagmatic aspects of sense distinction to improve feature representativeness; and (ii) exploiting external knowledge acquired from unlabeled data, with the purpose of drastically reducing the amount of labeled 3http: //download.wikimedia.org/enwiki/ 20090306 4 A context corresponds to a line of text in the Wikipediadump and it is represented as a paragraph in a Wikipediaarticle", 
    "clean_text": "The algorithm proved effective at Senseval-3 (Mihalcea and Edmonds, 2004) and, nowadays, it still represents the state-of-the-art in WSD (Pradhan et al, 2007). Specifically, they addressed these issues: (i) independently modeling domain and syntagmatic aspects of sense distinction to improve feature representativeness; and (ii) exploiting external knowledge acquired from unlabeled data, with the purpose of drastically reducing the amount of labeled 3http: //download.wikimedia.org/enwiki/ 20090306 4 A context corresponds to a line of text in the Wikipedia dump and it is represented as a paragraph in a Wikipedia article.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "S12-1014", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Sanja, Fidler | Wesley, May | Afsaneh, Fazly | Sven, Dickinson | Suzanne, Stevenson", 
    "raw_text": "For unsupervised WSD (applied to text only), we use WordNet: :SenseRelate: :TargetWord, here after PBP (Patwardhan et al, 2007), the highest scoring unsupervised lexical sample word sense disambiguation algorithm at SemEval07 (Pradhan et al., 2007)", 
    "clean_text": "For unsupervised WSD (applied to text only), we use WordNet: :SenseRelate: :TargetWord, here after PBP (Patwardhan et al, 2007), the highest scoring unsupervised lexical sample word sense disambiguation algorithm at SemEval07 (Pradhan et al., 2007).", 
    "keep_for_gold": 0
  }
]
