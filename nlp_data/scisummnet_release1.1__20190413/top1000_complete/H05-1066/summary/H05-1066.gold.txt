Non-Projective Dependency Parsing Using Spanning Tree Algorithms
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
Using this representation, the parsing algorithm of Eisner (1996) is sufficient for searching over all projective trees in O(n3) time.
More surprisingly, the representation is extended naturally to non-projective parsing using Chu-Liu-Edmonds (Chu and Liu, 1965; Edmonds, 1967) MST algorithm, yielding an O(n2) parsing algorithm.
We evaluate these methods on the Prague Dependency Treebank using online large-margin learning techniques (Crammer et al., 2003; McDonald et al., 2005) and show that MST parsing increases efficiency and accuracy for languages with non-projective dependencies.
The key idea is to build a complete graph consisting of tokens of the sentence where each edge is weighted by a learned scoring function.
