[
  {
    "citance_No": 1, 
    "citing_paper_id": "P14-3010", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Clayton, Greenberg", 
    "raw_text": "Although some parse tree sin the corpus are known to have errors, the accuracy figures do not take this into account. Also, Ratnaparkhi et al (1994) conducted human experiments with a subset of their corpus", 
    "clean_text": "Also, Ratnaparkhi et al (1994) conducted human experiments with a subset of their corpus.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-3010", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Clayton, Greenberg", 
    "raw_text": "The perhaps underwhelming human performance is partially due to misclassifications by the Treebank assemblers who made these determinations by hand, and also unclear cases, which we discuss in the next sec tion. Collins and Brooks (1995) introduced modifications to the Ratnaparkhi et al (1994) dataset meant to combat data sparsity and used the modified version to train their backed-off model", 
    "clean_text": "Collins and Brooks (1995) introduced modifications to the Ratnaparkhi et al (1994) dataset meant to combat data sparsity and used the modified version to train their backed-off model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P14-3010", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Clayton, Greenberg", 
    "raw_text": "Stetina and Nagao (1997) trained on a version of the Ratnaparkhi et al (1994) dataset that contained modifications similar to those by Collins and Brooks (1995) and excluded forms not present in WordNet", 
    "clean_text": "Stetina and Nagao (1997) trained on a version of the Ratnaparkhi et al (1994) dataset that contained modifications similar to those by Collins and Brooks (1995) and excluded forms not present in WordNet.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P14-3010", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Clayton, Greenberg", 
    "raw_text": "The system achieved 89.0% on a similarly modified Ratnaparkhi et al (1994) dataset", 
    "clean_text": "The system achieved 89.0% on a similarly modified Ratnaparkhi et al (1994) dataset.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P14-3010", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Clayton, Greenberg", 
    "raw_text": "They used a version of the Ratnaparkhi et al (1994) dataset that had all words lemmatized and all digits re placed by@", 
    "clean_text": "They used a version of the Ratnaparkhi et al (1994) dataset that had all words lemmatized and all digits replaced by @.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P14-3010", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Clayton, Greenberg", 
    "raw_text": "Theirfinal system had 85.0% precision and 91.8% recall on the Ratnaparkhi et al (1994) dataset", 
    "clean_text": "Their final system had 85.0% precision and 91.8% recall on the Ratnaparkhi et al (1994) dataset.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P06-2004", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Michaela, Atterer | Hinrich, Sch&uuml;tze", 
    "raw_text": "The best performing systems for many tasks innatural language processing are based on supervised training on annotated corpora such as the Penn Treebank (Marcus et al, 1993) and the prepositional phrase data set first described in (Ratnaparkhi et al, 1994)", 
    "clean_text": "The best performing systems for many tasks in natural language processing are based on supervised training on annotated corpora such as the Penn Treebank (Marcus et al, 1993) and the prepositional phrase dataset first described in (Ratnaparkhi et al, 1994).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P06-2004", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Michaela, Atterer | Hinrich, Sch&uuml;tze", 
    "raw_text": "We did not use the PP data set described by (Ratnaparkhi et al, 1994) because we are using more context than the limited context available in that set (see below)", 
    "clean_text": "We did not use the PP data set described by (Ratnaparkhi et al, 1994) because we are using more context than the limited context available in that set (see below).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D11-1113", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Enrique, Henestroza Anguiano | Marie, Candito", 
    "raw_text": "For English, the average human performance on pp-attachment for the (v ,n1, p ,n2) problem formulation is just 88.2% when given only the four head-words, but increases to 93.2% when given the full sentence (Ratnaparkhi et al, 1994)", 
    "clean_text": "For English, the average human performance on pp-attachment for the (v, n1, p, n2) problem formulation is just 88.2% when given only the four head-words, but increases to 93.2% when given the full sentence (Ratnaparkhi et al, 1994).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W04-2410", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Mark, McLauchlan", 
    "raw_text": "A benchmark dataset of 27,937 such quadruples was extracted from the Wall Street Journal corpus by Ratnaparkhi et al (1994) and has been the basis of many subsequent studies comparing machine learning algorithms and lexical resources", 
    "clean_text": "A benchmark dataset of 27,937 such quadruples was extracted from the Wall Street Journal corpus by Ratnaparkhi et al (1994) and has been the basis of many subsequent studies comparing machine learning algorithms and lexical resources.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W04-2410", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Mark, McLauchlan", 
    "raw_text": "Ratnaparkhi et al (1994) trained a maximum entropy model on (v ,n1, p ,n2) quadruples extracted from the Wall Street Journal corpus and achieved 81.6% accuracy. The Collins and Brooks (1995) model scores 84.5 %accu racy on this task, and is one of the most accurate models that do not use additional supervision", 
    "clean_text": "Ratnaparkhi et al (1994) trained a maximum entropy model on (v, n1, p, n2) quadruples extracted from the Wall Street Journal corpus and achieved 81.6% accuracy.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W04-2410", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Mark, McLauchlan", 
    "raw_text": "The maximum entropy approach of Ratnaparkhiet al (1994) uses the mutual information clustering algorithm described in (Brown et al, 1992)", 
    "clean_text": "The maximum entropy approach of Ratnaparkhiet al (1994) uses the mutual information clustering algorithm described in (Brown et al, 1992).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W04-2410", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Mark, McLauchlan", 
    "raw_text": "For our experiments we use the Wall Street Journal dataset created by Ratnaparkhi et al (1994)", 
    "clean_text": "For our experiments we use the Wall Street Journal dataset created by Ratnaparkhi et al (1994).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P06-2029", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Kilian A., Foth | Wolfgang, Menzel", 
    "raw_text": "Supervised training methods already applied to PP attachment range from stochastic maximum likelihood (Collins and Brooks, 1995) or maxi mum entropy models (Ratnaparkhi et al, 1994) to the induction of transformation rules (Brill and Resnik, 1994), decision trees (Stetina and Nagao, 1997) and connectionist models (Sopena et al, 1998)", 
    "clean_text": "Supervised training methods already applied to PP attachment range from stochastic maximum likelihood (Collins and Brooks, 1995) or maximum entropy models (Ratnaparkhi et al, 1994) to the induction of transformation rules (Brill and Resnik, 1994), decision trees (Stetina and Nagao, 1997) and connectionist models (Sopena et al, 1998).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "H05-1105", 
    "citing_paper_authority": 19, 
    "citing_paper_authors": "Preslav, Nakov | Marti A., Hearst", 
    "raw_text": "Ratnaparkhi et al (1994 )created a benchmark dataset of 27,937 quadruples (v ,n1, p ,n2), extracted from the Wall Street Journal", 
    "clean_text": "Ratnaparkhi et al (1994) created a benchmark dataset of 27,937 quadruples (v, n1, p, n2), extracted from the Wall Street Journal.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P01-1039", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Jing, Huang | Geoffrey, Zweig | Mukund, Padmanabhan", 
    "raw_text": "It has been used in a variety of difficult classification tasks such as part-of-speech tagging (Ratnaparkhi, 1996), prepositional phrase attachment (Ratnaparkhi et al, 1994) and named entity tagging (Borthwick et al, 1998), and achieves state of the art performance", 
    "clean_text": "It has been used in a variety of difficult classification tasks such as part-of-speech tagging (Ratnaparkhi, 1996), prepositional phrase attachment (Ratnaparkhi et al, 1994) and named entity tagging (Borthwick et al, 1998), and achieves state of the art performance.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W06-2112", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Martin, Volk", 
    "raw_text": "A year later (Ratnaparkhi et al, 1994 )publisheda supervised approach to the PP attachment problem", 
    "clean_text": "A year later (Ratnaparkhi et al, 1994) published a supervised approach to the PP attachment problem.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W06-2112", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Martin, Volk", 
    "raw_text": "The latter tuple set has been reused by subsequent research, so let us focus on this one.2 (Ratnaparkhi et al, 1994) used 20,801 tuples for training and 3097 tuples for evaluation", 
    "clean_text": "(Ratnaparkhi et al, 1994) used 20,801 tuples for training and 3097 tuples for evaluation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W06-2112", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Martin, Volk", 
    "raw_text": "The difference in noun attachments between these two sets is striking, but (Ratnaparkhi et al, 1994) do not discuss this (and we also do not have an explanation for this)", 
    "clean_text": "The difference in noun attachments between these two sets is striking, but (Ratnaparkhi et al, 1994) do not discuss this (and we also do not have an explanation for this).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W06-2112", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Martin, Volk", 
    "raw_text": "But it makes obvious that (Ratnaparkhi et al, 1994) were tackling a problem different from (Hindle and Rooth, 1993) given the fact that their baseline was at 59% guessing noun attachment (rather than 67% in the Hindle and Rooth experiments) .3Of course, the baseline is not a direct indicator of the difficulty of the disambiguation task. We may construct (artificial) cases with low base lines and a simple distribution of PP attachment tendencies", 
    "clean_text": "But it makes obvious that (Ratnaparkhi et al, 1994) were tackling a problem different from (Hindle and Rooth, 1993) given the fact that their baseline was at 59% guessing noun attachment (rather than 67% in the Hindle and Rooth experiments).", 
    "keep_for_gold": 0
  }
]
