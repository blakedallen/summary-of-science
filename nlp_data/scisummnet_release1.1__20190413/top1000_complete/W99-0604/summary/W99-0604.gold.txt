Improved Alignment Models For Statistical Machine Translation
In this paper, we describe improved alignment models for statistical machine translation.
The statistical translation approach uses two types of information: a translation model and a language model.
The language model used is a bigram or general m-gram model.
The translation model is decomposed into a lexical and an alignment model.
We describe two different approaches for statistical translation and present experimental results.
The first approach is based on dependencies between single words, the second approach explicitly takes shallow phrase structures into account, using two different alignment levels: a phrase level alignment between phrases and a word level alignment between single words.
We present results using the Verbmobil task (German-English, 6000-word vocabulary) which is a limited-domain spoken-language task.
The experimental tests were performed on both the text transcription and the speech recognizer output.
To obtain the best single alignment, we use a post-hoc algorithm to merge directional alignments.
We propose a heuristic, where all the aligned phrase pairs (x?, a?, y?) satisfying the following criteria are extracted: (1) x? and y? consist of consecutive words of x and y, and both have length at most k, (2) a? is the alignment between words of x? and y? induced by a, (3) a? contains at least one link, and (4) there are no links in a that have just one end in x? or y?.
