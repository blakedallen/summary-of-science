[
  {
    "citance_No": 1, 
    "citing_paper_id": "N10-1067", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Beata, Beigman Klebanov | Eyal, Beigman", 
    "raw_text": "It is possible that the length of stay of an annotator in the pool is not independent of her diligence; for example, Callison-Burch (2009) found in his AMT experiments with tasks related to ma chine translation that lazy annotators tended to stay longer and do more annotations.9Beigman Klebanov and Beigman (2009) discuss the connection between noise models and inter-annotator agreement", 
    "clean_text": "It is possible that the length of stay of an annotator in the pool is not independent of her diligence; for example, Callison-Burch (2009) found in his AMT experiments with tasks related to machine translation that lazy annotators tended to stay longer and do more annotations.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P10-1023", 
    "citing_paper_authority": 22, 
    "citing_paper_authors": "Roberto, Navigli | Simone Paolo, Ponzetto", 
    "raw_text": "We will perform a semi-automatic validation of BabelNet ,e.g. by exploiting Amazon? s Mechanical Turk (Callison-Burch, 2009) or designing a collaborative game (von Ahn, 2006) to validate low-ranking mappings and translations", 
    "clean_text": "We will perform a semi-automatic validation of BabelNet, e.g. by exploiting Amazon's Mechanical Turk (Callison-Burch, 2009) or designing a collaborative game (von Ahn, 2006) to validate low-ranking mappings and translations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W10-0705", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Michael, Heilman | Noah A., Smith", 
    "raw_text": "For example, Callison-Burch (2009) used MTurk to evaluate ma chine translations", 
    "clean_text": "For example, Callison-Burch (2009) used MTurk to evaluate machine translations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W10-0731", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Cem, Akkaya | Alexander, Conrad | Janyce, Wiebe | Rada, Mihalcea", 
    "raw_text": "(Callison-Burch, 2009) uses MTurk workers for manual evaluation of automatic translation quality and experiments with weighed voting to combine multiple annotations", 
    "clean_text": "(Callison-Burch, 2009) uses MTurk workers for manual evaluation of automatic translation quality and experiments with weighed voting to combine multiple annotations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W12-3153", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Laura, Jehl | Felix, Hieber | Stefan, Riezler", 
    "raw_text": "The use of crowd sourcing to evaluate machine translation and to build development sets was pioneered by Callison-Burch (2009) and Zaidan and 4http: //www.statmt.org/wmt11/featured-translation-task.htmlCallison-Burch (2009)", 
    "clean_text": "The use of crowd sourcing to evaluate machine translation and to build development sets was pioneered by Callison-Burch (2009) and Zaidan and Callison-Burch (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W10-0709", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Michael, Denkowski | Alon, Lavie", 
    "raw_text": "Following Callison-Burch (2009), we treat evaluation as a weighted voting problem where each annotator? s contribution is weighted by agreement with either a gold standard or with other annotators", 
    "clean_text": "Following Callison-Burch (2009), we treat evaluation as a weighted voting problem where each annotator's contribution is weighted by agreement with either a gold standard or with other annotators.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "C10-2109", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Kristen, Parton | Kathleen R., McKeown", 
    "raw_text": "It has also been used in MT evaluation (Callison-Burch, 2009), though that evaluation used reference translations", 
    "clean_text": "It has also been used in MT evaluation (Callison-Burch, 2009), though that evaluation used reference translations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W10-0734", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Matteo, Negri | Yashar, Mehdad", 
    "raw_text": "As an example, among the collected material several translations in languages other than English revealed a massive and defective use of on-line translation tools by untrusted workers, as also ob served by (Callison-Burch, 2009) .Step 2: reducing validation errors", 
    "clean_text": "As an example, among the collected material several translations in languages other than English revealed a massive and defective use of on-line translation tools by untrusted workers, as also observed by (Callison-Burch, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W10-0710", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Vamshi, Ambati | Stephan, Vogel", 
    "raw_text": "We do not select German, French and other language pairs as they have already been explored by Callison-Burch (2009)", 
    "clean_text": "We do not select German, French and other language pairs as they have already been explored by Callison-Burch (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W10-0714", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Chiara, Higgins | Elizabeth, McGrath | Laila, Moretto", 
    "raw_text": "Furthermore, previous re search shows the effectiveness of crowd sourcing as a method of accomplishing labor intensive natural language processing tasks (Callison-Burch, 2009) and the effectiveness of using MTurk for a variety of natural language automation tasks (Snow, Jurafsy,& amp; O &apos; Connor, 2008)", 
    "clean_text": "Furthermore, previous research shows the effectiveness of crowd sourcing as a method of accomplishing labor intensive natural language processing tasks (Callison-Burch, 2009) and the effectiveness of using MTurk for a variety of natural language automation tasks (Snow, Jurafsy, & O'Connor, 2008).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "D10-1013", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Philip, Resnik | Olivia, Buzek | Changjian, Hu | Yakov, Kronrod | Alex, Quinn | Benjamin B., Bederson", 
    "raw_text": "The value of this upper bound is quite consistent with the bound computed similarly by Callison-Burch (2009)", 
    "clean_text": "The value of this upper bound is quite consistent with the bound computed similarly by Callison-Burch (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "N10-1080", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Daniel, Cer | Christopher D., Manning | Daniel, Jurafsky", 
    "raw_text": "We suspect that the newer RYPT metric (Zaidan and Callison-Burch, 2009), which directly makes use of human adequacy judgements of sub strings, would obtain better human results than the automated metrics presented here", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W10-0701", 
    "citing_paper_authority": 30, 
    "citing_paper_authors": "Chris, Callison-Burch | Mark, Dredze", 
    "raw_text": "Others have used MTurk for novel research directions like non simulated active learning for NLP tasks such as sentiment classification (Hsueh et al, 2009) or doing quixotic things like doing human-in-the-loop minimum error rate training for machine translation (Zaidan and Callison-Burch, 2009) .Some projects have demonstrated the super scalability of crowd sourced efforts", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "N10-1024", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Scott, Novotney | Chris, Callison-Burch", 
    "raw_text": "Callison-Burch (2009) showed similar results for machine translation evaluation, and further showed that Turkers could accomplish complex tasks like translating Urdu or creating reading comprehension tests", 
    "clean_text": "Callison-Burch (2009) showed similar results for machine translation evaluation, and further showed that Turkers could accomplish complex tasks like translating Urdu or creating reading comprehension tests.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W10-0703", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Gabriel, Parent | Maxine, Eskenazi", 
    "raw_text": "While many studies have shown that MTurk can be used for labeling tasks (Snow et al 2008), to rate automatically constructed artifacts (Callison-Burch, 2009, Alonso et al 2008) and to transcribe speech (Ledlie et al 2009, Gruenstein et al, 2009), to our knowledge, there has not been much work on evaluating the use of MTurk for 21clustering tasks", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W10-1006", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Joel R., Tetreault | Elena, Filatova | Martin, Chodorow", 
    "raw_text": "Recently, AMT has been shown to be an effective tool for annotation and evalatuation in NLP tasks ranging from word similarity detection and emotion detection (Snow et al, 2008) to Machine Translation quality evaluation (Callison-Burch, 2009)", 
    "clean_text": "Recently, AMT has been shown to be an effective tool for annotation and evalatuation in NLP tasks ranging from word similarity detection and emotion detection (Snow et al, 2008) to Machine Translation quality evaluation (Callison-Burch, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P11-1122", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Omar F., Zaidan | Chris, Callison-Burch", 
    "raw_text": "Callison-Burch (2009) proposed several ways to evaluate MT output on MTurk", 
    "clean_text": "Callison-Burch (2009) proposed several ways to evaluate MT output on MTurk.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W11-0409", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Anna, Rumshisky", 
    "raw_text": "Over the last several of years, Mechanical Turk, introduced by Amazon as? artificial artificial intelligence?, has been used successfully for a number of NLP tasks, including robust evaluation of machine translation systems by reading comprehension (Callison-Burch, 2009), and other tasks explored in the recent NAACL workshop (Callison-Burch and Dredze, 2010b)", 
    "clean_text": "Over the last several of years, Mechanical Turk, introduced by Amazon as \"artificial artificial intelligence\", has been used successfully for a number of NLP tasks, including robust evaluation of machine translation systems by reading comprehension (Callison-Burch, 2009), and other tasks explored in the recent NAACL workshop (Callison-Burch and Dredze, 2010b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W10-0704", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Qin, Gao | Stephan, Vogel", 
    "raw_text": "There have been several research papers on using MTurk to help natural language processing tasks, Callison-Burch (2009) used MTurk to evaluate machine translation results", 
    "clean_text": "There have been several research papers on using MTurk to help natural language processing tasks, Callison-Burch (2009) used MTurk to evaluate machine translation results.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W10-1701", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Qin, Gao | Nguyen, Bach | Stephan, Vogel", 
    "raw_text": "On another way, an application can combine active learning (Arora et al, 2009) and crowd sourcing, asking non-expertise such as workers of Amazon Mechanical Turk to label crucial alignment links that can improve the system with low cost, which is now a promising methodology in NLP areas (Callison-Burch, 2009) .In this paper, we propose a semi-supervised ex tension of the IBM Models that can utilize partial alignment links", 
    "clean_text": "On another way, an application can combine active learning (Arora et al, 2009) and crowd sourcing, asking non-expertise such as workers of Amazon Mechanical Turk to label crucial alignment links that can improve the system with low cost, which is now a promising methodology in NLP areas (Callison-Burch, 2009).", 
    "keep_for_gold": 0
  }
]
