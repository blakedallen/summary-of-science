Dependency Treelet Translation: Syntactically Informed Phrasal SMT
We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation.
This method requires a source language dependency parser, target language word segmentation and an unsupervised word alignment component.
We align a parallel corpus, project the source dependency parse onto the target sentence, extract dependency treelet translation pairs, and train a tree-based ordering model.
We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser.
Our treelet-based SMT system is trained on about 4.6M parallel sentence pairs from diverse sources including bilingual books, dictionaries and web publications.
We extend paths to treelets, arbitrary connected subgraphs of dependency structures, and propose a model based on treelet pairs.
We demonstrate the success of using fragments of a target language's grammar, treelets, to improve performance in phrasal translation.
