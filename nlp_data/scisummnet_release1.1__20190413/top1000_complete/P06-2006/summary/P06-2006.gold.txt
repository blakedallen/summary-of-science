Evaluating The Accuracy Of An Unlexicalized Statistical Parser On The PARC DepBank
We evaluate the accuracy of an unlexicalized statistical parser, trained on 4K treebanked sentences from balanced data and tested on the PARC DepBank.
We demonstrate that a parser which is competitive in accuracy (without sacrificing processing speed) can be quickly tuned without reliance on large in-domain manually-constructed treebanks.
This makes it more practical to use statistical parsers in applications that need access to aspects of predicate-argument structure.
The comparison of systems using DepBank is not straightforward, so we extend and validate DepBank and highlight a number of representation and scoring issues for relational evaluation schemes.
We show that the system has equivalent accuracy to the PARC XLE parser when the morphosyntactic features in the original DepBank gold standard are taken into account.
We provide annotation for internal NP structure.
We recommend looking at accuracy figures by dependency type to understand what a parser is good at.
We re annotated DepBank using GRs scheme, and used it to evaluate the RASP parser.
