Findings of the 2009 Workshop on Statistical Machine Translation
This paper presents the results of the WMT09 shared tasks, which included a translation task, a system combination task, and an evaluation task.
We conducted a large-scale manual evaluation of 87 machine translation systems and 22 system combination entries.
We used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality, for more than 20 metrics.
We present a new evaluation technique whereby system output is edited and judged for correctness.
Our Fr-En 109 corpus aggregates huge numbers of parallel French English sentences from the web.
We show that the performance of corpus-based statistical machine translation (SMT) has come up to the traditional rule-based method.
