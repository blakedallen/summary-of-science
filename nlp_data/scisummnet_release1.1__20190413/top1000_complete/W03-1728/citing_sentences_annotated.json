[
  {
    "citance_No": 1, 
    "citing_paper_id": "W04-3236", 
    "citing_paper_authority": 60, 
    "citing_paper_authors": "Hwee Tou, Ng | Jin Kiat, Low", 
    "raw_text": "The word segmenter we built is similar to the maximum entropy word segmenter of (Xue and Shen, 2003)", 
    "clean_text": "The word segmenter we built is similar to the maximum entropy word segmenter of (Xue and Shen, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W04-3236", 
    "citing_paper_authority": 60, 
    "citing_paper_authors": "Hwee Tou, Ng | Jin Kiat, Low", 
    "raw_text": "The default feature, boundary tag feature of the previous character, and boundary tag feature of the character two before the current character used in (Xue and Shen, 2003) were dropped from our word segmenter, as they did not improve word segmentation accuracy in our experiments", 
    "clean_text": "The default feature, boundary tag feature of the previous character, and boundary tag feature of the character two before the current character used in (Xue and Shen, 2003) were dropped from our word segmenter, as they did not improve word segmentation accuracy in our experiments.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W04-3236", 
    "citing_paper_authority": 60, 
    "citing_paper_authors": "Hwee Tou, Ng | Jin Kiat, Low", 
    "raw_text": "We observed that character features were successfully used to build our word segmenter and that of (Xue and Shen, 2003)", 
    "clean_text": "We observed that character features were successfully used to build our word segmenter and that of (Xue and Shen, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W04-3236", 
    "citing_paper_authority": 60, 
    "citing_paper_authors": "Hwee Tou, Ng | Jin Kiat, Low", 
    "raw_text": "Our maximum entropy word segmenter is similar to that of (Xue and Shen, 2003), but the additional features we used and the post processing step gave improved word segmentation accuracy", 
    "clean_text": "Our maximum entropy word segmenter is similar to that of (Xue and Shen, 2003), but the additional features we used and the post processing step gave improved word segmentation accuracy.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P13-1075", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Wenbin, Jiang | Meng, Sun | Yajuan, L&uuml; | Yating, Yang | Qun, Liu", 
    "raw_text": "Word segmentation can be formalized as a character classification problem (Xueand Shen, 2003), where each character in the sentence is given a boundary tag representing its position in a word", 
    "clean_text": "Word segmentation can be formalized as a character classification problem (Xue and Shen, 2003), where each character in the sentence is given a boundary tag representing its position in a word.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "I05-3023", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Yaoyong, Li | Chuanjiang, Miao | Kalina, Bontcheva | Hamish, Cunningham", 
    "raw_text": "This kind of strategy has been widely used in the applications of machine learning to named entity recognition and has also 154 been used in Chinese word segmentation (Xue and Shen, 2003)", 
    "clean_text": "This kind of strategy has been widely used in the applications of machine learning to named entity recognition and has also been used in Chinese word segmentation (Xue and Shen, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "I05-3023", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Yaoyong, Li | Chuanjiang, Miao | Kalina, Bontcheva | Hamish, Cunningham", 
    "raw_text": "Actually we can only use part of co-occurrences as features, which can be regarded as some kind of semi-quadratic kernel. Table 3 compares the three types of kernel for Perceptron, where for the semi quadratic kernel we used the co-occurrences of characters in context window as those used in (Xue and Shen, 2003), namely{ c? 2c? 1, c? 1c0 ,c0c1 ,c1c2, c? 1c1}", 
    "clean_text": "Table 3 compares the three types of kernel for Perceptron, where for the semi quadratic kernel we used the co-occurrences of characters in context window as those used in (Xue and Shen, 2003), namely{ c? 2c? 1, c? 1c0 ,c0c1 ,c1c2, c? 1c1}.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "I08-2134", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Richard Tzong-Han, Tsai | Hsi-Chuan, Hung", 
    "raw_text": "Character n-gram features have proven their effectiveness in ML-based CWS (Xue and Shen,2003)", 
    "clean_text": "Character n-gram features have proven their effectiveness in ML-based CWS (Xue and Shen,2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "N06-2049", 
    "citing_paper_authority": 19, 
    "citing_paper_authors": "Ruiqiang, Zhang | Genichiro, Kikui | Eiichiro, Sumita", 
    "raw_text": "It was first used in Chinese word segmentation by (Xue and Shen, 2003), where maximum entropy methods were used", 
    "clean_text": "It was first used in Chinese word segmentation by (Xue and Shen, 2003), where maximum entropy methods were used.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "I08-4033", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Ruiqiang, Zhang | Eiichiro, Sumita", 
    "raw_text": "Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (MaxEnt) (Xue and Shen, 2003), support vector machine (SVM) (Kudo and Matsumoto, 2001), conditional random fields (CRF) (Peng and McCallum, 2004), and minimum error rate training (Gao et al, 2004)", 
    "clean_text": "Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (MaxEnt) (Xue and Shen, 2003), support vector machine (SVM) (Kudo and Matsumoto, 2001), conditional random fields (CRF) (Peng and McCallum, 2004), and minimum error rate training (Gao et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "I05-3019", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Aitao, Chen | Yiping, Zhou | Anne, Zhang | Gordon, Sun", 
    "raw_text": "The conditional maximum entropy model in our implementation is based on the one described in Section 2.5 in (Ratnaparkhi, 1998), and features are the same as those described in (Xue and Shen, 2003)", 
    "clean_text": "The conditional maximum entropy model in our implementation is based on the one described in Section 2.5 in (Ratnaparkhi, 1998), and features are the same as those described in (Xue and Shen, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P08-1102", 
    "citing_paper_authority": 33, 
    "citing_paper_authors": "Wenbin, Jiang | Liang, Huang | Qun, Liu | Yajuan, L&uuml;", 
    "raw_text": "Since the typical approach of discriminative models treats segmentation as a labelling problem by assigning each character a boundary tag (Xue and Shen, 2003), Joint S& amp; Tcan be conducted in a labelling fashion by expanding boundary tags to include POS information (Ngand Low, 2004)", 
    "clean_text": "Since the typical approach of discriminative models treats segmentation as a labelling problem by assigning each character a boundary tag (Xue and Shen, 2003), Joint S&T can be conducted in a labelling fashion by expanding boundary tags to include POS information (Ngand Low, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W10-4127", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Qin, Gao | Stephan, Vogel", 
    "raw_text": "By casting the problem as a character labeling task, sequence labeling models such as Conditional Random Fields can be applied on the problem (Xueand Shen, 2003)", 
    "clean_text": "By casting the problem as a character labeling task, sequence labeling models such as Conditional Random Fields can be applied on the problem (Xue and Shen, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P06-2123", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Ruiqiang, Zhang | Genichiro, Kikui | Eiichiro, Sumita", 
    "raw_text": "Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (Max Ent) (Xue and Shen, 2003), support vector machine? Now the second author is affiliated with NTT", 
    "clean_text": "Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (Max Ent) (Xue and Shen, 2003), support vector machine Now the second author is affiliated with NTT.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P06-2123", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Ruiqiang, Zhang | Genichiro, Kikui | Eiichiro, Sumita", 
    "raw_text": "In the third step, we used the maximum entropy (MaxEnt) approach (the results of CRF are given in Section 3.4) to train the IOB tagger (Xue and Shen, 2003)", 
    "clean_text": "In the third step, we used the maximum entropy (MaxEnt) approach (the results of CRF are given in Section 3.4) to train the IOB tagger (Xue and Shen, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P06-2123", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Ruiqiang, Zhang | Genichiro, Kikui | Eiichiro, Sumita", 
    "raw_text": "It was first implemented in Chinese word segmentation by (Xue and Shen, 2003) using the maximum entropy methods", 
    "clean_text": "It was first implemented in Chinese word segmentation by (Xue and Shen, 2003) using the maximum entropy methods.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P09-1059", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Wenbin, Jiang | Liang, Huang | Qun, Liu", 
    "raw_text": "Xue and Shen (2003) describe for the first time the character classification approach for Chinese word segmentation, where each character is given a boundary tag denoting its relative position in a word", 
    "clean_text": "Xue and Shen (2003) describe for the first time the character classification approach for Chinese word segmentation, where each character is given a boundary tag denoting its relative position in a word.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "I05-3031", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Tak Pang, Lau | Irwin, King", 
    "raw_text": "In this pa per, we propose a statistical approach based on the works of (Xue and Shen, 2003), in which the Chinese word segmentation problem is first transformed into a tagging problem, then the Maximum Entropy classifier is applied to solve the problem", 
    "clean_text": "In this paper, we propose a statistical approach based on the works of (Xue and Shen, 2003), in which the Chinese word segmentation problem is first transformed into a tagging problem, then the Maximum Entropy classifier is applied to solve the problem.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "I05-3031", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Tak Pang, Lau | Irwin, King", 
    "raw_text": "In Section 2, we briefly discuss the scheme proposed by (Xue and Shen, 2003), followed by our additional works to improve the performance", 
    "clean_text": "we briefly discuss the scheme proposed by (Xue and Shen, 2003), followed by our additional works to improve the performance.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "I05-3031", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Tak Pang, Lau | Irwin, King", 
    "raw_text": "One of the difficulties in Chinese word segmentation is that, Chinese characters can appear in different positions within a word (Xue and Shen, 2003), and LMR Tagging was proposed to solve the problem", 
    "clean_text": "One of the difficulties in Chinese word segmentation is that, Chinese characters can appear in different positions within a word (Xue and Shen, 2003), and LMR Tagging was proposed to solve the problem.", 
    "keep_for_gold": 0
  }
]
