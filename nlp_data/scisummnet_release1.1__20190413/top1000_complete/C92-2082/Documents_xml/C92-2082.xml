<PAPER>
  <S sid="0" ssid="0">Automatic Acquisition of Hyponyms ~om Large Text Corpora Mart i  A. Hearst Computer  Science Division, 571 Evans Hall Un ivers i ty  of Cal i fornia,  Berkeley Berkeley,  CA 94720 and Xerox Palo A l to  Research Center mart i~cs ,  berkeley, edu Abst rac t We describe a method for the automatic acquisition of the hyponymy lexical relation from unrestricted text.</S>
  <S sid="1" ssid="1">Two goals motivate the approach: (i) avoid- ance of the need for pre-encoded knowledge and (ii) applicability across a wide range of text.</S>
  <S sid="2" ssid="2">We identify a set of lexico-syntactic patterns that are easily rec- ognizable, that occur iYequently and across text genre boundaries, and that indisputably indicate the lexical relation of interest.</S>
  <S sid="3" ssid="3">We describe a method for discov- ering these patterns and suggest hat other lexical relations will also be acquirable in this way.</S>
  <S sid="4" ssid="4">A subset of the acquisition algorithm is implemented and the results are used to attgment and critique the struc- ture of a large hand-built hesaurus.</S>
  <S sid="5" ssid="5">Extensions and applications to areas uch as information retrieval are suggested.</S>
  <S sid="6" ssid="6">1 In t roduct ion Currently there is much interest in the automatic ac- quisition of lexiea[ syntax and semantics, with the goal of building up large lexicons for natural lain guage processing.</S>
  <S sid="7" ssid="7">Projects that center around ex- tracting lexical information from Machine Readable Dictionaries (MRDs) have shown much success but are inherently limited, since the set of entries within a dictionary is fixed.</S>
  <S sid="8" ssid="8">In order to find terms and ex- pressions that are not defined in MRDs we must turn to other textual resources.</S>
  <S sid="9" ssid="9">For this purpose, we view a text corpus not only as a source of information, but also as a source of information about the language it is written in.</S>
  <S sid="10" ssid="10">When interpreting unrestricted, omain-independent text, it is difficult to determine in advance what kind of infbrmation will be encountered and how it will be expressed.</S>
  <S sid="11" ssid="11">Instead of interpreting everything in the text in great detail, we can searcil for specific lexical relations that are expressed in well-known ways.</S>
  <S sid="12" ssid="12">Sur- prisingly useful information can be found with only a very simple understanding of a text.</S>
  <S sid="13" ssid="13">Consider the following sentence: 1.</S>
  <S sid="14" ssid="14">(SI) The  bow lu te ,  such as the  Bambara ndang, is plucked and has an ind iv idual curved neck :for each string.</S>
  <S sid="15" ssid="15">Most fluent readers of English who }lave never be- fore encountered the term q3amhara ndang" will nev- ertheless from this sentence infer that a "Bambara udang" is a kind of "bow Iute".</S>
  <S sid="16" ssid="16">This is true even if tile reader has only a fuzzy conception of what a how lute is.</S>
  <S sid="17" ssid="17">Note that the attthor of the sentence is not de- liberately defining the term, as would a dictionary or a childrens book containing a didactic sentence like A Bambara ndang is a kind of bow lute.</S>
  <S sid="18" ssid="18">However, the semantics of the lexico-syntactic construction i - dicated by the pattern: (la) NPo ..... h as {NP1, NP2 .</S>
  <S sid="19" ssid="19">(and Ior)} NP,, are such that they imply (lb) for all NP , ,  1 &lt; i&lt; n, hyponym(NPi,  NPo) Thus from sentence (SI) we conclude hyponym ( "Barn bare n dang", "how lu re").</S>
  <S sid="20" ssid="20">We use the term hyponym similarly to the sense used in (Miller et el.</S>
  <S sid="21" ssid="21">1990): a concept represented by a lexicaI item L0 is said to be a hyponym of the concept represented by a lexical item LI if native speakers of English accept sentences constructed from the frame An Lo is a (kind of) L1.</S>
  <S sid="22" ssid="22">Here Lt is the hypernym of Lo and the relationship is reflexive and transitive, but not symmetric.</S>
  <S sid="23" ssid="23">This example shows a way to discover a hyponymic lexical relationship between two or more noun phrases in a naturally-occurring text.</S>
  <S sid="24" ssid="24">This approach is siml- lar in spirit to the pattern-based interpretation tech- niques being used in MRD processing.</S>
  <S sid="25" ssid="25">For example, t All examples in this paper are real text, taken from Grolters Amerwan Acaderntc Encyclopedia(Groher tg00) AcrF.s DE COLING-92, NANTI~S, 23-28 Aol}r 1992 5 3 9 PROC.</S>
  <S sid="26" ssid="26">OV COLING-92, NhNTIIS, AUG. 23-28, 1992 (Alshawi 1987), in interpreting LDOCE definitions, uses a hierarchy of patterns which consist mainly of part-of-speech indicators and wildcard characters.</S>
  <S sid="27" ssid="27">(Markowitz e~ al.</S>
  <S sid="28" ssid="28">1986), (Jensen &amp; Binot 1987), and (Nakamura &amp; Nagao 1988) also use pattern recogni- tion to extract semantic relations uch as taxonomy from various dictionaries.</S>
  <S sid="29" ssid="29">(Ahlswede &amp; Evens I988) compares an approach based on parsing Websters 7th definitions with one based on pattern recognition, and finds that for finding simple semantic relations, pattern recognition [s far more accurate and efficient than parsing.</S>
  <S sid="30" ssid="30">The general feeling is that the struc- ture and function of MRDs makes their interpretation amenable to pattern-recognition techniques.</S>
  <S sid="31" ssid="31">Thus one could say by interpreting sentence (S1) ac- cording to (In-b) we are applying pattern-based rela- tion recognition to general texts.</S>
  <S sid="32" ssid="32">Since one of the goals of building a lexical hierarchy automatically is to aid in the construction of a natural anguage processing program, this approach to acquisition is preferable to one that needs a complex parser ~nd knowledge base.</S>
  <S sid="33" ssid="33">The tradeoff is that the the refor- mation acquired is coarse-grained.</S>
  <S sid="34" ssid="34">There are many ways that the structure of a lan- guage can indicate the meanings of lexical items, but the difficulty lies in finding constructions that fre- quently and reliably indicate the relation of interest.</S>
  <S sid="35" ssid="35">It might seem tbat because free text is so varied in form and content (as compared with the somewhat regular structure of the dictionary) that it may not be possible to find such constructions.</S>
  <S sid="36" ssid="36">However, we have identified a set of lexico-syntactic patterns, in- cluding the one shown in (In) above, that indicate the hyponymy relation and that satisfy the following desiderata: (i) They occur frequently and in many text genres.</S>
  <S sid="37" ssid="37">(ii) They (almost) always indicate the relation of in- terest.</S>
  <S sid="38" ssid="38">(iii) They can be recognized with little or no pre- encoded knowledge.</S>
  <S sid="39" ssid="39">Item (i) indicates that the pattern will result in the discovery of many instances of the relation, item (ii) that the information extracted will not be erroneous, and item (iii) that making use of the pattern does not require the tools that it is intended to help build.</S>
  <S sid="40" ssid="40">Finding instances of the hyponymy relation is useful for several purposes: Lexicon Augmentat ion .</S>
  <S sid="41" ssid="41">Hyponymy relations can be used to augment and verify existing lexicons, in- cluding ones built from MRDs.</S>
  <S sid="42" ssid="42">Section 3 of this paper describes an example, comparing results ex- tracted from a text corpus with information stored in the noun hierarchy of WordNet ((Miller et al.</S>
  <S sid="43" ssid="43">1990)), a hand-built lexical thesaurus.</S>
  <S sid="44" ssid="44">Noun Phrase  Semantics.</S>
  <S sid="45" ssid="45">Another purpose to which these relations can be applied is the identifi- cation of the general meaning of an unfamiliar noun phrases.</S>
  <S sid="46" ssid="46">For example, discovering the predicate hyponym( "broken bone", "injury") indicates that tbe term "broken bone" can be under- stood at some level as an "injury" without having to determine the correct senses of the component words and how they combine.</S>
  <S sid="47" ssid="47">Note also that a term like "broken bone" is not likely to appear in a dictionary or lexicon, although it is a common locution.</S>
  <S sid="48" ssid="48">Semant ic  Relatedness In fo rmat ion .</S>
  <S sid="49" ssid="49">There bas recently been work in the detection of semantically re- lated nouns via, for example, shared argument struc- tures (Hindle 1990), and shared dictionary definition context (Wilks e?</S>
  <S sid="50" ssid="50">These approaches at- tempt to infer relationships among [exical terms by looking at very large text samples and determining which ones are related in a statistically significant way.</S>
  <S sid="51" ssid="51">The technique introduced in this paper can be seen as having a similar goal but an entirely different approach, since only one sample need be found in or- der to determine a salient relationship (and that sam- ple may be infrequently occurring or nonexistent).</S>
  <S sid="52" ssid="52">Thinking of the relations discovered as closely related semantically instead of as hyponymic is most felic- itous when the noun phrases involved are modified and atypical.</S>
  <S sid="53" ssid="53">Consider, for example, the predicate hyponym( "detonating explosive", "blasting agent") This relation may not be a canonical ISA relation but the fact that it was found in a text implies that the terms meanings are close.</S>
  <S sid="54" ssid="54">Connecting terms whose expressions are quite disparate but whose meanings are similar should be useful for improved synonym ex- pansion in information retrieval and for finding chains of semantically related phrases, as used in the ap- proach to recognition of topic boundaries of (Morris Hirst 1991).</S>
  <S sid="55" ssid="55">We observe that terms that occur in a list are often related semantically, whether they occur in a hyponymy relation or not.</S>
  <S sid="56" ssid="56">In the next section we outline a way to discover these lexico-syntactic patterns as well as illustrate those we have found.</S>
  <S sid="57" ssid="57">Section 3 shows the results of searching texts for a restricted version of one of the patterns and compares the results against a hand-built hesaurus.</S>
  <S sid="58" ssid="58">Section 4 is a discussion of the merits of this work and describes future directions.</S>
  <S sid="59" ssid="59">2 Lexico-Syntactic Patterns for Hyponymy Since only a subset of the possible instances of the hyponymy relation will appear in a particular form, we need to make use of as many patterns as possi- ble.</S>
  <S sid="60" ssid="60">Below is a list of lexico-syntactie patterns that indicate the hyponymy relation, followed by illustra- tive sentence fragments and the predicates that can ACTI~S DE COLING-92, NANTES, 23-28 AOt~r 1992 5 4 0 PROC.</S>
  <S sid="61" ssid="61">OF COLING-92, NANTES, AUG. 23-28, 1992 be derived from them (detail about the environment surrounding tile patterns is omitted for simplicity): (2) .... h NP us {NP ,}* {(or [ and)} NP ... works  by such authors  as Her r i ck , Go ldsmi th ,  and Shakespeare .</S>
  <S sid="62" ssid="62">hyf)onym I~author", "Ilerrick), llyponym( "author", "(;oldsmith "), hyponynl( "author", "Shakespeare") (3) NP {, NP} * {,} o, other NP Bru ises ,  wounds ,  broken bones or o ther in ju r ies  .</S>
  <S sid="63" ssid="63">~... hyponym( "bruise".</S>
  <S sid="64" ssid="64">"injury"), hyponym ( "wo und", "mj ury" ), hyponym( "broken bone", "injury") (4) NP {, NP}* {,} and other NP ... temples ,  t reasur ies ,a l td  o ther impor tant  c iv ic  buildings.</S>
  <S sid="65" ssid="65">:~- hyponym("tenlple", "civic building"), hyponym( "treasury ", "civic building") (5) m, {,} .~clsa,,~y {NP 5* {o,.</S>
  <S sid="66" ssid="66">.a} NP Al l  common- law count r ies ,  including Canada and England ... -~, hyponym( "Canada", "collllnou--law coon try"), f lyponym ( "Eng]and", "common-law co lm - try") (6) NP {,} especially {NP ,}* {or] and} NP .</S>
  <S sid="67" ssid="67">most: European count r ies ,  espec ia l l y France, England, and Spain.</S>
  <S sid="68" ssid="68">~ hyponym( "France", "European country"), hyponym( "England", "European country"), hypouym( "Spain", "European country") When a relation hyponym(NPo, NI  I )  is discov- ered, aside from some temmatiz ing and removal of unwanted modifiers, tile uonn phrase is left as all atomic unit, not broken clown and analyzed.</S>
  <S sid="69" ssid="69">I ra  more detailed interpretation is desired, the results can be passed on to a more intelligent or specialized language analysis component.</S>
  <S sid="70" ssid="70">And, as mentioned above, this kind of discovery procedure can be a partial solution for a problenr like noun phrase interpretation because at least part of the meaning of the phrase is indicated by tile hyponymy relation.</S>
  <S sid="71" ssid="71">and we usually want them to be singular.</S>
  <S sid="72" ssid="72">Adjecti- val quantiflers uch as "other" and "some" are usu- ally undesirable and can be eliminated in most cases without making the statement of tile hypouym rela- tion erroneous.</S>
  <S sid="73" ssid="73">( omparat ives SUCh as "inlportaat" and "smaller" are usually best removed, since their meaning [s relative and dependent on tile context in which they appear.</S>
  <S sid="74" ssid="74">I low much modification is desirable depends on the application to which the lexical relations will be put.</S>
  <S sid="75" ssid="75">For budding up a basic, general-domain thesaurus, single-word uouns and very cOnllnon colnpouuds are most appropriate.</S>
  <S sid="76" ssid="76">For a inore specialized domain, umre modified terms have their place.</S>
  <S sid="77" ssid="77">Per example, noun phrases in ~he me(licai ?lontain otteu have sev- eral layers of modification which should be preserved in a taxonomy of medical terms.</S>
  <S sid="78" ssid="78">Other difficulties and concerns are discussed ill Sec- tion a.</S>
  <S sid="79" ssid="79">2.2  Discovery  o f  New Pat terns How can these patterns be found?</S>
  <S sid="80" ssid="80">Initially we dis- covered patterns (1 ) -  (3) 5y observation, looldug through text and noticing die patterns and tile rela- tionships they indicate, lu order to find new patterns automatical ly, we sketch the following procedure: 1. l)ecide on a lexical relation, R, that is of interest, e.g., "gro up/member"(iu our formulation this is a subset of the hypouylny relation).</S>
  <S sid="81" ssid="81">Gather a list of terms for which this rela- tion is known to hold, e.g., "England-country.</S>
  <S sid="82" ssid="82">This list can be found autonmtically using the method described here, bootstrapping from pat- terns found by hand, or by bootstrapping from an existing lexicon or knowledge base.</S>
  <S sid="83" ssid="83">Find places in tile corpus where these expressions occur syntactically near one another and record the environment.</S>
  <S sid="84" ssid="84">4. t,ind the commonaflties among these environ- i~leuts and hypothesize that corn.men ones yield patterns that indicate the relation of interest.</S>
  <S sid="85" ssid="85">Once a new pattern has been positively identi- fied, use it to gather more instances of the target relation and go to Step 2.</S>
  <S sid="86" ssid="86">2.1  Some Cons iderat ions In example (4) above, the full noun phrase corre- sponding to the hypernym is "other important civic buildings".</S>
  <S sid="87" ssid="87">This illustrates a difficulty that arises from using free text as the data source, as opposed to a dictionary - often the form that a noun phrase occurs in is not what we would like to record.</S>
  <S sid="88" ssid="88">For example, nouns frequently occur in their plural form We tried this procedure by hand using just one pair of terms at a time.</S>
  <S sid="89" ssid="89">In the first case we tried the "Fngland-country" example, and with just this pair we tound uew patterns (4) and (5), as well as (1) (3) which were already known.</S>
  <S sid="90" ssid="90">Next we tried "tank- vehicle" and discovered a very productive pattern, pattern (6).</S>
  <S sid="91" ssid="91">(Note that for this pattern, even though it has an emphatic element, this does not affect the fact that the relation indicated is hypouymic.)</S>
  <S sid="92" ssid="92">AcrEs DE COLING-92, N^mEs, 23-28 hotrr 1992 5 4 1 l)Roc, ov COLING-92, NAbrrEs, AUG. 23-28, 1992 We have tried applying this technique to meronymy (i.e., the part/whole relation), but without great suc- cess.</S>
  <S sid="93" ssid="93">The patterns fotu~.d for this relation do not tend to uniquely identify it, but can be used to express other relations as well.</S>
  <S sid="94" ssid="94">It may be the case that in English the hyponymy relation is especially amenable to this kind of analysis, perhaps due to its "naming" nature.</S>
  <S sid="95" ssid="95">However, we have bad some success at iden- tification of more specific relations, such as patterns that indicate certain types of proper nouns.</S>
  <S sid="96" ssid="96">We have not implemented an automatic version of this algorithm, primarily because Step 4 is underde- termined.</S>
  <S sid="97" ssid="97">2.3 Related Work This section discusses work in acquisition of lexical in- formation from text corpora, although as mentioned earlier, significant work has been done in acquiring lexical information from MRDs.</S>
  <S sid="98" ssid="98">(Coates-Stephens 1991) acquires semantic descrip- tions of proper nouns in a system called FUNES.</S>
  <S sid="99" ssid="99">FU- NES attempts to fill in frame roles, (e.g., name, age~ origin, position, and works-for, for a person frame) by processing newswire text.</S>
  <S sid="100" ssid="100">This system is simi- lar to the work described here in that it recognizes some features of the context in which the proper noun occurs in order to identify some relevant semantic attributes.</S>
  <S sid="101" ssid="101">Coates-Stephens mentions that "known as" can explicitly introduce meanings for terms, as can appositives.</S>
  <S sid="102" ssid="102">We also have consid- ered these markers, hut the tbrmer often does not cleanly indicate "another name for" and the latter is difficult to recognize accurately.</S>
  <S sid="103" ssid="103">FUNES differs quite strongly from our approach in that, because it is able to fill in many kinds of frame roles, it requires a parser that produces a detailed structure, and it requires a domain-dependent k owlege base/lexicon.</S>
  <S sid="104" ssid="104">(Velardi &amp; Pazienza 1989) makes use of hand-coded selection restriction and conceptual relation rules in order to assign case roles to lexical items, and (Ja- cobs &amp; Zernik 1988) uses extensive domain knowledge to fill in missing category information for unknown words.</S>
  <S sid="105" ssid="105">Work on acquisition of syntactic information from text corpora includes Brents (Brent 1991) verb subcategorization frame recognition technique and Smadjas (Smadja &amp; McKeown 1990) collocation ac- quisition algorithm.</S>
  <S sid="106" ssid="106">(Calzolari &amp; Bindi 1990) use corpus-based statistical association ratios to deter- mine lexical information such as prepositional com- plementation relations, modification relations, and significant compounds.</S>
  <S sid="107" ssid="107">Our methodology is similar to Brents in its effort to distinguish clear pieces of evidence from ambigu- ous ones.</S>
  <S sid="108" ssid="108">The assumption is that that given a large enough corpus, the algorithm can afford wait until it encounters clear examples.</S>
  <S sid="109" ssid="109">Brents algorithm re- lies on a clever trick: in the configuration of interest (in this case, verb valence descriptions), where noun phrases are the source of ambiguity, it uses only sen- tences which have pronouns in the crucial position, since pronouns do not allow this ambiguity.</S>
  <S sid="110" ssid="110">This approach is qnite effective, but the disadvantage is that it isnt clear that it is applicable to any other tasks.</S>
  <S sid="111" ssid="111">The approach presented in this paper, using the algorithm sketched in the previous ubsection, is potentially extensible.</S>
  <S sid="112" ssid="112">3 Incorporating Results i n to WordNet To validate this acquisition method, we compared the results of a restricted version of the algorithm with information found in WordNet.</S>
  <S sid="113" ssid="113">2 WordNet (Miller et al.</S>
  <S sid="114" ssid="114">1990) is a hand-built online thesaurus whose organization is modeled after the results of psycbolin- guistic research.</S>
  <S sid="115" ssid="115">To use tile authors words, Wordnet "... is an attempt o organize lexical information in terms of word meanings, rather than word forms.</S>
  <S sid="116" ssid="116">In that respect, WordNet resembles a thesaurus more than a dictionary ..." To this end, word forms with synonymous meanings are grouped into sets, called synsets.</S>
  <S sid="117" ssid="117">This allows a distinction to be made be- tween senses of homographs.</S>
  <S sid="118" ssid="118">For example, the noun "board" appears in the synsets {board, plank} and {board, committee}, and this grouping serves for the most part as the words definition.</S>
  <S sid="119" ssid="119">In version 1.1, WordNet contains about 34,000 noun word forms, including some compounds and proper nouns, orga- nized into about 26,000 synsets.</S>
  <S sid="120" ssid="120">Noun synsets are organized hierarchically according to the hyponymy relation with implied inheritance and are further dis- tinguished by values of features uch as meronymy.</S>
  <S sid="121" ssid="121">WordNets coverage and structure are impressive and provide a good basis for an automatic acquisition al- gorithm to build on.</S>
  <S sid="122" ssid="122">When comparing a result hyponym(No,Nt) to the contents of WordNets noun hierarchy, three kinds of outcomes are possible: Verify.</S>
  <S sid="123" ssid="123">If both No and Nt are in WordNet, and if the relation byponym(No,N1) is in the hierarchy (possi- bly througi~ transitive closure) then the thesaurus i verified.</S>
  <S sid="124" ssid="124">If both No and N1 are in WordNet, and if the relation hyponym(No, N1) is not in the hierarchy (even through transitive closure) then the thesaurus is critiqued, i.e., a new set of hyponym connections i suggested.</S>
  <S sid="125" ssid="125">If one or both of No and NI are not present then these noun phrases and their relation are suggested as entries.</S>
  <S sid="126" ssid="126">As an example of critiquing, consider the following 2The author thanks Miller, et al,, for the distribution of WordNet.</S>
  <S sid="127" ssid="127">AcrEs DE COL1NG-92, NANTES, 23-28 AoUr 1992 5 4 2 PRec.</S>
  <S sid="128" ssid="128">OF COLING-92, NANTES, AUG. 23-28, 1992 sentence and derived relation: (S2) Other  input -output  dev?ces ,  such as pr in ters ,  co lo r  p lo tzers ,  .</S>
  <S sid="129" ssid="129">~ hyponym(~rinter,~npnt-mltput device") The text indicates that a printer is a kind of input- output device.</S>
  <S sid="130" ssid="130">Figure 1 indicates tile portion of tile hyponymy relation in WordNets noun hierarchy that has to do with printers and devices.</S>
  <S sid="131" ssid="131">Note ;although the terms device and printer are present, they are not linked in such as way as to allow the easy insertion UO device under the more general dewce and over the more specific printer.</S>
  <S sid="132" ssid="132">Although it is not obvious what to suggest to fix this portion of the hierarchy from this one relation ~done, it is clear that its discovery highlights a trouble spot ill tile structure.</S>
  <S sid="133" ssid="133">,__/_"-._._, Figure t: A Fragment of the WordNet Noun Hier- archy.</S>
  <S sid="134" ssid="134">Syasets are enclosed in braces; most synsets have more connections than those shown.</S>
  <S sid="135" ssid="135">aereal~: ricu* ~heat* countries: Cuba Vietnam France* hydrocarbon: ethylene ~ubstances: bromine* hydrogen* protozoa: parameclum liqueurs: anisette* absinthe* rocks: gralt lte* substances: phosphorus* nitrogen* species: stuatornis oilbirds bivalves: scallop* fungi: smuts* rusts* fabrics: acrylics* nylon* silk* antibiotlcS: amplcillin erythromycln* institutions: temples king seabirds: penguins albatross* flatworms: tapeworms pla~aria amphibians: frogs* ~aterfowl: ducks legumes: lentils* beans* nuts org~lisms: horsetails ferns mosses rivers: Sevier Ca[rson Humboldt fruit: olives* grapes* hydrocarbons: benzene gasol?ne ideologies: liberalism conservatism industries: steel iron shoes min.rals: pyrite* galena phenomena: lightning* infection; menlngltis dyes: quercitron Figure 2: Relations found in Groliers.</S>
  <S sid="136" ssid="136">The format is hypernym: hyponyrn list.</S>
  <S sid="137" ssid="137">Entries with * indicate relations found in WordNet.</S>
  <S sid="138" ssid="138">Most of the terms in WordNets noun hierarchy are unmodified nouns or nouns with a single modifier.</S>
  <S sid="139" ssid="139">For this reason, ill this experiment we only extracted relations consisting of mmmdif ied nouns in both the hypernym and hypouym roles (although determiners are allowed and a very small set of quantifier ad- jectives: "some", "many", "certain", and "other").</S>
  <S sid="140" ssid="140">Making this restriction is also usethl because of the difficulties with determining which modifiers are sig- nificant, as touched on above, and because it seems easier to make a judgement call about the correctness of the classification of unmodified nouns for evalua- tion purposes.</S>
  <S sid="141" ssid="141">Since we are trying to acquire lexical information our parsing mechanism should not be one that requires extensive lexicat information.</S>
  <S sid="142" ssid="142">In order to detect the lexico-syntactic patterns, we use a unification-based constituent analyzer (taken from (Batali 1991)), which builds on the output of a part-or=speech tag- ger (Cutt ing el al.</S>
  <S sid="143" ssid="143">(All code described in this report is written m Common Lisp and run on Sun SparcStations.)</S>
  <S sid="144" ssid="144">We wrote grammar  ules for the constituent analyzer to recognize the pattern in ( la) .</S>
  <S sid="145" ssid="145">As mentioned above, in this experiment we are detecting only unmodified nouns.</S>
  <S sid="146" ssid="146">Therefore, when a noun is found in the hyper- nym position, that is, before the lexemes "such as", we check for the nouns inclusion in a relative clause, or as part of a larger noun phrase that includes an appositive or a parenthetical.</S>
  <S sid="147" ssid="147">Using tile constituent analyzer, it is not necessary to parse the entire sell- tence; instead we look at just enough local context around the iexical items in the pattern to ensure that tile nouns in tile pattern are isolated.</S>
  <S sid="148" ssid="148">After the hypernym is detected the hyponyms are identified.</S>
  <S sid="149" ssid="149">Often they occur ill a llst and each ele- ment ill the list holds a hyponym relation with the hypernym.</S>
  <S sid="150" ssid="150">The main difficulty here lies m determin- ing the extent of the last term in the list.</S>
  <S sid="151" ssid="151">3.1 Results and Evaluation Figure 2 illustrates some of the results of a run of the acquisition algorithm on Groliers American Aca- demic Encyelopedia(Grolier 1990), where a restricted version of pattern ( la)  is the target (space constraints do not allow a full listing of the results).</S>
  <S sid="152" ssid="152">After the re- lations are found they are looked up in WordNet.</S>
  <S sid="153" ssid="153">We placed the WordNet noun hierarchy into a b-tree data structure for efficient retrieval and update and used a breadth-first-search to search through the transit ive closure.</S>
  <S sid="154" ssid="154">Ont of 8.6M words of encyclopedia text, there are AcrEs DE COL1NG-92, NANt .F.S, 23-28 ho,,~r 1992 5 4 3 Paoc.</S>
  <S sid="155" ssid="155">ov COLING-92, NANTES, AUO.</S>
  <S sid="156" ssid="156">23-28, 1992 7067 sentences that contain tile lexemes "such as" contiguously.</S>
  <S sid="157" ssid="157">Out of these, 152 relations fit tile re- strictions of the experiment, namely that both the hyponyms and the hypernyms are unmodified (with the exceptions mentioned above).</S>
  <S sid="158" ssid="158">When the restric- tions were eased slightly, so that NPs consisting of two nouns or a present/past participle plus a noun were allowed, 330 relations were found.</S>
  <S sid="159" ssid="159">Wheu the lat- ter experiment was run o21 about 20M words of New York Times text, 3178 sentences contained "such as" contiguously, and 46 relations were found using the strict no-modifiers criterion.</S>
  <S sid="160" ssid="160">Wilen the set of t52 Groliers relations was looked up in WordNet, 180 out of the 226 mlique words involved in the relations actually existed in the hierarchy, and 61 out of the 106 feasible relations (i.e., relations in which both terms were already registered in Word- Net) were found.</S>
  <S sid="161" ssid="161">The quality of the relations found seems high over- all, although there are difficulties.</S>
  <S sid="162" ssid="162">As to be expected, metonymy occurs, as seen in hyponym("king", "in- stitution").</S>
  <S sid="163" ssid="163">A more common problem is under- specification.</S>
  <S sid="164" ssid="164">For example, one relation is hy- ponym( "steatornis, "species"), which is problematic because what kind of species needs to be known and most likely this reformation was mentioned in the pre- vious sentence.</S>
  <S sid="165" ssid="165">Similarly, relations were found be- tween "device" and "plot", "metaphor", and "char- acter", underspecifying the fact that literary devices of some sort are under discussion.</S>
  <S sid="166" ssid="166">Sometimes the relationship expressed is slightly askance of the norm.</S>
  <S sid="167" ssid="167">For example, the algorithm finds hyponym( "Washington", nationalist")and hy- ponym( "aircraft", "target") which are somewhat con- text and point-of-view dependent.</S>
  <S sid="168" ssid="168">This is not neces- sarily a problem; as mentioned above, finding alter- native ways of stating similar notions is one of our goals.</S>
  <S sid="169" ssid="169">However, it is important to try to distinguish the more canonical and context-independent relations for entry in a thesaurus.</S>
  <S sid="170" ssid="170">There are a few relations whose hypernyms are very high-level terms, e.g., "substance" aud "form".</S>
  <S sid="171" ssid="171">These are not incorrect; they just may not be as useful as more specific relations.</S>
  <S sid="172" ssid="172">Overall, the results are encouraging.</S>
  <S sid="173" ssid="173">Although the number of relations found is small compared to the size of the text used, this situation can he greatly im- proved in several ways.</S>
  <S sid="174" ssid="174">Less stringent restrictions will increase the numbers, as the slight loosening shown in the Groliers experiment indicates.</S>
  <S sid="175" ssid="175">A more savvy grammar for the constituent analyzer should also in- crease the results.</S>
  <S sid="176" ssid="176">3.2 Automatic Updating The question arises as to how to automatically in- sert relations between terms into the hierarchy.</S>
  <S sid="177" ssid="177">This involves two main difficulties.</S>
  <S sid="178" ssid="178">First, if both lexical expressions are present in the noun hierarchy but one or both }lave more than one sense, the algorithm ust decide which senses to link together.</S>
  <S sid="179" ssid="179">We have prelim- inary ideas as to how to work around this problem.</S>
  <S sid="180" ssid="180">Say the hyponym in question has only one sense, but the hypernym has several.</S>
  <S sid="181" ssid="181">Then the task is simplified to determining which sense of the hypernym to link the hypouym to.</S>
  <S sid="182" ssid="182">We can then make use of a lexical disambiguation algorithm, e.g., (Hearst 1991), to de- termine which sense of the hypernym is being used iu the sample sentence.</S>
  <S sid="183" ssid="183">Furthermore, since weve assumed the hyponym has only one main sense we could do tile following: Look through a corpus for occurrences of the hyponym and see if its environment tends to be similar to one of the senses of its hypernym.</S>
  <S sid="184" ssid="184">For example, if the hypernym is "bank" and the hyponym is "First National", ev- ery time, within a sample of text, the term "First National" occurs, replace it with "bank", and then run the disambiguation algorithm as usual.</S>
  <S sid="185" ssid="185">If this term can be positively classified as having one sense of bank over the others, then this would provide strong evidence as to which sense of the hypernym to link the hypouym to.</S>
  <S sid="186" ssid="186">This idea is purely speculative; we have not yet tested it.</S>
  <S sid="187" ssid="187">The second main problem with inserting new rela- tions arises when one or both terms do not occur in the hierarchy at all.</S>
  <S sid="188" ssid="188">In this case, we have to deter- mine which, if any, existing synset the term belongs in and then do the sense determination mentioned above.</S>
  <S sid="189" ssid="189">4 Conc lus ions We have described a low-cost approach for automatic acquisition of semantic lexical relations from uure- stricted text.</S>
  <S sid="190" ssid="190">This method is meant to provide an incremental step toward the larger goals of natural language processing.</S>
  <S sid="191" ssid="191">Our approach is complementary to statistically based approaches that find semantic relations between terms, iu that ours requires a sin- gle specially expressed instance of a relation while the others require a statistically significant number of generally expressed relations.</S>
  <S sid="192" ssid="192">Weve shown that our approach is also useful as a critiquing component for existing knowledge bases and lexicons.</S>
  <S sid="193" ssid="193">We plan to test the pattern discovery algorithm on more relations and on languages other than English (depending on the corpora available).</S>
  <S sid="194" ssid="194">We would also like to do some analysis of the noun phrases that are acquired, and to explore the effects of various kinds of modifiers on the appropriateness of the noun phrase.</S>
  <S sid="195" ssid="195">We plan to do this in the context of analyzing envi- ronmental impact reports.</S>
  <S sid="196" ssid="196">Acknowledgements .</S>
  <S sid="197" ssid="197">This work was supported in part by an internship at tile Xerox Palo Alto Research Center and in part by the University of California nd Digital Equipment Corporation under Digitals flag- AcrEs DE COLING-92, NANTES, 23-28 ^o~-r 1992 5 4 4 PRoc.</S>
  <S sid="198" ssid="198">23-28, 1992 ship research project Sequoia 2000: Large Capacity Object Servers to Support Global Change Research.</S>
  <S sid="199" ssid="199">References Ahlswede, T. &amp; M. Evens (1988).</S>
  <S sid="200" ssid="200">Parsing vs. text processing in the analysis of dictionary defini- tions.</S>
  <S sid="201" ssid="201">Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, pages 217-224.</S>
  <S sid="202" ssid="202">Alshawi, H. (1987).</S>
  <S sid="203" ssid="203">Processing dictionary definitions with phrasal pattern hierarchies.</S>
  <S sid="204" ssid="204">American Jour- nal of Computational Linguistics, 13(3):195 202.</S>
  <S sid="205" ssid="205">Automatic Acquisition and Use of Some of the Knowledge in Physics Tezts.</S>
  <S sid="206" ssid="206">PhD thesis, Massachusetts Institute of Technology, Artificial Intelligence Laboratory.</S>
  <S sid="207" ssid="207">Brent, M. R. (1991).</S>
  <S sid="208" ssid="208">Automatic acquisition ofsubcat- egorization frames from untagged, free-text cor- pora.</S>
  <S sid="209" ssid="209">In Proceedings of the 29th Annual Meet- ing of the Association foe Computational Lin- guistics.</S>
  <S sid="210" ssid="210">Calzolari, N. &amp; R. Bindi (1990).</S>
  <S sid="211" ssid="211">Acquisition of lexi- cal information from a large textual italian cor- pus.</S>
  <S sid="212" ssid="212">In Proceedings of the Thirteenth Interna- tional Conference on Computational Linguistics, Helsinki.</S>
  <S sid="213" ssid="213">Coates-Stephens, S. (1991).</S>
  <S sid="214" ssid="214">Coping with lexical in- adequacy - the automatic acquisition of proper nouns from news text.</S>
  <S sid="215" ssid="215">In The Proceedings of the 7th Annual Conference of the UW Centre for the New OED and Tezt Research: Using Corpora, pages 154-169, Oxford.</S>
  <S sid="216" ssid="216">Cutting, D., J. Kupiec, J. Pedersen, &amp; P. Sibun (1991).</S>
  <S sid="217" ssid="217">A practical part-of-speech tagger.</S>
  <S sid="218" ssid="218">Sub- mitted to The 3rd Conference on Applied Natural Language Process*ng.</S>
  <S sid="219" ssid="219">Grolier (1990).</S>
  <S sid="220" ssid="220">Academic American Encyclopedia.</S>
  <S sid="221" ssid="221">Grolier Electronic Publishing, Danbury, Con- neeticut.</S>
  <S sid="222" ssid="222">Jensen, K. &amp; J.-L. Binot (1987).</S>
  <S sid="223" ssid="223">Disambiguating prepositional phrase attachments by using on- line dictionary definitions.</S>
  <S sid="224" ssid="224">American Journal of Computational Linguistics, 13(3):251-260.</S>
  <S sid="225" ssid="225">Markowitz, J., T. Ahlswede, &amp; M. Evens (1986).</S>
  <S sid="226" ssid="226">Se- mantically significant patterns in dictionary def- initions.</S>
  <S sid="227" ssid="227">Proceedings of the 24th Annual Meet- ing of the Assoczation for Computational Lin- guistics, pages 112-119.</S>
  <S sid="228" ssid="228">Miller, G. A., R. Beckwith, C. Fellbaum, D. Gross, &amp; K. J. Miller (1990).</S>
  <S sid="229" ssid="229">Introduction to wordnet: An on-line lexieal database.</S>
  <S sid="230" ssid="230">Journal of Le~xieography, 3(4):235-244.</S>
  <S sid="231" ssid="231">&amp; G. Hirst (1991).</S>
  <S sid="232" ssid="232">Lexical cohesion com- puted by tbesaural relations as an indicator of the structure of text.</S>
  <S sid="233" ssid="233">Computational Lzngmstics, 17(1):21-48.</S>
  <S sid="234" ssid="234">&amp; M. Nagao (1988).</S>
  <S sid="235" ssid="235">Extraction of se- mantic inlbrmation t?om an ordinary english dic- tionary and its evaluation.</S>
  <S sid="236" ssid="236">In Proceedings of the Twelfth International Conference on Computa- tional Linguistics, pages 459-464, Budapest.</S>
  <S sid="237" ssid="237">&amp; K. R. McKeown (1990).</S>
  <S sid="238" ssid="238">Automati- cally extracting and representing collocations for language generation.</S>
  <S sid="239" ssid="239">Proceedings ofthe 28th An- nual Meeting of the Association for Computa- tional Linguistics, pages 252-259.</S>
  <S sid="240" ssid="240">Velardi, P. &amp; M. T. Pazienza (1989).</S>
  <S sid="241" ssid="241">Computer aided interpretation of lexical cooccurrences.</S>
  <S sid="242" ssid="242">Proceed- ings of the 27th Annual Meeting of the Associ- ation for Computational Linguistics, pages 185- 192.</S>
  <S sid="243" ssid="243">A., D. C. Fass, C. ruing Guo, J. E. McDon- ald, T. Plate, &amp; B. M. Slator (1990).</S>
  <S sid="244" ssid="244">Providing machine tractable dictionary tools.</S>
  <S sid="245" ssid="245">Journal of Machzne Translation, 2.</S>
  <S sid="246" ssid="246">Noun homograph disambigua- tion using local context in large text corpora.</S>
  <S sid="247" ssid="247">In The Proceedings of the 7th Annual Conference of the UW Centre for the New OED and Tezt Research: Using Corpora, Oxford.</S>
  <S sid="248" ssid="248">Hindle, D. (1990).</S>
  <S sid="249" ssid="249">Noun classification from predicate- argument structures.</S>
  <S sid="250" ssid="250">Proceedings ofthe 28th An- nual Meeting of the Association for Computa- tional Linguistics, pages 268-275.</S>
  <S sid="251" ssid="251">Jacobs, P. &amp; U. Zernik (1988).</S>
  <S sid="252" ssid="252">Acquiring lexical knowledge from text: A case study.</S>
  <S sid="253" ssid="253">In Proceed- ings of AAAI88, pages 739-744.</S>
  <S sid="254" ssid="254">ACrF~ DE COLING-92, NANTES, 23-28 AOt~T 1992 5 4 5 PRoc.</S>
  <S sid="255" ssid="255">OF COLING-92, NANTnS.</S>
</PAPER>
