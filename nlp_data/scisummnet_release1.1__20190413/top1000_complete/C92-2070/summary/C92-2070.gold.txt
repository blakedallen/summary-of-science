Word-Sense Disambiguation Using Statistical Models Of Roget's Categories Trained On Large Corpora
This paper describes a program that disambignates English word senses in unrestricted text using statistical models of the major Roget's Thesaurus categories.
Roget's categories serve as approximations of conceptual classes.
The categories listed for a word in Roger's index tend to correspond to sense distinctions; thus selecting the most likely category provides a useful level of sense disambiguation.
The selection of categories is accomplished by identifying and weighting words that are indicative of each category when seen in context, using a Bayesian theoretical framework.
Other statistical approaches have required special corpora or hand-labeled training examples for much of the lexicon.
Our use of class models overcomes this knowledge acquisition bottleneck, enabling training on unrestricted monolingual text without human intervention.
Applied to the 10 million word Grolier's Encyclopedia, the system correctly disambiguated 92% of the instances of 12 polysemous words that have been previously studied in the literature.
We rely on the intuition that the senses of words are hinted at by their contextual information. From the perspective of a generative process, neighboring words of a target are generated by the target's underlying sense.
