[
  {
    "citance_No": 1, 
    "citing_paper_id": "N10-1068", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "David, Chiang | Jonathan, Graehl | Kevin, Knight | Adam, Pauls | Sujith, Ravi", 
    "raw_text": "Each point represents one run; the y-axis is tagging accuracy and the x-axis is the average? log P (derivation) over all samples after burn-in. Bayesian methods (85.2% from Goldwater and Griffiths (2007), who use a trigram model) and close to the best accuracy reported on this task (91.8% from Ravi and Knight (2009b), who use an integer linear program to minimize the model directly)", 
    "clean_text": "Bayesian methods (85.2% from Goldwater and Griffiths (2007), who use a trigram model) and close to the best accuracy reported on this task (91.8% from Ravi and Knight (2009b), who use an integer linear program to minimize the model directly).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P10-1051", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Sujith, Ravi | Jason, Baldridge | Kevin, Knight", 
    "raw_text": "Ravi and Knight (2009) achieved the best results thus far (92.3% word token accuracy) via a MinimumDescription Length approach using an integer pro gram (IP) that finds a minimal bigram grammar that obeys the tag dictionary constraints and covers the observed data. A more challenging task is learning super tag gers for lexicalized grammar formalisms such asCombinatory Categorial Grammar (CCG) (Steedman, 2000)", 
    "clean_text": "Ravi and Knight (2009) achieved the best results thus far (92.3% word token accuracy) via a Minimum Description Length approach using an integer program (IP) that finds a minimal bigram grammar that obeys the tag dictionary constraints and covers the observed data.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P10-1051", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Sujith, Ravi | Jason, Baldridge | Kevin, Knight", 
    "raw_text": "The strategies employed in Ravi and Knight (2009) and Baldridge (2008) are complementary", 
    "clean_text": "The strategies employed in Ravi and Knight (2009) and Baldridge (2008) are complementary.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P10-1051", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Sujith, Ravi | Jason, Baldridge | Kevin, Knight", 
    "raw_text": "Applying the approach of Ravi and Knight (2009) naively to CCG super tagging is intractable due to the high level of ambiguity", 
    "clean_text": "Applying the approach of Ravi and Knight (2009) naively to CCG supertagging is intractable due to the high level of ambiguity.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P10-1051", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Sujith, Ravi | Jason, Baldridge | Kevin, Knight", 
    "raw_text": "However, the original IP method of Ravi and Knight (2009) is intractable for super tagging, so we propose a new two-stage method that scales to the larger tag sets and data involved", 
    "clean_text": "However, the original IP method of Ravi and Knight (2009) is intractable for supertagging, so we propose a new two-stage method that scales to the larger tag sets and data involved.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P10-1051", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Sujith, Ravi | Jason, Baldridge | Kevin, Knight", 
    "raw_text": "This stage uses the original minimization formulation for the super tagging problem IPoriginal, again using an integer programming method similar to that pro posed by Ravi and Knight (2009)", 
    "clean_text": "This stage uses the original minimization formulation for the supertagging problem I Poriginal, again using an integer programming method similar to that proposed by Ravi and Knight (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P10-1051", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Sujith, Ravi | Jason, Baldridge | Kevin, Knight", 
    "raw_text": "Raviand Knight (2009) exploited this to iteratively improve their POS tag model: since the first minimization procedure is seeded with a noisy gram mar and tag dictionary, iterating the IP procedure with progressively better grammars further improves the model", 
    "clean_text": "Ravi and Knight (2009) exploited this to iteratively improve their POS tag model: since the first minimization procedure is seeded with a noisy gram mar and tag dictionary, iterating the IP procedure with progressively better grammars further improves the model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "C10-2159", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mehmet Ali, Yatbaz | Deniz, Yuret", 
    "raw_text": "dictionary (Goldberg et al, 2008) 91.8 Minimized models for EM-HMM with 100 random restarts (Ravi and Knight, 2009).", 
    "clean_text": "Minimized models for EM-HMM with 100 random restarts (Ravi and Knight, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "C10-2159", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mehmet Ali, Yatbaz | Deniz, Yuret", 
    "raw_text": "(Ravi and Knight, 2009) focus on the POS tag collection to find the smallest POS model that ex plain the data", 
    "clean_text": "(Ravi and Knight, 2009) focus on the POS tag collection to find the smallest POS model that explain the data.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "C10-2159", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mehmet Ali, Yatbaz | Deniz, Yuret", 
    "raw_text": "The abuse of the rare tags is presented in Table 5 in a similar fashion with (Ravi and Knight, 2009)", 
    "clean_text": "The abuse of the rare tags is presented in Table 5 in a similar fashion with (Ravi and Knight, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "C10-2159", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mehmet Ali, Yatbaz | Deniz, Yuret", 
    "raw_text": "Model Accuracy Data Size BHMM 87.3 24K CE+spl 88.7 24K RD 92.9 24K LDA+AC 93.4 1M InitEM-HMM 93.8 1M IP+EM 96.8 24K Table 9: Performance of different systems using the coarse grained dictionary. The IP+EM system constructs a model that describes the data by using minimum number of bi gram POS tags then uses this model to reduce the dictionary size (Ravi and Knight, 2009)", 
    "clean_text": "The IP+EM system constructs a model that describes the data by using minimum number of bi gram POS tags then uses this model to reduce the dictionary size (Ravi and Knight, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P11-1061", 
    "citing_paper_authority": 63, 
    "citing_paper_authors": "Dipanjan, Das | Slav, Petrov", 
    "raw_text": "Ravi and Knight (2009) instead of the feature-HMM for POS induction on the foreign side", 
    "clean_text": "Ravi and Knight (2009) instead of the feature-HMM for POS induction on the foreign side.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "D10-1083", 
    "citing_paper_authority": 14, 
    "citing_paper_authors": "Yoong Keok, Lee | Aria, Haghighi | Regina, Barzilay", 
    "raw_text": "A more rigid mechanism for modeling sparsity is proposed by Ravi and Knight (2009), who minimize the size of tagging grammar as measured by the number of transition types", 
    "clean_text": "A more rigid mechanism for modeling sparsity is proposed by Ravi and Knight (2009), who minimize the size of tagging grammar as measured by the number of transition types.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "D12-1075", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Dan, Garrette | Jason, Baldridge", 
    "raw_text": "To avoid the need for manually pruning the tag dictionary, Ravi and Knight (2009) 824? b? The boy sees a dog? \b?? b? 2%% DT 1& amp;& amp; DT 1%% NN& amp;& amp; NN 3 \u0018\u0018 V B& amp;& amp; BB FW? \b? Figure 1: MIN-GREEDY graph showing a state in the first phase", 
    "clean_text": "To avoid the need for manually pruning the tag dictionary, Ravi and Knight (2009) proposed that low-probability tags might be automatically filtered from the tag dictionary through a model minimization procedure applied to the raw text and constrained by the full tag dictionary.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P10-1132", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Omri, Abend | Roi, Reichart | Ari, Rappoport", 
    "raw_text": "Raviand Knight (2009) use a dictionary and an MDL inspired modification to the EM algorithm. Many of these works use a dictionary providing allowable tags for each or some of the words. While this scenario might reduce human annotation efforts, it does not induce a tagging scheme but remains tied to an existing one", 
    "clean_text": "Ravi and Knight (2009) use a dictionary and an MDL inspired modification to the EM algorithm.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P14-2132", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Hui, Zhang | John, DeNero", 
    "raw_text": "This efficient and data-driven approach gives the best reported tagging accuracy for type-supervised sequence models, outperforming the minimized model of Ravi and Knight (2009), the Bayesian LDA-based model of Toutanova and Johnson (2008), and an HMM trained with language-specific initialization described by Goldberg et al (2008)", 
    "clean_text": "This efficient and data-driven approach gives the best reported tagging accuracy for type-supervised sequence models, outperforming the minimized model of Ravi and Knight (2009), the Bayesian LDA-based model of Toutanova and Johnson (2008), and an HMM trained with language-specific initialization described by Goldberg et al (2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P14-2132", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Hui, Zhang | John, DeNero", 
    "raw_text": "93.4? Linguistic initialization (Goldberg et al, 2008) 91.4? 93.8? Minimal models (Ravi and Knight, 2009)? 92.3? 96.8 Table 2: Tagging accuracy of different approaches on English Penn Treebank", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P14-2132", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Hui, Zhang | John, DeNero", 
    "raw_text": "Columns labeled 973k train describe models trained on the subset of 973k tokens used by Ravi and Knight (2009)", 
    "clean_text": "Columns labeled 973k train describe models trained on the subset of 973k tokens used by Ravi and Knight (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P14-2132", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Hui, Zhang | John, DeNero", 
    "raw_text": "Ravi and Knight (2009) employs integer linear programming to select a minimal set of parameters that can generate the test sentences, followed by EM to set parameter values", 
    "clean_text": "Ravi and Knight (2009) employs integer linear programming to select a minimal set of parameters that can generate the test sentences, followed by EM to set parameter values.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D12-1127", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Jo&atilde;o, Gra&ccedil;a | Shen, Li | Ben, Taskar", 
    "raw_text": "For example, the work if Ravi and Knight (2009) minimizes the number of possible tag-tag transitions in the HMMviaa integer program, hence discarding unlikely transitions that would confuse the model", 
    "clean_text": "For example, the work of Ravi and Knight (2009) minimizes the number of possible tag-tag transitions in the HMM via an integer program, hence discarding unlikely transitions that would confuse the model.", 
    "keep_for_gold": 0
  }
]
