[
  {
    "citance_No": 1, 
    "citing_paper_id": "N10-1075", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Robert, Munro | Christopher D., Manning", 
    "raw_text": "We therefore omit these for space and scope. However, one interesting result came from ex tending the feature space with topics derived from Latent Dirichlet Allocation (LDA) using similar methods to Ramage et al (2009)", 
    "clean_text": "However, one interesting result came from extending the feature space with topics derived from Latent Dirichlet Allocation (LDA) using similar methods to Ramage et al (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-3004", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "C\u00c3\u00a4cilia, Zirn", 
    "raw_text": "There are variations of topic models that al low for influencing the creation of the topics, such as the systems of (Ramage et al, 2009) (LabeledLDA), (Andrzejewski and Zhu, 2009) or (Jagarlamudi et al, 2012)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "D12-1073", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Zhao-Yan, Ming | Xian-Ling, Mao | Hongfei, Yan | Tat-Seng, Chua | Xiaoming, Li | Si, Li", 
    "raw_text": "Another category of models, such as the MM-LDA (Ramage et al2009b), Author TM (Rosen-Zvi et al2004), Flat LDA (Rubin et al2011), Prior-LDA (Rubin et al 2011), Dependency-LDA (Rubin et al2011) and Partially LDA (PLDA) (Ramage et al2011) etc., are not constrained to one label per document be cause they model each document as a bag of words with a bag of labels", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D12-1073", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Zhao-Yan, Ming | Xian-Ling, Mao | Hongfei, Yan | Tat-Seng, Chua | Xiaoming, Li | Si, Li", 
    "raw_text": "Labeled LDA (LLDA) (Ramage et al2009a) can be used to solve this problem. None of these non-hierarchical supervised mod els, however, leverage on dependency structure, such as parent-child relation, in the label space", 
    "clean_text": "Labeled LDA (LLDA) (Ramage et al 2009a) can be used to solve this problem.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P13-1024", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Weiwei, Guo | Hao, Li | Heng, Ji | Mona, Diab", 
    "raw_text": "Modeling Tweets in a Latent Space: Ramageet al (2010) also use hash tags to improve the la tent representation of tweets in a LDA framework, Labeled-LDA (Ramage et al, 2009), treating eachhashtag as a label", 
    "clean_text": "Modeling Tweets in a Latent Space: Ramage et al (2010) also use hash tags to improve the latent representation of tweets in a LDA framework, Labeled-LDA (Ramage et al, 2009), treating each hashtag as a label.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W11-1101", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Dingcheng, Li | Swapna, Somasundaran | Amit, Chakraborty", 
    "raw_text": "Latent Dirichlet Allo cation and its supervised extensions such as Labeled LDA (LLDA) (Ramage et al, 2009) and supervisedLDA (sLDA) (Blei and McAuliffe, 2008) are powerful generative models that capture the underlying semantics of texts", 
    "clean_text": "Latent Dirichlet Allocation and its supervised extensions such as Labeled LDA (LLDA) (Ramage et al, 2009) and supervised LDA (sLDA) (Blei and McAuliffe, 2008) are powerful generative models that capture the underlying semantics of texts.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P12-2052", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Yanir, Seroussi | Fabian, Bohnert | Ingrid, Zukerman", 
    "raw_text": "Lacoste-Julien et al (2008) and Ramage et al (2009) (among others) also used disjoint topic sets to represent document labels, and Chemudugunta et al (2006) separated corpus-level topics from document-specific words", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D11-1141", 
    "citing_paper_authority": 47, 
    "citing_paper_authors": "Alan, Ritter | Sam, Clark | Mausam,  | Oren, Etzioni", 
    "raw_text": "1524 knowledge. To address these issues we propose a distantly supervised approach which applies LabeledLDA (Ramage et al, 2009) to leverage large amounts of unlabeled data in addition to large dictionaries of entities gathered from Freebase, and combines information about an entity? s context across its mentions", 
    "clean_text": "To address these issues we propose a distantly supervised approach which applies LabeledLDA (Ramage et al, 2009) to leverage large amounts of unlabeled data in addition to large dictionaries of entities gathered from Freebase, and combines information about an entity's context across its mentions.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D11-1141", 
    "citing_paper_authority": 47, 
    "citing_paper_authors": "Alan, Ritter | Sam, Clark | Mausam,  | Oren, Etzioni", 
    "raw_text": "Distant Supervision with Topic Models: To model unlabeled entities and their possible types ,weapply LabeledLDA (Ramage et al, 2009), constraining each entity? s distribution over topics based on its set of possible types according to Freebase", 
    "clean_text": "Distant Supervision with Topic Models: To model unlabeled entities and their possible types, we apply LabeledLDA (Ramage et al, 2009), constraining each entity's distribution over topics based on its set of possible types according to Freebase.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P11-1026", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Yuening, Hu | Jordan, Boyd-Graber | Brianna, Satinoff", 
    "raw_text": "i.e. deterministically hold constant topic assignments (Ramage et al, 2009)", 
    "clean_text": "In other models, this input is sometimes used to \"fix,\" i.e. deterministically hold constant topic assignments (Ramage et al, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "E12-1021", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Jagadeesh, Jagarlamudi | Hal, Daum&eacute; III | Raghavendra, Udupa", 
    "raw_text": "To enable this, we first take class labeled data (doesn? t need to be multi-class labeled data unlike (Ramage et al 2009)) and identify the discriminating features for each class", 
    "clean_text": "To enable this, we first take class labeled data (doesn't need to be multi-class labeled data unlike (Ramage et al 2009)) and identify the discriminating features for each class.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "E12-1021", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Jagadeesh, Jagarlamudi | Hal, Daum&eacute; III | Raghavendra, Udupa", 
    "raw_text": "Of these models, the most related one to SeededLDA is the LabeledLDA model (Ramage et al 2009)", 
    "clean_text": "Of these models, the most related one to SeededLDA is the Labeled LDA model (Ramage et al 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P11-2118", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Yves, Petinot | Kathleen R., McKeown | Kapil, Thadani", 
    "raw_text": "Our purpose here is more specialized and similar to that of Labeled LDA (Ramage et al, 2009a) or FixedhLDA (Reisinger and Pas? ca, 2009) where the set of topics associated with a document is known a priori", 
    "clean_text": "Our purpose here is more specialized and similar to that of Labeled LDA (Ramage et al, 2009a) or FixedhLDA (Reisinger and Pas? ca, 2009) where the set of topics associated with a document is known a priori.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P11-2118", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Yves, Petinot | Kathleen R., McKeown | Kapil, Thadani", 
    "raw_text": "Since the non-Regional portion of the DMOZ hierarchy is organized more consistently ina semantic fashion6, we believe this reflects the ability of the hierarchical models to take advantage of6The specificity of the Regional sub-tree has also been dis cussed by previous work (Ramage et al, 2009b), justifying a special treatment for that part of the DMOZ dataset", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P13-1066", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Arjun, Mukherjee | Bing, Liu", 
    "raw_text": "There have been various extensions to multi-grain (Titov and McDonald, 2008), labeled (Ramage et al, 2009), and sequential (Du et al, 2010) topic models", 
    "clean_text": "There have been various extensions to multi-grain (Titov and McDonald, 2008), labeled (Ramage et al, 2009), and sequential (Du et al, 2010) topic models.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P12-1034", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Arjun, Mukherjee | Bing, Liu", 
    "raw_text": "There have been various extensions to multi-grain (Titov and McDonald, 2008a), labeled (Ramage et al, 2009), partially-labeled (Ramage et al, 2011), constrained (Andrzejewski et al, 2009) models, etc. These models produce only topics but not multiple types of expressions together with topics", 
    "clean_text": "There have been various extensions to multi-grain (Titov and McDonald, 2008a), labeled (Ramage et al, 2009), partially-labeled (Ramage et al, 2011), constrained (Andrzejewski et al, 2009) models, etc.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "D11-1050", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Matthias, Hartung | Anette, Frank", 
    "raw_text": "We present two variants of LDA that differ in the way attributes are associated with the induced LDA topics: Controled LDA (C-LDA) and Labeled LDA (L-LDA; Ramage et al (2009))", 
    "clean_text": "We present two variants of LDA that differ in the way attributes are associated with the induced LDA topics: Controled LDA (C-LDA) and Labeled LDA (L-LDA; Ramage et al (2009)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "D11-1050", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Matthias, Hartung | Anette, Frank", 
    "raw_text": "Recent work investigates ways of accommodating supervision with LDA ,e.g. supervised topic models (Blei and McAuliffe, 2007), Labeled LDA (L-LDA) (Ramage et al, 2009) or DiscLDA (Lacoste-Julien et al, 2008)", 
    "clean_text": "Recent work investigates ways of accommodating supervision with LDA, e.g. supervised topic models (Blei and McAuliffe, 2007), Labeled LDA (L-LDA) (Ramage et al, 2009) or DiscLDA (Lacoste-Julien et al, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "D11-1050", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Matthias, Hartung | Anette, Frank", 
    "raw_text": "Figure 2: L-LDA generative process (Ramage et al 2009) P (w|a)? P (w|d)=? t P (w|t) P (t|d) (4) 3.3 Labeled LDA", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D11-1050", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Matthias, Hartung | Anette, Frank", 
    "raw_text": "L-LDA (Ramage et al, 2009) extends standard LDA to include supervision for specific target categories, yet in a different way: (i) The generative process includes a second observed variable ,i.e. each document is explicitly labeled with a target category. A document may be labeled with an arbitrary number of categories; unlabeled documents are also possible", 
    "clean_text": "L-LDA (Ramage et al, 2009) extends standard LDA to include supervision for specific target categories, yet in a different way: (i) The generative process includes a second observed variable, i.e. each document is explicitly labeled with a target category.", 
    "keep_for_gold": 1
  }
]
