Exploring Content Models for Multi-Document Summarization
We present an exploration of generative probabilistic models for multi-document summarization.
Beginning with a simple word frequency based model (Nenkova and Vanderwende, 2005), we construct a sequence of models each injecting more structure into the representation of document set content and exhibiting ROUGE gains along the way.
Our final model, HIERSUM, utilizes a hierarchical LDA-style model (Blei et al., 2004) to represent content specificity as a hierarchy of topic vocabulary distributions.
At the task of producing generic DUC-style summaries, HIERSUM yields state-of-the-art ROUGE performance and in pairwise user evaluation strongly outperforms Toutanova et al. (2007)'s state-of-the-art discriminative system.
We also explore HIERSUM's capacity to produce multiple 'topical summaries' in order to facilitate content discovery and navigation.
In TOPICSUM, each word is generated by a single topic which can be a corpus-wide background distribution over common words, a distribution of document-specific words or a distribution of the core content of a given cluster.
We build a summarization system based on topic models, where both topics at general document level as well as those at specific subtopic levels were learnt.
