Mixture-Model Adaptation for SMT
We describe a mixture-model approach to adapting a Statistical Machine Translation System for new domains, using weights that depend on text distances to mixture components.
We investigate a number of variants on this approach, including cross-domainversus dynamic adaptation; linear versus loglinear mixtures; language and translation model adaptation; different methods of assigning weights; and granularity of the source unit being adapted to.
The best methods achieve gains of approximately one BLEU percentage point over a state-of-the art non-adapted baseline system.
We conclude that the best approach was to combine submodels of the same type (for instance, several different TMs or several different LMs) linearly, while combining models of different types (for instance, a mixture TM with a mixture LM) log linearly.
We interpolate the in and general-domain phrase tables together, assigning either linear or log-linear weights to the entries in the tables before combining overlapping entries; this is now standard practice.
