[
  {
    "citance_No": 1, 
    "citing_paper_id": "W04-3215", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Stephen, Clark | Mark, Steedman | James R., Curran", 
    "raw_text": "The CCG parser used here (Clark and Curran, 2004b) is highly accurate and efficient, recovering labelled dependencies with an overall F-score of over 84% on WSJ text, and parsing up to 50 sentences per second", 
    "clean_text": "The CCG parser used here (Clark and Curran, 2004b) is highly accurate and efficient, recovering labelled dependencies with an overall F-score of over 84% on WSJ text, and parsing up to 50 sentences per second.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W04-3215", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Stephen, Clark | Mark, Steedman | James R., Curran", 
    "raw_text": "The parser used in this paper is described in Clark and Curran (2004b)", 
    "clean_text": "The parser used in this paper is described in Clark and Curran (2004b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W04-3215", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Stephen, Clark | Mark, Steedman | James R., Curran", 
    "raw_text": "A Maximum Entropy CCG super tagger (Clark and Curran, 2004a) is used to assign the categories", 
    "clean_text": "A Maximum Entropy CCG supertagger (Clark and Curran, 2004a) is used to assign the categories.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W04-3215", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Stephen, Clark | Mark, Steedman | James R., Curran", 
    "raw_text": "In Clark and Curran (2004b) we investigate several log-linear parsing models for CCG", 
    "clean_text": "In Clark and Curran (2004b) we investigate several log-linear parsing models for CCG.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W04-3215", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Stephen, Clark | Mark, Steedman | James R., Curran", 
    "raw_text": "The parsing results in Clark and Curran (2004b) rely on a super tagger per-word accuracy of at least 97%, and a sentence accuracy of at least 60% (for1.5 categories per word)", 
    "clean_text": "The parsing results in Clark and Curran (2004b) rely on a supertagger per-word accuracy of at least 97%, and a sentence accuracy of at least 60% (for 1.5 categories per word).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W04-3215", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Stephen, Clark | Mark, Steedman | James R., Curran", 
    "raw_text": "However, the scores in Clark and Curran (2004b) give an indication of how super tagging accuracy corresponds to overall dependency recovery", 
    "clean_text": "However, the scores in Clark and Curran (2004b) give an indication of how supertagging accuracy corresponds to overall dependency recovery.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "C10-2051", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Matthew, Honnibal | Jonathan K., Kummerfeld | James R., Curran", 
    "raw_text": "This is particularly true of the C& amp; C parser, which exploits CCG? s lexicalisation to divide the parsing task between two integrated models (Clark and Curran, 2004) .We have followed this formalism-driven approach by exploiting morphology for English syntactic parsing, using a strategy designed for morphologically rich languages", 
    "clean_text": "This is particularly true of the C&C parser, which exploits CCG? s lexicalisation to divide the parsing task between two integrated models (Clark and Curran, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "N06-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Stephen, Clark | James R., Curran", 
    "raw_text": "The dependency parsing model of Clark and Curran (2004b) is ex tended to exploit this partial training data", 
    "clean_text": "The dependency parsing model of Clark and Curran (2004b) is extended to exploit this partial training data.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "N06-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Stephen, Clark | James R., Curran", 
    "raw_text": "The formalism we use is Combinatory Categorial Grammar (Steedman, 2000), together with a parsing model described in Clark and Curran (2004b) which we adapt for use with partial data", 
    "clean_text": "The formalism we use is Combinatory Categorial Grammar (Steedman, 2000), together with a parsing model described in Clark and Curran (2004b) which we adapt for use with partial data.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "N06-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Stephen, Clark | James R., Curran", 
    "raw_text": "Parsing with Combinatory Categorial Grammar (CCG) takes place in two stages: first, CCG lexical categories are assigned to the words in the sentence, and then the categories are combined by the parser (Clark and Curran, 2004a)", 
    "clean_text": "Parsing with Combinatory Categorial Grammar (CCG) takes place in two stages: first, CCG lexical categories are assigned to the words in the sentence, and then the categories are combined by the parser (Clark and Curran, 2004a).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "N06-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Stephen, Clark | James R., Curran", 
    "raw_text": "The partial training method uses the log-linear dependency model described in Clark and Curran (2004b), which uses sets of predicate-argument de 144pendencies, rather than derivations, for training", 
    "clean_text": "The partial training method uses the log-linear dependency model described in Clark and Curran (2004b), which uses sets of predicate-argument dependencies, rather than derivations, for training.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "N06-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Stephen, Clark | James R., Curran", 
    "raw_text": "Clark and Curran (2004b) describes two log-linear parsing models for CCG: a normal-form derivation model and a dependency model", 
    "clean_text": "Clark and Curran (2004b) describes two log-linear parsing models for CCG: a normal-form derivation model and a dependency model.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "N06-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Stephen, Clark | James R., Curran", 
    "raw_text": "We define the probability of a dependency structure as the sum of the probabilities of all those derivations leading to that structure (Clark and Curran, 2004b)", 
    "clean_text": "We define the probability of a dependency structure as the sum of the probabilities of all those derivations leading to that structure (Clark and Curran, 2004b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "N06-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Stephen, Clark | James R., Curran", 
    "raw_text": "Clark and Curran (2004b) describes the training procedure for the dependency model, which uses a discriminative estimation method by maximising the conditional likelihood of the model given the data (Riezler et al, 2002)", 
    "clean_text": "Clark and Curran (2004b) describes the training procedure for the dependency model, which uses a discriminative estimation method by maximising the conditional likelihood of the model given the data (Riezler et al, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "N06-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Stephen, Clark | James R., Curran", 
    "raw_text": "Clark and Cur ran (2003) shows how the sum over the complete derivation space can be performed efficiently using a packed chart and the inside-outside algorithm, and Clark and Curran (2004b) extends this method to sum over all derivations leading to a gold-standard dependency structure", 
    "clean_text": "Clark and Curran (2003) shows how the sum over the complete derivation space can be performed efficiently using a packed chart and the inside-outside algorithm, and Clark and Curran (2004b) extends this method to sum over all derivations leading to a gold-standard dependency structure.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "N06-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Stephen, Clark | James R., Curran", 
    "raw_text": "The definitions of the objective function (4) and the gradient (5) for training remain the same in the partial-data case; the only differences are that? (pi) is now defined to be those derivations which are con sis tent with the partial dependency structure pi, and the gold-standard dependency structures pij are the partial structures extracted from the gold-standard lexical category sequences.2 Clark and Curran (2004b) gives an algorithm forfinding all derivations in a packed chart which produce a particular set of dependencies", 
    "clean_text": "The definitions of the objective function (4) and the gradient (5) for training remain the same in the partial-data case; the only differences are that (pi) is now defined to be those derivations which are con sis tent with the partial dependency structure pi, and the gold-standard dependency structures pij are the partial structures extracted from the gold-standard lexical category sequences. Clark and Curran (2004b) gives an algorithm for finding all derivations in a packed chart which produce a particular set of dependencies.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "N06-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Stephen, Clark | James R., Curran", 
    "raw_text": "The lexical category sequences for the sentences in 2-21 can easily be read off the CCGbank derivations. The derivations licenced by a lexical category sequence were created using the CCG parser described in Clark and Curran (2004b)", 
    "clean_text": "The lexical category sequences for the sentences in 2-21 can easily be read off the CCGbank derivations. The derivations licenced by a lexical category sequence were created using the CCG parser described in Clark and Curran (2004b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "N06-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Stephen, Clark | James R., Curran", 
    "raw_text": "The training data for the dependency model was created by first super tagging the sentences in sections 2-21, using the super tagger described in Clark and Curran (2004b) .4 The average number of categories 3Since our training method is intended to be applicable in the absence of derivation data, the use of such rules may appear suspect", 
    "clean_text": "The training data for the dependency model was created by first supertagging the sentences in sections 2-21, using the supertagger described in Clark and Curran (2004b). The average number of categories Since our training method is intended to be applicable in the absence of derivation data, the use of such rules may appear suspect.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "N06-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Stephen, Clark | James R., Curran", 
    "raw_text": "Approximate memory usage in each case was 17.6 GB of RAM.The dependency model uses the same set of features described in Clark and Curran (2004b) :dependency features representing predicate-argument dependencies (with and without distance measures); rule instantiation features encoding the combining categories together with the result category (wit hand without a lexical head); lexical category features, consisting of word? category pairs at the leaf nodes; and root category features, consisting of headword? category pairs at the root nodes", 
    "clean_text": "Approximate memory usage in each case was 17.6 GB of RAM.The dependency model uses the same set of features described in Clark and Curran (2004b): dependency features representing predicate-argument dependencies (with and without distance measures); rule instantiation features encoding the combining categories together with the result category (wit hand without a lexical head); lexical category features, consisting of word category pairs at the leaf nodes; and root category features, consisting of head word category pairs at the root nodes.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "N06-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Stephen, Clark | James R., Curran", 
    "raw_text": "The CCG parsing consists of two phases: first the super tagger assigns the most probable categories toeach word, and then the small number of combina tory rules, plus the type-changing and punctuation rules, are used with the CKY algorithm to build a packed chart.5 We use the method described in Clark and Curran (2004b) for integrating the supertaggerwith the parser: initially a small number of categories is assigned to each word, and more categories are requested if the parser can not find a spanning analysis", 
    "clean_text": "The CCG parsing consists of two phases: first the supertagger assigns the most probable categories toeach word, and then the small number of combinatory rules, plus the type-changing and punctuation rules, are used with the CKY algorithm to build a packed chart. We use the method described in Clark and Curran (2004b) for integrating the supertagger with the parser: initially a small number of categories is assigned to each word, and more categories are requested if the parser can not find a spanning analysis.", 
    "keep_for_gold": 1
  }
]
