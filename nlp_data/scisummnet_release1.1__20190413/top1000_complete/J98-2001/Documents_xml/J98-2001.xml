<PAPER>
  <S sid="0">A Corpus-Based Investigation Of Definite Description Use</S>
  <ABSTRACT>
    <S sid="1" ssid="1">We present the results of a study of the use of definite descriptions in written texts aimed at assessing the feasibility of annotating corpora with information about definite description interpretation.</S>
    <S sid="2" ssid="2">We ran two experiments, in which subjects were asked to classify the uses of definite descriptions in a corpus of 33 newspaper articles, containing a total of 1,412 definite descriptions.</S>
    <S sid="3" ssid="3">We measured the agreement among annotators about the classes assigned to definite descriptions, as well as the agreement about the antecedent assigned to those definites that the annotators classified as being related to an antecedent in the text.</S>
    <S sid="4" ssid="4">The most interesting result of this study a corpus annotation perspective was the rather low agreement = 0.63) we obtained versions of Hawkins's and Prince's classification schemes; better results = 0.76) obtained using the simplified scheme proposed by Fraurud that includes only two classes, firstmention and subsequent-mention.</S>
    <S sid="5" ssid="5">The agreement about antecedents was also not complete.</S>
    <S sid="6" ssid="6">These findings raise questions concerning the strategy of evaluating systems for definite description inby comparing their results with a standardized annotation. a linguistic of view, the most interesting observations were the great number of discourse-new definites in our corpus (in one of our experiments, about 50% of the definites in the collection were classified as discourse-new, 30% as anaphoric, and 18% as associative/bridging) and the presence of definites that did not seem to require a complete disambiguation.</S>
  </ABSTRACT>
  <SECTION title="" number="1">
    <S sid="7" ssid="1">We present the results of a study of the use of definite descriptions in written texts aimed at assessing the feasibility of annotating corpora with information about definite description interpretation.</S>
    <S sid="8" ssid="2">We ran two experiments, in which subjects were asked to classify the uses of definite descriptions in a corpus of 33 newspaper articles, containing a total of 1,412 definite descriptions.</S>
    <S sid="9" ssid="3">We measured the agreement among annotators about the classes assigned to definite descriptions, as well as the agreement about the antecedent assigned to those definites that the annotators classified as being related to an antecedent in the text.</S>
    <S sid="10" ssid="4">The most interesting result of this study from a corpus annotation perspective was the rather low agreement (K = 0.63) that we obtained using versions of Hawkins's and Prince's classification schemes; better results (K = 0.76) were obtained using the simplified scheme proposed by Fraurud that includes only two classes, firstmention and subsequent-mention.</S>
    <S sid="11" ssid="5">The agreement about antecedents was also not complete.</S>
    <S sid="12" ssid="6">These findings raise questions concerning the strategy of evaluating systems for definite description interpretation by comparing their results with a standardized annotation.</S>
    <S sid="13" ssid="7">From a linguistic point of view, the most interesting observations were the great number of discourse-new definites in our corpus (in one of our experiments, about 50% of the definites in the collection were classified as discourse-new, 30% as anaphoric, and 18% as associative/bridging) and the presence of definites that did not seem to require a complete disambiguation.</S>
  </SECTION>
  <SECTION title="1." number="2">
    <S sid="14" ssid="1">The work presented in this paper was inspired by the growing realization in the field of computational linguistics of the need for experimental evaluation of linguistic theories&#8212;semantic theories, in our case.</S>
    <S sid="15" ssid="2">The evaluation we are considering typically takes the form of experiments in which human subjects are asked to annotate texts from a corpus (or recordings of spoken conversations) according to a given classification scheme, and the agreement among their annotations is measured (see, for example, Passonneau and Litman 1993 or the papers in Moore and Walker 1997).</S>
    <S sid="16" ssid="3">These attempts at evaluation are, in part, motivated by the desire to put these theories on a more &amp;quot;scientific&amp;quot; footing by ensuring that the semantic judgments on which they are based reflect the intuitions of a large number of speakers;1 but experimental evaluation is also seen as a necessary precondition for the kind of system evaluation done, for example, in the Message Understanding initiative (MUC), where the performance of a system is evaluated by comparing its output on a collection of texts with a standardized annotation of those texts produced by humans (Chinchor and Sundheim 1995).</S>
    <S sid="17" ssid="4">Clearly, a MUC-style evaluation presupposes an annotation scheme on which all participants agree.</S>
    <S sid="18" ssid="5">Our own concern are semantic judgments concerning the interpretation of noun phrases with the definite article the, that we will call definite descriptions, following (Russell 1919).2 These noun phrases are one of the most common constructs in English,' and have been extensively studied by linguists, philosophers, psychologists, and computational linguists (Russell 1905; Christophersen 1939; Strawson 1950; Clark 1977; Grosz 1977; Cohen 1978; Hawkins 1978; Sidner 1979; Webber 1979; Clark and Marshall 1981; Prince 1981; Heim 1982; Appelt 1985; Li5bner 1985; Kadmon 1987; Carter 1987; Bosch and Geurts 1989; Neale 1990; Kronfeld 1990; Fraurud 1990; Barker 1991; Dale 1992; Cooper 1993; Kamp and Reyle 1993; Poesio 1993).</S>
    <S sid="19" ssid="6">Theories of definite descriptions such as (Christophersen 1939; Hawkins 1978; Webber 1979; Prince 1981; Heim 1982) identify two subtasks involved in the interpretation of a definite description: deciding whether the definite description is related to an antecedent in the texe&#8212;which in turn may involve recognizing fairly fine-grained distinctions-and, if so, identifying this antecedent.</S>
    <S sid="20" ssid="7">Some of these theories have been cast in the form of classification schemes (Hawkins 1978; Prince 1992), and have been used for corpus analysis (Prince 1981, 1992; Fraurud 1990);5 yet, we are aware of no attempt at verifying whether subjects not trained in linguistics are capable of recognizing the proposed distinctions, which is a precondition for using these schemes for the kind of large-scale text annotation exercises necessary to evaluate a system's performance, as done in muc.</S>
    <S sid="21" ssid="8">In the past two or three years, this kind of verification has been attempted for other aspects of semantic interpretation: by Passonneau and Litman (1993) for segmentation and by Kowtko, Isard, and Doherty (1992) and Carletta et al. (1997) for dialogue act annotation.</S>
    <S sid="22" ssid="9">Our intention was to do the same for definite descriptions.</S>
    <S sid="23" ssid="10">We ran two experiments to determine how good naive subjects are at doing the form of linguistic analysis presupposed by current schemes for classifying definite descriptions.</S>
    <S sid="24" ssid="11">(By &amp;quot;how good&amp;quot; here we mean &amp;quot;how much do they agree among themselves?&amp;quot; as commonly assumed in work of this kind.)</S>
    <S sid="25" ssid="12">Our subjects were asked to classify the definite descriptions found in a corpus of natural language texts according to classification schemes that we developed starting from the taxonomies proposed by Hawkins (1978) and Prince (1981, 1992), but which took into account our intention of having naive speakers perform the classification.</S>
    <S sid="26" ssid="13">Our experiments were also designed to assess the feasibility of a system to process definite descriptions on unrestricted text and to collect data that could be used for this implementation.</S>
    <S sid="27" ssid="14">For both of these reasons, the classification schemes that we tried differ in several respects from those adopted in prior corpus-based studies such as Prince (1981) and Fraurud (1990).</S>
    <S sid="28" ssid="15">Our study is also different from these previous ones in that measuring the agreement among annotators became an issue (Carletta 1996).</S>
    <S sid="29" ssid="16">For the experiments, we used a set of randomly selected articles from the Wall Street Journal contained in the ACL/DCI CD-ROM, rather than a corpus of transcripts of spoken language corpora such as the HCRC MapTask corpus (Anderson et al. 1991) or the TRAINS corpus (Heeman and Allen 1995).</S>
    <S sid="30" ssid="17">The main reason for this choice was to avoid dealing with deictic uses of definite descriptions and with phenomena such as reference failure and repair.</S>
    <S sid="31" ssid="18">A second reason was that we intended to use computer simulations of the classification task to supplement the results of our experiments, and we needed a parsed corpus for this purpose; the articles we chose were all part of the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993).</S>
    <S sid="32" ssid="19">In the remainder of the paper, we review two existing classification schemes in Section 2 and then discuss our two classification experiments in Sections 3 and 4.</S>
  </SECTION>
  <SECTION title="2." number="3">
    <S sid="33" ssid="1">When looking for an annotation scheme for definite descriptions, one is faced with a wide range of options.</S>
    <S sid="34" ssid="2">At one end of the spectrum there are mostly descriptive lists of definite description uses, such as those in Christophersen (1939) and Hawkins (1978), whose only goal is to assign a classification to all uses of definite descriptions.</S>
    <S sid="35" ssid="3">At the other end, there are highly developed formal analyses, such as Russell (1905), Heim (1982), Lobner (1985), Kadmon (1987), Neale (1990), Barker (1991), and Kamp and Reyle (1993), in which the compositional contribution of definite descriptions to the meaning of an utterance, as well as their truth-conditional properties, are spelled out in detail.</S>
    <S sid="36" ssid="4">These more formal analyses are concerned with questions such as the quantificational or nonquantificational status of definite descriptions and the proper treatment of presuppositions, but tend to concentrate on a subset of the full range of definite description use.</S>
    <S sid="37" ssid="5">Among the more developed semantic analyses, some identify uniqueness as the defining property of definite descriptions (Russell 1905; Neale 1990), whereas others take familiarity as the basis for the analysis (Christophersen 1939; Hawkins 1978; Heim 1982; Prince 1981; Kamp and Reyle 1993).</S>
    <S sid="38" ssid="6">We will say more about some of these analyses below.</S>
    <S sid="39" ssid="7">Our choice of a classification scheme was dictated in part by the intended use of the annotation, in part by methodological considerations.</S>
    <S sid="40" ssid="8">An annotation used to evaluate the performance of a system ought to identify the anaphoric connections between discourse entities; this makes familiarity-based analyses more attractive.</S>
    <S sid="41" ssid="9">From a methodological point of view, it was important to choose an annotation scheme that (i) would make the classification task doable by subjects not trained in linguistics, and (ii) had already been applied to the task of corpus analysis.</S>
    <S sid="42" ssid="10">We felt that we could ask naive subjects to assign each definite description to one of a few classes and to identify its antecedent when appropriate; we also wanted an annotation scheme that would characterize the whole range of definite description use, so that we would not need to worry about eliminating definite .descriptions from our texts because they were unclassifiable.</S>
    <S sid="43" ssid="11">For these reasons, we chose Hawkins's list of definite description uses (Hawkins 1978) and Prince's taxonomy (Prince 1981, 1992) as our starting point, and developed from there two slightly different annotation schemes, which allowed us to see whether it was better to describe the classes to our annotators in a surface-oriented or a semantic fashion, and to evaluate the seriousness of the problems with these schemes identified in the literature (see Fraurud 1990).</S>
    <S sid="44" ssid="12">The wide range of uses of definite descriptions was already highlighted in Christophersen (1939).</S>
    <S sid="45" ssid="13">In the third chapter of his book, Hawkins (1978) further develops and extends Christophersen's list.</S>
    <S sid="46" ssid="14">He identifies the following classes, or uses, of definite descriptions: Anaphoric Use.</S>
    <S sid="47" ssid="15">These are definite descriptions that cospecify with a discourse entity already introduced in the discourse.6 The definite description may use the same descriptive predicate as its antecedent, or any other capable of indicating the same antecedent (e.g., a synonym, a hyponym, etc.).</S>
    <S sid="48" ssid="16">Immediate Situation Uses.</S>
    <S sid="49" ssid="17">The next two uses of definite descriptions identified by Hawkins are occurrences used to refer to an object in the situation of utterance.</S>
    <S sid="50" ssid="18">The referent may be visible, or its presence may be inferred.</S>
    <S sid="51" ssid="19">The visible situation use occurs when the object referred to is visible to both speaker and hearer, as in the following examples: Hawkins classifies as immediate situation uses those definite descriptions whose referent is a constituent of the immediate situation in which the use of the definite description is located, without necessarily being visible: standard terminology, we will use the term referent to indicate the object in the world that is contributed to the meaning of an utterance by a definite description&#8212;e.g., we will say that Bill Clinton is the referent of a referential use of the definite description the president of the USA in 1997.</S>
    <S sid="52" ssid="20">We will then say, following Sidner's terminology (Sidner 1979), that a definite description cospecifies with its antecedent in a text, when such antecedent exists, if the definite description and its antecedent denote the same object.</S>
    <S sid="53" ssid="21">This is probably the most precise way of referring to the relation between an anaphoric expression and its antecedent; note that two discourse entities can cospecify without referring to any object in the world&#8212;e.g., in The (current) king of France is bald.</S>
    <S sid="54" ssid="22">He has a double chin, as well., he cospecifies with the (current) king of France, but this latter expression does not refer to anything.</S>
    <S sid="55" ssid="23">However, since we will mostly be concerned with referential discourse entities, we will often use the term corefer instead of cospecify.</S>
    <S sid="56" ssid="24">Apart from this, we have tried to avoid more complex issues of reference insofar as possible (Donnellan 1972; Kripke 1977; Barwise and Perry 1983; Neale 1990; Kronfeld 1990).</S>
    <S sid="57" ssid="25">Larger Situation Uses.</S>
    <S sid="58" ssid="26">Hawkins lists two uses of definite descriptions characteristic of situations in which the speaker appeals to the hearer's knowledge of entities that exist in the nonimmediate or larger situation of utterance&#8212;knowledge they share by being members of the same community, for instance.</S>
    <S sid="59" ssid="27">A definite description may rely on specific knowledge about the larger situation: this is the case in which both the speaker and the hearer know about the existence of the referent, as in the example below, in which it is assumed that speaker and hearer are both inhabitants of Halifax, a town which has a gibbet at the top of Gibbet Street: (4) The Gibbet no longer stands.</S>
    <S sid="60" ssid="28">Specific knowledge is not, however, a necessary part of the meaning of larger situation uses of definite descriptions.</S>
    <S sid="61" ssid="29">While some hearers may have specific knowledge about the actual individuals referred to by a definite description, others may not.</S>
    <S sid="62" ssid="30">General knowledge about the existence of certain types of objects in certain types of situations is sufficient.</S>
    <S sid="63" ssid="31">Hawkins classifies those definite descriptions that depend on this knowledge as instances of general knowledge in the larger situation use.</S>
    <S sid="64" ssid="32">An example is the following utterance in the context of a wedding: Such a first-mention of the bridesmaids is possible on the basis of the knowledge that weddings typically have bridesmaids.</S>
    <S sid="65" ssid="33">In the same way, a first-mention of the bride, the church service, or the best man would be possible.</S>
    <S sid="66" ssid="34">Associative Anaphoric Use.</S>
    <S sid="67" ssid="35">Speaker and hearer may have (shared) knowledge of the relations between certain objects (the triggers) and their components or attributes (the associates): associative anaphoric uses of definite descriptions exploit this knowledge.</S>
    <S sid="68" ssid="36">Whereas in larger situation uses the trigger is the situation itself, in the associative anaphoric use the trigger is an NP introduced in the discourse.</S>
    <S sid="69" ssid="37">Some of the classes in the Christophersen/Hawkins classification are specified in a semantic fashion; other classes are defined in purely syntactic terms.</S>
    <S sid="70" ssid="38">It is natural to ask what these uses of definite descriptions have in common from a semantic point of view: for example, is there a connection between the unfamiliar and unexplanatory uses of definite descriptions and the other uses?</S>
    <S sid="71" ssid="39">(The unfamiliar uses with associative clauses seem related to the associative anaphoric ones, and both seem related to the uses based on referent-establishing relative clauses.)</S>
    <S sid="72" ssid="40">Many authors, including Hawkins himself, have attempted to go beyond the purely descriptive list just discussed.</S>
    <S sid="73" ssid="41">One group of authors have identified uniqueness as the defining property of definite descriptions.</S>
    <S sid="74" ssid="42">This idea goes back to Russell (1905), and is motivated by larger situation definite descriptions such as the pope and by some cases of unexplanatory modifier use such as the first person to sail to America.</S>
    <S sid="75" ssid="43">The hypothesis was developed in recent years to address the problem of uniqueness within small situations (Kadmon 1987; Neale 1990; Cooper 1993).7 Another line of research is based on the observation that many of the uses of definite descriptions listed by Hawkins have one property in common: the speaker (or writer) is making some assumptions about what the hearer (or reader) already knows.</S>
    <S sid="76" ssid="44">Speaking very loosely, we might say that the speaker assumes that the hearer is able to &amp;quot;identify&amp;quot; the referent of the definite description.</S>
    <S sid="77" ssid="45">This is also true of some of the uses Hawkins classified as unfamiliar, such as his nominal modifiers and associative clause classes.</S>
    <S sid="78" ssid="46">Attempts at making this intuition more precise include Christophersen's (1939) familiarity theory, Strawson's (1950) presuppositional theory of definite descriptions, Hawkins's (1978) location theory and its revision, Clark and Marshall's (1981) theory of definite reference and mutual knowledge, as well as more formal proposals such as Heim (1982).</S>
    <S sid="79" ssid="47">Neither the uniqueness nor the familiarity approach have yet succeeded in providing a satisfactory account of all uses of definite descriptions (Fraurud 1990; Birner and Ward 1994).</S>
    <S sid="80" ssid="48">However, the theories based on familiarity address more directly the main concern of NLP system designers, which is to identify the connections between discourse entities.</S>
    <S sid="81" ssid="49">Furthermore, the prior corpus-based studies of definite descriptions use that we are aware of (Prince 1981, 1992; Fraurud 1990) are based on theories of this type.</S>
    <S sid="82" ssid="50">For both of these reasons, we adopted semantic notions introduced in familiaritystyle accounts in designing our experiments&#8212;in particular, distinctions introduced in Prince's taxonomy.</S>
    <S sid="83" ssid="51">Prince studied in detail the connection between a speaker /writer 's assumptions about the hearer /reader and the linguistic realization of noun phrases (Prince 1981, 1992).</S>
    <S sid="84" ssid="52">She criticizes as too simplistic the binary distinction between given and new discourse entities that is at the basis of most previous work on familiarity, and proposes a much more detailed taxonomy of &amp;quot;givenness&amp;quot;&#8212;or, as she calls it, assumed familiarity&#8212;meant to address this problem.</S>
    <S sid="85" ssid="53">Also, Prince's analysis of noun phrases is closer than the Christophersen/Hawkins taxonomy to a classification of definite descriptions on purely semantic terms: for example, she relates unfamiliar definites based on referent-establishing relative clauses with Hawkins's associative clause and associative anaphoric uses.'</S>
    <S sid="86" ssid="54">Hearer-New/Hearer-Old.</S>
    <S sid="87" ssid="55">One factor affecting the choice of a noun phrase, according to Prince, is whether a discourse entity is old or new with respect to the hearer's knowledge.</S>
    <S sid="88" ssid="56">A speaker will use a proper name or a definite description when he or she assumes that the addressee already knows the entity whom the speaker is referring to, as in (12) and (13).</S>
    <S sid="89" ssid="57">(13) Nine hundred people attended the Institute.</S>
    <S sid="90" ssid="58">On the other hand, if the speaker believes that the addressee does not know of Sandy Thompson, an indefinite will be used: (14) I'm waiting for it to be noon so I can call someone in California.</S>
    <S sid="91" ssid="59">Discourse-New/Discourse-Old.</S>
    <S sid="92" ssid="60">In addition, discourse entities can be new or old with respect to the discourse model: an NP may refer to an entity that has already been evoked in the current discourse, or it may evoke an entity that has not been previously mentioned.</S>
    <S sid="93" ssid="61">Discourse novelty is distinct from hearer novelty: both Sandy Thompson in (12) and the someone in California mentioned in (14) may well be discourse-new even if only the second one will be hearer-new.</S>
    <S sid="94" ssid="62">On the other hand, for an entity, being discourse-old entails being hearer-old.</S>
    <S sid="95" ssid="63">In other words, in Prince's theory, the notion of familiarity is split in two: familiarity with respect to the discourse, and familiarity with respect to the hearer.</S>
    <S sid="96" ssid="64">Either type of familiarity can license the use of definites: Hawkins's anaphoric uses of definite descriptions are cases of noun phrases referring to discourse-old discourse entities, whereas his larger situation and immediate situation uses are cases of noun phrases referring to discourse-new, hearer-old entities.'</S>
    <S sid="97" ssid="65">Inferrables.</S>
    <S sid="98" ssid="66">The uses of definite descriptions that Hawkins called associative anaphoric, such as a book .</S>
    <S sid="99" ssid="67">.</S>
    <S sid="100" ssid="68">. the author, are not discourse-old or even hearer-old, but they are not entirely new, either; as Hawkins pointed out, the hearer is assumed to be capable of inferring their existence.</S>
    <S sid="101" ssid="69">Prince called these discourse entities inferrables.</S>
    <S sid="102" ssid="70">(This is the class of definite descriptions for which Clark [1977] used the term bridging references.)</S>
    <S sid="103" ssid="71">Containing Inferrables.</S>
    <S sid="104" ssid="72">Finally, Prince proposes a category for noun phrases that are like inferrables, but whose connection with previous hearer's knowledge is specified as part of the noun phrase itself&#8212;her example is the door of the Bastille in the following example: (15) The door of the Bastille was painted purple.</S>
    <S sid="105" ssid="73">At least three of the unfamiliar uses of Hawkins&#8212;NP complements, referent-establishing relative clauses, and associative clauses&#8212;fall into this category.</S>
    <S sid="106" ssid="74">(See also Clark and Marshall [1981].)</S>
    <S sid="107" ssid="75">Perhaps the most important question concerning a classification scheme is its coverage.</S>
    <S sid="108" ssid="76">The two taxonomies we have just seen are largely satisfactory in this respect, but a couple of issues are worth mentioning.</S>
    <S sid="109" ssid="77">First of all, Prince's taxonomy does not give us a complete account of the licensing conditions for definite descriptions.</S>
    <S sid="110" ssid="78">Of the uses mentioned by Hawkins, the unfamiliar definites with unexplanatory modifiers and NP complements need not satisfy any of the conditions that license the use of definites according to Prince: these definites are not necessarily discourse-old, hearer-old, inferrables, or containing inferrables.</S>
    <S sid="111" ssid="79">These uses fall outside of Clark and Marshall's classification, as well.</S>
    <S sid="112" ssid="80">Secondly, none of the classification schemes just discussed, nor any of the alternatives proposed in the literature, consider so-called generic uses of definite descriptions, such as the use of the tiger in the generic sentence The tiger is a fierce animal that lives in the jungle.</S>
    <S sid="113" ssid="81">The problem with these uses is that the very question of whether the &amp;quot;referent&amp;quot; is familiar or not seems misplaced&#8212;these uses are not &amp;quot;referential.&amp;quot; A problem related to the one just mentioned is that certain uses of definite descriptions are ambiguous between a referential and an attributive interpretation (Donnellan 1972).</S>
    <S sid="114" ssid="82">The sentence The first person to sail to America was an Icelander, for example, can have two interpretations: the writer may either refer to a specific person, whose identity may be mutually known to both writer and reader; or he or she may be simply expressing a property that is true of the first person to sail to America, whoever that person happened to be.</S>
    <S sid="115" ssid="83">This ambiguity does not seem to be possible with all uses of definite descriptions: e.g., pass me the salt seems only to have a referential use.</S>
    <S sid="116" ssid="84">Again, the schemes we have presented do not consider this issue.</S>
    <S sid="117" ssid="85">The question of how to annotate generic uses of definite descriptions or uses that are ambiguous between a referential and an attributive use will not be addressed in this paper.</S>
    <S sid="118" ssid="86">A second problem with the classification schemes we have discussed was raised by Fraurud in her study of definite NPs in a corpus of Swedish text (Fraurud 1990).</S>
    <S sid="119" ssid="87">Fraurud introduced a drastically simplified classification scheme based on two classes only: subsequent-mention, corresponding to Hawkins's anaphoric definite descriptions and Prince's discourse-old, and first-mention, including all other definite descriptions.</S>
    <S sid="120" ssid="88">Fraurud simplified matters in this way because she was primarily interested in verifying the empirical basis for the claim that familiarity is the defining property of definite descriptions; she also observed, however, that some of the distinctions introduced by Hawkins and Prince led to ambiguities of classification.</S>
    <S sid="121" ssid="89">For example, she observed that the reader of a Swedish newspaper can equally well interpret the definite description the king in an article about Sweden by reference to the larger situation or to the content of the article.</S>
    <S sid="122" ssid="90">We took into account Fraurud's observations in designing our experiments, and we will compare our results to hers below.</S>
  </SECTION>
  <SECTION title="3." number="4">
    <S sid="123" ssid="1">For our first experiment evaluating subjects' performance at the classification task, we developed a taxonomy of definite description uses based on the schemes discussed in the previous section, preliminarily tested the taxonomy by annotating the corpus ourselves, and then asked two annotators to do the same task.</S>
    <S sid="124" ssid="2">This first experiment is described in the rest of this section.</S>
    <S sid="125" ssid="3">We explain first the classification we developed for this experiment, then the experimental conditions, and, finally, discuss the results.</S>
    <S sid="126" ssid="4">The annotation schemes for noun phrases proposed in the literature fall into one of two categories.</S>
    <S sid="127" ssid="5">On the one hand, we have what we might call labeling schemes, most typically used by corpus linguists, which involve assigning to each noun phrase a class such as those discussed in the previous section; the schemes used by Fraurud and Prince fall into this category.</S>
    <S sid="128" ssid="6">On the other hand, there are what we might call linking schemes, concerned with identifying the links between the discourse entity or entities introduced by a noun phrase and other entities in the discourse; the scheme used in MUC-6 is of this type.</S>
    <S sid="129" ssid="7">In our experiments, we tried both a pure labeling scheme and a mixed labeling and linking scheme.</S>
    <S sid="130" ssid="8">We also tried two slightly different taxonomies of definite descriptions, and we varied the way membership in a class was defined to the subjects.</S>
    <S sid="131" ssid="9">Both taxonomies were based on the schemes proposed by Hawkins and Prince, but we introduced some changes in order, first, to find a scheme that would be easily understood by individuals without previous linguistic training and would lead to maximum agreement among the classifiers; and second, to make the classification more useful for our goal of feeding the results into an implementation.</S>
    <S sid="132" ssid="10">In the first experiment, we used a labeling scheme, and the classes were introduced to the subjects with reference to the surface characteristics of the definite descriptions.</S>
    <S sid="133" ssid="11">(See below and Appendix A.)</S>
    <S sid="134" ssid="12">The taxonomy we used in this experiment is a simplification of Hawkins's scheme, to which we made three main changes.</S>
    <S sid="135" ssid="13">First of all, we separated those anaphoric descriptions whose antecedents have the same descriptive content as their antecedent (which we will call anaphoric (same head)) from other cases of anaphoric descriptions in which the association is based on more complex forms of lexical or commonsense knowledge (synonyms, hypernyms, information about events, etc.).</S>
    <S sid="136" ssid="14">We grouped these latter definite descriptions with Hawkins's associative descriptions in a class that we called associative.</S>
    <S sid="137" ssid="15">This was done in order to see how much need there is for complex lexical inferences in resolving anaphoric definite descriptions, as opposed to simple head matching.</S>
    <S sid="138" ssid="16">Secondly, we grouped together all the definite descriptions that introduce a novel discourse entity not associated to some previously established object in the text, i.e., that were discourse-new in Prince's sense.</S>
    <S sid="139" ssid="17">This class, that we will call larger situation/unfamiliar, includes both definite descriptions that exploit situational information (Hawkins's larger situation uses) and discourse-new definite descriptions introduced together with their links or referents (unfamiliar) This was done because of Fraurud's observation that distinguishing the two classes is generally difficult (Fraurud 1990).</S>
    <S sid="140" ssid="18">Third, we did not include a class for immediate situation uses, since we assumed they would be rare in written text.'</S>
    <S sid="141" ssid="19">We also introduced a separate class of idioms including indirect references, idiomatic expressions and metaphorical uses, and we allowed our subjects to mark definite descriptions as doubts.</S>
    <S sid="142" ssid="20">To summarize, the classes used in this experiment were as follows: Caspar, Wyo., to drill the Bilbrey well, a 15,000-foot, $1-million-plus 10 This was indeed the case, but we did observe a few instances of an interesting kind of immediate situation use.</S>
    <S sid="143" ssid="21">In these cases, the text is describing the immediate situation in which the writer is, and the writer apparently expects the reader to reconstruct this situation: natural gas well.</S>
    <S sid="144" ssid="22">The rig was built around 1980, but has drilled only two wells, the last in 1982.</S>
    <S sid="145" ssid="23">II.</S>
    <S sid="146" ssid="24">Associative.</S>
    <S sid="147" ssid="25">We assigned to this class those definite descriptions that stand in an anaphoric or associative anaphoric relation with an antecedent explicitly mentioned in the text, but that are not identified by the same head noun as their antecedent.</S>
    <S sid="148" ssid="26">This class includes Hawkins's associative anaphoric definite descriptions and Prince's inferrables, as well as some definite descriptions that would be classified as anaphoric by Hawkins and as textually evoked in Prince (1981).</S>
    <S sid="149" ssid="27">Recognizing the antecedent of these definite descriptions involves at least knowledge of lexical associations, and possibly general commonsense knowledge.'</S>
    <S sid="150" ssid="28">(17) a.</S>
    <S sid="151" ssid="29">With all this, even the most wary oil men agree something has changed.</S>
    <S sid="152" ssid="30">&amp;quot;It doesn't appear to be getting worse.</S>
    <S sid="153" ssid="31">That in itself has got to cause people to feel a little more optimistic,&amp;quot; says Glenn Cox, the president of Phillips Petroleum Co.</S>
    <S sid="154" ssid="32">Though modest, the change reaches beyond the oil patch, too. b. Toni Johnson pulls a tape measure across the front of what was once a stately Victorian home.</S>
    <S sid="155" ssid="33">A deep trench now runs along its north wall, exposed when the house lurched two feet off its foundation during last week's earthquake. c. Once inside, she spends nearly four hours measuring and diagramming each room in the 80-year-old house, gathering enough information to estimate what it would cost to rebuild it.</S>
    <S sid="156" ssid="34">While she works inside, a tenant returns with several friends to collect furniture and clothing.</S>
    <S sid="157" ssid="35">One of the friends sweeps broken dishes and shattered glass from a countertop and starts to pack what can be salvaged from the kitchen.</S>
    <S sid="158" ssid="36">III.</S>
    <S sid="159" ssid="37">Larger situation/unfamiliar.</S>
    <S sid="160" ssid="38">This class includes Hawkins's larger situation uses of definite descriptions based on specific and general knowledge (discourse-new, hearerold in Prince's terms) as well as his unfamiliar uses (many of which correspond to Prince's containing inferrables).</S>
    <S sid="161" ssid="39">(18) a.</S>
    <S sid="162" ssid="40">Out here on the Querecho Plains of New Mexico, however, the mood is more upbeat-trucks rumble along the dusty roads and burly men in hard hats sweat and swear through the afternoon sun.</S>
    <S sid="163" ssid="41">First of all, we classified the definite descriptions included in 20 randomly chosen articles from the Wall Street Journal contained in the subset of the Penn Treebank corpus included in the ACL/DCI CD-ROM.12 All together, these articles contain 1,040 instances of definite description use.</S>
    <S sid="164" ssid="42">The results of our analysis are summarized in Table 1.</S>
    <S sid="165" ssid="43">Next, we asked two subjects to perform the same task.</S>
    <S sid="166" ssid="44">Our two subjects in this first experiment were graduate students in linguistics.</S>
    <S sid="167" ssid="45">The two subjects were given the instructions in Appendix A.</S>
    <S sid="168" ssid="46">They had to assign each definite description to one of the classes described in Section 3.1: I. anaphoric (same head), II. associative, III. larger situation/unfamiliar, and IV. idiom.</S>
    <S sid="169" ssid="47">The subjects could also express V. doubt about the classification of the definite description.</S>
    <S sid="170" ssid="48">Since the classes I-III are not mutually exclusive, we instructed the subjects to resolve conflicts according- to a preference ranking, i.e., to choose a class with higher preference when two classes seemed equally applicable.</S>
    <S sid="171" ssid="49">The ranking was (from most preferred to least preferred): 1) anaphoric (same head), 2) larger situation/unfamiliar, and 3) associative.</S>
    <S sid="172" ssid="50">The annotators were given one text to familiarize themselves with the task before starting with the annotation proper. annotator (henceforth, Annotator A) are shown in Table 2, and those of the second annotator (henceforth, Annotator B) in Table 3.</S>
    <S sid="173" ssid="51">As the tables indicate, the annotators assigned approximately the same percentage of definite descriptions to each of the five classes as we did; however, the classes do not always include the same elements.</S>
    <S sid="174" ssid="52">This can be gathered by the confusion matrix in Table 4, where an entry mx,y indicates the number of definite descriptions assigned to class x by subject A and to class y by subject B.</S>
    <S sid="175" ssid="53">In order to measure the agreement in a more precise way, we used the Kappa statistic (Siegel and Castellan 1988), recently proposed by Carletta as a measure of agreement for discourse analysis (Carletta 1996).</S>
    <S sid="176" ssid="54">We also used a measure of per-class agreement that we introduced ourselves.</S>
    <S sid="177" ssid="55">We discuss these results below, after reviewing briefly how K is computed.</S>
    <S sid="178" ssid="56">3.3.2 The Kappa Statistic.</S>
    <S sid="179" ssid="57">Kappa is a test suitable for cases when the subjects have to assign items to one of a set of nonordered classes.</S>
    <S sid="180" ssid="58">The test computes a coefficient K of agreement among coders, which takes into account the possibility of chance agreement.</S>
    <S sid="181" ssid="59">It is dependent on the number of coders, number of items being classified, and number of choices of classes to be ascribed to items.</S>
    <S sid="182" ssid="60">The kappa coefficient of agreement between c annotators is defined as: where P(A) is the proportion of times the annotators agree and P(E) is the proportion of times that we would expect the annotators to agree by chance.</S>
    <S sid="183" ssid="61">When there is complete agreement among the raters, K = 1; if there is no agreement other than that expected by chance, K = 0.</S>
    <S sid="184" ssid="62">According to Carletta, in the field of content analysis&#8212; where the Kappa statistic originated&#8212;K &gt; 0.8 is generally taken to indicate good reliability, whereas 0.68 &lt; K &lt; 0.8 allows tentative conclusions to be drawn.</S>
    <S sid="185" ssid="63">We will illustrate the method for computing K proposed in Siegel and Castellan (1988) by means of an example from one of our texts, shown in Table 5.</S>
    <S sid="186" ssid="64">The first column in Table 5 (Definite description) shows the definite description being classified.</S>
    <S sid="187" ssid="65">The columns ASH, ASS, and LSU stand for the classification options presented to the subjects (anaphoric (same head), associative, and larger situation/unfamiliar, respectively).</S>
    <S sid="188" ssid="66">The numbers in each nil entry of the matrix indicate the number of classifiers that assigned the description in row i to the class in column j.</S>
    <S sid="189" ssid="67">The final column (labeled S) represents the percentage agreement for each definite description; we explain below how this percentage agreement is calculated.</S>
    <S sid="190" ssid="68">The last row in the table shows the total number of descriptions (N), the total number of descriptions assigned to each class and, finally, the total percentage agreement for all descriptions (Z).</S>
    <S sid="191" ssid="69">The equations for computing Si, PE, PA, and K are shown in Table 6.</S>
    <S sid="192" ssid="70">In these formulas, c is the number of coders; S, the percentage agreement for description i (we show S1 and S2 as examples); m the number of categories; T the total number of classification judgments; PE the percentage agreement expected by chance; PA the total agreement; and K the Kappa coefficient.</S>
    <S sid="193" ssid="71">3.3.3 Value of K for the First Experiment.</S>
    <S sid="194" ssid="72">For the first experiment, K = 0.68 if we count idioms as a class, K = 0.73 if we take them out.</S>
    <S sid="195" ssid="73">The overall coefficient of agreement between the two annotators and our own analysis is K = 0.68 if we count idioms, K = 0.72 if we ignore them.</S>
    <S sid="196" ssid="74">3.3.4 Per-Class Agreement.</S>
    <S sid="197" ssid="75">K gives a global measure of agreement.</S>
    <S sid="198" ssid="76">We also wanted to measure the agreement per class, i.e., to understand where annotators agreed the most Computing the K coefficient of agreement. and where they disagreed the most.</S>
    <S sid="199" ssid="77">The confusion matrix does this to some extent, but only works for two annotators&#8212;and therefore, for example, we couldn't use it to measure agreement on classes between the two annotators and ourselves.</S>
    <S sid="200" ssid="78">We computed what we called per-class percentage of agreement for three coders (the two annotators and ourselves) by taking the proportion of pairwise agreements relative to the number of pairwise comparisons, as follows: whenever all three coders ascribe a description to the same class, we count six pairwise agreements out of six pairwise comparisons for that class (100%).</S>
    <S sid="201" ssid="79">If two coders ascribe a description to class 1 and the other coder to class 2, we count two agreements in four comparisons for class 1 (50%) and no agreement for class 2 (0%).</S>
    <S sid="202" ssid="80">The rates of agreement for each class thus obtained are presented in Table 7.</S>
    <S sid="203" ssid="81">The figures indicate better agreement on anaphoric same head and larger situation/unfamiliar definite descriptions, worse agreement on the other classes.</S>
    <S sid="204" ssid="82">(In fact, the percentages for idioms and doubts are very low; but these classes are also too small to allow us to draw any conclusions.)</S>
    <S sid="205" ssid="83">3.4.1 Distribution.</S>
    <S sid="206" ssid="84">One of the most interesting results of this first experiment is that a large proportion of the definite descriptions in our corpus (48.37%, according to our own annotation; more, according to our two annotators) are not related to an antecedent previously introduced in the text.</S>
    <S sid="207" ssid="85">Surprising as it may seem, this finding is in fact just a confirmation of the results of other researchers.</S>
    <S sid="208" ssid="86">Fraurud (1990) reports that 60.9% of definite descriptions in her corpus of 11 Swedish texts are first-mention, i.e., do not corefer with an entity already evoked in the text;&amp;quot; Gallaway (1996) found a distribution similar to ours in (English) spoken child language. low agreement among annotators.</S>
    <S sid="209" ssid="87">The reason for this disagreement was not so much annotators' errors as the fact, already mentioned, that the classes are not mutually exclusive.</S>
    <S sid="210" ssid="88">The confusion matrix in Table 4 indicates that the major classes of disagreements were definite descriptions classified by annotator A as larger situation and by annotator B as associative, and vice versa.</S>
    <S sid="211" ssid="89">One such example is the government in (20).</S>
    <S sid="212" ssid="90">This definite description could be classified as larger situation because it refers to the government of Korea, and presumably the fact that Korea has a government is shared knowledge; but it could also be classified as being associative on the predicate Koreans.'</S>
    <S sid="213" ssid="91">We will analyze the reasons for the disagreement in more detail in relation to our second experiment, in which we also asked the annotators to indicate the antecedent of definite descriptions. in this experiment, we were able to confirm the correlation observed by Hawkins between the syntactic structure of certain definite descriptions and their classification as discourse-new.</S>
    <S sid="214" ssid="92">Factors that strongly suggest that a definite description is discoursenew (and in fact, presumably hearer-new as well) include the presence of modifiers such as first or best, and of a complement for NPs of the form the fact that .</S>
    <S sid="215" ssid="93">.</S>
    <S sid="216" ssid="94">. or the conclusion that .</S>
    <S sid="217" ssid="95">.15 Postnominal modification of any type is also a strong indicator of discourse novelty, suggesting that most postnominal clauses serve to establish a referent in the sense discussed in the previous section.</S>
    <S sid="218" ssid="96">In addition, we observed a previously unreported (to our knowledge) correlation between discourse novelty and syntactic constructions such as appositions, copular constructions, and comparatives.</S>
    <S sid="219" ssid="97">The following examples from our corpus illustrate the correlations just mentioned: In addition, we observed a correlation between larger situation uses of definite descriptions (discourse-new, and often hearer-old) and certain syntactic expressions and lexical items.</S>
    <S sid="220" ssid="98">For example, we noticed that a large number of uses of definite descriptions in the corpus used for this first experiment referred to temporal entities such as the year or the month, or included proper names in place of the head noun or in premodifier position, as in the Querecho Plains of New Mexico and the Iran-Iraq war.</S>
    <S sid="221" ssid="99">Although these definite descriptions would have been classified by Hawkins as larger situation uses, in many cases they couldn't really be considered hearer-old or unused: what seems to be happening in these cases is that the writer assumed the reader would use information about the visual form of words, or perhaps lexical knowledge, to infer that an object of that name existed in the world.</S>
    <S sid="222" ssid="100">We evaluated the strength of these correlations by means of a computer simulation (Vieira and Poesio 1997).</S>
    <S sid="223" ssid="101">The system attempts to classify the definite descriptions found in texts syntactically annotated according to the Penn Treebank format.</S>
    <S sid="224" ssid="102">The system classifies a definite description as unfamiliar using heuristics based on the syntactic and lexical correlations just observed, i.e., if either (i) it includes an unexplanatory modifier, (ii) it occurs in an apposition or a copular construction, or (iii) it is modified by a relative clause or prepositional phrase.</S>
    <S sid="225" ssid="103">A definite description is classified as larger situation if its head noun is a temporal expression such as year or month, or if its head or premodifiers are head nouns.</S>
    <S sid="226" ssid="104">The implementation revealed that some of the correlations are very strong: for example, the agreement between the system's classification and the annotators' on definite descriptions with a nominal complement, such as the fact that .</S>
    <S sid="227" ssid="105">.</S>
    <S sid="228" ssid="106">. varied between 93% and 100% depending on the annotator; and on average, 70% of temporal expressions such as the year were interpreted as larger situation by the annotators.</S>
    <S sid="229" ssid="107">All of this suggests that in using definite descriptions, writers may not just make assumptions about their readers' knowledge; they may also rely on their readers' ability to use lexical or syntactic cues to classify a definite description as discourse-new even when these readers don't know about the particular object referred to already.</S>
    <S sid="230" ssid="108">This observation is consistent with Fraurud's hypothesis that interpreting definite descriptions involves two processes&#8212;deciding whether a definite description relates to some entity in the discourse or not, and searching the antecedent&#8212;and that the two processes are fairly independent.</S>
    <S sid="231" ssid="109">Our findings also suggest that the classification process may rely on more than just lexical cues, as Fraurud seems to assume (taking up a suggestion in Lobner [1985]; see below).</S>
  </SECTION>
  <SECTION title="4." number="5">
    <S sid="232" ssid="1">In order to address some of the questions raised by Experiment 1 we set up a second experiment.</S>
    <S sid="233" ssid="2">In this second experiment we modified both the classification scheme and what we asked the annotators to do.</S>
    <S sid="234" ssid="3">One concern we had in designing this second experiment was to understand better the reasons for the disagreement among annotators observed in the first experiment.</S>
    <S sid="235" ssid="4">In particular, we wanted to understand whether the classification disagreements reflected disagreements about the final semantic interpretation.</S>
    <S sid="236" ssid="5">Another difference between this new experiment and the first one is that we structured the task of deciding on a classification for a definite description around a series of questions originating a decision tree, rather than giving our subjects an explicit preference ranking.</S>
    <S sid="237" ssid="6">A third aspect of the first experiment we wanted to study more carefully was the distribution of definite descriptions, in particular, the characteristics of the large number of definite descriptions in the larger situation/unfamiliar class.</S>
    <S sid="238" ssid="7">Finally, we chose truly naive subjects to perform the classification task.</S>
    <S sid="239" ssid="8">In order to get a better idea of the extent of agreement among annotators about the semantic interpretation of definite descriptions, we asked our subjects to indicate the antecedent in the text for the definite descriptions they classified as anaphoric or associative.</S>
    <S sid="240" ssid="9">This would also allow us to test how well subjects did with a linking type of classification like the one used in MUC-6.</S>
    <S sid="241" ssid="10">We also replaced the anaphoric (same head) class we had in the first experiment with a broader coreferent class including all cases in which a definite description is coreferential with its antecedent, whether or not the head noun was the same: e.g., we asked the subjects to classify as coreferent a definite like the house referring back to an antecedent introduced as a Victorian home, which would not have counted as anaphoric (same head) in our first experiment.</S>
    <S sid="242" ssid="11">This resulted in a taxonomy that was at the same time more semantically oriented and closer to Hawkins's and Prince's classification schemes: our broadened coreferent class coincides with Hawkins's anaphoric and Prince's textually evoked classes, whereas the resulting, narrower associative class (that we called bridging references) coincides with Hawkins's associative anaphoric and Prince's class of inferrables.</S>
    <S sid="243" ssid="12">Our intention was to see whether the distinctions proposed by Hawkins and Prince would result in a better agreement among annotators than the taxonomy used in our first experiment, i.e., whether the subjects would be more in agreement about the semantic relation between a definite description and its antecedent than they were about the relation between the head noun of the definite description and the head noun of its antecedent.</S>
    <S sid="244" ssid="13">The larger situation/unfamiliar class we had in the first experiment was split back into two classes, as in Hawkins's and Prince's schemes.</S>
    <S sid="245" ssid="14">We did this to see whether indeed these two classes were difficult to distinguish; we also wanted to get a clearer idea of the relative importance of the two kinds of definites that we had grouped together in the first annotation.</S>
    <S sid="246" ssid="15">The two classes were called Larger situation and Unfamiliar.</S>
    <S sid="247" ssid="16">We used three subjects for Experiment 2.</S>
    <S sid="248" ssid="17">Our subjects were English native speakers, graduate students of mathematics, geography, and mechanical engineering at the University of Edinburgh; we will refer to them as C, D, and E below.</S>
    <S sid="249" ssid="18">They were asked to annotate 14 randomly selected Wall Street Journal articles, all but one of them different from those used in Experiment 1, and containing 464 definite descriptions in tota1.16 Unlike in our first experiment, we did not suggest any relation between the classes and the syntactic form of the definite descriptions in the instructions.</S>
    <S sid="250" ssid="19">The subjects were asked to indicate whether the entity referred to by a definite description (i) had been mentioned previously in the text, else if (ii) it was new but related to an entity already mentioned in the text, else (iii) it was new but presumably known to the average reader, or, finally, (iv) it was new in the text and presumably new to the average reader.</S>
    <S sid="251" ssid="20">When the description was indicated as discourse-old (i) or related to some other entity (ii), the subjects were asked to locate the previous mention of the related entity in the text.</S>
    <S sid="252" ssid="21">Unlike the first experiment, the subjects did not have the option of classifying a definite description as Idiom; we instructed them to make a choice and write down their doubts.</S>
    <S sid="253" ssid="22">The written instructions and the script given to the subjects can be found in Appendix B.</S>
    <S sid="254" ssid="23">As in Experiment 1, the subjects were given one text to practice before starting with the analysis of the corpus.</S>
    <S sid="255" ssid="24">They took, on average, eight hours to complete the task.</S>
    <S sid="256" ssid="25">The distribution of definite descriptions in the four classes according to the three coders is shown in Table 8.</S>
    <S sid="257" ssid="26">We had 283 cases of complete agreement among annotators on the classification (61%): 164 cases of complete agreement on coreferential definite descriptions, 7 cases of complete agreement on bridging, 65 cases of complete agreement on larger situation, and 47 cases of complete agreement on the unfamiliar class.</S>
    <S sid="258" ssid="27">As in Experiment 1, we measured the K coefficient of agreement among annotators; the result for annotators C, D, and E is K = 0.58 if we consider the definite descriptions marked as doubts (in which case we have 464 descriptions and five classes), K = 0.63 if we leave them out (430 descriptions and the four classes I-IV).</S>
    <S sid="259" ssid="28">We also measured the extent of agreement among subjects on the antecedents for coreferential and bridging definite descriptions.</S>
    <S sid="260" ssid="29">A total of 164 descriptions were classified as coreferential by all three coders; of these, 155 (95%) were taken by all coders to refer to the same entity (although not necessarily to the same mention of that entity).</S>
    <S sid="261" ssid="30">There were only 7 definite descriptions classified by all three annotators as bridging references; in 5 of these cases (71%) the three annotators also agreed on a textual antecedent (i.e., on the discourse entity to which the bridging reference was related to).</S>
    <S sid="262" ssid="31">4.4.1 Distribution into Classes.</S>
    <S sid="263" ssid="32">As shown in Table 8, the distribution of definite descriptions among discourse-new, on the one side, and coreferential with bridging references, one the other, is roughly the same in Experiment 2 as in Experiment 1, and roughly the same among annotators.</S>
    <S sid="264" ssid="33">The average percentage of discourse-new descriptions (larger situation and unfamiliar together) is 46%, against an average of 50% in the first experiment.</S>
    <S sid="265" ssid="34">Having split the discourse-new class in two in this experiment, we got an indication of the relative importance of the hearer-old and hearer-new subclasses&#8212; about half of the discourse-new uses fall in each of these classes&#8212;but only very approximate, since the first two annotators classified the majority of these definite descriptions as larger situation, whereas the last annotator classified the majority as unfamiliar.</S>
    <S sid="266" ssid="35">As expected, the broader definition of the coreferent class resulted in a larger percentage of definite descriptions being included in this class (an average of 45%), and a smaller percentage being included in the bridging reference class.</S>
    <S sid="267" ssid="36">Considering the difference between the relative importance of the same-head anaphora class in the first experiment and of the coreferent class in the second experiment we can estimate that approximately 15% of definite descriptions are coreferential and have a different head from their antecedents.</S>
    <S sid="268" ssid="37">4.4.2 Agreement among Annotators.</S>
    <S sid="269" ssid="38">The agreement among annotators in Experiment 2 was not very high: 61% total agreement, which gives K = 0.58 or K = 0.63, depending on whether we consider doubts as a class.'</S>
    <S sid="270" ssid="39">This value is worse than the one we obtained in Experiment 1 (K = 0.68 or K = 0.73); in fact, this value of K goes below the level at which we can tentatively assume agreement among the annotators.</S>
    <S sid="271" ssid="40">There could be several reasons for the fact that agreement got worse in this second experiment.</S>
    <S sid="272" ssid="41">Perhaps the simplest explanation is that we were just using more classes.</S>
    <S sid="273" ssid="42">In order to check whether this was the case, we merged the classes larger situation and unfamiliar back into one class, as we had in the Experiment 1: that is, we recomputed K after counting all definite descriptions classified as either larger situation or unfamiliar as members of the same class.</S>
    <S sid="274" ssid="43">And indeed, the agreement figures went up from K = 0.63 to K = 0.68 (ignoring doubts) when we did so, i.e., within the &amp;quot;tentative&amp;quot; margins of agreement according to Carletta (1996) (0.68 &lt; x &lt; 0.8).</S>
    <S sid="275" ssid="44">The remaining difference between the level of agreement obtained in this experiment and that obtained in the first one (K = 0.73, ignoring doubts) might have to do with the annotators, with the difficulty of the texts, or with using a syntactic (same head) as opposed to a semantic notion of what counts as coreferential; we are inclined to think that the last two explanations are more likely.</S>
    <S sid="276" ssid="45">For one thing, we found very few examples of true mistakes in the annotation, as discussed below.</S>
    <S sid="277" ssid="46">Secondly, we observed that the coefficient of agreement changes dramatically from text to text: in this second experiment, it varies from K = 0.42 to K = 0.92 depending on the text, and if we do not count the three worst texts in the second experiment, we get again K = 0.73.</S>
    <S sid="278" ssid="47">Third, going from a syntactic to a semantic definition of anaphoric definite description resulted in worse agreement both for coreferential and for bridging references: looking at the per-class figures, one can see that we went from a per-class agreement on anaphoric definite descriptions in Experiment 1 of 88% to a per-class agreement on coreferential definites of 86% in Experiment 2; and the per-class agreement for associative definite descriptions of 59% went down rather dramatically to a per-class agreement of 31% on bridging descriptions.</S>
    <S sid="279" ssid="48">The good result obtained by reducing the number of classes led us to try to find a way of grouping definite descriptions into classes that would result in an even better agreement.</S>
    <S sid="280" ssid="49">An obvious idea was to try with still fewer classes, i.e., just two.</S>
    <S sid="281" ssid="50">We first tried the binary division suggested by Fraurud: all coreferential definite descriptions 7 on one side (subsequent-mention), and all other definite descriptions on the other (first-mention).</S>
    <S sid="282" ssid="51">Splitting things this way did result in an agreement of K = 0.76, i.e., almost a good reliability, although not quite as strong an agreement as we would have expected.</S>
    <S sid="283" ssid="52">The alternative of putting in one class all discourse-related definite descriptions&#8212;coreferential and bridging references&#8212;and putting larger situation and unfamiliar definite descriptions in a second class resulted in a worse agreement, although not by much (K = 0.73).</S>
    <S sid="284" ssid="53">This suggests that our subjects did reasonably well at distinguishing first-mention from subsequent-mention entities, but not at drawing more complex distinctions.</S>
    <S sid="285" ssid="54">They were particularly bad at distinguishing bridging references from other definite descriptions: dividing the classifications into bridging definites, on the one hand, and all other definite descriptions, on the other, resulted in a very low agreement (K = 0.24).</S>
    <S sid="286" ssid="55">We obtained about the same results by computing the per-class percentage of agreement discussed in Section 3.</S>
    <S sid="287" ssid="56">The rates of agreement for each class thus obtained are presented in Table 9.</S>
    <S sid="288" ssid="57">Again, we find that the annotators found it easier to agree on co-referential definite descriptions, harder to agree on bridging references; the percentage agreement on the classes larger situation and unfamiliar taken individually is much lower than the agreement on the class larger situation/unfamiliar taken as a whole.</S>
    <S sid="289" ssid="58">The results in Table 9 confirm the indications obtained by computing agreement for a smaller number of classes: our subjects agree pretty much on coreferential definite descriptions, but bridging references are not a natural class.</S>
    <S sid="290" ssid="59">We discuss the cases of disagreement in more detail next. among annotators: about classification, and about the identification of an antecedent.</S>
    <S sid="291" ssid="60">There were 29 cases of complete classification disagreement among annotators, i.e., cases in which no two annotators classified a definite description in the same way, and 144 cases of partial disagreement.</S>
    <S sid="292" ssid="61">All four of the possible combinations of total disagreement were observed, but the two most common combinations were BCU (bridging, coreferential, and unfamiliar) and BLU (bridging, larger situation, and unfamiliar); all six combinations of partial disagreements were also observed.</S>
    <S sid="293" ssid="62">As we do not have the space to discuss each case in detail, we will concentrate on pointing out what we take to be the most interesting observations, especially from the perspective of designing a corpus annotation scheme for anaphoric expressions.</S>
    <S sid="294" ssid="63">We found very few true mistakes.</S>
    <S sid="295" ssid="64">We had some problems due to the presence of idioms such as they had to pick up the slack or on the whole.</S>
    <S sid="296" ssid="65">But in general, most of the disagreements were due to genuine problems in assigning a unique classification to definite descriptions.</S>
    <S sid="297" ssid="66">The mistakes that our annotators did make were of the form exemplified by (22).</S>
    <S sid="298" ssid="67">In this case, all three annotators indicate the same antecedent (the potential payoff) for the definite description the rewards, but whereas two of them classify the rewards as coreferential, one of them classifies it as bridging.</S>
    <S sid="299" ssid="68">What seems to be happening here and in similar cases is that even though we asked the subjects to classify semantically, they ended up using a notion of relatedness that is more like the notion of associative in Experiment 1.</S>
    <S sid="300" ssid="69">(We found 10 such cases of partial disagreement between bridging and coreferential in which all three subjects indicated the same antecedent for the definite description.)</S>
    <S sid="301" ssid="70">&amp;quot;When we evaluated raising our bid, the risks seemed substantial and persistent over the next five years, and the rewards seemed a long way out.&amp;quot; A particularly interesting version of this problem appears in the following example, when two annotators took the verb to refund as antecedent of the definite description the refund, but one of them interpreted the definite as coreferential with the eventuality, the other as bridging.</S>
    <S sid="302" ssid="71">The refund was about $55 million more than previously ordered by the Illinois Commerce Commission and trade groups said it may be the largest ever required of a state or local utility.</S>
    <S sid="303" ssid="72">As could be expected by the discussion of the K results above, the most common disagreements (35 cases of partial disagreement out of 144) were between the classes larger situation and unfamiliar.</S>
    <S sid="304" ssid="73">One typical source of disagreement was the introductory use of definite descriptions, common in newspapers: thus, for example, some of our annotators would classify the Illinois Commerce Commission as larger situation, others as unfamiliar.</S>
    <S sid="305" ssid="74">In many cases in which this form of ambiguity was encountered, the definite description worked effectively as a proper name: the world-wide supercomputer law, the new US trade law, or the face of personal computing.</S>
    <S sid="306" ssid="75">Rather surprisingly, from a semantic perspective, the second most common form of disagreement was between the coreferential and bridging classes.</S>
    <S sid="307" ssid="76">In this case, the problem typically was that different subjects would choose different antecedents for a certain definite description.</S>
    <S sid="308" ssid="77">Thus, in example (23), the third annotator indicated $250 million as the antecedent for the refund, and classified the definite description as coreferential.</S>
    <S sid="309" ssid="78">A similar example is (24), in which two of the annotators classified the spinoff as bridging on spinoff Cray Computer Corp., whereas the third classified it as coreferential with the pending spinoff (24) The survival of spinoff Cray Computer Corp. as a fledgling in the supercomputer business appears to depend heavily on the creativity&#8212;and longevity&#8212;of its chairman and chief designer, Seymour Cray.</S>
    <S sid="310" ssid="79">Documents filed with the Securities and Exchange Commission on the pending spinoff disclosed that Cray Research Inc. will withdraw the almost $100 million in financing it is providing the new firm if Mr. Cray leaves or if the product-design project he heads is scrapped.</S>
    <S sid="311" ssid="80">While many of the risks were anticipated when Minneapolis-based Cray Research first announced the spinoff in May, the strings it attached to the financing hadn't been made public until yesterday.</S>
    <S sid="312" ssid="81">An example of total (BLU) disagreement is the following: In this case, we can see that all three interpretations are acceptable: we may take the definite description the government of President Carlos Menem, who took office July 8, either as a case of bridging reference on the previously mentioned Argentina, or as a larger situation use, or as a case of unfamiliar definite description, especially if we assume that this latter class coincides with Prince's containing inferrables.</S>
    <S sid="313" ssid="82">In conclusion, our figures can be seen as an empirical verification of Fraurud's and Prince's hypothesis that the classification disagreements among annotators depend to a large extent on the task they are asked to do, rather than reflecting true differences in semantic intuitions.</S>
    <S sid="314" ssid="83">4.4.4 Antecedent Disagreements.</S>
    <S sid="315" ssid="84">Interestingly, we also found cases of disagreement about the antecedent of a definite description.</S>
    <S sid="316" ssid="85">We have already discussed the most common case of antecedent disagreement: the case in which a definite description could equally well be taken as co-referential with one discourse entity or as bridging to another.</S>
    <S sid="317" ssid="86">For example, in an article in which the writer starts discussing Aetna Life &amp; Casualty, and then goes on mentioning major insurers, either discourse entity could then serve as antecedent for the subsequent definite description the insurer, depending on whether the definite description is classified as coreferential or bridging.</S>
    <S sid="318" ssid="87">Perhaps the most interesting cases of disagreement about the antecedent are examples such as (26).</S>
    <S sid="319" ssid="88">One subject indicated parts of the factory as the antecedent; another indicated the factory; and the third indicated areas of the factory. dusty where the crocidolite was used.</S>
    <S sid="320" ssid="89">Workers dumped large burlap sacks of the imported material into a huge bin, poured in cotton and acetate fibers and mechanically mixed the dry fibers in a process used to make filters.</S>
    <S sid="321" ssid="90">Workers described &amp;quot;clouds of blue dust&amp;quot; that hung over parts of the factory, even though exhaust fans ventilated the area.</S>
    <S sid="322" ssid="91">What's interesting about this example is that the text does not provide us with enough information to decide about the correct interpretation; it is as if the writer didn't think it necessary for the reader to assign an unambiguous interpretation to the definite description.</S>
    <S sid="323" ssid="92">Similar cases of underspecified definite descriptions have been observed before (e.g., Nunberg's John shot himself in the foot [1978] or I'm going to the store mentioned in Clark and Marshall [19811) but no real account has been given of the conditions under which they are possible.</S>
  </SECTION>
  <SECTION title="5." number="6">
    <S sid="324" ssid="1">5.1.1 Consequences for Corpus Annotation.</S>
    <S sid="325" ssid="2">This study raises the issue of how feasible it is to annotate corpora for anaphoric information.</S>
    <S sid="326" ssid="3">We observed two problems about the task of classifying definite descriptions: first, neither of the more complex classification schemes we tested resulted in a very good agreement among annotators; and second, even the task of identifying the antecedent of discourse-related definite descriptions (i.e., coreferential and bridging) is problematic&#8212;we only obtained an acceptable agreement in the case of coreferential definite descriptions, and it was difficult for our annotators to choose a single antecedent for a definite description when both bridging and coreference were allowed.</S>
    <S sid="327" ssid="4">These results indicate that annotating corpora for anaphoric information may be more difficult than expected.</S>
    <S sid="328" ssid="5">The task of indicating a unique antecedent for bridging definite descriptions appears to be especially challenging, for the reasons discussed above (multiple equally good antecedents and referential underspecification, for example).</S>
    <S sid="329" ssid="6">On the positive side, we have two observations: our subjects did reasonably well at distinguishing fir&#167;t-mention from subsequent-mention antecedents, and at identifying the antecedent of a subsequent-mention definite description.</S>
    <S sid="330" ssid="7">A classification scheme based on this distinction (such as Fraurud's) that just asked subjects to indicate an antecedent for subsequent-mention definite descriptions may have a chance of resulting in a standardized annotation.</S>
    <S sid="331" ssid="8">Even in this case, however, the agreement we observed was not very high, but better results may be obtained with more training.</S>
    <S sid="332" ssid="9">The possibility we are exploring is that these results might get better if annotators are given computer support in the form of a semiautomatic classifier&#8212;i.e., a system capable of suggesting to annotators a classification for definite descriptions, including possibly an indication of how reliable the classification might be.</S>
    <S sid="333" ssid="10">We briefly discuss below our progress in this direction so far.</S>
    <S sid="334" ssid="11">5.1.2 Consequences for Linguistic Theory.</S>
    <S sid="335" ssid="12">Our study confirms the findings of previous work (e.g., Fraurud [1990]) that a great number of definite descriptions in texts are discourse-new: in our second experiment we found an equal number of discourse-new and discourse-related definite descriptions, although many of the definite descriptions classified as discourse-new could be seen as associative in a loose sense.</S>
    <S sid="336" ssid="13">Interestingly, this suggests that each of the competing hypotheses about the licensing conditions for definite descriptions&#8212;the uniqueness and the familiarity theory accounts&#8212;accounts satisfactorily for about half of the data.</S>
    <S sid="337" ssid="14">Of the existing theories of definite descriptions, the one that comes closest to accounting for all of the uses of definite descriptions that we observed is Lobner 's (1985).</S>
    <S sid="338" ssid="15">Lobner proposes that the defining property of definite descriptions, from a semantic point of view, is that they indicate that the head noun complex denotes a functional concept, i.e., a function which, according to Lobner, can take one, two, or three arguments.</S>
    <S sid="339" ssid="16">He argues that some head noun complexes denote such a function on purely lexical semantic grounds: this is the case, for example, of the head noun complexes in the father of Mr. Smith, the first man to sail to America and the fact that life started on Earth; he calls these definite descriptions semantic definites.</S>
    <S sid="340" ssid="17">In other cases, such as the dog, the head noun by itself would not denote a function, but a sort: in these cases, according to Lobner, the use of a definite description is only felicitous if context indicates the function to be used.</S>
    <S sid="341" ssid="18">This latter class of pragmatic definites includes the best-known cases of familiar definites&#8212;anaphoric, immediate and visible situation, and larger situation&#8212;as well as some cases classified by Hawkins as unfamiliar and by Prince as containing inferrables.</S>
    <S sid="342" ssid="19">Lobner does not discuss the conditions under which a writer can assume that the reader can recognize that context creates a functional concept out of a sortal one, but his account could be supplemented by Clark and Marshall's theory of what may count as a basis for a mutual knowledge induction schema (Clark and Marshall 198418 5.1.3 Consequences for Processing Theories.</S>
    <S sid="343" ssid="20">Given that first-mention definite descriptions are so numerous, and that recognizing them does not depend on commonsense knowledge alone, we conclude that any general theory of definite description interpretation should include methods for recognizing such definites.</S>
    <S sid="344" ssid="21">The architecture of our own classifier (see below) is also consistent with Fraurud's hypothesis that these methods are not just used when no suitable antecedent can be found, but more extensive investigations will be needed before we can conclude that this architecture significantly outperforms other ones.</S>
    <S sid="345" ssid="22">The presence of such a large number of discourse-new definite descriptions is also problematic for the idea that definite descriptions are interpreted with respect to the global focus (Grosz 1977; Grosz and Sidner 1986).</S>
    <S sid="346" ssid="23">A significant percentage of the larger situation definite descriptions encountered in our corpus cannot be said to be in the global focus in any significant sense: as we observed above, in many of these cases the writer seems to rely on the reader's capability to add a new object such as the Illinois Commerce Commission to her or his model of the world, rather than expecting that object to be already present.</S>
    <S sid="347" ssid="24">As already mentioned, we are in the course of implementing a system capable of performing the classification task semiautomatically (Vieira 1998).</S>
    <S sid="348" ssid="25">This system would help the human classifiers by suggesting possible classifications, and possible antecedents in the case of discourse-related definite descriptions.</S>
    <S sid="349" ssid="26">Our system implements the dual-processing strategy discussed above.</S>
    <S sid="350" ssid="27">On the one hand, it attempts to resolve anaphoric same head definite descriptions by maintaining a simple discourse model and searching back into this model to find all possible antecedents of a definite description (using special matching heuristics to deal with preand postmodification).</S>
    <S sid="351" ssid="28">On the other, it uses heuristics to identify unfamiliar and larger situation definite descriptions on the basis of syntactic information and very little lexical information about nouns that take complements.</S>
    <S sid="352" ssid="29">The current order of application of the resolution and classification steps has been determined by empirical testing, and has been compared with that suggested by decision-tree learning techniques.</S>
    <S sid="353" ssid="30">We trained a version of the system on the corpus used for the first experiment, and then compared its classification of the corpus used for the second experiment with that of our three subjects.'</S>
    <S sid="354" ssid="31">We developed two versions of the system: one that only attempts to classify subsequent-mention and discourse-new definite descriptions (Vieira and Poesio 1997), and one that also attempts to classify bridging references (Poesio, Vieira, and Teufel 1997).</S>
    <S sid="355" ssid="32">The first version of the system finds a classification for 318 definite descriptions out of the 464 in our test data (the articles used in the second experiment).</S>
    <S sid="356" ssid="33">The agreement between the system and the three annotators on the two classes first-mention and subsequent-mention is K = 0.70 overall (K = 0.77 for the three annotators on the converted annotation), if all definite descriptions to which the system cannot assign a classification are treated as first-mention; the coefficient of agreement is K = 0.78 if we do not count the definite descriptions that the system cannot classify (K = 0.81 for the annotators on just those definite descriptions).</S>
    <S sid="357" ssid="34">The version of the system that also attempts to recognize bridging references has a worse performance, which is not surprising given the problems our subjects had in classifying bridging descriptions.</S>
    <S sid="358" ssid="35">This version of the system finds a classification for 355 descriptions out of 464, and its agreement with the three annotators is K = 0.63 if the cases that the system cannot classify are not counted (K = 0.70 for the three annotators on three categories with just these definites); K = 0.57 if we count the cases that the system does not classify as discourse-new (for 447 descriptions); and K = 0.63 again if we count the cases that the system does not classify as bridging (again, 447 descriptions).</S>
    <S sid="359" ssid="36">We collected plenty of data about definite descriptions that we are still in the process of analyzing.</S>
    <S sid="360" ssid="37">One issue we are studying at the moment is what to do with bridging references: how to classify them if at all, and how to process them.</S>
    <S sid="361" ssid="38">We also intend to study Lobner's hypothesis about the role played by the distinction between sortal and relational head nouns in determining the type of process involved in the resolution of a definite description, possibly by finding a way to ask our subjects to recognize these distinctions.</S>
    <S sid="362" ssid="39">We also plan to study the issue of generic definites.</S>
    <S sid="363" ssid="40">An obvious direction in which to extend this study is by looking at other kinds of anaphoric expressions such as pronouns and demonstratives.</S>
    <S sid="364" ssid="41">We are doing preliminary studies in this direction.</S>
    <S sid="365" ssid="42">Finally, we would like to emphasize that although this study is the most extensive investigation of definite description use in a corpus that we know of (we looked at a total of more than 1,400 definite descriptions in 33 texts, i.e., almost three times as many as in Fraurud's study), in practice we still got very little data on many of the uses of definite descriptions, so some caution is necessary in interpreting these results.</S>
    <S sid="366" ssid="43">The problem is that the kind of analysis we performed is extremely time consuming: it will be crucial in the future to find ways of performing this task that will allow us to analyze more data, possibly with the help of computer simulations.</S>
  </SECTION>
  <SECTION title="Appendix A: Instructions to the Annotators (First Experiment)" number="7">
    <S sid="367" ssid="1">You will receive a set of texts to read and annotate.</S>
    <S sid="368" ssid="2">From the texts, the system will extract and present you &amp;quot;the&amp;quot;-phrases and will ask you for a classification.</S>
    <S sid="369" ssid="3">You must choose one of the following classes: noun phrase which has a different noun for the interpretation of the given &amp;quot;the&amp;quot;phrase.</S>
    <S sid="370" ssid="4">The antecedent for the &amp;quot;the&amp;quot;-phrase in this case may Also for unfamiliar uses of &amp;quot;the&amp;quot;-phrases the text does not provide an antecedent.</S>
    <S sid="371" ssid="5">The &amp;quot;the&amp;quot;-phrase refers to something new to the text.</S>
    <S sid="372" ssid="6">The help for the interpretation may be given together with the &amp;quot;the&amp;quot;-phrase as in PREFERENCE ORDER FOR THE CLASSIFICATION: In spite of the fact that definites often fall in more than one class of use, the identification of a unique class is required.</S>
    <S sid="373" ssid="7">In order to make the choices uniform, priority is to be given to anaphoric situations.</S>
    <S sid="374" ssid="8">According to this ordering, cases like &amp;quot;the White House&amp;quot; or &amp;quot;the government&amp;quot; are anaphoric rather than larger situation, when it has already occurred once in the text.</S>
    <S sid="375" ssid="9">When a &amp;quot;the&amp;quot;-phrase seems to belong both to larger sit./unfamiliar and associative classes, preference is given to larger sit.</S>
    <S sid="376" ssid="10">/unfamiliar.</S>
    <S sid="377" ssid="11">[Examples from the corpus were given as in Section 31 There is an antecedent in the text which has the same descriptive noun of the &amp;quot;the&amp;quot;-phrase.</S>
    <S sid="378" ssid="12">2.: ASSOCIATIVE There is an antecedent in the text which has a different noun, but it is a synonym or associate to the description.</S>
    <S sid="379" ssid="13">WHEN THE REFERENT FOR THE DESCRIPTION IS KNOWN OR NEW:(3,4) The &amp;quot;the&amp;quot;-phrase is an idiomatic expression</S>
  </SECTION>
  <SECTION title="Appendix B: Instructions to the Subjects (Second Experiment)" number="8">
    <S sid="380" ssid="1">This material provides you with instructions, examples and some training for the text-annotation task.</S>
    <S sid="381" ssid="2">The task consists of reading newspaper articles and analyzing occurrences of DEFINITE DESCRIPTIONS, which are expressions starting with the definite article THE.</S>
    <S sid="382" ssid="3">We will call these expressions DDs or DD.</S>
    <S sid="383" ssid="4">DDs describe things, ideas or entities which are talked about in the text.</S>
    <S sid="384" ssid="5">The things, ideas or entities being described by DDs will be called ENTITIES.</S>
    <S sid="385" ssid="6">You should look at the text, carefully in order to indicate whether the ENTITY was mentioned before in the text and if so, to indicate where.</S>
    <S sid="386" ssid="7">You will receive a set of texts and their corresponding tables to fill in.</S>
    <S sid="387" ssid="8">There are basically four cases to be considered: &amp;quot;Mrs. Park is saving to buy an apartment.</S>
    <S sid="388" ssid="9">The housewife is saving harder than ever.&amp;quot; the ENTITY described by the DD &amp;quot;the housewife&amp;quot; was mentioned before as &amp;quot;Mrs. Park&amp;quot;.</S>
    <S sid="389" ssid="10">2.</S>
    <S sid="390" ssid="11">If the ENTITY itself was not mentioned before but its interpretation is based on, dependent on, or related to some other idea or thing in the text, you should indicate it.</S>
    <S sid="391" ssid="12">For instance, in the sequence: &amp;quot; The Parks wanted to buy an apartment but the price was very high. the ENTITY described by the DD the price is related to the idea expressed by an apartment in the text.</S>
    <S sid="392" ssid="13">3.</S>
    <S sid="393" ssid="14">It may also be the case that the DD was not mentioned before and is not related to something in the text, but it refers to something which is part of the common knowledge of the writer and readers in general.</S>
    <S sid="394" ssid="15">(The texts to be analyzed are Wall Street Journal articles - location and time, for instance, are usually known to the general reader from sources which are outside the text).</S>
    <S sid="395" ssid="16">Example: &amp;quot;During the past 15 years housing prices increased nearly fivefold&amp;quot;. here, the ENTITY described by the DD the past 15 years is known to the general reader of the Wall Street Journal and was not mentioned before in the text.</S>
    <S sid="396" ssid="17">4.</S>
    <S sid="397" ssid="18">Or it may be the case that the DD is self-explanatory or it is given together with its own identification.</S>
    <S sid="398" ssid="19">In these cases it becomes clear to the general reader what is being talked about even without previous mention in the text or without previous common knowledge of it.</S>
    <S sid="399" ssid="20">For instance: &amp;quot;The proposed legislation is aimed at rectifying some of the inequities in the current land-ownership system.&amp;quot; the ENTITY described here is new in the text, and is not part of the knowledge of readers but the DD the inequities in the current land-ownership system is self-explanatory.</S>
    <S sid="400" ssid="21">The texts will be presented to you in the following format: on the left, the text with its DDs in evidence; on the right, the keys (number of the sentence/number of DD) and the DD to be analyzed.</S>
    <S sid="401" ssid="22">The key is for internal control only, but it may help you to find DDs in the table you have to fill in.</S>
    <S sid="402" ssid="23">Text 0 1 Y. J.</S>
    <S sid="403" ssid="24">Park and her family scrimped for four years to buy a tiny apartment here, but found that the closer they got to saving the $40,000 they originally needed, the more the price rose.</S>
    <S sid="404" ssid="25">3 Now the 33-year-old housewife, whose husband earns a modest salary as an assistant professor of economics, is saving harder than ever.</S>
    <S sid="405" ssid="26">Each case (1 to 4, above) is to be indicated on the table according to the following (see examples in the table below): Whenever you find a previous mention in the text of the DD you should mark the column LINK: In the case of both 1 and 2 you should provide the sentence number where the previous/related mention is and write down the previous/related mention of it (see example in the table below).</S>
    <S sid="406" ssid="27">If the entity was not previously mentioned in the text and it is not related to something mentioned before, then mark the column NO LINK: In case of doubt just leave the line in blank and comment at the back of the page using the key number to identify the DD you are commenting on.</S>
    <S sid="407" ssid="28">Next we present some examples and further explanation for each one of the four cases that are being considered.</S>
    <S sid="408" ssid="29">Case 1 - LINK (.)</S>
    <S sid="409" ssid="30">For case no.</S>
    <S sid="410" ssid="31">1 you may find a previous mention that may be equal or different from the DD (for instance, the government - the government, a report - the report, and three bills - the proposed legislation in the examples below); distances from previous mentions and DDs may also vary.</S>
    <S sid="411" ssid="32">Case 2 - LINK (R) Here are cases of DDs which are related to something that was present in the text.</S>
    <S sid="412" ssid="33">If you ask for the examples below, &amp;quot;Which government, population, nation is that?&amp;quot;,&amp;quot;Which blame is that?&amp;quot; the answer is given by something previously mentioned in the text (Koreans, and the increase of housing prices, respectively) 20. housing prices increased nearly fivefold.</S>
    <S sid="413" ssid="34">The report laid the blame on speculators, who it said had pushed land prices up ninefold.</S>
    <S sid="414" ssid="35">Case 3 - NO LINK (K) These cases of DDs are based on the common reader's knowledge.</S>
    <S sid="415" ssid="36">The texts to be analyzed are Wall Street Journal articles - location and time, for instance, are usually known to the general reader from sources which are outside the text 21.</S>
    <S sid="416" ssid="37">Case 4 - NO LINK (D) These cases of DDs are self-explanatory or accompanied by their identification.</S>
    <S sid="417" ssid="38">For instance if you ask &amp;quot;Which difficulty is that?&amp;quot;, &amp;quot;Which fact is that?&amp;quot;, &amp;quot;Which know-how is that?&amp;quot; etc. for the examples below, the answer is given by the DD itself.</S>
    <S sid="418" ssid="39">In the last example the DD is accompanied by its explanation.</S>
  </SECTION>
  <SECTION title="SCRIPT" number="9">
    <S sid="419" ssid="1">In order to help you filling in the table, answer the YES-NO questions below for each one of the DDs in the text.</S>
    <S sid="420" ssid="2">When the answer for the question is YES (Y) you have an action to follow, if the answer is NO (N), skip to the next question. mentioned before and tell where by providing the sentence number and the words used in the previous mention.</S>
    <S sid="421" ssid="3">N Go to question no.</S>
    <S sid="422" ssid="4">2.</S>
    <S sid="423" ssid="5">2.</S>
    <S sid="424" ssid="6">Is the ENTITY new but related to something mentioned before?</S>
    <S sid="425" ssid="7">If you ask: &amp;quot;Which entity is that?&amp;quot;, is the answer based on previous text 22?</S>
    <S sid="426" ssid="8">Y Mark &amp;quot;R&amp;quot; (column LINK) to indicate related entity and provide the sentence number and the previous mention on which the DD is based.</S>
    <S sid="427" ssid="9">N Go to question no.</S>
    <S sid="428" ssid="10">3.</S>
    <S sid="429" ssid="11">3.</S>
    <S sid="430" ssid="12">Is the ENTITY new in the text?</S>
    <S sid="431" ssid="13">If it was not mentioned before and its interpretation is not based on the previous text, then: is it something mutually known by writer and general readers of the Wall Street Journal?</S>
    <S sid="432" ssid="14">Y Mark &amp;quot;K&amp;quot; (column NO LINK) to indicate general knowledge about the entity.</S>
    <S sid="433" ssid="15">N Go to question no.</S>
    <S sid="434" ssid="16">4.</S>
    <S sid="435" ssid="17">4.</S>
    <S sid="436" ssid="18">Is the ENTITY new in the text?</S>
    <S sid="437" ssid="19">If it was not mentioned before and its interpretation is not based on the previous text, then: is it self-explanatory or accompanied by its identification?</S>
    <S sid="438" ssid="20">Y mark &amp;quot;D&amp;quot; (column NO LINK) to indicate that the description is enough to make readers identify the entity.</S>
    <S sid="439" ssid="21">N Leave the line in blank and comment at the back of the page using the key number to identify the DD.&amp;quot;</S>
  </SECTION>
  <SECTION title="Acknowledgments" number="10">
    <S sid="440" ssid="1">We wish to thank Jean Carletta for much help both with designing the experiments and with the analysis of the results.</S>
    <S sid="441" ssid="2">We are also grateful to Ellen Bard, Robin Cooper, Kari Fraurud, Janet Hitzeman, Kjetil Strand, and our anonymous reviewers for many helpful comments.</S>
    <S sid="442" ssid="3">Massimo Poesio holds an Advanced Research Fellowship from EPSRC, UK; Renata Vieira is supported by a fellowship from CNPq, Brazil.</S>
  </SECTION>
</PAPER>
