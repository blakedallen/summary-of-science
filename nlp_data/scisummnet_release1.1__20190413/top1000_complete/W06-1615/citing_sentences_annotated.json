[
  {
    "citance_No": 1, 
    "citing_paper_id": "D07-1129", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Nobuyuki, Shimizu | Hiroshi, Nakagawa", 
    "raw_text": "Following (Blitzer et al, 2006), we present an application of structural correspondence learning to non-projective dependency parsing (McDonald et al, 2005)", 
    "clean_text": "Following (Blitzer et al, 2006), we present an application of structural correspondence learning to non-projective dependency parsing (McDonald et al, 2005).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "D07-1129", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Nobuyuki, Shimizu | Hiroshi, Nakagawa", 
    "raw_text": "In this paper, we investigate the effectiveness of structural correspondence learning (SCL) (Blitzer et al, 2006) in the domain adaptation task given by the CoNLL 2007", 
    "clean_text": "In this paper, we investigate the effectiveness of structural correspondence learning (SCL) (Blitzer et al, 2006) in the domain adaptation task given by the CoNLL 2007.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P11-1033", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Bin, Lu | Chenhao, Tan | Claire, Cardie | Benjamin, K. Tsou", 
    "raw_text": "Prettenhofer and Stein (2010) investigate cross lingual sentiment classification from the perspective of domain adaptation based on structural correspondence learning (Blitzer et al, 2006)", 
    "clean_text": "Prettenhofer and Stein (2010) investigate cross lingual sentiment classification from the perspective of domain adaptation based on structural correspondence learning (Blitzer et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P10-2048", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Bin, Wei | Christopher, Pal", 
    "raw_text": "There has been a lot of work in domain adaption for NLP (Dai et al, 2007) (Jiang and Zhai, 2007) and one suitable choice for our problem is the approach based on structural correspondence learning (SCL) as in (Blitzer et al, 2006) and (Blitzer et al, 2007b)", 
    "clean_text": "There has been a lot of work in domain adaption for NLP (Dai et al, 2007) (Jiang and Zhai, 2007) and one suitable choice for our problem is the approach based on structural correspondence learning (SCL) as in (Blitzer et al, 2006) and (Blitzer et al, 2007b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P10-2048", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Bin, Wei | Christopher, Pal", 
    "raw_text": "These features can either be identified with heuristics (Blitzer et al, 2006) or by automatic selection (Blitzer et al, 2007b)", 
    "clean_text": "These features can either be identified with heuristics (Blitzer et al, 2006) or by automatic selection (Blitzer et al, 2007b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "D07-1070", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "David A., Smith | Jason M., Eisner", 
    "raw_text": "However, another approach is to train a separate out-of-domain parser, and use this to generate additional features on the supervised and unsupervised in-domain data (Blitzer et al, 2006)", 
    "clean_text": "However, another approach is to train a separate out-of-domain parser, and use this to generate additional features on the supervised and unsupervised in-domain data (Blitzer et al, 2006).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "D07-1096", 
    "citing_paper_authority": 178, 
    "citing_paper_authors": "Joakim, Nivre | Johan, Hall | Sandra, K&uuml;bler | Ryan, McDonald | Jens, Nilsson | Sebastian, Riedel | Deniz, Yuret", 
    "raw_text": "Recent work by McClosky et al (2006) and Blitzer et al (2006) have shown that the existence of a large unlabeled corpus in the new domain can be leveraged in adaptation", 
    "clean_text": "Recent work by McClosky et al (2006) and Blitzer et al (2006) have shown that the existence of a large unlabeled corpus in the new domain can be leveraged in adaptation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P11-1014", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Danushka, Bollegala | David, Weir | John, Carroll", 
    "raw_text": "SCL is the structural correspondence learning technique of Blitzeret al (2006)", 
    "clean_text": "SCL is the structural correspondence learning technique of Blitzer et al (2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D09-1058", 
    "citing_paper_authority": 27, 
    "citing_paper_authors": "Jun, Suzuki | Hideki, Isozaki | Xavier, Carreras | Michael John, Collins", 
    "raw_text": "Note that there are some similarities between our two-stage semi-supervised learning approach and the semi-supervised learning method introduced by (Blitzer et al, 2006), which is an extension of the method described by (Ando and Zhang, 558 2005)", 
    "clean_text": "Note that there are some similarities between our two-stage semi-supervised learning approach and the semi-supervised learning method introduced by (Blitzer et al, 2006), which is an extension of the method described by (Ando and Zhang, 558 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W10-2607", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Anna, Margolis | Karen, Livescu | Mari, Ostendorf", 
    "raw_text": "SCL (Blitzer et al, 2006) is one feature representation approach that has been effective on certain high-dimensional NLP problems, including part-of-speech tagging and sentiment classification", 
    "clean_text": "SCL (Blitzer et al, 2006) is one feature representation approach that has been effective on certain high-dimensional NLP problems, including part-of-speech tagging and sentiment classification.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W10-2607", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Anna, Margolis | Karen, Livescu | Mari, Ostendorf", 
    "raw_text": "The other dimensions of both domains were difficult to interpret. We experimented with using the SCLfeatures together with the raw features (n-grams and length), as suggested by (Blitzer et al, 2006)", 
    "clean_text": "The other dimensions of both domains were difficult to interpret. We experimented with using the SCL features together with the raw features (n-grams and length), as suggested by (Blitzer et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W10-2607", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Anna, Margolis | Karen, Livescu | Mari, Ostendorf", 
    "raw_text": "As in (Blitzer et al, 2006), we found it necessary to scale up the SCL features to increase their utilization in the presence of the raw features; however, it was difficult to guess the optimal scaling factor without having access to labeled target data", 
    "clean_text": "As in (Blitzer et al, 2006), we found it necessary to scale up the SCL features to increase their utilization in the presence of the raw features; however, it was difficult to guess the optimal scaling factor without having access to labeled target data.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W10-2607", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Anna, Margolis | Karen, Livescu | Mari, Ostendorf", 
    "raw_text": "In this way our problem resembles the part-of-speech tagging task 50 (Blitzer et al, 2006), where the category of each word is predicted using values of the left, right, and current word token", 
    "clean_text": "In this way our problem resembles the part-of-speech tagging task (Blitzer et al, 2006), where the category of each word is predicted using values of the left, right, and current word token.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W10-1757", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Kevin, Duh | Katsuhito, Sudoh | Hajime, Tsukada | Hideki, Isozaki | Masaaki, Nagata", 
    "raw_text": "(Blitzer et al, 2006) applies the multi task algorithm of (Ando and Zhang, 2005) to domain adaptation problems in NLP", 
    "clean_text": "(Blitzer et al, 2006) applies the multitask algorithm of (Ando and Zhang, 2005) to domain adaptation problems in NLP.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W11-0310", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Ruchita, Sarawgi | Kailash, Gajulapalli | Yejin, Choi", 
    "raw_text": "Of course, it is a known fact that machine learning techniques do not transfer well across different domains (e.g., Blitzer et al (2006))", 
    "clean_text": "Of course, it is a known fact that machine learning techniques do not transfer well across different domains (e.g., Blitzer et al (2006)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P11-2021", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Anna, Margolis | Mari, Ostendorf", 
    "raw_text": "Finally, we compare two domain adaptation approaches to utilize unlabeled speech data: bootstrapping, and Blitzer et al? s Structural Correspondence Learning (SCL) (Blitzer et al, 2006)", 
    "clean_text": "Finally, we compare two domain adaptation approaches to utilize unlabeled speech data: bootstrapping, and Blitzer et al's Structural Correspondence Learning (SCL) (Blitzer et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P11-2021", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Anna, Margolis | Mari, Ostendorf", 
    "raw_text": "In contrast with bootstrapping, SCL (Blitzer et al,2006) uses the unlabeled target data to learn domain independent features", 
    "clean_text": "In contrast with bootstrapping, SCL (Blitzer et al,2006) uses the unlabeled target data to learn domain independent features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W09-2420", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Eneko, Agirre | Oier, L&oacute;pez de Lacalle | Christiane, Fellbaum | Andrea, Marchetti | Antonio, Toral | Piek, Vossen", 
    "raw_text": "Blitzer et al (2006) used Structural CorrespondenceLearning and unlabeled data to adapt a Part-of Speech tagger", 
    "clean_text": "Blitzer et al (2006) used Structural Correspondence Learning and unlabeled data to adapt a Part-of Speech tagger.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P14-1058", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Danushka, Bollegala | David, Weir | John, Carroll", 
    "raw_text": "For example, the word signal is predominately used as a noun in MEDLINE, whereas it appears predominantly as an adjective in the Wall Street Journal (WSJ) (Blitzer et al, 2006)", 
    "clean_text": "For example, the word signal is predominately used as a noun in MEDLINE, whereas it appears predominantly as an adjective in the Wall Street Journal (WSJ) (Blitzer et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P14-1058", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Danushka, Bollegala | David, Weir | John, Carroll", 
    "raw_text": "Blitzer et al (2006) append the source domain labeled data with predicted pivots (i.e. words that appear in both the source and target domains) to adapt a POS tagger to a tar get domain", 
    "clean_text": "Blitzer et al (2006) append the source domain labeled data with predicted pivots (i.e. words that appear in both the source and target domains) to adapt a POS tagger to a target domain.", 
    "keep_for_gold": 1
  }
]
